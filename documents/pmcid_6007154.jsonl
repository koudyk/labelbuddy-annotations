{"text": "Runge, Matthew S and Cheung, Mike W-L and D\u2019Angiulli, Amedeo\nNeurosci Conscious, 2017\n\n# Title\n\nMeta-analytic comparison of trial- versus questionnaire-based vividness reportability across behavioral, cognitive and neural measurements of imagery\n\n# Keywords\n\nvividness\nvividness of visual imagery questionnaire\nimagery\nneuroimaging\nvalidity\n\n\n# Abstract\n \nVividness is an aspect of consciousness related to mental imagery and prospective episodic memory. Despite being harshly criticized in the past for failing to demonstrate robust correlations with behavioral measures, currently this construct is attracting a resurgent interest in cognitive neuroscience. Therefore, an updated examination of the validity of this construct is timely. A corpus of peer-reviewed literature was analyzed through meta-analysis, which compared the two main formats used to measure vividness [trial-by-trial vividness ratings (VR) and the Vividness of Visual Imagery Questionnaire (VVIQ)]. These two formats were compared in relation to all available behavioral/cognitive (BC) and neuroscience (NS) measures in Phase 1 (3542 statistical observations representing 393 journal articles); and then in relation to all available BC, EEG and fMRI literature in Phase 2 (3624 observations representing 402 articles). Both Phases observed significantly larger effect size estimates (ESEs) for VR than VVIQ, and larger ESEs for NS than BC measures. ESEs for EEG and fMRI were not significantly different in Phase 2, but were greater than BC ESEs. These data suggest VR are a more reliable self-report measure than VVIQ, and may reflect a more direct route of reportability than the latter. Furthermore, both VR and VVIQ are more strongly associated with the neural, than the cognitive and behavioural correlates of imagery. If one establishes neuroscience measures as the criterion variable, then self-reports of vividness show higher construct validity than behavioural/cognitive measures of imagery. We discuss how the present findings contribute to current issues on measurement of reportability; and how this study advances our understanding of vividness as a phenomenological characteristic of imagery, and other forms of conscious experience which do not necessarily involve imagery. \n \n\n# Body\n \n## Introduction \n  \nVisual mental imagery refers to the subjective experience of a percept-like pattern in the absence of a relevant physical stimulus on the retina ( ;  ). Historically,   was the first to observe that the \u201cdetail and clarity with which individuals experience mental imagery\u201d involves an individual difference gradient across a population, which he operationally defined as \u201cvividness.\u201d While much progress has been achieved in clarifying the neural and information processing nature of mental imagery, dimensions such as vividness, which concern the phenomenal experience of imagery, have potentially been neglected by contemporary cognitive psychology. Indeed, after  , in the last 15 years very few examples can be found in the literature attempting to readdress this topic and its ambiguousness [see  ] or situate it within the broader arena of consciousness research [see  ]. Correspondingly, it seems very little progress has been made in terms of a complete account of mental imagery which offers a constructive integration of its component dimensions \u2013 cognitive, affective, neural, and phenomenological [the term \u201cconstructive\u201d is borrowed from  ]. \n\nLack of progress in this direction is surprising, given that no author ever denies the experiential aspects of imagery (or, similarly, that vividness of imagery is relevant to the scientific study of inner experience). On the contrary, experiential aspects of mental imagery continue to be used circularly, and ubiquitously for defining the psychological status and relevance of mental imagery [for both points, see  ]. For example, imagery paradigms that require subjects to provide an observable objective behavior (e.g. a button press) in response to generating, holding or transforming images rely on subjects being aware that they are experiencing an image. Thus, objective responses during imagery tasks are incontrovertibly entangled with the report of phenomenological awareness [see  ]. Because conscious phenomenal awareness of the imagery experience is constitutive of what is reported (the content of conscious experience), the button press or other behavioral measures are not independent of the reported content ( ). In other words, there is no independent way of telling whether the button press or other behavioral measures involve visual mental imagery, unless the latter experience is explicitly reported by the subject. This type of circularity is generally acknowledged in the broader context within the study of visual consciousness ( ;  ). \n\nIn the \u201cimagery debate,\u201d two contending approaches provide the best accounts for several aspects of imagery, and still remain the most influential cognitive psychology approaches to its study. According to  \u2019s \u201cpictorial theory,\u201d visual mental images are constructed from depictive representations, which come into play at higher stages of visual information processing during actual perception. According to  \u2019s \u201ctacit knowledge,\u201d experimental data on visual mental images simply reflect different instances of what people implicitly know or believe about how they perceive. Although Kosslyn and Pylyshyn do not explicitly acknowledge, or refer to the vividness construct overtly in their theories, and both authors might even summarily dismiss the relevance of the vividness construct, they allude to it at several critical junctions in their explanatory arguments, as evidenced by the following examples. \n\nIn discussing the mental scanning paradigm and the size of mental images, to illustrate what tacit knowledge involves,  , p. 163) repeatedly refers to \u201cdetails\u201d represented in images and \u201cblurry\u201d versus \u201cclear\u201d images. These adjectives epitomize the two terms used to describe vividness, according to the classical definition of vividness in psychology ( ,  ;  ; note the historical reference has been introduced by the authors of the current paper, Pylyshyn did not mention it). Consequently, at least some of his key conclusions about self-reports assume the validity of the vividness measure is sufficient. \n\nOn the other hand, in a paper that set the methodology benchmark for a series of fMRI studies showing activation of V1 by visual imagery,   use the word vividness when describing their mental imagery model based on Hebb\u2019s cell assembly hypothesis; especially, in framing some aspects of their data. For example, when discussing the controversy concerning the reinterpretation of mental images ( ), these authors argue that past imagery reinterpretation tasks may have required high-resolution images. Cues were effective in facilitating reinterpretation because their \u201c\u2026 images were not very vivid\u201d ( , p. 286). Additionally, these authors defend another conclusion carefully stating that \u201c\u2026 additional effort is required in imagery to represent visual patterns with high resolution.\u201d However, resolution and vividness were equated earlier in the article: \u201ctranslated in our present understanding, more vivid images would occur when stored information activates lower areas, which have higher spatial resolution than do higher areas\u201d ( , p. 277). Correspondingly, at least some of the supporting explanations used by Kosslyn   et al.   go circularly back to vividness. \n\nEven if these authors do not acknowledge vividness as a classical and contemporary psychological construct, it is nonepiphenomenal in the context of their explanations, and cannot be eliminated, nor refuted at present. In addition, a number of imagery researchers have shown that properties available to self-report, such as the ones typically included in definitions of vividness can reflect the resolution of the visual buffer [see  ;  ]. Furthermore, at the crossroads with imagery \u2013 episodic memory and cognitive neuroscience \u2013 some investigators use self-report variables such as Paivio\u2019s imageability ( ), or other contextual variables in their experiments ( ) as an indirect way to observe, interpret, and discuss the underlying vividness of the cognitive event. Thus, it seems that contentions toward the validity of the vividness construct do not take in consideration subtle differences in how vividness is actually measured, or what vividness actually means. Reexamination of the construct of vividness is timely also because multiple versions of essentially a similar latent construct are increasingly being used in different areas of neuroscience and psychology related to, but other than mental imagery, such as prospective and episodic memory ( ), and aging ( ). Vividness is increasingly becoming a central topic for phenomenological, neurobiological, and genetic links between visual memory and emotion ( ). Thus, the concept has the potential to advance many fields of research, but presumably for structural and historical constraints, transdisciplinary integration of advances in knowledge seems to progress inductively, from more specific, particular topics (case in point, vividness in imagery) to the general (consciousness). \n\nWith such transdisciplinary background in mind, the purpose of the present article is to update the status of vividness. We attempt to achieve the goal by working toward a new way to substantiate the construct with empirically demonstrated validity, which includes current findings from neuroscience, among other different disciplines. Our approach to the study of the validity of vividness, however, is based on \u201creference\u201d rather than \u201cmeaning\u201d ( ). From this perspective, the crucial issue is not what \u201cvividness really means,\u201d but rather, to what extent our subjective measures of imagery vividness work; namely, whether they measure the intended core latent attribute of inner conscious experience that comes with having visual mental images. Therefore, we already make the prior assumption that there does exist, in reality, an attribute that one designates when using the term \u201cvividness.\u201d Following this approach, the issue of validity can be reduced to whether a measurement instrument is sensitive to variations of the assumed attribute ( ). Namely, the question becomes: what do subjective vividness instruments really measure? \n\nTo find out what is measured, one has to find out how the instrument works. Accordingly, the development of any construct requires the refinement of its operational definition, namely, defining the range of variation of the underlying assumed attribute, such that it can be calibrated more precisely against related psychological and neurophysiological variables ( ). For example, to illustrate one of the most relevant ambiguity that has been identified over the years, although vividness is operationally defined by the key words \u201cdetail\u201d and \u201cclarity,\u201d   observed a neurophysiological distinction between the vividness of a memory and the detail a memory possesses, as they relate to brain activation patterns. Such ubiquity could be interpreted as contradictory, but from the empirical point of view just confirms earlier phenomenological findings, that across several different instruction conditions, people seem to heed to, and report on, both an intensive aspect of the sensory strength of their images (or \u201cclarity,\u201d generally described as brightness and color) and the level of precision or \u201cdetail\u201d discerned within them ( ;  ;  ). \n\nAs two very recent landmark studies show, the ubiquity that seems associated with the construct of vividness almost invariably reflects empirical variations in individual differences. On the one hand, it has been shown the overlap in neural activation (especially in the early primary visual cortex, V1) between imagery and perception is directly, positively correlated with trial by trial vividness ratings (VR) and imagery ability ( ). On the other hand, individual differences in the imagery experience are found to vary according to the two inversely correlated attributes associated with the size of V1. Individuals with above-average V1 size experience higher detailedness but lower sensory strength, whereas individuals with below-average V1 size show the opposite pattern (Bergman   et al.   2016). But most important, performance and verbal reports by the majority of people, with average V1 size, reflect a relative mixture of those two visual features of images. \n\nPrevious phenomenological and behavioral (Reaction Times modeling) evidence confirms the trend in the majority of the observers, and based on the weight of this evidence combined with neurophysiological data ( ;  ) some authors defend that it seems reasonable to assume as a definition of vividness the most exhaustive subjective conscious experience of imagery, in terms of both amount of detail (resolution) and sensory strength of a mental image, relative to the experience of actual seeing. The latter operational working definition is the frame of reference for the tests of validity proposed in this article. \n\nA line of thinking about validity similar to the one just discussed has led to some of the strongest arguments demarking the necessity and objectifiability of self-reports in cognitive neuroscience, and consciousness research more generally. Particularly relevant is   analysis of the \u201ctriangulation\u201d in consciousness research; namely, the convergent use of introspective, behavioral and neurophysiological evidence. As they argued, empirical validity of introspective reports cannot be only established by examining the relationship between reported vividness and other objective behavioral measures (e.g. memory accuracy). Rather, empirical validity should be based on the relationship between neural correlates of perceived vividness and reported vividness at the first-person level. Without considering perceived vividness (what the person is actually experiencing), the fact that reported vividness may not correlate with behavior does not refute the validity of the vividness construct. Crucially, reported vividness may still be strongly correlated with the neural correlates of perceived vividness experience. Because vividness was defined \u223c130 years ago, and its main synthetic assessment [the meta-analysis by  ] did not include current neuroscience findings, the construct requires an updated reconsideration as to what it actually means in the fields of consciousness and imagery at present. This effort may accommodate novel, contemporary conceptualizations concerning the nature of memory ( ), or even new knowledge regarding the neural basis of consciousness, such as the default mode network ( ). \n\nIn addition, as a psychological construct, vividness requires convergent and discriminative validation through empirical, objective testing. For instance, vividness has been positively correlated with performance on perceptual and memory tasks ( ;  ;  ), arousal level ( ;  ), and sleep stages ( ), even though it is debated whether or not it is correlated with certain dynamic spatial tasks like mental rotation ( ;  ). Moreover, a growing body of research suggests VR correlate with neural modulations in specific brain regions ( ;  ;  ;  ;  ), which covary with the phenomenological ratings offered by participants. \n\nPerhaps the most commonly used global assessment of imagery ability is the Vividness of Visual Imagery Questionnaire (VVIQ;  ;  ;  ) and its successor the VVIQ2 ( ;  ). The VVIQ provides a global assessment of vividness, and is typically used to categorize participants according to the individual differences in visual imagery ability. It consists of 16 items, which are to be rated on a five-point scale from (1) \u201cperfectly clear and as vivid a normal vision,\u201d to (5) \u201cno image at all, you only \u2018know\u2019 that you are thinking of the object.\u201d The versatility of the VVIQ is such that it can be administered before, during, or after experimental manipulations, and demonstrates sufficient retest and internal reliability ( ). \n\nAlternatively, vividness may be rated on a \u201ctrial-by-trial\u201d VR basis through a single response, which corresponds to the subjective experience at a particular moment in time, structurally constrained by what types of images participants are required to form. In addition to methodological advantages,   argue that trial-by-trial VR are perhaps the most effective means by which imagery vividness can be studied (e.g.  ). Similarly, participants are prompted with a scale such as that used in the VVIQ, wherein vividness is rated from (1) \u201cno image,\u201d to (5) \u201cperfectly vivid\u201d (albeit the scale can range from 1 to 3, 1 to 7, 1 to 100, etc.). A major contention concerning the use of VVIQ is that global assessments offered through surveys of group differences in mental imagery ability may describe too coarsely, or even miss specific cognitive and neural processes affiliated with the phenomenological experience of vividness occurring within each trial ( ). \n\nThe reliability of vividness, as a construct presumed to reflect identifiable and separable processes, is largely undermined through the use of a single test score, such as the one offered by the VVIQ, or global assessments of imagery ability more generally ( ). In contrast, experimental procedures employing VR may procure more reliable patterns of results and interpretations than those employing the VVIQ ( ;  ,  ;  ;  ;  ). If VR are observed in structured experimental settings, and participants are given clear instructions as to the nature of the task, VR may resolve critically informative and specific aspects concerning the subjective experience of the imagery processes ( ). In this way, VR are a type of retrospective verbal report ( ), which can be put in correspondence with decomposable task-related behavior and neural processes. Accordingly, VR is compatible with the principle of \u201creportability,\u201d i.e., the more general condition with which the levels and contents of phenomenal conscious awareness in visual working memory can be properly defined and investigated ( ;  ). \n\nExperimental results which are based on behavioral, cognitive, or neuroscience types of measures are assumed to produce effects which vary in their relative sizes; however, there has been no systematic quantitative comparison that evaluates the claim, nor offers an evidence-based indication as to whether vividness provides weak or robust data [for a complete account of this debate, see  ]. Adopting a meta-analysis approach offers the opportunity to formulate a set of clear and straightforward hypotheses and predictions that could be put forward to empirical testing. Because VRs resolve critical aspects of, and measure a greater subset of the variability in the mental imagery experience, they may systematically demonstrate greater content validity than the VVIQ within behavioral, cognitive, and neuroscience experimental paradigms ( ;  ;  ;  ). Accordingly, one would expect larger effect sizes for VR [see  ]. If VR resolve phenomenological aspects of mental imagery to a greater degree than the VVIQ (i.e. they are more exhaustive), then the reported effect sizes pertaining to VR should be greater in magnitude than the effect sizes associated with the VVIQ, when averaged over a large and representative sample of relevant literature. To test this first key hypothesis, in the present meta-analysis, VR were compared against all available behavioral, cognitive, and neuroscience imagery measures throughout a robust and representative sample of literature with the VVIQ providing the criterion variable against which self-reports are traditionally compared and validated ( ). \n\nThe viability of an evidence-based approach to mental imagery is one which is theoretically driven by and supported through neurocomputational modeling ( ). In addition, neuroimaging experiments typically exhibit a great amount of control and precision ( ). Thus, the second hypothesis tested through the present meta-analysis was that neuroscience measures may resolve critical aspects of the mental imagery experience more reliably than behavioral and or cognitive ones, and as result, it would be possible to conclude that vividness may be more thoroughly validated as an independent and empirical construct through neuroscience approaches. If neuroscientific measures are capable of resolving phenomenological vividness more closely than behavioral and or cognitive ones, then the prediction follows that the reported magnitude of effect sizes which are neuroscience should be greater than those which are behavioral and or cognitive. Specifically, VRs should also be greater than the VVIQ for effect sizes which are associated with neuroscience measurements. The latter outcome would entail a broader implication in terms of how conscious verbal reports of imagery could be conceptualized. That is, imagery reportability may be associated with two routes, a \u201cdirect\u201d route, represented by VRs, and an indirect one, represented by VVIQ. Following   general typologies of verbal protocols, it would be reasonable to interpret the predicted pattern as an indication that VR and VVIQ may reflect two different processing routes supporting retrospective verbal reports as postulated in the schemas shown in  . Like other types of retrospective reports, VR are obtained by asking subjects about a neurocognitive process which recently occurred. It is reasonable that in structured conditions, in which VR are collected, the image contents may be accessed through a relatively more direct route, with minimal verbal recoding and delay that reflect predominantly or exclusively task-relevant information and processes ( , right panel). Conversely, in the case of VVIQ, VR may require additional scanning, filtering, inference or rule-based and metacognitive processes; as a result, verbalization may mediate or even modify the imagery experience revealing information or knowledge that goes beyond or is not relevant to processes underlying the task ( , left panel). \n  \nSchematic models representing types of VR (left panel: VVIQ; right panel: trial-by-trial VR) as particular cases of two retrospective verbal report processing routes, adapted from  . Like other types of retrospective reports, VR are obtained by asking subjects about a process which occurred recently. This figure shows the cases similar to introspection, in which VR requires scanning, filtering, inference, or rule-based processes, thus verbalization mediates or even modifies the imagery task. \n  \nA third hypothesis may also be derived as a possible contingency from the first two, if the presence of a significant interaction is observed between Vividness and Measure factors, it may represent a differential propensity for VR/VVIQ within the behavioral/cognitive (BC) and/or NS dimensions. Because the effect sizes for VR are hypothesized to exceed those of the VVIQ for both BC and NS measurements, failing to reject the null hypothesis for the interaction effect would imply the strongest form of convergent validation, and support for the first two hypotheses. \n\n\n## Method: Phase 1 \n  \n### Sampling \n  \nA corpus of peer-reviewed journal articles representing a robust subset of the relevant literature available through the databases Web of Science, Scopus, Embase, and PsycINFO were retrieved through our University\u2019s library on October 25th, 2012.   A priori   criteria restricted the search results to those of the English language, to those published after 1950, and those using human subjects. Given the current major issues concerning the inclusion of \u201cgrey literature\u201d \u2013 such as poorer research quality, search un-standardization, data duplication and/or incompleteness, minimal reliability improvement at cost of major energy/resource search expenditure [see extensive review in  ] \u2013 theses, dissertations, and other unpublished works were deliberately avoided (a more detailed rationale for this decision contextualized to the present study is given in the \u201cDiscussion\u201d section). Data for Phase 1 are available upon request. \n\nSearch parameters included the general terms \u201cvivid* and image*\u201d, as well as additional syntax employed to minimize the discovery of irrelevant papers (see  ). A total of 1290 journal articles were discovered (Web of Knowledge, 36; Scopus, 34; Embase, 188; PsycINFO, 1032), and exported to RefWorks, wherein 320 duplicates were observed and deleted from the corpus. The remaining 970 journal articles were systematically analyzed in relation to their relevance to the research question. Those which did not include at least one relevant statistical outcome relating either vividness ratings (VR) and/or VVIQ to another variable were not considered further, of which there were 577. From the remaining 393 papers that contained at least one relevant statistical outcome, each and every statistical outcome relating either VR and/or VVIQ to another variable was recorded into a database, as it appeared in the original journal article. \n\n\n### Data trimming and data analysis \n  \nUpon inclusion into the database, every statistical outcome was categorized as either VR or VVIQ, and further categorized as either BC, or neuroscience (NS). A total of 3697 statistical outcomes were observed from the 393 papers included, which were organized into four focal categories (VR ,   n  \u2009=\u20091826; VVIQ ,   n  \u2009=\u20091680; VR ,   n  \u2009=\u200982; VVIQ ,   n  \u2009=\u200962), and one peripheral category consisting of observations which directly correlated VR with VVIQ (  n  \u2009=\u200947). \n\nEach statistical outcome was transformed from its original statistical metric into the form of the correlation coefficient (  r  ), from which absolute Fisher\u2019s   Z   transformed score were computed. Statistical outcomes for which   r   could not be calculated were excluded from the analysis (  n  \u2009=\u2009108), such as beta-values (  n  \u2009=\u200973),   t  ,   F  ,   r, U  , and   q   values which did not included sufficient information (  n  \u2009=\u200935). Because scaling phenomenological ratings from 1 (low) to 5 (high), has the exact opposite meaning as scaling phenomenological ratings from 5 (low) to 1 (high), rearranging statistical outcomes to accommodate the scaling   post priori   was methodologically difficult. Subsequently, the present research abandoned directionality and transformed   Z   vector quantities to their absolute, scalar   Z   form. Observations directly measuring VR and VVIQ together were considered separately, such that an average correlation could be isolated. \n\nData were modeled with a series of three-level meta-analysis ( ;  ). Traditional meta-analytic approaches assume independence in the effect sizes ( ). As there are 3697 effect sizes nested within 393 studies in the present meta-analysis, statistical inferences of traditional meta-analysis are incorrect. Three-level meta-analysis enables researchers to implement an additional cluster effect (dependence within the same study). Although ignoring dependence is not recommended, aggregating multiple statistical outcomes into one summary statistic can likewise be problematic ( ), as it may afford larger standard errors affiliated with parameter estimates, and generally contributes to a high attrition rate (loss of sample size). As such, the present research necessitated a more precise and accommodating meta-analytic framework to answer the primary research question in Phase 2. Data were analyzed using R software, with the \u201cmetaSEM\u201d package ( ). The level-2 and level-3 heterogeneity variances represent the within- and between-study heterogeneity variances, respectively. If the level-2 heterogeneity variance is large, it means that the reported effect sizes also vary within the same study. \n\nCorrespondingly, data for VR  (  n  \u2009=\u20091760) represented 238 experiments from 194 journal articles, VVIQ  (  n  \u2009=\u20091640) represented 248 experiments from 212 journal articles, VR  (  n  \u2009=\u200980) represented 13 experiments from 13 journal articles, and VVIQ  (  n\u2009  =\u200962) represented 7 experiments from 7 journal articles. A 2 (VR, VVIQ) \u00d7 2 (BC, NS) study design was used to test the abovementioned research hypotheses (i) effect sizes on VR are larger than those on VVIQ; (ii) effect sizes on NS are larger than those on BC; and (iii) there is an interaction between these two factors. \n\n\n\n## Results \n  \nA preliminary analysis was first performed, wherein a three-level meta-analytic framework was employed to determine the overall effect size estimate (ESE), and parameter estimates for the entire dataset. The average ESE (  Z  ) with its 95% Wald confidence interval (CI) was 0.4011 [0.3795, 0.4227], where the level-2 and level-3 heterogeneity variances (\u03c4 ) were 0.0434 and 0.0404, respectively. The test on the null hypothesis of equality of population level-2 and level-3 heterogeneity variances is not statistically significant, \u03c7  (1)\u2009=\u20090.4913,   P\u2009=\u2009  0.4833. The percentage of variation accounted for at level-2 and level-3 (  I  ) were 0.4572 and 0.4249, respectively. This indicates the effect sizes have similar degree of variation within and between studies. Subsequently, a moderator variable was created for each focal category, and the data from each focal category were subjected to an independent three-level meta-analytic framework, such that an internal ESE for each category could be calculated. The ESE and parameter estimates for the four focal categories are presented in   and  . In comparison to the overall model, the effect of the moderator variables was statistically significant, \u03c7  (3)\u2009=\u200965.03,   P\u2009  <\u20090.001.\n   \nDescriptive statistics for phase 1, including the number of statistical outcomes, number of journal articles, number of experiments, ESEs, and 95% Wald CIs for each category \n  \n  \nInternal ESEs for each of the four categories in Phase 1, and their 95% Wald CIs. Also plotted are the predicted values from the regression analysis (dotted lines), which are based on the model without the interaction.   Note  : the 95% Wald CIs are based on the estimated values (not the predicted values). \n  \nA 2 Vividness (VR, VVIQ) \u00d7 2 Measure (BC, NS) design was used to test the research hypotheses with a mixed-effects meta-analysis. The interaction between Vividness and Measure was not statistically significant \u03c7  (1)\u2009=\u20091.71,   P   = 0.19, which indicated that the effect of Vividness and Measure was additive. In other words, the effect of Vividness is independent of the effect of Measure (and vice versa). We may independently interpret the effects of Vividness and Measure. When there is an interaction, however, the effect of Vividness depends on the level of Measure (and vice versa). We need to select the level of Measure when we interpret the effect of Vividness (and vice versa). Both Vividness and Measures were significant \u03c7  (2)\u2009=\u200963.31,   P   < 0.001, level-3   R  \u2009=\u20090.182. The ESE for VR was statistically greater than VVIQ (\u0394  Z  \u2009=\u20090.133, 95% Wald CI [0.093, 0.173]), after controlling the effect of Measure. NS was statistically greater than BC (\u0394  Z  \u2009=\u20090.257, 95% Wald CI [0.150, 0.364]), after controlling the effect of Vividness. Finally, concerning the peripheral analysis examining the direct relationship between VR and VVIQ, the results from 47 effect sizes nested within 19 studies using a three-level meta-analysis suggests an ESE of 0.3977 (0.2886, 0.5069), where the level-2 and level-3 heterogeneity variances (\u03c4 ) were 0.0260 and 0.0293, respectively. \n\n\n## Discussion \n  \nThe results from the Phase 1 offered significant insight into the ESEs for each of the four focal categories. Although the differences between VR and VVIQ appear to be robust within the BC dimension, the differences within the NS dimension were not as clear cut. Nevertheless, the peripheral category directly correlating VR and VVIQ suggests a weak to moderate relationship. Comparisons concerning the NS dimension did not resolve any differences between VR and VVIQ; however, this effect may have remained unresolved for at least two reasons. First, standard error (SE) within each of the NS focal categories was larger than those within the BC focal categories, which resulted from a much smaller sample size, and a much larger estimate of within study variance (  \u1e7d\u2019  ). Secondly, between-study heterogeneity (  \u03c4  ) was generally larger within the NS focal categories. \n\nTwo strategies were implemented to homogenize the NS focal categories. First, because no future searches indicated additional evidence pertaining to PET (  n  \u2009=\u20095), NIRS (  n  \u2009=\u20096), or pharmacological NS (  n  \u2009=\u20094) neuroscience outcomes, and to avoid overestimating between study error, only fMRI (  n  \u2009=\u200973), and EEG (  n  \u2009=\u200954) were selected as representative to the NS sample. Incidentally, this methodological conceptualization may lend insight into temporal specific (EEG) and spatial specific (fMRI) variations in neurophysiological measurement within this construct. If indicative, a differential propensity for the NS dimension may be observed between fMRI and EEG, a pattern of which should be emergent between both VR and VVIQ. Secondly, another systematic literature search was performed to acquire previously undiscovered journal articles pertaining to VR and VVIQ in the context of NS, but specifically those relating to fMRI and/or EEG. \n\n\n## Method: Phase 2 \n  \n### Sampling \n  \nIn an effort to clarify the meaning of the NS data specifically, an exhaustive systematic search was performed, which sought to discover any and all journal articles relating VR and/or VVIQ to EEG and/or fMRI. Four strategies were employed. First, PsychINFO was searched on July 20th, 2015, using the specific parameters \u201cvivid* fMRI\u201d, and \u201cvivid* EEG\u201d, from which six novel journal articles were discovered ( ;  ;  ;  ;  ;  ) resulting in 37 novel observations (VR ,   n  \u2009=\u200930; VR ,   n\u2009  =\u20094; VVIQ ,   n  \u2009=\u20093; VVIQ ,   n  \u2009=\u20090). Similar searches through PsychINFO for VVIQ did not return any results. \n\nSecond, the entire library catalog in our institution was searched on July 20th, 2015 using the specific parameters \u201cVVIQ fMRI,\u201d and \u201cVVIQ EEG,\u201d from which three novel journal articles were discovered ( ;  ;  ), resulting in 27 novel observations (VR ,   n\u2009  =\u20096; VR ,   n  \u2009=\u20090; VVIQ ,   n  \u2009=\u20090; VVIQ ,   n  \u2009=\u200921). \n\nThird, the discussion sections of all relevant papers were read, and references were recorded for comparisons the authors sought to explain their findings. This resulted in an additional two novel journal articles ( ;  ), resulting in 29 novel observations (VR ,   n  \u2009=\u200928; VR ,   n  \u2009=\u20090; VVIQ ,   n  \u2009=\u20091; VVIQ ,   n  \u2009=\u20090). Finally, a journal article known to be relevant ( ), and published in a pilot study through this research group, and not found in any other search was also included, resulting in four novel observations (VR ,   n  \u2009=\u20094; VR ,   n\u2009  =\u20090; VVIQ ,   n  \u2009=\u20090; VVIQ ,   n  \u2009=\u20090). Data for Phase 2 are available upon request. \n\n\n### Data trimming and data analysis \n  \nThe novel fMRI and EEG data from Phase 2 were compiled with existing fMRI and EEG data from Phase 1. Subsequently, the entire NS database consisted of 224 observations. Data for VR  (  n  \u2009=\u2009102) represented 13 experiments from 13 journal articles, VVIQ  (  n  \u2009=\u200943) represented eight experiments from eight journal articles, VR  (  n  \u2009=\u200935) represented six experiments from six journal articles, and VVIQ  (  n  \u2009=\u200944) represented four experiments from four journal articles. BC data from Phase 1 were also borrowed from Phase 1, resulting in a 2 (VR, VVIQ) \u00d7 3 (BC, EEG, fMRI) study design. Phase 2 data were modeled in the same way as Phase 1. A 2 (VR, VVIQ) \u00d7 3 (BC, EEG, fMRI) study design was used to test the abovementioned research hypotheses (i) effect sizes on VR are larger than those on VVIQ; (ii) effect sizes on EEG and fMRI are larger than those on BC; and (iii) there is an interaction between these two factors. \n\nDuring the interval of time required for peer-review, a final library search was conducted to double check that the database was still representative of the very latest publications. The search revealed that only three new (fMRI) papers published during the peer-review lag ( ;  ;  ) fitting the inclusion criteria were not included in our revised analysis. All the data points from these papers were observed to fall within the 95% CIs calculated in Phase 2 ( ).\n   \nDescriptive statistics for phase 2, including the number of statistical outcomes, number of journal articles, number of experiments, ESEs, and 95% Wald CIs for each category \n  \n\n\n\n## Results \n  \nA preliminary analysis was first performed, wherein a three-level meta-analytic framework was employed to determine the overall ESE, and parameter estimates for the entire dataset. The average ESE (  Z  ) with its 95% Wald CI was 0.4080 [0.3854, 0.4306], where the level-2 and level-3 heterogeneity variances (\u03c4 ) were 0.0427 and 0.0472, respectively. The test on the null hypothesis of equality of population level-2 and level-3 heterogeneity variances is not statistically significant, \u03c7  (1)\u2009=\u20091.03,   P\u2009=\u2009  0.31. Therefore, the percentage of variation accounted for at level-2 and level-3 (  I  ) were 0.4214 and 0.4660, respectively. This indicates the effect sizes have similar degree of variation within and between studies. Subsequently, a moderator variable was created for each focal category, and the data from each focal category were subjected to an independent three-level meta-analytic framework, such that an internal ESE for each category could be calculated. The ESE and parameter estimates for the six focal categories are presented in   and  . In comparison to the overall model, the effect of the moderator variables was statistically significant, \u03c7  (5)\u2009=\u200976.77,   P\u2009  <\u20090.001. \n  \nInternal ESEs for each of the six categories in Phase 2, and their 95% Wald CIs. Also plotted are the predicted values from the regression analysis (dotted lines), which are based on the model without the interaction.   Note  : the 95% Wald CIs are based on the estimated values (not the predicted values). \n  \nA 2 Vividness (VR, VVIQ) \u00d7 3 Measure (BC, EEG, fMRI) design was used to test the research hypotheses with a mixed-effects meta-analysis. The interaction between Vividness and Measure was not statistically significant \u03c7  (2)\u2009=\u20091.14,   P   = 0.57, which indicated that the effect of Vividness and Measure was additive. In other words, the effect of Vividness is independent of the effect of Measure (and vice versa). Both Vividness and Measures were significant \u03c7  (3)\u2009=\u200975.63,   P   < 0.001, level-3   R  \u2009=\u20090.214. The ESE for VR was statistically greater than VVIQ (\u0394  Z  \u2009=\u20090.137, 95% Wald CI [0.095, 0.178]), after controlling the effect of Measure. By using BC as the reference group, EEG was statistically greater than BC (\u0394  Z  \u2009=\u20090.229, 95% Wald CI [0.079, 0.379]), and the predicted ESE for fMRI was likewise statistically greater than BC (  \u0394Z  \u2009=\u20090.297, 95% Wald CI [0.184, 0.410], after controlling the effect of Vividness. There was no difference between the ESE for EEG and the ESE for fMRI, \u03c7  (1)\u2009=\u20090.52,   p\u2009=\u2009  0.47. \n\n\n## General Discussion \n  \nThe present research analyzed a robust and representative subset of literature in an effort to understand the relationship between trial-by-trial VR and VVIQ, within the context of behavioral/cognitive (BC) and neuroscience (NS) experimental paradigms in Phase 1, and within the context of BC, EEG, and fMRI experimental paradigms in Phase 2. \n\nThrough the preliminary analysis in Phase 1, a significant difference between the ESEs for VR and VVIQ in the context of BC experimentation was observed. This result is limited in so far as we assume the effect sizes used to create the database have the same statistical meaning, and that there are no systematic differences between the way in which VR and VVIQ are implemented in research. For example, it is possible that VVIQ is more conducive to between-groups comparison, and VR more conducive to within-group comparisons, which may imply the latter has inherently greater effect sizes. It is unlikely, however, that this limitation can account for the differences which were observed across these multiple domains of psychology and neuroscience. For example, the average correlation between VR and VVIQ was generally weak (  r   \u223c 0.40), for two measures which purportedly \u201cmeasure\u201d the same thing [note the correlation reported here is similar to the one reported by  ]. Although differences between VR and VVIQ were observed in Phase 1, the methodology utilized in Phase 2 sought to homogenize, and increase the sample size of the NS dimension, such that differences between the ESEs for VR and VVIQ could be observed within the NS dimension as well. \n\nThe statistical methodology employed in Phase 2 was designed to evaluate the data at different levels. Data were first analyzed at an overall level, then analyzed at theoretically determined levels, which were represented by six independent categories belonging to BC, EEG, or fMRI experimental types. The three-level meta-analysis provides a correct statistical model to handle multiple effect sizes nested within studies ( ). The ESE, when calculated over the entire dataset was approximately   Zr  \u2009=\u20090.40. Interestingly, the level-2 and level-3 estimates of heterogeneity, or the proportion of variation accounted for at each level (  I  ), show a similar magnitude (\u223c0.42, and \u223c0.47, respectively). This finding may suggest just as much variation exists within experiments as between. Finally, the unique contributions of Vividness and Measure were tested by a three-level mixed-effects meta-analysis with the data from Phase 2. \n\nThe results did not support the interaction between Vividness and Measure. This seems to suggest that the effects of Vividness and Measures are additive. On the other hand, the results provided strong support for both major hypotheses. VR demonstrated larger ESEs than the VVIQ, when compared against a large and representative sample, and larger ESEs were also observed for EEG and fMRI when compared with BC. Although BC experimental paradigms generally result in smaller ESEs, no significant difference was observed between EEG and fMRI neuro-imaging experiment types; albeit, the small sample sizes do not lend to a strong conclusion. Although fMRI has a tendency to overinflate effect sizes in some psychological contexts ( ), presumably based on statistical power, and limitations arising from small sample sizes ( ), the results of the present analysis do not suggest the ESE for fMRI data deviate significantly from EEG data. However, differences between VR and VVIQ remained unobserved within the EEG dimension, as this level of analysis was presumably limited by very small sample sizes (six and four experiments, respectively). \n\nIn relation to other subjective measures used in consciousness research, vividness could be interpreted as the measurement of a specific type of conscious experience, correlate of imagery. Although there have been very few studies comparing imagery vividness to the different types of subjective scales used in consciousness research such as the perceptual awareness scale (PAS, e.g.  ) or confidence ratings (CR, e.g.,  ), few older studies (pre-dating PAS creation) which compared VR in perception and imagery seem to show robust relationships ( ;  ). Relatively more studies showed that VVIQ, and to some extent VR, are correlated with CR [see  , for review; see also  ] in that as people rate themselves as having relatively more vivid images, they are also more confident about their imagery-related ability and performance (and females do so more than males). In addition, in his meta-analysis   reported on a subset of 15 studies correlating VVIQ and objective responses and subjective judgments in perceptual tasks, with composite effect size of   r  \u2009=\u20090.45 [95% CI\u2009=\u20090.31, 0.56]. Thus, issues of reportability for subjective measures of awareness used in consciousness research can shed some insights into vividness as a characteristic of conscious experiences in general. As reviewed by  , the validity and reliability of subjective measures of conscious awareness can be assessed through a set of reportability criteria: \u201cexhaustiveness\u201d (of all relevant contents in consciousness) and \u201cexclusiveness\u201d (of relevant conscious processes but not unconscious or irrelevant conscious ones), as well as how \u201cdirectly\u201d or \u201cindirectly\u201d the scales, ratings or reports, measure these attributes in underlying processes as defined by reference to objective measurements. Similar criteria can be applied to VR and VVIQ to better understand vividness as an attribute of visual consciousness. Hence, where relevant in the following discussion, we will highlight points of connection and the reciprocal implications for vividness as type-specific imagery experience measure and as an attribute sharing aspects common to other forms of consciousness as measured by PAS, CR, and other subjective measures. \n\nIf we consider VR as an entire set of all phenomenological experiences we can probe (we can ask participants to rate the vividness of mental images generated in any number of single trials), the VVIQ can only approximate this set, as it makes a series of vividness measurements from a small, standardized subset of all possible mental images we can imagine. Albeit, the questions used in the VVIQ may be highly exemplary/representative of the general vividness construct. According to this reasoning, the VVIQ is a robust subset of all VR. Although the 16 or 32 items on the VVIQ/VVIQ2 possess excellent content validity, they cannot accommodate special circumstances in human psychological experience, like those concerning flash-bulb memories in PTSD, or vivid mental images as they relate to mental health more generally ( ). As such, the greater effect sizes observed for VR observations is likely the surplus of what the VVIQ cannot measure. If VR can be seen as a specific type of subjective awareness measure such as PAS or CR used in consciousness research, then VR can be said to be more \u201cexhaustive\u201d than VVIQ as a measure of the conscious states associated with imagery, in that it reveals most of the relevant knowledge of the conscious state experienced by the imager. \n\nIn comparison to BC, larger ESEs were observed for EEG and fMRI experimental paradigms, which may lend weight to the interpretation that, when behavioral and cognitive factors are ruled-out, something extra remains unexplained in the statistical model, yet is captured by neuroimaging studies. Vividness ratings can be captured on a millisecond to millisecond temporal basis (EEG), and in a millimeter to millimeter spatial basis (fMRI), in a way which most closely approximates the conscious \u201cpsychological\u201d experience of the mental image. NS experimental paradigms allow for the resolution of specific and intrinsic processes, closely following the human psychological experience of vividness, which is an otherwise unobservable phenomenon. Given this interpretation requires extensive support, Phase 2 was designed to exhaustively retrieve any and all evidence linking vividness to brain modulation. A series of searches afforded 29 relevant papers, representing 224 effect sizes, which were statistically modeled with a series of three-level meta-analyses. The three-level meta-analysis has high statistical power as it includes all effect sizes and models the dependence of the data properly. The significance of the present results is contingent on the weight of a corpus of BC experimentation, which showed a similar pattern, but with a much larger sample size \u2013 and thusly \u2013 contribution to the overall analysis. \n\nAs previously mentioned, one possible limitation to the present analysis may be that VR and VVIQ correspond to different methodological designs, and the inherent lack of heterogeneity between these measures may warrant careful reconsideration of the abovementioned interpretation. However, systematic differences in the way VR and VVIQ are administered, if any, are marginal at best, and cannot account for the present pattern of results. First, the correlation between the VVIQ and VR was weak to moderate. Secondly, the present argument can be thought of as a trade-off in the implementation of the VVIQ, where the convenience of administering a questionnaire (which measures trait ability) sacrifices resolution moment-to-moment. VRs seem to reasonably resolve the spectrum of variability in the mental imagery experience (which can be assumed to include measurement of both trait and state ability). It is this variability which can be more sensitively correlated to modulations in brain activity, which exist within a narrow temporal and/or spatial window, the likes of which a questionnaire cannot impute. Just to clarify with an example, our scores on the VVIQ may very well be the same, but the vividness of events relating to my PTSD (if I suffered from it), would be wildly different than yours (if you did not). Such situational variability may be consistent with flash-bulb memories, pharmaceutical interventions, hallucinations, or dreams. Furthermore, we do acknowledge that the practical interpretability of the average effect size for each main category may be limited (for predictive purposes). However, the relativistic differences (VR\u2009>\u2009VVIQ) are sufficiently accurate, robust, withstanding replication and convergent validation. \n\nAnother potential limitation is that there is a disparity between the number of studies as well as the number of effect sizes in Phase I (VRBC,   n\u2009  =\u20091826; VVIQBC,   n  \u2009=\u20091680; VRNS,   n  \u2009=\u200982; VVIQNS,   n  \u2009=\u200962). This disparity indicates that traditionally BC has been much more studied than NS. The estimated average effects (VR versus VVIQ and BC versus NS) are still unbiased regardless of the disparity of the number of effect sizes. On the other hand, the estimated heterogeneity variances are likely biased toward BC as there are more studies in BC. \n\nThere are pros and cons of including unpublished studies in a meta-analysis.   argued against including unpublished studies. For example, unpublished studies are usually of weaker methodology. Moreover, the search for unpublished studies may also be biased due to the availability of unpublished studies to the authors. On the other hand,   provided counter arguments for including unpublished studies. They suggested unpublished studies may be excluded on the methodological rigorousness by using clearly defined inclusion criteria rather than excluding all unpublished studies. The present study only included effect sizes from published studies because we wanted to include peer-reviewed studies with rigorous methodology. However, we do not think that the presence of unpublished studies may alter our conclusions because there are more than 3600 effect sizes nested within about 400 studies. It is not feasible to find enough unpublished studies with null effect substantially changing our conclusions. \n\nIf one considers the totality of the available data in comparison to theoretically established categories, cluster/types of research can be independently identified, and decomposed from the overall analysis. The entire BC dimension could, by necessity, be further reduced into cluster/types (as were EEG and fMRI data decomposed from the Phase 1\u2009NS dimension), which can then be objectively compared, contrasted, and evaluated. In fact, the 32-month delay between the searches in both Phases represents a temporal necessity, allowing the collection of an incremental amount of literature pertaining to the spatial/temporal imaging of vividness, which remains a specialist field of ongoing research debate. After this interval of time, enough literature was compiled to reflect trends previously observed within the BC dimension. The replication of low \u201coverall\u201d effect sizes throughout the BC subdimensions is a consistent finding; here, \u0394  Zr   (\u223c0.14) is estimated to be the general differential throughout every possible subset comparison of VR and VVIQ within the BC dimension. The estimation is supported at an overall level, theoretically relevant NS levels, and replicated in two previous smaller subset analyses ( ;  ). \n\nThe question is, then, at what \u201clevel\u201d does one want to cluster the BC subsets? At some point, researchers are required to make a conceptual distinction between two or more types of research within an overall dataset. Indeed, \u201cBehavioural\u201d experimentation compared to \u201cCognitive\u201d experimentation may be the simplest BC comparison one could make, the effect of which was already measured as 0.40 \u201coverall\u201d \u2013 the VRs \u223c 0.46, and the VVIQs \u223c 0.32. Conversely, if one wants to make absolutely no assumptions concerning heterogeneity, only direct correlations between VR and VVIQ can be considered valid comparisons (because they are within studies, and unambiguously summarize the relationship), the effect size of which is similarly \u223c0.40. Making relevant theoretical distinctions [qualified by theory, quantified by estimates of heterogeneity (\u03c4 )] enables meta-analysis. For example, by concentrating research efforts on peer-reviewed quality reports and filtering out the gray literature, an acceptable level of journal quality heterogeneity was assumed, which was defined by the requirement of empirically evaluated, evidenced-based research ( ). \n\nFundamentally, the consistent observation that ESEs for VR exceed those of VVIQ suggests convergent validation, and under such circumstances, it is reasonable to conclude that VR is a more reliable self-report measure than VVIQ. In this context, however, we can go a step further and define \u201cmore reliable\u201d concretely in terms of underlying processes, which are related to reportability. That is, the present findings support the conclusion that VR offer a relatively more direct report of imagery, in that they may be more sensitive to immediate, unfiltered information about the visual qualities of mental images relevant to a task or a resting condition, and may show knowledge that is relatively more exclusive to sensory-perceptual consciousness. In contrast, VVIQ is more indirect, since it could include higher-order and metacognitive processes related to the self-judged expected ability to generate at will a visual image that corresponds to a complex scene (which includes relatively more abstract knowledge, and needs to be translated from a fairly complex verbal narrative). In many respects, the difference between VR and VVIQ parallels the difference between PAS and CR in consciousness research, where the former measure has been shown to be correlated more with perception than metacognition, whereas the latter shows the opposite pattern of correlation ( ). All the pros and cons of using PAS and CR, as those authors have well pointed out, also apply for VR and VVIQ. For example, both vividness measures might fail in being exclusive, because they might reflect information below the level the experimenter is interested in, or because unconscious processes may exert an influence by boosting or attenuating the ratings. However, it is unclear whether a \u201creverse subtractive logic\u201d can be pursued in comparing proportions of accounted variation in the data between VR and VVIQ, as it could be done for PAS and other subjective awareness measures. Could we infer that the differential \u201cunexplained\u201d variance between VR and VVIQ indicates underlying overflow conscious processes plus underlying unconscious processes? This is an interesting empirical question for future research. \n\nThe operational partition in neural and behavioural processes is a feature derived from the way the field has historically developed, and it reflects a legitimate reduction of the investigative approach: it is not practical, nor scientifically necessary to consider all possible variables and measures. However, it still remains that such partition is artificial. Phenomenology, neural, cognitive and behavioral processes are all components of an integrated system. The finding that both VR and VVIQ are more strongly associated with the neural components of imagery generation than the cognitive and behavioral ones implies that if neural measures are considered the third independent criterion of reference for validity, then VR, regardless of the route of reportability they implement \u2013 VR or VVIQ \u2013 may in some circumstances be more valid than behavioral (and cognitive) measures. The findings and theoretical implications of the present meta-analysis lend support to the view that typical findings in the literature which show low correlations between self-report and behavioral measures should not be necessarily interpreted as a weakness of the former, rather the latter. Studies that do not adopt a single behavioral measure as the gold standard and criterion variable, and use multiple formats of the construct of interest, show that construct validity coefficients of self-reports such as VR are invariably greater than their behavioral counterparts [see review in  ].As earlier noted by  , self-reports are an aspect of consciousness that needs to be established with brain patterns, to explain the nature of experience. Inevitably, they need to be understood. However, our \u201capproximation\u201d of what the sentient unit is experiencing at any particular moment in time grows as we fumble with reductionism, and deconstruction, consistent with an information-processing approach. Validity of vividness seems to be proportional to the correlation between vividness consciously experienced and vividness verbally reported, and it is a misjudgment to assume we cannot trust subject\u2019s verbal interpretations of their own conscious states. In other words, it is a misjudgment to assume that validity needs to be established only by robust correlations with behavioral measures. \n\nThe previous conclusion has all but a trivial implication since the data we have presented clearly do not support current approaches which call for \u201celiminating\u201d subjective measures, thereby only focusing on the relationship between behavioral and neural measures of conscious processes [see again  ]. Expanding on the Jack and Roepfstorff\u2019s triangulation challenge,  , p. 9) offered a compelling argument that from a possible lack of correlation between vividness and behavioral accuracy (for instance in memory), it is not possible to refute the correspondence between vividness measures and actual experienced vividness. The accuracy of the vividness measures may still be valid even if there is no correspondence between behavioral accuracy and experienced vividness. Our study contributes to this specific argument in showing that, empirically, brain activity measures correspond closely to vividness measures, and to a lesser degree to cognitive and behavioral measures. Consequently, matters appear to be a bit more complex: it is not so much about the absence of correspondence, since across many experiments all the terms in the set of relationships are to some extent reciprocally correlated. It is about the strength of the correlations, i.e., empirically what matters is the degree of precision (reliability) for which some relationships stand out more than others. \n\n\n## Vividness and Consciousness: Theoretical Underpinnings of Validity \n  \nFinally, we would like to discuss some implications of a more general, less technical nature concerning how this study is situated to advance our understanding of vividness and consciousness in general. That is, in terms of the validity approach we have taken this is the next logical step: we attempt here to provide a full blown (albeit concise) theory of the structure of the attribute which the term vividness refers to. \n\nThe present study is compatible with a tenet that is widely held in some current neurobiological theories of consciousness. In brief, that sensory-affective (not exclusively/necessarily visual) mental images, defined as objective \u201cisomorphic neural maps\u201d associated with external and inner (somatic) environmental input, can constitute the first-order basic building block of consciousness during both perception and memory of perception [for review see  ]. Within this broader theoretical framework, a corollary that can be added through this study is that vividness expresses the graded isomorphic aspect of the conscious experience that more or less directly and immediately arises from the brain\u2019s complex processing of sensory-affective information in perception and memory. That is, vividness could be conceived as a particular isomorphism or equivalence mapping function ( ) that goes beyond the \u201cturned on\u201d consciousness state; as it expresses changes and states of inner experience in terms of equivalent graded levels of knowledge. In this context, vividness may have the role of making explicit the level or strength of the isomorphic correspondence between the inner first-person experience of the input and the environmental input itself ( ). In other words, measurements of vividness, notably through VR, reflect the gradient of immediate conscious experience of images that mirror isomorphic objective neural processes during perception and memory. Thus, vividness can be considered a chief phenomenological feature of primary sensory consciousness, and it supports the idea that consciousness is a graded phenomenon. \n\nThe concept of vividness however can be extended to a number of other types of consciousness. Isomorphic maps may develop into and become embedded in more complex and dynamic neurofunctional structures [\u2018nested neural hierarchies\u2019  ; \u201cactivity cycles\u201d ( )] that include emotions, plans, goals and actions, etc., which are removed from immediate environmental inputs or memory of them, in other words, states of consciousness other than those associated with perception and memory. These states may involve derivative \u201csecond-order\u201d isomorphic correspondences ( ) whose organization is not in forms of maps, but complex multidimensional patterns [e.g. the computational conceptual structures described by  ]. In this other context, vividness may be recycled to express graded knowledge of conscious experience that may or may not be linked with any first-order isomorphic representations, and it may or may not recycle sensory-affective isomorphic maps in memory. In these cases, vividness may express conscious knowledge even though it is not necessarily experienced in the form of mental images. Hence, vividness may have also an important role in accounting for phenomenal conscious processes associated with mental simulation ( ), analogical reasoning ( ), and strategies and metacognition ( ). As suggested by our findings, VVIQ may be a particularly sensitive measure of vividness when the latter cases involve imagery. However, other subjective or indirect computational measures could be devised to indicate how vividness captures other aspects of conscious knowledge which do not involve or require mental images at all ( ). Indeed, as mentioned in the introduction, we believe one of the most promising potential future contributions of the construct of vividness may be allowing a constructive integration of the roles of emotions, motives and goals within neurocognitive and epigenetic theories of imagery and consciousness. \n\n\n## Conclusion \n  \nAlthough the first attempt to validate the vividness construct through meta-analysis can be attributed to  , his detailed and systematic study was limited to the VVIQ. The VVIQ became the most widely used, standard tool by which vividness, and imagery self-reports are studied ( ), but this conclusion may be predicated on an erroneous assumption. The present analysis suggests the study of vividness, and researcher conceptualization of it more generally, needs to be reconsidered. In addition, it suggests that the construct of vividness may be most thoroughly studied using neuroscience methodologies that do not necessarily have observable behavioural outputs, such that phenomenological self-reports may be reliably and validly associated with neural correlates on a trial-by-trial basis. Capitalizing on the theoretical and methodological underpinnings of its validity, the concept of vividness can explain key aspects of the phenomenological experience of mental imagery, but it can be applied beyond, extending to other forms of conscious awareness, which do not necessarily involve imagery. \n\n\n## Supplementary Material \n  \n \n", "metadata": {"pmcid": 6007154, "text_md5": "79437b48cd23a4d5a48a05c8b5c22e27", "field_positions": {"authors": [0, 60], "journal": [61, 79], "publication_year": [81, 85], "title": [96, 245], "keywords": [259, 341], "abstract": [354, 2265], "body": [2274, 64598]}, "batch": 2, "pmid": 30042840, "doi": "10.1093/nc/nix006", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6007154", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6007154"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6007154\">6007154</a>", "list_title": "PMC6007154  Meta-analytic comparison of trial- versus questionnaire-based vividness reportability across behavioral, cognitive and neural measurements of imagery"}
