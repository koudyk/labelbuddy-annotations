{"text": "Ran, Qian and Jamoulle, Tarik and Schaeverbeke, Jolien and Meersmans, Karen and Vandenberghe, Rik and Dupont, Patrick\nBrain Behav, 2020\n\n# Title\n\nReproducibility of graph measures at the subject level using resting\u2010state fMRI\n\n# Keywords\n\ndenoising\ngraph measures\nnetwork construction\nreproducibility\nresting\u2010state fMRI\ntest\u2013retest variability\n\n\n# Abstract\n \n## Introduction \n  \nGraph metrics have been proposed as potential biomarkers for diagnosis in clinical work. However, before it can be applied in a clinical setting, their reproducibility should be evaluated. \n\n\n## Methods \n  \nThis study systematically investigated the effect of two denoising pipelines and different whole\u2010brain network constructions on reproducibility of subject\u2010specific graph measures. We used the multi\u2010session fMRI dataset from the Brain Genomics Superstruct Project consisting of 69 healthy young adults. \n\n\n## Results \n  \nIn binary networks, the test\u2013retest variability for global measures was large at low density irrespective of the denoising strategy or the type of correlation. Weighted networks showed very low test\u2013retest values (and thus a good reproducibility) for global graph measures irrespective of the strategy used. Comparing the test\u2013retest values for different strategies, there were significant main effects of the type of correlation (Pearson correlation vs. partial correlation), the (partial) correlation value (absolute vs. positive vs. negative), and weight calculation (based on the raw (partial) correlation values vs. based on transformed   Z  \u2010values). There was also a significant interaction effect between type of correlation and weight calculation. Similarly as for the binary networks, there was no main effect of the denoising pipeline. \n\n\n## Conclusion \n  \nOur results demonstrated that normalized global graph measures based on a weighted network using the absolute (partial) correlation as weight were reproducible. The denoising pipeline and the granularity of the whole\u2010brain parcellation used to define the nodes were not critical for the reproducibility of normalized graph measures. \n\n  \nWe used the multi\u2010session fMRI dataset from the Brain Genomics Superstruct Project consisting of 69 healthy young adults. Our results demonstrated that normalized global graph measures based on a weighted network using the absolute (partial) correlation as weight were reproducible. The denoising pipeline and the granularity of the whole\u2010brain parcellation used to define the nodes were not critical for the reproducibility of normalized graph measures.   \n \n\n# Body\n \n## INTRODUCTION \n  \nResting\u2010state fMRI (rs\u2010fMRI) is a task\u2010free and an easy\u2010to\u2010use tool for neuroscientific data acquisition. It is used to detect spontaneous low frequency (<0.1\u00a0Hz) fluctuations of the brain by blood\u2010oxygen\u2010level\u2010dependent (BOLD) signals during a state of rest (Biswal, Yetkin, Haughton, & Hyde,\u00a0 ; Smith et\u00a0al.,\u00a0 ). Those fluctuations are highly organized across discrete brain regions (Greicius, Krasnow, Reiss, & Menon,\u00a0 ). Functional connectivity analysis is a way to analyze how distant brain regions interact and graph theory can be used to quantify performance of the entire network (Bullmore & Sporns,  ; Park & Friston,\u00a0 ; Sporns,\u00a0 ). \n\nMany studies have reported that alterations of interactions among distant brain regions and dysfunction of networks are closely related to brain diseases, such as epilepsy (Burianov\u00e1 et\u00a0al.,\u00a0 ), Alzheimer's disease (Greicius, Srivastava, Reiss, & Menon,\u00a0 ; Hallquist & Hillary,\u00a0 ; Johnson, Sperling, & Sepulcre,\u00a0 ) and among others. Petrella ( ) proposed the use of graph metrics as potential biomarkers and diagnostic tools in clinical work. However, before graph measures can be widely applied as a biomarker in a clinical setting, it is critical that a number of properties of graph measures should be evaluated rigorously. These properties include simplicity, robustness, and test\u2013retest variability. \n\nThe reproducibility of rs\u2010fMRI based graph measures faces a big challenge, namely how to effectively handle BOLD signals contaminated by noise (Bianciardi et\u00a0al.,\u00a0 ) and how to reduce the influence of noise on the reproducibility of graph measures. The main causes of this contamination are head motion and non\u2010neuronal physiological fluctuations. Head motion, even very subtle movement, has been demonstrated to have a negative impact on BOLD signals (Parkes, Fulcher, Y\u00fccel, & Fornito,\u00a0 ; Satterthwaite et\u00a0al.,\u00a0 ,  ). Therefore, the influence caused by head motion and non\u2010neuronal physiological fluctuations should be removed as much as possible to reduce the impact on functional connectivity. \n\nResearch in denoising techniques reducing the influence of noise in BOLD signals attracted quite some attention (Satterthwaite et\u00a0al.,\u00a0 ). Denoising techniques can have an impact on the reproducibility of graph measures. The most common strategies for denoising typically correct the signal using three types of information: (a) head movement parameters (Friston, Williams, Howard, Frackowiak, & Turner,\u00a0 ; Satterthwaite et\u00a0al.,\u00a0 ); (b) physiological signals derived from white matter and cerebrospinal fluid (Fox, Snyder, Vincent, & Raichle,\u00a0 ); and (c) a global signal regressor (GSR) (Fox, Zhang, Snyder, & Raichle,\u00a0 ; Murphy, Birn, Handwerker, Jones, & Bandettini,\u00a0 ). These strategies are often combined with temporal censoring of bad volumes that contain too much noise (Power, Barnes, Snyder, Schlaggar, & Petersen,\u00a0 ; Power et\u00a0al.,\u00a0 ; Satterthwaite et\u00a0al.,\u00a0 ). Unfortunately, there has been no agreement on which strategy is superior to reduce the noise present in rs\u2010fMRI images (Caballero\u2010Gaudes & Reynolds,\u00a0 ). Therefore, we investigated to which degree reproducibility of graph measures depends on the denoising techniques. \n\nBesides the challenge of reducing noise before network construction, network construction itself can influence the reproducibility of graph measures (Dimitriadis, Drakesmith, et al.,  ; Wang et\u00a0al.,\u00a0 ,  ). However, this has not been systematically explored. Network construction consists of defining the nodes of the network and defining the connectivity measure and how to calculate the weights of the network from this measure (Rubinov & Sporns,\u00a0 ). Nodes are the main elements of a network. They can be defined using an atlas or parcellation (Desikan et\u00a0al.,\u00a0 ; Shen, Tokoglu, Papademetris, & Constable,\u00a0 ; Tzourio\u2010Mazoyer et\u00a0al.,\u00a0 ). They can also be defined based on a set of a priori regions (Fritz et\u00a0al.,\u00a0 ) or based on a data\u2010driven method (de Vos et\u00a0al.,\u00a0 ) or even be defined as the voxels themselves (Horn et\u00a0al.,\u00a0 ). Different definitions of nodes have different advantages and limitations (Arslan et\u00a0al.,\u00a0 ). Node definition may affect reproducibility but also the way functional connectivity between nodes is calculated (Liang et\u00a0al.,\u00a0 ). The latter is typically based on a Pearson correlation but also partial correlations can be used since it can remove the influences of other nodes (Marrelec et\u00a0al.,\u00a0 ; Smith et\u00a0al.,\u00a0 ). Both types of correlation can be used to derive graphs. However, a choice needs to be made how to treat negative (partial) correlations. One option is to use the absolute value representing the information shared between two nodes. Graphs based on the absolute value are graphs in which all functional information among nodes is presented. An alternative is to study graphs based on only the positive or negative (partial) correlations separately setting the other values to zero. However, the proportion of positive and negative connections in a real network may vary, which may induce some bias if we would take only either positive correlations or negative correlations into account. The effect of these choices on the reproducibility of graph measures has not yet been systematically investigated. The last element of network construction is the choice between a weighted and a binary network. In weighted networks, a selection of connections can be made, for example, using a soft\u2010thresholding removing small weights and keeping the weights of the remaining connections or they can be used as fully weighted graphs in which no a priori selection is made (Li, Xue, Ellmore, Frye, & Wong,\u00a0 ; van den Heuvel, Mandl, Stam, Kahn, & Hulshoff Pol,\u00a0 ; Wang, Ghumare, Vandenberghe, & Dupont,\u00a0 ). For weighted networks, the weight can be obtained either from the raw (partial) correlations itself or from a transformed   Z  \u2010value after a Fisher   r  \u2010to\u2010  Z   transform (Wang et\u00a0al.,\u00a0 ). In binary networks, selection of connections is based on significance or amplitude. Selected connections will get a weight of 1 while the weight of the others is set to 0 (Hosseini et\u00a0al.,\u00a0 ; Wang et\u00a0al.,\u00a0 ). \n\nMost studies only focused on the robustness of resting\u2010state fMRI based graph measures at the group level (Braun et\u00a0al.,\u00a0 ; Du et\u00a0al.,\u00a0 ; Paldino, Chu, Chapieski, Golriz, & Zhang,\u00a0 ). Although it can provide interesting information about brain functioning in normal or pathological conditions, it is not sufficient if we want to introduce these techniques in a clinical setting in which subject\u2010specific graphs have to be constructed and quantified (Gordon et\u00a0al.,\u00a0 ; Poldrack et\u00a0al.,\u00a0 ). Therefore, we focused on subject\u2010specific graph measures in this paper. \n\nIn this study, we comprehensively investigated how these factors mentioned above affect the reproducibility of subject\u2010specific graph measures and investigated which combination gave reasonable results. We investigate the use of two denoising pipelines: a simple versus a more complex denoising pipeline (Ciric et\u00a0al.,\u00a0 ; Parkes et\u00a0al.,\u00a0 ). Furthermore, we investigated the use of the two functional connectivity measures (correlations vs. partial correlations), three different approaches to handle negative correlations (taking the absolute value, taking only positive values, or taking only the negative values), two types of network (binary or weighted), and two types of calculations of the weights of the network (based on the (partial) correlation values or based on a transformation of   Z  \u2010values obtained after a Fisher   r  \u2010to\u2010  Z   transformation). Finally, we also considered two levels of granularity for the whole\u2010brain parcellation (50 vs. 100 parcels per hemisphere). The overall aim was to answer the following questions: (a) are subject\u2010specific graph measures reproducible and (b) what is the optimal pipeline for rs\u2010fMRI based subject\u2010specific graph measures? \n\n\n## MATERIALS AND METHODS \n  \n### Dataset and ethical statement \n  \nWe used multi\u2010session fMRI datasets from the Brain Genomics Superstruct Project (GSP) (Holmes et\u00a0al.,\u00a0 ). This dataset consisted of 69 healthy young adults (34 males) between 19 and 27\u00a0years old and is publically available at  . All participants provided written informed consent in accordance with guidelines established by the Partners HealthCare Institutional Review Board and the Harvard University Committee on the Use of Human Subjects in Research (Holmes et\u00a0al.,\u00a0 ). All images were acquired at Harvard University and Massachusetts General Hospital using Siemens 3T MAGNETOM Tim Trio MRI scanners equipped with a 12\u2010channel phase\u2010array head coil. Each subject had two sessions on a different day with a gap between scan days within 6\u00a0months. Each session consisted of a structural scan and one or two runs of resting\u2010state fMRI. The structural image was a T1\u2010weighted Multi\u2010Echo MPRAGE (ME\u2010MPRAGE) image with 1.2\u00a0mm isotropic resolution (van der Kouwe, Benner, Salat, & Fischl,\u00a0 ). The BOLD images had a 3\u00a0mm isotropic resolution. Each BOLD volume had 47 slices including the full cerebellum. The interleaved slices were acquired in an interleaved fashion in ascending order (from bottom to top). The TR was 3\u00a0s, and the number of volumes in each run was 124. The total scan time of each functional run was 6\u00a0min and 12\u00a0s. During BOLD data collection, all participants were instructed to keep their eyes open while blinking normally. For more details about the scans, see (Holmes et\u00a0al.,\u00a0 ). \n\n\n### Standard preprocessing \n  \nThe standard preprocessing was performed using Matlab (R2014b) and Statistical Parametric Mapping software (version SPM12, Wellcome Department of Cognitive Neurology, London, UK;  ; RRID:SCR_007037). Before data preprocessing, we set the origin for all structural and functional MRI images close to the anterior commissure and if needed, adapted the orientation to make it more similar to the template in MNI space. This step only affected the transformation matrix and not the data itself since we did not reslice the images. The standard preprocessing steps included: (1) The first four dummy scans of each run were removed; (2) all resting\u2010state functional images were realigned to correct for head movement; (3) slice timing; (4) coregistration of the structural and mean functional image; (5) segmentation of the structural image which provides deformation fields to warp the data to MNI space; and (6) warping of the functional images to MNI space using the deformation field of each subject obtained in the previous step. \n\n\n### Image quality control \n  \nBesides visually checking image quality by a neuroradiologist (QR) to make sure there were no apparent structural abnormalities or artifacts present, image quality of the rs\u2010fMRI data was further assessed using the head movement parameters obtained during the realignment step (overall translation or rotation along any direction and framewise displacement) and the change in brain intensities between two consecutive volumes (Power et\u00a0al.,\u00a0 ,  ). \n\nFramewise displacement (FD) was calculated as (Power et\u00a0al.,\u00a0 ,  ). in which\n , and similarly for the other movement parameters\n . Note that the rotation parameters should be expressed in radians and translation parameters in mm. \n\nThe volume by volume intensity changes across whole\u2010brain voxels are calculated as (Power et\u00a0al.,\u00a0 ; Smyser et\u00a0al.,\u00a0 ). in which\n  is the image intensity at locus\n  in volume i, <.> denotes the spatial average over the whole\u2010brain voxels (Power et\u00a0al.,\u00a0 ; Smyser et\u00a0al.,\u00a0 ). \n\nIn this work, we used a cutoff value for FD of <0.5\u00a0mm consistent with values reported by Waheed et\u00a0al.\u00a0( ). The DVARS threshold was set (per run) at the mean of the DVARS values over time plus three standard deviations. The overall translation (across the run) was required to be <1.5\u00a0mm and the overall rotation <1.5\u00a0degrees (in all directions). When no 5\u00a0min interval was present with these characteristics, we applied scrubbing on those volumes which were outside these predefined limits. We only did this for at most 20 \u201cbad\u201d volumes. Scrubbing seems compelling to reduce head movement effects but at the cost of loss of temporal degrees of freedom (Ciric et\u00a0al.,\u00a0 ; Parkes et\u00a0al.,\u00a0 ). Furthermore, if too many volumes required scrubbing, it is not clear if the scrubbed data still represent the underlying connectivity. When none of the above was satisfied, we considered the data as of too low quality and that run was taken off\u2010study. \n\nTo investigate the reproducibility of graph measures among sessions, we selected the first run of each session except when the first run was taken off\u2010study in which case the second run was used. \n\n\n### Pipelines for denoising \n  \nWe selected two denoising pipelines: a simple approach on the one hand and a complex one on the other hand to evaluate the effect of denoising on the reproducibility of graph measures. The simple approach consisted of the inclusion of 9 regressors: 6 head motion parameters, 2 physiological parameters (a WM and CSF regressor, see below), and the GSR. The complex denoising pipeline had 30 regressors: 24 head motion parameters (6 basic ones along with their temporal derivatives, squared values and the squared values of the temporal derivatives), 2 physiological parameters along with their temporal derivatives and the global signal regressor along with its derivative. \n\nThe head motion parameters were derived from the realignment step in the preprocessing. WM and CSF regressors were extracted in a WM and a CSF mask, respectively, which were calculated as the intersection between the subject\u2010specific WM and CSF segmentations (thresholded at 0.9) and a priori masks of WM and CSF. The a priori masks were generated from the a priori masks from SPM (in case of CSF, we limited it to the lateral ventricles) by thresholding them at 0.5 and by applying an erosion to avoid being too close to GM. \n\nThe global signal regressor was calculated as the average BOLD time series across all voxels within a global brain mask defined as voxels in which the sum of the GM, WM, and CSF segmentation maps is more than 0.9 (Fox et\u00a0al.,\u00a0 ; Shirer, Jiang, Price, Ng, & Greicius,\u00a0 ). We included GSR in both simple and complex denoising pipelines. \n\nIn case scrubbing was required (i.e., when censored volumes were identified), the censored volumes were not taken into account in any of the preprocessing steps except for the band\u2010pass filtering in which case they were marked, and their values were replaced by linear interpolation before the filtering. During the calculation of the functional connectivity, the censored volumes were not used. It is worth mentioning that we applied scrubbing of bad volumes in both denoising pipelines (Power et\u00a0al.,\u00a0 ) if required. \n\nAfter defining all regressors, we applied a principal component analysis (PCA) to avoid multi\u2010collinearity of regressors (Jackson,\u00a0 ). \n\nAfter removal of the nuisance signals, band\u2010pass filtering was applied (0.009\u20130.1\u00a0Hz). \n\n\n### Network construction \n  \nA network consists of nodes and connections. The nodes in this study were derived from a whole\u2010brain parcellation using different levels of granularity (Shen et\u00a0al.,\u00a0 ). We selected 50 parcels (Shen50) and 100 parcels (Shen100) per hemisphere for this work ( ). Each parcel was taken as a node of the network. \n\nFor each subject, the average time series of each parcel was calculated as the mean of the time series over all voxels in the parcel. Based on the average time series, we calculated either a Pearson correlation or a partial correlation between the average time series in any pair of parcels. The partial correlations were calculated between any pair of time series taking the other time series as controllers. The calculation was based on the inversion of the covariance matrix. Partial correlations remove the influence of other regions and could be considered as a more specific measure for functional connectivity (Marrelec et\u00a0al.,\u00a0 ; Smith et\u00a0al.,\u00a0 ). \n\nWe studied two types of networks: a binary network and a weighted undirected network without self\u2010connections. Binary networks were studied at different densities. The density should neither be too sparse nor too dense (Hosseini et\u00a0al.,\u00a0 ; Kaiser & Hilgetag,\u00a0 ). Therefore, we used densities ranging from 5% to 40% (Wang et\u00a0al.,\u00a0 ). A weighted network can avoid the problem of thresholding and takes all weights into account (Schwarz & McGonigle,\u00a0 ; Wang et\u00a0al.,\u00a0 ,  ; van Wijk, Stam, & Daffertshofer,\u00a0 ). The weights have a value between 0 and 1, and they were calculated in different ways: (partial) Correlations were directly taken as weights by either (a) its absolute value (abs), (b) by taking only the positive values and setting negative values to 0 (pos), or (c) by setting positive values to zero and then take the absolute value of the negative values (neg). \n\nAnother way is to transform (partial) correlations to   Z  \u2010scores using a Fisher   r  \u2010to\u2010  Z   transform (Finn,\u00a0 ): in which r indicates the (partial) correlation,   n   is the number of volumes, and   p   is the number of regions (which is 2 in case of correlations) (Finn,\u00a0 ; Wang et\u00a0al.,\u00a0 ). Weights are then calculated from the   Z  \u2010scores as (Wang et\u00a0al.,\u00a0 ). in which\n  is the cumulative distribution function of the standard normal distribution. \n\nSimilar as before, one can take all the   Z  \u2010values (abs), set the negative Z\u2010values to zero (pos), or set the positive   Z  \u2010values to zero (neg) before calculating the weights   w  . Although the approach in which we calculate weights based on   Z  \u2010scores is theoretically better, it suffers from two problems: The number of volumes should be greater than the number of parcels plus one in order to obtain real values when calculating partial correlations directly without any regularization approach. In the current dataset, the maximally available number of volumes was 120 for a whole run. Therefore, partial correlations were only obtained for the first level of granularity (50 parcels per hemisphere). The other problem is that the values of the   Z  \u2010scores depend on the number of volumes used, and this has an impact on the graph measures themselves. This can be a problem when combining data from subjects with a different number of volumes. \n\n\n### Graph analysis \n  \nGraph theoretical analysis was conducted using the brain connectivity toolbox version 2017\u201005\u201001 ( ; RRID:SCR_018421; Rubinov & Sporns,\u00a0 ). We calculated nodal and global measures. The nodal graph measures were average path length, nodal clustering coefficient, nodal efficiency, and nodal betweenness centrality. The global graph measures included characteristic path length, clustering coefficient, efficiency, and betweenness centrality. These graph measures were calculated at the individual level. Furthermore, hubs were defined based on the hub score. The hub score is calculated as the sum of dummy values (0 or 1) for four criteria based on whether the node belongs to the top 20% of nodes (a) showing the highest degree, (b) showing the lowest path length, (c) showing the lowest clustering coefficient, and (d) showing the highest betweenness centrality. If the hub score was at least 2, the node was considered a hub. The modularity structure was determined using Newman's algorithm using 100 realizations (Vandenberghe et\u00a0al.,\u00a0 ; Wang et\u00a0al.,\u00a0 ). This defines the probabilistic co\u2010assignment matrix in which the probability is given that two nodes belong to the same module when applying Newman's algorithm. We also calculated normalized graph measures. A normalized graph measure is the ratio between the graph measure and the average graph measure of 30 equivalent random networks. Equivalent random networks have the same number of nodes and the same density (in case of binary networks) or the same distribution of connectivity values (for a weighted network) but connections are randomly assigned to each pair of nodes. \n\n\n### Measures of reproducibility for graph measures \n  \nThe reproducibility of graph measures (Wang et\u00a0al.,\u00a0 ) at the individual level can be easily assessed using the test\u2013retest variability (TRT) (in %):  and\n  are the values of the graph measure derived from the first and second measurement, respectively. A higher TRT value indicates higher variability and less reproducibility. \n\nThe consistency of hubs is determined by measuring the co\u2010occurrence (Hc) of hubs (Wang et\u00a0al.,\u00a0 ) which is based on the Dice coefficient. where   H   and   H   are the list of hubs in the network of the first, respectively, and second measurements. \n\nA value of 1 corresponds to a perfect agreement of hubs while 0 reflects no agreement at all. \n\nTo assess the consistency of the modularity structure, we used probabilistic scaled inclusivity (pSI) (Wang et\u00a0al.,\u00a0 ): \n\nHere, i and j indicate two nodes;   P (i,j)   and   P (i,j)   are the probabilistic co\u2010assignment between nodes i and j in the network derived from the first and second measurement, respectively. A value of 1 corresponds to a perfect agreement of modularity while 0 reflects no agreement at all. Here, we calculated\n  for each node. \n\n\n### Statistics \n  \nIn this study, we investigate the effect of different factors on the reproducibility of graph measures. These factors included denoising pipelines (simple vs. complex), types of correlation (Pearson correlation vs. partial correlation), the handling of negative correlation values (absolute vs. positive vs. negative values), type of network (weighted vs. binary networks), the weight calculation (based on the (partial) correlation or based on a Fisher   r  \u2010to\u2010  Z   based transformation), and the granularity of the parcellation (50 vs. 100 parcels per hemisphere). To ensure that the results are not depending on the weight distribution or the density, all comparisons for weighted networks were based on normalized graph measures, and for binary networks, we used identical densities. \n\nMost graph measures were not normally distributed (based on a Shapiro\u2013Wilk test), and therefore, we used a relative nonparametric analysis of variance through the aligned rank transform method (ART) (Wobbrock, Findlater, Gergle, & Higgins,\u00a0 ). \n\nThe analyses were performed in three steps. \n\nFirst, we used a 2\u00a0\u00d7\u00a02 factorial repeated measures nonparametric analysis of variance using ART to assess TRT values of graph measures, in which the first factor was the denoising pipeline (simple vs. complex denoising) and the second factor was the type of correlation (Pearson correlation vs. partial correlation). For this analysis, we used the Shen50 parcellation and the absolute value of the (partial) correlations. We performed the analysis separately for binary networks at different densities and for weighted networks. In the latter case, we introduced a third factor based on how the weights were calculated (using the (partial) correlation values or using weights based on the Fisher   r  \u2010to\u2010  Z   transformation), and thus, we analyzed a 2\u00a0\u00d7\u00a02\u00a0\u00d7\u00a02 factorial repeated measures nonparametric analysis of variance. \n\nSecond, we performed a 3\u00a0\u00d7\u00a02 factorial repeated measures nonparametric analysis of variance using ART (ARTool in R) in which the first factor was the handling of the negative correlations (absolute value, only positive values, and only negative values) and the second factor was the type of correlation (Pearson correlation vs. partial correlation). For this analysis, we used\u2014based on the results of the first analyses (see below)\u2014the Shen50 parcellation, the simple denoising pipeline, and weighted graphs in which weights were calculated based on the value of the (partial) correlations. \n\nThird, we used ART to compare the effect of the level of parcellation (50 vs. 100 parcels per hemisphere). In this analysis, we used again the simple denoising pipeline and weighted graphs in which weights were calculated based on the value of the correlations. We also had to limit this analysis to Pearson correlations since partial correlations cannot be reliably calculated given the number of data points in the time series compared to the number of nodes. \n\nAn overview of all analyses is given in Table\u00a0  and Figure  . \n  \nStatistical analyses \n    \nFlow chart of the different analyses \n  \nThe   p  \u2010value was set at a Bonferroni corrected   p  \u00a0<\u00a0.05 to take into account multiple comparisons (the number of graph measures we have evaluated although graph measures are not completely independent). We did not correct for the number of analyses we performed, to prevent too much reduction of power. All statistical analyses were performed in Rstudio (version 3.6.0). \n\n\n\n## RESULTS \n  \n### The effect of denoising pipelines and types of correlation \n  \n#### Binary networks \n  \nIn binary networks, the TRT variability for global measures was large at low density (Figure\u00a0 , Table  ) irrespective of the denoising strategy or the type of correlation. Comparing the different strategies (analysis 1a, Table\u00a0 ; Figure  ), the type of correlation (Pearson correlation vs. partial correlation) has a significant effect on TRT (Table  ): Pearson correlations showed lower TRT values (Table  ). The denoising pipelines (simple vs. complex denoising) did not have a significant effect, and there was no interaction effect between the denoising pipelines and the type of correlation (Table  ). Since TRT values were large at lower densities even for global graph measures (Table  ), we did not further investigated binary networks. \n  \nTRT (%) values of global graph measures in binary networks. The   x  \u2010axis indicates density (in percent) of the network ranging from 5% to 40%. S, simple denoising; C, complex denoising; Cor, Pearson correlation; Parco, partial correlation;   \u03bb  , normalized characteristic path length;   C  , normalized clustering coefficient;   E  , normalized efficiency; and BC , normalized betweenness centrality \n    \nComparison of denoising strategy and type of correlation on test\u2013retest values for global graph measures of binary networks (analysis 1a) \n   Note    \n\n#### Weighted networks \n  \nWeighted networks showed very low TRT values for global graph measures (Figure\u00a0 , Table  , Table  ) irrespective of the strategy used. Comparing the TRT values for different strategies (analysis 1b, Table\u00a0 , Figure  ), there were significant main effects of the type of correlation (Pearson correlation vs. partial correlation) and weights calculation (based on the raw (partial) correlation values vs. based on transformed   Z  \u2010values) (Table  ). There was also a significant interaction effect between type of correlation and weight calculation (Table  ). Similarly as for the binary networks, there was no main effect of the denoising pipeline. \n  \nTRT (%) values of global graph measures in weighted networks. (a) weights are based on the raw (partial) correlations; (b), weights are based on Fisher's transformed   r  \u2010to\u2010  Z   values. BC , normalized betweenness centrality; C, complex denoising;   C  , normalized clustering coefficient; Cor, Pearson correlation;   E  : normalized efficiency; Parco, partial correlation; S, simple denoising;   \u03bb  , normalized characteristic path length \n    \nSummary of normalized global graph measures for weighted networks (analysis 1b). A. Results for the simple denoising strategy when using the raw partial correlations as weight. B. Results of the statistical analysis \n   Note    \nLocal clustering coefficient and nodal average path length showed relatively low TRT values but local betweenness centrality showed high TRT values (Figure\u00a0 , Table  ). Nodal efficiency also showed high TRT values in all cases except when weights were calculated based on transformed   Z  \u2010values of the correlations. \n  \nTRT (%) values of nodal graph measures based on different weight calculations. (a) weights are based on the raw (partial) correlations; (b) weights are based on Fisher's transformed   r  \u2010to\u2010  Z   values. Each node is located on a circle and the radius represents the TRT value. C, complex denoising; Cor, Pearson correlation; Parco, partial correlation; S, simple denoising \n  \nHub consistency was moderate with average values (for the different strategies) between 0.23 and 0.29. \n\nThe average consistency of the modularity structure was between 0.18 and 0.24. \n\n\n#### Binary and weighted networks constructed using orthogonal minimal spanning trees \n  \nWe have also applied a data\u2010driven topological filtering approach based on orthogonal minimal spanning trees (OMST) to construct a binary and a weighted network. This method was recently proposed by Dimitriadis, Antonakakis, Simos, Fletcher, and Papanicolaou ( ), Dimitriadis, Salis, Tarnanas, and Linden ( ). The results are given in Tables   and are in line with the results obtained before. \n\n\n#### Binary and weighted networks constructed using the Oxford\u2013Harvard atlas \n  \nTo ensure that the results were not critical depending on the Shen50 atlas, we also performed an additional analysis using the Oxford\u2013Harvard atlas (Desikan et\u00a0al.,\u00a0 ; Frazier et\u00a0al.,\u00a0 ; Goldstein et\u00a0al.,\u00a0 ; Makris et\u00a0al.,\u00a0 ). The results (shown in Tables  ) were in the same line as for the Shen50 atlas. \n\n\n\n### The effect of type of correlation and the handling of negative values \n  \nIn a second analysis (analysis 2, Table\u00a0 , Figure  ), we investigated the TRT variability of different strategies to handle negative values in the (partial) correlations (see Section  ). In this analysis, we used the Shen50 parcellation to define the nodes and the simple denoising pipeline according to the outcome of the first analysis. \n\nThere was a significant main effect of the handling of negative values in which taking the absolute value showed overall the lowest test\u2013retest values (Figure\u00a0 , Table  ). Similar to analysis 1, there was a significant main effect of the type of correlation, in which Pearson correlation\u2010based normalized global graph measures showed lower test\u2013retest values compared to the ones based on partial correlations (Table  ). There was also a significant interaction effect (Table  ). \n  \nTRT (%) values of global graph measures based on different (partial) correlation value: handling of negative values. Abs: values based on the absolute (partial) correlations; BC , normalized betweenness centrality; C, complex denoising;   C  , normalized clustering coefficient; Cor, Pearson correlation;   E  , normalized efficiency; neg, values based on only the positive (partial) correlations; Parco, partial correlation; pos, values based on only the positive (partial) correlations; S, simple denoising;   \u03bb  , normalized characteristic path length \n  \nHub consistency ranged from 0.22 to 0.29, and the average consistency of the modularity structure was between 0.17 and 0.26. \n\n\n### The effect of parcellation granularity \n  \nIn the third analysis (analysis 3, Table  , Figure  ), we used the simple denoising pipeline and weighted graphs in which weights were calculated based on the absolute value of the (partial) correlations. We only varied the number of parcels per hemisphere: 50 versus 100 by comparing the results for the Shen50 versus Shen100 parcellation. \n\nMean TRT values of all global graph measures obtained using the Shen100 parcellation decreased compared to the values obtained using the Shen50 parcellation (Table\u00a0 ). However, the difference was not significant (all   p  \u2010value\u00a0>\u00a0.05) (Table\u00a0 ). The distribution of TRT for all global graph measures for the Shen50 and Shen100 parcellation can be found in Figure\u00a0 . \n  \nNormalized global graph measures for different levels of granularity and their comparison (analysis 3) \n   Note      \nTRT (%) values of global graph measures based on different granularity. The   x  \u2010axis indicates the level of granularity. 50 and 100 relate to the 50, respectively, and 100 parcels per hemisphere used in the brain parcellation. BC : normalized betweenness centrality;   C  : normalized clustering coefficient;   E  : normalized efficiency;   \u03bb  : normalized characteristic path length \n  \n\n\n## DISCUSSION \n  \nIn this study, we investigated the effects of denoising pipelines and network constructions on reproducibility of graph measures. We found that the choice of denoising pipeline did not significantly affect the reproducibility of graph measures. Furthermore, the reproducibility of graph measures of individual   binary   networks was insufficient, especially when the network density was low. This was also the case for the reproducibility of nodal graph measures, in particular local betweenness centrality and nodal efficiency. For   weighted   networks, the method of choice was the absolute value of the (partial) correlation as weight. The reproducibility of normalized global graph measures did not critically depend on the level of granularity or the parcellation scheme that was used. \n\n### Denoising: simple denoising versus complex denoising \n  \nWe used a simple and a complex denoising strategy by means of a model with a low or a high number of parameters. The parameters of the simple model included the six basic head movements and regressors for WM, CSF, and a GSR. This pipeline is widely applied for preprocessing of functional connectivity studies (Fox et\u00a0al.,\u00a0 ). The parameters of the complex model consisted of the same parameters as the simple model but extended with their temporal derivatives, their squared values and the squared values of the temporal derivatives (Ciric et\u00a0al.,\u00a0 ,  ; Parkes et\u00a0al.,\u00a0 ). According to the findings of Parkes et\u00a0al.\u00a0( ), the percentage of edges significantly associated with head motion was 10.7% for the simple denoising strategy versus 10.4% for the complex denoising strategy (Parkes et\u00a0al.,\u00a0 ) which is very similar. In our study, we also found that the reproducibility of the graph measures of networks preprocessed using either the simple or complex denoising strategy was very similar and statistically not different. \n\nIncluding the GSR, dominated by non\u2010neural signals such as motion\u2010related and respiratory noise rather than signals from regions of gray matter, has been demonstrated to noticeably decrease the impact caused by head movement\u2010related artifacts and other physiological confounds (Power, Plitt, Laumann, & Martin,\u00a0 ). It had also been reported that including the GSR could introduce negative correlations (Fox et\u00a0al.,\u00a0 ; Murphy et\u00a0al.,\u00a0 ) and may have an impact on graph measures (Chen et\u00a0al.,\u00a0 ). In this work, we included the GSR based on the work of Parkes and Ciric (Ciric et\u00a0al.,\u00a0 ; Parkes et\u00a0al.,\u00a0 ). The combination of head movement parameters and physiological non\u2010neural signal regressors and GSR is a relatively effective way to decrease the influence by noise. It improved the reproducibility of the functional connectivity among regions (Parkes et\u00a0al.,\u00a0 ). Additionally, we investigated differences in reproducibility between a simple and a complex denoising models at the subject level and in both denoising models, a global signal regressor was included. \n\n\n### Definition of correlation: correlation versus partial correlation \n  \nIn this study, we found that graph measures based on Pearson correlations showed lower TRT values versus those based on partial correlations. Once nodes have been defined, another important question to consider is how to quantify the interaction among these spatially distinct regions through neurobiologically interpretable quantities. The most commonly used functional interactions are based on correlations (Kirino et\u00a0al.,\u00a0 ) or partial correlations (Lin et\u00a0al.,\u00a0 ) between the time course of two nodes. Functional connections based on correlations between two spatially distinct regions could be driven by other regions (Wang et\u00a0al.,\u00a0 ). Functional connections based on partial correlations avoid this caveat, and they are more related to effective connectivity (Marrelec et\u00a0al.,\u00a0 ; Smith et\u00a0al.,\u00a0 ). Therefore, they are a more appropriate method (Dawson et\u00a0al.,\u00a0 ; Wang, Kang, Kemmer, & Guo,\u00a0 ) to detect biologically interpretable alterations of graph measures under different disease conditions. This might also explain the higher TRT values of graph measures based on partial correlations: They could provide more biologically meaningful information and therefore are more dependent on the brain state. \n\n\n### Weight selection \n  \nWe demonstrated that the weight selection affected the TRT values of graph measures. How to generate weights when applying a weighted network analysis has not been systematically investigated until now. We explored its effect on TRT of graph measures through combining it with other network construct factors. The weights were derived either using raw (partial) correlations or using   Z  \u2010values obtained after a Fisher   r  \u2010to\u2010  Z   transform. The weight distribution depends on this choice. \n\nWhen looking at differences at the functional connectivity level, it is mandatory to use a Fisher   r  \u2010to\u2010  Z   transform in order to perform a correct statistical analysis. However, this transformation depends on the number of data points that is used. In this study, the calculation of graph measures was based on the functional connectivity. As a result, the weights when calculated using these Z\u2010values also depend on the number of data points. As long as all data have the same number of data points, this is not a fundamental problem; but when pooling data with a different number of data points, this approach cannot be used. \n\n\n### Binary versus weighted networks \n  \nBinary networks can be constructed independently of the method to define weights since they are typically studied at different densities and the selection of the highest connections based on raw (partial) correlations, transformed   Z  \u2010values, or weights is the same since these methods preserve the order of highest connections. However, we have shown that the reproducibility of binary networks at the subject level is low especially at lower densities such as 5%\u201310%. This is not surprising since at lower densities, each change in connection has a more dramatic impact on the graph measures. Group based binary networks are more reproducible (Wang et\u00a0al.,\u00a0 ) but in the current study, we focused on the use of graph measures derived from single subjects since this is the preferred method to use in a clinical setting (Xiang et\u00a0al.,\u00a0 ). \n\n\n### (Partial) correlation values: absolute, positive, and negative \n  \nWhen using (partial) correlations as measure of functional connectivity between nodes, one needs to decide how to handle negative values. In most studies, either the absolute value is used or the connectivity is limited to only those connections with a positive value while neglecting the negative (partial) correlations (Kazeminejad & Sotero,\u00a0 ). However, negative correlations may contain important biological information, which cannot be neglected (Kazeminejad & Sotero,\u00a0 ). We found that the reproducibility of graph measures for networks based on only positive or only negative values were worse compared to taking the absolute value. Furthermore, the proportion of positive and negative (partial) correlations in a given network may vary, which may induce bias if we take only either positive or negative correlations into account. Therefore, we recommend using the absolute value, because connections with negative correlations are taken into account and the absolute value can be interpreted as the amount of information shared between two regions. The only drawback is that we cannot distinguish between positive or negative correlations with the same amplitude. \n\n\n### Granularity of parcels \n  \nThe first step in defining a graph is the definition of the nodes of the network. There are many different ways to define nodes such as based on cytoarchitecture, anatomy, or connectivity\u2010driven methods with different levels of granularity (Arslan et\u00a0al.,\u00a0 ). \n\nParcellation methods based on functional data have nodes which are more homogeneous and functionally coherent (Arslan et\u00a0al.,\u00a0 ). In our study, we have used a brain parcellation obtained from connectivity\u2010driven analyses using spectral graph theory (Shen et\u00a0al.,\u00a0 ). These parcellations were available for different levels of granularity, which made it easier to study the effect of granularity. Using parcellation schemes which were based on different criteria would be an extra confounding factor. Furthermore, there is currently no golden standard for which parcellations to use. \n\n\n### Hubs and modularity \n  \nThe hubs and the modularity structure were only partially consistent at the subject level. This may be partially explained because of the low reproducibility of the local graph measures. Another possibility is that the identification of hubs and modules is affected by different brain states present during the resting\u2010state experiment (Kabbara et\u00a0al.,\u00a0 ). As a result, the hubs and modules may be different during different brain states which may explain the limited reproducibility. This hypothesis has to be tested by further investigations. \n\n\n### Limitations \n  \nThere are a number of limitations in this study. First, we did not investigate all possible denoising pipelines, because the effect of denoising pipelines on functional connectivity has been studied previously (Ciric et\u00a0al.,\u00a0 ; Parkes et\u00a0al.,\u00a0 ). We selected relatively powerful denoising methods based on a similar type of regressors (e.g., head movement, WM, CSF, and a global signal regressor) to explore the reproducibility of graph measures. Second, we used a publicly available dataset for which the imaging parameters and the protocol were already defined. As a result, we could not determine the effect of the sampling rate (repetition time) or the variations in protocol such as eyes open (with or without a fixation point) or eyes closed. Third, we looked at graph measures based on overall functional connectivity. In future studies, the reproducibility of graph measures for different brain states can be investigated. \n\n\n\n## CONCLUSIONS \n  \nWe systematically investigated the reproducibility of graph measures of brain networks defined at the subject level as potential biomarkers in clinical work. The denoising pipeline did not affect the reproducibility. The reproducibility of graph measures of individual binary networks was insufficient especially when the density of the network was low. This was also the case for the reproducibility of nodal graph measures based on weighted or binary networks. For weighted networks, using the absolute value of the (partial) correlation as weight, was the method of choice and the reproducibility does not critically depend on the level of granularity. \n\n\n## CONFLICTS OF INTEREST \n  \nThe authors declare no competing financial interests. \n\n\n## AUTHOR CONTRIBUTIONS \n  \nQR, RV, and PD designed the study; QR and PD performed the research; PD made the scripts used in this study; QR, TJ, JS, KM, RV, and PD wrote the paper and critically checked the content. \n\n\n## Supporting information \n  \n \n", "metadata": {"pmcid": 7428495, "text_md5": "6b75b9da8f03cfe1abf6820e2b531103", "field_positions": {"authors": [0, 117], "journal": [118, 129], "publication_year": [131, 135], "title": [146, 225], "keywords": [239, 344], "abstract": [357, 2571], "body": [2580, 45580]}, "batch": 2, "pmid": 32614515, "doi": "10.1002/brb3.1705", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7428495", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7428495"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7428495\">7428495</a>", "list_title": "PMC7428495  Reproducibility of graph measures at the subject level using resting\u2010state fMRI"}
