{"text": "Corina, David P. and Lawyer, Laurel A. and Hauser, Peter and Hirshorn, Elizabeth\nPLoS One, 2013\n\n# Title\n\nLexical Processing in Deaf Readers: An fMRI Investigation of Reading Proficiency\n\n# Keywords\n\n\n\n# Abstract\n \nIndividuals with significant hearing loss often fail to attain competency in reading orthographic scripts which encode the sound properties of spoken language. Nevertheless, some profoundly deaf individuals do learn to read at age-appropriate levels. The question of what differentiates proficient deaf readers from less-proficient readers is poorly understood but topical, as efforts to develop appropriate and effective interventions are needed. This study uses functional magnetic resonance imaging (fMRI) to examine brain activation in deaf readers (N\u200a=\u200a21), comparing proficient (N\u200a=\u200a11) and less proficient (N\u200a=\u200a10) readers\u2019 performance in a widely used test of implicit reading. Proficient deaf readers activated left inferior frontal gyrus and left middle and superior temporal gyrus in a pattern that is consistent with regions reported in hearing readers. In contrast, the less-proficient readers exhibited a pattern of response characterized by inferior and middle frontal lobe activation (right>left) which bears some similarity to areas reported in studies of logographic reading, raising the possibility that these individuals are using a qualitatively different mode of orthographic processing than is traditionally observed in hearing individuals reading sound-based scripts. The evaluation of proficient and less-proficient readers points to different modes of processing printed English words. Importantly, these preliminary findings allow us to begin to establish the impact of linguistic and educational factors on the neural systems that underlie reading achievement in profoundly deaf individuals. \n \n\n# Body\n \n## Introduction \n  \nThe orthographic representation of English encodes relationships between the sound-based properties of English words and conventionalized graphemic forms. As profoundly -deaf individuals often lack the ability to hear word forms of spoken English, a deaf learner\u2019s ability to master the sound-form mappings is often hampered. Though this mapping in English is not fully transparent, decades of research with normally hearing children indicates that the appreciation of the relationship between visual symbols and the sounds these visual forms represent is often highly predictive of reading success  \u2013 . However, while some profoundly deaf individuals do learn to read and process written English at levels comparable to their normally hearing peers, little is known about how these readers ultimately succeed in this task. In this study, we compare proficient deaf readers and less-proficient deaf readers in an attempt to characterize the patterns of brain activity that may differentiate these understudied groups. \n\nAlthough opinions differ significantly  ,  , two prevailing hypotheses about how deaf readers attain reading success can be identified. The most common assumption is that successful deaf readers are those who have obtained some degree of phonological awareness of English that is sufficient to provide a consistent mapping between visual letters and English words  . Support for this phonological hypothesis comes from the finding that, despite profound hearing loss, some deaf individuals obtain above-chance performance on English-based phonological tasks such as rhyming, even when orthographic similarity does not provide clues to sound-based similarity  \u2013 . As might be expected, some of these studies have also reported a relationship between English phonological skills and reading  ,  ,  , but see also  . It is often assumed in these cases that the successful deaf reader is in fact making use of auditory, articulatory, and perhaps visual properties of English phonology in forming relationships between print and meaning. Though not a necessary condition of the phonological hypothesis, it is reasonable to assume that these skilled deaf readers engage largely similar neural regions during reading as their hearing counterparts  . The assumption here is that while there may be subtle differences due to the distribution of effort required for relating visual symbols to lexical meaning, the fundamental cognitive processing is likely to be quite similar. Under this view, the successful deaf reader has simply been able to master the same mapping strategies utilized by hearing individuals, albeit at times with some compensatory strategies for inferring sound forms, such as a greater reliance on the articulatory and visual properties of oral English. \n\nA second, though less well-developed, class of hypotheses posit that some successful deaf readers have mastered reading through a qualitatively different process than hearing individuals. Under one formulation, deaf individuals do not decompose English words into constituent sounds, but rather they are able to map directly between visual word forms and lexical-semantic representations  ,  . In some aspects, this hypothesis appears to be similar to the \u201cwhole-word\u201d reading approach popularized by Goodman   and Smith  . However, proponents of this view suggest that the end result is a mapping not to English-based representations per se, but to semantic representations that underlie native-language abilities, which for many deaf individuals in the United States is American Sign Language  ,  . Proponents of this view suggest that deaf readers may resemble non-native (i.e. L2) speakers reading English, especially when early language preferences are based in signed languages. In support of this hypothesis, studies have shown that native (L1) competence in a sign language is a good predictor of success in English reading  \u2013  and that there is evidence for activation of ASL forms during the processing of English word forms  . \n\nThe idea that an alternative and non-phonologically based mapping between visual form and meaning exists is ensconced in the classic dual route models of reading, and in the more nuanced and complex implementations thereof  . The motivation for a non-phonological route for reading is based, in part, from consideration of the acquired dyslexias, specifically the syndrome known as deep dyslexia. Deep dyslexic readers are characterized by a constellation of reading errors which include impaired abilities to read non-words aloud, the presence of reading errors that are based in visual similarity (tribute \u2192 tribe; thing \u2192 thin), and additional unusual semantic errors (cart \u2192 horse; slope \u2192 snow). It is of further interest to note that deep dyslexics also make orthographic errors in spelling, which have been taken as evidence of lexical mediation across output domains (oral reading, writing, etc.)  . Collectively, these reading errors are thought to reflect the inability to make use of phoneme-to-grapheme routines and an over-reliance on the visual and semantic properties of print forms. \n\nStudies of deaf readers\u2019 spelling errors suggest that deaf subjects make more phonologically implausible errors than hearing counterparts (responsible \u2192 responbile; medicine \u2192 medince). While this may indicate a lack of appreciation of English phonotactics, they nevertheless tend to be orthographically legal. The sources of the observed spelling error patterns are difficult to categorize but likely reflect multiple constraints such as those on permissible syllable forms  . In their examination of deaf spelling errors, Olson and Caramazza   note that spelling patterns were not strongly predicted on the basis of purely visual-based frequency effects governing orthographic regularity as might be expected. For example, less common letter combinations are not replaced by more frequently occurring bigrams in these data. However, the visual-based frequency discounted by Olson and Caramazza is but one of many possible indications of an over-reliance on visual word form properties, and more work is needed to fully characterize the distribution and development of spelling errors in deaf subjects and how these patterns may reflect their processing of text. \n\nConsideration of theories which suggest non-phonologically mediated routes of reading in deaf subjects have several implications for neural systems which may support successful reading in deaf signers. First, researchers have suggested that the non-phonological reading exhibited by deep dyslexics reflects a non-optimal right hemisphere visual language processing strategy  ,  . However, reading abilities observed in deaf readers have not implicated right hemisphere compensatory strategies. Second, theories which posit that deaf readers are making use of L1 ASL representations in their understanding of English print independently suggest differences in the neural representation of reading in deaf signers. For example, several studies have indicated that in hearing populations L2 reading engages the primary language areas associated with L1 written language processing, often to a greater extent  ,  . While research has shown that sign language processing calls upon left-hemisphere perisylvian regions in much the same way as spoken language processing  , there remain subtle differences reported for ASL especially in the distribution of activations in posterior temporal-parietal regions. For example it has been shown that ASL processing in native signers recruits both the left and right posterior parietal regions  \u2013 , and that lesions to the right hemisphere can lead to impairments in the use of spatial-linguistic properties of ASL  . If skilled deaf readers are relying upon a mapping from English orthographic form to ASL semantic representations, it is reasonable to assume that this strategy would evoke activation in left hemisphere perisylvian language areas common to English and ASL, as well as regions believed to be unique to ASL processing, for example right hemisphere inferior parietal regions. Whether this same pattern of result would hold for less successful deaf readers is unclear. \n\nFinally, whether successful deaf readers decompose English words into constituent sounds or process written English in a whole-word fashion, it is germane to consider the influence of the orthographic system itself. An emerging literature suggests that neural activation may be differentially distributed as a function of the form of script used  ,  . For example, research has shown that reading alphabetic scripts engenders more left-hemisphere fusiform processing whereas logographic writing systems like Chinese activate fusiform gyri bilaterally  . Moreover, studies have shown that the processing of logographic scripts evokes relatively greater activation in the left middle frontal gyrus (MidFG) while phonologically based scripts engender relatively greater activation in the left inferior frontal opercular region associated with phonological processing  . These script-based activation discrepancies are thought to reflect the differences in cognitive processing required for alphabetic words, which are predominantly read out by assembling fine-grained phonemic units (i.e., by assembled phonology)  ,  , as opposed to the phonological codes resultant from logographic orthographies (i.e. addressed phonology) which are thought to arise after the visuo-orthographic information of the appropriate lexical candidate has been identified  . To the extent that orthographic forms for deaf readers are essentially non-canonically \u201cassembled\u201d they may show activation in neural regions which are more reflective of logographic scripts, which would give rise to differences in early temporal-ventral visual processing regions as well as differences in MidFG and opercular regions. \n\nThe consideration of experiential factors of deafness, coupled with theoretical models of reading in normal and disordered populations have led us to make several predictions regarding the neural regions which support the processing of orthographic word forms in English. To the extent that deaf readers are using some type of decomposition that entails aspects of phonological processing (whether auditory, visual or articulatory) we suggest these readers will show activations similar to that of hearing readers. Specifically we predict that we should find activation in left inferior frontal gyrus and left posterior-temporal regions. Conversely, under the premise that deaf readers are using qualitatively different means for understanding written words, we might expect neural activations that differ from hearing peers. These differences may manifest in several ways. First, to the extent that deaf readers mirror the strategies of acquired dyslexia (i.e. individuals who have lost the ability to use a phonologically mediated form for reading), we expect greater contributions of the right hemisphere. Second, if deaf readers are making reference to ASL representations during reading we expect English forms to activate L1 processing, which would include both left hemisphere perisylvian regions as well as language-specific right hemisphere activation, particularly in tempo-parietal regions. Finally, to the extent that deaf readers are using strategies akin to the reading of logographic scripts we expect to see activation in early temporal-ventral visual processing regions as well as differences between opercular and MidFG regions relative to what is traditionally reported for readers of alphabetic scripts. Finally, it is possible that a single modal pattern does not underlie both proficient and less-proficient deaf readers. Indeed relative degrees of proficiency may result in qualitatively different patterns between these subgroups of deaf readers. \n\nIn the following study, two groups of deaf readers were presented with English words and unrecognizable \u201cfalse font\u201d forms (see   for discussion and Supplementary materials for examples). In both cases, subjects were asked to analyze only visual characteristics of the stimuli by indicating whether each form had \u201ctall\u201d letters (those which ascended above the midline of the written forms). While both real English words and false fonts should recruit the same degree of low-level visual form processing, it is presumed that English words automatically and irrepressibly engage further lexical processing  . Characterizing the differences in processing between these two conditions allows for the identification of regions which contribute uniquely to reading above those responsible for decomposing complex orthographic stimuli. Furthermore, the patterns of activation between groups of proficient and less-proficient readers are compared, which sheds light on the processing strategies characteristic of these subgroups deaf readers. \n\n\n## Results \n  \nThe fMRI data reflect a summary statistics approach of random-effects models appropriate when inferences are to be applied to the entire population. An analysis of variance (ANOVA) was performed with Group (proficient vs. less-proficient readers) and Lexicality (words vs. false fonts) as factors. We examine significant main effects of lexicality reporting responses to words and false fonts. We then report a statistical group interaction that reveals neural regions that were more active in proficient readers than less-proficient readers during word reading compared to false fonts. A further investigation into the effects of reading proficiency is highlighted by consideration of a separate group analyses of proficient and less-proficient deaf readers (see   section for details). Please refer to   &   for a list of activation foci and significance values for all comparisons. \n   List of all activation foci in group analysis.           List of all activation foci in the subgroup analyses.        \n### Group Results \n  \nMain effects for Group and Lexicality were significant (both F(1,32)\u200a=\u200a9.09, p<0.005)). A Group\u00d7Lexicality interaction was also significant (F(1,38)\u200a=\u200a7.35, p<0.01). Post hoc analyses were performed to analyze the contributions of individual groups and stimulus conditions. These results are presented below. \n\n#### Positive effect: Words \n  \nAn analysis of the positive effect of words (T(1,38)\u200a=\u200a2.43, p<.01, k\u200a=\u200a10) resulted in large regional activation in left inferior frontal gyrus (IFG), including the operculum (BA 45; peak at \u221253, 21, 26) with extension to the left middle frontal gyrus (BA8) as well as activation in the right medial frontal gyrus (BA10; peak 16, 39, 8). Prominent bilateral activation was also found in the anterior cingulate cortex (peaks at 1, 10, 26; \u221213, 43, 4),the left cerebellum, and left middle temporal gyrus (BA 22; peak \u221267, \u221236, 0). \n\nThe pattern of activity involving the left inferior frontal gyrus, left middle frontal gyrus, left middle temporal gyrus and the bilateral cingulate gyri is consistent with foci of reported in   which used the same task. However, in our data, inferior frontal gyrus activation was limited to the left hemisphere, while the activation reported in   is more ventral and bilateral. \n\nThe activation of the left frontal operculum has emerged as a consistent cluster in the meta-analysis of ortholinguistic activity reported in  . This region has been extensively described as being involved in aspects of semantic retrieval and selection processing  \u2013 . In the context of the present experiment, this provides evidence that the implicit reading task is sufficient to engage aspects of semantic evaluation of word forms in deaf readers. \n\nThe activation of the anterior cingulate, a region commonly associated with error and conflict monitoring  ,  , is greater in the context of monitoring for critical visual features in the presence of words rather than to meaningless false font word forms. In a fashion similar to the color Stroop task, automatic engagement of reading abilities in the task likely interferes with the attempt to make visual feature judgments. The suppression of the irrelevant dimension (in this case, reading) may result in greater anterior cingulate participation relative to the false font task, where no such implicit lexical activation is possible. \n\n\n#### Positive effect: False fonts \n  \nThe positive effect for false fonts (T(1,38)\u200a=\u200a2.43, p<.01, k\u200a=\u200a10) showed overall less activation, and revealed a pattern more consistent with the simple processing of visual stimuli. The comparison reveals right hemisphere activation in the inferior occipital extrastriate region (peak at 34, \u221294, 8) which has been associated with feature analysis, especially when contrasted with low-level baselines. This has been observed in a variety of domains, including object recognition  , complex scene analysis  , graphical form analysis  ,  , and human action recognition  . \n\n\n#### Positive interaction: Group\u00d7Lexicality \n  \nIn evaluating the interaction of Group by Lexicality (T(1,38)\u200a=\u200a2.43, p<.01, k\u200a=\u200a10), we find several regions that show significantly greater activation for the proficient deaf readers during word processing (relative to false fonts) compared to the less-proficient readers during word processing (relative to false fonts). Activations included left middle frontal gyrus (peak at \u221210, 10, 44), bilateral-fusiform gyrus (peaks at \u221238, \u221254, \u221221; 37, \u221244, \u221225), the left superior and middle temporal gyrus (peaks \u221260, \u221215, 11; \u221249, \u221236, 0), bilateral supramarginal gyrus (left>right; peaks at \u221260, \u221240, 29 and 62, \u221226, 26), left anterior cingulate, and the right cuneus. There were no regions that showed greater activation for the less-proficient readers compare to the proficient readers in evaluation of this interaction. \n\nThe fusiform activations found here are within the range of locations reported for the Visual Word Form Area (VWFA; mean \u221242, \u221257, \u221215) which Cohen et al.   situated at the ventral junction between the occipital and temporal lobes. Originally, the VWFA was characterized as a specifically left-hemisphere region responsible for prelexical processing specific to words or word-like stimuli. In its original description, the VWFA was considered a region with considerable plasticity, tuned to the orthographic regularities that constrain letter combinations during the acquisition of literacy  ,  . In subsequent work, the category-specificity of this region has been challenged  , and research has further shown that a specialized visual analysis region may be seen in right hemisphere inferior temporal regions under some circumstances, as in the present case  \u2013 . Current views suggest that one property of this region is in the participation of segmentation and classification of visually presented stimuli  , an analysis which accords with our results. \n\nIt is important to note that this fusiform gyrus region showed greater activation in our proficient readers relative to the less-proficient readers. Several researchers have suggested that the responsivity of the VWFA is experience dependent  . Particularly relevant to our research is the observation that development of activation in VWFA is related to skill in reading, rather than maturation. Shaywitz and colleagues   reported that activation of the VWFA was positively correlated with standardized scores in grapheme\u2013phoneme decoding ability. Such findings have been taken as evidence that successful mastery of grapheme\u2013phoneme conversion (i.e. decoding) is a critical precursor to the development of the adult-like response properties of the VWFA  . \n\nA second region observed in this interaction was the left-hemisphere superior temporal gyrus (peak at \u221260, \u221215, 11). This region appears to lie proximal to temporal lobe region T1a (\u221256, \u221212, \u22123) reported in  . T1a is considered a \u201cvoice-specific area\u201d  , and is a common area of activation across phonological, semantic and syntactic judgments tasks suggesting this is a region for high-level linguistic integration. As discussed in  , T1a is argued to have a dorsal component more associated with abstract phonological processing and a ventral part involved in the processing of intelligible words  . This characterization appears apt as our deaf subjects, who are unable to process auditory speech, may nevertheless be able to process abstract properties of phonological structure. \n\nTo further explore group differences at a finer level of detail, separate random-effects models were estimated using the existing contrasts for the proficient and less-proficient readers. The data from these models is reported below. \n\n\n\n### Proficient Readers \n  \n#### Words \u2013 false fonts \n  \nFor proficient readers, activation for word stimuli over false font stimuli (p<.005, k\u200a=\u200a15) shows a stronger left-dominant pattern than in the previous full group results (see  ). This includes left Broca\u2019s area (peak \u221253, 21, 15) consistent with the activation found in the full group analysis as well as inferior opercular activation (BA 47, peak at \u221231, 36, \u22127). The opercular portion of Broca\u2019s region has long been implicated in spoken language phonological tasks, including maintenance in phonological working memory, as well as retrieval, manipulation, and selection of phonological representations  , \u2013 . Lexical access is known to rely in particular on Broca\u2019s region in the left inferior frontal cortex, involving areas 44 and 45  \u2013 . Recent work utilizing cytoarchitectonic probability maps   suggests that area 45 supports lexical selection processes whereas area 44 is more involved in lexical access via the segmental route to reading. A number of studies of signed language processing have reliably found activation in the left IFG which further speaks to the modality independence of Broca\u2019s region  ,  ,  . \n   Activations in proficient deaf readers for words versus false fonts, p<.005.    \nProficient readers also exhibited bilateral activation of middle superior frontal gyrus (BA8, peaks \u221220, 28, 40; 16, 36, 51). A wide variety of functions have been assigned to this region, which has traditionally been associated with occulo-motor activity involving frontal eye fields, including activation of left BA 8, and secondary motor areas related to speech  . It is interesting to note that activation in BA 8 has been previously reported in studies of speech reading  . \n\nAnother area of prominent activation was observed in bilateral middle temporal gyrus (MTG; peaks \u221267, \u221240, 0; 66, \u221233, \u22123) and adjacent right superior temporal sulcus (STS; peak 62, \u221211, \u22127). This posterior temporal region is commonly seen in tasks requiring word comprehension both in auditory and visual modalities  . As in the full group analysis, proficient readers showed robust activation in left posterior fusiform gyrus (\u221238, \u221244, \u221221) and anterior cingulate. \n\nFinally, a small region in the right cuneus (peak 8, \u221295, 15) was observed during the reading of words relative to false fonts. Activation of the cuneus is associated with higher level visual processing including action recognition   and visual reading  . The involvement of this region may reflect activation of higher level properties of the visual word stimuli, and/or co-activation of action routines associated with sign language interpretation. Further work is needed to specify the role of this visual processing region in signing deaf readers. \n\nOverall, the data from the proficient deaf readers suggests that these individuals are likely making use of neural regions for lexical recognition that are similar to those utilized by hearing individuals, in particular, involvement in the opercular region of the IFG which is suggestive of lexical selection, and the left-temporal lobe, often observed in studies of lexical semantics. \n\n\n#### False fonts \u2013 words \n  \nThe contrast between false fonts and words, produced no above threshold activation in our group of proficient readers. Activation at a reduced threshold was found only in the right middle occipital gyrus (peak 34, \u221294, 8), a region which has been reported in complex visual processing tasks, including reflecting on the physical appearances of famous persons   and visual memory for barcodes  , suggesting a role of this region in evaluation of high level visual properties. \n\n\n\n### Less-proficient Readers \n  \n#### Words \u2013 false fonts \n  \nExamination of the less-proficient deaf readers in the word versus false font contrasts (p<.005, k\u200a=\u200a15) reveals a markedly different pattern of activation. Prominent activity was observed in the anterior cingulate (12, 39, 11) during this condition. Smaller clusters of activity (p<.005, k\u200a=\u200a5) were located in and left and right middle and inferior frontal gyri BA46/9 (48, 21, 18), BA 44/9 (\u221253, 21, 26). This left inferior frontal gyrus activation lies dorsal to the IFG region observed in the proficient readers (see  ). In this analysis, activation was also observed in the pulvinar (12, \u221229, 15). \n   Activations in less-proficient deaf readers for words versus false fonts, p<.005.    \nThe activation of the left middle frontal cortex in language processing has been repeatedly demonstrated in fMRI studies of logographic reading using Chinese. In particular, left middle frontal activation has been obtained in word generation  , semantic judgment  , homophone judgment (compared to fixation)  , rhyme decision  , and syllable decision tasks  . In a meta-review exploring activation during reading of alphabetic languages versus Chinese, Tan et al.   concluded that the left MFG is responsible for addressed phonology in Chinese reading. The involvement of the MFG in our less-proficient readers may indicate that for these deaf readers the implicit recognition of word forms engenders processing similar to that found in Chinese readers processing logographic scripts. Specifically, these deaf subjects could be processing English word forms as non-decomposable logographic-like forms analogous to Chinese. \n\nThere are, however, some differences between the current findings and those of Chinese logographic reading. First, the less-skilled deaf subjects\u2019 activation was larger in the right hemisphere than left, whereas the results from the Chinese reading studies are clearly left hemisphere dominant. Second, we do not observe robust fusiform activation as might be expected (but see below). \n\nWhile right hemisphere activation in the IFG and MFG has occasionally been reported in tasks of alphabetic reading, leading some to suggest different roles for phonology across the left and right hemispheres, there is little consensus and a general underreporting of right hemisphere effects in alphabetic reading. Pugh et al.   reported a correlation between right hemisphere IFG activation during phonological processing and regularity and word length effects. Regularity effects refer to the relatively slower ability to read words with irregular phoneme-to-grapheme correspondences (e.g. leaf versus deaf). In many models of reading, the reading of irregular words is suggested to place greater demands on lexical-semantic processing. Similarly, word length effects refer to the sensitivity of reading speed to the word length as measured by number of characters. One interpretation of these data would suggest that right hemisphere activation is evoked under conditions of effort, where traditional routes to successful reading are taxed. Thus, the presence of right hemisphere activation seen in the less-skilled deaf readers, encompassing both IFG (BA 46) and MFG (BA 46/9), may be a signature of an inefficient reading strategy. Additional data from reading skill matched hearing controls would be a useful means to further understand this unusual pattern of neural activation in less-proficient deaf readers. \n\n\n#### False fonts \u2013 words \n  \nIn the less-proficient readers, activation for false fonts over words (p<.005, k 15) is again dominated by visual processing. This contrast produced robust bilateral ventral fusiform (peak \u221238, \u221290, \u22123) and right fusiform activation (peak 30, \u221233, \u221228) The right fusiform region appears to be related to the left-hemisphere homologue of VWFA (\u221244, \u221251, \u221216), often reported in visual word processing tasks  . Here again it is interesting to note a hemispheric reversal of typically reported coordinates for the VWFA in the less-proficient readers. \n\nThe relatively large magnitude of visual fusiform activation during the false fonts over words comparison in the less proficient deaf readers compared to the proficient readers is noteworthy. This may be an indication that these less proficient readers are in fact making use of differential visual based analyses for these unusual orthographic false font forms to a greater extent than the more proficient readers. Note that a more expected pattern of left-hemisphere fusiform activation is present in the proficient deaf readers during the words over false font comparisons. Further work is needed to clarify these distributional differences in response to orthographic forms in these populations. \n\n\n\n\n## Discussion \n  \nIn our study, we speculated that neural imaging studies of deaf readers may result in a number of possible activation outcomes. Based both upon past research with deaf and hearing readers we outlined three possibilities. First, to the extent that deaf readers were using a phonologically based avenue for reading, we might expect neural activation to appear largely similar to hearing readers, specifically with activation in the left IFG, and the posterior and middle temporal regions. Second, we suggested that if deaf readers were making significant use of native language abilities, patterns of activation during English reading should map on to regions independently observed for ASL processing, notably left perisylvian regions and right temporal-parietal regions. Finally, to the extent that deaf readers were using a strategy that circumvented segmental analysis in favor of whole word form processing, we predicted involvement of the left hemisphere MidFG and activation in early temporal-ventral visual processing regions. \n\nIn the overall group analysis, we observed activation of neural regions that were largely similar to those reported previously using this implicit word recognition task. Prominent activation of left MidFG (BA 45) suggests that lexical-semantic processing is being engaged by deaf readers through implicit word recognition when contrasted with false fonts. The contrast of the false fonts relative to words resulted in activation of the right inferior occipital extrastriate regions consistent with a visual feature analysis of these novel and complex stimuli. These data are important as they extend previous findings in studies which have used this implicit reading task to investigate lexical processing in hearing adults, children, and dyslexic readers. Our data provide evidence that this implicit reading task engages neural regions associated with lexical-semantic and visual feature processing in deaf readers. \n\nOne concern raised in the present study is the relative lack of robust patterns of activation in the fMRI data. As seen in the whole group analysis, even with 21 subjects, significance cluster-level values for this reading measure do not often survive corrections for multiple comparisons. Careful inspection of our data suggests considerable variability in this population (resulting in less-robust significance values at the group level), and this heterogenity provides support for the notion that proficient and less-proficient deaf readers may be engaging in differing reading strategies which should be studied in their own right. As further knowledge regarding subgroups of deaf individuals who may exhibit differing reading processing strategies begins to accrue, one may expect more homogeneity to emerge. However, given the paucity of data in this research field, we are purposely taking a less conservative approach in the present paper. The reader should be aware of the limitations associated with this decision. \n\nWhen deaf readers were divided in two groups on the basis of independently obtained reading levels, a particularly interesting finding emerged. In this analysis, we observed that proficient deaf readers activated the left IFG and the left STG in a pattern that is highly consistent with regions that have been reported in hearing readers. These data accord with the reports of Apracio et al.   and MacSweeney et al.   who also noted the prominent role of the left IFG in deaf readers during lexical decision and phonological judgment tasks. The MacSweeney et al.   report is of further interest due to the inclusion of a hearing dyslexic group in their study of pictorial rhyming. MacSweeny et al.   suggested that prominent left IFG activation is indicative of greater reliance on the articulatory component of speech during phonological processing when auditory processes are absent (deaf group) or impaired (dyslexic group). Thus, the brain appears to develop a similar solution to a processing problem that has different antecedents in these two populations. The differences in IFG foci between the deaf subjects (more ventral and superior) and the hearing dyslexics (more anterior and ventral) may reflect different degrees of reliance upon articulatory routines and lexical-semantic access in the service of these tasks. \n\nBased upon the multiplicity of functions now attributed to Broca\u2019s region (including its role in the mediation of sign language), one must exercise some caution in attributing left IFG activation to speech-articulatory processing. This point is underscored in the present study, where in contrast to the studies of Apracio et al.   and MacSweeney et al  , which included a more heterogeneous mix of deaf subjects who used a variety of preferred communicative methods (i.e. oral speech, cued-speech and sign language (LSF & BSL)), had mixed sign-proficiency levels (only four of the seven participants in the MacSweeney et al   study had deaf parents and were assumed to be highly proficient signers and had attended oral-based educational school programs), the present study included only deaf subjects who were highly sign proficient (including 8\u20139 native signers in each group), reported ASL as their preferred mode of communication, and attended residential schools with sign-based instruction. Thus, based upon anatomy alone one cannot assume that the proficient deaf readers were using an oral approach to reading. Rather, given the reported role of BA 45 in aspects of language segmentation in the service of lexical-semantic processing, it seems plausible that these individuals were engaged in a more compositional approach of word recognition in this task relative to the less-skilled readers. Additional work is required to further tease apart how the pedagogical approaches to reading instruction and language competencies influence cognitive routines and the subsequent engagement of reading networks in skilled deaf readers. \n\nThe less-proficient readers exhibited a pattern of response characterized by bilateral middle frontal lobe activation (right>left) and a lack of temporal and/or parietal lobe activation in the word versus false font comparisons. This limited activation appears qualitatively different from that reported by Gizewskiet al.   who examined reading in German deaf signers and hearing non-signers. The adult deaf subjects had good to excellent knowledge of German Sign Language (DGS) but self-reported weak to moderate levels of reading ability. The deaf subjects exhibited a mix of etiologies, including prenatal and postnatal deafened individuals with delayed exposure to sign language that ranged from 0\u20136 years (mean 4.4 years). In this study, read narratives were compared to a baseline of meaningless character strings. The narrative paradigm produced widespread activation, including the left angular gyrus, bilateral occipitotemporal areas, and frontoparietal secondary motor areas in the deaf readers. In contrast, no activation of left temporal lobe (BA 21) was observed. Recall that in our study, the presence of left superior temporal lobe activation differentiated proficient from less-proficient deaf readers. For less-proficient deaf readers, we speculated that word recognition may reflect a less successful whole-word approach to word recognition, one which does not seem to fully engage regions that support a semantic analysis. Moreover, we suggested the middle frontal regions observed seemed similar to, though more medial than, the homologous left hemisphere regions characteristic of logographic reading in Chinese readers, further raising the possibility that these individual are using a qualitatively different mode of orthographic processing than is traditionally observed in hearing individuals reading alphabetic scripts. Finally the robust activation of bilateral temporal fusiform region in the less proficient group during the processing of false fonts relative to alphabetic strings suggest a different emphasis on visual form analysis of grapheme forms. Taken together, the comparisons of proficient and less proficient deaf readers have given an indication that qualitatively different neural processes may be engaged during single word reading. \n\nTo conclude, the implicit word reading task has proven useful in beginning to explicate the systems that deaf readers use during reading. Considerable heterogenity was found in the overall group results, supporting an evaluation of proficient and less-proficient readers which points to different modes of processing in deaf readers\u2019 exposure to printed English words. Importantly, these preliminary findings allow us to begin to characterize the neural signatures related to linguistic and educational factors that underlie reading achievement in profoundly deaf individuals. \n\n\n## Materials and Methods \n  \n### Participants \n  \nTwenty-one subjects participated in this study. Before beginning the experiment, written informed consent was acquired in accordance with the regulations of the Institutional Review Board of the University of California, Davis. Subjects completed background questionnaires which included items relevant to exposure to ASL. Each subject was further administered an assessment of their English reading comprehension (PIAT, Reading Comprehension Subtest)   after the fMRI session was complete. Median PIAT score was 73, and this served as the basis for placing the subjects into either above-median (proficient) or below-median (less-proficient) groups. Groups were designated for analysis only, and had no effect on the experiment in terms of task. \n\nThe proficient group had eleven subjects (8 female) with an average PIAT score of 84.55 (SD\u200a=\u200a6.15) (mean grade equivalent: 8.7, mean age equivalent: 14). Age ranged from 19 to 46 (average 28.73, SD\u200a=\u200a9.90). Ten subjects reported right-hand dominance; one subject was left handed. Nine subjects were native ASL users as indicated in the background questionnaire; the two remaining subjects reported first using ASL at age 13. The less-proficient group had ten subjects (7 female) with an average PIAT score of 60.80 (SD\u200a=\u200a8.74) (mean grade equivalent: 4.0; mean age equivalent: 9.9). Age ranged from 19 to 45 (average 30.00, SD\u200a=\u200a10.27) and nine subjects reported right-hand dominance; one subject was left-handed. Eight of the below-median subjects were native ASL users, with the remaining two subjects reporting using ASL from ages 8\u20139 and 13 respectively. \n\n\n### Stimuli \n  \nStimuli were composed of 40 English nouns and verbs (words) in standard lowercase orthography and 40 false font items (FF) both projected in black font on a white background. All word and FF items had five orthographic characters, and half of each set contained items with \u2018tall\u2019 letters (those which ascended above the midline of the word) as an experimental manipulation. FF items were created to match the original word stimuli in size, shape, distribution of ascending/descending letters, and overall orthographic frequency. These were created using items from previous implicit reading studies which utilize a font whose characters mimic English orthography in general composition, but are unrecognizable as known letters (see  ,   for discussion). See   and  . A list of all word stimuli used in the experiment is provided in Supporting Information  . A control condition which consisted of a black fixation cross on a white background was also included, and used as the baseline in analysis. \n   False fonts with no tall letters (corresponds to words \u201cmanor\u201d, \u201counce\u201d and \u201cgroom\u201d).       False fonts with tall letters (corresponds to words \u201cstole\u201d, \u201csnort\u201d and \u201cpulse\u201d).    \n\n### Experimental Design and Image Acquisition \n  \nThe experiment was comprised of alternating blocks of word and FF stimuli in two sets. Subjects were presented two alternating blocks of each stimulus type per set, which consisted of 10 unique stimulus items, randomly ordered. Each item was shown for 1 second, followed by 3 seconds of fixation. At the end of each block, the control condition was presented for 18 seconds. Completing the first set, subjects were allowed a break before beginning the second set. Both set order and block order within sets was counterbalanced across subjects. \n\nIn both word and FF conditions, subjects were asked to press a button to indicate whether the presented item contained a letter which ascended above the midline of the word (such as \u2018t\u2019, \u2018h\u2019, \u2018l\u2019, or \u2018d\u2019). All items required a yes/no button press response. Subjects were shown examples of word and FF items similar to those used in the task prior to scanning to ensure they understood the directions. None of the items used in training were included in the experiment. Each subject completed both sets, resulting in the presentation of 40 Word and FF items each. Each set took approximately 5 minutes to complete. Subjects also participated in a second study on ASL and gesture perception, discussed in a separate paper. \n\nImaging data was acquired on two Siemens Trio Tim 3T scanners located at the University of California, Davis Imaging Research Center in Sacramento, California and at the Rochester Center for Brain Imaging in Rochester, New York. A standard Siemens 8-channel head coil was employed in both locations, with added foam padding to minimize subject head movement during scanning. Four functional runs (two word/FF and two sign/gesture) and one structural image were acquired from each subject. Functional runs consisted of 89 volumes and were collected using a gradient echo EPI sequence (46 slices, thickness\u200a=\u200a3.6 mm, TR\u200a=\u200a3000 ms, TE\u200a=\u200a30 ms, flip angle\u200a=\u200a90-, FOV\u200a=\u200a230 mm\u00d7230 mm, voxel size\u200a=\u200a3.6 mm ). Functional volumes were aligned parallel to the anterior-posterior commissure (AC-PC line) and provided full brain coverage. The initial 8 fixation volumes acquired at the beginning of each run were discarded from analysis. \n\nDuring scanning, stimuli were presented via a Digital Projection Mercury 5000HD projector. The experiment was back-projected onto a screen placed at the foot of the scanner bed. A mirror mounted to the head coil and angled at approximately 45 degrees allowed subjects to comfortably view stimuli from inside the scanner bore. Each subject verified their ability to see the stimuli and adjustments were made to mitigate eye strain. Following the acquisition of functional images, a high-resolution structural image covering the entire brain was acquired using an MPRAGE sequence (208 slices, thickness\u200a=\u200a1 mm, TR\u200a=\u200a1900 ms, TE\u200a=\u200a3.06 ms, flip angle\u200a=\u200a7-, FOV\u200a=\u200a256 mm\u00d7256 mm, matrix\u200a=\u200a256\u00d7256, voxel size\u200a=\u200a1 mm ). \n\n\n### Data Analysis \n  \nData from all subjects was preprocessed before being submitted to statistical analysis using SPM8 (Welcome Department of Imaging Neuroscience). All volumes with large movement artifacts were removed from analysis. Remaining images were slice time corrected and realigned to each subject\u2019s mean image. Both structural and functional images were coregistered to the mean image, and normalized to the MNI template to enable group comparisons. Functional images were smoothed with an 8 mm  FWHM Gaussian kernel. \n\nA random-effects statistical model was used to quantify BOLD effects. First-level condition-related changes in regional brain activity were first estimated for each participant according to the general linear model fitted with the parameters for each condition (words, false fonts, fixation) and each subject\u2019s 6 realignment parameters included as regressors. Significant cerebral activations for the critical contrasts (Words-Fixation, False Font-Fixation) of interest were then examined at the second-level in SPM using a 2\u00d72 analyses of variance (ANOVA) with factors of Group (Proficient vs. Less-proficient) and Lexically (Words vs. False Fonts). Positive interactions for each group were tested using post-hoc T-tests with significance level of p<.01 uncorrected, and a 10 voxel cluster. In addition, separate random-effects models were estimated in SPM for the contrasts (Words-False Fonts) and (False Fonts-Words) for the proficient and less-proficient subjects respectively. Given the smaller sample size, unless otherwise noted, these individual contrasts were evaluated at p<.005 uncorrected, 15 voxel clusters. Values reported in the   &   reflect activations which exceed Z\u22653, p\u200a=\u200a.0013. \n\n\n\n## Supporting Information \n  \n \n", "metadata": {"pmcid": 3554651, "text_md5": "1ad57c7b01259b4d72546c13fca532ef", "field_positions": {"authors": [0, 80], "journal": [81, 89], "publication_year": [91, 95], "title": [106, 186], "keywords": [200, 200], "abstract": [213, 1837], "body": [1846, 47369]}, "part": 1, "chapter": 6, "page": 8, "pmid": 23359269, "doi": "10.1371/journal.pone.0054696"}, "display_title": "pmcid: <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3554651>3554651</a> \u2014 Part 1 Chapter 6 Page 8", "list_title": "1.6.8  Lexical Processing in Deaf Readers: An fMRI Investigation of Reading Proficiency"}
