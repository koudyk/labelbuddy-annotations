{"text": "Rahaman, Md Abdur and Damaraju, Eswar and Saha, Debbrata K. and Plis, Sergey M. and Calhoun, Vince D.\nHum Brain Mapp, 2022\n\n# Title\n\nStatelets: Capturing recurrent transient variations in dynamic functional network connectivity\n\n# Keywords\n\ndynamic functional network connectivity\nearthmover distance\nkernel density estimator\nresting\u2010state MRI\nschizophrenia\ntime series motifs summarization\n\n\n# Abstract\n \nDynamic functional network connectivity (dFNC) analysis is a widely used approach for capturing brain activation patterns, connectivity states, and network organization. However, a typical sliding window plus clustering (SWC) approach for analyzing dFNC models the system through a fixed sequence of connectivity states. SWC assumes connectivity patterns span throughout the brain, but they are relatively spatially constrained and temporally short\u2010lived in practice. Thus, SWC is neither designed to capture transient dynamic changes nor heterogeneity across subjects/time. We propose a state\u2010space time series summarization framework called \u201cstatelets\u201d to address these shortcomings. It models functional connectivity dynamics at fine\u2010grained timescales, adapting time series motifs to changes in connectivity strength, and constructs a concise yet informative representation of the original data that conveys easily comprehensible information about the phenotypes. We leverage the earth mover distance in a nonstandard way to handle scale differences and utilize kernel density estimation to build a probability density profile for local motifs. We apply the framework to study dFNC of patients with schizophrenia (SZ) and healthy control (HC). Results demonstrate SZ subjects exhibit reduced modularity in their brain network organization relative to HC. Statelets in the HC group show an increased recurrence across the dFNC time\u2010course compared to the SZ. Analyzing the consistency of the connections across time reveals significant differences within visual, sensorimotor, and default mode regions where HC subjects show higher consistency than SZ. The introduced approach also enables handling dynamic information in cross\u2010modal and multimodal applications to study healthy and disordered brains. \n  \nWe proposed a novel method for analyzing dynamic functional connectivity via extracting high\u2010frequency texture from the connectivity space. The analysis of those motifs enables measuring the characteristics of brain circuitry and network organization. The experiments don't he summary motifs facilitate the observation of distinguishing connectivity signatures and the interplay among the hubs to process information   \n \n\n# Body\n \n## INTRODUCTION \n  \nSchizophrenia (SZ) is a neuropsychiatric disorder characterized by diverse cognitive impairments and a decline in personal and social functioning. The decomposition of brain images into meaningful independent components (ICs) and generating biomarkers helps analyze SZ to a greater extent (Calhoun, Liu, & Adal\u0131,\u00a0 ; Du et al.,\u00a0 ; Erhardt et al.,\u00a0 ; Liang et al.,\u00a0 ; Rahaman et al.,\u00a0 ; Zhou et al.,\u00a0 ). Nevertheless, to reason about the neuropsychiatric disorders and studying the brain remains challenging because of the heterogeneous nature of these diseases (Aln\u00e6s et al.,\u00a0 ; Tsuang, Lyons, & Faraone,\u00a0 ). Thus, studies employ subgrouping/clustering of the subjects to minimize the dissimilarity in the population and make the investigation more viable (Luchins, Weinberger, & Wyatt,\u00a0 ; Rahaman et al.,\u00a0 ; Scarr et al.,\u00a0 ). The human brain is considered an interconnected dynamical system with real\u2010time interaction between different nodes of the brain network (Bassett & Sporns,\u00a0 ; Betzel & Bassett,\u00a0 ). These dependencies among the neuronal populations or brain regions are described as functional connectivity (FC) and generally computed using Pearson correlation of time courses (TCs) in task\u2010based or resting\u2010state functional magnetic resonance Imaging (fMRI) (Buckner, Krienen, & Yeo,\u00a0 ; Power et al.,\u00a0 ). Recent empirical evidence has suggested that this dynamic spatiotemporal configuration better models brain activities and network organization (Liu et al.,\u00a0 ; Ma et al.,\u00a0 ; Sako\u011flu et al.,\u00a0 ; Vergara et al.,\u00a0 ; Zhi et al.,\u00a0 ). Studies have hypothesized that SZ is a disorder of disrupted cognition, network dysconnectivity, and lack of functional integration (Friston & Frith,\u00a0 ; Lynall et al.,\u00a0 ; Stephan, Baldeweg, & Friston,\u00a0 ). Moreover, not all cognitive processes occur within a single brain component, instead of requiring dynamic reconfiguration of neural resources such as the brain network's nodes and connections (Alavash, Tune, & Obleser,\u00a0 ; Petersen & Sporns,\u00a0 ). As such, research into the brain's static and dynamic functional network connectivity (dFNC), in which nodes are distributed maps, for example, IC maps, may provide crucial insights into functional integration and its disorder due to a heterogeneous neuropsychiatric disorder such as SZ. \n\ndFNC is defined as the temporal interdependence among intrinsic connectivity networks (ICNs) extracted from independent component analysis (ICA) (Allen et al.,\u00a0 ; Jafri et al.,\u00a0 ; Rashid et al.,\u00a0 ). dFNC study provides an ability to track time\u2010varying transitions in connectivity strength, thus moving beyond the limiting assumption of a single static connectivity pattern (Rashid et al.,\u00a0 ; Vergara et al.,\u00a0 ). However, a typical dFNC analysis assumes fixed discrete states with varying occupancy over time and does not capture continuous transient information. Studies often analyze dFNC through connectivity states and estimate those states via clustering the windowed FNC sliding across time (Miller et al.,\u00a0 ; Rashid et al.,\u00a0 ; Saha et al.,\u00a0 ). The obtained states essentially fuse all homogenous connectivity patterns ignoring their order and timing. Additionally, these states explore connectivity patterns that span throughout the brain and prevail for a longer timescale. In practice, connectivity signatures are more spatially constrained and exist at a shorter timescale (Grandjean et al.,\u00a0 ; Hilger et al.,\u00a0 ; Liao et al.,\u00a0 ; Miller et al.,\u00a0 ). That is, transformations manifest over a slower timescale, and dynamics can adjust functional network topology accordingly (Aine et al.,\u00a0 ; Bullmore & Sporns,\u00a0 ). So, these methods are less suitable for capturing dynamic changes in the dFNC TC. Specially, those which manifest over a short and continuous timescale. Consequently, the methods also incompetent to analyze dynamic properties of dFNC, such as synchronizability and intermittent connectivity, which are also affected by neuropsychiatric disorders like SZ (Siebenh\u00fchner et al.,\u00a0 ; Yu et al.,\u00a0 ). \n\nAddressing the shortcomings of the existing methods, an increasing number of recent studies have started to investigate connectivity time series in a reformed timescale through bipartitions (Sporns et al.,\u00a0 ) or network dynamics (Esfahlani et al.,\u00a0 ; Faskowitz et al.,\u00a0 ; Morioka, Calhoun, & Hyv\u00e4rinen,\u00a0 ; Sporns et al.,\u00a0 ). We further advance this agenda by introducing a robust approach to decompose FC into a more granular scale by tracking the most recurring patterns of the dFNC TC. To capture brief, repetitive co\u2010fluctuations, we focus on the time\u2010series \u201cmotif\u201d\u2014a previously unknown but recurring time\u2010series pattern (Lin et al.,\u00a0 ). In data mining, time series motifs as such signatures are deemed powerful tools for modeling and analyzing dynamical systems (Mueen,\u00a0 ; Torkamani & Lohweg,\u00a0 ). The dFNC TC represents the link between a pair of nodes during a time interval; intuitively, we are interested in the frequently occurring behavior of the signal rather than a few sporadic episodes. Motif extraction from each connection of FC can easily yield an extensive collection of variable\u2010length shapes even for a moderate connectivity dataset. A comprehensive collection of samples dramatically complicates the task of summarizing the transient dynamics into a few interpretable trends; thus, predicting the overall dynamical system's behaviors is still similar to looking for a needle in a haystack. \n\nThis article addresses the tradeoff between the desire to model transient dynamics and the need to constrain the set of extracted features to a reasonable size. Summarization helps to distill useful information and general trends from the data making them interpretable. Studies that propose summarizing time series are mostly domain\u2010specific and lack generalization (S. Ahmad, Taskaya\u2010Temizel, & Ahmad,\u00a0 ; Kacprzyk, Wilbik, & Zadro\u017cny,\u00a0 ; Sripada et al.,\u00a0 ). This article offers a novel probabilistic pattern summarization framework called \u201cstatelets,\u201d highlighting the dynamics of capturing FC of the brain. Statelets are driven by the desire to build a general summarization method and rely on an efficient earth mover distance (EMD) (R\u00fcschendorf,\u00a0 ) implementation supporting kernel density estimation (KDE) in motif space. We demonstrate how the EMD may be an effective similarity metric for motif comparison. EMD provides a scale\u2010independent comparison between signatures that can handle variable\u2010length substructures and account for partial matching (Rubner, Tomasi, & Guibas,\u00a0 ). \n\nResults present the summary prototypes of both connectivity dynamics. The statelets from both groups pose substantial group differences in multiple dynamic properties of the brain's functional system. The connection rank computed based on the probability density (PD) within the groups reveals unique co\u2010fluctuations among functional brain networks and their corresponding dynamic interplay (Figure 7). Connections identified in SZ patients show reduced modularity relative to healthy controls (HCs) (Figure 9), and in addition, HC statelets are significantly more recurring than in SZ (Figure 10). An experiment of the transitivity of time decay (TD) graphs indicates that HC networks are more often in sync and for more extended periods, consistent with increased inter\u2010communication to SZ (Figure 11). Finally, statelet\u2010wise subgrouping of the dynamics reports salient and stable group differences in sensorimotor (SM), cognitive control (CC), and cerebellar (CB) domains, which are not observed in earlier studies. The main contributions of our article can be highlighted as follows:   \n\u2022 Propose a new statelet approach to address the limitations of current sliding window plus clustering (SWC) methods for dFNC analysis. \n  \n\u2022 Adapt the EMD as a distance metric for comparing time series motifs. \n  \n\u2022 Use time\u2010series motifs for capturing transient recurring co\u2010fluctuation of neuronal populations and unwarp the FC in a finer time scale. \n  \n\u2022 Develop a novel probabilistic motifs summarization framework for providing the synopsis of the dynamic through a subset of connectivity prototypes. \n  \n\u2022 Use PD of motifs to assess spatial consistency across a group. \n  \n\u2022 Introduce a TD metric to investigate the summary signatures' temporal consistency. \n  \n\u2022 Enable measurement of the brain's dynamic properties: an inherent dynamical system. \n  \n\u2022 Show significant differences in SZ patients who generally show less frequent and shorter statelets. \n  \n\n\n## DEFINITIONS AND   BACKGROUND  \n  \n### Definition 1: Dynamic functional network connectivity \n  \ndFNC is a time\u2010varying correlation typically computed using a sliding window (block of time points, for example, 30\u201360\u2009s) technique among ICs of the brain. The correlation value at each window also quantifies the FC strength between a pair of brain networks within the time frame. \n\n\n### Definition 2:   dFNC   time course \n  \nA dFNC time series,   T  \u00a0=\u00a0  w  ,   w  ,   w  , \u2026,   w   is a sequential set of   n   real values, where   w   represents the correlation between a pair of ICs of the brain for a certain period.   w   stands for a sliding window of a certain size. There is one such TC for each pair of components (connections). \n\n\n### Definition 3: Connections/pair \n  \nA connection is a functional association between a pair of independent neural components. We use \u201cconnection\u201d and \u201cpair\u201d interchangeably in our writing. \n\n\n### Definition 4: Subsequence \n  \nGiven a time series   T   of length   n  , a subsequence   S   is a subset of length   m  \u2009\u2264\u2009  n   contiguous indices of   T  . \n\n\n### Definitions 5: Motif \n  \nGiven a time series   T   of length n, a motif   H   is a subsequence of   T   with length   m   having the minimum average distance from   C  \u2009\u2212\u20091 other   m  \u2010length subsequences of   T  .   H   is the most recurring shape in   T   of length   m  . \n\n\n### Definition 6: Statelets \n  \nGiven a collection (constant/variable\u2010lengths) of time series motifs   G   and a positive real number   d   (size parameter), Statelets   S   is a subset of size   d   of state\u2010shape prototypes evaluated using the proposed summarization framework. \n\n\n\n## DATA COLLECTION AND PREPROCESSING \n  \nWe used an existing SZ dataset for generating the dFNC TCs in this project (Keator et al.,\u00a0 ). The data repository has resting\u2010state functional magnetic resonance imaging data collected from 163 HCs (117 males, 46 females; mean age 36.9) and 151 age\u2010 and gender\u2010matched patients with SZ (114 males, 37 females; mean age 37.8) during the eyes\u2010closed condition. Collected data pass\u2010through data quality control (explained in Allen et al.,\u00a0 ; Damaraju et al.,\u00a0 ). The participant's consent was obtained before scanning following the Internal Review Boards of affiliated institutions. Data were collected with a repetition time (TR) of 2\u00a0s on 3T scanners. Imaging data for six of the seven sites were collected on a 3T Siemens Tim Trio System and a 3rGeneral Electric Discovery MR750 scanner at one site. Resting\u2010state fMRI scans were acquired using a standard gradient\u2010echo echo\u2010planar imaging paradigm: Field of view of 220\u2009\u00d7\u2009220\u2009mm (64\u2009\u00d7\u200964 matrices), TR\u00a0=\u00a02\u2009s, Echo time \u00a0=\u00a030\u2009ms, Fractional anisotropy\u00a0 =\u00a0770, 162 volumes, 32 sequential ascending axial slices of 4\u2009mm thickness and 1\u2009mm skip. Subjects had their eyes closed during the resting state scan. \n\nData preprocessing, quality control, and dFNC approximation follow the standard pipeline described in (Rashid et al.,\u00a0 ). The preprocessing follows a standard pipeline that has been adapted in several previous studies (Agcaoglu et al.,\u00a0 ; Damaraju et al.,\u00a0 ; Espinoza et al.,\u00a0 ; Rashid et al.,\u00a0 ,  ). The preprocessing steps include image alignment (motion correction), slice timing correction, spatial normalization, despiking, and smoothing, which are commonly used for fMRI preprocessing. Depending on the MRI scanning protocols and collected data, the preprocessing parameters were selected and described in these studies and their supplementary (Allen et al.,\u00a0 ,  ; Damaraju et al.,\u00a0 ). First, rigid body motion correction has been done using the INRIAlign toolbox in SPM to correct for subject head motion, followed by a slice\u2010timing correction to account for timing differences in slice acquisition (Freire & Mangin,\u00a0 ). Then, the scans went through a 3dDespike algorithm to regress out the outlier effect and warped to a Montreal Neurological Institute (MNI) template and resampled to 3\u2009mm  isotropic voxels. Instead of Gaussian smoothing, we smoothed the data to 6\u2009mm full width at half maximum (FWHM) using the BlurToFWHM algorithm, which performs smoothing by a conservative finite difference approximation to the diffusion equation. Additionally, the voxel TC was variance normalized before performing the ICA (Hyv\u00e4rinen & Oja,\u00a0 ), as this has shown better to decompose subcortical (SB) sources in addition to cortical networks. Group ICA (Calhoun et al.,\u00a0 ) was performed on the preprocessed data and identified 100 ICNs. Subject\u2010specific spatial maps (SMs) and TCs were obtained using the spatiotemporal regression back reconstruction approach implemented in GIFT software (Calhoun et al.,\u00a0 ). To ensure estimation stability, we repeated the ICA algorithm 20 times in ICASSO, and aggregate SMs were estimated as the modes of component clusters. Subject\u2010specific SMs and TCs were obtained using the spatiotemporal regression back reconstruction (Calhoun et al.,\u00a0 ; Erhardt et al.,\u00a0 ) implemented in GIFT. Following ICA, we obtained one sample   t  \u2010test map for each SM across all subjects and threshold these maps to obtain regions of peak activation clusters for each component; we also computed the mean power spectra of the corresponding TCs. These heuristics curated a group of components as ICNs if their peak activation clusters fell on gray matter and showed less overlap with known vascular, susceptibility, ventricular, and edge regions corresponding to head motion. We also ensured that the mean power spectra of the selected ICN TCs showed higher low\u2010frequency spectral power. This selection procedure resulted in 47 ICNs out of the 100 ICs obtained. The cluster stability/quality (  I  ) index for these ICNs over 20 ICASSO runs was very high (  I  \u2009>\u20090.9) for all of the components, except an ICN that resembles a language network (  I  \u00a0=\u00a00.74). The subject\u2010specific TCs corresponding to the ICNs selected were detrended, orthogonalized with respect to estimated subject motion parameters, and then despiked. The despiking procedure involved detecting spikes as determined by AFNI's 3dDespike algorithm and replacing spikes by values obtained from the third\u2010order spline fit to neighboring clean portions of the data. The despiking process reduces the impact/bias of outliers on subsequent FNC measures. The 47 components are organized into modular partitions using the Louvain algorithm of the brain connectivity toolbox. We computed functional network connectivity (FNC), defined as pairwise correlation between ICN TCs. To compute the time varying FNC between the ICN TCs defined as pairwise correlation dFNC between two ICA TCs referred to dFNC was evaluated using a sliding window correlation approach with a window size of 22 TR (44\u00a0s) in steps of 1 TR (Allen et al.,\u00a0 ; Calhoun et al.,\u00a0 ). The window constituted a rectangular window of 22 time points convolved with Gaussian of sigma 3 TRs to obtain tapering along the edges (Allen et al.,\u00a0 ). We compute the time\u2010varying FNC for each connection between a pair of nodes (ICNs) and generate a time series. We estimated covariance from the regularized inverse covariance matrix (Smith et al.,\u00a0 ; Varoquaux et al.,\u00a0 ) using the graphical LASSO framework (Friedman, Hastie, & Tibshirani,\u00a0 ). The regularization parameter was optimized for each subject by evaluating the log\u2010likelihood of the subject's unseen data in a cross\u2010validation framework. Consistent for all post\u2010hoc steps for extracting and validating. Subject\u2010wise dFNC values were Fisher\u2010Z transformed and residualized with respect to age, gender, and site. After computing dFNC values for each subject, covariance values were Fisher\u2010Z transformed and residualized with respect to age, gender, and site using the reduced model determined from our static FNC (sFNC) analysis. The mean dFNC matrix was computed over all subjects. This connectivity represents the association/relation between two parts of the brain and how this relation evolves with time. In other words, we can interpret this connection as an abstraction of communication between different brain hubs to process information. As such, both highly positive and negative correlations are informative to characterize the relations in two distinct directions. The hypothesis is the presence of these connections make the neural system process information and generate response in a healthy manner. Likewise, having disruption in those connections can cause symptoms present in several mental disorder like SZ. Our study aims to extract most dominant repetitive patterns of these connections by decomposing the time series in a granular scale. Then, summarize these patterns as a global representative set (Statelets) that helps leveraging this knowledge to measure different dynamic features of brain in post hoc study. More details about the components and the dFNC computation is available in this study and its supplementary (Damaraju et al.,\u00a0 ). \n\n\n## EARTH MOVER DISTANCE \n  \nWe implement the EMD for computing distances between motifs. EMD usually measures the dissimilarity between two probability distributions (Levina & Bickel,\u00a0 ; Vallender,\u00a0 ). Also, EMD is effectively adaptable for time series subsequence comparison. It corresponds to the minimum amount of work required to make two subsequences look\u2010alike (Champion, De Pascale, & Juutinen,\u00a0 ). For   p   and   q  , two given signatures,   F  (  p  ,   q  ) represents the set of all possible flow between   p   and   q  . Then, the work is defined as follows, \n\nhere   is some measure of dissimilarity (e.g., Euclidean distance),   is the optimal flow that minimizes the cost between   and   (  i  th time points). The terms   m   and   n   denote the length of the signatures, respectively. The heuristic minimizes the amount of work done to compute the EMD between   p   and   q   given by the following equation (Andoni, Indyk, & Krauthgamer,\u00a0 ; Champion et al.,\u00a0 ). \n\nThe above equations provide the canonical formulation for computing EMD between signatures of any dimensions; however, we opt to compare shapes from one\u2010dimensional time series. Hence, we propose a more straightforward implementation in the next paragraph where we are not required to use an off\u2010the\u2010shelf distance measure. \n\n### Implementation in our study \n  \nWe use a particular case of EMD for a one\u2010dimensional time series, which parses through the vectors and keeps track of how much flow occurs between consecutive time points. Here, flow is the difference between the amplitudes of two\u2010time series at a given time point. The method recursively accumulates the absolute work done at each time point, and finally, the summation over the time points corresponds to the EMD distance (see Equations\u00a0  and  ). Equations\u00a0  and   normalize shapes   p   and   q  , respectively. \n\n\n\n## OUR PROPOSED FRAMEWORK \n  \nOur architecture performs two fundamental steps to estimate state\u2010shape prototypes (statelets) from time\u2010series dataset, (A) motif discovery and (B) summarization. Figure 3 depicts the subprocesses required to perform these steps. \n\n### Step 1: Motif discovery \n  \nEach dFNC time series represents the FC between two distinct brain networks. Therefore, it is not feasible to impose a common motif length for all the time series in the dataset, like most other motif discovery methods. The proposed heuristic takes a range [R1 R2] and suggests the perfect length to explore the time series within that boundary. In our case, dFNC is collected using a window size of 22 time points. So, the lower bound for R1\u2009>\u200922. The upper bound for R2 should be confined within half of the signal length for a sensible parcellation of dFNC. Since the study aims to observe transient signatures in the data, we select the range [30 50] in our analysis. Figure\u00a0  demonstrates the step for performing motif discovery. At first, the process creates all the subsequences of different lengths and then passes these candidates through the following subroutines (Matlab scripts). \n  \nOur proposed methodology for time series motifs discovery and summarization. (a) Step 1: Motif extraction using EMD as a similarity metric. The subroutine takes out the most repetitive pattern (possibly with multiple occurrences) of a given time course, (b) Step 2: Summarization of motifs using their probability density computed by a kernel density estimator (KDE). It takes a bag of varying length motifs and generates a concise smaller collection of the most frequent shapes/patterns representing the functional system (SZ/HC). We defined these prototypes as the statelets. The EMD distance matrix is used for both performing the tSNE and computing probability density (PD) of the motifs. The relevant processing blocks and their intuitions in Step 2 are described elaborately in Section\u00a0 \n  \n####  EMD   layer \n  \nFor a given candidate of length  , the algorithm searches through the timepoints by taking all other candidates of that length and computing the EMD between them. We can consider the selected candidate as a kernel here, and the idea is to apply that kernel on the input signal to compute distances. \n\n\n#### Pooling local minima \n  \nThe module pools a subset of top matches (minimum distance) instead of just one across the signal. Since motifs are repeating signatures, intuitively, we scrutinize the top matches only. It decomposes the input TC into several subsections and pools the minimum from each subsection. \n\n\n#### Mean of   LM  's and global minimum \n  \nThis layer computes the mean of those local minima, representing the overall performance by that specific candidate. After finishing computation for all the candidates of  , the method selects the global minimum, which corresponds to the best acquirable matching (BAM) score. \n\n\n#### The best length selection \n  \nTo extract most recurring transient patterns, a recommender unit optimizes two objectives using the BAM scores considering all different lengths (i) minimizing the motif's length and (ii) maximizing the similarity score. The recommender unit returns the best length for decomposing a time series. \n\n\n#### Motif extraction \n  \nWe have already collected information from the length selection process, that is, distance, occurrences required for motifs extraction. So, using the leading candidate as the benchmark, the subroutine collects similar nonoverlapping occurrences of local motifs across the TC and stores these motifs for creating global dominants across the subjects for a given pair. \n\nThis analysis compares the dFNC time\u2010series datasets across the two groups, HC and SZ. After discovering the motifs from all the dFNC time series, we have a large population of variable length patterns. Next, a group\u2010wise summarization is performed on these motifs. \n\n\n\n### Step 2: Summarization \n  \nThe decomposition technique (motif discovery) transforms the FC into a diverse connectivity signatures manifold. Each pair of components (connection) discovers a group of shapes from all the subjects. Summarization aims to fetch the representatives of the motif's collection. The intuition is to find highly persistent patterns from all the distinctive subgroups of the population to ensure that statelets approximately capture all the diversities in the given stack of motifs. The persistence is measured from the shape's PD across the given trajectory, and the subgrouping is unveiled through the t\u2010distributed stochastic neighbor embedding (tSNE). Our summarization scheme weighs the tSNE points using the corresponding PD. Then, an off\u2010the\u2010shelf peak technique locates the expected prototypes with standard smoothing and proximity parameters. To run the subprocesses, the probabilistic summarization runs a module called \u201cFindDominants\u201d: a suite of Matlab and Python scripts consisting of four steps (a, b, c, and d) mentioned in Figure\u00a0  to identify pairwise dominant motifs. We replicate the same analysis for both subject groups SZ and HC. \n\n####  EMD   matrix \n  \nWe need the distance from each motif to all others to measure the density and to subgroup them using tSNE. Here, we use EMD again for computing the distance matrix. First, we normalize the TCs to make our distance invariant to scale and offset. Then, calculate cross EMD across the motifs, which creates a square matrix of   n  \u2009\u00d7\u2009  n   dimension where   n   is the number of shapes in the given collection. \n\n\n#### Kernel density estimator \n  \nOur method applies KDE to calculate the PD of data instances (motifs) in the population. We incorporate a Gaussian kernel with optimal bandwidth (Sheather & Jones,\u00a0 ; Silverman,\u00a0 ) in KDE. In this setting, kernel density at a point   x   is given by Equation\u00a0 , \n\nFor \u2018  D  \u2019 dimensions, the formulation becomes, where   n   is the number of samples,   is the kernel with a smoothing parameter,   h   is called the bandwidth. The kernel is a non\u2010negative function and   h  \u2009>\u20090. The common practice uses the Gaussian kernel for a smoother density model, simplifying the following kernel density model. here   is the SD of the Gaussian components. Another crucial part of the process is to select an appropriate bandwidth (  h  ) for the density, and several strategies for selecting   (I. A. Ahmad & Amezziane,\u00a0 ; Turlach,\u00a0 ). Our approach incorporates the rule\u2010of\u2010thumb bandwidth estimator for Gaussian (Scott,\u00a0 ). The optimal choice for   is following, here   is the SD of the samples, and   is the number of total samples. The term   in the equation corresponds to the distance between the sample   and  . So, we assign EMD distances between the shapes computed in Section\u00a0  to assign the value of the term   in the equation. Using Equation\u00a0( ), KDE generates PD for all motifs in the collection. \n\n\n####  tSNE   using   EMD  \n  \ntSNE is a powerful and flexible visualization tool for high\u2010dimensional data by giving each datapoint a location in a two\u2010 or three\u2010dimensional map (Gisbrecht, Schulz, & Hammer,\u00a0 ; Maaten & Hinton,\u00a0 ). Decentralized stochastic neighbor embedding (dSNE) separates the data subgroups using their distance metrics (Saha et al.,\u00a0 ,  ). In our case, tSNE considers each motif as a data point and uses the EMD matrix (computed in Section\u00a0 ) to select the neighbors for the embeddings. Next, the method weighs all the points using their corresponding PD. Figure\u00a0  presents an example of how tSNE reveals intrinsic subgroups of data collection. The color indicates the PD. The brighter, the higher. The visualizations in the subsequent steps are generated using this same plot. \n  \nAn example of tSNE using EMD distance on a collection of real motifs. Data points represent the motifs weighted by their probability density computed using KDE.   X   and   Y   axis stand for the horizontal and vertical coordinates of each point, respectively \n  \n\n#### Two\u2010dimensional mapping \n  \nAlthough the above tSNE map unveils the subgroups, we still need to mechanistically locate the summary prototypes. To employ the peak finder, we need to map the tSNE plot (Figure\u00a0 ) to a standard discrete two\u2010dimensional (2D) coordinate system, for example, a 2D grid. This subroutine assigns all tSNE points to a two\u2010dimensional discrete system and accumulates the PD of all closely neighboring shapes onto a single cell. The strive is to make dominant points more distinguishable by increasing the frequency in the corresponding vicinity. This approach discretizes the range of coordinates into a set of integer intervals. As a result, multiple points from the tSNE plot are stacked together into a single cell, as shown in Figure\u00a0  to summarize the PD of a close neighborhood. \n  \nMapping tSNE points to a 2D matrix for accumulating PD's of close neighbors. Therefore, we observe the higher density data with a brighter color in the figure \n  \n\n#### Gaussian blur and peak finding \n  \nDefocusing noise helps identify significant features/data points representing the subgroup. We apply a Gaussian blur to the tSNE image to facilitate the estimation of the peaks. Figure\u00a0  displays how the blurring effect changes the focus toward relevant loci of the image. Then, we use a two\u2010dimensional peak finder to compute the high\u2010density data points. The peak finder extracts a characteristic shape from each subgroup with a higher PD. The spikes in Figure\u00a0  indicate the representative motifs (statelets) from the whole population. It visualizes one spike per high\u2010density subspace. It visualizes how the summarization scheme covers the whole state\u2010shape trajectory and approximates the synopsis. For more clarity, the method restricts the peak finding subroutine by calibrating the smoothing parameter to avoid creating a pile of similar patterns. The objective is to find a diversified set of shapes that reasonably approximates the overall dynamics. \n  \nAfter applying a Gaussian blur on the 2D image to defocus less dense data points \n    \nA three\u2010dimensional view of the tSNE plot after marking the peaks extracted by a 2D peak finder. The peak finder selects at least one peak from each high\u2010density region. Later, we use peak's tSNE coordinates to determine the real motifs it represents \n  \n\n\n\n## EXPERIMENTAL RESULTS \n  \nWe divide the dataset into 163 HC subjects and 151 SZ patients (SZ) groups. Each subject has   C  \u00a0=\u00a01,081 pairs of components or 1,081 connections: 1081 dFNC TCs. For each connection, we take TCs from all the subjects within that group (HC/SZ). Our method evaluates a subset of statelets from both groups of subjects (SZ/HC). The PD of these high dimensional state shapes denotes the consistency of these statelets across connections among multiple brain regions. In Figure\u00a0 , we show the most frequent statelets from both groups. We used the Jonker\u2010Volgenant algorithm (Cao,\u00a0 ) for a linear assignment problem that optimizes the mapping of tSNE coordinates to a two\u2010dimensional grid preserving the matching shapes in the same neighborhood constraint. In Figure\u00a0 , we compute the statelet's PD that denotes the consistency of these statelets across connections among multiple brain regions. Each bar indicates how frequently a connection's statelet has appeared in the group dynamics. The frequencies are also sorted based on their relative rank computed on their frequency in both patient and control groups. This serves to analyze the connection's readiness in the functional dynamics. We can see that the pair (connections) rank is very different in each group, suggesting a diverse influence of a connection driving the dynamics of patients versus controls. The observation indicates two distinct subsets of connection drive the group dynamics and evident a high\u2010level group difference in terms of neural components participating in the information processing. Further analysis is required to shed more light on these differences. Another observation is frequency of the statelets in HC connections is higher than in the SZ. To test the statistical significance of this difference between the two distributions, we compute a Kendall tau correlation coefficient, which is traditionally used to measure the ordinal association between two entities (Kendall,\u00a0 ; Puka,\u00a0 ). The hypothesis test evaluates   =\u20090.045 with a   p  \u2010value\u00a0=\u00a00.025 indicating a statistically significant difference. \n  \nA subset of dominant motifs from SZ and HC dynamics. The motifs are detrended and visualized using tSNE followed by the Jonker\u2010Volgenant algorithm for the linear assignment problems. A similar type of shape is embedded into the same neighborhood. We can see a few potential subgroups of motifs. The blank space in the figure was generated because we used a larger 2D grid than the number of motifs to display. So, the algorithm optimizes the location for each motif from the 2D coordinate system to assign the matching patterns in the nearby vicinity. The   X   axis is time, and the   Y   axis represents the dynamic functional connectivity strength \n    \nEach connection's probability density (PD) demonstrates how frequently the statelets extracted from a connection appear in the group dynamic. Each connection has two density values: one per subject group. Blue demonstrates PD in controls (HC) and red in the patients (SZ). We sort the connections low to high according to their PD in the SZ group (left subplot), and HC sorts the right subplot. Y axis represents the order of the links after sorting, and X axis depicts their corresponding PD. We observe that the rank of connections differs in both subject's groups in terms of their PD; the PD difference is statistically significant and visually evident in the plot \n  \n### Dynamic features analysis \n  \nWe focus more on the dynamic features of the neural system, which have been primarily unexplored in previous studies of dFNC. The dynamic properties of these representative shapes show significant group differences between HC and SZ phenotypes. \n\n#### Recurrence \n  \nTo quantify the recurrence of statelets, we use passage coding by convolving the group\u2010wise most frequent statelet with each connectivity time series. Passage coding annotates a time series with the corresponding convolution score and visually perceivable the repetitions. Figure\u00a0  presents the occurrences of the group statelets in individual dynamics (randomly selected three subjects from each group). We investigated the recurrence of statelets for all the subjects and got consistent results, as shown in Figure\u00a0 . Statelets are designed to be the most generalized envelopes of brain connectivity time series; thus, higher recurrence endorses better convergence to the standard form of connectivity. The agreement toward regular co\u2010fluctuations by the connection aids synchronization in the brain circuitry. In the SZ dynamic, the repetitions of statelets are significantly lower than HC. That leads to a weaker association between the brain components in SZ dynamics to perform smoother cognition. Also, fewer connections are present in the SZ dynamics than HC, which indicates the absence of necessary communication among the subunits of the brain to process brain signals. Overall, the recurrence helps understand the pattern of communication (e.g., message passing) between the modules of the brain. Apparently, a more connected brain graph with the edges characterized by a recurrent communication scheme is required to produce the necessary cognitive response. This recurrence analysis indicates the absence of the necessary repetition of communications between the submodules of the brain in the SZ dynamic. This provides a ground for further study to explore the reasoning behind these abrupt connectivity patterns. Also, more analyses are required to identify why these disruptions are being triggered. \n  \nEach graph represents the occurrences of the most recurring statelets over each subject's time course. These are three randomly selected subjects from the HC (top) and SZ (bottom) groups. We convolve the group statelets with the subject dynamics (all the dFNC time courses, 1,081) to investigate the recurrence of the statelets over time. Then, we sorted the pairs based on the dominant shape's first occurrence in their time series. Consequently, the early the statelets appear in a pair's time course, the higher the pair/connection in that subject's dynamics\u2014we threshold these convolutions matching scores at 0.8 for both groups to track down the strong appearances only. The color intensity corresponds to how strongly/weakly the shape appears in that part of the course. The color bar is identical for all the reference subjects in the figure \n  \n\n#### Modularity \n  \nThe line graphs in Figure 11 illustrate the ensemble behavior of the connections in both dynamics (SZ/HC). The value represents the number of connections with similar prototypes at each time point. Throughout the scan session, comparatively more HC connections are activated in identical time steps than patients. This characterizes the higher modularity in the HC functional network/graph (the connections between the functional components of the brain). Modularity is imperative because it quantifies the strength of the network's division into modules. Each module consists of a subset of nodes, independent brain components in our case. These modules help data transmission by performing specific tasks independently. Results show individuals with higher baseline modularity exhibit more significant improvement with cognitive training, suggesting that a more modular baseline network state may contribute to greater adaptation in response to cognitive training (Arnemann et al.,\u00a0 ). Also, cognitive ability is influenced by the relative extent of integration and segregation of functional networks (i.e., modules) distributed across distant brain regions (Chen, Abrams, & D'Esposito,\u00a0 ; Stevens et al.,\u00a0 ). Subsequently, the difference in modularity is informative about the cognitive symptoms of SZ. In addition, the graph shows SZ connections become modularized at the end of the time series, whereas the HC ensembles are reduced by their size (Figure\u00a0 ). This ensemble activation also demonstrates a distinct synchronization pattern between SZ and HC brains and suggests an interchanging control by various neural components. \n  \nBased on probability density ranking (in Figure\u00a0 ), we computed a collective appearance of the connections across all the subjects. The X axis shows the time steps, and the Y axis corresponds to the number of pairs connections that show the first statelet at that step, which indicates the activation of the pair \n  \n\n#### Consistency graphs \n  \nTo measure the statelets' temporal consistency in the connectivity time series, we introduced a metric called TD. The primary motivation behind introducing TD is to approximate the temporal consistency of the statelets. Also, measuring how frequently these generalized dominant patterns appear in the timeline. The metric indicates how temporally localized or widespread the statelets are. TD is defined as follows. \n\nTD: a temporal consistency measure\u2014The TD approximates how consistently a pair's connectivity exhibits the dominant motif in the TC. The metric captures the temporal information of the summary shapes and integrates it across a group dynamic. The following equation describes TD. \n\nHere, |  S  |\u00a0=\u00a0The total number of subjects in the group SZ/HC and   T   the index at which the pair has appeared for the first time in a subject (  T  \u00a0=\u00a01 to 136). If the pair is not present in a subject's dynamic, then   T   =   thus, TD for that pair in a subject is zero. We calculate the TD for each connection in a subject's dynamic and lately compute the average across the subjects within a group (SZ/HC). We used the meantime decay computed on the group dynamic for the group representation. We consider the appearance of a connection in a subject's dynamic based on the first occurrence of group statelet on that time series. The occurrence is calculated based on a thresholded convolution score. We also sorted the connection based on their first initialization in the subject's dFNC. The intuition was to investigate which connections are responsible for triggering the convergence toward statelets and how it propagates the dominance across the TC. The expected time point at which the connection is initiated in the dynamic is inverted. So, if the TD is very localized, then the mean is very close to that time point and has a higher value. In essence, it quantifies the temporal uniformity of the statelets in a subject's dynamic. Since statelets are the most repeated, stable, and representative subsequences of the time series, this attribute can potentially explain the connection's affinity toward a more generic connectivity state contributing to the dynamics. Also, TD estimates how quickly/lately the connectivity rectifies their initial disparity and converges to routine cognition. It characterizes a connection as consistently late (low TD value), consistently early (high TD value), pseudo\u2010random positioning (medium TD value, e.g., 0.10 to 0.15), consistent but sparse in the group dynamics (0.5\u20130.9), etc. \n\nFigure\u00a0  demonstrates the average TD graphs computed on both dynamics. Here, the vertices are independent brain networks, and the edge represents the connection between two functional networks. The weight of the edge stands for the TD; the darker, the higher. As we can see, HC functional networks are firmly connected, and most of the connections (out of 1,081) pass the TD benchmark. On the other hand, only a small subset of SZ connections converges to their group statelets. This provides evidence that the consistency of SZ network connections is considerably lower than HC. The functional connections between different brain components show more substantial temporal consistency in HC. SZ statelets are more dispersed along the timeline, consequently lacking the expected connectivity signature in the active channels. It might impact overall information processing due to a deficiency in temporally sensitive message passing in the functional network. To further probe the interconnections, we computed the transitivity of each subject's TD graph. Figure\u00a0  shows the histograms of transitivity of subject\u2010wise TD graphs in both groups. Transitivity symbolizes the global probability of the network (connectivity graph) to have adjacent nodes interconnected, revealing the existence of tightly connected communities, e.g., clusters and subgroups. Most of the SZ graphs have zero or very low transitivity compared to HCs. We compute a two\u2010sample   t   test on the transitivity scores from both groups, and the   p  \u2010value,   p  \u00a0=\u00a09.23e\u201088, indicates the difference is highly statistically significant. Higher transitivity suggests that modules in the network consistent with prior work showing increased modularity are linked to improved cognitive performance (Arnemann et al.,\u00a0 ). The analysis indicates that HC networks intercommunicate more consistently and keep the channels up than SZ. This result is consistent with previous work (Allen et al.,\u00a0 ; Karlsgodt, Sun, & Cannon,\u00a0 ; Rashid et al.,\u00a0 ), which suggested that patients exhibit more erratic and less efficient communication among brain regions than controls. Figure\u00a0  shows the average TD of each connection in both SZ and HC groups. The rightmost map shows HC\u2010SZ group differences. All the pairs in HC show a more substantial TD than SZ, especially in visual, SM, and default mode (DM) regions. Notably, HC subjects show higher TD than patients with SZ, and the apparent group differences present almost all over the brain. That also makes the data more useful for classification. Intuitively, we feed subject\u2010wise TD data to multiple classifiers and get good accuracy in every case. To avoid bias, the statelets are extracted from the whole dataset without using group (SZ/HC) information (unsupervised). Thus, the classification accuracies are reasonably comparable. For clarity, we can consider it a dimensionality reduction method like principal component analysis (PCA) (Wold, Esbensen, & Geladi,\u00a0 ) for better features selection. We compare the performance between running the models directly on the dFNC matrix and methods like PCA (Wold et al.,\u00a0 ) for better features selection. We compare the performance between running the models directly on the dFNC matrix and the subject\u2010wise TD. We use multiple classifiers to test TD and observe significant accuracy improvement for more robustness. Figure\u00a0  shows how the models perform in both cases. We can see a simple SVM or logistic regression model using TD outperforms all other methods, including LSTM with attention. \n  \nTime decay graphs from both groups. The nodes are functional networks, edges correspond to the connection between them (maximum 1,081 possible), and the weight represents the mean time decay (TD) of a connection within a group dynamic. We compute color scaling from the 95 percentiles of the total values. After thresholding at average group mean (SZ group mean\u2009+\u2009HC group mean)/2, 1,061 edges survive in the HC group and only 16 edges in the SZ group \n    \nHistogram of transitivity from subject\u2010wise time decay graphs. It refers to the extent to which the relation between two nodes in a network connected by an edge is transitive. A significant portion of SZ subjects shows 0 transitivity, which means the connections are less consistent across different subjects. We show the differences are statistically significant using a two\u2010sample   t  \u2010test on both distributions. Transitivity is also related to the clustering coefficient \n    \nPairwise mean time decays in healthy control (HC) and schizophrenia (SZ) groups. We run a two sample   t   test on the pairwise time decay values to check the statistical significance of their HC\u2010SZ group differences. The rightmost subfigure represents the FDR corrected   t   values \n    \nClassification accuracy for different methods. First, three methods were applied to the dFNC matrix and LSTM with the attention model applied to the dFNC time course. The last two methods use time decay (TD) for classification. We run the models on time decay information of all the subjects for 100 repeated iterations, and the accuracies are mean across the iterations. We train the model on 200 random samples in each iteration and cross\u2010validate them using the remaining 114 subjects \n  \ndFNC states from statelets\u2014In this cross\u2010group analysis, we focus on obtaining statelets across the dataset without separating SZ and HC subjects into two different bins. The major objectives can be articulated (i) extracting cross\u2010group patterns, (ii) subgrouping the subjects based on statelets, (iii) experimenting with the statelet's connectivity strength and evaluating domain\u2010wise group differences. It is identical to the group\u2010wise analysis motif extraction followed by probabilistic summarization. The key difference is we send all the time series (from both subject's group HC/SZ) together through our statelet framework. Then, using approximated statelets as the representative, we partition the collection of shapes into several subgroups (connectivity states). After that, we use the EMD of extracted motifs to determine their association toward a specific subgroup/state\u2014assign motifs to the nearest (lowest EMD) state. Statelets characterize the intrinsic cluster in the motifs extracted from dFNC TCs. The centroids of these clusters are referred to as brain states. We represent these connectivity patterns extracted from the dFNC TC as dFNC states. The centroids of these states represent patterns of FNC (temporal coherence) that individuals move between throughout the course of the experiment. We evaluate the HC\u2010SZ group differences in connectivity strength across the subjects within a state. For measuring the statistical significance of these differences, we use a two\u2010sample   t   test. The   t  \u2010values provide significant group differences in connectivity strength throughout the distinct regions of the brain (Figure\u00a0 ). HC subjects in state 1 show stronger connections than SZ, and differences are statistically significant in SM, CC, and DM regions. In states 2 and 3, the differences are mostly HC\u2009<\u2009SZ; in state 3, group differences are statistically significant across the brain but similar strength in the connections between SB and other domains. State 4 shows mostly weaker differences except for a few auditory (AUD) and SB components, demonstrating SZ subjects are more strongly connected than HC in those regions. Two connections between AUD and DM show a statistically significant difference in state 5, and state 6 exhibits HC\u2009>\u2009SZ in the CC region. Above all, states 7, 8, and 9 show significant connectivity differences in CC and DM regions. Specifically, state 7 depicts HC\u2009>\u2009SZ and 8 and 9 shows HC\u2009<\u2009SZ group distinction. In an earlier study (Rashid et al.,\u00a0 ), strong group differences are mostly in visual and AUD, but we got differences in SM, CC, and CB. We got both HC\u2009<\u2009SZ and SZ\u2009<\u2009HC in SM, CC, and DM. We observe the most significant pattern of group differences here in CC, DM, and CB regions. This triangle shows the variation in connectivity between patients and controls across multiple states with an alternating directionality, which indicates a potential biomarker for specific subtypes of SZ. \n  \nHC\u2014SZ group differences in terms of max connectivity strength. State\u2010wise group differences in functional connectivity (FC). We have both SZ and HC subjects' groups at each state. For each pair of components, we have a subset of statelets from HC subjects and a subset from SZ subjects. Then, we compute the maximum connectivity strength of those statelets from both subgroups. A two\u2010sample   t   test using a null hypothesis of \u201cNo group difference\u201d compares patients' max connectivity versus controls. A higher   t   value indicates the rejection of the null hypothesis irrespective of their sign. However, the sign of   t   values represents the directionality of the group difference. The pair matrix (47 \u00d7\u200947) is labeled into seven different domains subcortical (SB), auditory (AUD), visual (VIS), sensorimotor (SM), cognitive control (CC), defaultmode (DM), cerebellar (CB), respectively. White cells in the matrix indicate either the absence of that pair or nonsignificant group differences for this pair within a state. The upper triangle represents the FDR corrected differences \n  \n\n\n\n## CONCLUSION \n  \nWe proposed a novel method for analyzing dynamic FC via extracting high\u2010frequency texture from the connectivity space. To our best knowledge, it is the first pattern mining application on dFNC data. The proposed framework addresses issues in current dFNC analysis methods by modeling the dynamics through brief connectivity shapes. The analysis of those motifs enables measuring the characteristics of brain circuitry and network organization. The major contributions of our study are two\u2010folded, an unsupervised method for motifs discovery using EMD as a distance metric and a probabilistic summarization of these patterns. Because of the complexity of the data, it was necessary to summarize the information into a predictable and concise subspace. To do this, we included a representative snippet of the human brain connectivity graph, using the set of components as reduced space to show how it behaves over time. The experiments facilitate the observation of distinguishing connectivity signatures and the interplay among the hubs to process information. Statelets provide this summary that includes abstraction, analytics, and current trends at a glance. The statelet approach seeks an improved understanding of connectivity states and the mechanism through which their dynamics vary across individuals. Results demonstrate how these state movies help to investigate the dynamic properties of an inherently dynamic system (i.e., brain). Our approach is more robust to noise while observing short\u2010length dynamic features of the functional dynamics of the brain. These connectivity shapes from SZ and HC dynamics help create a global contrast between healthy and diseased brains and illustrate crucial group differences in several dynamic properties such as recurrence, modularity, and synchronizability. Our method has some limitations and potential future improvements too. That includes high time complexity and parameters tuning. We are working on a dynamic programming implementation of motif extractions to reduce the time complexity to a polynomial order\u2014also, a framework for automatic fine\u2010tuning of the model's free parameters. However, statelets provide shape\u2010based analytics and outlines of the dynamics for the first time. It enriches our understanding of how networks communicate in spontaneous brain activity and the pattern of binding/impairment between them to maximize information transfer and minimize connection costs. We believe this would fill in a gap in the field that will help us understand the dynamics better, possibly providing an improved way to study neuropsychiatric disorders more effectively. \n\n\n## CONFLICT OF INTERESTS \n  \nThere is no conflict of interest. \n\n\n## AUTHOR CONTRIBUTIONS \n  \nVince D. Calhoun and Md Abdur Rahaman proposed the idea of statelets. Md Abdur Rahaman and Sergey M. Plis developed the methodology. Md Abdur Rahaman ran the experiments and drafted the manuscript. Sergey M. Plis helped to design a few experiments and edited the manuscript. Vince D. Calhoun supervised the whole project, thoroughly edited the article, and gave valuable feedback on the results. Eswar Damaraju provided the data and performed the preprocessing. Eswar Damaraju and Debbrata K. Saha helped run the experiments and significantly contributed to the manuscript. All authors have approved the final version of the submission. \n\n \n", "metadata": {"pmcid": 9057100, "text_md5": "be70709586411909c2f1b4b39079985d", "field_positions": {"authors": [0, 101], "journal": [102, 116], "publication_year": [118, 122], "title": [133, 227], "keywords": [241, 391], "abstract": [404, 2636], "body": [2645, 55900]}, "batch": 1, "pmid": 35274791, "doi": "10.1002/hbm.25799", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9057100", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9057100"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9057100\">9057100</a>", "list_title": "PMC9057100  Statelets: Capturing recurrent transient variations in dynamic functional network connectivity"}
