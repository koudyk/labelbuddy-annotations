{"text": "Farahibozorg, S Rezvan and Harrison, Samuel J and Bijsterbosch, Janine D and Woolrich, Mark W and Smith, Stephen M\nbioRxiv, 2024\n\n# Title\n\nMultiscale Modes of Functional Brain Connectivity\n\n# Keywords\n\n\n\n# Abstract\n \nInformation processing in the brain spans from localised sensorimotor processes to higher-level cognition that integrates across multiple regions. Interactions between and within these subsystems enable multiscale information processing. Despite this multiscale characteristic, functional brain connectivity is often either estimated based on 10\u201330 distributed modes or parcellations with 100\u20131000 localised parcels, both missing   across  -scale functional interactions. We present Multiscale Probabilistic Functional Modes (mPFMs), a new mapping which comprises modes over various scales of granularity, thus enabling direct estimation of functional connectivity within- and across-scales. Crucially, mPFMs emerged from data-driven multilevel Bayesian modelling of large functional MRI (fMRI) populations. We demonstrate that mPFMs capture both distributed brain modes and their co-existing subcomponents. In addition to validating mPFMs using simulations and real data, we show that mPFMs can predict ~900 personalised traits from UK Biobank more accurately than current standard techniques. Therefore, mPFMs can offer a paradigm shift in functional connectivity modelling and yield enhanced fMRI biomarkers for traits and diseases. \n \n\n# Body\n \n## Introduction \n  \nWithin the complex system of 86 billion neurons ( ) in the human brain, large ensembles of neurons work in synchrony, such that they produce distinct modes of extended, correlated activity ( ). These functional modes exhibit a spectrum of scales and functionalities, from localised brain modes facilitating specialised information processing, such as responses to sensory or motor stimuli, to higher-level cognitive modes integrating across multiple regions through long-range connections. Functional modes underlie spontaneous brain activity during task-free periods (often referred to as resting state networks, RSNs), adapt dynamically during cognitive tasks, and undergo permanent changes in neurodegenerative diseases ( \u2013 ). Growing evidence, especially from new datasets with thousands of individuals, has highlighted that spatiotemporal characteristics of functional modes vary systematically across individuals, providing biomarkers for traits and disease, akin to a diagnostic assay for the brain ( \u2013 ). In this paper, we introduce a novel representation, Multiscale Probabilistic Functional Modes (mPFMs), which, unlike the existing single-scale modes, encapsulates an ensemble of modes across multiple scales. mPFMs have the potential to provide a paradigm shift in how functional connectivity has been modelled to date, by offering a new basis to gain insights into spatiotemporal connectivity within and across diverse processing scales, and providing more sensitive biomarkers from functional neuroimaging. \n\nFunctional MRI (fMRI), with a spatial resolution of ~2mm and a temporal resolution of ~1s, provides a suitable spatiotemporal resolution to characterise functional modes non-invasively. This has largely been done using two distinct approaches: a) high-dimensional (highD) decomposition of fMRI data into functional parcellations with 100\u20131000 modes (i.e., parcels), where each mode is typically   localised   to a single brain region ( \u2013 ); b) low dimensional (lowD) decomposition of fMRI data into ~20\u201330 modes ( ,  ) - the conventional RSNs - each   distributed   across multiple distant brain regions, and often with some spatial overlap between the modes. The latter is often carried out using spatial Independent Component Analysis (ICA) ( ), or lowD parcellations ( ). Each of these two approaches offer distinct benefits. On the one hand, fine-grained, highD parcellations capture local details in the brain\u2019s organisation, especially details that have proved useful for cross-individual variability modelling, and prediction of traits and disease ( ,  ). On the other hand, lowD large-scale modes capture the more global functional configuration of the brain. Distant brain regions with intrinsic long-range connections are grouped into biologically meaningful neural entities such as language and attention networks, allowing for easier interpretation and putative links to cognitive functions ( ,  ,  ). Additionally, lower data dimensionality makes subsequent statistical analyses more manageable. Therefore, distributed vs localised modes each offer distinct benefits and limitations for capturing global vs local functional architecture of the brain. Crucially, however, neither of these approaches allow for direct modelling of inherent interactions across multiple scales of information processing in the brain. \n\nIn this context, we report the finding of mPFMs, which can bridge this gap by providing a unified representation that encompasses modes across multiple scales. mPFMs were identified through high dimensional decomposition of resting state fMRI using the sPROFUMO framework ( ,  ). sPROFUMO defines a Bayesian hierarchy with two levels of group and individuals across big data populations, where group priors are iteratively used for top-down regularisation of individuals, and evidence across individuals is accumulated and fed back to the group. Two key distinguishing aspects of the model are that: 1) sPROFUMO is subject-specific, i.e., inferring the modes for populations and individuals   simultaneously  ; 2) unlike ICA or parcellation-based techniques, sPROFUMO does not impose strong constraints on spatial or temporal independence between the modes, thus yielding modes that are more flexibly interacting, spatially and temporally ( ,  ). \n\nWe report that this added flexibility in modelling population variations, and in spatiotemporal connectivity between the modes, resulted in the discovery of mPFMs ( ), which preserve conventional large-scale modes, and add new modes with different scales of granularity to the ensemble. mPFMs can be considered an alternative to conventional (\u201csingle scale\u201d) resting state networks (RSNs). We report that: a) mPFMs emerge to explain the existence of multiple distinct time-courses within each large-scale mode, thus capturing voxel-to-voxel variability of temporal dynamics that cannot be captured by these distributed modes alone; b) we validate mPFMs using several methods, including synthetic data, reproducibility between Human Connectome Project (HCP) and UK Biobank (UKB) data, and link to HCP\u2019s Multimodal Parcellation ( ); c) we further show the added benefit of cross-scale interactions of mPFMs, compared with within-scale interactions, for capturing cross-individual variability and predicting personalised traits; d) finally, we show that, compared with two commonly used techniques, spatial ICA modes and parcellations from the Schaefer Atlas ( ), mPFMs (of matched high dimensionality) yield more accurate prediction of a wide range of imaging- and non-imaging-derived phenotypes (IDPs/nIDPs) related to cognition, blood and heart health, brain anatomy, and task fMRI in UK Biobank. \n\n\n## Results \n  \nResults presented here are based on applying sPROFUMO to resting-state fMRI (rfMRI) data from 1003 HCP subjects and separately to 4999 UK Biobank subjects. Results predominantly focus on a 25-mode low-dimensional (lowD) PFM decomposition and its comparison to higher-dimensional (highD, >100) PFM decompositions, to investigate the functional relevance and the added benefit of mPFMs.   includes a summary of the terminology used in the paper. \n\n shows direct comparisons between lowD vs highD Probabilistic Functional Modes (PFM) decomposition of rfMRI data in HCP, where a force-directed network layout is used for visualisation ( ). LowD decomposition (shown in yellow) yielded the conventional distributed-only resting state networks, hereafter referred to as large-scale RSNs. The highD decomposition yielded a mixture of modes across various scales. By spatial pairing of the modes from highD and lowD decompositions, we found a one-to-one correspondence between a set of highD modes (shown in orange) and large-scale RSNs, indicating that as we increase the dimensionality from 25 to 150, conventional RSNs are preserved, and new modes are added (shown in blue). This is a novel type of decomposition, and since it includes functional modes across multiple scales, we refer to it as   Multiscale Probabilistic Functional Modes, mPFMs  . \n\nThe following subsections aim to unravel the properties of the brain function that give rise to mPFMs, validating them based on simulations and real data, as well as demonstrating the utility of mPFMs for capturing individualistic traits and prediction of cognition and health. HCP data, compared to UK Biobank, provides higher data quality and longer fMRI recordings (1 hour vs ~6 minutes) per subject. Thus, HCP data was primarily used for untangling the functional relevance of mPFMs, and how they yield a more comprehensive summary of brain activity and connectivity. UK Biobank, given its larger sample size and more extensive phenotyping, was primarily used for evaluating mPFMs\u2019 performance in out-of-sample prediction of phenotypes. Both datasets were used for reproducibility analyses. \n\n### The functional relevance of mPFMs \n  \nFocussing on 25 and 150 sPROFUMO RSNs from rfMRI data of 1003 HCP subjects, we investigated the properties of the brain function that underlie mPFMs, and their added benefit over large-scale (distributed-only) decompositions for capturing multiscale information processing in the brain. We use the following terminology in the rest of the paper (see  ): a) large-scale RSNs (yellow): 25 modes from low-dimensional decomposition; b) \u201cprimary\u201d mPFMs (orange): 25 distributed modes from high-dimensional PFM decomposition that best-match the low-dimensional RSNs; c) \u201csecondary\u201d mPFMs (blue): remaining 125 modes from high-dimensional PFM decomposition. \n\n#### Multiple distinct subcomponents within each conventional RSN \n  \nEach functional mode is typically characterised by two key characteristics: a) the spatial topography across brain voxels (i.e., a spatial map), from which one can derive spatial correlations or overlaps with other modes; b) a timecourse, and the resulting temporal correlations with other modes (i.e., functional connectivity). \n\nThis representation assumes that voxels within a mode are highly correlated with each other, such that they can be summarised with one consensus timecourse. In other words, it assumes that temporal variability across voxels within each RSN\u2019s spatial map is negligible. To determine whether lowD decomposition complies with this assumption, we asked: how many components are needed to explain a majority of variance in the voxel-wise activity within each large-scale RSN? We used Principal Component Analysis (PCA), which projects data onto new orthogonal axes of variation, and allows to identify distinct subcomponents based on the proportion of variance explained (details in  ). We found that ( ) the first Principal Component could only explain up to 53.2% of variance of temporal variability, with the second to fifth Principal Components each explaining ~5\u201310% of variance. \n\nNext, we applied follow-up temporal ICA on data of each mode from lowD decomposition, as detailed in  . Temporal ICA projects data onto statistically independent axes of variations and allow us to identify   temporally independent subcomponents   more interpretably. We restricted the number of subcomponents to 5 per mode; i.e., 5 subcomponents for each of the 25 modes.   shows examples of these subcomponents for the Default Mode and Language Networks. We found that these subcomponents were spatially and temporally distinct, with one subcomponent being spatiotemporally best-represented by the original large-scale decomposition compared with the rest of the subcomponents ( ).   shows the temporal correlation of each of the best-matching subcomponents to the large-scale RSN that they originated from. Interestingly, we found that even the temporal representation of the best-represented subcomponent ranged from Pearson correlation coefficient = 0.22\u00b10.13 to 0.70\u00b10.09 across the 25 large-scale RSNs (i.e., in many cases there is not a strong temporal match). We replicated this finding using two alternative subcomponent identification techniques, spatial ICA and PCA ( ). \n\nThese results provide evidence that voxel-wise temporal variability within large-scale RSNs results in   temporally distinct   subcomponents that are not well-represented by one timecourse, as assigned in conventional RSN decompositions. Instead, multiple subcomponents are needed to explain this voxel-wise temporal variability. \n\n\n#### Temporal subcomponents were best represented by mPFMs \n  \nWe next tested if the 5\u00d725 subcomponents described in the previous subsection were better represented by mPFMs, compared with lowD large-scale RSNs alone. For this purpose, we applied a winner-takes-all approach: the timecourse of each of the subcomponents was correlated with: a) large-scale RSNs; b) primary mPFMs and c) secondary mPFMs. As shown in  , we found that only 12 of the 125 subcomponents were temporally best represented by the large-scale RSNs, 9 of which were significantly higher (Bonferroni-corrected,  ). The remaining 28 and 85 subcomponents were better represented by the primary and secondary mPFMs, respectively (28/28 and 83/85 statistically significant). Therefore, the ensemble of multiscale modes in mPFMs can capture the temporally distinct subcomponents within conventional large-scale RSNs. \n\n\n#### Secondary mPFMs were due to temporal co-activation periods of multiple large-scale RSNs \n  \nResting state networks in the brain might be spatially and temporally correlated. Therefore, it is plausible that the subcomponents that give rise to the secondary mPFMs are either due to spatially overlapping regions or due to distinct temporal co-activation periods of multiple large-scale RSNs. To test this hypothesis, we compared the original subcomponents (described in the previous subsection) with two alternative scenarios: a) temporally-exclusive subcomponents: estimated from each large-scale RSN after the timecourses of the other 24 RSNs were regressed out of its timecourse; b) spatially-exclusive subcomponents: estimated from each large-scale RSN after spatial maps of the other 24 RSNs were regressed out of its spatial map. Conceptual illustrations of these two analyses are included in   and  , respectively. \n\nAs shown in  , we found that a majority of the temporally-exclusive subcomponents (114 out of 125, with109 statistically significant,  ) were temporally best represented by the   lowD decomposition  , unlike the original subcomponents that were best represented by mPFMs. Conversely, as shown in  , the majority of the spatially-exclusive subcomponents (104 out of 125, 100 statistically significant,  ) were instead best represented by primary and secondary mPFMs, i.e., similar to original subcomponents. All results were Bonferroni-corrected for multiple comparisons. \n\nPut together, these analyses suggest that temporal co-activation periods of two or multiple large-scale RSNs from lowD decomposition give rise to new mixed-scale RSNs that are temporally distinct from the existing RSNs. These emerge as secondary mPFMs. In other words, secondary mPFMs are likely due to transient dynamic connectivity between subnetworks of large-scale modes, that are eliminated by temporal averaging (across voxels and/or timepoints) in low-dimensional decompositions. \n\n\n#### Functional connectivity modelling using mPFMs \n  \nHaving examined timecourse modelling in mPFMs, we next investigated the functional connectivity (i.e., temporal correlations) between the modes to compare large-scale RSNs (lowD, d=25) with mPFMs (d=100 and 150). This was done using 4999 subjects in UK Biobank ( ), and separately using 1003 subjects in HCP ( ).  -right shows the histograms of between-subject consistency of functional connectivity. We observed that in both datasets, between-subject consistency was increased with dimensionality. In HCP, this was increased from 0.19\u00b10.09 for d=25 to 0.46\u00b10.06 and 0.59\u00b10.05 for d=100 and 150, respectively. In UK Biobank, this was increased from 0.07\u00b10.07 for d=25 to 0.43\u00b10.13 and 0.70\u00b10.12 for d=100 and 150, respectively. Therefore, mPFMs yielded more consistent functional connectivity values than lowD. Interestingly, subject-specific functional connectivity became sparser for mPFMs ( -left). This sparsity can be understood in light of the previous subcomponent analysis: by attempting to merge the time courses of multiple temporally distinct subcomponents, conventional RSNs can yield spurious connectivity between large-scale modes, which in reality can be due to one or a few of the underlying subcomponents. mPFMs capture the subcomponents using secondary modes, thus reducing such spurious connectivity, and yielding sparser subject-specific functional connectivity. As a result, functional connectivity in mPFMs becomes less contaminated by modelling inaccuracies, and more consistent across individuals. \n\n\n#### Cross-scale interactions of mPFMs predict individualistic traits \n  \nmPFMs can directly characterise the   spatiotemporal correlations between modes across multiple scales of information processing in the brain  . We evaluated the utility of temporal and spatial correlations between mPFMs for out-of-sample prediction of a range of phenotypes in UK Biobank. This was performed using volumetric rfMRI data from 4999 UK Biobank subjects and 893 phenotypes divided into 6 categories: region-wise cortical area (148 phenotypes) and thickness (148), White Matter (WM) tracts\u2019 microstructure (451), task fMRI response to the contrast of emotional faces and shapes ( ), cognition (68) and blood & heart health (77), see   for details of phenotypes, feature extraction and prediction pipeline.  & , show functional and spatial connectivity of large-scale RSNs (d=25) and mPFMs (d=100) for an example subject. As demonstrated in these panels, cross-subject consistency of both functional and spatial connectivity was higher in mPFMs compared with large-scale RSNs. \n\nFirst, we compared the prediction performance of mPFMs with large-scale RSNs, shown in  . We found that spatial connectivity of mPFMs, after matching the number of features as elaborated in Materials and Methods, significantly outperformed (Bonferroni corrected,  ) that of large-scale decomposition in predicting all phenotype categories except cognitive scores. Similarly, functional connectivity of mPFMs significantly outperformed that of large-scale decomposition in predicting region-wise cortical area and task fMRI phenotypes. This shows that subject-specific spatiotemporal correlations between mPFMs carry additional information about each person\u2019s traits that is otherwise missed in large-scale decomposition. \n\nNext, we divided spatiotemporal interactions of mPFMs into three subtypes: i) within primary mPFMs; ii) within secondary mPFMs, and iii) between primary and secondary mPFMs. Aiming to evaluate the added benefit of cross-scale interactions (iii), we compared its prediction performance to within-scale interactions (i.e., i&ii). As shown in  -top, cross-scale spatial connectivity significantly outperformed (Bonferroni corrected,  ) within-secondary for region-wise cortical area and thickness, task fMRI and cognitive phenotype categories, and they additionally outperformed within-primary for all the phenotype categories, except cognitive scores. Cross-scale functional connectivity, as shown in  -bottom, performed on par with or worse than within-secondary, but significantly outperformed (Bonferroni corrected,  ) within-primary for region-wise cortical area, thickness, blood and heart health metrics. \n\nThese results demonstrate that spatial and temporal connectivity of the ensemble of mPFMs yields improved biomarkers for individualistic traits in two ways: first, compared with conventional large-scale RSNs, and second, subject variability captured in spatiotemporal correlations   across   multiple scales is more phenotypically relevant compared with within a single scale. \n\n\n\n### Validation of mPFMs \n  \nOur results so far have focussed on resolving the origins and functional relevance of mPFMs in modelling brain connectivity. Here we set to validate this new decomposition based on simulations, its reproducibility between HCP and UK Biobank datasets and similarity to HCP\u2019s Multimodal Parcellation. \n\n#### Simulations \n  \nBased on real data in   section, we found evidence that secondary mPFMs likely emerge to explain temporally-distinct subcomponents within the conventional large-scale RSNs. In other words, we showed that the ensemble of multiscale modes captures the integrated-segregated functional brain connectivity. Here we simulated datasets, where distributed and localised modes co-existed, such that localised modes were spatial sub-modes of the distributed modes, with distinct timecourses. Using these simulations, we tested how well PFM decomposition can recover the co-existence of multiscale modes, and compared its performance to spatial ICA, which is the current standard technique for RSN modelling. Across 10 simulated datasets, each included 12 modes, 6 distributed and 6 localised.   shows examples of group-average simulated modes in one of the datasets. We compared three elements of the estimated modes with the ground truth: group spatial maps, subject spatial maps, and subject time courses, shown in  ,  ,  , respectively. For the group spatial maps, the accuracy of PFM decomposition for distributed and localised modes was 0.93 and 0.78, respectively, which was reduced to 0.74 and 0.47 in spatial ICA modes. For the subject spatial maps, the accuracy of PFM decomposition for distributed and localised modes was 0.87 and 0.70, respectively, which was nearly halved (0.48 and 0.31) in spatial ICA modes. For the subject timecourses, the accuracy of PFM decomposition for distributed and localised modes was 0.95 and 0.64, respectively, which was reduced to 0.78 and 0.33 in spatial ICA modes. Therefore, at both group and subject level, PFMs can recover the simulated multiscale modes with overall (average) accuracy of ~0.8 or higher. \n\n\n#### Reproducibility across datasets and data formats \n  \nThe next step of validation involved cross-dataset reproducibility tests. We applied sPROFUMO separately to three rfMRI datasets and obtained 150 modes per run: 1) 1003 HCP subjects, volumetric whole-brain rfMRI (HCP VOL); 2) 1003 HCP subjects, CIFTI cortical rfMRI (HCP CORT); 3) 4999 UKB subjects, volumetric whole-brain rfMRI (UKB VOL). All these scenarios yielded mPFMs consisting of primary and secondary modes. We paired these mPFMs across runs based on spatial correlation of group-level spatial maps. \n\nFirstly, by comparing HCP VOL and UKB VOL ( ), we found 100 modes to show very good matching (absolute correlation >= 0.7), 40 modes to show good matching (absolute correlation between 0.5 and 0.7), and 10 modes to show mediocre matching (absolute correlation <= 0.5). Some of the modes in the latter category were due to differences in structured noise across datasets ( ). The top 40 best matching mPFMs across these datasets are shown in  . \n\nSecondly, by comparing HCP VOL and HCP CORT ( ), we found 74 modes to show very good matching (absolute correlation >= 0.7), 28 modes to show good matching (absolute correlation between 0.5 and 0.7), and 48 modes to show mediocre matching (absolute correlation <= 0.5). Some of the modes in the latter category were due to structured noise differences across data-types, and the remainder were due to inherent differences between volumetric and CIFTI fMRI reconstructions. \n\n\n#### Validating secondary mPFMs using HCP\u2019s Multi-Modal Parcellation \n  \nAs the next step, we validated mPFMs based on the HCP\u2019s Multimodal Parcellation v1.0 (HCP_MMP1.0), aiming to validate the secondary mPFMs. We compared mPFMs against the HCP_MMP1.0, which includes 360 cortical parcels. This parcellation includes both group-average and subject-specific parcels, allowing us to validate secondary mPFMs at both levels. We applied sPROFUMO to cortical rfMRI data of 446 HCP subjects (matching the number of subjects in HCP-MMP) and estimated 360 modes. Similar to before, this yielded a multiscale ensemble of modes (i.e., mPFMs). \n\nWe found an interesting group correspondence ( ) between secondary mPFMs and HCP-MMP, especially 95 parcel-like mPFMs showed a strong correspondence to HCP-MMP (dice similarity >=0.5), illustrated in  . 73 mPFMs showed less than 0.2 dice similarity to any HCP-MMP parcels; these included conventional low-dimensional modes and the less well-known variants of distributed modes, and typically occupied multiple distant sub-regions. We further found that modes with high group-level correspondence also showed high subject-level correspondence ( ), with the top 95 matching modes at the group-level also showing correlation of 0.47\u00b10.19 (average \u00b1 standard deviation across subjects and modes) at the subject-level. \n\nThese evaluations add to the previous validation steps, by demonstrating that those of the mPFMs that are parcel-like have clear spatial similarities to the state-of-the-art individualised parcellations, both at the group- and the subject-level. \n\n\n\n### mPFMs yield enhanced biomarkers of personalised traits \n  \nWe have so far investigated the brain properties underlying mPFMs, and their added benefit over conventional large-scale RSNs. Here we focus on the usefulness of individual-specific mPFMs for providing biomarkers for traits and disease. This was done using two steps: 1- population covariations between mPFMs and behavioural traits in HCP; 2- out of sample prediction of phenotypes in UK Biobank. \n\n#### Positive-negative axis of population covariation between mPFMs and behaviour \n  \nWe investigated whether or not mPFMs can capture one of the key findings in brain-behaviour literature: a positive-negative mode of population covariation that links brain connectivity to cognition and lifestyle. This was originally reported by Smith et al., (2015) using HCP data, and has been replicated on other large datasets since ( ). We used Canonical Correlation Analysis (CCA), a method that allows to investigate associations between a set of features from brain data and a set of personalised traits (i.e., phenotypes), all in a single integrated multivariate analysis. Using CCA, we identified modes of population co-variation between brain and phenotypes, as pairs of canonical components along which the phenotypes and mPFMs co-varied in a similar way across subjects. We used the same analysis pipeline as Smith et al., (2015). \n\nTo examine the link between personalised traits and spatiotemporal characteristics of mPFMs, CCA was conducted on features related to spatial maps, spatial and functional connectivity of mPFMs.   shows results of correlation between brain and phenotypes after CCA transformation. As shown in  , we identified the raw behavioural metrics that were most strongly linked to the top CCA components. This was done by correlating the behavioural metrics with the topmost CCA components related to spatial maps, spatial and functional connectivity, and taking the average correlation across the three. This unravelled a single axis of population variation: at one end of this axis, we found behavioural traits positively associated with the prominent CCA component. These included metrics related to cognition and emotion such as performance on language tests, executive function, self-regulation, and life satisfaction. At the other end of this axis, we found behavioural traits negatively associated with the prominent CCA component. These included metrics related to psychiatric disorders and substance use such as rule breaking, antisocial behaviour, alcohol, tobacco and cannabis use. Therefore, this positive-negative mode of population variation significantly links brain function mapping using mPFMs to behaviour, and interpretably places positive traits close to each other and distant from the negative traits, and vice versa. \n\n\n#### Enhanced predictions of personalised traits in UK Biobank \n  \nNext, we evaluated the potential of mPFMs for out-of-sample prediction of traits. For this purpose, we compared mPFMs to two of the most commonly used techniques in the literature: spatial ICA, the current main RSN modelling technique in the core UK Biobank pipeline ( ); and the Schaefer atlas, a high dimensional hard parcellation derived from the Yeo parcellation ( ). For this purpose, we used the 100-dimensional Schaefer parcellation and further applied the other two methods to volumetric rfMRI data of 4999 UK Biobank subjects, estimating 100 mPFMs and 100 ICs. We used features of each functional mode (feature matrix, X) to make predictions about phenotypes (target, y), details in Materials and Methods. We used ElasticNet regression with 5-fold nested cross-validation, and predicted 893 phenotypes divided into 6 categories: region-wise cortical area and thickness (296), White Matter (WM) tracts\u2019 microstructure (451), task fMRI response to the contrast of emotional faces vs shapes ( ), cognition (68) and blood&heart health metrics (77). Results are shown in  , with prediction accuracies of mPFMs shown on the y-axis, and accuracies of spatial ICA modes on the x-axis. We found that mPFMs significantly outperformed (Bonferroni corrected,  ) Schaefer parcellation in prediction of all the phenotype categories, and significantly outperformed spatial ICA in prediction of all the phenotype categories except cognitive traits. \n\n\n\n\n## Discussion \n  \nIn this paper, we presented Multiscale Probabilistic Functional Modes (mPFMs), a new representation of the brain\u2019s functional modes, that improves fMRI modelling and its utility for prediction of cognition and health. mPFMs were identified using stochastic Probabilistic Functional Mode (sPROFUMO) modelling and, unlike any existing representation, include an ensemble of modes across multiple scales. sPROFUMO does not impose or prevent this behaviour by design, instead, it allows the modes to be spatiotemporally correlated, and accumulate Bayesian evidence across individuals in large populations. Therefore, if a multiscale organisation arises from the results, this is driven by the structure in the data. Indeed, as demonstrated in the   section, the presence of multiple distinct subcomponents within each large-scale (distributed) mode indicates spatiotemporal multiplicity within these modes, which cannot be captured by distributed-only or localised-only representations. Put together, our results demonstrate mPFMs\u2019 potential to provide a useful representation of multiscale information processing in the brain, and enhance fMRI-derived biomarkers for traits and disease. We release this representation publicly; we have made the group-level maps openly available, whereas subject-level maps will be released in the future as part of ongoing work to rebuild a \u201cv2\u201d UKB pipeline ( ). \n\nMultiscale modes are compatible with the notion of hierarchal information processing in the brain; that brain function is organised in a hierarchical manner, with each level of the hierarchy underlying increasingly complex and abstract processing( ,  \u2013 ). Hierarchical processing is enabled via interactions between local unimodal information processing and distributed higher level cognitive function. Such interactions have been well-established, e.g., in visual search tasks, where interactions between sub-regions of the visual cortex and fronto-parietal attention networks allows for top-down modulation of visual processing by attention, as well as bottom-up modulation of attention by the incoming stimulus ( ,  ). Interactions between brain systems at different levels of these hierarchies cannot be directly modelled using existing functional mode representations, considering that they can either be used to measure interactions between distributed modes (lowD decompositions) or localised regions (highD parcellations). As a result, the interactions   between   these two layers will have to be modelled using post-hoc techniques, such as hierarchical clustering ( ) or module detection ( ). Even then, the resulting connectivity will depend on the assumptions of the post-hoc techniques, and change depending on the choice of parameters, rather than being integrated within the original brain function mapping. In contrast, mPFM inherently incorporates such multiscale connectivity within fMRI decomposition. Crucially, as we demonstrated in the  , these interactions provide stronger biomarkers of cognition and health compared with connectivity within large-scale or within localised modes alone. \n\nAdditionally, by allowing the modes to be spatially overlapping, mPFMs can capture functional multiplicity in the brain\u2019s organisation, where a single region contributes to different functions depending on the context. Until recently, spatially overlapping functional modes have been largely absent from resting state literature. Specifically, studies have commonly relied on either spatial ICA ( ,  ), that imposes spatial independence between the modes, or hard parcellations, that enforce rigid boundaries between the modes ( ,  ). Therefore, the literature has relied on spatial bases that minimise or prevent spatial overlap. However, growing evidence is now highlighting the importance of spatial overlap in modelling cross-individual variability in brain function ( ). Importantly, recent successful characterisation of brain connectivity using gradients or connectopy mapping ( ,  ) has brought functional multiplicity to the fore of resting state connectivity. These techniques have unravelled multiple overlapping connectivity patterns within brain regions, e.g., retinotopic organisation of the visual cortex, and follow-up studies have highlighted the cognitive and clinical relevance of these overlapping connectopy maps. As such, allowing for spatial overlap, in addition to and not instead of temporal correlations between the modes, is proving imperative for obtaining a more comprehensive representation of brain function. mPFMs are, on the one hand, similar to conventional spatial ICA modes, in that they capture large-scale prominent networks in the brain. One the other hand, mPFMs additionally allow multiple overlapping subcomponents within these networks to co-exist. As such, mPFMs can be viewed as a new category of brain function mapping that stands somewhere in-between conventional RSNs and the more recent gradients of connectivity. \n\nIn addition to their functional relevance, mPFMs also provided enhanced biomarkers for prediction of individualistic traits in UK Biobank. To benchmark of mPFMs against standard ICA-based or hard parcellation techniques, we used a range of imaging-derived and non-imaging derived phenotypes such as cortical geometry, white matter microstructure, brain response to cognitive tasks, behavioural cognitive scores, and health outcome related to blood and heart. The overall prediction accuracies of mPFMs were found to be significantly higher than standard techniques for various phenotype categories. One key reason for this higher prediction accuracy is likely the more comprehensive spatiotemporal feature set in mPFMs. On the one hand, hard parcellations yield binary spatial maps for each mode/parcel, and no spatial overlaps between the modes, thus summarising individual-specific brain features solely in temporal space. Somewhat similarly, Spatial ICA, due to its assumption of spatial independence between the modes, minimises spatial overlap by design ( ,  ,  ). Consequently, both approaches yield singlescale decompositions of functional modes. Therefore, large-scale modes, and their spatiotemporal correlation with each other and with localised modes, cannot be fully characterised by the standard techniques. Therefore, mPFMs yield a richer set of spatial and temporal features that, even after matching the number of features between the methods, can outperform the standard techniques in reflecting individualistic traits in brain function. \n\n\n## Materials and Methods \n  \n### Data \n  \n#### Human Connectome Project (HCP) \n  \nWe used minimally pre-processed fMRI data from Human Connectome Project (HCP) from S1200 data release ( ), with acquisition and processing details outlined in ( ,  ). Resting state data from 1003 subjects aged 22\u201335 years were used here and included 4\u00d715 minute runs per subject (i.e., 1 hour recording per subject). With repetition time (TR) of 0.72s, this dataset includes 4800 time points per individual. We used two data formats, volumetric and HCP CIFTI. CIFTI data includes grey matter voxels only (i.e., greyordinates), where cortical grey matter is surface-registered using MSMAll ( ) and subcortical grey matter is in volumetric space. This results in inherent data differences such as signal to noise ratio between cortical and subcortical regions, affecting matrix factorisation techniques in, e.g., finding an unbalanced number of cortical vs subcortical modes. To prevent such unbalances and make the results more easily comparable across CIFTI and Volumetric fMRI, we only used cortical greyordinates of CIFTI in this paper. ICA-FIX was used to remove artefacts from volumetric data before resampling to 32k_fs_LR space and projecting onto the surface. Standard HCP preprocessing includes spatial smoothing with a 2mm FWHM smoothing kernel. We applied additional smoothing to obtain 5mm FWHM (for both volumetric and CIFTI data), which improves SNR and was found to be useful for obtaining reliable subject-specific modes ( ). \n\nHCP data were predominantly used for analyses that aimed at examining timecourse and functional connectivity modelling using mPFMs, their reproducibility across datasets (HCP and UK Biobank), and validation of mPFMs against existing functional parcellations. Given the longer recordings per subject (1 hour vs 6 minutes), we deemed HCP more suitable for these analyses. \n\n\n#### UK Biobank (UKB) \n  \nWe randomly selected 4999 subjects aged > 45 years from the May 2019 release of UK Biobank data (application number 8107). Resting state fMRI data in UKB (at the time that this research was conducted) was in standard volumetric space, and included 1 recording of ~6 minute per subject. With a TR of 0.735s, data consisted of 490 time points per session. The standard UKB pipeline, which includes quality control, brain extraction, motion correction, artefact rejection using FSL-FIX, high-pass temporal filtering (sigma = 50.0s, Gaussian-weighted least-squares straight line fitting) and registration to standard MNI-2mm space was used for preprocessing ( ). Standard UKB preprocessing includes spatial smoothing with a 2mm FWHM smoothing kernel. We applied additional smoothing to obtain 5mm FWHM, which improves SNR and is useful for obtaining reliable subject-specific high dimensional PFMs. UKB was used for evaluating reproducibility of mPFMs (i.e. high-dimensional PFMs) across datasets, and their prediction accuracy for personalised traits. Given the wide range of imaging derived phenotypes (IDPs) and non-imaging derived phenotypes (nIDPs) in UK Biobank, this dataset was deemed more suitable for prediction of traits (see \u201c \u201d section for details). \n\n\n\n### Estimating Resting State Networks \n  \n#### Probabilistic Functional Modes (PFMs) \n  \nDetails of PROFUMO/sPROFUMO models and inference are elaborated in our previous work ( ,  ). Here we provide a brief summary of the model and its application to the data. sPROFUMO is a matrix factorisation model for big fMRI data, which uses hierarchical Bayes with two levels of modelling and inference: population and individual. \n\nAt the subject level, fMRI timeseries   are decomposed into a set of spatial maps  , time courses   and time course amplitudes  , with residuals  :\n \nwhere s denotes subject, r denotes a recording session and   denotes mode amplitudes.  ,   and   denote the number of voxels, modes and time points, respectively. \n\n denotes spatial mode layout across brain voxels, hereafter referred to as   spatial maps  , or just   maps  . These are modelled using a Double-Gaussian Mixture Model (DGMM), with one Gaussian component used to model signal and a second Gaussian distribution to model the background spatial noise in each voxel. To model the spatial maps hierarchically, in addition to   for each subject, a consensus set of group-level parameters is also estimated to capture both the group mean and variance.   represents mode time courses per subject and scan. The time courses also model signal and noise elements separately, where the signal element is HRF-constrained and the noise element follows a Gaussian distribution. Connectivity between the timecourses of functional modes can have a consensus structure across individuals. To model this simultaneously for population and individuals, a second hierarchy is defined over the precision matrix   using Wishart distributions. To further allow for modelling of haemodynamic responses that govern the BOLD signal, HRF-constrained autocorrelations are incorporated in the modelling of this functional connectivity between the modes.   denotes mode amplitudes. These are modelled using a multivariate normal distribution, with a Bayesian hierarchy between the group and the subject levels.   is diagonal (one value per PFM) and captures timecourse variance for each subject and recording. \n\nTo find a solution for the probabilistic model described above, sPROFUMO uses stochastic Variational Bayesian (VB) inference. This includes dividing subjects from large data into small batches, and optimising the parameters of an approximating distribution  , with the aim that it is as close as possible to the true posterior. The group model is maintained across batches and continuously updated over time, and within each iteration of each batch, it is used for top-down regularisation of subject-specific matrix factorisations, from which the posterior distributions for subject-specific spatial maps, time course correlations and amplitudes are inferred. Subsequently, posterior distributions are accumulated across individuals and fed back to the group to update the group model. The model iterates between these two levels of estimation until convergence. We used the model\u2019s default parameters for application to both HCP and UKB datasets. The forget rate   was set to 0.6; this controls the degree to which global parameter updates rely on the current compared with previous batches. Delay parameter   was set to 5; this controls the degree to which initial batches influence the overall inference. Batch size was set to 50 subjects, and the number of batches was tuned such that each subject will be visited 2.5 times on average (i.e., normally chosen in 2 to 3 batches). The overall group model was set to be updated at least 5000 times for UKB and 4000 times for HCP. \n\nWhen applying to each dataset, and as a part of sPROFUMO\u2019s internal initialisation, voxel-wise de-meaning and variance normalisation was applied to rfMRI recordings. Additionally, to initialise the model using a realistic set of initial group maps that can place the parameters within a realistic ballpark, sPROFUMO internally applies an online PCA algorithm called MELODIC\u2019s Incremental Group-PCA (MIGP) ( ) followed by variational ICA. These initial maps, together with hyperpriors, are used to initialise the group-level parameters before conducting the full Bayesian inference at subject- and group-level. It is worth noting that, to make the results fully comparable across HCP and UKB, the same set of initial maps were used to initialise both datasets. We estimated 25, 50, 100, and 150 PFMs, each used in a subset of the analyses, as elaborated in   section. \n\n##### Volumetric vs CIFTI PFMs: \n  \nsPROFUMO was applied to volumetric and CIFTI data from HCP separately, and group-level spatial maps were used as the basis for computing the reproducibility scores reported in   section \u201c \u201d. In order to compare volumetric and CIFTI results, volumetric PFMs were mapped onto CIFTI using linear regression at the subject level. More specifically, for each subject and run, we used volumetric PFM timeseries   and amplitudes  , as well as raw CIFTI fMRI timeseries  . We computed spatial maps in CIFTI space   through back projection of   onto   using linear regression with L2 regularisation. Regression betas were then converted to t-stat values. We next averaged   across subjects and obtained volume-to-surface mapped group spatial maps to compare against surface based spatial maps. \n\n\n\n#### Spatial ICA and Dual Regression \n  \nWe applied the widely-used group level spatial ICA followed by dual regression (DR) to characterise subject-specific RSNs and compare against sPROFUMO results. In standard pipelines of large datasets such as HCP and UKB, ICA/ICA-DR have been used for RSN characterisation, thus providing a suitable baseline to compare sPROFUMO results against. We applied ICA to UKB data and identified 100 group-level spatial components using FSL   MELODIC,   and subsequently mapped these group-level results onto single subject data using FSL   dual_regression  . Subject-specific time courses for each mode and subject-specific spatial maps we obtained from stages 1 and 2 of Dual Regression, respectively. Mode amplitudes were computed as standard deviation of the time courses and functional connectivity was computed using Tikhonov/L2-regularised partial correlations. In order to make the final sPROFUMO and ICA/ICA-DR results fully comparable, the same PCA initialisation (using the MIGP approach) was used for both models. ICA-DR results were used to predict non-imaging phenotypes and compare PFM\u2019s performance against. \n\n\n\n### Identifying temporally distinct subcomponents within large-scale RSNs \n  \nLow-dimensional representation of functional modes yields large-scale RSNs that are distributed across multiple brain areas. Matrix factorisation techniques (e.g. sPROFUMO or ICA) describe each of these modes with a single timecourse. We tested if there are distinct temporal subcomponents within each of these modes, and whether or not these subcomponents will be better represented by lowD large-scale RSNs vs highD mPFMs. For this purpose, we focused on 25-mode decomposition from HCP CIFTI rfMRI data of 1003 subjects (see \u201c \u201d section), and conducted the following tests:\n   \nThis first step aimed to test whether a single prominent subcomponent can explain a majority of   group-level   temporal variance in the voxel-wise activity within each large-scale mode. For this purpose, we used PCA as follows:\n   \n subject rfMRI timeseries were weighted by each subject PFM (d=25) spatial map, obtaining   weighted rfMRI timeseries (the data dimensions are unchanged, but voxels within a given map are up-weighted); \n  \nPCA was applied to each of these weighted timeseries and 10 components were estimated per subject per mode. The resulting PCA maps were concatenated across subjects (per mode), a second group-level PCA was applied and 10 group-level components were extracted per mode. The explained variance per PC was estimated (by considering the 10 singular values), results of this analysis are reported in \u201c \u201d section. \n  \n  \nThis second step aimed to test whether multiple temporally distinct subcomponents exist within each large-scale RSN (i.e., distributed only), and whether subcomponents originating from large-scale RSNs can be better represented by large-scale (lowD) vs multiscale (highD) PFMs. This was done using temporal ICA, and further replicated using spatial ICA and PCA. Steps 2\u20134 were focused on   single-subject   modes.\n   \nSimilar to step 1,   subject rfMRI timeseries were weighted by each subject PFM (d=25) spatial map, and 5 spatial PCs were extracted per mode per subject. The choice of 5 PCs was determined based on results of step 1, where PCs >6 were found to explain less than 3% of variance for all the PFMs ( ). \n  \nFor each PFM the 5 PC maps were concatenated across subjects and group-level PCA was used to extract 5 spatial subcomponents per PFM. \n  \nThese group-level PCs were then linearly regressed onto each subject\u2019s PFM-weighted rfMRI timeseries (as described in step 2a), giving 5 temporal components per subject per mode, which were then concatenated across subjects to obtain 5 long timeseries per PFM. \n  \nTemporal ICA was applied to the resulting long timeseries to obtain timeseries for 5 temporally-independent subcomponents. These timeseries were split up into temporal chunks to obtain subject-specific tICA subcomponent timeseries. \n  \nSubject-specific tICA subcomponent timeseries were linearly regressed onto each subject\u2019s PFM-weighted rfMRI timeseries (as described in step 2a) to obtain subject-specific tICA subcomponent spatial maps. \n  \nBy correlating the subject-specific timecourses of each subcomponent with all the original lowD and highD mode timeseries, we applied a winner-takes-all approach to determine how many of the subcomponents originating from large-scale lowD modes were best-represented by lowD vs primary vs secondary mPFMs. An unpaired t-test was used to conduct statistical comparisons, and results were Bonferroni-corrected for multiple comparisons. \n  \n  \nThis third step aimed to test whether subcomponents identified in step 2 were exclusive to one lowD mode, or if they resided in the   temporal space   shared by multiple lowD modes:\n   \nSimilar to step 2a,   subject fMRI timeseries were weighted by each subject PFM (d=25) spatial map, obtaining 25 weighted fMRI datasets per subject. \n  \nLinear regression was used to regress out the timecourses of every other ( ) PFM from each PFM\u2019s weighted fMRI. Then 5 PCs were extracted per mode per subject. \n  \nSteps 2b-f were repeated to test if subcomponents originating from the temporally-exclusive space of lowD modes were best-represented by lowD vs primary vs secondary mPFMs. \n  \n  \nThis fourth step aimed to test whether subcomponents identified in step 2 were exclusive to a single lowD mode, or if they resided in the   spatial   space shared by multiple lowD PFMs:\n   \nLinear regression was used to regress out the spatial maps of every other ( ) PFM from each PFM\u2019s spatial map. \n  \n subject fMRI timeseries were weighted by the resulting subject PFM (d=25) spatial map after regression, obtaining 25 weighted fMRI datasets per subject. \n  \nLinear regression was used to regress the spatial maps of every other ( ) PFM from each PFM\u2019s weighted fMRI. Then 5 PCs were extracted per mode per subject. \n  \nSteps 2b-f were repeated to test if subcomponents originating from the spatially-exclusive (non-overlapping) space occupied by lowD modes were best-represented by lowD vs primary vs secondary mPFMs. \n  \n  \n\n\n### Simulations \n  \nBased on real data (Methods section \u201c \u201d and   section \u201c \u201d), we found that Secondary mPFMs were likely due to existence of temporally-distinct subcomponents within the Primary mPFMs, i.e., the ensemble would capture integrated-segregated modes of brain connectivity. Here we simulated datasets where overlapping distributed and localised RSNs exist in the brain, such that localised RSNs are spatial sub-nodes of distributed RSNs but have distinct timecourses. Using these simulations, we tested how well PFM decomposition can recover the co-existence of global-local RSNs in the brain, and compared its performance to spatial ICA as the standard technique. Details of simulations were as follows:\n   \nData: 10 resting state fMRI datasets were simulated, each consisting of 50 subjects and 2 runs per subject. \n  \n12 resting state modes were simulated in each dataset, and they were created from scratch in each dataset. \n  \n6 of these modes were distributed, covering >=2 brain areas, 6 of these modes were localised, covering 1 brain area. Distributed modes were allowed to spatially overlap with each other, such that on average, 1.3 modes included a given voxel. \n  \nLocalised modes were simulated such that they were primarily a spatial sub-node of one distributed mode, while spatially overlapping with two or multiple distributed modes. \n  \nData properties per subject and run: 10,000 voxels, 300 time points at a TR of 0.72s. Data was created as detailed below: \n  \n\nWe defined a set of spatial maps   at the group level. Each mode consisted of one or more randomly-selected contiguous blocks of voxels (i.e., parcels). Signal weights (per voxel per mode) were drawn from a Gamma distribution. Subject-specific spatial maps,  , were defined based on the group maps by adding background Gaussian noise and applying spatial warps. Subject maps were generated to be spatially misaligned in reference to the group, with any a given subject mode having on average 83% overlap with the group-average (i.e., 17% spatial misalignment). Time courses were generated independently for each session, subject and mode to mimic the unconstrained resting state data (but following the between-mode temporal correlation structure described next). We assigned a hierarchical link between the group and subjects\u2019 temporal correlation matrices, following a Wishart distribution. This was done to obtain a consistent functional connectivity pattern between subjects and the group. Time courses were initially simulated as semi-Gaussian neural time courses with amplified frequencies < 0.1Hz, and subsequently convolved with a random draw from the FLOBS haemodynamic basis functions( ) to mimic realistic BOLD signal. Finally, data were created using outer product of subject mode spatial maps and timecourses, and random noise was added to the outer product to create spacetime data matrices. More details of simulation parameters are available in( ). \n\nThese simulated modes were then estimated using PFM decomposition and ICA-Dual Regression, and results were compared with the ground truth. We initialised both models based on the same set of spatial bases from MIGP, to ensure that the observed differences were not due to initialisation of the probabilistic models. \n\n\n### mPFMs vs HCP-MMP \n  \nWe applied sPROFUMO to cortical rfMRI data of 446 HCP subjects (matching the number of subjects for which HCP-MMP was available) and estimated 360 PFMs. The two decompositions were compared at two levels: First, we computed group correspondence ( & ) between mPFMs and HCP-MMP. We binarised group-level mPFMs\u2019 spatial maps by hard thresholding at 0.3 and computed their dice similarity to group-level parcels in HCP-MMP. The modes were paired based on group-level matching, and this ordering was used in the subsequent analyses presented below. Second, we examined subject-level correspondence ( ) by binarising subject-level mPFMs\u2019 spatial maps by hard thresholding, and finding dice similarity between binarised mPFMs and subject-level parcels in HCP-MMP. The same mode ordering as the group-level was used here in visualisation. \n\n\n### Out-of-sample prediction pipeline \n  \nWe investigated the link between the spatial/temporal properties of mPFMs and a range of phenotypes in UKB and HCP. This was done using out-of-sample predictions in UKB and Canonical Correlation Analysis (CCA) in HCP. These accuracies were used to compare mPFMs vs conventional large-scale RSNs, primary vs secondary mPFMs, and mPFMs vs spatial ICA and Schaefer parcellation of same dimensionality. Depending on the question at hand in each subsection, we conducted predictions based on all or some of the following features: a) Mode spatial maps, b) Mode temporal network matrices (TNETs or temporal NetMats; partial correlation matrix between mode timecourses), c) Mode spatial NetMats (SNETS, the full spatial correlation matrix between mode maps). \n\n#### Imaging and non-imaging derived phenotypes (IDPs and nIDPs) \n  \nWe used 893 Imaging-derived and non-Imaging-Derived phenotypes (IDPs and nIDPs) from UK Biobank as targets in the prediction pipeline. These included IDPs related to Grey Matter, White Matter and task fMRI, as well as nIDPs related to cognitive scores and blood and heart health metrics. A brief summary of these phenotypes is included in this subsection, and a full list is included in  \u2013 . \n\n##### Grey Matter: \n  \n148 IDPs related to GM area and 148 IDPs related to GM thickness, generated with Freesurfer by parcellation of the white surface using Destrieux (a2009s) parcellation. More details about these IDPs (e.g. histograms) can be found on the UKB website:  . \n\n\n##### White matter: \n  \n3 IDPs extracted based on the volume of white matter hyperintensities using BIANCA. 162 IDPs extracted based on mean intensity for dtifit outputs (FA, MD, MO3) and NODDI outputs (ICVF, OD, ISOVF) for the 27 tracts segmented with the probabilistic tractography analysis. 288 IDPs extracted based on mean intensity for dtifit outputs (FA, MD, MO) and NODDI outputs (ICVF, OD, ISOVF) for the 48 tracts segmented with the TBSS-like analysis. \n\n\n##### Task fMRI: \n  \nUKB includes data for one task, which involves brain responses to images of emotionally-valenced faces and shapes. 1 IDP, called \u2018contrast\u2019 in the   section, was estimated as 90th percentile (z-statistic) of activity for response to faces vs shapes ( ). \n\n\n##### Cognitive: \n  \nStarting from 1172 nIDPs related to cognitive tests, we narrowed these down to 68 using two criteria. Firstly, one of the authors prefiltered the outcome measures manually, by only including active measures that were indicative of subject\u2019s performance. For example, among outputs directly related to \u201cReaction Time\u201d, which entails viewing two cards (A and B) and pressing buttons when identical, \u201cMean time to correctly identify matches\u201d, was included whereas \u201cIndex for card A in round\u201d was excluded. Secondly, we only selected tests that had a non-NaN value in at least 25% of the subjects. The final list of 68 tests belonged to the following categories:   Reaction time, Trail making, Matrix pattern completion, Numeric memory, Prospective memory, Pairs matching, Symbol digit substitution   and   Fluid intelligence  . More details about these nIDPs are available here:  . \n\n\n##### Blood and Heart related metrics: \n  \nStarting from 992 nIDPs related to blood and heart related health, we narrowed these down to 77 using two criteria. Firstly, one of the authors prefiltered the outcome measures manually, by excluding metrics that were not directly related to health. For example, \u201cLV stroke volume (2.0)\u201d and \u201cSystolic blood pressure, manual reading (0.0)\u201d were included whereas \u201cCompletion status of test (0.0)\u201d and \u201cProgram category (0.0)\u201d were excluded. Secondly, we only selected tests that had a non-NaN value in at least 25% of the subjects. More details about these nIDPs are available in the following links:  ,   and  \n\n\n\n#### Confound Removal in UK Biobank \n  \nWhen conducting brain-behaviour analyses in big data, e.g., association or out-of-sample predictions, imaging confounds can significantly distort the interpretability of the results ( ,  ). For example, if a common confounding factor such as head size or head motion is correlated with both brain features and behavioural targets, this is likely to inflate our prediction accuracies ( ). Therefore, we opted to de-confound the data before conducting any brain-behaviour analyses. This was done by linearly regressing out the confounds from both imaging and non-imaging variables. \n\nFor UK Biobank, we started with a comprehensive set of 602 confounds proposed by Alfaro-Almagro et al. (2020). We reduced this set by: a) selecting conventional confounds including age, age squared, sex, age \u00d7 sex, site, head size and head motion; b) reducing the remaining confounds using Principal Component Analysis. The top PCs that explained >85% of the variance were kept. These two steps yielded 82 variables. Importantly, we applied deconfounding taking into account cross-validation folds in order to avoid leakage of information from test to train data, as proposed by ( ). \n\n\n#### Elastic-Net prediction and cross-validation \n  \nWe used Python 3.6.5 and scikit-learn 0.19.1 ( ) to set up the prediction pipeline. We used ElasticNet regression and nested 5-fold cross validations to conduct out-of-sample predictions, with 20/80 test/train ratio. Next, we Gaussianised each predictor and target variable across subjects using quantile transformation (  QuantileTransformer  ). In each cross-validation loop, the training set was used to compute the quantile transforms which were then applied to both train and test data. Similarly, deconfounding was also conducted within each cross-validation loop, where training set was used to estimate the regression parameters (or \u201cbetas\u201d), which were then applied to de-confound both train and test data. Finally, we used   ElasticNetCV   to predict target variables in the test set. Hyperparameters related to ElasticNet; i.e., ratio of Lasso to Lasso+Ridge regularisation (  L1 ratio   varied between [0.1,0.5,0.7,0.9,0.95,0.99,1.0] with 10 alphas per   L1 ratio  ) we optimised using nested cross-validations within the training set. Finally, we computed correlations between estimated and actual values of the target variables across subjects in the test set, which will be reported as prediction accuracies. \n\n\n#### Feature spaces: Large-scale vs multiscale PFMs \n  \nThe comparison between conventional large-scale RSNs and mPFMs aimed to determine any added benefit of the latter, and additionally to determine the added benefit of having both types of primary and secondary modes in a decomposition, as opposed to one type only. For this purpose, we focussed on interactions between the modes, i.e., spatial/temporal correlations, and their prediction power for phenotypes in UKB. Specifically, the comparison was made between prediction power of correlations in three scenarios: large-scale RSNs vs mPFMs; between primary and secondary mPFMs vs within primary mPFMs; between primary and secondary mPFMs vs within secondary mPFMs. \n\nTo summarise mode interactions, two types of feature matrices were used, Spatial NetMats (SNETs) and partial temporal NetMats (TNETs). TNETs were computed based on precision matrices and with a Tikhonov regularisation parameter 0.01. SNETs and TNETs are of size   for each subject in each PFM decomposition. \n\nBased on highD decomposition (d=100), we divided each of the NetMats into three sub-matrices\n   \n and  , with  \n  \n and  , with  \n  \n and  \n  \nBased on large-scale lowD decomposition  , we obtained   and  \n  \n\nWe applied the Fisher r-to-Z transformation, and unwrapped these matrices into 1D vectors. Since Pri2Pri, Sec2Sec and LowD2LowD matrices (but not Pri2Sec) are symmetric, only the upper diagonal elements were kept before unwrapping. Next, we used SVD to dimension-reduce each of these eight   matrices to feature matrices of size  , which were fed into ElasticNet. The dimensionality reduction was done to obtain the same number of features to use in predictions, reducing the possibility of one mode type outperforming due to the number of features. Five-fold cross-validations were performed and accuracies computed as detailed in Section \u201c \u201d. Cross-validations were repeated k times for each phenotype category, k being: GM: 20, WM: 20, task fMRI-condition: 200 (since there is only 1 phenotype in this category), task fMRI-contrast: 200, cognitive: 20, blood and heart metrics: 20. \n\nFor each IDP/nIDP category, accuracies were computed for each phenotype, and pooled across the number of phenotypes in that category (N ) and number of repeats (k), yielding two vectors of size k* N  to be compared between different mode types. \n\n\n#### Feature spaces: mPFMs vs standard techniques: \n  \n##### mPFMs and spatial ICA features: \n  \nThe comparison of mPFMs to highD ICA aimed to examine any added benefit of mPFMs over state-of-the-art RSN decompositions for capturing individualistic traits and phenotype predictions. For this purpose, three types of feature matrices were used in predictions, spatial maps (SMAPs), SNETs, and TNETs. HighD decompositions with 100 RSNs from UKB data were used in these analyses. This dimensionality was optimised based on a left-out phenotype (age): we compared age prediction using 50, 100, 150, and 200 dimensional decompositions and found 100 to be optimal. Feature spaces were estimated using a pipeline similar to the Uni-mode predictions described in our previous study ( ):\n   \nFor SMAPs, estimating 100 modes resulted in a matrix of  . We performed dimensionality reduction across the second dimension (per mode) using sparse dictionary learning ( ) and obtained feature matrix of size  . Next, we used the feature space of each PFM separately in phenotype predictions. \n  \nFor SNETs and TNETs, we started with matrices of size  . After applying the Fisher r-to-Z transformation per subject, we used rows of correlation matrices (i.e., one per mode) for each subject without additional dimensionality reduction, thus obtaining 100 feature matrices of size   from SNETs and 100 feature matrices of size   from TNETs that were used separately for predictions. TNETs were computed using partial correlations with Tikhonov regularisation. \n  \n\n\n##### Schaefer Parcellation features: \n  \nThe standard Schaefer parcellation in MNI space, Schaefer2018_100Parcels_17Networks_order_FSLMNI152_2mm.nii.gz, from   was applied to pre-processed fMRI timeseries of UK Biobank subjects; timecourses of voxels within each parcel were averaged to obtain one timecourse per parcel/mode. Subsequently, similar to the PFM/sICA procedure explained above, TNET features were computed from these timecourses using Fisher r-to-Z transformed partial correlations with Tikhonov regularisation. These resulted in 100 feature matrices of size   which were used in uni-mode predictions. \n\n\n##### Summary of features from mPFM/sICA/Schaefer: \n  \nWe used features of each mode separately in predictions. \n\nOn the one hand, for PFM and sICA, SMAP, SNET and TNET feature matrices were concatenated horizontally, yielding 100 features matrices of size   to use in cross-validated ElasticNet predictions, as elaborated in \u201c \u201d Section. Accuracies were computed for each mode and pooled across modes to compare PFMs and ICA-DR. \n\nOn the other hand, mPFMs and spatial ICA both yield spatial and temporal features, whereas hard parcellations such as Schaefer generate TNET features only. This is due to the fact that hard parcellations yield binarised spatial topographies for the modes/parcels, with fixed hard boundaries between the parcels. Therefore, the number of features derived from the Schaefer parcellation will be lower. To balance this number across the three methods, we used cross-validated feature selection based on correlation to the target in the training set to select a subset of features from mPFM/sICA, matching the number of features (99 per mode) from the Schaefer parcellation. \n\nFor each phenotype category (e.g., blood, cognitive etc.), accuracies were computed for each mode and each phenotype, and pooled across the number of phenotypes in that category   and number of modes (100), yielding three vectors of length   to compare mPFMs with ICA-DR and the Schaefer Parcellation. \n\n\n\n\n### Canonical Correlation Analysis \n  \nCanonical Correlation Analysis (CCA) was used to find a single multivariate mapping between a set of PFM features and a set of non-imaging variables. Each CCA component estimates a linear combination of PFM features and a linear combination of phenotypes, such that the transformed outputs are maximally correlated. In order words, CCA components project data onto common axes of subject variability that co-vary between brain and behaviour. In previous studies of rfMRI functional connectivity using spatial ICA, CCA has identified a positive-negative axis of brain-behaviour associations in HCP data ( ). Here, using HCP and focussing on the same set of phenotypes, we conduced CCA aiming to examine the behavioural relevance of mPFMs in the context of existing literature. 1001 out of 1003 subjects that were included in both fMRI and phenotype recordings were included in this analysis. \n\n#### Non-imaging Phenotypes \n  \nWe used 158 phenotypes for the CCA. These were sub-selected from a wider range of phenotypes using a set of criteria described in( ), and included metrics related to cognition such as various measures of fluid intelligence, executive function, language, episodic memory, working memory, attention; metrics of emotion such as life satisfaction, friendship, loneliness; metrics of psychiatric and life function such as depression, anxiety, aggression; metrics of alertness related to sleep, five metrics of personality related to agreeableness, extraversion, neuroticism, conscientiousness and openness, metrics of physical health related to sensory-motor function, and lifestyle metrics related to substance use such as alcohol, tobacco and drug. A full list of these phenotypes is presented in  . \n\n\n#### Confound Removal in HCP \n  \nSimilar to \u201c \u201d Section , we de-confounded both feature and phenotype matrices before conducting CCA. For this purpose, we used 13 imaging confounds that are included regularly in HCP studies: acquisition reconstruction software version; age; age squared; sex; age \u00d7 sex; sex \u00d7 age squared; race, ethnicity; height; weight; a summary statistic quantifying average subject head motion during the resting-state fMRI acquisitions; the cube-root of total brain volume (including ventricles), as estimated by FreeSurfer; the cube-root of total intracranial volume, as estimated by FreeSurfer. \n\n\n#### mPFMs feature spaces \n  \nFor CCA, we need a single feature matrix of size   estimated from brain imaging to be paired with a single phenotype matrix of size   from behavioural/non-imaging traits. Therefore, we required a further condensed feature space compared to what described earlier in trait prediction. We extracted feature summaries separately from SMAPs, SNETs, and TNETs, and ran CCA using each feature type independently. Feature summaries were created as follows:\n   \nFor the spatial maps (SMAPs), estimating 150 modes resulted in a   matrix of   , yielding ~35 million features per subject. To extract a few hundred features that can meaningfully capture the essence of subject SMAPs, we used unsupervised learning by applying FMRIB\u2019s Linked ICA for big data (BigFLICA)( ,  ). This is an ICA framework originally proposed for multimodal data fusion, and was applied here in two steps. First, subject SMAPs were dimension-reduced across voxels using sparse dictionary learning, yielding a matrix of size  . Next, each PFM was used as a separate \u201cmodality\u201d within bigFLICA to obtain a feature matrix of size  . Using FLICA here allows us to preserve subject-specific variations in each mPFM and efficiently summarise them across numerous modes to obtain a set of independent features to characterise the sources of population variations in mPFMs. \n  \nFor the spatial and partial temporal correlation matrices (SNET, TNET), we started with matrices of size   for each subject. After applying the Fisher r-to-Z transformation, we flattened these matrices by taking the above-diagonal elements. With 150 PFMs, this resulted in two feature matrices, one for SNET another for TNET, each of size  . \n  \n\nEach of these three matrices were used separately in CCA estimation, and results were combined post-hoc, as elaborated in the next subsection. \n\n\n#### Conducting CCA \n  \nCCA analysis consisted of the following steps:\n   \nOne side of CCA received mPFM feature matrices as input: SMAPs:  ; SNETs:  ; TNETs:  . Preprocessing steps similar to( ) were applied to these matrices, which included normalisation and dimensionality reduction using SVD. Each feature matrix was reduced to a matrix of size 1001 \u00d7 50. The dimension reduction helps to avoid an over-determined (rank deficient) CCA solution. \n  \nThe other side of CCA received phenotype matrices as input: 1001 \u00d7 158. Preprocessing steps similar to ( ) were applied to these matrices, which included inverse Gaussian transformation and dimensionality reduction using SVD. The phenotype matrix was reduced to a matrix of size 1001 \u00d7 50. \n  \nImaging confounds were regressed out of both phenotype and PFM feature matrices, as elaborated in \u201c \u201d Section. \n  \nCCA was conducted for three pair-wise comparisons: 1) PFM SMAP vs phenotypes; 2) PFM SNET vs phenotypes; 3) PFM TNET vs phenotypes. This was done using the \u2018canoncorr\u2019 function in Matlab. \n  \nCCA yields a linear transformation of PFM feature matrix (X) and phenotype feature matrix (Y) so as to maximise their correlation; i.e.  , where   and   are the linearly-transformed versions of ICA-DR and PFM feature matrices, respectively. \n  \nBy finding correlations between columns of U and V for the top 50 CCA components, we estimated shared variances for each pairwise comparison. \n  \nWe finally tested how many of the CCA components were significantly correlated. For this purpose, we conducted multi-level block permutations( ) which takes family structure of HCP data into account. In each iteration, X in step 5 was kept fixed, and rows of Y were randomly permuted (i.e., permuting subjects, while keeping family members together), and step 6 was repeated. Across 10,000 permutations, we constructed a null distribution for the correlations of the top 50 CCA components. The correlation value corresponding to the top 5% of the null distribution for the   first   CCA component was used as threshold for p-value<0.05 significance level for all the CCA components. This yields a significance threshold that is Family-Wise Error-rate (FWE) corrected for multiple comparisons (across CCA components). \n  \n\n\n\n\n## Supplementary Material \n  \n \n", "metadata": {"pmcid": 11160636, "text_md5": "4f6460ca185733815ac2e7b9b8d1ac9b", "field_positions": {"authors": [0, 114], "journal": [115, 122], "publication_year": [124, 128], "title": [139, 188], "keywords": [202, 202], "abstract": [215, 1455], "body": [1464, 74162]}, "batch": 2, "pmid": 38854078, "doi": "10.1101/2024.05.28.596120", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11160636", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=11160636"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11160636\">11160636</a>", "list_title": "PMC11160636  Multiscale Modes of Functional Brain Connectivity"}
