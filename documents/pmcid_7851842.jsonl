{"text": "He, Yifei and Steines, Miriam and Sammer, Gebhard and Nagels, Arne and Kircher, Tilo and Straube, Benjamin\nNeuroimage Clin, 2021\n\n# Title\n\nModality-specific dysfunctional neural processing of social-abstract and non-social-concrete information in schizophrenia\n\n# Keywords\n\nSocial\nMultimodal processing\nmPFC\nGesture\nSpeech\nSchizophrenia\n\n\n# Abstract\n  Highlights  \n  \nSocial/non-social information processing in three modalities was investigated in SZ. \n  \nSZ showed reduced activation for social information only in gesture modality. \n  \nReduced activation in SZ was observed for non-social information only in speech. \n  \nNeural Neural processing in bimodal condition is not different between patients and controls. \n  \n  \nSchizophrenia is characterized by marked communication dysfunctions encompassing potential impairments in the processing of social-abstract and non-social-concrete information, especially in everyday situations where multiple modalities are present in the form of speech and gesture. To date, the neurobiological basis of these deficits remains elusive. In a functional magnetic resonance imaging (fMRI) study, 17 patients with schizophrenia or schizoaffective disorder, and 18 matched controls watched videos of an actor speaking, gesturing (unimodal), and both speaking and gesturing (bimodal) about social or non-social events in a naturalistic way. Participants were asked to judge whether each video contains person-related (social) or object-related (non-social) information. When processing social-abstract content, patients showed reduced activation in the medial prefrontal cortex (mPFC) only in the gesture but not in the speech condition. For non-social-concrete content, remarkably, reduced neural activation for patients in the left postcentral gyrus and the right insula was observed only in the speech condition. Moreover, in the bimodal conditions, patients displayed improved task performance and comparable activation to controls in both social and non-social content. To conclude, patients with schizophrenia displayed modality-specific aberrant neural processing of social and non-social information, which is not present for the bimodal conditions. This finding provides novel insights into dysfunctional multimodal communication in schizophrenia, and may have potential therapeutic implications. \n \n\n# Body\n \n## Introduction \n  \nIn everyday social communication, humans encounter a diverse spectrum of inputs from multiple modalities ( ), which might be potentially difficult to process for patients with schizophrenia. These include non-linguistic stimuli from others\u2019 facial expressions ( ,  ), body movements, e.g., postures and gestures ( ,  ,  ), and linguistic stimuli in the form of auditory speech and written texts ( ). Importantly, the multimodal inputs comprise both social-abstract and non-social-concrete information, and patients\u2019 social functioning heavily depends on the processing of these stimuli, which serves as the basis to further mentalize social intentions and to perform appropriate social interaction ( ). To date, however, it remains elusive if the processing of these social/non-social information in schizophrenia is impaired in schizophrenia in a multimodal context. \n\nSocial cognition is known to be impaired in schizophrenia ( ). Regarding the perception of social stimuli, in particular, prior research on patients\u2019 social perception dysfunction has focused on emotional perception of faces and voices ( ,  ), whereas limited studies have investigated the perception of social-abstract information delivered via linguistic and gesture stimuli. In healthy participants, a seminal fMRI (functional magnetic resonance imaging) study has identified distinct brain regions for processing socially and non-socially relevant linguistic information ( ): When participants were asked to judge whether visual word pairs are person\u2013 or object-related, person-related social stimuli activated the medial prefrontal cortex (mPFC), a crucial region forming the mentalizing network ( ,  ,  ,  ). On the other hand, when processing linguistic stimuli about non-social-concrete content (e.g., words and sentences about objects), healthy participants activate regions including a left-lateralized network including the left the bilateral insula and the left parietal lobe ( ,  ). \n\nNotably, in everyday life, both types of information are also commonly conveyed via non-linguistic channels such as manual gestures. For instance, even without speech, individuals can use a \u201cbe silent\u201d emblematic gesture to deliver social information, which is commonly intransitive and symbolic; on the other hand, for describing concrete actions, transitive and object-related hand actions, i.e., pantomimes such as \u201chammering\u201d are commonly used. Moreover, it is common to use both gesture and speech together: To ask someone else to stop, one can use a \u201cstop\u201d gesture (e.g., a front-facing, raised hand) together with its verbal counterpart. Emerging basic research has investigated if the processing of social-abstract and non-social-concrete information is modality-independent: for healthy populations, social-abstract information delivered by both auditory speech and manual gesture commonly activates the mPFC and the (IFG) and middle temporal gyri ( ,  )\u2014regions that are typically activated for social cognition and abstract semantics ( ,  ). For processing non-social action and object information, literature also suggests that humans recruit modality-independent regions, such as the lateral occipitotemporal cortex (LOTC) and the pre/postcentral gyri ( ,  ,  ). \n\nThe multimodal characteristics of social/non-social information processing, as well as its supramodal neural basis, may have profound implications in schizophrenia research. Schizophrenia is characterized by well-known deficits in the comprehension and production of speech ( ,  ,  ,  ), as well as impairments in the perception and production of gesture ( ,  ,  ,  ,  ,  ,  ,  ,  ). Clinically, these two aspects may directly contribute to major symptoms of schizophrenia such as formal thought disorder and apraxia/catatonia respectively. They are also indicative of a range of other negative and positive symptoms of schizophrenia ( ,  ), and are functionally highly relevant ( ,  ). Yet, regarding the processing of social/non-social information, it remains unknown if both processes are impaired in schizophrenia irrespective of modality, or if the impairments are modality-specific. For the processing of social-abstract information, both linguistic (visual and auditory) and gesture (social emblems) have not been investigated in schizophrenia so far. However, studies employing non-semantic hand actions have shown that patients might be impaired for gesture perception in general ( ,  ). For the processing of concrete and non-social information, a previous study shows that patients are impaired in visually presented sentences ( ). Moreover, given potential dysfunctional processing of social or non-social information in schizophrenia, it remains unclear if these deficits could be potentially compensated by multimodal inputs containing both speech and gesture: Emerging literature suggests mutual facilitation between speech and gesture, at least for healthy populations ( ,  ,  ,  ,  ). \n\nTo address these remaining research questions, we conducted the current study, presenting to patients with schizophrenia and matched controls with videos of an actor communicating in a spontaneous and naturalistic manner. In these videos, the actor performs either social-abstract (person-related) or non-social (object-related) content in different modalities, where social and non-social information is perceivable in gesture- and speech-only modalities. Similar to approaches from previous research ( ,  ), we directly compared social vs. non-social videos to identify neural perception of social and non-social information in both auditory-speech and visual-gesture modalities. Additionally, we showed to participants videos with bimodal inputs (actor both speaking and gesturing). Based on previous research, we hypothesized activation of the mPFC and a left frontal-temporal network (e.g., inferior frontal gyrus, middle temporal gyrus) for the processing of social-abstract information ( ). For non-social-concrete information processing, we hypothesized left-lateralized regions including the lateral occipitotemporal cortex (LOTC), the superior temporal gyrus/sulcus (STG/STS), as well as pre/postcentral gyri forming the putative mirror neuron system ( ,  ,  ,  ). We focused directly on group differences between a group of patients suffering from schizophrenia or schizoaffective disorder, and their age- and education-matched controls: for social content, as patients are well-known for their social cognition impairments, we expected patients to show reduced activation in the mPFC, irrespective of encoding modality ( ); For non-social content, despite mixed findings from previous neuroimaging research on hand action observation on schizophrenia ( ,  ), following previous report on dysfunctional processing of non-social linguistic stimuli in schizophrenia ( ), we hypothesized neural modulation of the object-related regions for patients with schizophrenia for both gesture and speech modalities. Additionally, based on prior basic research on mutual facilitation between gesture and speech ( ; see   for review), we hypothesized that the bimodal input could compensate for potential unimodal processing deficits, leading to improved performance in the patient group. \n\n\n## Methods \n  \n### Participants \n  \nWe summarized participants\u2019 demographic and clinical characteristics in  . Healthy controls were recruited matching age, gender, and education to patients. Seventeen patients were recruited at the Department of Psychiatry and Psychotherapy at the Philipps University of Marburg, and were diagnosed according to ICD-10 with schizophrenia (F20.0, n\u00a0=\u00a013, and F20.3, n\u00a0=\u00a01) or schizoaffective disorder (F25.0, n\u00a0=\u00a02, and F25.2, n\u00a0=\u00a01). Participants in both groups are native speakers of German, and have no knowledge of Russian language. All except one of the patients received antipsychotic treatment; six were additionally treated with antidepressive medication (For detailed medication at the time scanning, see  ). Positive and negative symptoms were assessed with the Scale for the Assessment of Positive Symptoms (SAPS) ( ), and the Scale for the Assessment of Negative Symptoms (SANS) ( ). Eighteen age\u2013, gender\u2013, and education-matched healthy participants with no history of any mental disorders were recruited from the same area. Exclusion criteria for both groups were brain injury and neurological or other medical diseases affected by brain physiology. In both groups, we conducted neuropsychological tests to assess working memory function, digit span, trail making (TMT), verbal IQ (MWT-B) ( ), and metaphoric language processing (concretism, evaluated with the Proverb Interpretation Task) ( ). These measures are reported in  . We report, additionally, scores from word fluency test, as well as gesture production and perception (BAG, Brief Assessment of Gesture ( )) in the supplement ( ). All participants had normal or corrected-to-normal vision and hearing. Except for one control and one patient, all other participants are right-handed ( ). All participants gave written informed consent prior to participation in the experiment and were compensated monetarily. The study was approved by the ethics committee of the School of Medicine, Philipps University Marburg.   \nDemographic, medication, symptom, and neuropsychological measures. \n    \n\n\n### Materials and procedure \n  \nWe employed a content judgement paradigm from previous studies from our research group to investigate modality-specific processing of social/non-social information ( ,  ,  ), which has elicited dissociable but supramodal neural processing of social-abstract and non-social-concrete information in a healthy student sample ( ). Of note, the same fMRI dataset has been published with an unrelated research question ( ). We showed to participants five-second videos of an actor spontaneously communicating both social-abstract (S) and non-social-concrete (N) events in the following modalities: 1) incomprehensible Russian sentences with gestures. This is considered as a gesture-only (G) condition because social feature is only available to participants in the gesture form. 2) comprehensible German sentences (S) without any gestures. Additionally, we also showed to participants 3) German sentences with accompanying gestures as a bimodal input condition (B). A filler condition is also included with videos of incomprehensible Russian sentences with meaningless gestures. An example of both a social (S) and non-social (N) bimodal videos is illustrated in  A. For a complete list of all videos, please refer to Appendix in  .   \nPanel A: Picture illustration for social-abstract (S) and non-social-concrete (N) videos in the bimodal condition (B). The same stimuli were also presented in two additional modalities: gestures with foreign Russian sentences (G) and German sentences without any gestures (S). For illustrative purposes, the spoken German sentences were translated into English, and all spoken sentences were written into speech bubbles. Panel B: Illustration of a sample trial. Participants performed a content judgment task for each video, indicating via button press whether a stimulus was either person\u2013 or object-related. \n  \n\n\n### Procedure \n  \nAltogether, 312 experimental video slips (26 videos per condition\u00a0\u00d7\u00a06 conditions\u00a0\u00d7\u00a02 sets) were included in the study. For each participant, an experimental session comprised 182 videos from one set of videos (156 critical videos and 26 filler videos), and consisted of two 14-minute runs. Each run contained 91 trials with a matched number of items from each condition. The stimuli were presented in an event-related design in pseudo-randomized order. Within each trial, each video-clip was followed by a gray background with a variable duration of 2154\u20135846\u00a0ms (jitter average: 4000\u00a0ms), as illustrated in  B. Participants performed a content judgement task for each video ( ,  ), indicating via button press (with their left hand) whether a stimulus was either person\u2013 or object-related. Participants were instructed to respond to the task as soon as they had decided on an answer. \n\n\n### fMRI acquisition and preprocessing \n  \nAll images were acquired using a 3\u00a0T MRI scanner (Siemens MRT Trio series). The functional images were obtained using a T2*-weighted echo-planar image sequence (TR\u00a0=\u00a02\u00a0s, TE\u00a0=\u00a030\u00a0ms, flip angle\u00a0=\u00a090\u00b0, slice thickness\u00a0=\u00a04\u00a0mm, interslice gap\u00a0=\u00a00.36\u00a0mm, field of view\u00a0=\u00a0230\u00a0mm, matrix\u00a0=\u00a064\u00a0\u00d7\u00a064, voxel size\u00a0=\u00a03.6\u00a0\u00d7\u00a03.6\u00a0\u00d7\u00a04.0\u00a0mm, 30 axial slices orientated parallel to the AC-PC line, ascending order). Two runs of 425 volumes each were acquired during the experiment. Additionally, simultaneous EEG data from the participants were also collected for other analyses not relevant for the current study, and are therefore not further discussed here. MR images were preprocessed using the SPM12 software package (Statistical Parametric Mapping, Welcome Trust Center for Neuroimaging, London, UK) based on Matlab R2017a (version 9.2.0; MathWorks): after discarding the first five volumes to minimize T1-saturation effects, all images were spatially and temporally realigned, and normalized into the MNI space using the MNI template (resulting voxel size 2\u00a0\u00d7\u00a02\u00a0\u00d7\u00a02\u00a0mm), smoothed (8\u00a0mm isotropic Gaussian filter), and high-pass filtered (cut-off period 128\u00a0s). \n\n\n### fMRI data analysis \n  \nWe performed statistical whole-brain analysis in a two-level, mixed-effects procedure. On the first level, single-participant BOLD responses were modeled by a design matrix comprising the onset time points of each event (critical word of each sentence as used in the previous event-related fMRI and EEG studies, e.g., ( ,  ,  ,  ,  )), with a duration of 5\u00a0s for all experimental conditions. The micro-time onset was set to the average time bin (8 of 16) to align the onset vector to the slice in the middle of the brain. For all conditions, the duration of speech and gesture was used as parameters of no interests on a single trial level. Six movement regressors (three rotations and three translations) were entered in the single participant\u2019s model to account for movement-induced effects on fMRI results. HRF was defined as the canonical HRF. Contrasts images against implicit baseline for all experimental conditions were used as summary measures and were included in the between-group analysis. We applied a flexible factorial analysis of variance using condition as main effect. We applied a Monte-Carlo simulation to determine the cluster extent threshold to correct for multiple comparisons, ( ,  ), which has been used in comparable studies in our laboratory on social perception of multimodal stimuli ( ). For all statistical comparisons, the whole-brain activation was simulated assuming a voxel type-I error activation of p\u00a0<\u00a0.05, this revealed a cluster extent of 2268 contiguous resampled voxels as sufficient to correct for multiple comparisons at p\u00a0<\u00a0.0167 (Bonferroni-corrected for three independent tests for interaction within three independent modalities, with 0.05/3). We also reported in activation tables uncorrected cluster p-values and marked significance for cluster-level FWE correction. The reported voxel coordinates of activation peaks are located in MNI space. For the anatomical localization, functional data were referenced to the AAL toolbox ( ). \n\nFirstly, we tested three-way interaction of group\u00a0\u00d7\u00a0modality\u00a0\u00d7\u00a0content. We then conducted, within each modality, interaction analyses to investigate group differences in the processing of social or non-social conditions, and masked the respective results based the contrast image from the first analysis, to reveal modality-specific group interaction. In addition, within each modality, for each group, we conducted pair-wise comparison between social and non-social conditions (S\u00a0>\u00a0N and N\u00a0>\u00a0S), for illustrating modality\u2013 and group-specific brain activations for either social or non-social information processing. In the end, following our hypotheses on bimodal enhancement for patients, within patients, we tested the interaction between modalities on social vs. non-social content processing, so as to reveal how bimodal stimuli might compensate potential neural processing deficits for patients with schizophrenia. Results of this analysis is reported in  . \n\nBased on the literature showing a potential relationship between symptom severity (especially negative symptoms) and social/non-social cognition ( ,  ), as well as gesture processing ( ,  ), for patients with schizophrenia, we conducted exploratory correlation analysis, probing for the potential relationship between clinical measures and brain activation in areas that are relevant to social/non-social information processing. To this end, spearman correlation analyses (uncorrected) were conducted between 1) parameter estimates from clusters showing significant group difference for either social or non-social conditions, 2) behavioral measures (reaction times and accuracy) for each experimental condition, and 3) scores from sum/general and subscales of SAPS and SANS. \n\n\n\n## Results \n  \n### Behavioral results \n  \nHealthy controls and patients with schizophrenia were instructed to indicate via button press whether the actor in the video described a person-related content or an object-related content. Correct responses (percentage correct) and their reaction times were analyzed each with mixed ANOVA [within factors: CONTENT (social vs. non-social) and MODALITY (bimodal vs. gesture vs. speech); between factor: GROUP (control vs. patient)]. Descriptive statistics for each experimental condition for both groups were provided in  .   \nAccuracy and reaction times (RT) for the behavioral task. \n    \n\nFor accuracy, we observed three main effects despite, but no interaction with GROUP (F \u00a0=\u00a00.83, p\u00a0=\u00a00.44, \u03b7 G\u00a0=\u00a00.003): Patients were significantly less accurate than healthy controls (F \u00a0=\u00a05.18, p\u00a0=\u00a0.03, \u03b7 G\u00a0=\u00a00.05). Non-social videos were judged more accurately than social videos (F \u00a0=\u00a019.75, p\u00a0=\u00a0.0001, \u03b7 G\u00a0=\u00a00.18). Additionally, accuracy between the three modalities was different (F \u00a0=\u00a014.53, p\u00a0=\u00a0.00001, \u03b7 G\u00a0=\u00a00.04). Post-hoc pairwise   t  -test showed that the accuracy for the bimodal conditions were highest (vs. gesture, t\u00a0=\u00a05.81, p\u00a0=\u00a0.000001; vs. speech, t\u00a0=\u00a02.77, p\u00a0=\u00a0.007). The accuracy for the speech conditions was also higher than the gesture conditions (t\u00a0=\u00a02.14, p\u00a0=\u00a0.035). \n\nFor reaction times, there were also three main effects, but no interaction with GROUP (F \u00a0=\u00a00.75, p\u00a0=\u00a00.47, \u03b7 G\u00a0=\u00a00.003). Patients were generally slower than healthy controls (F \u00a0=\u00a019.64, p\u00a0=\u00a0.00001, \u03b7 G\u00a0=\u00a00.35). Reaction times for non-social content were faster than social content (F \u00a0=\u00a08.63, p\u00a0=\u00a0.005, \u03b7 G\u00a0=\u00a00.005). Additionally, reaction times for the three modalities were different (F \u00a0=\u00a010.14, p\u00a0=\u00a0.0001, \u03b7 G\u00a0=\u00a00.01). Post-hoc pairwise   t  -test showed that the reaction time for gesture modality was significantly slower than the other modalities (|t| \u00a0=\u00a04.03, p \u00a0=\u00a00.0001), and there was no significant difference between the bimodal and the speech modalities (t\u00a0=\u00a00.21, p\u00a0=\u00a0.82). \n\nThe results from the behavioral task showed that patients with schizophrenia were generally slower and less accurate in the content judgement task. Additionally, the responses for non-social videos were faster and more accurate. With regard to modality, responses in the bimodal conditions were the most accurate and the fastest. However, it has to be noted that, due to the limited sample size (see Discussion), we refrain from elaborating on the interpretation of the observed behavioral effects. \n\n\n### fMRI results \n  \n#### Social-abstract (S)\u00a0>\u00a0Non-social-concrete (N) \n  \nWe report whole-brain fMRI results for S\u00a0>\u00a0N comparisons in   and  . For the speech conditions (SS\u00a0>\u00a0NS), healthy controls activated an extensive fronto-temporal-parietal network including the bilateral inferior frontal gyrus (IFG) and the temporal lobe, the dorsolateral prefrontal cortex (dlPFC) and mPFC, and the left supramarginal gyrus; patients revealed similar regions for this comparison, and we observed no group difference for social\u00a0>\u00a0non-social speech. For the gesture conditions (SG\u00a0>\u00a0NG), controls activated the bilateral PFC and IFG; patients activated the bilateral prefrontal cortex. Group interaction (Control (SG\u00a0>\u00a0NG)\u00a0>\u00a0Patient (SG\u00a0>\u00a0NG)) suggests that patients showed reduced activation in the mPFC and the anterior cingulate cortex for the social gesture condition when compared to controls ( B). In the bimodal condition (SB\u00a0>\u00a0NB), both controls and patients activated regions similar to that of the speech condition. For patients, we additionally reported modality*content interaction in the  , which shows that patients\u2019 aberrant processing of social gestures is improved in the bimodal modality.   \nActivation maps for social-abstract\u00a0>\u00a0non-social-concrete videos (S\u00a0>\u00a0N). Panel A: S\u00a0>\u00a0N contrasts within each modality (S: Speech, G: Gesture, B: bimodal) for controls and patients. Panel B: interaction analysis (Control\u00a0>\u00a0Patient) in the gesture modality (SG\u00a0>\u00a0NG) together with box- and swarm-plots of eigenvariates for selected clusters. All results are correct for multiple comparison with Monte-Carlo simulation with k\u00a0>\u00a02268 voxels. \n    \nPeak MNI coordinates of within- and between-group significant brain comparisons for social\u00a0>\u00a0non-social conditions. Cluster-level uncorrected p-value is provided for each cluster, asterisk indicates significance (p\u00a0<\u00a00.05) with cluster-level FWE correction. \n  \n\n\n#### Non-social-concrete (N)\u00a0>\u00a0Social-abstract (S) \n  \nWe report whole-brain fMRI results for N\u00a0>\u00a0S comparisons in   and  . For the speech conditions (NS\u00a0>\u00a0SS), healthy controls activated the left pre/postcentral gyrus, supramarginal gyrus, and the left insula, whereas patients did not reveal any significant activations for this comparison. The group interaction (Control (NS\u00a0>\u00a0SS)\u00a0>\u00a0Patient (NS\u00a0>\u00a0SS)) suggests that, when compared to controls, patients showed reduced activation in the left postcentral gyrus and the right insula for the processing of non-social content in the speech-only modality (see  B). For gesture conditions (NG\u00a0>\u00a0SG), controls showed increased activation for the non-social content in the bilateral posterior temporal gyrus, supramarginal gyrus, and occipital cortices, as well as the left pre/postcentral gyrus and the left insula. Patients also activated the bilateral posterior temporal gyrus and occipital lobe, as well as the left pre/postcentral gyrus. The group interaction revealed no significant clusters. For bimodal conditions (NB\u00a0>\u00a0SB), both controls and patients activated regions that are comparable to that of the gesture conditions. Additionally, for patients, bimodal input seems to enhance their aberrant processing of non-social speech, as reported in  .   \nActivation maps for non-social-concrete\u00a0>\u00a0social-abstract videos (N\u00a0>\u00a0S). Panel A: N\u00a0>\u00a0S contrasts within each modality (S: Speech, G: Gesture, B: Bimodal) for controls and patients. Panel B: interaction analysis (Control\u00a0>\u00a0Patient) in the speech modality (NS\u00a0>\u00a0SS) together with box- and swarm-plots of eigenvariates for selected clusters. All results are correct for multiple comparison with Monte-Carlo simulation with k\u00a0>\u00a02268 voxels. \n    \nPeak MNI coordinates of within- and between-group significant brain comparisons for non-social\u00a0>\u00a0social conditions. Cluster-level uncorrected p value is provided for each cluster, asterisk indicates signifance (p\u00a0<\u00a00.05) with cluster-level FWE correction. \n  \n\n\n\n### Exploratory correlation analyses \n  \nIn patients, for the NS condition, we found that the accuracy for the NS condition correlate negatively with the SANS composite scores of the patients (r\u00a0=\u00a0-0.52, p\u00a0=\u00a00.03, power\u00a0=\u00a00.63;  A). Additionally, SANS 1 (flat affect) and SANS 2 (alogia) scores correlate negatively with the accuracy for the NS condition (SANS 1: r\u00a0=\u00a0-0.62, p\u00a0=\u00a00.008, power\u00a0=\u00a00.79,  B; SANS 2: r\u00a0=\u00a0-0.63, p\u00a0=\u00a00.006, power\u00a0=\u00a00.82,  C).   \nSignificant negative correlations between patients\u2019 accuracy for the NS condition and A) patients\u2019 SANS composite scores, B) their SANS 1 (flat affect) scores, and C) their SANS 2 (alogia) scores. \n  \n\n\n\n## Discussion \n  \nWith an fMRI study on the perception of social-abstract and non-social-concrete stimuli in auditory-speech, visuo-gestural, and bimodal modalities, we observed modality-specific neural modulation in schizophrenia: In comparison to controls, reduced neural activity in patients was observed only for social gesture and non-social speech. Moreover, in the bimodal condition, neural activation for both social and non-social contents was comparable in patients and controls. \n\n### Social information processing in schizophrenia \n  \nIn the current study, patients showed dissociable neural modulation during the processing of social content in speech and gesture modalities. In the speech modality, both controls and patients activated a left-lateralized set of brain regions, including the dlPFC, mPFC, the IFG, the temporal lobe, and the angular/supramarginal gyrus, without any group difference. This finding replicates results from our previous study showing supramodal social-abstract processing of healthy individuals ( ), and is consistent with earlier studies in basic research on the role of the mPFC in both perceiving social-related stimuli and mentalizing social intentions ( ,  ,  ). The observed left IFG and temporal lobe activation is also in line with the literature on the neural substrates of abstract vs. concrete semantics ( ,  ), as the videos in the social-abstract condition, irrespective of modality, are more abstract than the non-social, object-related condition. The fact that we did not find any group differences in social-abstract speech processing suggests that patients with schizophrenia exhibit intact neural processing of social content presented in this modality. This finding complies with a previous language study in schizophrenia, in which patients also activated a comparable left fronto-temporal network to controls when they processed abstract vs. concrete visual sentences ( ). Together, although schizophrenia is well-known for its social cognition deficits ( ), as well as impairments in the perception of affective face or pitch ( ,  ,  ), patient\u2019s processing of social speech may remain intact. In the gesture modality, however, although patients activated the mPFC for the social vs. non-social stimuli, this activation was reduced when compared to controls. Notably, such modality-specific neural modulation is, for the first time, reported for social information processing in schizophrenia. Notably, in addition to the mPFC modulation, in schizophrenia, we did not observe the activation for social gestures in the left IFG. The left IFG has been linked to motor planning of gesture ( ); and, together with the DLPFC, left IFG activation has been shown to be modulated in schizophrenia for social gesture planning ( ). In addition to the left IFG, the left middle temporal gyrus (MTG) activation was not observed for patients with schizophrenia when processing social gestures. Importantly, functional and structural aberrance in both the left IFG and MTG are highly indicative of major language deficits (e.g., formal thought disorders) in schizophrenia ( ,  ). Here, however, rather than showing a modality (speech) -specific neural modulation, our results indicate that these regions indicate a cross-modality deficit, and echo prior research on potential neural aberrance in these regions regarding integration between speech and gesture at both lower-perceptual and higher-semantic levels ( ,  ). To summarize, our results, from a processing perspective, corroborate these extant studies, showing that functional modulation in the PFC, and potentially in the left IFG and MTG, may give rise to gesture-specific social perception deficits. \n\n\n### Non-social information processing in schizophrenia \n  \nFor the processing of non-social (object-related) information, again, the neural modulation in patients showed an apparent dissociation. In the gesture modality, both controls and patients activated the bilateral occipital-parietal cortices, STG, LOTC, insula, and the pre/postcentral gyrus. In the speech modality, although these regions were similarly activated in controls, their brain activation was significantly reduced for patients. The group comparison suggests reduced activation in schizophrenia patients in the bilateral insula and the left postcentral gyrus for non-social speech. Of note, the observed regions for non-social and object-related information processing overlap with regions considered as part of the putative mirror neuron network, which is not only important for action observation and imitation, but also for the understanding of object- and motor-related features in verbal form ( ,  ,  ,  ). This process would require mental simulation of sensorimotor experience ( ,  ,  ). Additionally, the LOTC is also crucially involved in the perception of biological motion, object, face, as well as tool-use ( ,  ,  ,  ,  ). Moreover, these regions are also reported to support the processing of concrete linguistic information ( ,  ). Our data from the control group suggest that these regions support the processing of non-social-concrete features, irrespective of encoding modality. This finding is in line with the embodiment view of action and language processing ( ,  ). With regard to the patients, we observed normal neural processing of non-social content in the gesture modality, supporting a previous study ( ), which reported intact mirror neuron activity in schizophrenia (but see ( )). However, as we also observed reduced bilateral postcentral gyrus and right insula activity for patients for non-social speech, in turn, this would imply that motor simulation, as required for processing object-related features from auditory speech, might still be impaired in schizophrenia ( ,  ). This impairment concurs with the reported deficits of schizophrenia in action imitation ( ,  ,  ,  ,  ,  ), where certain degrees of motor simulation is required. However, adding to prior research on schizophrenia\u2019s motor impairments, our results provide a more nuanced version: Motor-related semantics as delivered by pantomime does not necessarily lead to reduced neural activation in schizophrenia; rather, modulated neural activity is only observed for speech contents simulating these concrete motor-actions. Additionally, schizophrenia is commonly related to structural changes in the left insula; this region is also functionally relevant to a range of language and speech processing aberrances in schizophrenia ( ,  ,  ). Therefore, functional abnormality in this region might also contribute to the simulation of motor events with speech. In sum, our fMRI results may suggest that patients with schizophrenia are impaired in a mirror-mechanism simulating concrete-motor events with speech. \n\nIn the NS condition, we also observed negative correlation between patients\u2019 SANS composite and subscores and their task accuracy. This evidence converges with previous research, corroborating the potential role of the mirror neuron system during embodiment of non-social information (e.g., action imitation and observation), as well as its relation to the development and persistence of negative symptoms ( ,  ). Our correlational finding, although being exploratory (see 4.4), links the mirror neuron system to the reported studies showing correlation between compromised gesture performance and more severe negative symptoms ( ,  ), tentatively suggests that the theoretical link between gesture and negative symptom may partially derive from motor-simulation. Notably, in the current study, for social processing, we did no observe any correlations between brain activations / behavior and symptom measures, especially positive symptoms such as hallucinations, and positive formal thought disorders, as in  . Clearly, the exact relationship between social/non-social information processing and major symptoms of schizophrenia needs to be addressed by further research with larger samples. \n\n\n### Enhancing modality-specific information processing deficits with bimodal input \n  \nThe novelty of our findings lies in the dissociable modality-specificity concerning dysfunctional neural processing of social and non-social features. Social-abstract and non-social-concrete features are functionally and neurally dissociable at the representational level ( ,  ,  ). Besides, they might be differentially processed through either linguistic (speech) or non-linguistic (gesture) channels. It has been proposed that social-abstract concepts may be   preferentially   represented in speech, and that non-social concrete concepts are   preferentially   delivered in hand action and gesture ( ,  ). Despite this theoretical proposal, however, during comprehension, healthy participants are able to process both types of information in a supramodal manner (e.g., semantic processing with unitary core systems, irrespective of encoding modality, as in ( ,  )). For patients with schizophrenia, as they exhibit similar neural activations when processing social speech and non-social gestures to controls, this might be an indication that they are at least intact in processing these contents through a   preferred   modality at representational level. But, they might show activation reduction in relevant regions when these features are conveyed in a   non-preferred   modality, as the processing of these features would require some form of mental simulation: In the case non-social information, patients are impaired in the simulation of motor-related experience from action to language ( ); In contrast, when patients are presented with social information, they might be impaired when simulating social features encoded by hand gestures (but not with speech), as shown in their reduced mPFC activation. This observed modality-specific processing deficit might also suggest that patients, unlike controls, are not capable of processing social/non-social information in a supramodal manner like healthy participants, as reported in previous studies ( ,  ). More importantly, extending previous studies on aberrant processing of social/non-social content in schizophrenia, our results indicate that this neural deficit is not universally present for either a specific modality or content, but rather appears only in specific combinations of these two factors. \n\nDespite reduced neural processing of both social and non-social content in gesture and speech modalities, patients displayed intact neural processing of these features, as well as improved task accuracy in the bimodal conditions. This enhancement effect concurs with a line of proposals ( ), who argue for a bi-directional facilitative relation between speech and gesture (for empirical evidence, see ( ,  ,  ,  ,  )). More importantly, our finding extends previous basic research, suggesting the translational implication of this mechanism. In schizophrenia research, the past decade has witnessed substantial progress in the development of social cognitive training in schizophrenia ( ,  ), with recent innovation regarding the incorporation of social stimuli from a broader range of modalities ( ). Our findings extend these approaches, proposing potential therapeutic implications of deploying naturalistic and multimodal stimuli during social cognitive training ( ), as they might be able to normalize processing of both social and non-social information, at least at a neural level. Future research is expected to further explore whether the neural enhancements can be linked to functional outcome after social cognitive training in a multimodal setting. \n\n\n### Limitations \n  \nDespite new insights, our study has limitations in several aspects. Firstly, the sample size of this study (n\u00a0=\u00a017 and 18 for each group) falls within the required minimum of this type of studies ( ). Hence, the patient group was limited to medicated chronic patients, and we were thus unable to test if the neural pattern is comparable to first-episode schizophrenia ( ), and were unable to attribute the findings to schizophrenia without separating out the effects of medication. Secondly, due to the limited sample size and the exploratory nature, the findings resulted from the correlation analyses needs to be treated with caution. Thirdly, our the reported group interaction did not survive the most conservative FWE threshold. Future replications are thus necessary to validate if the observed effects are replicatable when a larger sample is possible. Lastly, we did not observe any reliable relationship between BOLD signal and behavioral results: More careful, and neurobiologically plausible behavioral tasks on the social/non-social information processing are necessary for future experiments, so that their processing deficits in schizophrenia can be better examined by clinical neuroscientists and practitioners. \n\n\n### Conclusion \n  \nHere, in an fMRI study, we for the first time showed modality-specific neural modulation in schizophrenia when patients process social-abstract and non-social-concrete content in speech and gesture. Moreover, these deficits could be compensated when both speech and gesture were presented together. Our findings provide novel insights on dysfunctional multimodal communication in schizophrenia, and suggest potential therapeutic implications of employing multimodal social cognitive intervention in schizophrenia. \n\n\n\n## Declaration of Competing Interest \n  \nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. \n\n \n", "metadata": {"pmcid": 7851842, "text_md5": "161a415c41b76335208caae0a6ac32bf", "field_positions": {"authors": [0, 106], "journal": [107, 122], "publication_year": [124, 128], "title": [139, 260], "keywords": [274, 337], "abstract": [350, 2345], "body": [2354, 40176]}, "part": 1, "chapter": 12, "page": 4, "pmid": 33524805, "doi": "10.1016/j.nicl.2021.102568"}, "display_title": "pmcid: <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7851842>7851842</a> \u2014 Part 1 Chapter 12 Page 4", "list_title": "1.12.4  Modality-specific dysfunctional neural processing of social-abstract and non-social-concrete information in schizophrenia"}
