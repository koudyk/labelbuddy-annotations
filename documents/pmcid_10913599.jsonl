{"text": "Islam, Saiful and Khanra, Pitambar and Nakuci, Johan and Muldoon, Sarah F. and Watanabe, Takamitsu and Masuda, Naoki\nBMC Neurosci, 2024\n\n# Title\n\nState-transition dynamics of resting-state functional magnetic resonance imaging data: model comparison and test-to-retest analysis\n\n# Keywords\n\nfMRI\nEEG\nMEG\nMicrostates\nClustering\nDynamics\nTest\u2013retest reliability\nFingerprinting\n\n\n# Abstract\n \nElectroencephalogram (EEG) microstate analysis entails finding dynamics of quasi-stable and generally recurrent discrete states in multichannel EEG time series data and relating properties of the estimated state-transition dynamics to observables such as cognition and behavior. While microstate analysis has been widely employed to analyze EEG data, its use remains less prevalent in functional magnetic resonance imaging (fMRI) data, largely due to the slower timescale of such data. In the present study, we extend various data clustering methods used in EEG microstate analysis to resting-state fMRI data from healthy humans to extract their state-transition dynamics. We show that the quality of clustering is on par with that for various microstate analyses of EEG data. We then develop a method for examining test\u2013retest reliability of the discrete-state transition dynamics between fMRI sessions and show that the within-participant test\u2013retest reliability is higher than between-participant test\u2013retest reliability for different indices of state-transition dynamics, different networks, and different data sets. This result suggests that state-transition dynamics analysis of fMRI data could discriminate between different individuals and is a promising tool for performing fingerprinting analysis of individuals. \n\n## Supplementary Information \n  \nThe online version contains supplementary material available at 10.1186/s12868-024-00854-3. \n\n \n\n# Body\n \n## Introduction \n  \nActivity of the human brain is dynamic even at rest, and brain dynamics on various spatial scales are considered to drive myriad functions of the brain [ \u2013 ]. Multiple methods to characterize brain dynamics have been proposed, many of which rely on the detection of brain states and quantification of how the brain transitions through such states. Microstate analysis is an early-proposed method for estimating discrete states in electroencephalogram (EEG) data [ \u2013 ]. EEG microstate analysis usually entails clustering of multi-electrode EEG signals, with each data point to be clustered corresponding to a time point of the measurement. Each cluster, or microstate, is a representation of a global functional state of the brain. Microstates obtained from resting-state EEG data tend to last about 100 ms and are reproducible [ ,  \u2013 ]. Microstate analysis has been extended for magnetoencephalography (MEG) data, with the microstates being estimated by conventional clustering methods [ ,  ] or the hidden-Markov model (HMM) [ ,  ] among other methods. Microstate analysis in its original sense (i.e., detecting and utilizing microstates lasting about 100 ms) does not directly apply to functional magnetic resonance imaging (fMRI) data because the temporal resolution of fMRI is limited, preventing one from detecting dynamics on the timescale of 100 ms. One direction to resolve this limitation is to use EEG microstate analysis results to inform states in fMRI data [ \u2013 ]. An alternative approach is to estimate and use state-transition dynamics of spatial fMRI signals, as microstate analysis does for EEG (and MEG) data, regardless of different time resolutions between fMRI and EEG/MEG. Such state-transition dynamics for fMRI data have been estimated by data clustering algorithms as in the case of the EEG/MEG microstate analysis [ \u2013 ], the HMM or its variants [ \u2013 ], and energy landscape analysis [ \u2013 ]. Each discrete state in fMRI data corresponds to a vector of activity patterns at specified regions of interests (ROIs) [ ,  \u2013 ], or a functional network among ROIs [ \u2013 ,  ,  ,  \u2013 ]. \n\nIn general, successful single individual inferences from neuroimaging data would suggest their potential applications for both scientific investigations and clinical practice. Research has shown that functional networks from fMRI data can be used as a reliable fingerprint of human individuals through test\u2013retest analyses [ \u2013 ]. Test\u2013retest reliability has also been assessed for dynamic functional networks estimated from fMRI data [ \u2013 ], whereas test\u2013retest reliability for dynamic functional networks has been reported to be lower than that for static functional networks [ ,  ]. With this study, we are interested in test\u2013retest reliability of state-transition dynamics in fMRI data, which has been underexplored. \n\nIn the present study, we assess the potential effectiveness of dynamics of discrete states estimated from fMRI data at fingerprinting individuals. Here, we use fMRI data as multivariate time series, each dimension of which represents a single ROI, akin to microstate analysis for EEG and MEG data. This approach contrasts with the aforementioned prior studies on test\u2013retest reliability of dynamic functional networks. Our analysis involves examination of what methodological choices (e.g., the clustering method applied to the fMRI data to define discrete states, the number of clusters identified, and the indices used to characterize the estimated state transition dynamics) yield a higher test\u2013retest reliability of the state-transition dynamics; such an assessment has previously been carried out for EEG microstate analysis [ ]. Based on a permutation test to quantify test\u2013retest reliability, we show that, in general, transitory dynamics of discrete states estimated for fMRI data yield higher within-participant than between-participant test\u2013retest reliability across clustering methods, the number of clusters, observables of the state-transition dynamics, two sets of ROIs, and two data sets. Code for computing dynamics of discrete states and their test\u2013retest reliability used in the present paper is available on GitHub [ ]. \n\n\n## Methods \n  \n### Midnight Scan Club data \n  \nWe use the resting-state fMRI data provided by the Midnight Scan Club (MSC) project [ ]. The MSC\u2019s resting-state fMRI data consist of recording from ten healthy human adults [age:   (average \u00b1 standard deviation); five males and five females] over ten consecutive nights. A single recording session of the resting-state fMRI experiment lasted for 30 mins, resulting in 818 volumes. The imaging was performed on a Siemens TRIO 3T MRI scanner. All functional imaging was performed using an echo planar imaging (EPI) sequence (TR   s, TE   ms, flip angle  , voxel size   mm   4\u00a0mm   4\u00a0mm, 36 slices). \n\nIt was originally reported that the eighth participant (i.e., MSC08) fell asleep, showed frequent and prolonged eye closures, and had systematically large head motion, yielding considerably less reliable data than those obtained from the other participants [ ]. In our previous work, we also noticed that the quality of the data analysis fluctuated considerably more across the different sessions for the tenth participant (i.e., MSC10) than for the other participants except MSC08 [ ]. Therefore, we excluded MSC08 and MSC10, and only used the remaining eight participants (age:  ; four males and four females) in the following analysis. \n\nWe used SPM12 ( ) to preprocess the resting-state functional images. Specifically, we first conducted realignment, unwrapping, slice-timing correction, and normalization to a standard template (ICBM 152). Then, we performed regression analyses to remove the effects of head motion, white matter signals, and cerebrospinal fluid signals. Lastly, we conducted band-pass temporal filtering (0.01\u20130.1 Hz). \n\nWe used a DMN composed of 12 ROIs [ ]. To optionally reduce the dimension of the DMN, which may improve the estimation of discrete states, we averaged over each pair of the symmetrically located right- and left-hemisphere ROIs into one observable. The symmetrized DMN has eight ROIs because four ROIs (i.e., amPFC, vmPFC, pCC, and retro splen) in the original coordinate system are approximately on the midline and therefore have not undergone the averaging over the right- and left-hemisphere ROIs [ ]. \n\nIn addition to the DMN, we also analyzed the so-called whole-brain network. We determined the regions of interest (ROIs) of the whole-brain network by employing the 264 spherical ROIs whose coordinates were identified in a previous study [ ]. We then removed 50 ROIs labelled \u2018uncertain\u2019 or \u2018subcortical\u2019, resulting in 214 ROIs. We removed these 50 ROIs because they are located in the peripheral or border areas of the brain such that signals from these regions are easily contaminated with cerebrospinal fluid (CSF) signals. The 214 ROIs were labeled either of the following nine functionally different brain systems: auditory network, dorsal attention network (DAN), ventral attention network (VAN), cingulo-opercular network (CON), default mode network (DMN), fronto-parietal network (FPN), salience network (SAN), somatosensory and motor network (SMN), or visual network. We merged the DAN, VAN, and CON into an attention network (ATN) to reduce the number of observables from nine to seven, as we did in our previous studies [ ,  ]. This is because the DAN, VAN, and CON have been suggested to be responsible for similar attention-related cognitive activity [ ]. We then calculated the average fMRI signal for each of the seven systems by first averaging the signal over the volumes in the sphere of radius 4\u00a0mm centered around the provided coordinate of each ROI [ ], and then averaging the signal over all ROIs belonging to the system (e.g., 13 ROIs in the auditory network). We call the thus obtained seven-dimensional system the whole-brain network. It should be noted that the DMN constitutes one ROI in the whole-brain network, whereas the DMN described above as a system of ROIs is composed of either 8 or 12 ROIs depending on whether or not we average over symmetrically located ROIs. \n\n\n### Human Connectome Project data \n  \nWe also analyzed the fMRI data recorded from healthy human adults and shared as the S1200 data in the Human Connectome Project (HCP) [ ]. In the S1200 data, 1200 adults between 22-35 years old underwent four sessions of 15-min EPI sequence with a 3T Siemens Connectome-Skyra (TR   s, TE   ms, 72 slices, 2.0 mm isotropic, field of view (FOV)   mm) and a T1-weighted sequence (TR   s, TE   ms, 0.7 mm isotropic, FOV   mm). To circumvent any potential influence of familial relationships, we use a subset of 100 participants that do not share any family relationship, called \u201c100 unrelated participants\u201d (age:  ; 46 males and 54 females), released by the HCP. All these 100 participants completed both diffusion weighted MRI and two resting-state fMRI scans. \n\nEach participant underwent two sessions of resting-state fMRI recording, and each session consisted of both Left-Right (LR) and Right-Left (RL) phases. In the following text, we refer to phases as sessions. Therefore, each participant\u2019s data consist of four sessions. We used data from participants with at least 1150 volumes in each of the four sessions after we had removed volumes with motion artifacts, resulting in a final analysis of 87 participants (age:  ; 40 males and 47 females). For the 87 participants, we removed the volumes with motion artifacts and then used the last 1150 volumes in each session, with the aim of removing possible transient effects. \n\nWe employed independent component analysis (ICA) to remove nuisance and motion signals [ ]. Then, any volumes with frame displacement greater than 0.2 mm [ ] were excised [ ]. This is because the ICA-FIX pipeline has been found not to fully remove motion-related artifacts [ ,  ]. Next, we standardized each voxel by subtracting the temporal mean, and then global signal regression (see \u201c \u201d section) was carried out. \n\nWe averaged the fMRI signal over all the voxels within each ROI of the AAL atlas [ ] in each volume. We remark that the AAL atlas is composed of 116 ROIs. In order to map these ROIs to representative brain systems, we first mapped each of the cortical ROIs to the parcellation scheme from the Schaefer-100 atlas [ ]. We based the assignment of the ROI to the brain system that minimized the Euclidian distance from the centroid of an ROI in the AAL to the corresponding centroid of an ROI in the Schaefer atlas. We provide the correspondence between each AAL ROI and the brain system in Additional file  : section S1. After we assigned each ROI to a system, we removed 42 ROIs labeled \u2018subcortical\u2019 or \u2018cerebellar\u2019, which yielded 74 ROIs. These 74 ROIs were then assigned to one of the   functionally different brain networks: control network, DMN, DAN, limbic network, salience/ventral attention network, somatomotor network, and visual network. We call this seven-dimensional system the whole-brain network for the HCP data. Similarly to the case of the whole-brain network for the MSC data, we first averaged the fMRI signal over the voxels within each ROI and then further averaged the signal over the ROIs belonging to the same system (e.g., 59 ROIs belonging to the DMN). \n\n\n### Global signal removal \n  \nWe denote the fMRI time series for a session by  , where   T   is the number of volumes (i.e., time points),   is the fMRI signal at time   t  , and   is the number of ROIs with which we compute the global signal. Note that   may be larger than   N  , which occurs when we define a global signal widely from the brain including ROIs that we do not use for estimating the discrete states. The global signal is the average of the signal over all the   ROIs at each time, i.e., We remove the global signal [ ] by subtracting   from each   (with  ) and dividing the result by the standard deviation, i.e., We carry out this procedure for each   t  . \n\nThe global signal in resting-state fMRI data is considered to primarily consist of physiological noise stemming from different factors such as respiration, scanner-related artifacts, and motion-related artifacts. By removing the global signal, several quality-control metrics are improved, the anatomical specificity of functional-connectivity patterns is enhanced, and there is a potential increase in behavioral variance [ ,  ]. \n\nIt is a common practice to calculate the global signal using the gray matter, white matter, and CSF (e.g., [ ,  ]). However, we calculate the global signal using the gray matter but not the white matter or CSF [ ], as explained above, for the following reasons. First, white matter noise and CSF-oriented noise were removed in the preprocessing procedure that aims to suppress the effect of motion. Second, white matter and CSF signals contribute little to the fMRI signal in the gray matter. In fact, the characteristics of the blood-oxygen-level-dependent (BOLD) signal are substantially different in the gray matter compared with the white matter and even more so with CSF, which should not contain any signal associated with the BOLD signal. Therefore, including the white matter and CSF in the global signal calculation is more likely to induce distortions in the signal [ ,  ]. \n\nFor the DMN obtained from the MSC data, we first removed the global signal calculated over the   ROIs in the coordinate system provided by [ ], which included the   ROIs in the DMN. Then, we compared three treatments of global signal removal for the DMN as follows. In the first and second treatments, we then removed the global signal calculated from the   DMN ROIs from each of the 12 ROIs in the DMN. Next, we averaged the obtained time series over each symmetric pair of DMN ROIs corresponding to the two hemispheres. If the ROI is roughly on the midline, there is no such symmetric pair of ROIs, in which case we only removed the global signal. After aggregating the symmetric pairs of ROIs in this manner, there are   ROIs in the DMN. This concludes the first treatment. In the case of the second treatment, we additionally removed the global signal calculated over the   ROIs. In the third treatment, after the removal of the global signal calculated over 30 ROIs, which is common for all the three treatments, we further removed global signal calculated from the   DMN ROIs from each of the 12 ROIs. We do not further process the data. Therefore, with the third treatment, the final DMN consists of   ROIs. \n\nFor the whole-brain network obtained from the MSC data, we first removed the global signal computed from the   ROIs. Then, we extracted  \u2014dimensional time series as described in \u201c \u201d section. Finally, we further removed the global signal computed from the   ROIs in the whole-brain network. The global signal removal for the whole-brain network obtained from the HCP data is the same except that we computed the first global signal from the   ROIs of the AAL atlas (see \u201c \u201d section). \n\n\n### Estimation of discrete states \n  \nThere are various methods for estimating microstates in the EEG and MEG data [ \u2013 ,  ]. We tailor seven popular methods for finding microstates in EEG and MEG data to the case of fMRI data to estimate their discrete states. Because the discrete states that we find for fMRI data are not equivalent to EEG/MEG microstates, we refer to the former as states, discrete states, or clusters in the following text. We describe each method in the following subsections. See Table\u00a0  for main notations.   \nMain notations used in this paper \n  \n\n#### K-means clustering \n  \nThe K-means clustering is a simple and popular clustering method to partition the data points into   K   mutually exclusive clusters. Various EEG and MEG microstate analysis [ ,  ,  ] and the studies on temporal variability of functional connectivity states of fMRI data [ ,  ,  ] used the K-means clustering. It starts with a predefined number of clusters,   K  . We initialize the centroids of the clusters by the k-means++ algorithm [ ]. The k-means++ algorithm consists of the following steps. In step (i), we select one centroid uniformly at random from all the data points. In step (ii), for each data point   that is not yet selected as a centroid, we calculate the distance to the nearest centroid. In step (iii), we sample one   that is not yet selected as a centroid yet with the probability proportional to the square of the distance between   to the nearest centroid. In step (iv), we add the   sampled in the third step as a new centroid. We repeat steps (ii), (iii), and (iv) until we obtain   K   centroids. This initialization method accelerates the convergence of the algorithm. \n\nThen, we refine the   K   centroids, denoted by  ,  ,  , as follows. The first step is to assign each data point   to the nearest centroid, i.e., the centroid realizing where   denotes the Euclidean norm. The second step is to update the centroid of each cluster   by the average of the data points belonging to the cluster as follows: where   is the Kronecker delta;   if  , and   otherwise. The Kronecker delta in the equation allows us to take the summation only over the data points belonging to the  th cluster. We repeat the first and second steps until the change in the residual sum of squares (RSS), defined by between the two subsequent steps falls below   for the first time. We use the implementation of   k  -means in scikit-learn [ ]. \n\n\n#### K-medoids clustering \n  \nThe K-medoids clustering algorithm [ ] is a variant of the K-means clustering. The K-medoids clustering uses the original data points as the centroids of the clusters, referred to as medoids. In contrast, the K-means clustering uses the average of the points in the cluster as the centroid of the cluster. The K-medoids clustering begins with a set of   K   data points as medoids, which we select using the k-medoids++ method. In fact, k-medoids++ is the same as k-means++. In the next step, we assign each   to the  th cluster whose medoid is closest to   in terms of the Euclidean distance. Then, we update the medoid of each cluster to   that belongs to the cluster and minimizes the sum of the Euclidean distance to the other data points in the same cluster. We repeat the last two steps until the dissimilarity score (i.e., the sum of the Euclidean distance from the medoid to the other data points in the cluster) stops changing for each cluster. We use the   k  -medoids implemented in scikit-learn [ ]. \n\n\n#### Agglomerative hierarchical clustering \n  \nAgglomerative hierarchical clustering, which we simply call the agglomerative clustering (AC), is a bottom-up clustering method. The AC method initially regards each data point as a single-node cluster. Then, one merges a pair of clusters one after another based on a linkage criterion. Among various linkage criteria, we use the Ward\u2019s method implemented in scikit-learn [ ]. In each step of merging two clusters, the Ward\u2019s method minimizes the within-cluster variance, i.e., the squared Euclidean distance between   and the centroid of the new cluster to which   belongs, which is summed over  . We stop the cluster merging procedure once the number of clusters is equal to   K  . \n\n\n#### Atomize and agglomerate hierarchical clustering \n  \nThe Atomize and Agglomerate Hierarchical Clustering (AAHC) is another bottom-up hierarchical clustering algorithm [ ,  ,  ]. A main difference between AAHC and traditional bottom-up hierarchical clustering methods is that AAHC atomizes the worst cluster. In other words, AAHC disintegrates the worst cluster and assigns each member of this cluster to a different cluster instead of merging the entire worst cluster with the most similar cluster. \n\nAAHC uses the global explained variance (GEV) as a measure of the quality of the cluster [ ,  ,  ,  ]. The GEV for the  th cluster is defined by where   is the cosine similarity between   and   given by In Eq.\u00a0( ),   is the inner product of   and  . Variable   represents the standard deviation of the data point   across the ROIs and is given by Eq.\u00a0( ). Quantity   is known as global field power (GFP) in the literature of microstate analysis for EEG and MEG data [ ,  ,  ,  ]. For the second and third treatments of the global signal removal, it holds true that   for any   t   because of the global signal removal carried out in the last step of the treatment. \n\nIn the AAHC, we define the worst cluster as the one with the smallest  ,   and atomize it. Then, we assign each data point   of the atomized cluster to the  th cluster that maximizes Eq.\u00a0( ) [ ,  ]. As in the AC, the AAHC initially regards each   as a single-node cluster. We repeat finding the worst cluster, atomizing it, and assigning each   in the atomized cluster to a different cluster until the number of clusters reaches   K  . \n\n\n#### Topographic atomize and agglomerate hierarchical clustering \n  \nThe Topographic Atomize and Agglomerate Hierarchical Clustering (TAAHC) is a modification of AAHC [ ,  ]. The difference between AAHC and TAAHC is that TAAHC defines the worst cluster to be the  th cluster that is the smallest in terms of the sum of the correlation of the data points in the cluster with its centroid   [ ,  ]. In other words, the worst cluster   is the minimizer of over  . As in the AC and AAHC, the TAAHC first regards each   as a single-node cluster. Second, we identify the cluster with the smallest  . Third, we atomize the selected cluster and reassign each of its member   to the cluster whose centroid is the closest to   in terms of  . We iterate the second and third steps until we obtain   K   clusters. \n\n\n#### Bisecting K-means clustering \n  \nThe bisecting K-means method combines the K-means clustering method and divisive hierarchical clustering [ ]. Initially, we let all data points form a single cluster. Then, we apply the K-means clustering with   to partition the data points into two clusters, by\u00a0following the procedure described in \u201c \u201d section. Then, we select the cluster that has the larger value of the dissimilarity defined for the  th cluster by Then, we run the K-means clustering on the selected cluster to split it into two clusters. We repeat selecting the cluster with the largest   and bisecting it until we obtain   K   clusters. We use the implementation of the bisecting K-means in scikit-learn [ ]. \n\n\n#### Gaussian mixture model \n  \nThe Gaussian mixture model (GMM) represents each cluster as a multivariate Gaussian distribution. We denote by  , with  , the multidimensional Gaussian distribution with mean vector   and covariance matrix   [ ,  ]. The GMM is given by where   is the mixing weight, i.e., the probability that a data point originates from the  th multivariate Gaussian distribution. Note that  . The likelihood function for the set of all the data points is given by We infer the parameter values by maximizing the log-likelihood function using an expectation-maximization (EM) algorithm [ ,  ,  ]. We regard   as the centroid of the  th cluster. Because the GMM is a soft clustering method, we assign each time point   t   to the  th cluster that maximizes  , where  ,  , and   are the obtained maximum likelihood estimator. We use the GaussianMixture class in scikit-learn, which uses K-means clustering for initializing the parameters [ ]. \n\nAmong the seven methods that we employ to cluster the fMRI data, the GMM is the only parametric model. All the other methods are non-parametric clustering methods. \n\n\n\n### Evaluation of the clustering methods \n  \nThe number of microstates estimated for EEG and MEG data depends on studies [ ,  ,  ,  ]. Studies on temporal dynamics of functional connectivity in fMRI data are also diverse with respect to the number of clusters [ ,  ,  ]. Therefore, we examine the number of states,   K  , from 2 to 10 for each clustering algorithm. To compare the quality of the different clustering methods, we use the GEV given by Eq.\u00a0( ). The GEV captures the amount of the data variance explained by the microstates\u2019 centroids, also called the global map, cluster map, microstate map, and template map [ ,  ,  ,  ]. We calculate the total GEV as the sum of the GEV over all the states, i.e., and average it over all the sessions and participants. A large value of the   suggests that the obtained clustering is of high quality. \n\nWe also measure the quality of the clustering methods using the within-cluster sum of squares (WCSS) [ ], also known as the distortion measure [ ]. The WCSS is defined by A small WCSS value indicates that the data points are tightly clustered and therefore the clustering is of high quality. \n\n\n### Comparison of state-transition dynamics between different sessions \n  \n#### Observables for the state-transition dynamics \n  \nTo test reproducibility of the fMRI state-transition dynamics across participants and sessions, we measure the following five observables for each session. These observables are often used in the analysis of microstate dynamics for EEG and MEG data [ ,  ,  ,  ] and activity patterns for fMRI data [ ,  ,  ]. \n\nFirst, we use the centroid of each of the   K   states as an observable. The centroid   of the  th state represents the set of data points which are assigned to the  th state. We remind that the centroid is an   N  -dimensional vector. \n\nSecond, the coverage time of the  th state is the number of times   in which the  th state appears. We normalize the coverage time of each state by dividing it by the total observation time,   T  . \n\nThird, we measure the frequency of appearance of each state. If the  th state starts and then lasts for some time steps before transiting to a different state, then we say that this is a unique appearance of  . That is, we count the consecutive appearances as one unique appearance. The frequency of appearance of   is defined as the number of unique appearance divided by   T  . \n\nFourth, the average lifespan of the  th state is the time spent in a unique appearance of   that is averaged over all unique appearances of  . The average lifespan of   is equal to the coverage time divided by the number of unique appearance of  . \n\nFifth, we investigate the frequency of transitions from one state to another as follows. Let   be the number of times with which the transition from the  th state to the  th state occurs in the given session, where  . We define the transition probability from   to   by   and we set  . The   transition probability matrix is given by   with  . \n\n\n#### Discrepancy measures for comparing the state-transition dynamics between two sessions \n  \nFor examining the reproducibility of state-transition dynamics between sessions of the same participant and between different participants, we need to compare observables between pairs of sessions. To this end, we first need to find the best matching of the states between the two sessions. For  , we assess all the possible pairwise matchings of the states between the two sessions. This entails exhaustively matching every permutation of the   K   states of the one session with the states of the another session. The total number of such pairwise matchings is equal to   K  !. For each matching, we calculate the correlation between centroids   and   of the matched states, i.e.,  th state in the first session and the  th state in the second session, by  , where   is defined in Eq.\u00a0( ). We then average   over all the   K   matched pairs of states in the two sessions and call it the centroid similarity. We select the matching that maximizes the centroid similarity among the   K  ! matchings. \n\nFor   and  , we cannot assess all possible pairwise matchings due to combinatorial explosion. Therefore, we use a greedy search to find an approximately optimal matching. First, we find the pair of the  th state in the first session and the  th state in the second session that maximizes  . Second, we select one state from the remaining   states in the first session and one state from the remaining   states in the second session such that the correlation between the two centroids is the largest, and we pair them. We repeat this procedure until all the   K   states are matched between the two sessions. \n\nOnce we have determined the final matching between the   K   states in the first session and those in the second session, we use the centroid dissimilarity, defined as  , as a measure of discrepancy between the set of   K   states in the two sessions. The centroid dissimilarity ranges between 0 and 2. It is equal to 0 if and only if the set of the   L   centroid positions is exactly parallel between the two sessions. \n\nThe centroid similarity,  , only compares the direction of the two centroids,   and  , from the origin. Therefore, we also measured the discrepancy between the set of   K   states in the two sessions based on the Euclidean distance between   and  , given by In the verification analysis, we searched for the best matching of the   K   states between the two sessions by minimizing the average of   over the   K   matched pairs of states instead of maximizing the average of  . Similar to the case of using  , we did so by the exhaustive search when   and by the greedy algorithm when  . The dissimilarity obtained using the average of   d   is equal to 0 if and only if the set of the   L   centroid positions is the same between the two sessions, and its large value implies a large discrepancy between the two sessions in terms of the centroid position. \n\nFor the coverage time, frequency of appearance, and average lifespan of states, we compute the total variation (TV) to quantify the difference in the state-transition dynamics between two sessions. Let   be the coverage time, frequency of appearance, or average lifespan for the  th state in session   i  . For the notational convenience, we assume without loss of generality that we have matched the  th state in session   i   with the  th state in session   j  . For the coverage time of the  th microstate, we use the normalized coverage time defined in \u201c \u201d section as  . The TV is defined by where  . \n\nTo quantify the difference between the transition probability matrices for two sessions   i   and   j  , denoted by   and  , respectively, where  , we calculate the Frobenius distance given by \n\n\n#### Permutation test \n  \nWe hypothesize that the state-transition dynamics estimated from fMRI data is more consistent between different sessions of the same participant than between different participants. To test this hypothesis, we compare the dissimilarity between two sessions originating from the same participant and the dissimilarity between two sessions originating from different participants. If the former is smaller than the latter, then the state-transition dynamics is more reproducible within a participant than between different participants, supporting the potential ability of state-transition dynamics to be used for individual fingerprinting. \n\nWe measure the dissimilarity between a given pair of sessions in terms of one of the five observables (i.e., centroid position, distribution of the coverage time, normalized frequency of appearance of states, distribution of the average lifespan, or the transition probability matrix). For each observable, we compare the within-participant dissimilarity and between-participant dissimilarity using the normalized distance ND combined with the permutation test [ ,  ], which we adapt here for our purpose. Denote by   q  (  p  ,\u00a0  s  ) one of the five observables for participant   and session  , where   is the number of participants, and   is the number of sessions per participant. We define the ND by where   denotes the dissimilarity (i.e., the Euclidean distance, TV, or Frobenius norm, depending on the observable; see \u201c \u201d section) between two sessions. The prefactor on the right-hand side on the first line of Eq.\u00a0( ) accounts for the normalization; there are   and   terms in the summation on the numerator and denominator, respectively. Therefore, the numerator of the right-hand side on the first line of Eq.\u00a0( ) represents the average dissimilarity between two sessions obtained from different participants. The denominator represents the average dissimilarity between two sessions obtained from the same participant. If the state-transition dynamics are more consistent among different sessions within the same participant than among different sessions of different participants, we expect that  . \n\nTo statistically test the   value, we ran a permutation test [ ]. Specifically, we carried out the following steps.    \nShuffle the values of   q   across all participants and sessions uniformly at random. This process is equivalent to applying a random permutation on  . We denote the   q   value for the   s  th session for   p  th participant after the random permutation by  . Note that the   value originates from any of the   participants with probability   and any of the   sessions with probability  . \n  \nCalculate  . \n  \nRepeat steps (i) and (ii)   R   times. We set  . \n  \nThe permutation   p  -value is equal to the fraction of the runs among the   R   runs in which the   value is larger than the empirical   value. \n  \n\n\n\n\n## Results \n  \n### Choice of the global signal reduction and clustering methods \n  \nWe ran the seven clustering methods for each number of clusters,  , each of the ten sessions, each of the eight participants, and each of the three global signal removal methods for the DMN extracted from the MSC data. Then, we calculated the total GEV, i.e.,  , for each combination of these variables as a measure of the quality of clustering. We show the   values averaged over all the participants and sessions in Fig.\u00a0 a\u2013c, for each combination of these variations. Each panel of Fig.\u00a0  corresponds to a treatment of the global signal removal. In all the cases,   increases as   K   increases. We also find that   is notably larger with the first and second treatments than the third treatment for all the seven clustering methods and that   is slightly larger under the second than the first treatment for all values of   K   and for all the clustering methods. Because the second treatment of the global signal removal shows the best performance in terms of clustering quality (i.e., providing the largest  ), we use the second treatment in the following analyses.   \nPerformance of estimating discrete states from the DMN extracted from the MSC data. We show the results for the three treatments of global signal removal, seven clustering methods, and  .   a  \u2013  c   Total GEV.   d  \u2013  f   WCSS.   a  ,   d   First treatment of the global signal removal.   b  ,   e   Second treatment.   c  ,   f   Third treatment. Each   and WCSS value shown is the average over the eight participants and ten sessions per participant \n  \n\nWe select the three clustering methods with the largest  , which are the K-means, TAAHC, and bisecting K-means. For these three clustering methods,   is around 70% with   (K-means:   (average \u00b1 standard deviation calculated on the basis of the 80 sessions of the MSC data), TAAHC:  , bisecting K-means:  ) and more than 75% with   (K-means:  , TAAHC:  , bisecting K-means:  ). We show a brain map of each of the   discrete states estimated by K-means in Fig.\u00a0 . As references, previous microstate analyses on EEG data found the   values of   [ ] and   [ ] using the K-means clustering, and   using TAAHC [ ], all with  . Furthermore,   values of   and   with   were reported for EEG data recorded under eyes-closed and eyes-open conditions, respectively [ ]. A MEG study reported a   of   using the K-means clustering with   [ ]. Our present data analysis with the fMRI data has yielded somewhat larger   values than these studies. \n\nThe GEV is based on the similarity in the direction of the   N  -dimensional fMRI signal,  , and the centroid of the cluster,  , where we remind that   is the index of the cluster to which   belongs. Therefore, the GEV can be large even if   and   are not close to each other. Therefore, we also computed the WCSS, which is the sum of the distance between   and   over all the volumes. We confirmed that the dependence of the WCSS on the global signal removal method, clustering method, and   K   is similar to that with   (see Fig.\u00a0 d\u2013f). Note that a large   value implies a good clustering result, whereas a small WCSS value implies a good clustering result. In particular, with the WCSS, the second treatment of the global signal removal is the best among the three treatments, and the best three clustering methods remain the same, while the GMM performs as equally well as the TAAHC and the bisecting K-means for the second treatment of the global signal removal (see Fig.\u00a0 e). Therefore, in the remainder of this paper, we further focus our analysis only on the K-means, TAAHC, and bisecting K-means clustering methods.   \nBrain map for each of the   K  =4 discrete states estimated by K-means for the first session of the first participant (i.e., MSC01). This choice of session and participant is arbitrary. We employed the second treatment of the global signal removal. Each circle represents an ROI in the left hemisphere. The color represents the activity averaged over the volumes belonging to the corresponding state. We used the BrainNet Viewer tool [ ] for the visualization \n  \n\nGlobal signals can show spatio-temporal patterns and may provide specific pathological or psychological information [ ,  ]. Therefore, we examined the quality of clustering produced by seven clustering methods and for   in the absence of global signal removal. The quality of clustering was worse without global signal removal than with global signal removal in terms of both   and WCSS (see Additional file  : section S2). Therefore, we do not consider the analysis without global signal removal in the following sections. \n\n\n### Test\u2013retest reliability of the observables of the state-transition dynamics \n  \nWe calculated the five observables, i.e., centroid of the clusters, coverage time, frequency, average lifespan, and transition probability matrix, of the estimated state-transition dynamics for each of the three selected clustering methods, each   K   value, session, and participant. Then, we calculated the discrepancy in each observable between two sessions. To compare the state-transition dynamics of different sessions within the same participant, which we call the within-participant comparison, we calculated the discrepancy in terms of each observable for each pair of sessions for each participant. Because there are ten sessions for each of the eight participants, there are   within-participant comparisons, where   represents the binomial coefficient. To compare the state-transition dynamics between different participants, which we call the between-participant comparison, we calculated the discrepancy in terms of each observable between each pair of sessions obtained from different participants. There are   between-participant comparisons. \n\nWe show the distribution of the discrepancy measure for each observable with  , separately for the within-participant and between-participant comparisons, in Fig.\u00a0 . Figure\u00a0 a\u2013c shows the results for the K-means, TAAHC, and bisecting K-means, respectively. We find that the state-transition dynamics are visually more similar in the within-participant than between-participant comparisons across all the indices and for all the three clustering methods when we compare the minimum, maximum, median, first quartile, and third quartile values of each distribution. For all the three clustering methods, the gap between the within-participant and between-participant comparison is apparently the largest for the centroid position among the five observables. The gap between the within-participant and between-participant comparisons often looks subtle, in particular for the coverage time. The results with   and   are qualitatively the same as those with   (see Additional file  : section S2).   \nWithin-participant and between-participant reproducibility of the state-transition dynamics with   states.   a   K-means.   b   TAAHC.   c   Bisecting K-means. \u201cWithin\u201d and \u201cBetween\u201d indicate the within-participant and between-participant comparisons, respectively. Each box plot shows the minimum, maximum, median, first quartile, and third quartile of the measurements. Each dot represents a session. \u201cCentroid\u201d abbreviates the centroid position, and \u201cTransition prob.\u201d abbreviates the transition probability matrix \n  \n\nTo test the significance of the difference between the within-participant and between-participant session-to-session reproducibility of the state-transition dynamics, we carried out the permutation test. We computed the ND value for each clustering method, value of  , and observable. Furthermore, we computed the ND values for   randomized session-to-session comparisons. The permutation test concerns whether the ND value for the original session-to-session comparisons is significantly different from the ND values for the comparisons between the randomized pairs of sessions. \n\nWith  , we show the ND value for the original session-to-session comparisons and the distribution of the ND values for the randomized sessions in Fig.\u00a0 . Each panel of Fig.\u00a0  shows a combination of the clustering method and the observable. The vertical dashed lines represent the ND values for the original session-to-session comparisons. We find that the result of the permutation test is significant in many cases even after correcting for multiple comparisons over the three clustering methods, nine values of   K  , and five observables; see the uncorrected   p   values in the figure; an uncorrected   corresponds to a Bonferroni corrected  . A small   p   value implies that the within-participant session-to-session reproducibility is higher than the between-participant session-to-session reproducibility, suggesting the possibility of using the observable for fingerprinting individuals.   \nDistribution of the ND values for the original and randomized session-to-session comparisons with  .   a   K-means.   b   TAAHC.   c   Bisecting K-means. The   p   values shown are the uncorrected values \n  \n\nWe tabulate the   p   values from the permutation test for the three clustering methods,  , and the five observables in Table\u00a0 . In the table,   indicates that the ND value for the original session-to-session comparisons is farther from 1 than all the   randomized comparisons. The table shows that a majority of the   p   values (i.e., 126 out of 135; 93.33%) are smaller than 0.05 (shown with *). One hundred and seventeen of them (i.e., 86.67% of the 135 comparisons) remain significant after the Bonferroni correction (shown with ***; equivalent to  , uncorrected). Because there are 135 comparisons in the table and using the Bonferroni correction may be too stringent, we also counted the cases in which the uncorrected   p   value is less than 0.001, shown with **; there are 119 out of the 135 comparisons (i.e., 88.15%) with  . We find that the number of significant   p   values with the K-means and bisecting K-means is somewhat larger than with the TAAHC (with  , K-means, TAAHC, and bisecting K-means have 44, 39, and 43 significant comparisons, respectively). We also find that the   p   values considerably depend on the observables. The permutation test result is strongly significant (i.e.,  ) for all the clustering methods and   K   values for the centroid position. In contrast, the number of significant combinations of the clustering method and   K   value is smallest for the coverage. Lastly, we do not observe a notable dependence of the permutation test result on   K  .   \nResults of the permutation test for the DMN extracted from the MSC data \n  \n* , uncorrected \n\n** , uncorrected \n\n*** , uncorrected (which is equivalent to\u00a0  p  <0.05, Bonferroni corrected). We remark that \u201cCentroid\u201d and \u201cTrans. prob.\u201d abbreviate the centroid\u2019s position and the transition probability matrix, respectively \n  \n\n\n### Robustness tests \n  \nFor validation, we also estimated the state-transition dynamics for the whole-brain network extracted from the MSC data. We show the results for the permutation test in Table\u00a0 . The results are similar to those for the DMN. In particular, the centroid position is the most effective among the five observables at distinguishing between the within-participant and between-participant comparisons, and the coverage is the least effective.   \nResults of the permutation test for the whole-brain network extracted from the MSC data \n  \n* , uncorrected \n\n** , uncorrected \n\n*** , uncorrected (which is equivalent to  , Bonferroni corrected) \n  \n\nTo examine the robustness of the proposed method with respect to fMRI experiments, we also ran the same permutation test for a whole-brain network obtained from the resting-state HCP data. Note that, among various parameters, the TR for the HCP data (i.e., 0.72 s) is substantially different from that for the MSC data (i.e., 2.2 s). It should also be noted that we use different atlases for the MSC and HCP data. While this decision is convenient for us because we have been using the obtained ROI-based fMRI data in different projects, it allows us to investigate the robustness of the proposed methods with respect to the atlas. The results, shown in Table\u00a0 , are similar to those for the DMN and whole-brain networks extracted from the MSC data. However, the permutation test results were stronger for the HCP than MSC data (i.e., a larger number of significant comparisons among the 135 comparisons). In particular, the frequency, lifespan, and the transition probability matrix as well as the centroid position yielded the smallest possible   p   value (i.e.,  ) for all pairs of the clustering method and   K   value.   \nResults of the permutation test for the whole-brain network extracted from the HCP data \n  \n* , uncorrected \n\n** , uncorrected \n\n*** , uncorrected (which is equivalent to  , Bonferroni corrected) \n  \n\nMoreover, as we noted earlier, our main definition of the centroid dissimilarity relies on the (dis)similarity between   and   only in terms of the direction. Therefore, we reran the permutation test by replacing the centroid (dis)similarity by the WCSS to measure the average distance between   and  . This change not only affected the discrepancy measure between two sessions in terms of the centroid position but also the discrepancy between pairs of sessions in terms of the other four observables (i.e., coverage time, frequency of appearance of each state, average lifespan, and transition probability matrix). This is because changing the discrepancy measure for cluster centroids affects how the set of centroids (and therefore clusters) is matched between two given sessions. We confirmed that the permutation test results with the WCSS is similar to those with   (see Additional file  : section S4). In particular, the   p   values were overall small, the results tended to be more significant for the K-means and bisecting K-means than for the TAAHC, and for the centroid position and the transition probability matrix than for the other three observables. \n\nLastly, we employed a 59-ROI DMN [ ] extracted from MSC data to further assess the impact of the dimension reduction. We found that results of the test\u2013retest reproducibility are roughly as good as those with the 12-ROI DMN (see Additional file  : section S5). \n\n\n\n## Discussion \n  \nWe carried out a comparative study of methods to cluster volumes of the fMRI to extract time series of the system\u2019s state, akin to microstate analysis for EEG and MEG data, for each recording session. We found that aggregating the symmetrically located ROIs into one ROI and then conducting the global signal removal yielded a high accuracy of clustering in terms of the total GEV and WCSS. We obtained total GEV values that are somewhat larger than those obtained in previous studies for EEG microstate analysis [ ,  ,  ,  ], which suggests that fMRI state-transition dynamics analysis may be promising. Furthermore, by carrying over the three clustering methods yielding the best clustering performance to a test\u2013retest reliability analysis, we found that, for different fMRI data sets and different networks, test\u2013retest reliability was higher in the within-participant comparison than the between-participant comparison. This result held true for most combinations of the number of clusters,  , and index quantifying the estimated state-transition dynamics. We also found that the K-means clustering yielded the highest test\u2013retest reliability among the three clustering methods. The present results suggest that clustering-based analysis of state-transition dynamics, which is substantially simpler than the hidden Markov model [ \u2013 ,  \u2013 ,  ,  ] and the energy landscape analysis [ \u2013 ], may be a sufficiently competitive method to derive state-transition dynamics in fMRI data. \n\nThe microstate analysis was originally proposed for EEG data [ \u2013 ,  ,  ,  ]. Microstates in EEG data are typically of the order of 100 ms. One cannot directly associate the discrete states estimated from fMRI data with EEG or MEG microstates because the time resolution of fMRI data is much lower than 100 ms; a typical TR is approximately between 1 and 3\u00a0s. Furthermore, the typical duration of a discrete state is longer than one TR. For example, the average lifespan of a state was 3.3 TR, 2.5 TR, and 2.2 TR when we estimated four, seven, and ten states, respectively, for the DMN extracted from the MSC data. Therefore, cognitively or physiologically relevant discrete states estimated for fMRI data [ ,  ,  ] may be different from those captured by microstates in EEG and MEG data. However, promising correspondences between EEG microstates and fMRI states have been reported [ ,  ,  ,  ]. Analyzing simultaneously recorded EEG-fMRI data may further reveal connection between EEG microstates and discrete states for fMRI data [ ,  ,  \u2013 ]. \n\nWe examined test\u2013retest reliability of discrete states estimated by clustering activity pattern vectors of fMRI data. In contrast, various previous studies estimated discrete states by clustering functional networks from fMRI data [ ,  \u2013 ,  ,  ,  \u2013 ]. Our methods of test\u2013retest reliability analysis do not depend on how the discrete states are estimated and therefore are applicable to the case of state-transition dynamics of functional networks. To the best of our knowledge, no work has systematically compared the reliability between state-transition dynamics estimated for spatial activity patterns or their vectorized versions and those estimated for functional networks from the same fMRI data. Such a comparative analysis may better inform us whether activity patterns or functional networks are more powerful biomarkers than the other when combined with state-transition dynamics modeling. In a similar vein, the aforementioned studies pursuing similarity between EEG microstates and fMRI dynamic states have been confined to the case in which fMRI dynamic states are estimated from dynamics of functional connectivity, not dynamics of activity patterns. These topics warrant future work. \n\nIn EEG microstate analysis, it is common to generate global microstate maps, which is to determine a given number of microstates by clustering candidate EEG maps obtained from different participants altogether. Then, one matches the obtained microstate maps shared by all the participants to the individual EEG maps from the individual participants to determine the microstate dynamics for each participant [ ,  ,  ,  ,  ]. For EEG data, this approach has been shown to accrue higher reliability than microstate maps estimated separately for individual participants [ ]. Nevertheless, we have estimated the states separately for individual participants (and for individual sessions) in the present study. This is because, for fMRI data, one often estimates state dynamics separately for each individual, which allows one to study subject variability of the estimated state dynamics or to exploit it [ ,  ,  ,  ]. In contrast, pooling fMRI data from different participants to generate across-participant templates of discrete states is also a common practice [ ,  ,  ,  ,  ]. In fact, one can run our test\u2013retest reliability analysis even if we estimate the templates of the discrete states shared by all participants, with the exception of the cluster centroid,  , as an observable of the estimated state dynamics; if we use a shared template,   is the same for all sessions and individuals and therefore one cannot compare its reliability within versus between participants. We point out that comparison of the reliability between shared templates and individualized templates of discrete states for fMRI data, as was done for EEG data [ ], is underexplored. \n\nWe ran a permutation test to statistically compare the within-participant and between-participant test\u2013retest reliability. This permutation test is an adaptation of what we recently developed for energy landscape analysis [ ] to the case of clustering-based state-transition dynamics. This method is not limited to fMRI data. It is straightforward to use it for EEG and MEG microstate data analysis obtained from multiple participants and multiple sessions per participant. Our code is publicly available on GitHub [ ]. The only requirement is to define observables and to be able to measure the discrepancy in the observable between an arbitrary pair of sessions. Assessing test\u2013retest reliability in EEG [ ,  \u2013 ] and MEG [ ,  ] data using this technique as well as furthering the application to fMRI data in health and disease may be fruitful. \n\n\n\n### Supplementary Information \n  \n\n\n\n \n", "metadata": {"pmcid": 10913599, "text_md5": "43d974f5dd292169775d166a4235b73d", "field_positions": {"authors": [0, 116], "journal": [117, 129], "publication_year": [131, 135], "title": [146, 277], "keywords": [291, 375], "abstract": [388, 1843], "body": [1852, 55695]}, "batch": 1, "pmid": 38438838, "doi": "10.1186/s12868-024-00854-3", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10913599", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=10913599"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10913599\">10913599</a>", "list_title": "PMC10913599  State-transition dynamics of resting-state functional magnetic resonance imaging data: model comparison and test-to-retest analysis"}
