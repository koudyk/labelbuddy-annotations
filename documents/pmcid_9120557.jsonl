{"text": "Gupta, Sukrit and Lim, Marcus and Rajapakse, Jagath C.\nHum Brain Mapp, 2022\n\n# Title\n\nDecoding task specific and task general functional architectures of the brain\n\n# Keywords\n\nbrain decoding\ndeep learning\nfunctional connectivity\nfunctional MRI\ntask general architecture\ntask specific architecture\n\n\n# Abstract\n \nFunctional magnetic resonance imaging (fMRI) is used to capture complex and dynamic interactions between brain regions while performing tasks. Task related alterations in the brain have been classified as task specific and task general, depending on whether they are particular to a task or common across multiple tasks. Using recent attempts in   interpreting   deep learning models, we propose an approach to determine both task specific and task general architectures of the functional brain. We demonstrate our methods with a reference\u2010based decoder on deep learning classifiers trained on 12,500 rest and task fMRI samples from the Human Connectome Project (HCP). The decoded task general and task specific motor and language architectures were validated with findings from previous studies. We found that unlike intersubject variability that is characteristic of functional pathology of neurological diseases, a small set of connections are sufficient to delineate the rest and task states. The nodes and connections in the task general architecture could serve as potential disease biomarkers as alterations in task general brain modulations are known to be implicated in several neuropsychiatric disorders. \n  \nTask\u2010related alterations in the brain have been classified as task\u2010specific and task\u2010general, depending on whether they are particular to a task or common across multiple tasks. Using recent attempts in deciphering deep learning models, we propose an approach to determine both task\u2010specific and task\u2010general architectures of the functional brain. We demonstrate our methods with a reference\u2010based decoder on deep learning classifiers trained on 12,500 rest and task fMRI samples from the Human Connectome Project (HCP).   \n \n\n# Body\n \n## INTRODUCTION \n  \nThe study of functional self\u2010organization of the human brain during task performance is a widely researched area in cognitive neuroscience. There is significant functional modulation in the brain during task performance (Fox et al.,\u00a0 ). Two types of task evoked alterations are known to shape brain states: task specific and task general alterations (Cole, Bassett, Power, Braver, & Petersen,\u00a0 ; D\u00fczel et al.,\u00a0 ; Norman & Shallice,\u00a0 ; Nyberg et al.,\u00a0 ).   Task general   alterations are task independent alterations in the brain that occur across multiple tasks whereas   task\u2010specific   alterations depend on the particular task being performed. \n\nAging (Meinzer et al.,\u00a0 ) and multiple neurological disorders such as major depressive disorder (MDD) (Hamilton et al.,\u00a0 ; Knyazev et al.,\u00a0 ), attention deficit hyperactivity disorder (ADHD) (Mills et al.,\u00a0 ), mild cognitive impairment (MCI) (Melrose et al.,\u00a0 ), and schizophrenia (Haatveit et al.,\u00a0 ) have been characterized by anomalous task general architecture. Task general alterations are further classified as   task positive   and   task negative  , depending on whether the neurons and their connections in a region are activated or deactivated during the task performance. We model the alterations in the brain functional connectivity as   positive task general   and   negative task general   depending on the presence or absence of functional connectivity during task states relative to the rest\u2010state. \n\nAdvances in neuroimaging have made it easier to study dynamic in vivo changes in regional relationships during different task and the rest state. Multiple studies have investigated the modulations in brain functional architecture during task performance. Betti et al.\u00a0( ) used group averaged connectivity from magnetoencephalography (MEG) and fMRI scans for 12 subjects to recover rest and task functional connectivity and study the alterations during rest and task. They concluded that although the resting\u2010state and task network interactions had similar network topography, clear differences existed in the frequency domain. Krienen, Yeo, and Buckner\u00a0( ) acquired task fMRI data from 48 subjects for 14 distinct sub\u2010tasks (grouped into passive, sensory, and motor tasks) and by performing correlation and seed\u2010based analysis on the group averaged data, found that the task modulations varied around a common central tendency across all task states. Cole, Bassett, et al.\u00a0( ) used two task datasets, one containing 64 tasks and the other containing 7 tasks (from the Human Connectome Project), and found that the central tendency for each functional connection during varied tasks was the one represented during the rest state. They found that a stable intrinsic functional network architecture that is present across rest and tasks, and a few but statistically significant alterations had shaped task states. In another study, Cole, Ito, Bassett, and Schultz\u00a0( ) selected the first principal component of task activation to detect task general architecture. These studies suggest that although there are small\u2010scale alterations in the brain functional architecture, there is an intrinsic stable functional backbone that remained unchanged during both the rest and task state (Betti et al.,\u00a0 ; Cole, Bassett, et al.,\u00a0 ; Krienen et al.,\u00a0 ). \n\nAlthough multiple recent studies (Gordon et al.,\u00a0 ; Gratton et al.,\u00a0 ; Xie et al.,\u00a0 ) have depicted the role of subject\u2010level characteristics, most previous efforts studying alterations in functional connectivity involved studying alterations at the group level. Gratton et al.\u00a0( ) used data for nine subjects with 10\u00a0hr of scan data per subject (10 scans of 1\u2009hr each containing resting state and four task states) from the Midnight Scan Club (Gordon, Laumann, Gilmore, Newbold, et al.,\u00a0 ) and studied the dependence of functional connectivity on task states, subjects, and scan sessions. They found that while the task states and the sessions shaped the functional connectivity patterns, common organizational principles, and subject\u2010specific features had a higher impact. Similarly, Xie et al.\u00a0( ) used task fMRI scans and k\u2010means clustering to separate the effects of subject\u2010level functional connectivity and tasks to determine what caused changes in group functional connectivity. They found that subject\u2010level functional connectivity was the most dominant factor in group\u2010level functional connectivity variability. These results, combined with previous studies on resting state brain functional architecture pointing towards significant intersubject variability (Finn et al.,\u00a0 ; Gordon et al.,\u00a0 ; Gordon, Laumann, Adeyemo, & Petersen,\u00a0 ; Mueller et al.,\u00a0 ; Wang et al.,\u00a0 ) that necessitates consideration of subject variability in the functional connectome while studying alterations during task performance. However, earlier studies had only considered group\u2010level functional connectivity. In this study, instead of studying group level alterations, we investigate intersubject variability by explicitly modeling subject\u2010level alterations. \n\nAnother concern with previous studies is that they only captured linear relationships between functional connectivity at rest or at task. In a recent study, He et al.\u00a0( ) used resting state functional connectivity to predict behavior by using traditional machine learning algorithms and multiple deep neural networks (DNNs) proposed for functional connectivity based analysis. They demonstrated that kernel regression applied on functional connectivity was sufficient and DNNs did not bring additional value as far as predicting individual behavior was concerned. We test this with classification of rest and task functional connectivity by using traditional supervised learning models along with the highly parametric DNNs. We trained classifiers on both models on individual subject rest\u2010state and task state data, and thereafter distinguished features responsible for different tasks from the trained model. We refer to identification of salient features of the network as decoding (different from the decoding performed in autoencoders). We found that although all classifiers gave a high accuracy for classification, DNNs were able to classify with a better accuracy than the shallow models such as support vector machines (SVM). We uncover the task general architecture by decoding a binary classifier trained for classifying rest and multiple task states. Using such obtained task general architecture, we demonstrated decoding of task specific brain architectures for the motor and language tasks. \n\nRecent attempts have been made to evaluate the salience given to input features of neural network models classifying neuroimaging data. Jang, Plis, Calhoun, and Lee\u00a0( ) used the trained weights in different layers of a feedforward neural network and mapped them to four sensorimotor task states. Several works using a gradient\u2010based decoder with different neural network architectures have culminated. Using a gradient\u2010based decoder on a trained long short\u2010term memory recurrent neural network, Li and Fan\u00a0( ) identified functional signatures in rest and task states. Floren, Naylor, Miikkulainen, and Ress\u00a0( ) identified brain regions involved in different visual processing tasks. However, these studies did not validate their derived feature set and issues like gradient saturation and discontinuities due to bias terms have not been addressed before using gradient\u2010based decoders on neural networks (Shrikumar, Greenside, & Kundaje,\u00a0 ). \n\nRecent methods such as Integrated Gradients (Sundararajan, Taly, & Yan,\u00a0 ), DeepLIFT (Shrikumar et al.,\u00a0 ), and SHAP (Lundberg & Lee,\u00a0 ) attempt to ameliorate the issues with gradient\u2010based approaches. These approaches find contributions of the neurons at each layer from those at the output layer and then backpropagate the contributions of all the layers to the input layer. DeepLIFT is one of the approaches that gives consideration to both negative and positive contributions, and computes the salience scores efficiently in a single pass, thus addressing the issues confounded in gradient based approaches. Gupta et al.\u00a0( ) used a DeepLIFT based decoder to derive salient features for distinguishing Alzheimer's disease and Autism patients from cognitively normal subjects. In the present article, we use DeepLIFT to study the microscale and mesoscale brain alterations that shape task related alterations in the brain (Cole et al.,\u00a0 ). We used the state\u2010of\u2010the\u2010art resting state and seven\u2010task fMRI data from the Human Connectome Project (HCP) dataset to demonstrate our methods. \n\nUsing functional connectivity between brain regions as inputs to train DNN, we made the following novel contributions in this work:   \nWith our experiments on different models for rest versus task classification, we show that DNNs outperform simpler models such as SVM even with a few training samples. However, the classification accuracy of SVMs improves with more training data. \n  \nWe proposed a novel method that uncovers salient task general and task specific functional brain architectures. The task related architectures detected by our method were validated with previous studies. \n  \nWe show that although there is pronounced intersubject variability in task related brain architectures, the small subset of detected features identified by our method were able to provide near 100% classification accuracy while distinguishing tasks from the rest states. \n  \n\nUsing feature salience scores, we identified functional connections and functional modular interactions that characterize task general, and motor and language task specific architectures of the brain. We discovered widespread system reorganization during task performance and were able to classify the rest versus all tasks, rest versus motor task, and rest versus language task with high accuracies by using a five\u2010layer feedforward DNN. The high classification accuracy was maintained even while taking only a subset of decoded features classified as highly salient by our decoder. We confirmed that the default mode network (DMN), commonly known for its deactivation during task performance, formed positive correlations with the salience network (SN) (Elton & Gao,\u00a0 ). Similarly, we found an important role for the regions in the motor sub\u2010systems for performing the motor task and left lateral temporal regions in performing the language task (Binder et al.,\u00a0 ). \n\n\n## METHODS \n  \nLet brain functional network   G  \u00a0=\u00a0(\u03a9,   A  ) where \u03a9 denotes the set of brain regions of interest (ROI) or nodes and   A  \u00a0=\u00a0{  a  }  denotes the adjacency matrix of functional connectivity between different ROI. We obtained a symmetric   A   for each fMRI scan and input features   x   for the feedforward DNN were obtained by taking only the lower half of elements of the adjacency matrix. We used rest and task data gathered on healthy subjects in the HCP. \n\n### Feedforward   DNN  \n  \nFor each subject, we obtained (  x  ,   d  ) where   x  \u00a0=\u00a0(  x  ) is the input features and   d   is the task label. The output   y   of the DNN gives the probability of the input belonging to one of the labeled task classes from Table\u00a0 . We consider a DNN of   L   layers with   L  \u2009\u2212\u20091 rectified linear unit (ReLU) layers and a final softmax layer. \n  \nSummary of HCP task and resting state data \n  \nLet the weights and biases of the layer   l   be given by   W   and   b  , respectively. The output   h   of layer   l  \u2209{0,   L  } is given by \n\nFor the input layer   l  \u00a0=\u00a00,   h  \u00a0=\u00a0  x  . For the output softmax layer   l  \u00a0=\u00a0  L  , the output   y   is given by the probability of a sample   x   belonging to class   k  : where   k   \u2208{1, \u2026,   K  } represents the class label, the output layer weight   W  \u00a0=\u00a0[  w  ], and bias   b  \u00a0=\u00a0(  b  ). \n\nTo learn the parameters of the network, the cross\u2010entropy cost   J  (  \u03b8  ) was minimized: where   E   is expectation taken over all the scan samples   x   and   denotes all the parameters in the network. We used minibatch stochastic gradient descent learning with a fixed learning rate to learn the parameters   \u03b8  . \n\n\n### Salience of input features \n  \nLet   f   be neural network function mapping input   x   to output   y  . Let   g   be a simpler   explanation model   that is interpretable and an approximation of the network mapping   f  . Let the number of neurons in layer   l   be   n  . Using an appropriate reference, let us assign to each neuron   i   at layer   l   its contribution   to the change in the output of neuron   k   at layer   l  \u2009+\u20091. Then, the change \u0394  h   in the activation of the   i  th neuron of layer   l   due to the input relative to the reference is given by when   and when   l  \u00a0=\u00a0  L  \u2009\u2212\u20091. \n\nIn order to determine the feature salience scores, we evaluate three types of references; namely sample mean, sample mode, and taking a sample which has the least   L   norm from the rest of the samples. We empirically determined the mean reference   to be the most representative of the samples. Given the reference input   and the original input   x  , we can substitute   and   g  (  x  )\u00a0=\u00a0  f  (  x  ), giving us an equation for the model   g  : where the contribution of neurons in each layer   l   to the output   y   is given by   (Shrikumar et al.,\u00a0 ): where   can be computed from the Linear, Rescale, and RevealCancel rule (Shrikumar et al.,\u00a0 ). We can get contribution of neurons in all layers 0\u2009\u2264\u2009  l  \u2009<\u2009  L   to the output   y   by backpropagating contributions of layers to the input, using the chain\u2010rule given by Equation\u00a0( ). \n\nThe   salience scores c   for the input layer are evaluated as   such that each element gives the contribution of the corresponding input to the changes of the output. The DeepLIFT method (Shrikumar et al.,\u00a0 ) implements computation of feature salience scores based on the changes of the output from a reference input, allowing information to propagate across the network layers even when the gradient is zero. We compute feature importance scores using Equation\u00a0( ): \n\nThe salience vector   c   represents the salience scores for the input features. The input features constitute the lower triangular matrix of the adjacency matrix. Vector   c   is mapped to a salience matrix   S  \u00a0=\u00a0{  s  }  where   s   represents the salience of the connectivity between ROI   i   and   j  . \n\nWhile the salience matrix   S   from the DeepLIFT algorithm gives the salience of all connectivity features, we establish the validity of the decoded features by performing recursive feature elimination based on the salience scores of the features. If the features identified by the DeepLIFT based decoder are indeed salient, a subset of the most salient features will also give a high classification accuracy. In fact, recent work by the authors based on the premise that only a subset of regions and function connections are involved in task performance has shown promise (Gupta et al.,\u00a0 ). \n\nThe input features that were insignificant were recursively removed by choosing connections whose salience |  s  |\u2009<\u2009  t   between brain regions   i   and   j   less than a threshold   t   and the neural network was retrained on the reduced feature set. The threshold was correspondingly set at the 90th percentile of significance. We repeated this experiment until only 0.1% initial features were left. We did not go below 0.1% as that corresponded to \u224834 features that were sufficient to give an accuracy close to the initial accuracy with all the features. The recursive elimination of irrelevant features not only tests the validity of the features identified by the decoder but also gives us the minimal subset of features needed for the classification. \n\n\n### Decoding the task general brain architecture \n  \nWe define decoding functional brain connectivity as identification of salient functional connectivity features that are crucial for classifying different brain states. The classification models are built using functional connectivity features for rest and task data while the DeepLIFT algorithm is used to find the salience of connectivity features. \n\nCole, Bassett, et al.\u00a0( ) used two task datasets, one containing 64 tasks and the other containing 7 tasks (from the Human Connectome Project), and found that the central tendency for each functional connection during varied tasks was the one represented during the rest state. They found that a stable intrinsic functional network architecture that is present across rest and tasks, and a few but statistically significant alterations had shaped task states. In another study, Cole et al.\u00a0( ) selected the first principal component of task activation to detect task general architecture. These studies suggest that although there are small\u2010scale alterations in the brain functional architecture, there is an intrinsic stable functional backbone that remained unchanged during both the rest and task state (Betti et al.,\u00a0 ; Cole, Bassett, et al.,\u00a0 ; Krienen et al.,\u00a0 ). \n\nMultiple previous studies (Betti et al.,\u00a0 ; Cole et al.,\u00a0 ; Cole, Bassett, et al.,\u00a0 ; Krienen et al.,\u00a0 ) point to the presence of an intrinsic backbone that remains unchanged during task performance. They also point to a common set of alterations that shape task states. While a task state can be considered to be amalgamation of both task general and task specific brain modulations over the rest state, the task general modulations can be represented by a common set of connectivity features that distinguish the brain at rest and during varied task states. In our formulation, connectivity features are the inputs to the DNN classifier and the task general architecture is defined by salient input features classifying the rest task versus all the tasks. We hypothesize that if we classify the brain at rest and during multiple varied task states, then the set of most salient connectivity features distinguishing the rest versus all the tasks represent the task general architecture of functional connectivity. To test this hypothesis, we identified the features with high salience scores distinguishing between rest and multiple dissimilar task states. \n\nThe sign of salience   s   of a connection determines whether the   presence   or   absence   of functional connectivity between brain regions   i   and   j   leads to the differentiation of the rest\u2010state from the task states. This information is in turn used to derive positive and negative task general architectures such that the presence of a positive task general connection during tasks is crucial in differentiating the task states from the rest state and vice\u2010versa. We derived the task general architecture defined by the seven tasks in the HCP data. \n\n\n### Decoding the task specific brain architectures \n  \nOnce the task general architecture is derived, we obtain the task specific architecture with salient features obtained from a DNN trained to classify rest and the task under investigation. The salient features for the rest versus single task classification represent both task general and task specific brain modulations. We hypothesize that the salient connectivity features distinguishing a particular task from the rest represents both the task general and task specific architectures. Therefore, if we are able to compute task general architecture, we can derive the task specific architecture from the salient features of the DNN trained to classify some task and the rest state. \n\nIn order to demonstrate the determination of task specific architecture, we used the subject data from the motor and language tasks and performed classification for rest versus motor and rest versus language tasks. Let   S   denote the salience of connectivity features representing the task general architecture. If the salience of features in rest versus motor and rest versus language (containing both task general and task specific modulations) are denoted by   S   and   S  , respectively, then the motor and language task specific architectures are given by the salient features highlighted by   S  \u2009\u2212\u2009  S   and   S  \u2009\u2212\u2009  S  , respectively. \n\n\n### Salient interactions between functional modules \n  \nAlterations in brain functional architecture are often discussed in terms of changes between different brain functional modules. The brain is organized into functional modules consisting of brain regions involved in specialized functional tasks. We quantified the importance of interactions among different brain functional modules with   modular salience maps  . Given functional modules   a   and   b  , the salience of interactions   m   between them is obtained by \n\nThe modular salience map {  m  } represents the average salience of the nodal connections within (when   a  \u00a0=\u00a0  b  ) and between (when   a  \u2009\u2260\u2009  b  ) brain functional modules. The modular salience map provides a powerful framework to interpret and understand brain functional alterations in terms of how the interactions between different functional modules vary during different brain states (in this case, tasks). \n\n\n### Intersubject variability in task related functional architectures \n  \nMultiple studies have pointed out the pronounced intersubject variability in the brain functional architecture both during rest (Finn et al.,\u00a0 ; Gordon, Laumann, Adeyemo, Gilmore, et al.,\u00a0 ; Gordon, Laumann, Adeyemo, & Petersen,\u00a0 ; Mueller et al.,\u00a0 ; Wang et al.,\u00a0 ) and task performance (Gordon, Laumann, Gilmore, Newbold, et al.,\u00a0 ; Gratton et al.,\u00a0 ; Xie et al.,\u00a0 ). It is, therefore, important that the detected task general and task specific architectures consist of features that are stable across subjects. We measure the intersubject variability in the feature salience scores for different subjects as: where std measures the standard deviation of the salience scores over multiple subjects. The mean of the salience scores is given by salience vector   c   (given by Equation\u00a0( )). We perform regression on the mean of   c   and the variability   v   of the salience scores to understand the relationship between the two sets of values. \n\n\n\n## EXPERIMENTS AND RESULTS \n  \n### Dataset \n  \nWe experimented with data from the Human Connectome Project (HCP) (van Essen et al.,\u00a0 ), comprising of fMRI data from 897 healthy adults (mean age\u00a0=\u00a028.1\u2009years, 390 females). The HCP currently hosts one of the largest open databases of fMRI data. We used both the task evoked fMRI (tfMRI) for seven tasks and the rest\u2010state fMRI (rfMRI) data of healthy subjects, collected from a Siemens 3\u00a0T Skyra scanner with TR\u00a0=\u00a0720\u2009ms, TE\u00a0=\u00a033.1\u00a0ms, flip angle\u00a0=\u00a052 , FOV\u00a0=\u00a0208 \u00d7\u2009180\u2009mm, 2\u2009mm \u00d7\u20092\u2009mm isotropic voxel and 72 slices. We used the preprocessed data release that included removal of spatial artifacts, motion correction, intensity normalization, and denoising (Glasser et al.,\u00a0 ). We further processed the task data to fit a finite impulse response (FIR) model to each of the 24 subtasks for the seven tasks (emotion processing, gambling, language, motor, relational processing, social cognition, and working memory) and removed the mean task evoked activation from time\u2010series data. This step is necessary as these task related activations have been found to inflate task state functional connectivity inappropriately (Cole et al.,\u00a0 ), especially with fMRI data. We also removed the rest periods from the task related time series before computing functional correlations between them. \n\nTable\u00a0  summarizes the available data for each task and the rest\u2010state. The average number of time points for the task fMRI scans was 277. We divided each fMRI resting state BOLD scan of 1,200 time points into four scans of 300 time points each. From each of these truncated BOLD time series, we obtained four functional connectivity matrices. We obtained 690 subjects having scans for all seven tasks and the resting state since not all subjects had been able to complete every task and resting state scans. For each subject, by considering one for each encoding direction, we obtained eight resting state functional connectivity matrices and 14 task state matrices. \n\nFor each functional network, we selected anatomically and functionally diverse 264 ROIs identified by Power et al.\u00a0( ) and calculated the mean time series of all voxels within a sphere of radius 2.5\u2009mm to represent activation of each ROI. We considered the Pearson correlation between time\u2010series to derive the functional connectivity between the 264 ROIs covering the entire cerebral cortex. \n\n\n### Building the classifiers \n  \nUsing the functional connectivity between 264 ROIs identified by Power et al.\u00a0( ) as inputs, we trained classifiers on both task fMRI (tfMRI) and rest\u2010state (rfMRI) data. We ensured that all the resting state and task scans of a subject are either in the test or the train set. We used Tensorflow (Abadi et al.,\u00a0 ) and Keras (Chollet,\u00a0 ) python libraries to implement the DNN. Since there was a class imbalance with \u22489,650 task samples and \u22488,300 resting state samples, we also computed the mean absolute error (MAE), the mean of the absolute errors between the predicted outputs and the ground\u2010truth labels. We first split the dataset into a train and test set in the ratio 4:1 and then performed fivefold cross validation to select the best model parameters on the train set. We ensured that all the samples for each subject were either in the train or test set (and note that the samples from the same subject were in the same fold during fivefold cross validation). We implemented different classifiers using the feedforward neural networks (FFN), convolution neural network (CNN) (Brown, Kawahara, & Hamarneh,\u00a0 ; Meszl\u00e9nyi, Buza, & Vidny\u00e1nszky,\u00a0 ) and support vector machines (SVM). The details of the different configurations for the models can be found in the Appendix\u00a0 . \n\nFor all the experiments (rest vs. all tasks and rest vs. specific tasks), we found that all the classifiers achieved classification accuracy above 90% (refer Table\u00a0 ). However, SVM based classifiers gave lower accuracies while the FFN and CNN based classifiers gave similar accuracies for the same number of parameters. We, therefore, used FFN based classifiers with optimal hyperparameters for feature selection and decoding. We used the best FFN model after performing hyperparameter tuning on the train set for five different FFN parameter initializations. Since the accuracies for all the classifiers were high, we performed additional experiments to determine the time taken for error convergence for the SVM and the FFN classifiers and their performances for different subset of training samples (refer corresponding figures in the Appendix\u00a0 ). We found that the test performance for the FFN converged faster than the corresponding SVM classifier for all the cases (refer corresponding figures in the Appendix\u00a0 ). \n  \nPerformance of the FFN and the SVM (on the test set) for rest versus all task classification using different fractions of features (MAE denotes mean absolute error) \n  \n\n### Decoding the task general brain architecture \n  \nWe obtained the best set of hyperparameters for the rest versus all tasks classification as described in the previous section. For the best FFN model, the configuration is given in Table\u00a0 . Using the trained classifier, we computed the salience for the input connectivity features by using DeepLIFT. The salience scores were computed using samples from the train set. It was observed that the majority of features had positive salience (number: 31,381, range: 0 to 1891.6, average: 81.96\u2009\u00b1\u2009124.2) in comparison with features with negative salience (number: 3,335, range: 0 to \u2212259.60, average: \u221229.62\u2009\u00b1\u200931.42). The histogram for distribution of salience scores and the feature salience score matrix   S   are available in Appendix\u00a0  (Figure\u00a0 ). \n  \nParameters of the four layer FFN used for classification of rest versus all tasks and rest versus language task \n  \nIn order to validate the decoded task general architecture, we recursively eliminated the input features, using the salience scores obtained from the FFN on the train set (refer Table\u00a0 ). The connections in the task general architecture are shown in Figure\u00a0 . The modular salience maps highlighting the task general connections are shown in Figure\u00a0 . The functional modules were derived from Power et al.\u00a0( ). Connections with positive and negative salience scores in   S   correspond to positive task general and negative task general connections, respectively. Using salient modular interaction scores, we computed statistically significant interactions having   p  \u2010value <.05. We report significant task positive and task negative modular interactions in Table\u00a0 . It can be seen that the DMN, FP task control, and dorsal attention networks are involved in both task positive and task negative interactions. \n  \nPerformance of different classification models on the HCP data with five\u2010fold cross\u2010validation (the individual tasks were classified against the rest task) \n    \nThe decoded task general brain architecture obtained from consensus over multiple runs. Edge thickness corresponds to the number of runs these connections were classified as relevant for distinguishing rest and task states, and the node color corresponds to the node's modular membership \n    \nThe task general architectures in the brain at the modular level. The part figures (a: negative task general) and (b: positive task general) depict the modular salience matrices for negative and positive task general connections, respectively \n    \nSignificant task general modular interactions \n  \n\n### Decoding motor task specific brain architecture \n  \nIn the motor task adapted from Buckner, Krienen, Castellanos, Diaz, and Yeo\u00a0( ), participants were asked to either tap their left or right fingers, or squeeze their left or right toes, or move their tongue on cue. Each block of movement style lasted 12\u00a0s and is preceded by a 3\u2009s cue. In each run, there were 13 blocks of which there were two tongue movements, four hand movements, four foot movements and three 15\u00a0s fixation blocks. \n\nThe configuration of the best FFN model derived for classifying rest versus motor task is given in Table\u00a0 . We achieved an average accuracy of 99.65 and 97.82% by using all the features for the rest versus motor task with the FFN and SVM (linear kernel,   C  \u00a0=\u00a00.001) models, respectively. We show the results for the recursive feature elimination experiments with both FFN and SVM in Table\u00a0 . In order to obtain the task specific architecture, we used the salience scores of the connections for the rest versus motor task and subtracted the task general scores. We averaged the feature salience scores   S   for all the seeds and subtracted   S   from   S  . In Figure\u00a0 , we show the top 0.1% relevant task specific features corresponding to the motor task computed as consensus over multiple runs. \n  \nParameters of the five layer FFN used for classification of rest versus motor task \n    \nPerformance of the FFN and the SVM for rest versus motor task classification using different fraction of features \n      \nThe motor task specific architecture in the brain. Figure shows the top 0.1% task specific connections for the motor task. The edge thickness corresponds to the salience score and the node color corresponds to the node's modular membership \n  \nUsing the task specific salience scores, we obtained the module salience maps for both the positive and negative task specific features for the motor task (refer Figure\u00a0 a,b) and obtained the significant modular interactions (with   p  \u2010value <.05). The significant task specific motor modular interactions involved the somatomotor mouth, somatomotor hand, CO Task Control, Dorsal attention, and the FP Task Control modules (Table\u00a0 ). \n  \nSignificant modular interactions specific to the motor task \n  \n\n### Decoding language task specific brain architecture \n  \nThe language task was proposed by Binder et al.\u00a0( ), where participants were presented with short narrated stories and given a two\u2010alternative forced\u2010choice question about the topic of the story. The two runs that were interleaved with four blocks of a story task and four blocks of a math task. Story blocks presented brief sentences from Aesop's fables, followed by two\u2010choice questions querying the topic of the story, whereas math blocks were presented aurally and required the subject to compute addition and subtraction problems and chose the result among the two choices by a finger tap feedback. \n\nFor the rest versus language task, the best FFN configuration was the same as rest versus all tasks (given in Table\u00a0 ). For five seeds, we achieved an average accuracy of 99.86% using all the features for the language task classification. For the selected SVM model (linear kernel,   C  \u00a0=\u00a01.0), we were able to achieve a high classification accuracy with the whole feature set. We averaged the feature salience scores   S   for all the seeds and obtained the language task specific feature salience scores by subtracting   S   from   S  . The result of the recursive feature elimination experiments is given in Table\u00a0 . We computed the top 0.1% relevant language task specific features (shown in Figure\u00a0 ). \n  \nPerformance of the FFN and the SVM for rest versus language task classification using different fraction of features \n      \nThe language task specific architecture in the brain. Figure shows the top 0.1% task specific connections for the language task. The edge thickness corresponds to the salience score and the node color corresponds to the node's modular membership \n  \nSince the language network is not delineated clearly in the Power Atlas networks, we also computed the salience of connections between different anatomical regions by mapping regions from the Power atlas to regions in the Crossley atlas (Crossley et al.,\u00a0 ), with known anatomical labels, using their Euclidean distance. We computed the salience between the functional connectivity of different regions by averaging the salience for connections between multiple Power atlas regions mapped to the same region from the Crossley atlas (shown in Figure\u00a0 ). Using the task specific salience scores, we obtained the module salience maps for both the positive and negative task specific features for the language task (refer Figure\u00a0 c,d) and obtained the significant modular interactions (with   p  \u2010value <.05, shown in Table\u00a0 ). \n  \nThe salient anatomical connections for the task specific language architecture in the brain. The part figures (a: Language positive task specific) and (b: Language negative task specific) depict the salient connections between regions for the positive and negative language task specific connections, respectively \n    \nSignificant modular interactions specific to the language task \n  \n\n### Intersubject variability in task related architectures \n  \nWe measured the intersubject variability in the feature salience scores by considering the mean of the salience scores,   c  , and the intersubject variability   v   in the salience scores. The scatter plots for the normalized mean and standard deviation scores are given in Figure\u00a0 . While the green markers represent all the features, the decoded task general (Figure\u00a0 ) and task specific architectures (Figure\u00a0  for motor and (Figure\u00a0  for language task) are represented by features in blue color. Furthermore, we regressed salience scores against decoded task specific and task general feature values and found that a quadratic polynomial model (sum of squared errors for task general: 24.14, language task specific: 27.13, motor task specific: 47.19) was a better fit than a linear model (sum of squared errors for task general: 25.00, language task specific: 29.87, motor task specific: 49.33). The best fitted quadratic polynomials are shown with red curves in the figures. On computing the correlation between the mean   c   and the intersubject variability   c   in the salience scores, we found that these two are weakly but positively correlated (Pearson's correlation for task general\u00a0=\u00a00.43, motor task specific\u00a0=\u00a00.56, and language task specific\u00a0=\u00a00.21). It can be observed that the decoded task related architectures consist of features that have a high salience score and low variability across subjects. However, some features that were on the lower end of the salience scores and had a low variability across subjects were also included. This can be discerned from the fact that most of the decoded features are below the quadratic polynomial curve fit for the respective task. \n  \nIntersubject variability in task related architectures. Figures (a: Task general features; b: Motor task specific features; c: Language task specific features) shows the scatter plot for the mean and variability in the task general and task specific salience scores across subjects. The blue markers represent the decoded task related features selected and the red curve represents the quadratic polynomial regression fit for the selected features \n  \n\n\n## DISCUSSION \n  \n### Classification of rest and task brain functional scans \n  \nWe performed classification for rest versus all tasks and rest versus individual tasks (for tasks besides motor and language, refer to Appendix\u00a0 ) and found that deeper models are able to achieve a higher accuracy even with a small subset of connectivity features than the shallow models such as SVM. This points to the presence of nonlinear and hierarchical relationships between functional connectivity and the tasks, which were better captured by DNN. The decoded task related functional brain architecture is composed of a small set of functional connections that were realized through elimination of insignificant features. The small fraction of salient connections between brain regions was found to be capable of accurately distinguishing brain resting and task states. \n\nRecursive feature elimination experiments with SVM models deteriorated in classification performance when the connectivity features were reduced. This could be due to the fact that SVM models are not able to learn complex brain architecture due its shallow representations while DNN capture the complex and hierarchical relationships among functional connections. Our results differ from the results from He et al.\u00a0( ) which showed that simple models trained on functional connectivity could achieve comparable accuracy as complex deep models for their behavior prediction task. Also, our previous works (Gupta et al.,\u00a0 ,  ) using functional connectivity for disease prediction have shown that DNNs had a significantly better performance than SVM based shallow models for disease detection. \n\nAlthough we removed the resting state time segments from the time series of the task data, a limitation of this study arises from the fact that we did not consider the different subtasks in each task state separately. The subtasks exist in each state, were assumed to be similar to each other, and involved in similar cognitive processing. But these subtasks may invoke different brain regions. If we consider component tasks separately, we are left with fewer time points that leads to poor signal\u2010to\u2010noise ratio and could ultimately degrade detection of functional activity (Birn et al.,\u00a0 ). We, therefore, used the whole task scan as one specific task for our modeling. \n\nRecent studies have used salience backpropagation to prune the neural network neurons by removing irrelevant features to prevent network overfitting (Gupta et al.,\u00a0 ,  ). However, application of such methods for brain decoding does not succeed if individual variations are not properly accounted for. This is due to the heterogeneity in disease pathology across participants, whereby a small set of features cannot account for disease across all the participants in the ensemble. However from our results, we conclude that although healthy subjects have pronounced intersubject variability in functional architecture (Mueller et al.,\u00a0 ), a small set of common distinguishing features characterize task related alterations across subjects. From our experiments, we infer that there are roughly two sets of features in the selected task related architectures, one that had a high salience and high variability, and another that had a moderate salience and low variability. We inferred that these two together help classify the rest and task states with an almost perfect accuracy, with the former handling variations while the latter form a stable core connectivity across all tasks. This has an important implication in aging (Meinzer et al.,\u00a0 ) and detection of various neurological disorders that are characterized by impairments/alterations in the task general architecture. \n\n\n### Task general architecture \n  \nThe positive and negative task general alterations found by our approach do not refer to activations/deactivations of regions but to the presence or absence of the connectivity during task performance with respect to the rest state. We found that the positive task general modulations are more wide\u2010spread and apparent than negative task general modulations, that is, most of the salient task general connections during task performance are absent during rest (positive task general), while few salient task general connections are present during rest but absent during task (negative task general). It is to be noted that the positive and negative task general architectures only refer to the presence and absence of the connections during tasks and do not refer to the polarity (positive/negative) or magnitude (strong/weak) of the correlations. \n\nWith our recursive feature elimination experiments, we observed that although the classifier performance slightly deteriorated, the classifier was able to achieve more than 99% accuracy even with just 0.1% of initial number of features. For SVM, we also performed recursive feature elimination based on the corresponding weights obtained for the best SVM model (linear kernel,   C  \u00a0=\u00a00.001). The SVM classification accuracy dropped when feature set was reduced to 0.1%. The respective MAE and accuracies for both FFN and the SVM classifiers can be discerned from Table\u00a0 . The recursive feature elimination experiments validate the correctness of the salience scores derived from our decoder. More importantly, it derived a small subset of features that was sufficient to distinguish between the rest and task states across subjects. For the FFN, we obtained the consensus of the 0.1% (34) remaining connections from each run and show the decoded features in Figure\u00a0 . As seen, the task general salient connections consist of the DMN, fronto\u2010parietal (FP) task\u2010control, SN, cingulo\u2010opercular (CO) task\u2010control, and somatomotor hand modules. \n\nThe functional brain has been shown to be composed of groups of brain regions performing specialized tasks. In order to analyze the task general changes, we performed the analysis at the modular level, whereby each module contains regions performing similar task (Gupta & Rajapakse,\u00a0 ). We analyzed the task general changes between (and within) the modules and found that different interactions from the same module could be part of negative and positive task general alterations. For negative task general alterations, we found that it was primarily the connections of the regions in the DMN (posterior cingulate cortex, precuneus, medial prefrontol cortex, and middle temporal gyrus), the fronto parietal task control (prefrontol and intraparietal sulcus) and the salience (anterior insula and dorsal anterior cingulate cortex) modules that were altered. However, for positive task general, it is primarily the connections with the somatomotor mouth, the visual and the memory retrieval modules that were altered. It is well\u2010known that the cerebellum contains multiple somatomotor representations and relays information between the sensory neurons to the corresponding motor neurons in the cerebrum (Buckner et al.,\u00a0 ). Since all tasks involved visually presented cues and the participant responses by motor movement (finger tap in all except social cognition task which involved a verbal response), our results on the task general architecture have invariably included the modulations between the cerebellar, motor, and visual systems. \n\nThe DMN has been characterized as a \u201ctask negative\u201d network and it plays a role in extended support of internal mentation processes (Fox et al.,\u00a0 ; Kelly, Uddin, Biswal, Castellanos, & Milham,\u00a0 ) and observing internal and/or external environment (Gao, Gilmore, Alcauter, & Lin,\u00a0 ). The CO task control, FP task control, and the salience networks help in configuring the brain to different brain states, and configuring information processing in response to different task demands. These networks thus support varied cognitive functions including sensory perception and motor control. The FP task control network acts as a flexible hub for cognitive control facilitating special attention to trial specific information (Marek & Dosenbach,\u00a0 ) whereas the CO task control network maintains alertness during task performance and correction based on feedback from each trial (Cocchi, Zalesky, Fornito, & Mattingley,\u00a0 ). The salience network determines the importance given to different stimuli for the brain to act and is known to be widely activated across different tasks (Seeley et al.,\u00a0 ). Our results are thus in line with the widely known task related deactivations that are observed in the DMN (Buckner, Andrews\u2010Hanna, & Schacter,\u00a0 ) and the memory retrieval systems (Fox et al.,\u00a0 ; Power et al.,\u00a0 ) while the FP task\u2010control, CO task\u2010control and ventral attention systems are known for their task related activations (Cole, Repov\u0161, & Anticevic,\u00a0 ; Corbetta, Kincade, Ollinger, McAvoy, & Shulman,\u00a0 ; Power et al.,\u00a0 ). \n\n\n### Task specific architectures \n  \nWe investigated task specific modulations for tasks that involved more perceptual and fewer cognitive processing systems so that we did not only identify task specific modulations but also can also verify them. The task specific alterations for both the motor and the language tasks were found to be limited to primarily the somatomotor, attentional, task control, and the salience systems. \n\nFor the recursive feature elimination experiments with the motor task, the MAE improved with fewer features and the accuracy for classification with just 0.1% features was the highest (and close to 100%) for the FFN. For the SVM, the accuracy and MAE improved initially, but there was a deterioration when the feature set was reduced to 0.1%. As a result, we were able to find a set of 34 task specific connections from the FFN that were important for the classification task. These consist of correlations between the somatomotor hand, SN, dorsal attention, FP Task control, and DMN (prefrontal cortex) subsystems. Besides moving the hand and feet, the motor task also involved tongue movements. These are reflected in the connectivity of multiple systems with somatomotor hand and mouth systems being classified as crucial. While the FP task control (Zanto & Gazzaley,\u00a0 ) network is known to alter its functional connectivity with nodes of other networks based on task goals, the dorsal attention (Corbetta et al.,\u00a0 ) and the CO task control (Sadaghiani & D'Esposito,\u00a0 ) networks are involved in voluntary attention and are altered when directed attention and alertness is required. \n\nAs seen, the motor task specific alterations within visual, motor mouth and memory retrieval modules are reported as both positive and negative. It is known that the motor task leads to an increased local, within module functional connectivity and a decrease in global integration (Cohen & D'Esposito,\u00a0 ). Our results for the motor modules show that there is heterogeneity in how the within motor modules connections are altered, since some connections are positive task specific while others are negative task specific. This is noteworthy since the motor areas are known for their high within module functional connectivity during rest (Biswal, Kylen, & Hyde,\u00a0 ; Biswal, Zerrin Yetkin, Haughton, & Hyde,\u00a0 ) and that there is intrinsic information processing in these regions even in the absence of tasks or during rest (Biswal et al.,\u00a0 ; Cordes et al.,\u00a0 ; Greicius, Krasnow, Reiss, & Menon,\u00a0 ). The present results demonstrate that the performance of the motor task alters functional connectivity differently for different regions. It can also be seen that most of the negative motor task specific alterations were limited to connections within the respective module (motor, visual, FP task control, dorsal attention, and memory retrieval), which points to the absence of the connections during task performance. \n\nFor the language task, we performed recursive feature elimination and found that the accuracy for classification with just 0.1% features was higher than the accuracy for 100% features (refer Table\u00a0 ). However, the performance with SVM deteriorated with fewer features both in terms of accuracy and MAE. The top 0.1% language task specific features (shown in Figure\u00a0 ) are from the auditory (mostly left: L temporal), FP task\u2010control (angular L and right: R), DMN (inferior parietal L and R, and frontal), SN (anterior cingulum), somatomotor hand (post central gyrus), and visual (occipital lobe) subsystems. Anatomically, the most distinguishing connections were from regions in the supramarginal gyrus, occipital lobe, angular gyrus, lingual gyrus, cuneus, temporal gyrus, and the frontal orbital lobe. While the supramarginal gyrus, angular gyrus, lingual gyrus and cuneus are well known for their role in language and visual processing tasks, multiple studies (Binder et al.,\u00a0 ; Crinion, Lambon\u2010Ralph, Warburton, Howard, & Wise,\u00a0 ; Flinker, Chang, Barbaro, Berger, & Knight,\u00a0 ; Meschyan & Hernandez,\u00a0 ) have reported extensive activations in different areas of the temporal lobe along with areas in the lateral occipital lobe and the frontal lobe during language processing. The significant task specific language modular interactions involved the visual module (regions from the occipital lobe), the SN (anterior insula and dorsal anterior cingulate cortex), somatomotor hand, somatomotor mouth, dorsal and ventral attention modules, memory retrieval (precuneus and posterior cingulate cortex) modules (Table\u00a0 ). \n\nThus, we have not only shown that a small set of features is able to classify the rest and task states but also verified that these feature sets have been deemed important by previous studies. More importantly, our work inferred the task general and task specific architecture from fMRI scans. \n\n\n\n## CONCLUSION \n  \nWe detected task general and task specific brain architectures by decoding the DNNs trained to classify rest\u2010state and cognitive task states fMRI data. Using a small subset of functional connectivity between functionally diverse brain regions as features for a five\u2010layer feedforward DNN, we were able to reliably classify rest\u2010state and seven tasks and rest\u2010state from motor task scans of 690 subjects from the HCP with nearly 100% accuracy. Using a salience backpropagation based decoder, we identified connections that formed the task general and task specific brain architecture in the brain. We also studied what modular interactions are altered during task performance. We validated the results of our decoder by showing that a small subset of features deemed important by the decoder gives us a high accuracy. We also studied the intersubject variability in the task related functional architectures. Our method has a strong potential of replication in brain state classification and identification of distinctive biomarkers between the healthy and diseased brain states. \n\n\n## CONFLICT OF INTEREST \n  \nThe authors declare no conflicts of interest. \n\n\n## Supporting information \n  \n \n", "metadata": {"pmcid": 9120557, "text_md5": "077c41ac677ba640a69eed13b813da05", "field_positions": {"authors": [0, 54], "journal": [55, 69], "publication_year": [71, 75], "title": [86, 163], "keywords": [177, 298], "abstract": [311, 2057], "body": [2066, 53967]}, "batch": 1, "pmid": 35224817, "doi": "10.1002/hbm.25817", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9120557", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9120557"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9120557\">9120557</a>", "list_title": "PMC9120557  Decoding task specific and task general functional architectures of the brain"}
