{"text": "Kotchoubey, Boris and Pavlov, Yuri G.\nFront Neurol, 2018\n\n# Title\n\nA Systematic Review and Meta-Analysis of the Relationship Between Brain Data and the Outcome in Disorders of Consciousness\n\n# Keywords\n\nconsciousness\nimprovement criteria\nmeta-analysis\nminimally conscious state\nneurophysiological markers\nprognosis\npublication bias\nunresponsive wakefulness syndrome\n\n\n# Abstract\n \nA systematic search revealed 68 empirical studies of neurophysiological [EEG, event-related brain potential (ERP), fMRI, PET] variables as potential outcome predictors in patients with Disorders of Consciousness (diagnoses Unresponsive Wakefulness Syndrome [UWS] and Minimally Conscious State [MCS]). Data of 47 publications could be presented in a quantitative manner and systematically reviewed. Insufficient power and the lack of an appropriate description of patient selection each characterized about a half of all publications. In more than 80% studies, neurologists who evaluated the patients\u2019 outcomes were familiar with the results of neurophysiological tests conducted before, and may, therefore, have been influenced by this knowledge. In most subsamples of datasets, effect size significantly correlated with its standard error, indicating publication bias toward positive results. Neurophysiological data predicted the transition from UWS to MCS substantially better than they predicted the recovery of consciousness (i.e., the transition from UWS or MCS to exit-MCS). A meta-analysis was carried out for predictor groups including at least three independent studies with N\u2009>\u200910 per predictor per improvement criterion (i.e., transition to MCS versus recovery). Oscillatory EEG responses were the only predictor group whose effect attained significance for both improvement criteria. Other perspective variables, whose true prognostic value should be explored in future studies, are sleep spindles in the EEG and the somatosensory cortical response N20. Contrary to what could be expected on the basis of neuroscience theory, the poorest prognostic effects were shown for fMRI responses to stimulation and for the ERP component P300. The meta-analytic results should be regarded as preliminary given the presence of numerous biases in the data. \n \n\n# Body\n  \n\u2026the quality of methodological reporting in the social and behavioral science research literature is poor. Reports are often silent or ambiguous on important methodological and procedural matters making it difficult for the analyst to determine what was done. The metaanalyst who develops elaborate and detailed methodological criteria for study selection, therefore, will most likely find that study reports do not provide sufficient information for those criteria to be confidently applied. [Lipsey and Wilson ( ) (p. 22)] \n \nA systematic analysis of several published datasets can yield substantial new knowledge as compared with the data of each single experiment ( ). This insight, increasingly admitted during the last decades, underlies the use of meta-analyses and other kinds of quantitative reviews that can largely overcome the subjectivity and deliberateness of the \u201cgood old\u201d narrative reviews. The domain of the severe Disorders of Consciousness (DoC) is, however, still dominated by the latter genre. Thus a brief overview of journal publications about brain imaging data in DoC for the last 5\u2009years reveals that almost every fourth paper (exactly, 33 of the 137 papers) is a narrative review. Book publications further increase this number. \n\nThe notion DoC most usually includes two diagnostic entities: the vegetative state, or unresponsive wakefulness syndrome (UWS), and the minimally conscious state (MCS) ( ,  ). To the best of our knowledge, the first systematic analysis of neurophysiological data in DoC was devoted to the question whether these data confirm the reality of the distinction between UWS and MCS ( ). The authors came to the conclusion that there were no reliable differences in terms of neurophysiological variables (mainly EEG, PET, and fMRI) between the two diagnoses. \n\nHannawi et al. ( ) concentrated on brain imaging studies and performed a voxel-based meta-analysis of 13 PET and fMRI studies in DoC patients, in which the corresponding data were reported. The authors identified a number of structures whose resting state activity was significantly decreased in patients as compared with healthy controls. On the other hand, they did not find convincing differences between UWS and MCS, which was in line with Liberati et al. ( ). Kondziella et al. ( ) came, however, to a different conclusion that brain connectivity data in rest and under passive stimulation (but not in active instruction conditions) reliably differ between UWS and MCS. Unfortunately, inclusion criteria in this study were not completely clear; thus the question still remains open whether late event-related brain potential (ERP) components (P300, N400) can be regarded as indicators of cortical connectivity, and therefore, the authors should either include all P300 and N400 studies in their analysis (if they answer this question positively), or exclude all of them (if they answer it negatively), but instead, they included only some of them. The data were not checked for publication bias, that is, the tendency for positive results or stronger effects to get published more readily than negative results or weaker effects ( ). The simplest index of this bias is a negative correlation between the size of the obtained effect and its reliability ( ). On the other hand, Kondziella et al. ( ) indicated a bias in patient selection. The risk of this bias was estimated as \u201chigh\u201d in 81.4% of the analyzed studies and as \u201cuncertain\u201d in further 11.6%. \n\nAlso, Bender et al. ( ) were interested in the abilities of neurophysiological techniques to distinguish between UWS and MCS. Their meta-analysis aimed not at the presence and size of the effects, but at the parameters of sensitivity and specificity. The authors concluded \u201c\u2026 that modern diagnostic techniques can already make a major contribution to the diagnostic assessment of MCS.\u201d The inspection of their empirical findings yields a modest support for this conclusion, because good sensitivity and specificity values were found only for the measures of quantitative EEG; ERP and fMRI measures revealed, to the contrary, only moderate specificity and rather low sensitivity that did not significantly differ from chance. \n\nKotchoubey ( ) carried out a quantitative analysis of 61 reports on ERPs in DoC. ERPs are the most frequently used neurophysiological technique in DoC, which, however, does not mean that they are also most useful. In general, the results of the analysis were rather disappointing. Most studies possessed such a low statistical power that their findings can at best be regarded as \u201cpreliminary results.\u201d In addition, there was strong evidence for a publication bias toward positive findings. \n\nHowever, there were good news. The above-mentioned deficits mainly concerned the studies where ERPs were compared between UWS and MCS, which largely concurs with the conclusions of Liberati et al. ( ). The negative tendencies were substantially less expressed in the literature about the relationship between ERP and the prognosis of DoC outcome. Furthermore, the power of the prognostic studies correlated positively, and the effect sizes (ESs) correlated negatively, with the rank of journals where the data were reported. This indicated that weaker but more reliable effects could be published more successfully in top-ranking journals than strong but less reliable ones. \n\nLike all areas in which there is no golden diagnostic standard, meta-analyses of novel diagnostic tests in the domain of DoC have a strong circular component. The expensive neurophysiological techniques are developed to complement imperfect clinical methods and to increase the diagnostic precision; but in a meta-analysis, these novel techniques are evaluated on the basis of the same (presumably imprecise) diagnostic criteria that these methods should improve! The lack of the golden diagnostic standard makes another strategy more preferable, i.e., a search for the measurements most reliably related to prognosis. The above-cited findings, that prognostic studies in DoC appear to have a higher quality than diagnostic studies, are in line with this view. \n\nThe aim of the present study was a systematic analysis of all publications relating any functional brain data recorded in UWS and MCS patients to their outcome several weeks or months after the measurement. Data using only anatomical brain measurements were not included in the present analysis. Each of the analyzed publications will hereafter be designated as \u201crecord.\u201d The term \u201cdataset\u201d will, in contrast, refer to any individual comparison between a neurophysiological variable (e.g., fMRI activation in a specific task) and an outcome variable (e.g., Glasgow Outcome Scale\u2014Extended, or GOSE ( )). One record can, therefore, contain many datasets. \n\n## Methods \n  \n### Literature Search and ES Calculation \n  \nA search in MEDLINE and SCOPUS was conducted on the 23 November 2017 by using search terms ((prognos* OR predict* OR outcome) AND (vegetative state OR minimally conscious state OR unresponsive wakefulness syndrome)) AND (eeg OR fmri OR event related potentials OR erp OR positron emission). No time limits were set for the search. In addition, the systematic reviews cited above in the Introduction as well as recent informal reviews on neurophysiology of DoC, were consulted. Eight hundred ninety-seven peer-reviewed records published in English, German, or Russian, were identified. After reading abstracts and removing duplicates, 822 of them were rejected as irrelevant. Full test was sought for the other 76 records. Seven of them were rejected because they did not contain any outcome data on DoC patients, or contained outcome data already published elsewhere. Further exclusion criteria were (a) case studies or series of cases; (b) using patients\u2019 survival, and not the clinical improvement, as the only prognostic criterion; (c) presentation of the results in such a general form that the size of the observed effects cannot be calculated; and (d) reporting the data of UWS and MCS patients together with other diagnoses such as coma, exit-MCS, or locked-in syndrome: on the basis of these criteria 22 records were rejected. Regarding (d), we accepted studies in which UWS and MCS data were reported together, but not those in which the sample included more than these two diagnoses and the reported data did not give the reader a possibility to distinguish between the different diagnostic groups. The process of the selection of relevant records is shown in Figure  . \n  \nFlow chart of the selection of records. \n  \nThe search resulted in 47 records containing a total of 381 datasets. These records are summarized in Table  . Effect size was calculated for each dataset (i.e., for each predictor\u2013outcome pair) on the basis of primary data on each individual patient presented in the tables of most studies, or chi-squared based on the same patient data, or the   t  -statistics. Only in one record, ES was calculated from a coefficient of correlation. All these parameters were converted into Cohen\u2019s   d   following the methods summarized by Lenhard and Lenhard ( ). If a resulting 2\u2009\u00d7\u20092 table contained a zero cell (e.g., all patients having a positive neurophysiological sign recovered), the blind application of the corresponding formulas results in   d  \u2009=\u2009infinite; to avoid this, we added 0.5 to all cells, as recommended by Nakagawa and Cuthill ( ). When   d  -values were included in further operations (added, averaged, etc.), they were weighted by inverse standard error (SE). \n  \nA summary of the 47 records included in the systematic review. \n  \n N (UWS/MCS) means the number of UWS and MCS patients whose outcome and neurophysiological data were available. In the case of different number of patients available for different neurophysiological measurements, only the largest number is reported; it may be less than the total number of patients in the study  . \n\n NA, not available, AFR index, Amplitude/Frequency/Reactivity index; UWS, unresponsive wakefulness syndrome; MCS, minimally conscious state; EMCS, Exit form MCS; GOS(E), Glasgow Outcome Scale (Extended), GCS, Glasgow Coma Scale; DRS, Disability Rating Scale; LCF, levels of cognitive functioning scale; LoC, Level of Consciousness Scale; SEP, somatosensory evoked potentials; BAEP, brain stem auditory evoked potentials; dwPLI, debiased weighted phase lag index; SPECT, single-photon emission computed tomography; CRS-R, Coma Recovery Scale-Revised  . \n  \nA big and still underestimated problem of all quantitative reviews is the plenty of non-reported data. Several authors ( \u2013 ) indicated that measured but unreported variables constitute one of the main sources of false positive findings ubiquitous in biology and psychology and thus an important cause of the contemporary \u201creplication crisis\u201d ( ). When, and only when, it was evident for both present authors from the text of a paper that a neurophysiological variable was measured but not reported in relation to the outcome (or, rarely, reported as \u201cnon-significant\u201d), the ES of this variable was assumed to be 0, and the SE of ES was assumed to be equal to the median SE calculated for the reported variables in the same record. \n\nWhen the results presented several strongly correlated predictor variables (e.g., the same EEG variable in several adjacent regions), they were regarded as representing the same \u201cconstruct\u201d ( ), and the mean and standard deviation (SD) for the construct were calculated according to the formulas\n \nwhere   M   and   M  , SD  and SD  are mean and SD values for two to-be-combined variables, respectively. (Note that the formulas are so simple because both variables have the same   N  .) \n\n\n### Outcome Criteria \n  \nThe category \u201cbad outcome\u201d for UWS and MCS patients presumed remaining in the same condition. Deaths were included in this category only if it was clear that a patient died as a direct consequence of the brain lesion, otherwise excluded from the analysis. The category \u201cgood outcome\u201d has, on the other hand, two different definitions: minimal clinical improvement or regaining full consciousness.  For MCS, both criteria are the same, because their minimal improvement implies the transition to Exit-MCS. But this is not true for UWS, because their minimal improvement means only the transition to MCS. As shown in Section \u201c ,\u201d the two different improvement criteria of UWS yield different results. \n\nAvantaggiato et al. ( ) analyzed a group of DoC patients containing children and adolescents; because the authors presented individual data of each patient, we selected the results for patients >13\u2009years only. The category \u201cgood prognosis\u201d for MCS implied the recovery of consciousness. For UWS, however, it might include either the recovery of consciousness or the transition into MCS. All 381 datasets were included in the systematic review. \n\n\n### Quality Assessment \n  \nQuality of the records was estimated on the basis of the QUADAS criteria ( ) that have been tailored, as recommended in the original publication, for the specific research field. Because Kondziella et al. ( ) expressed concerns about possible bias in patient selection, we recorded whether a publication included a patient flow chart, and whether it described explicit exclusion criteria for UWS and MCS patients or simply mentioned that all patients admitted in the clinics for a particular time period were investigated. We also marked the records in which obviously more neurophysiological data were collected than reported in the analysis of outcome prediction. Another quality index was the use of the Coma Recovery Scale-Revised (CRS-R ( )) for DoC diagnostics, because this scale, though not being golden standard, possesses substantially better psychometric qualities than all other instruments for the assessment of DoC ( ). In addition, the impact factor (IF) of the publishing journal was included as an indirect quality criterion, because the data indicate high correlation between the IF and the informal reputation of the corresponding journal among neurologists ( ). \n\n\n### Meta-Analysis \n  \nTwo additional inclusion criteria for meta-analyses were (1) at least three independent records reporting the same predictor variable or variables related to the same construct and (2) each of these records includes at least 10 patients. The criteria can be regarded as very liberal because, first, only three records and only 10 patients (who further should be subdivided into at least two groups) are rather low numbers, and second, the notion of construct is rather vague and permits to include into one group, for example, studies of P300 to simple tones and to patients\u2019 own names, thus increasing heterogeneity. On the basis of these criteria, 319 datasets were excluded (of course, this number would be larger if the criteria were more conservative). The remaining 62 datasets finally entered the meta-analysis. \n\nWe used a random-effects meta-analysis with restricted maximum-likelihood (REML) estimator for pooling ESs. We assessed the level of heterogeneity between studies with a standard   Q  -test statistic as well as by   I   calculation ( ). Heterogeneity was regarded as significant when   p  \u2009<\u20090.05 or   I   >\u200950%. Potential publication bias for individual predictors was assessed with the Egger test for Funnel plot asymmetry and represented graphically with Begg\u2019s funnel plots of the ES versus its SE. Additionally, Rosenthal fail-safe test was also applied. All meta-analyses were performed using R package \u201cmetafor\u201d ( ) using inverted standard errors as weighting parameter. \n\n\n\n## Results \n  \n### Quality of Reporting \n  \nNone of the 47 records presented a flow chart depicting patient selection. The authors of 20 records (42.6%) explicitly state that they included all patients within some exactly described time period. Nine reports (19.1%) depicted at least some inclusion and/or exclusion criteria. In the remaining 18 records, patient selection was not described. \n\nMost selected records present their data either for each individual patient or as mean\u2009\u00b1\u2009SD (or SE) for each relevant group (e.g., recovered versus non-recovered). Three records present data only in a general form (e.g., as correlations). Five records (10.6%) mention the size of some effects. \n\nCRS-R was used for the diagnosis of UWS and MCS in 29 records (61.7%); other studies employed Disability Rating Scale, Glasgow Coma Scale, or other less powerful instruments. \n\nQuite surprisingly, only two records explicitly state that the neurologists who assessed the outcome were blinded to the neurophysiological data collected before. In six records, blindness of the outcome might be assumed because neurophysiological examination and outcome diagnostics were performed in different institutions. These eight records (17%) were combined into one \u201cblind\u201d group. In the majority of the records (83%), the outcome was diagnosed with knowledge of the neurophysiological findings. \n\nThe median time between the measurement and the outcome assessment was 6\u2009months, mean minimal time per record was 9\u2009months (range 1\u201336\u2009months), and the mean maximal time per record 16\u2009months (range 1.5\u2013150\u2009months). In 42 records (89%), this interval was same for all the examined patients. Seven records used broad variable intervals for different patients (1\u20136, 1\u201330, 2\u20139, 6\u201338, 10\u2013150, 26\u201336, and 24\u2013144\u2009months). One publication does not report the measurement\u2013outcome interval. \n\nThe mean total sample was 31.11\u2009\u00b1\u20093.66 patients, with a median of 21 patients and a range of 5\u2013123 patients. Eight records included <10 patients, 14 records had between 10 and 19 patients. Adding the case studies filtered out at the previous stage, we come to the result that about a half of all prognostic studies included <20 patients. The records that did not describe patient selection included significantly less patients (means 14.1 versus 43.0,   t  \u2009=\u20095.11,   p  \u2009<\u20090.001) than records describing their selection process. \n\nThe median IF of the publishing journals was 3.87, range from 0 to 44. IF did not differ between the records with correctly versus incorrectly described patient selection. We hypothesized that studies with more patients (thus having higher power) are published in more prestigious journals, but the corresponding correlation was not significant (Spearman\u2019s \u03c1\u2009=\u20090.26,   p  \u2009=\u20090.078). However, studies employing CRS-R were published in journals with higher IF than studies that did not use this scale:   p  \u2009<\u20090.001, Mann\u2013Whitney test. A few studies with blind outcome assessment included larger sample sizes than studies without outcome blindness (  t  \u2009=\u20092.35,   p  \u2009=\u20090.023) and were also published in more prestigious journals (  p  \u2009=\u20090.046, Mann\u2013Whitney test). \n\nNotably, we did not find a significant relationship between any of the variables and the time elapsed from the neurophysiological measurement till the assessment of the outcome. Non-weighted ES correlated with the mean time between neurophysiological measurement and outcome assessment with Spearman\u2019s \u03c1\u2009=\u2009\u22120.09, with minimal time per study \u03c1\u2009=\u2009\u22120.18, with maximal time per study \u03c1\u2009=\u2009\u22120.07 (all nonsignificant). For weighted ES, the corresponding correlations were 0.03, \u22120.06, and \u22120.11, respectively (all nonsignificant). Likewise, correlations of the time interval with the SD of ES (as a measure of its reliability) were all between 0.00 and 0.03, and correlations of the time interval with sample size were between 0.00 and 0.06, all non-significant. \n\nAlso, the year of publication did not correlate with any other measures. The bibliographic literature gives a reason to expect that later publications might have large samples or smaller ESs than earlier ( ). Although the corresponding correlations were in the expected direction, they did not reach significance (year/N: Spearman\u2019s \u03c1\u2009=\u20090.12; year/ES: \u03c1\u2009=\u2009\u22120.08). Also, the correlation between publication year and IF was close to 0 (\u03c1\u2009=\u20090.03). \n\n\n### Publication Bias \n  \nThe inverted SE (1/SE) was taken as a measure of the reliability of an ES. Across all datasets, the rank-order correlation between ES and its 1/SE was weak but significant (\u03c1\u2009=\u2009\u22120.22,   k  \u2009=\u2009381,   p  \u2009<\u20090.001). The result might be biased because different records contribute disproportionally to the whole mass of data. However, the positive correlation between the ES and its SE became even stronger when calculated for the selected subset of datasets included in the meta-analysis (\u03c1\u2009=\u2009\u22120.47,   k  \u2009=\u200962,   p  \u2009<\u20090.001), as well as for the ESs averaged for each record (\u03c1\u2009=\u2009\u22120.41,   k  \u2009=\u200947,   p  \u2009=\u20090.004). The results are shown in Figure  . \n  \nNegative correlations between effect size (ES) and its reliability, estimated by the inverted standard error (1/SE), for all individual datasets [  (A)  : Spearman\u2019s \u03c1\u2009=\u2009\u22120.22,   p  \u2009<\u20090.001], datasets included in the meta-analysis [  (B)  : \u03c1\u2009=\u2009\u22120.47,   p  \u2009<\u20090.001], and for mean ESs per record [  (C)  : \u03c1\u2009=\u2009\u22120.41,   p  \u2009=\u20090.004]. The regression lines are presented for illustration only, not for quantitative analysis. \n  \nNote that the first analysis (across all datasets) overestimates the contribution of the records reporting many datasets. The last analysis (across averaged ES), to the contrary, may overestimate the contribution of the records presenting few or only one dataset. Despite this contrary bias, very similar results were obtained. To sum up, these data show a trend to selective publication of strong but unreliable effects. How serious the bias is in respect of each particular predictor variable will be discussed below. \n\n\n### UWS and MCS \n  \nThirteen of the 381 datasets included only MCS samples, 248 datasets included only UWS patients, and the remaining datasets included both diagnostic groups of DoC patients. \n\nWhile the main issue of the present study was outcome prediction on the basis of neurophysiological data, we also asked the question whether the outcome can be predicted simply from the diagnosis. Many authors of the reviewed articles also asked this question and answered it negatively. However, a meta-analysis of the combined data from the records where both diagnosis and prognosis could be followed revealed that MCS patients recovered consciousness significantly more frequently than UWS patients (Figure  ): mean ES\u2009=\u20090.84, 95% CI from 0.61 to 1.06. On the other hand, if the positive outcome of UWS patients is defined as any minimal improvement, i.e., the transition to the MCS, the diagnosis loses its predictory value (Figure  ). \n  \nThe results of the meta-analysis for prediction of the outcome from the diagnosis. The criterion of improvement for all patients was recovery of full consciousness.   Q  , the corresponding   p  -value and   I   are estimates of between-study heterogeneity; symbols \u25a0 stay for the estimates of effect size (ES) in each single study, with the size of the symbol being proportional to the precision of the estimate. Error bars indicate the 95% confidence intervals of ES. The diamond \u2666 is the estimate of the overall effect, the edges of the diamond represent the 95% confidence interval limits; CI, confidence interval; UWS and MCS, sample size of UWS and MCS patients in individual studies; N_UWS and N_MCS, overall sample size of the two patient groups. The resulting ES was tested for significance using   z  -criterion; the values of   z   and the corresponding   p   are given at the end of the lower left line. \n    \nThe results of the meta-analysis for prediction of the outcome from the diagnosis. The criterion of improvement was \u201cminimal improvement,\u201d that is for UWS patients, it was the transition to MCS, and for MCS patients, at least the transition to Exit-MCS. As can be seen, with this improvement criterion the diagnosis does not predict outcome. The rest is the same as in Figure  . \n  \nBecause we found that the improvement criterion for UWS (transition to the MCS versus recovery of full consciousness, that is, exit-MCS) can play a role in the calculation of prediction effects, we compared weighted mean ES for the neurophysiological variables in three conditions: (i) prediction of the recovery of consciousness for MCS patients; (ii) prediction of the recovery of consciousness for UWS patients; and (iii) prediction of the transition to MCS for UWS patients. A one-way ANOVA across these three groups resulted in a highly significant effect:   F  (2,294)\u2009=\u200923.11,   p  \u2009<\u20090.001. The result does not change when we limit the analysis by only those datasets that will later enter the meta-analysis [  F  (2,60)\u2009=\u200919.88,   p  \u2009<\u20090.001], or when we exclude all mixed datasets [  F  (2,86)\u2009=\u200912.08,   p  \u2009<\u20090.001]. Independently of the method of calculation, the mean weighted ES for the groups (i) and (ii) (i.e., different diagnoses, the same improvement criterion) were very similar and varied\u2014dependent on the selected data\u2014between 0.41 and 0.48. The mean weighted ES for the group (iii) was about three times larger (between 1.40 and 1.68) and differed significantly from both of them, although the groups (iii) and (ii) included patients with the same diagnosis and some datasets involved in these two groups might even include some of the same patients. To sum up, neurophysiological methods are significantly more successful in prediction of the transition from UWS to MCS than in prediction of the recovery of full consciousness. \n\n\n### Meta-Analysis of Predictory Constructs \n  \nAccording to the above results, we performed the meta-analysis separately for (a) prediction of any clinical improvement (for which UWS patients means at least transition to the MCS), and (b) prediction of the recovery of full consciousness. Sixty-two datasets comprising a total of 1,919 patients were analyzed. They involved the following potential predictors:\n   \nEEG reactivity to \u201cpassive\u201d stimulation (i.e., without an active instruction). Hypothesis: stronger EEG oscillatory responses\u2009=\u2009>\u2009better prognosis. \n  \nEEG entropy indices. Hypothesis: higher EEG entropy\u2009=\u2009>\u2009better prognosis. \n  \nEEG dominant oscillatory activity. Hypothesis: background activity closer to the alpha frequency\u2009=\u2009>\u2009better prognosis. \n  \nEEG Synek score ( ) is frequently used in the intensive care medicine for the prognosis of the outcome of acute coma. Hypothesis: higher score\u2009=\u2009>\u2009better prognosis. \n  \nfMRI BOLD response to passive (auditory or nociceptive) stimulation. Hypothesis: stronger response\u2009=\u2009>\u2009better prognosis. \n  \nResting state PET or SPECT metabolism. Hypothesis: closer to normal brain metabolism\u2009=\u2009>\u2009better prognosis. \n  \nN20 component of somatosensory evoked potentials (SSEP). Hypothesis: normal N20\u2009=\u2009>\u2009better prognosis. \n  \nAuditory Mismatch Negativity (MMN) to a change in ongoing acoustic stimulation. Hypothesis: larger MMN\u2009=\u2009>\u2009better prognosis. \n  \nAuditory P300 as an index of complex processing in cortico-subcortical networks. Hypothesis: larger amplitude or shorter latency\u2009=\u2009>\u2009better prognosis. \n  \nSpindle activity as an index of information processing in sleep ( ). Hypothesis: presence of sleep spindles\u2009=\u2009>\u2009better prognosis. \n  \n\nThe findings are summarized in Figures   and   and presented in more detail in Figures S1 and S2 and Tables S2 and S3 in Supplementary Material. \n  \nThe results of the meta-analysis for prediction of the outcome from neurophysiological variables. The criterion of improvement for all patients was the recovery of consciousness. RE, random effects. The rest is the same as in Figure  . \n    \nThe results of the meta-analysis for prediction of the outcome from neurophysiological variables. The criterion of improvement for UWS patients was the transition to MCS, and for MCS patients, the recovery of consciousness. The rest is the same as in Figure  . \n  \nOnly oscillatory EEG responses to passive stimulation appear to be reliably related to both prognostic criteria (i.e., minimal clinical improvement and the recovery of full consciousness). The included datasets are highly homogenous and yield a highly significant mean ES of 1.45 on a sample of 99 patients. Another prediction variable that significantly predicted the recovery of consciousness was brain metabolism assessed by PET/SPECT. It attained a mean ES of 1.40 on a sample of 106 patients. The prognostic value of the MMN, P300, EEG entropy variables, and fMRI responses to passive stimulation was not significant and characterized by strong heterogeneity of the primary datasets. \n\nMore promising results have been obtained in relation to the minimal improvement criterion. In addition to the EEG reactivity, significant effects are found for the MMN and sleep spindles. Formally positive results are obtained for the SSEP component N20 and the background EEG frequency, but the data are too heterogeneous to make a conclusion. \n\n\n\n## Discussion \n  \nAlthough the Section \u201cLimitation\u201d is frequently placed at the end of Discussion, we believe that particularly the discussion of meta-analytic data is useful to begin with limitations. One important limitation is that of the present work as such. As the manuscript was prepared for a special issue, we did not systematically address the authors of the original publications but relied solely on the published data including supplementary information. Although we believe that personal contact with the authors may have enhanced our knowledge, at the first step we did not use this strategy because it might have caused considerable delays. \n\nOther limitations of the meta-analysis are rather related to the limitations of the primary literature. A quantitative review can overcome some limitations of the reviewed studies, e.g., their small size (thus, it can reveal a consistent and significant effect on the basis of several inconsistent and non-significant ones), but it cannot remove the biases implied in its empirical basis. \n\nTo begin with the least, the quality of data reporting is far from the present-day standard. While Fritz et al. ( ) bristled that only 42% of empirical psychological studies report the size of their effects, in the present sample ES was mentioned only in five records (10.6%). Presenting a patient flow chart is already a standard in many fields of clinical research but fully unknown in the domain of DoC. About a half of the reviewed records neither describe inclusion and exclusion criteria nor even make a simple statement that all patients admitted to the hospital during some period were included. Thus, the concern of Kondziella et al. ( ) about possible bias in patient selection seems to be justified. \n\nThe majority of the reviewed studies employed a univariate approach, i.e., each predictor was separately compared with the target variable. Of course, this is a serious limitation because we know that the values of a regression strongly depend on the other predictor variables included or excluded in/from the equation. Thus, a neurophysiological variable (e.g., P300), which appears useless as a single predictor, might reveal its effect in a particular combination with other predictors. A few groups have recently attempted to overcome this limitation and employed a multivariate approach to outcome prediction in DoC ( ,  ). This seems to be a perspective line of research, but now the number of such records is still too low to undertake a separate meta-analysis of these data. \n\nThe negative correlation between the description of patient selection and the number of patients suggests that selection bias might be particularly strong in small-size studies. Although the sample size in prognostic studies is on average larger than in studies comparing UWS and MCS, we found, together with single case studies, 33 records with less than 20 patients, which implies that even in the case of the equal distribution at least one of the outcome groups (recovered or non-recovered) includes <10 patients. Particularly, the studies with the total   N  \u2009<\u200910 result in huge confidence intervals making any reliable conclusion impossible. Of course, small or even single case studies may have sense at the very beginning of the research process, when nothing is known about an investigated phenomenon whatsoever. However, in such a case, one can expect an increase of sample sizes with the year of publication, but this correlation was not significant. \n\nStrong negative effects of underpowered studies on the quality of the reported data have thoroughly been discussed in the literature in general ( ,  ,  ) and specifically in neuroscience ( ,  ). Positive findings of tiny studies can only result from chance or selective data report. Our data show a consistent and significant correlation between the size of a prognostic effect and its standard error, indicating that stronger effects are less reliable. The correlation even withstood the removal of all datasets with <10 patients. As these small samples yield particularly large SE, the variability of SE was severely restricted, which might be expected to reduce the correlation coefficient. This was, however, not the case (Figure  ). \n\nAnother important limitation of nearly all studies was the lack of outcome blindness. Only two groups of authors clearly indicated that the diagnosis of the outcome was performed by neurologists without the knowledge of predictor values. One might argue that the diagnosis of recovery of consciousness (based on the criteria of consistent communication and functional use of objects) is quite easy and can hardly be biased by neurophysiological data. Even if this argument is true for exit-MCS, it is obviously false for the other broadly used improvement criterion of UWS patients, namely the transition to MCS. As the differential diagnostics between UWS and MCS is notoriously difficult ( ), any information about positive or negative neurophysiological findings could influence the diagnostic decision. If this influence really takes place, we can expect much stronger correlation of neurophysiological indices with the transition to MCS than with the transition to exit-MCS, because the latter diagnosis is easier and thus less affected by additional information. \n\nExactly this was true. When the improvement criterion for both diagnostic groups (UWS and MCS) was the transition to exit-MCS, the weighted average ES (in terms of Cohen\u2019s   d  ) was rather moderate, in any case slightly smaller than 0.5. But the transition of UWS patients to MCS (which is quite difficult from the diagnostic point of view) was strongly related to the neurophysiological findings, with the weighted average ES being >1.4. \n\nA potentially strong but still underestimated bias is related to unreported predictor variables. In most of the reviewed records, outcome prediction was not the main aim of the study, but rather a by-product of other analyses. Particularly, in such studies (though not only in these), many variables could be measured but not really reported. Sometimes, many variables are used in a UWS/MCS comparison but not even mentioned in relation to prognosis, although one may suppose that they were also compared with the follow-up data. Less frequently prognostic effects are referred to as \u201clacking\u201d or \u201cnon-significant\u201d without further quantification. Simmons et al. ( ) suggest a very simple solution of the problem: whenever authors list their variables, they should add a short word \u201conly.\u201d We tried to counteract this false positive effect by assigning the value of 0 to the effects of obviously omitted variables (with its SE being assumed as the median SE of the reported variables). However, this method is not only imprecise but can also be biased, first, because the real number of such omitted variables may be much larger than a reader can guess, and second, because negative effects (i.e., those which run against the starting hypothesis, such as better neurophysiological responses in non-recovered patients) can be omitted more frequently than positive effects. \n\nWith this in mind, we understand that the data of meta-analyses should be taken with great caution. Nevertheless, we believe that a glance on the meta-analytic results can be of interest. First, the analysis was strongly complicated by the high variability of the primary records. Very small number of studies using exactly the same predictor and the same improvement criterion enforced us to combine similar methods, which resulted in high heterogeneity indices such as   I  . Poor prognostic features of the characteristics of fMRI reactivity might partially be attributed to this group of studies including fMRI responses to very different stimulations from pain to music. For the same reason, we excluded some possible predictors (e.g., responses to active behavioral instructions; ERP N400 component) that were employed in two records only. \n\nSecond, the empirical contribution of predictors does not necessarily follow their general theoretical value defined by basic neuroscience. This is quite demonstrative in the case of P300, one of the most useful and most widely employed indices in neuroscience whose effect in the prediction of the outcome turned out to be virtually 0. One might speculate that P300 is not immediately related to consciousness ( ), but, rather, to a more specific function such as working memory. Another possible reason may be the extreme difficulty of the separation between different P300 subcomponents (P3a and P3b) in the target population ( ). The subcomponents are usually distinguished by topography and responses to active instruction, but most DoC patients have changed ERP topography and do not respond to instruction. If the results of this preliminary analysis should be used to determine which lines of research should not be recommended for future studies, P300 is the first candidate for such a negative recommendation. Also, the importance of the (highly expensive) fMRI predictors might similarly be overestimated on the basis of their theoretical importance. \n\nOscillatory EEG responses to stimulation showed, to the contrary, most promising effects, which agree well with the results of Bender et al. ( ) obtained on the basis of different data. \n\nAlthough EEG reactivity was measured to very different stimuli [e.g., to passive ( ) or forced eyes opening ( ,  ), to pain ( ,  ), to warm water ( ), and no description was given by Sar\u00e0 et al. ( )] and the definition of reactivity substantially varied, the results are very homogenous across the reports. Moreover, this was the only group of predictor variables whose predictive value was significant for both improvement criteria (transition from UWS to MCS and the recovery of consciousness). Publication bias was also presented in these data, but it was less strong than for many other predictors (see Tables S2 and S3 in Supplementary Material). \n\nOther perspective variables are brain metabolism (estimated by means of PET or SPECT) and the presence of sleep spindles in the EEG. Recent sleep data indicate a vital importance of spindles in information processing during sleep, which affects numerous cognitive processes in the subsequent wakefulness ( ,  ,  ). DoC belongs to rare medical conditions characterized by severe deficits, or even complete absence, of sleep spindles, also in patients with relatively preserved sleep structure ( ,  ). We believe that the role of sleep spindles in the outcome prediction in DoC should be explored in future work. \n\nBoth MMN and SSEP are proven outcome predictors for acute coma ( ,  ). However, their value for the chronic DoC remains unclear. The present findings indicate their prognostic effects for the transition from UWS to MCS but not for recovery of consciousness. \n\nThe data further show that the predictive value of the auxiliary (e.g., neurophysiological) variables should be compared with the values of clinical variables. In the currently reviewed data, MCS patients had about 4.5 times better chances (if we take the lower limit of the 95% CI, three times better chances) to regain consciousness than UWS patients. It is true that we analyzed only records implementing the neurophysiological approach and missed similar data in the other publications not using neurophysiological variables. Nevertheless, the effect is very strong and, as far as we can judge, not strongly biased (as it was not a desired effect). This indicates the necessity to integrate neurophysiological and clinical predictors within a multivariate approach in further studies. This integration could be more productive in both diagnostic and prognostic respects than the attempts to oppose different classes of variables to each other. \n\nThese considerations can only be conceived of as preliminary. It should be stressed that all biasing factors discussed above act in the same direction, potentially increasing the number of   false positive   results. The general critique of Brok et al. ( ) remains valid also for the current study: as long as the original studies do not present all information, meta-analyses can only try to diminish, but not abolish the positive bias. If we want to eliminate the bias, (i) small-size studies should be avoided (for prediction studies, groups of recovered/non-recovered should include at least 20 patients each); (ii) a flow chart should make evident the procedure of patient selection; (iii) neurologists assessing the target variable (i.e., change of the diagnosis) should be completely blinded regardless the values of neurophysiological predictors; (iv) the full list of measured variables including all potential predictors should be presented from the beginning of a report (in a Methods section); (v) the intervals (a) between the accident and the neurophysiological measurement, and (b) between this measurement and the follow-up assessment should be specified; finally, (vi) all positive   and negative   (e.g., non-significant relationships) results should be described in the same quantitative manner, either including the size of all effects, or permitting to calculate this size (e.g., mean and SD for the recovered and non-recovered groups). \n\nTherefore, the numbers presented in Figures   and   and in the Supplementary Materials can now be regarded, not as estimates of real effects, but rather, as upper limits of these effects. The current state of affairs is yet far away from the level at which any practical recommendation can be given except the recommendation to be highly careful with interpretations. \n\n\n## Author Contributions \n  \nBoth authors performed data search and analyses. The manuscript was initiated by the second author and finalized by the first author. \n\n\n## Conflict of Interest Statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. The reviewer AP and handling Editor declared their shared affiliation. \n\n \n", "metadata": {"pmcid": 5954214, "text_md5": "712085b6d617a983a0e025e3ff59b3a9", "field_positions": {"authors": [0, 37], "journal": [38, 50], "publication_year": [52, 56], "title": [67, 189], "keywords": [203, 366], "abstract": [379, 2241], "body": [2250, 45161]}, "batch": 2, "pmid": 29867725, "doi": "10.3389/fneur.2018.00315", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5954214", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5954214"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5954214\">5954214</a>", "list_title": "PMC5954214  A Systematic Review and Meta-Analysis of the Relationship Between Brain Data and the Outcome in Disorders of Consciousness"}
