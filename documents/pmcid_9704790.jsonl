{"text": "Pat, Narun and Wang, Yue and Anney, Richard and Riglin, Lucy and Thapar, Anita and Stringaris, Argyris\nHum Brain Mapp, 2022\n\n# Title\n\nLongitudinally stable, brain\u2010based predictive models mediate the relationships between childhood cognition and socio\u2010demographic, psychological and genetic factors\n\n# Keywords\n\nadolescent brain cognitive development\ngeneral cognition\nlongitudinal large\u2010scale data\nmachine learning\nmultimodal MRI\npolygenic score\nresearch domain criteria\n\n\n# Abstract\n \nCognitive abilities are one of the major transdiagnostic domains in the National Institute of Mental Health's Research Domain Criteria (RDoC). Following RDoC's integrative approach, we aimed to develop brain\u2010based predictive models for cognitive abilities that (a) are developmentally stable over years during adolescence and (b) account for the relationships between cognitive abilities and socio\u2010demographic, psychological and genetic factors. For this, we leveraged the unique power of the large\u2010scale, longitudinal data from the Adolescent Brain Cognitive Development (ABCD) study (  n  \u00a0~\u200911\u2009k) and combined MRI data across modalities (task\u2010fMRI from three tasks: resting\u2010state fMRI, structural MRI and DTI) using machine\u2010learning. Our brain\u2010based, predictive models for cognitive abilities were stable across 2\u2009years during young adolescence and generalisable to different sites, partially predicting childhood cognition at around 20% of the variance. Moreover, our use of \u2018opportunistic stacking\u2019 allowed the model to handle missing values, reducing the exclusion from around 80% to around 5% of the data. We found fronto\u2010parietal networks during a working\u2010memory task to drive childhood\u2010cognition prediction. The brain\u2010based, predictive models significantly, albeit partially, accounted for variance in childhood cognition due to (1) key socio\u2010demographic and psychological factors (proportion mediated\u00a0=\u00a018.65% [17.29%\u201320.12%]) and (2) genetic variation, as reflected by the polygenic score of cognition (proportion mediated\u00a0=\u00a015.6% [11%\u201320.7%]). Thus, our brain\u2010based predictive models for cognitive abilities facilitate the development of a robust, transdiagnostic research tool for cognition at the neural level in keeping with the RDoC's integrative framework. \n  \n(1) Using opportunistic stacking and multimodal MRI, we developed brain\u2010based predictive models for children\u2032s cognitive abilities that were longitudinally stable, generalisable to different sites and robust against missing data. (2) Our brain\u2010based models were able to partially mediate the relationships of childhood cognitive abilities with the socio\u2010demographic, psychological and genetic factors. (3) Our approach should pave the way for future researchers to employ multimodal MRI as a tool for the brain\u2010based indicator of cognitive abilities, according to the integrative RDoC framework.   \n \n\n# Body\n \n## INTRODUCTION \n  \nAccording to the Research Domain Criteria (RDoC), cognitive abilities are considered one of the major transdiagnostic domains, cutting across mental disorders (Morris & Cuthbert,\u00a0 ). In children and adults, cognitive abilities are related to various mental disorders, including but not limited to depression (Shilyansky et al.,\u00a0 ), attention\u2010deficit/hyperactivity disorder (ADHD) (Thaler et al.,\u00a0 ) and psychotic disorders (Sheffield et al.,\u00a0 ). Cognitive abilities that span across cognitive tasks, such as language, mental flexibility and memory, reflect a trait, known as general cognition or the   g  \u2010factor (Flynn,\u00a0 ). Yet, we still do not have predictive models that can robustly capture the relationship between the   g  \u2010factor and the brain. Having a brain\u2010based predictive model for the   g  \u2010factor is a key for us to adapt the RDoC's integrative approach\u2014to understand cognitive abilities across units of analyses, from behaviours to brain and genes that reflect the influences of socio\u2010demographical and psychological factors across the lifespan (Insel et al.,\u00a0 ; National Institute of Mental Health [NIMH],\u00a0 ). \n\nDeveloping the brain\u2010based predictive models for children's   g  \u2010factor to be used in the RDoC framework faces several challenges. The first challenge is longitudinal stability, which is one of the requirements in the RDoC framework (Insel et al.,\u00a0 ; NIMH,\u00a0 ). Predictive models should not only be generalisable to out\u2010of\u2010sample data (i.e., be predictive of children's   g  \u2010factor that were not part of the original sample) but also be developmentally stable (Sui et al.,\u00a0 ) in order to capture the   g  \u2010factor across the lifespan (Tucker\u2010Drob,\u00a0 ). Here, we started to tackle this challenge by using\u2014for the first time to the best of our knowledge\u2014longitudinal, large\u2010scale data in children, from the Adolescent Brain Cognitive Development (ABCD) study (Yang & Jernigan,\u00a0 ), to demonstrate the longitudinal stability of the brain\u2010based predictive models across 2\u2009years during adolescence. \n\nThe second challenge is multimodal integration. So far, brain\u2010based predictive models have been mainly built from a single MRI modality without integrating different sources of information from different MRI modalities. For instance, the   g  \u2010factor is associated with activity during certain cognitive tasks, such as working memory (Gray et al.,\u00a0 ; Waiter et al.,\u00a0 ) (task\u2010based functional MRI; task\u2010fMRI), the intrinsic functional connectivity between different areas (Dubois et al.,\u00a0 ; Pamplona et al.,\u00a0 ; Sripada, Rutherford, et al.,\u00a0 ) (resting\u2010state fMRI [rs\u2010fMRI]) and the anatomy of grey matter (Narr et al.,\u00a0 ) (structural MRI [sMRI]) and white matter (Gen\u00e7 et al.,\u00a0 ; G\u00f3ngora et al.,\u00a0 ) (diffusion tensor imaging [DTI]). However, recent findings, mainly in adults, have started to show the benefits of integrating data across modalities, rather than relying solely on a single modality (Jiang et al.,\u00a0 ; Rasero et al.,\u00a0 ; Sui et al.,\u00a0 ). Here, we adapted a machine\u2010learning framework, called stacking (Wolpert,\u00a0 ), to integrate information across MRI modalities into a \u2018stacked\u2019 model. Briefly, we separately built models to predict the   g  \u2010factor based on each brain modality, resulting in one predicted value from each modality for each participant. We then built a \u2018stacked\u2019 model to predict the   g  \u2010factor based on these predicted values. We tested if the stacked model indeed enhanced predictive performance over single modalities in predicting children's   g  \u2010factor. \n\nThe third challenge is missing data. Children's neuroimaging data are notoriously affected by movement artefacts (Fassbender et al.,\u00a0 ). For example, the ABCD study recommended a set of quality control variables for detecting noisy data from each modality (Hagler et al.,\u00a0 ; Yang & Jernigan,\u00a0 ), resulting in a listwise exclusion of 17% to over 50% of data depending on a modality. If we were to exclude children who have noisy data from any single modality, we would have to exclude almost 80% of the data, strictly limiting the generalisability of our model to children with highly clean data (who are unlikely to be representative of the rest of the sample). We overcame this problem by using a recently developed framework, built on top of the stacking framework, called \u2018opportunistic stacking\u2019 (Engemann et al.,\u00a0 ). Briefly, we first duplicated predicted values from each modality\u2010specific model, and imputed the missing value in each duplicate either with an arbitrarily high or low value. We then used Random Forest (Breiman,\u00a0 ) to create a final prediction from the imputed, predicted values. Accordingly, opportunistic stacking allows us to keep the data as long as there is at least one modality available, leaving more data in the model\u2010building process and reducing the risk of missing\u2010data bias. \n\nBeyond demonstrating a robust out\u2010of\u2010sample relationship between the brain and the   g  \u2010factor, the brain\u2010based predictive models have to demonstrate the construct validity, especially for them to be used according to the RDoC framework (Insel et al.,\u00a0 ). For instance, RDoC stipulates that cognitive abilities are affected by socio\u2010demographic and psychological factors (Morris & Cuthbert,\u00a0 ; NIMH,\u00a0 ). This is in line with recent studies showing that cognitive abilities are related to factors such as socio\u2010economic status (Farah et al.,\u00a0 ), mental health (Biederman et al.,\u00a0 ; Goodall et al.,\u00a0 ) and extracurricular activities (Kirlic et al.,\u00a0 ). Accordingly, for the brain\u2010based predictive models to demonstrate RDoC's construct validity, the brain\u2010based predictive models should be able to explain the associations between the   g  \u2010factor and these socio\u2010demographic and psychological factors. \n\nLikewise, RDoC stipulates that cognitive abilities should not be studied as a unitary construct, but should rather be studied through different units of analysis, from behaviours to the brain and genes (Insel et al.,\u00a0 ; Morris & Cuthbert,\u00a0 ; NIMH,\u00a0 ,  ). Thus, the brain\u2010based predictive models for cognitive abilities should be related to the \u2018gene\u2010based\u2019 predictive models for cognitive abilities, given that they both reflect different units of analysis of the same RDoC's domain. A polygenic score (PGS), a composite measure of common gene variants, can be considered a predicted value from the gene\u2010based predictive models (Bogdan et al.,\u00a0 ). For cognitive abilities (Plomin & Deary,\u00a0 ), a PGS is based on the associations between several single nucleotide polymorphisms (SNPs) and cognitive abilities in a separate Genome\u2010Wide Association Study (GWAS) (Davies et al.,\u00a0 ), such as in a recent GWAS among 257,841 adults (Lee et al.,\u00a0 ). Accordingly, for the brain\u2010based predictive models to demonstrate RDoC's construct validity, the brain\u2010based predictive models should also be able to explain the associations between the   g  \u2010factor and the PGS of cognitive abilities (Lee et al.,\u00a0 ). \n\nTo develop brain\u2010based predictive models for the   g  \u2010factor, we (i) used behavioural performance from cognitive tasks to derive the   g  \u2010factor and (ii) built brain\u2010based predictive models to predict this behaviourally derived   g  \u2010factor from multimodal MRI data. We used the ABCD Release 3.0 (Yang & Jernigan,\u00a0 ), including baseline data (age 9\u201310\u2009years old) from over 11,000 children and follow\u2010up data (age 11\u201312\u2009years old) from roughly half of the participants. We first derived children's   g  \u2010factor from their behavioural performance on six cognitive tasks using confirmatory factor analysis (CFA). We then built brain\u2010based predictive models by treating multimodal MRI data as the features and the children's   g  \u2010factor derived from behavioural performance as the target. More specifically, in our models, we implemented opportunistic stacking (Engemann et al.,\u00a0 ) to integrate MRI data across modalities and to deal with missing values from each modality. There were six modalities in total: three task\u2010based fMRI (working\u2010memory \u2018N\u2010Back\u2019, reward \u2018Monetary Incentive Delay [MID]\u2019 and inhibitory control \u2018Stop Signal\u2019), rs\u2010fMRI, sMRI and DTI. To determine the robustness and longitudinal stability of the brain\u2010based predictive models, we tested how well the models predicted the   g  \u2010factor of unseen children at the same ages and at 2\u2009years older as well as at different data\u2010collection sites. Next, to demonstrate whether multimodal integration led to better predictive performance, we applied bootstrapping to compare the stacked model with the best\u2010performing modality\u2010specific model. To explain the feature importance of the final models (i.e., determining brain features that contributed highly to the prediction of the   g  \u2010factor), we applied several \u2018explainers\u2019, including eNetXplorer (Candia & Tsang,\u00a0 ), conditional permutation importance (CPI) (Strobl et al.,\u00a0 ) and SHapley Additive exPlanations (SHAP) (Lundberg & Lee,\u00a0 ). \n\nWe then conducted mediation analyses to ensure that the brain\u2010based predictive models for the   g  \u2010factor demonstrated RDoC's construct validity. In these analyses, we tested the extent to which our brain\u2010based predictive models could account for the relationships between the behaviourally derived   g  \u2010factor and key socio\u2010demographic, psychological and genetic factors. For this purpose, in addition to the brain\u2010based predictive models, we also computed two additional predictive models that predicted the behaviourally derived   g  \u2010factor, either from (a) 70 socio\u2010demographic and psychological variables (Kirlic et al.,\u00a0 ) or (b) genes via a PGS of cognitive abilities (Lee et al.,\u00a0 ). The 70 socio\u2010demographic and psychological variables covered children's and/or their parents' socio\u2010demographics, mental health, personality, sleep, physical activity, screen use, drug use, developmental adversity and social interaction. This resulted in three predicted values of the   g  \u2010factor, based on features of the predictive models: \u2018brain\u2010based   g  \u2010factor\u2019, \u2018socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor\u2019 and \u2018gene\u2010based   g  \u2010factor\u2019. We then computed these predicted values on unseen children at each hold\u2010out data collection site and applied the mediation analyses. Here, we treated (i) the socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors as the independent variables, (ii) the brain\u2010based   g  \u2010factor as the mediator and (iii) the behaviourally derived   g  \u2010factor as the dependent variable. Through these mediation analyses, we quantified the extent to which the brain\u2010based predictive models for cognitive abilities\u00a0developed in this study mediated the relationships between the behaviourally derived   g  \u2010factor and socio\u2010demographic, psychological and genetic factors. \n\n\n## MATERIALS AND METHODS \n  \nWe employed the ABCD Study Curated Annual Release 3.0 (Yang & Jernigan,\u00a0 ), which included 3\u00a0T MRI data and cognitive tests from 11,758 children (female\u00a0=\u00a05631) at the baseline (9\u201310\u2009years old) and 5693 children (female\u00a0=\u00a02617) at the 2\u2010year follow\u2010up (11\u201312\u2009years old). The study recruited the children from 21 sites across the United States (Garavan et al.,\u00a0 ). We further excluded 54 children based on Snellen Vision Screener (Luciana et al.,\u00a0 ; Snellen,\u00a0 ). These children either could not read any line, could only read the first (biggest) line, or could read up to the fourth line but indicated difficulty in reading stimuli on the iPad used for administering cognitive tasks (see below). The ethical considerations of the ABCD study, such as informed consent, confidentiality and communication with participants about assessment results, have been detailed elsewhere (Clark et al.,\u00a0 ). Institutional Review Boards where the data were collected approved the study's protocols. \n\n### The   g  \u2010factor \n  \nWe derived the   g  \u2010factor using children's behavioural performance from six cognitive tasks. These six tasks, collected on an iPad during a 70\u2010min in\u2010session visit outside of MRI (Luciana et al.,\u00a0 ; Thompson et al.,\u00a0 ), were available in both baseline and follow\u2010up datasets. First, the Picture Vocabulary measured vocabulary comprehension and language (Gershon et al.,\u00a0 ). Second, the Oral Reading Recognition measured reading and language decoding (Bleck et al.,\u00a0 ). Third, the Flanker measured conflict monitoring and inhibitory control (Eriksen & Eriksen,\u00a0 ). Fourth, the Pattern Comparison Processing measured the speed of processing (Carlozzi et al.,\u00a0 ). Fifth, the Picture Sequence Memory measured episodic memory (Bauer et al.,\u00a0 ). Sixth, the Rey\u2010Auditory Verbal Learning measured memory recall after distraction and a short delay (Daniel & Wahlstrom,\u00a0 ). \n\nSimilar to the previous work (Ang et al.,\u00a0 ; Pat et al.,\u00a0 ; Thompson et al.,\u00a0 ), we applied the second\u2010order model of the   g  \u2010factor using CFA to encapsulate the   g  \u2010factor as the higher\u2010order latent variable underlying performance across cognitive tasks. More specifically, our input data were standardised performance from each cognitive task. In our second\u2010order model, we had the   g  \u2010factor as the second\u2010order latent variable. We also had three first\u2010order latent variables in the model: language (underlying the Picture Vocabulary and Oral Reading Recognition), mental flexibility (underlying the Flanker and Pattern Comparison Processing), and memory recall (underlying the Picture Sequence Memory and Rey\u2010Auditory Verbal Learning). \n\nWe fixed latent factor variances to one and applied Maximum Likelihood with Robust standard errors (MLR) using Huber\u2010White statndard erros and scaled test statistics. To demonstrate model fit, we used scaled and/or robust indices, including comparative fit index (CFI), Tucker\u2010Lewis index (TLI), root mean squared error of approximation (RMSEA) and standardized root mean square residual (SRMR) as well as used internal consistency, OmegaL2 (Jorgensen et al.,\u00a0 ), of the   g  \u2010factor. To implement the CFA, we used lavaan (Rosseel,\u00a0 ) (version\u00a0=\u00a0.6\u20106) and semTools (Jorgensen et al.,\u00a0 ) along with semPlot (Epskamp,\u00a0 ) for visualisation. Note to ensure the robustness of the chosen   g  \u2010factor model, we also examined the similarity in factor scores of the   g  \u2010factor based on three different CFA models: the second\u2010order model, the single\u2010factor model, and the mixture between exploratory factor analysis (EFA) and CFA models (Appendix\u00a0 ). \n\n\n### Multimodal   MRI  \n  \nWe used MRI data from six modalities: three task\u2010based fMRI, rs\u2010fMRI, sMRI and DTI. Note \u2018modalities\u2019 here referred to sets of features in our predictive models, as such we treated three task\u2010based fMRI as separate modalities even though they were task\u2010based fMRI. The ABCD study provided detailed procedures on data acquisition and MRI image processing elsewhere (Casey et al.,\u00a0 ; Hagler et al.,\u00a0 ; Yang & Jernigan,\u00a0 ). We strictly followed their recommended exclusion criteria based on automated and manual QC review of each modality, listed under the   abcd_imgincl01   table (Yang & Jernigan,\u00a0 ). The ABCD created an exclusion flag for each modality (with a prefix \u2018imgincl\u2019) based on several criteria, involving image quality, MR neurological screening, behavioural performance, number of repetition time (TRs) among others. We removed participants with an exclusion flag at any MRI indices, separately for each modality. We also applied the three interquartile range (3 \u00d7 IQR) rule (i.e., datapoint with a value over 3 IQRs away from the nearest quartile) with listwise deletion to remove observations with outliers in any indices within each modality. Additionally, to adjust for between\u2010site variability, we used an Empirical Bayes method, ComBat (Fortin et al.,\u00a0 ; Nielson et al.,\u00a0 ). We applied ComBat to all modalities except for task\u2010based fMRI, given that between\u2010site variability was found to be negligible for task\u2010based contrasts (Nielson et al.,\u00a0 ). See below for our approach to mitigate data leakage due to 3 \u00d7 IQR and ComBat. \n\n#### Three task\u2010based fMRI \n  \nWe used task\u2010based fMRI from three tasks. First, in the working\u2010memory \u2018N\u2010Back\u2019 task (Barch et al.,\u00a0 ; Casey et al.,\u00a0 ), children saw pictures of houses and emotional faces. Depending on the block, children reported if a picture matched either: (a) a picture that was shown 2 trials earlier (2\u2010back), or (b) a picture that was shown at the beginning of the block (0\u2010back). To focus on working\u2010memory\u2010related activity, we used the (2\u2010back vs. 0\u2010back) linear contrast (i.e., high vs. low working memory load). Second, in the MID task (Casey et al.,\u00a0 ; Knutson et al.,\u00a0 ), children needed to respond before the target disappeared. And doing so would provide them with a reward, if and only if the target followed the \u2018reward cue\u2019 (but not the \u2018neural cue\u2019). To focus on reward anticipation\u2010related activity, we used the (Reward Cue vs. Neutral Cue) linear contrast. Third, in the Stop\u2010Signal Task (SST) (Casey et al.,\u00a0 ; Whelan et al.,\u00a0 ), children needed to withhold or interrupt their motor response to a \u2018Go\u2019 stimulus when it was followed unpredictably by a Stop signal. To focus on inhibitory control\u2010related activity, we used the (Any Stop vs. Correct Go) linear contrast. Note that, for the SST, we used two additional exclusion criteria,   tfmri_sst_beh_glitchflag  , and   tfmri_sst_beh_violatorflag  , to address glitches in the task as recommended by the study (Bissett et al.,\u00a0 ; Garavan et al.,\u00a0 ). For all tasks, we used the average contrast values across two runs. More specifically, these contrasts were unthresholded, similar to previous work (Bolt et al.,\u00a0 ). These values were embedded in the brain parcels based on FreeSurfer's (Dale et al.,\u00a0 ) Destrieux (Destrieux et al.,\u00a0 ) and ASEG (Fischl et al.,\u00a0 ) atlases (148 cortical surface and 19 subcortical volumetric regions, resulting in 167 features for each task\u2010based fMRI task). \n\n\n#### Resting\u2010state fMRI \n  \nDuring rs\u2010fMRI collection, the children viewed a crosshair for 20\u2009min. The ABCD's preprocessing strategy has been published elsewhere (Hagler et al.,\u00a0 ). Briefly, the study parcellated regions into 333 cortical\u2010surface regions (Gordon et al.,\u00a0 ) and correlated their time\u2010series (Hagler et al.,\u00a0 ). They then grouped these correlations based on 13 predefined large\u2010scale networks (Gordon et al.,\u00a0 ): auditory, cingulo\u2010opercular, cingulo\u2010parietal, default\u2010mode, dorsal\u2010attention, frontoparietal, none, retrosplenial\u2010temporal, salience, sensorimotor\u2010hand, sensorimotor\u2010mouth, ventral\u2010attention and visual networks. Note that \u2018none\u2019 refers to regions that do not belong to any networks. After applying the\u00a0Fisher's r\u2010to\u2010z transformation, the study computed mean correlations between pairs of regions within each large\u2010scale network (  n  \u00a0=\u00a013) and between large\u2010scale networks (  n  \u00a0=\u00a078) and provided these mean correlations in their Releases (Yang & Jernigan,\u00a0 ). This resulted in 91 features for the rs\u2010fMRI. Given that the correlations between (not within) large\u2010scale networks were highly collinear with each other (e.g., the correlation between auditory and cingulo\u2010opercular was collinear with that between auditory and default\u2010mode), we further decorrelated them using partial correlation. We first applied the\u00a0inverse Fisher's rto\u2010z transformation, then partial correlation transformation, and then reapplied the\u00a0Fisher r\u2010to\u2010z transformation. \n\n\n#### Structural MRI \n  \nThe ABCD study processed sMRI, including cortical reconstruction and subcortical volumetric segmentation, using FreeSurfer (Dale et al.,\u00a0 ). Here, we considered FreeSurfer\u2010derived Destrieux (Destrieux et al.,\u00a0 ) regional cortical thickness measures (  n  \u00a0=\u00a0148 cortical surface) and ASEG (Fischl et al.,\u00a0 ) regional subcortical volume measures (  n  \u00a0=\u00a019), resulting in 167 features for sMRI. We also adjusted regional cortical thickness and volumetric measures using mean cortical thickness and total intracranial volume, respectively. \n\n\n#### Diffusion tensor imaging \n  \nHere, we focused on fractional anisotropy (FA) (Alexander et al.,\u00a0 ) of DTI. FA characterises the directionality of the distribution of diffusion within white matter tracts, which can indicate the density of fibre packing (Alexander et al.,\u00a0 ). The ABCD study segmented major white matter tracts using AtlasTrack (Hagler et al.,\u00a0 ,  ). Here, we considered FA of 23 major tracks, 10 of which were separately labelled for each hemisphere. These tracks included corpus callosum, forceps major, forceps minor, cingulate and parahippocampal portions of cingulum, fornix, inferior frontal occipital fasciculus, inferior longitudinal fasciculus, pyramidal/corticospinal tract, superior longitudinal fasciculus, temporal lobe portion of superior longitudinal fasciculus, anterior thalamic radiations and uncinate. This left 23 features for DTI. \n\n\n\n### Predictive models of multimodal   MRI  : opportunistic stacking \n  \nTo integrate multimodal MRI into one predictive model and to control for missing values across modalities, we applied opportunity stacking (Engemann et al.,\u00a0 ) (Figure\u00a0 ). We started with the first\u2010layer training set. Here, we used standardised features from each modality to separately predict the   g  \u2010factor via a penalised regression. The main advantage of a penalised regression is its ease of interpretation given that the prediction is made based on a weighted sum of features. Moreover, predictive performance of penalised regressions for capturing brain\u2010and\u2010behaviour relationships in MRI appeared good, often on\u2010par with other more black\u2010box algorithms (Dadi et al.,\u00a0 ; Dubois et al.,\u00a0 ; Engemann et al.,\u00a0 ; Niu et al.,\u00a0 ; Rasero et al.,\u00a0 ). Following previous research (Dubois et al.,\u00a0 ), we used Elastic Net (Zou & Hastie,\u00a0 ), a general form of penalised regression via the glmnet package (Friedman et al.,\u00a0 ). Elastic Net requires two hyperparameters. First, the \u2018penalty\u2019 determines how strong the feature's slopes are regularised. Second, the \u2018mixture\u2019 determines the degree to which the regularisation is applied to the sum of squared coefficients (known as Ridge) versus to the sum of absolute values of the coefficients (known as LASSO). We tuned these two hyperparameters using a 10\u2010fold cross\u2010validation grid search and selected the model with the lowest mean absolute error (MAE). In the grid, we used 200 levels of the penalty from 10  to 10, equally spaced on the logarithmic\u201010 scale and 11 levels of the mixture from 0 to 1 on the linear scale. \n  \nLongitudinal predictive modelling approach used for out\u2010of\u2010sample predictive ability of multimodal MRI. We split the data into four sets: First\u2010layer training, second\u2010layer training, baseline test, and follow\u2010up test. We used the same participants in the baseline test and follow\u2010up test sets. Modality\u2010specific modelling only used the first\u2010layer training set, while stacked modelling used both training sets to combine predicted values across modalities. At the first training layer, using elastic net, we separately predicted the   g  \u2010factor based on each of the six modalities, resulting in six predicted values. At the second training layer, we applied opportunistic stacking by duplicating these six predicted values, and then imputed missing observations in one as an arbitrarily large value of 1000 and in the other as an arbitrarily small value of \u22121000, resulting in 12 predicted values. We then used Random Forest to predict the   g  \u2010factor based on these 12 predicted values. The number of observations was different depending on the quality control of data from each modality. \u201cData not yet released\u201d reflects the fact that ABCD release 3.0 (Yang & Jernigan,\u00a0 ) only provided half of the follow\u2010up data (age 11\u201312\u2009years old), while providing the full baseline data (age 9\u201310\u2009years old). CFA, confirmatory factor analysis; cor, correlation; CV, cross\u2010validation; FA, fractional anisotropy \n  \nOnce we obtained the final modality\u2010specific models from the first\u2010layer training set, we fit these models to data in the second\u2010layer training set. This gave us six predicted values of the   g  \u2010factor from six modalities, and these are the features to predict the   g  \u2010factor in the second\u2010layer training set. To handle missing observations when combining these modality\u2010specific features, we applied the opportunistic stacking approach (Engemann et al.,\u00a0 ) by creating duplicates of each modality\u2010specific feature. After standardisation, we coded missing observations in one as an arbitrarily large value of 1000 and in the other as an arbitrarily small value of \u22121000, resulting in 12 features. That is, as long as a child had at least one modality available, we would be able to include this child in stacked modelling. \n\nPrevious research (Engemann et al.,\u00a0 ) advocated for a more flexible algorithm that can capture non\u2010linear and interactive relationships at the second\u2010layer training set. Here, we used the Random Forests algorithm (Breiman,\u00a0 ) from the ranger package (Wright & Ziegler,\u00a0 ) to predict the   g  \u2010factor from the 12 features (Engemann et al.,\u00a0 ; Josse et al.,\u00a0 ). Random Forests use a multitude of decision trees on various sub\u2010samples of the data and implement averaging to enhance prediction and to control over\u2010fitting. We used 1000 trees and turned two hyperparameters. First \u2018mtry\u2019 is the number of features randomly sampled at each split. Second \u2018min_n\u2019 is the minimum number of observations in a node needed for the node to be split further. We implemented a 10\u2010fold cross\u2010validation grid search and selected the model with the lowest root mean squared error (RMSE). In the grid, we used 12 levels of the mtry from 1 to 12, and 101 levels of the min_n from 1 to 1000, both on the linear scale. This resulted in the \u2018stacked\u2019 model that incorporated data across modalities. \n\nTo prevent data leakage, we fit the CFA model to the observations in the first\u2010layer training data and then computed factor scores of the   g  \u2010factor on all training and test data. Note that to demonstrate the stability of the factor scores of the   g  \u2010factor when applied to unseen data (i.e., not part of the modelling process), we also compared the factor scores of the   g  \u2010factor estimated from the first\u2010layer training data and the scores estimated from the whole baseline data (Appendix\u00a0 ). Similarly, we also applied the 3 \u00d7 IQR rule and Combat separately for first\u2010layer training, second\u2010layer training, baseline test and follow\u2010up test data. For the machine learning workflow, we used \u2018tidymodels\u2019 ( ). \n\n\n### Testing the robustness of the predictive models of multimodal   MRI  \n  \nWe examined the predictive ability of the models based on multimodal MRI between predicted versus observed   g  \u2010factor, using Pearson's correlation (  r  ), coefficient of determination (  R  , calculated using the sum of square definition), MAE, and RMSE. To investigate the predictive ability of the modality\u2010specific models, we used the models tuned from the first\u2010layer training set. To investigate the predictive ability of the stacked model, we used the model tuned from both the first\u2010layer and second\u2010layer training sets. \n\n#### Out\u2010of\u2010sample predictive ability of multimodal MRI: Baseline and follow\u2010up samples \n  \nWe first split the data into four parts (Figure\u00a0 ): (1) first\u2010layer training set (  n  \u00a0=\u00a03041), (2) second\u2010layer training set (  n  \u00a0=\u00a03042), (3) baseline test set (  n  \u00a0=\u00a05622) and (4) follow\u2010up test set (  n  \u00a0=\u00a05656). Especially noteworthy is that children who were in the baseline test set were also in the follow\u2010up test set. In other words, none of the children in the first\u2010layer and second\u2010layer training sets was in either of the test sets. We used the baseline test set for\u00a0out\u2010of\u2010sample, same\u2010age predictive abilities, while we used the follow\u2010up test sets for out\u2010of\u2010sample, longitudinal predictive abilities. \n\nTo examine the performance of opportunistic stacking as a function of missing values, we further split the test sets based on the presence of each modality. First, Stacked All required data with at least one modality present. This allowed us to examine the stacked model's performance when the missing values were all arbitrarily coded. Second, Stacked Complete required data with all modalities present. This represents the situation when the data were as clean as possible. Third, Stacked Best had the same missing values as the modality with the best prediction. This allowed us to make a fair comparison in performance between the stacked model and the model with the best modality, given their same noise level from missing value. Fourth, Stacked No Best did not have any data from the modality with the best prediction and had at least one modality present. This represents the highest level of noise possible. \n\n\n#### Comparing out\u2010of\u2010sample predictive ability of multimodal MRI between the stacked model and the model with the best modality: baseline and follow\u2010up samples \n  \nHere, we made a statistical comparison in the out\u2010of\u2010sample predictive ability between Stacked Best and the modality\u2010specific model with the highest predictive performance, two of which had the same number of missing values in the test sets. We applied bootstrapping with 5000 iterations to examine the differences in performance indices (including,   r  ,   R  , MAE and RMSE) on both baseline and follow\u2010up test sets. If stacking truly led to enhanced predictive performance, then we should see 95% CI of the bootstrapped differences to be different from 0. \n\n\n#### Out\u2010of\u2010site predictive ability of multimodal MRI \n  \nTo examine out\u2010of\u2010site predictive ability, we applied leave\u2010one\u2010site\u2010out cross\u2010validation to the baseline data. This enabled us to extract predicted values of the   g  \u2010factor based on multimodal MRI data at each hold\u2010out site, and in turn, to examine the generalisability of different models on different data collection sites. Different sites involved different MRI machines, experimenters as well as demographics across the United States (Garavan et al.,\u00a0 ). Moreover, using leave\u2010one\u2010site\u2010out cross\u2010validation also prevented having the participants from the same family in the training and test sets. Here, we first removed data from one site that only recruited 34 participants and removed participants from six families who were separately scanned at different sites. We then held out data from one site as a test set and divided the rest to be first\u2010 and second\u2010layer training sets. We cross\u2010validated predictive ability across these hold\u2010out sites. We applied the same modelling approach with the out\u2010of\u2010sample predictive models, except for two configurations to reduce the amount of ram used and computational time. Specifically, in our grid search, we used 100 levels of penalty (as opposed to 200) for Elastic Net and limited the maximal min_n to 500 (as opposed to 1000) for Random Forests. For the stacked model, we tested its predictive ability on children with at least one modality (i.e., stacked all). We examined the out\u2010of\u2010site prediction between predicted versus observed   g  \u2010factor at each hold\u2010out site. \n\n\n\n### Feature importance of multimodal   MRI   models \n  \nTo understand which features contribute to the prediction of the modality\u2010specific (i.e., Elastic Net) models, we applied permutation from the eNetXplorer (Candia & Tsang,\u00a0 ) package to the first\u2010layer training set of the out\u2010of\u2010sample predictive ability splits (Figure\u00a0 ). We first chose the best mixture from the previously run grid and fit two sets of several Elastic Net models. The first \u2018target\u2019 models used the true   g  \u2010factor as the target, while the second \u2018null\u2019 models used the randomly permuted   g  \u2010factor as the target. eNetXplorer split the data into 10 folds 100 times/runs. For each run, eNetXplorer performed cross\u2010validation by repeatedly training the target models on nine folds and tested on the leftover fold. Also, in each cross\u2010validation run, eNetXplorer trained the null models 25 times. eNetXplorer then used the mean of non\u2010zero model coefficients across all folds in a given run as a coefficient for each run,   k  . Across runs, eNetXplorer weighted the mean of a model coefficient by the frequency of obtaining a non\u2010zero model coefficient per run. Formally, we defined an empirical   p  \u2010value as: where   p   is an empirical   p  \u2010value,   run   is a run index,   n_run   is the number of runs,   per   is a permutation index,   n_per   is the number of permutation, \u0398 is the right\u2010continuous Heaviside step function and |\u03b2| is the magnitude of feature coefficient. That is, to establish statistical significance for each feature, we used the proportion of runs in which the null models performed better than the target models. We plotted the target models' coefficients with   p  \u00a0<\u2009.05 on the brain images using the ggseg (Mowinckel & Vidal\u2010Pi\u00f1eiro,\u00a0 ) package. \n\nTo identify which modalities contributed strongly to the prediction of the stacked (i.e., Random Forests) model, we applied two methods: (1) CPI (Debeer & Strobl,\u00a0 ) and (2) SHAP (Lundberg & Lee,\u00a0 ) to the second\u2010layer training set. CPI is an explainer, designed specifically for Random Forest. We implemented CPI using the \u2018permimp\u2019 package, as detailed elsewhere (Debeer & Strobl,  ). Briefly, the original permutation importance (Breiman,\u00a0 ) shuffled the observations of one feature at a time while holding the target and other features in the same order. Researchers then examined decreases in predictive accuracy in the out\u2010of\u2010bag observations due to the permutation of some features. Stronger decreases are then assumed to reflect the importance of such features. However, this method has shown to be biased when there are correlated features (Strobl et al.,\u00a0 ). CPI corrected for this bias by constraining the feature permutation to be within partitions of other features, which was controlled by the threshold \u2018  s  \u2019 value. We used the default   s   value at 0.95, which assumed dependencies among features (Debeer & Strobl,\u00a0 ). \n\nSHAP (Lundberg & Lee,\u00a0 ) is a model\u2010agnostic explainer, designed to explain the contribution of each feature to the prediction from any machine learning models via Shapley values (Roth,\u00a0 ). We implemented SHAP using the \u2018fastshap\u2019 package ( ). Based on the cooperative game theory, a Shapley value (Roth,\u00a0 ) quantifies a fair distribution of a payout to each player based on his/her contribution in all possible coalitions where each coalition includes a different subset of players. When applying Shapley values to machine learning, researchers treat each feature as a player in a game, a model output as a pay out and subsets of features as coalitions. Shapley values reflect the weighted differences in a model output when each feature is included versus not included in all possible subsets of features. SHAP (Lundberg & Lee,\u00a0 ) offers a computationally efficient approach to estimate Shapley values. \n\n\n### Testing whether the brain\u2010based predictive models mediated the relationships of the behaviourally derived   g  \u2010factor with socio\u2010demographic, psychological and genetic factors \n  \nUsing leave\u2010one\u2010site\u2010out cross\u2010validation, we built three predictive models for the   g  \u2010factor from (1) multimodal MRI (see above under \u2018Out\u2010of\u2010site Predictive Ability of Multimodal MRI\u2019), (2) key socio\u2010demographic and psychological factors and (3) a PGS. This resulted in three types of predicted values of the   g  \u2010factor of unseen children at each hold\u2010out data collection site: the brain\u2010based   g  \u2010factor, the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor and the gene\u2010based   g  \u2010factor, respectively. We then test if the brain\u2010based   g  \u2010factor mediated the relationship that the behaviourally derived   g  \u2010factor had with the socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors. \n\n\n### Key socio\u2010demographic and psychological factors \n  \nWe performed leave\u2010one\u2010site\u2010out cross\u2010validation to build \u2018socio\u2010demographic\u2010and\u2010psychological\u2010based\u2019 predictive models. These models predicted the behaviourally derived   g  \u2010factor from key socio\u2010demographic and psychological factors on the baseline data, similar to using leave\u2010one\u2010site\u2010out cross\u2010validation to create the \u2018brain\u2010based\u2019 predictive models above. This enabled us to extract predicted values of the   g  \u2010factor based on key socio\u2010demographic and psychological factors at each hold\u2010out site, called socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor. Here, we applied a similar modelling approach with leave\u2010one\u2010site\u2010out cross\u2010validation for multimodal MRI, except that we used only one layer of Elastic Net tuned with 200 levels of the penalty (from 10  to 10) and 11 levels of the mixture (from 0 to 1). For pre\u2010processing, we first imputed missing values of the categorical features via mode replacement and then converted them to dummy variables. We next normalised these dummy variables and all numerical features and the behaviourally derived   g  \u2010factor. At the last pre\u2010processing step, we used k\u2010nearest neighbour with five neighbours to impute the missing values of the normalised, numerical features. \n\nKey socio\u2010demographic and psychological factors included 70 features (Kirlic et al.,\u00a0 ) collected at the baseline (9\u201310\u2009years old): child's mental health based on symptom scales in Child Behavioral Checklist (Achenbach et al.,\u00a0 ) (eight features), primary caretaker's mental health based on personal strengths and symptom scales in Aseba Adult Self Report (Achenbach et al.,\u00a0 ) and General Behavior Inventory\u2010Mania (Youngstrom et al.,\u00a0 ) (nine features), child's personality based on Behavioral Inhibition System/Behavioral Activation System (Carver & White,\u00a0 ) and the UPPS\u2010P Impulsive Behavior Scale (Zapolski et al.,\u00a0 ) (nine features), child's sleep problems based on Sleep Disturbance Scale (Bruni et al.,\u00a0 ) (eight features), child's physical activities based on Youth Risk Behavior Survey (Adolescent and School Health | CDC,\u00a0 ) (four features), child screen use (Bagot et al.,\u00a0 ) (four features), parental use of alcohol, tobacco and marijuana after pregnancy based on Developmental History Questionnaire (Kessler et al.,\u00a0 ; Merikangas et al.,\u00a0 ) (three features), child developmental adversity (prematurity, birth complications and pregnancy complications) based on Developmental History Questionnaire (Kessler et al.,\u00a0 ; Merikangas et al.,\u00a0 ) (three features), child socio\u2010demographics (Zucker et al.,\u00a0 ) including sex, race, bilingual use (Dick et al.,\u00a0 ), parental marital status, parental education, parental income, household size, economic insecurities, area deprivation index (Kind et al.,\u00a0 ), lead risk (Frostenson & Kliff,\u00a0 ), crime reports (United States Department of Justice. Office of Justice Programs. Federal Bureau of Investigation,  ), neighbourhood safety (Echeverria et al.,\u00a0 ) and school environment, involvement and disengagement (Stover et al.,\u00a0 ) (17 features) and child social interactions based on Parental Monitoring Scale (Chilcoat & Anthony,\u00a0 ), Child Report of Behavior Inventory (Schaefer,\u00a0 ), Strengths and Difficulties Questionnaire (Goodman et al.,\u00a0 ) and Moos Family Environment Scale (Moos & Humphrey,  ) (five features). \n\n\n### Polygenic scores \n  \nTo extract predicted values of the   g  \u2010factor based on genetics, we used PGSs for adult cognitive ability (Lee et al.,\u00a0 ). The ABCD study provided details on genotyping elsewhere (Uban et al.,\u00a0 ). Briefly, the study took saliva and whole blood samples and genotyped them using Smokescreen\u2122 Array. The ABCD applied quality control based on calling signals and variant call rates, ran the Ricopili pipeline and imputed the data with TOPMED. We excluded data from problematic plates and with a subject\u2010matching issue, identified by the ABCD. We further quality controlled the data as follows. First, we removed individuals with minimal or excessive heterozygosity. We also excluded SNPs based on minor allele frequency (<5%) and violations of Hardy\u2013Weinberg equilibrium (  P  \u00a0<\u20091E\u221210). We limited the analysis to \u2018unrelated individuals\u2019 as defined by individuals with low genetic relatedness (more than third\u2010degree relative pairs; identical by descent [IBD] \u2265\u20090.0422). \n\nWe defined alleles associated with the   g  \u2010factor as those related to cognitive abilities in a large\u2010scale discovery GWAS sample of European ancestry (  N  \u00a0=\u00a0257,841) (Lee et al.,\u00a0 ). Given the lower predictive performance of PGS when the ancestry of a sample does not match with that of the discovery GWAS sample (Duncan et al.,\u00a0 ), we restricted all analyses related to PGS to children of European ancestry (Duncan et al.,\u00a0 ). We considered children to be genetically similar to the ancestry reference if they were within four standard deviations of the mean of the top four principal components (PCs) of the super\u2010population individuals in the 1000 genomes Phase 3 reference genotypes (1000 Genomes Project Consortium,\u00a0 ). \n\nWe used the Pthreshold PGS approach where we defined risk alleles as those associated with cognitive abilities within the discovery GWAS sample (Lee et al.,\u00a0 ) at 10 different thresholds from   p  \u00a0<\u2009.5\u2013.00000001 (referred to as PGS thresholds). The final sample for PGS included 4,814 children (2,263 females;   M  \u00a0=\u20099.94 [SD\u00a0=\u2009.61] years). We computed PGS as the   Z  \u2010scored, weighted mean number of linkage independent risk alleles. While the   g  \u2010factor was significantly related to the PGS of cognitive ability across thresholds (Figure\u00a0 ), the relationship at the   p  \u00a0<\u2009.01 PGS threshold was the numerically strongest (  r  \u00a0=\u00a00.21,   p  \u00a0<\u2009.001 [95%CI\u00a0=\u00a00.18\u20130.24]). Accordingly, we focused our analyses using the   p  \u00a0<\u2009.01 PGS threshold and treated the PGS at this threshold as our gene\u2010based   g  \u2010factors. \n\n\n### Mediation analyses \n  \nTo examine the extent to which brain\u2010based, stacked predictive models of the   g  \u2010factor accounted for the relationship between the behaviourally derived   g  \u2010factor and the socio\u2010demographic, psychological and genetic   g  \u2010factors, we applied mediation analyses (MacKinnon et al.,\u00a0 ). In these mediation analyses, we treated (i) the brain\u2010based   g  \u2010factor as the mediator, (ii) the socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors as the independent variables and (iii) the behaviourally derived   g  \u2010factor as the dependent variable. Note the behaviourally derived   g  \u2010factor was computed based on the CFA models in the training data, which were later applied to each hold\u2010out site. While the behaviourally derived   g  \u2010factor was a latent variable, it represented the only \u2018observed\u2019 value here since the other three   g  \u2010factors (brain\u2010based, socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based) were \u2018predicted\u2019 values from predictive models. \n\nWe conducted three mediation analyses. The first analysis only used the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor as the independent variable. The second analysis only used the gene\u2010based   g  \u2010factor as the independent variable. The third analysis used both the socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors as the independent variables, simultaneously in the same model. To control for population stratification in genetics, we also included four PCs as control variables in the mediation analyses involving the gene\u2010based   g  \u2010factor. \n\nTo implement the mediation analyses, we used structural equation modelling (SEM) with 5000 bootstrapping iterations via lavaan (Rosseel,\u00a0 ). We specifically calculated the   indirect effects   to show whether the relationships between the behaviourally derived   g  \u2010factor and the socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors were significantly explained by the brain\u2010based   g  \u2010factor. Along with the indirect effects, we also computed the   proportion mediated   to demonstrate the proportion of variance accounted for by the brain\u2010based   g  \u2010factor. \n\n\n### Data and code availability \n  \nWe used publicly available data provided by the ABCD study ( ), held in the NIMH Data Archive ( ). \n\nWe uploaded the R analysis script and detailed outputs for predictive modelling:   and mediation analyses:  . \n\n\n\n## RESULTS \n  \n### How robust are the factor scores of the   g  \u2010factor based on the second\u2010order model? \n  \nBased on our CFA, the second\u2010order model of the   g  \u2010factor showed a good fit: (a) scaled, robust CFI\u00a0=\u00a00.995, (b) scaled, robust TLI\u00a0=\u00a00.988, (c) scaled, robust root mean square error of approximation (RMSEA)\u00a0=\u00a00.029 (90%CI\u00a0=\u00a00.015\u20130.043) and (d) robust SRMR\u00a0=\u00a00.014. The   g  \u2010factor latent variable of the second\u2010order model also had high internal consistency: OmegaL2\u00a0=\u00a00.78. \n\nSee Appendix S  and S  for a more detailed CFA of the   g  \u2010factor. In brief, firstly, the second\u2010order model had better fit indices than the single\u2010factor model. Additionally, factor scores of the   g  \u2010factor from the second\u2010order model, the single\u2010factor model, and the mixture between EFA and CFA models were similar to each other at high magnitude (Pearson's   rs  \u00a0\u2265\u20090.987). Accordingly, the choice of   g  \u2010factor models had only minimal effects on the estimation of the factor scores for the   g  \u2010factor, and thus our brain\u2010based predictive models should be generalisable to the factor scores of different   g  \u2010factor CFA models beyond the second\u2010order model. Lastly, the factor scores estimated from the first\u2010layer training data were similar to the factor scores estimated from the full baseline data at high magnitude (Pearson's   rs  \u00a0>\u20090.997), indicating the stability of the factor scores used. \n\n\n### How robust are the brain\u2010based predictive models? \n  \n#### Out\u2010of\u2010sample predictive ability of multimodal MRI \n  \nFor hyperparameter\u2010tuning results, see Appendix S . Table\u00a0  and Figure\u00a0  summarise the out\u2010of\u2010sample predictive ability of multimodal MRI for both baseline and follow\u2010up samples. Performance of Stacked All, Stacked Complete and Stacked Best was among the top with Pearson's   r   over 0.4 and   R   around 0.19. Importantly, the superior performance of stacked models was found across baseline and follow\u2010up test sets at a similar magnitude, suggesting their longitudinal stability. Note that given that the N\u2010back task\u2010based fMRI had the highest performance among modality\u2010specific models, we set the missing values of the Stacked Best to be the same as those of the N\u2010back task\u2010based fMRI. Moreover, the opportunistic stacking (Engemann et al.,\u00a0 ) algorithm that led to the stacked model with at least one modality present, Stacked All, was robust against missing values as the performance of Stacked All was similar to that of the stacked model with all modalities present, Stacked Complete. \n  \nOut\u2010of\u2010sample and out\u2010of\u2010site predictive ability of multimodal MRI \n      \nOut\u2010of\u2010sample predictive ability of multimodal MRI as a function of modalities in the test sets for baseline (a) and follow\u2010up (b) samples. Stacked all required the test data with at least one modality present. Stacked complete required the test data with all modalities present. Stacked best had the same missing values with the modality with the best prediction (N\u2010back task\u2010based fMRI). Stacked no best did not have any test data from the modality with the best prediction and had at least one modality present \n  \nFigure\u00a0  shows the proportion of missing data in the two test sets. sMRI had the lowest missing observations, while the three task\u2010based fMRI data had the highest. Missing observations in Stacked All were around 3%\u20136%, while those in Stacked Complete were up to 78.79%. Figure\u00a0  also shows the differences in the   g  \u2010factor between participants with versus without missing values for each model in the two test sets. Participants with missing values had a significantly lower   g  \u2010factor than those without missing values, as indicated by Welch's   t  \u2010test, for all models, except for Stacked No Best, which showed the opposite direction. Yet, numerically these differences in the   g  \u2010factor were weaker in magnitude in the Stacked All than in other models with high predictive performance (such as the N\u2010back task\u2010based fMRI and Stacked Complete) as indicated by Cohen's   d  . Accordingly, by imputing the data via the opportunistic stacking (Engemann et al.,\u00a0 ), we were able to include more participants, and thus, less likely to exclude participants with a lower   g  \u2010factor. \n  \nMissing values in each predictive model in the baseline and follow\u2010up test sets. (a) Shows the differences in the   g  \u2010factor between participants with versus without missing values for each predictive model in the two test sets. **** indicates   p  \u2010value < .001 based on Welsh's   t  \u2010test. Positive Cohen's   d   indicates that participants without missing values had a higher   g  \u2010factor than participants without missing values. Dot and line are the mean and standard deviation x 2 of the   g  \u2010factor, respectively. (b) Shows the proportion of missing data for each predictive model in the two test sets \n  \n\n#### Comparing out\u2010of\u2010sample predictive ability of multimodal MRI between the stacked model and N\u2010back task\u2010based fMRI \n  \nN\u2010back task\u2010based fMRI provided the best out\u2010of\u2010sample predictive ability for both baseline and follow\u2010up test sets, relative to other modality\u2010specific models. Figure\u00a0  compared the predictive ability between the Stacked Best and N\u2010back task\u2010based fMRI using bootstrapped differences. The Stacked Best had significantly higher performance in both baseline and follow\u2010up test sets, reflected by higher Pearson's   r   and   R   and lower MAE and RMSE. This indicates the boost in predictive performance when multiple modalities were integrated, at around 12% for the baseline data and 6% for the follow\u2010up data. Accordingly, the stacked model performed better than the best single modality. \n  \nComparing out\u2010of\u2010sample predictive ability of multimodal MRI between stacked best and the model with the best modality (N\u2010back task\u2010based fMRI). Here, we separately applied bootstrapping on the baseline and follow\u2010up test sets. At each of 5000 iterations, we computed performance indices (including   r  ,   R  , MAE and RMSE) of stacked best and N\u2010back task\u2010based fMRI models and subtracted performance indices of N\u2010back task\u2010based fMRI from that of stacked best. Dotted lines indicate 95% confidence intervals. MAE, mean absolute error;   R  , coefficient of determination; RMSE, root mean squared error \n  \n\n#### Out\u2010of\u2010site predictive ability of multimodal MRI \n  \nBased on leave\u2010one\u2010site\u2010out cross\u2010validation, the out\u2010of\u2010site predictive ability of the stacked model was highest, explaining on\u2010average 21% (SD\u00a0=\u00a05.2) of the variance in the   g  \u2010factor across 21 sites (Table\u00a0  and Figure\u00a0 ). This confirmed the generalisability of the stacked model and ensured its use for subsequent mediation analyses. \n  \nOut\u2010of\u2010site predictive ability of multimodal MRI via leave\u2010one\u2010site\u2010out cross\u2010validation. We evaluated out\u2010of\u2010site predictive ability between predicted versus observed   g  \u2010factor in the hold\u2010out site. Note that DTI data were not available from three sites (sites 1, 17 and 19). MAE, mean absolute error;   R  , coefficient of determination; RMSE, root mean squared error \n  \n\n\n### Feature importance of multimodal   MRI   models \n  \nFigure\u00a0  shows the feature importance of both the modality\u2010specific and stacked models. For the modality\u2010specific models, we applied eNetXplorer (Candia & Tsang,\u00a0 ) to show brain features that significantly (empirical   p  \u00a0<\u2009.05) contributed to the prediction. For N\u2010back task\u2010based fMRI, the   g  \u2010factor prediction was driven by activity in areas, such as the precuneus, sulcus intermedius primus, superior frontal sulci and dorsal cingulate. For MID task\u2010based fMRI, the prediction was driven by activity in several areas in the parietal, frontal and temporal regions. For SST, the prediction was contributed by activity in areas such as the supramarginal gyrus and inferior precentral sulcus. For rs\u2010fMRI, the prediction was driven by connectivity within cinguloparietal and sensory\u2010motor\u2010hand as well as between networks that were connected with frontoparietal, default\u2010mode and sensory\u2010motor\u2010hand networks. For sMRI, the prediction was driven by the volume/thickness at several areas, such as the insula, middle frontal gyrus and lingual sulcus. For DTI, the prediction was driven by FA at several white matter tracts, such as the superior longitudinal fasciculus, forceps minor, uncinate and parahippocampal cingulum. For the stacked model, we applied the CPI (Strobl et al.,\u00a0 ) and SHAP (Lundberg & Lee,\u00a0 ) to examine which of the modalities contributed strongly to the prediction. CPI and SHAP provided similar results. N\u2010back task\u2010based fMRI by far had the highest importance score. \n  \nFeature importance of the modality\u2010specific and stacked models. For the modality\u2010specific models, we applied eNetXplorer (Candia & Tsang,\u00a0 ) permutation and only plotted brain features with empirical   p  \u00a0<\u2009.05. For the stacked model, we applied conditional permutation importance (CPI) (Debeer & Strobl,\u00a0 ) and SHapley additive exPlanations (SHAP) (Lundberg & Lee,\u00a0 ). Both CPI and SHAP were computed based on the second\u2010layer training set. Error bars in the CPI plot show an interval between 0.25 and 0.75 quantiles of the CPI for each tree in the random forests. The \u2018_large\u2019 and \u2018_small\u2019 suffixes indicate whether the missing values were coded as a large (1000) or small (\u22121000) number, respectively. For SHAP, we combined Shapley values across the two coded features of the same modality. We then ranked the modalities according to the absolute value of SHAP; the highest one was N\u2010back task\u2010based fMRI. Note the grey colour indicates observations with a missing value (coded as 1000 or \u22121000). ant, anterior; G, gyrus; IFG, inferior frontal gyrus; L, left; Lat, lateral; med, medial; R, right; S, sulcus; Sup, superior \n  \n\n### Did the brain\u2010based predictive models mediate the relationships of the behaviorally derived   g  \u2010factor with socio\u2010demographic, psychological and genetic factors? \n  \n#### Key socio\u2010demographic and psychological factors \n  \nBased on leave\u2010one\u2010site\u2010out cross\u2010validation, socio\u2010demographic and psychological factors explained on\u2010average 29.7% (SD\u00a0=\u00a08.1) of the variance in the behaviourally derived   g  \u2010factor across sites (see Figure\u00a0 ). The top features in the Elastic\u2010Net models that had the magnitude of their standardised coefficients over 0.1 included parents' education and income along with child's attention and social problems as well as extracurricular activities. \n  \nKey socio\u2010demographic and psychological factors. (a) Shows the out\u2010of\u2010site predictive ability of the elastic\u2010net model predicting the   g  \u2010factor from key socio\u2010demographic and psychological factors, based on leave\u2010one\u2010site\u2010out cross\u2010validation. (b) Shows the top socio\u2010demographic and psychological features with the magnitude of standardised coefficient over 0.1 based on the elastic\u2010net model. Blue indicates a positive relationship while red indicates a negative relationship. (c) Shows a scatter plot between out\u2010of\u2010site predicted values of the   g  \u2010factor based on key socio\u2010demographic and psychological factors and the observed (i.e., real) values of the   g  \u2010factor. (d) Shows a mediation analysis where (1) the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor (the out\u2010of\u2010site predicted values of the   g  \u2010factor based on the key socio\u2010demographic and psychological factors at all hold\u2010out sites) is the independent variable, (2) the brain\u2010based   g  \u2010factor (the out\u2010of\u2010site predicted values of the   g  \u2010factor of the stacked model based on multimodal MRI data at all hold\u2010out sites) is the mediator and (3) the behaviourally derived   g  \u2010factor (the observed   g  \u2010factor) is the dependent variable. % under the indirect effect indicates proportion mediated. [] indicates a 95% confidence interval based on bootstrapping. MAE, mean absolute error;   R  , coefficient of determination; RMSE, root mean squared error \n  \n\n#### Polygenic scores \n  \nFigure\u00a0  shows the relationship between the behaviourally derived   g  \u2010factor and the PGS of cognitive abilities at different thresholds. While the behaviourally derived   g  \u2010factor was significantly related to the PGS of cognitive abilities across thresholds, the relationship at the   p  \u00a0<\u2009.01 PGS threshold was the numerically strongest (  r  \u00a0=\u00a00.21,   p  \u00a0<\u2009.001 [CI95%\u00a0=\u00a00.18\u20130.24]). Accordingly, we used PGS at the   p  \u00a0<\u2009.01 PGS threshold as the gene\u2010based   g  \u2010factor for the mediation analyses. \n  \nPolygenic scores (PGSs) of cognitive abilities. (a) Shows Pearson's correlations between the   g  \u2010factor and PGS of cognitive abilities at different PGS thresholds. (b) Shows a scatter plot between the PGS of cognitive abilities at the   p  \u00a0<\u2009.01 PGS threshold and the observed (i.e., real) values of the   g  \u2010factor. (c) Shows a mediation analysis where (1) gene\u2010based   g  \u2010factor (the PGS of cognitive abilities at the   p  \u00a0<\u2009.01 PGS threshold) is the independent variable, (2) the brain\u2010based   g  \u2010factor (the predicted values of the   g  \u2010factor of the stacked model based on multimodal MRI data at all hold\u2010out sites) is the mediator and (3) the behaviourally derived   g  \u2010factor (the observed   g  \u2010factor) is the dependent variable. Not shown in the figure are four PCs included as the control variables to adjust for population stratification. % under the indirect effect indicates proportion mediated. [] indicates a 95% confidence interval based on bootstrapping \n  \n\n#### Mediation analyses \n  \nWe tested whether brain\u2010based   g  \u2010factor mediated the relationships between the behaviourally derived   g  \u2010factor and socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors. We found significant indirect effects (1) when the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor was the sole independent variable (Figure\u00a0  proportion mediated\u00a0=\u00a019.1%), (2) when the gene\u2010based   g  \u2010factor was the sole independent variable (Figure\u00a0 , proportion mediated\u00a0=\u00a015.6%) and (3) when both socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor (Figure\u00a0 , proportion mediated\u00a0=\u00a015%) and gene\u2010based   g  \u2010factor (Figure\u00a0 , proportion mediated\u00a0=\u00a010.75%) were the covaried independent variables. \n  \nMediation analysis with both key socio\u2010demographic and psychological factors as well as genetic factors as independent variables. Specifically, this model treated (1) the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor (i.e., the out\u2010of\u2010site predicted values of the   g  \u2010factor based on the key socio\u2010demographic and psychological factors at all hold\u2010out sites) and (2) the gene\u2010based   g  \u2010factor (i.e., the PGS of cognitive abilities at the   p  \u00a0<\u2009.01 PGS threshold) as two separate independent variables. It treated the brain\u2010based   g  \u2010factor (i.e., the predicted values of the out\u2010of\u2010site predicted values of the   g  \u2010factor of the stacked model based on multimodal MRI data at all hold\u2010out sites) as the mediator and the behaviourally derived   g  \u2010factor (i.e., the observed   g  \u2010factor) as the dependent variable. Not shown in the figure are four PCs included as the control variables to adjust for population stratification. % under the indirect effect indicates proportion mediated. [] indicates a 95% confidence interval based on bootstrapping. The dotted, double arrowed line indicates covariation between the two independent variables. PGS, polygenic score \n  \n\n\n\n## DISCUSSION \n  \nFollowing the RDoC's integrative approach for cognitive abilities (Morris & Cuthbert,\u00a0 ), we aimed to develop brain\u2010based predictive models that can (a) improve our current ability to predict children's cognitive abilities and (b) account for the relationships between cognitive abilities and socio\u2010demographic, psychological and genetic factors. Here, we showed that incorporating data from different MRI modalities into stacked models substantially improved our ability to predict cognitive abilities, operationalised as the behaviourally derived   g  \u2010factor. Our brain\u2010based, stacked predictive models were stable across years and generalisable to different sites while being able to handle missing values. Moreover, we showed that the brain\u2010based, stacked models significantly, albeit partially, mediated the relationships of the behaviourally derived   g  \u2010factor with socio\u2010demographic, psychological and genetic factors. Thus, our brain\u2010based predictive models for children's   g  \u2010factor demonstrated construct validity according to the RDoC framework (Insel et al.,\u00a0 ; Morris & Cuthbert,\u00a0 ; NIMH,\u00a0 ;  ). \n\n### The brain\u2010based, stacked predictive models for the g\u2010factor were (1) predictive, (2) longitudinal stable, (3) robust against missing values and (4) explainable \n  \nWe developed longitudinal predictive models for children's   g  \u2010factor from MRI data of different modalities. We built models from the baseline MRI data and tested them on unseen children at the same age and 2\u2009years older. We found similar predictive abilities across these two test sets for all modality\u2010specific and stacked models. That is, the models that had high out\u2010of\u2010sample prediction on same\u2010age children also had high out\u2010of\u2010sample prediction on older children, suggesting the longitudinal stability of MRI for many modalities. The best model across all performance indices (Pearson's   r  ,   R  , MAE and RMSE) was the stacked model that incorporated all six modalities, which was followed closely by the N\u2010back task\u2010related fMRI model. Apart from the SST task\u2010related fMRI model, other models (including the MID tasked\u2010related, rs\u2010fMRI, sMRI and DTI) performed moderately well. We also found a similar magnitude for out\u2010of\u2010site predictive ability based on leave\u2010one\u2010site\u2010out cross\u2010validation, suggesting the generalisability of MRI not only across ages but also across data collection sites. Overall, the stacked model partially predicted the children's   g  \u2010factor at around 20% of the variance. This made the stacked model the most generalisable model\u00a0to out\u2010of\u2010sample, out\u2010of\u2010site children as well as the most longitudinally stable model. \n\nBeyond generalisability across ages and sites, the stacked model based on opportunistic stacking (Engemann et al.,\u00a0 ) also allowed us to handle missingness in the data. This is especially important for children's MRI data given high levels of noise in certain modalities (Fassbender et al.,\u00a0 ). If we were to use data only from children with all modalities present (i.e., the Stacked Complete), the model would not apply to around 80% of the children. The opportunistic stacking allowed us to use the data as long as one modality was present (i.e., the Stacked All), leaving the exclusion to just around 5%. Importantly, the predictive performance of Stacked Complete and Stacked All were both relatively high, ensuring the ability of opportunistic stacking to deal with the missing data. Furthermore, handling missingness in the data via opportunistic stacking also heightened the chance of including participants with a wider range of the   g  \u2010factor, including those with a lower   g  \u2010factor who usually had missingness in the MRI data (perhaps due to high movement artefacts [Fassbender et al.,\u00a0 ]). Moreover, in the case when the best modality was not available, using the stacked model (i.e., the Stacked No Best) could be helpful. While the predictive ability of the Stacked No Best was not as strong as the Stacked Complete, Stacked All and Stacked Best, its performance measures of variance (Pearson's   r   and   R  ) appeared stronger in magnitude than any other non\u2010optimal modalities by themselves. Accordingly, in settings where not all of the modalities are available, researchers/practitioners can still take advantage of the boosted predictive ability of the stacked models over unimodal models. \n\nThe stacked model improved predictive ability over and above the best modality, which was the N\u2010back task\u2010based fMRI. This is based on bootstrapping distributions of the differences in performance indices between the N\u2010back task\u2010based fMRI and the stacked model with the same participants (i.e., the Stacked Best). Our finding is consistent with previous studies showing the enhanced predictive power of the stacked model (Engemann et al.,\u00a0 ; Rasero et al.,\u00a0 ). Yet, it is important to note that, while the improvement in performance was statistically significant, the magnitude of this improvement was somewhat modest. For instance, in the case of the baseline samples, the Stacked Best led to   r  \u00a0=\u00a00.442 and   R  \u00a0=\u20090.195, which was improved from the N\u2010back task\u2010based fMRI at   r  \u00a0=\u00a00.402 and   R  \u00a0=\u20090.072, rendering the improvement at around   r  \u00a0~\u20090.04 and   R  \u00a0~\u20090.123. Accordingly for researchers who have access to all MRI modalities and several fMRI tasks, including the N\u2010back task, using the stacked model should provide the best possible performance for predicting the   g  \u2010factor. However, if resources are constrained, the next best option would be using the N\u2010back task\u2010based fMRI along with other modalities that are available. \n\nIn addition to predictability, our machine learning framework allowed for easy\u2010to\u2010explain models, highlighting the neurobiological bases of children's   g  \u2010factor. Explainability is used in a specific machine\u2010learning sense (Molnar,\u00a0 ), referring to the extent to which a technique applied allows us to explain the contribution of each brain feature to the prediction. Here, CPI (Debeer & Strobl,\u00a0 ) and SHAP (Lundberg & Lee,\u00a0 ) allowed us to infer that prediction from the stacked model was driven primarily by N\u2010back task\u2010related fMRI. This indicates the important role of working memory. eNetXplorer permutation (Candia & Tsang,\u00a0 ) further showed us that contribution from fMRI activity in the parietal and frontal areas during the N\u2010back task drove the prediction. These areas were similar to the areas previously found in a recent study in adults (Sripada, Angstadt, et al.,\u00a0 ). Similarly, we also found brain indices from other modalities, from activity during other tasks to the cortical thickness and white matter density, that contributed to the prediction of the   g  \u2010factor, albeit with lower predictive performance. \n\nUnlike previous unimodal (Dubois et al.,\u00a0 ; Gen\u00e7 et al.,\u00a0 ; G\u00f3ngora et al.,\u00a0 ; Gray et al.,\u00a0 ; Narr et al.,\u00a0 ; Pamplona et al.,\u00a0 ; Sripada, Rutherford, et al.,\u00a0 ; Waiter et al.,\u00a0 ) and multimodal studies (Jiang et al.,\u00a0 ; Rasero et al.,\u00a0 ), we were able to compare the ability of task\u2010based fMRI with other modalities in predicting the   g  \u2010factor. We found that one of the three task\u2010based fMRI models, the N\u2010back, performed exceptionally well. Based on the CPI (Debeer & Strobl,\u00a0 ) and SHAP (Lundberg & Lee,\u00a0 ), the N\u2010back task\u2010related fMRI appeared to drive the prediction of the stacked model. This finding is consistent with a recent study using adults' data from the Human Connectome Project, showing superior performance of the N\u2010back task in predicting the   g  \u2010factor, compared to rs\u2010fMRI (Sripada, Angstadt, et al.,\u00a0 ) and other tasks. Showing that task\u2010based fMRI from a certain task could capture cognitive ability across a 2\u2010year gap provided a promising outlook for the use of task\u2010based fMRI as a predictive tool. Our finding is contradictory to a more common practice in cognitive neuroscience that usually relies on sMRI (McDaniel,\u00a0 ; Mihalik et al.,\u00a0 ; Pietschnig et al.,\u00a0 ) or rs\u2010fMRI (Dubois et al.,\u00a0 ; Rasero et al.,\u00a0 ; Sripada, Angstadt, et al.,\u00a0 ) when predicting cognitive abilities. These sMRI and rs\u2010fMRI studies often result in poorer predictive performance (at   r  \u00a0<\u20090.4) than what was found here. Accordingly, we are in agreement with a recent movement (Finn,\u00a0 ) for studies on individual differences to move from rs\u2010fMRI and embrace other MRI modalities, including task\u2010based fMRI. \n\nIt is important to note that not all fMRI tasks were suitable for predicting certain targets. The N\u2010back task and SST, for instance, were designed to capture working memory (Barch et al.,\u00a0 ; Casey et al.,\u00a0 ) and inhibitory control (Casey et al.,\u00a0 ; Whelan et al.,\u00a0 ), respectively. Accordingly, both should be related to the   g  \u2010factor, especially on memory recall and mental flexibility portions of the   g  \u2010factor. Yet, only the N\u2010back task showed good predictive ability. This may be due to different cognitive processes in each task (i.e., working memory vs. inhibitory control) or to different task configurations. It is entirely possible, for instance, that the block design used in the N\u2010back, as opposed to the event\u2010related design used in the SST, allowed the N\u2010back to have higher predictive power. Accordingly, while task\u2010based fMRI can have high predictive power, systematic comparisons are required in future research to better understand the characteristics of some tasks that make them more suitable for predicting the   g  \u2010factor and other individual differences. \n\n\n### The brain\u2010based, stacked predictive models for the   g  \u2010factor demonstrated construct validity, according to the   RDoC   framework (Insel et al.,\u00a0 ) \n  \nHere we tested the construct validity of the brain\u2010based, stacked predictive models for the   g  \u2010factor according to the RDoC framework (Insel et al.,\u00a0 ). The RDoC proposes that cognitive abilities are affected by socio\u2010demographic and psychological factors (Morris & Cuthbert,\u00a0 ; NIMH,\u00a0 ). The RDoC also proposes that cognitive abilities as measured by brain differences belong to the same domain as cognitive abilities as measured by gene differences (Insel et al.,\u00a0 ; Morris & Cuthbert,\u00a0 ; NIMH,\u00a0 ,  ). Accordingly, to satisfy these presuppositions, our brain\u2010based, stacked predictive models for the   g  \u2010factor should be able to capture the relationship between the behaviourally derived   g  \u2010factor and socio\u2010demographic, psychological and genetic factors. \n\nWe first built a predictive model of the   g  \u2010factor using 70 socio\u2010demographic and psychological features (Kirlic et al.,\u00a0 ), resulting in the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor. This model had relatively high performance, accounting for around 30% of the   g  \u2010factor. Moreover, the top contributing features are consistent with previous studies, including socio\u2010demographics (Farah et al.,\u00a0 ) (e.g., parents' education and income) along with children's mental health (Biederman et al.,\u00a0 ; Goodall et al.,\u00a0 ) (e.g., attention and social problems) and children's extracurricular activities (Kirlic et al.,\u00a0 ). More importantly, our mediation analysis showed that the brain\u2010based   g  \u2010factor captured approximately 19% of the relationship between the behaviourally derived   g  \u2010factor and the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor. \n\nAs for the genetic factor, we first showed that the PGS based on adults' cognitive abilities (Lee et al.,\u00a0 ) was related to children's   g  \u2010factor, consistent with a recent study (Allegrini et al.,\u00a0 ). This enabled us to use the PGS of cognitive abilities as the gene\u2010based   g  \u2010factor. Similar to the socio\u2010demography\u2010and\u2010psychology\u2010based   g  \u2010factor, our mediation analysis showed that the brain\u2010based   g  \u2010factor accounted for approximately 16% of the relationship between the behaviourally derived   g  \u2010factor and the gene\u2010based   g  \u2010factor. In fact, mediation from the brain\u2010based   g  \u2010factor was still significant when having both socio\u2010demography\u2010and\u2010psychology\u2010based and gene\u2010based   g  \u2010factors together as independent variables in the model. Altogether, our brain\u2010based, stacked predictive models for the    g   \u2010factor demonstrated the construct validity of cognitive abilities that is in line with the RDoC framework (Insel et al.,\u00a0 ). \n\n\n### Applications, limitations and disclaimers \n  \nFor applications, our brain\u2010based predictive models for the   g  \u2010factor facilitate the development of a robust, transdiagnostic research tool for cognition at the neural level in keeping with the RDoC (Morris & Cuthbert,\u00a0 ). Cognitive abilities are one of RDoC's six major transdiagnostic domains (Morris & Cuthbert,\u00a0 ), relating to a number of psychiatric disorders (Sheffield et al.,\u00a0 ; Shilyansky et al.,\u00a0 ; Thaler et al.,\u00a0 ). Based on RDoC (Morris & Cuthbert,\u00a0 ), to improve our understanding of cognitive abilities, we need research tools that allow us to integrate different units of analysis, from behavioural down to neural and genetic levels, and that reflect the influences of socio\u2010demographical and psychological factors across the lifespan (Insel et al.,\u00a0 ; NIMH,\u00a0 ). Our brain\u2010based predictive models satisfied many presuppositions of RDoC (Morris & Cuthbert,\u00a0 ). Our brain\u2010based predictive models for the   g  \u2010factor were not only longitudinal stable (Insel et al.,\u00a0 ; NIMH,\u00a0 ), but they also captured the influences of socio\u2010demographical, psychological and genetic factors on cognitive abilities (Insel et al.,\u00a0 ; Morris & Cuthbert,\u00a0 ; NIMH,\u00a0 ,  ). In fact, the predictive ability of our brain\u2010based predictive models in capturing the behavioural performance of cognitive tasks was considerably higher than that of PGS (multimodal MRI's   r  \u00a0~\u20090.4 and   R  \u00a0~\u20090.2 vs. PGS's   r  \u00a0~\u20090.21 in our study and   R  \u00a0<\u20090.1 in another study [Allegrini et al.,\u00a0 ]), suggesting the potential use of brain\u2010based predictive models for a robust, transdiagnostic, brain\u2010based marker for cognitive abilities. \n\nWith opportunistic stacking, those who wish to adapt our brain\u2010based predictive models to compute a transdiagnostic brain\u2010based marker for cognition in their own data, but do not have as many modalities as the ABCD, can still use our models. That is, they can still use the model built from the ABCD and impute missing values of certain modalities to fits with their study. Accordingly, our use of opportunistic stacking provides a scalable and flexible approach for future researchers following the RDoC framework (Morris & Cuthbert,\u00a0 ). \n\nOur study is not without limitations. We relied on the ABCD study's curated, preprocessed data (Casey et al.,\u00a0 ; Hagler et al.,\u00a0 ; Yang & Jernigan,\u00a0 ). This provided certain advantages. For instance, given that the curated data provided by the ABCD have already been preprocessed, other studies that wish to apply our model of the   g  \u2010factor to the ABCD data can readily do so without concerns about differences in preprocessing steps. Preprocessed data also enabled us to apply the manual quality control done by the study, a process that required time and well\u2010trained labour (Casey et al.,\u00a0 ; Hagler et al.,\u00a0 ; Yang & Jernigan,\u00a0 ). Preprocessing large\u2010scale multi\u2010modal data ourselves would not only demand significant computer power and time but is prone to error. However, using the preprocessed data only allowed us to follow the choices of processing done by the study. For example, ABCD Release 3 only provided Freesurfer's parcellation (Destrieux et al.,\u00a0 ; Fischl et al.,\u00a0 ) for task\u2010based fMRI. While this popular method allowed us to explain task\u2010based activity on subject\u2010specific anatomical landmarks, the regions are relatively large compared to other parcellations. Future studies will need to examine if smaller and/or different parcellations would improve predictive performance. Next, our predictive modelling framework was designed to predict the out\u2010of\u2010sample   g  \u2010factor, but not the developmental changes in the   g  \u2010factor, from multimodal MRI. More specifically, we standardised MRI and cognitive data within each age group to satisfy the assumption of our machine\u2010learning algorithms (Zou & Hastie,\u00a0 ) and to force behavioural performance from different cognitive tasks onto the same scale. This unfortunately made our predictive models inappropriate for predicting the developmental changes in cognition over years (Moeller,\u00a0 ). Future research that aims to capture the developmental changes in cognition would need to employ a different strategy for standardisation (Moeller,\u00a0 ). \n\nIn terms of important disclaimers, research reporting on cognitive abilities can be misunderstood or misquoted for alien purposes (Suzuki & Aronson,\u00a0 ). It is therefore important to clarify the following. First, the fact that measurements taken from the brain were related to cognitive abilities should not be equated with assertions that variability in cognitive abilities is \u2018purely biological\u2019. Here, we showed that the predictive model for the   g  \u2010factor based on socio\u2010demographic and psychological variables that were available in the ABCD (Kirlic et al.,\u00a0 ) already accounted for a larger variance of the   g  \u2010factor (~30%) than the predictive models based on the brain (~20%) or genes (<10% [Allegrini et al.,\u00a0 ]). Moreover, our mediation analysis showed that the brain\u2010based predictive models could only account for approximately 19% of the relationship between cognitive abilities and socio\u2010demographic and psychological factors. Accordingly, it is very plausible that social\u2010demographic and psychological circumstances, broadly construed, have at least partial aetiological primacy. Second, it should be clear that social\u2010demographic, psychological and genetic circumstances may not be independent of one another, as suggested by studies on the complex interplay of genes and environments on cognitive abilities over the course of cognitive development (Tucker\u2010Drob et al.,\u00a0 ; Tucker\u2010Drob & Briley,\u00a0 ). This is shown in our mediation analyses. Here, the brain\u2010based   g  \u2010factor showed less proportion mediated for the influences of social\u2010demographic, psychological factors and genes when they were included together in the model, compared to when they were included in separate models. This suggests the interdependency among the brain, genes, social\u2010demographic and psychological factors as proposed by the RDoC (Insel et al.,\u00a0 ; NIMH,\u00a0 ). Third, under no circumstances should the results of this article be interpreted as entailing a value judgement about how people vary in measurements of cognitive abilities. Indeed, it is important to reflect on the fact that the way we measured cognitive abilities, for example, through the   g  \u2010factor here, reflects norms that are entrenched in cultures and societies of a certain time in history, rather than reflecting some universal truth or a supra\u2010historical marker of cognitive abilities (Flynn,\u00a0 ). The value of the   g  \u2010factor here is as a marker (present in early life) of a series of other important life outcomes in current societal circumstances. \n\n\n\n## CONCLUSION \n  \nIn conclusion, we developed brain\u2010based stacked, predictive models for children's cognitive abilities that were longitudinally stable, generalisable and robust against missingness. More importantly, our brain\u2010based models were able to partially mediate the relationships of childhood cognitive abilities with the socio\u2010demographic, psychological and genetic factors. Accordingly, our approach should pave the way for future researchers to employ multimodal MRI as a useful research tool for integrative, RDoC\u2010inspired research in cognition and mental health. \n\n\n## CONFLICT OF INTEREST \n  \nThe authors declare no conflict of interests. \n\n\n## Supporting information \n  \n \n", "metadata": {"pmcid": 9704790, "text_md5": "f0e72c358b08695036a83195eca3eaba", "field_positions": {"authors": [0, 102], "journal": [103, 117], "publication_year": [119, 123], "title": [134, 297], "keywords": [311, 471], "abstract": [484, 2864], "body": [2873, 81780]}, "batch": 2, "pmid": 35903877, "doi": "10.1002/hbm.26027", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9704790", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9704790"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9704790\">9704790</a>", "list_title": "PMC9704790  Longitudinally stable, brain\u2010based predictive models mediate the relationships between childhood cognition and socio\u2010demographic, psychological and genetic factors"}
