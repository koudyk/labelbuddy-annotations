{"text": "Torabi, Mohammad and Mitsis, Georgios D and Poline, Jean-Baptiste\nGigascience, 2024\n\n# Title\n\nOn the variability of dynamic functional connectivity assessment methods\n\n# Keywords\n\nneuroimaging\nreproducibility\nanalytical flexibility\nfunctional magnetic resonance imaging\ndynamic functional connectivity\n\n\n# Abstract\n \n## Background \n  \nDynamic functional connectivity (dFC) has become an important measure for understanding brain function and as a potential biomarker. However, various methodologies have been developed for assessing dFC, and it is unclear how the choice of method affects the results. In this work, we aimed to study the results variability of commonly used dFC methods. \n\n\n## Methods \n  \nWe implemented 7 dFC assessment methods in Python and used them to analyze the functional magnetic resonance imaging data of 395 subjects from the Human Connectome Project. We measured the similarity of dFC results yielded by different methods using several metrics to quantify overall, temporal, spatial, and intersubject similarity. \n\n\n## Results \n  \nOur results showed a range of weak to strong similarity between the results of different methods, indicating considerable overall variability. Somewhat surprisingly, the observed variability in dFC estimates was found to be comparable to the expected functional connectivity variation over time, emphasizing the impact of methodological choices on the final results. Our findings revealed 3 distinct groups of methods with significant intergroup variability, each exhibiting distinct assumptions and advantages. \n\n\n## Conclusions \n  \nOverall, our findings shed light on the impact of dFC assessment analytical flexibility and highlight the need for multianalysis approaches and careful method selection to capture the full range of dFC variation. They also emphasize the importance of distinguishing neural-driven dFC variations from physiological confounds and developing validation frameworks under a known ground truth. To facilitate such investigations, we provide an open-source Python toolbox,   PydFC  , which facilitates multianalysis dFC assessment, with the goal of enhancing the reliability and interpretability of dFC studies. \n\n \n\n# Body\n    \nThe impact of diverse dynamic functional connectivity (dFC) assessment methods on dynamic brain connectivity results was examined. \n  \nSubstantial variability among methods, comparable to temporal variation, was revealed. \n  \nThree method groups in terms of dFC results similarity were revealed. \n  \nAn open-source Python toolbox,   PydFC  , supporting multianalysis dFC assessments, was introduced. \n  \nOverall, the results suggest that multianalysis approaches may enhance reliability and interpretability of dFC studies. \n   \n## Introduction \n  \nFunctional connectivity (FC) has emerged as an important measure for understanding brain function and as a biomarker with significant potential [ ]. FC is typically assessed using blood oxygen level\u2013dependent (BOLD) signals from functional magnetic resonance imaging (fMRI). FC assessment was initially performed under the assumption that it does not change over time (stationarity). However, growing evidence supports that the dynamic variations of FC (dynamic FC [dFC]) play a critical role in brain functional organization and may provide a link between neural dynamics and cognition in healthy and diseased conditions [ ]. The significance of dFC extends beyond understanding interactions between brain regions. Recent studies have shown that patterns of dFC can reveal differences between healthy and diseased individuals and therefore could be used as a clinical biomarker. In this regard, several studies have reported alterations in dFC patterns in a number of neurological or psychiatric conditions, including autism spectrum disorders (ASDs) [ ], attention-deficit/hyperactivity disorder (ADHD) [ ], depression [ ], posttraumatic stress disorder (PTSD) [ ], schizophrenia (SZ) [ ], Parkinson\u2019s disease (PD) [ ], and Alzheimer\u2019s disease (AD) [ ]. \n\nIn recent years, a variety of methodologies for assessing dFC have been developed [ ,  ]. As the number of available methods continues to grow, there is an increasing need to comprehensively review these methodologies and examine their relative advantages and disadvantages, as well as converge toward recommendations for their application to experimental data [ ]. To date, several studies have reviewed different aspects of these methods and have highlighted the importance of understanding their limitations and underlying assumptions [ ,  ]. However, only a few of these studies have compared different methods in practice [ ,  ], and none have provided a comprehensive comparison of the results yielded by commonly used dFC assessment methods. \n\nMost studies that have applied dFC to various applications have not reported a clear justification for adopting a specific methodology for assessing dFC [ ,  ,  ,  ,  ]. For example, in clinical applications, some studies have employed sliding-window and clustering methods (e.g., PTSD [ ], PD [ ], SZ [ ,  ,  ]), while others have preferred hidden Markov model (HMM) approaches (e.g., SZ [ ], PTSD [ ,  ], mild cognitive impairment [MCI] [ ]), or time-frequency methods (e.g., ASD [ ,  ], SZ [ ]). It is worth noting that very few studies have used multiple methodologies (e.g., chronic headache [ ], disorders of consciousness [DOCs] [ ]). Similarly, in cognitive and behavioral applications, some studies have used sliding-window and clustering methods (e.g., task prediction [ ], cognitive and behavioral flexibility [ ]), some have used coactivation patterns (CAP) analysis (e.g., naturalistic stimuli [ ], multiple tasks [ ]) and HMM (e.g., sleep stage [ ], impulsivity [ ]), and very few have used multiple methods (e.g., working memory task [ ]). A complete list of the reviewed studies can be found in  ,  , and  . Strikingly, of the 62 dFC studies that we reviewed, only 4 considered more than 1 method to assess the robustness of their results. This is somewhat concerning since the variation in the dFC assessment results due to the choice of the assessment methodology (i.e., its analytical flexibility) has been studied on a relatively limited basis until now [ ]. \n\nAnalytical flexibility has recently become a critical issue in neuroimaging, particularly in fMRI data analysis [ ]. Several studies have revealed significant variations in the results obtained from multiple independent analyses using the same dataset, highlighting the impact that analytical flexibility may have on scientific findings. For example, a study by [ ] revealed considerable variation in the results reported by 70 independent teams using a common dataset, emphasizing the need for performing and comparing multiple analyses on the same dataset, as well as identifying the factors that explain the variation in the obtained results. \n\nSimilarly, the analytical flexibility of dFC assessment may greatly influence the reliability of the findings about brain functional organization and its alterations in diseased groups. Although several studies have investigated the reproducibility across individuals and scan sites of dFC patterns at rest [ ,  ,  ], no study has fully investigated the analytical flexibility of dFC assessments. It is also unclear how methodological variations compare to the expected biological variations. The need for understanding dFC analytical flexibility in the context of biological variability is a first critical step for result interpretation and for drawing conclusions about brain functional organization and its alterations in diseased groups. \n\nResting-state fMRI data lack a reliable biological reference for quantifying the scale of variability of dFC across assessment methods. It is well known that fMRI data are an indirect measure of the neural activity and are also modulated by physiological and motion processes [ ,  ]. This further complicates setting a biological reference. However, dFC variation over time or over subjects can serve as fair biological references. Comparing the variability over methods to dFC temporal variability would yield an interpretable biological scale. In other words, if assessing dFC at one time point across methods results in as much variation as the one found across time points using one method, then variability between methods is as large as the scale of the biological phenomenon that they intend to capture. This approach enabled us to directly compare the magnitude of the effect of methodology choice to the underlying biological phenomenon. An alternative to variability in time is intersubject variability, which can also help scale the magnitude of variations over method. \n\nIn this study, we assess the analytical flexibility of dFC estimation by investigating how dFC patterns estimated from the same dataset vary across a large selection of methods. Among the available dFC assessment methods, we have selected 7 widely used methods: CAP [ ], the clustering method [ ], continuous HMM [ ], discrete HMM [ ], the sliding-window method [ ], the time-frequency (wavelet-based) method [ ], and the window-less method [ ]. \n\nThe selected dFC assessment methods differ in terms of their basic underlying assumptions, ranging from the window-less method, which places a minimal set of assumptions, to the HMM-based methods, which place the most rigid assumptions [ ]. Furthermore, some of these methods are state-based methods, meaning that they assume a finite number of group-level FC spatiotemporal patterns or \u201cFC states\u201d recurring over time (CAP, clustering, continuous HMM, discrete HMM, and window-less), while the rest are state-free methods that do not impose any constraints on the estimated FC patterns (sliding window and time-frequency). Moreover, the examined methods differ with regards to whether they assume locality of neighboring time points. Briefly, locality assumption means that the FC at each time point is inferred from the data points that are close in time (sliding window, time-frequency, clustering, continuous HMM, and discrete HMM) or not (CAP and window-less). The methods also differ in whether they consider the temporal ordering of data points (sliding window, time-frequency, clustering, continuous HMM, and discrete HMM) or disregard this information (CAP and window-less). State-based methods may also vary in terms of assuming smooth transitions between different states (continuous HMM and discrete HMM) or allowing instantaneous reconfiguration (CAP, clustering, and window-less) [ ]. Table\u00a0  lists these 7 methods along with their number of citations (note that these numbers refer to the particular study that introduced them and hence may not be entirely reflective of the overall popularity of each method), year of publication, and assumptions. For the detailed pipeline used for each method, as well as their important hyperparameters, please see Fig.\u00a0 . \n  \nPipeline of the 7 dFC assessment methods (time series of all subjects are concatenated in the time dimension for state-based methods prior to finding FC states):   Time-frequency   [ ]: wavelet transform coherence (WTC) between each pair of regions is computed after applying the wavelet transform on region time courses. Finally, dFC assessment is performed by averaging WTC over all frequency scales.   Sliding window   [ ]: dFC is assessed for each time window using a sliding window that moves over data time points and typically uses Pearson correlation as the metric to quantify FC for each pair of regions.   Clustering   [ ]: applies 2-level   k  -means clustering on the sequence of measured dFC matrices from the sliding-window method to find the clusters that correspond to different FC states. Cluster centroids are considered the state FC matrices, and the sequence of clustering labels is considered the state time course.   Discrete hidden Markov model (HMM)   [ ]: the state FC matrices and the state time course inferred by clustering are used as the observation sequence of a categorical HMM. The model then finds the hidden states and infers the corresponding state FC matrices and the state time course.   Continuous HMM   [ ]: the BOLD data are fed to a Gaussian HMM. The model finds the hidden states and their continuous observation models. It then infers the state FC matrices and the state time course.   Window-less   [ ]: a sparse dictionary learning is applied on the BOLD data using a   k  -SVD model to infer the dictionary matrix (D) and the mixing matrix (M). Next, state FC matrices and the state time course are obtained from D and M, respectively.   Coactivation pattern (CAP)   [ ]: clustering is performed on vectors of BOLD activity at each time point. Next, outer product of each centroid vector and its transpose is calculated and forms the state FC matrix corresponding to that cluster. The sequence of clustering labels of time points is considered the state time course. The table in the figure shows a list of all implemented dFC assessment methods and their important hyperparameters. Note that the state FC matrices in this figure\u00a0are denoted using the term \u201cFCS.\u201d \n    \nThe seven selected dFC assessment methods and their number of citations, year of first publication, and assumptions \n  \nComparing different methods for assessing dFC poses significant challenges due to several factors. The primary challenge arises from the differences in the underlying assumptions and the mathematical framework of various methods, coupled with the lack of a clear ground truth for measuring the accuracy of the results [ ,  ]. Additionally, the distribution of estimated dFC values across methods can differ significantly, precluding the use of common similarity metrics such as the Euclidean distance or Pearson\u2019s correlation. The distribution of dFC values may not necessarily be Gaussian, and these values may considerably vary with regards to their mean and variance (see  ). Furthermore, the output format of different methods varies, making direct comparisons more challenging. For instance, some methods, such as CAP and window-less, rely on first-order statistics and provide outputs in the form of activity vectors. In contrast, other methods, such as the clustering method, encode dFC as FC matrices, which are second-order statistics. Additionally, state-free methods generate a continuous sequence of FC matrices over time, while state-based methods generate a set of state FC matrices and a state time course. \n\nComparing dFC methods lacks a general framework. Previous studies that have attempted to compare dFC methods have been limited to specific groups of methods or aspects of dFC. For instance, [ ] compared the results obtained by clustering, CAP, and phase synchrony (PS) converted to a discrete set of states, thus limiting the comparisons to state-based methods. To make the results of CAP method comparable to others, they calculated the outer-product of the state mean-activity vectors obtained by this method to construct the corresponding FC matrices. Their comparison criteria were limited to visual comparison of spatial patterns of FC states and a few statistical outcomes derived from FC states, such as fractional occupancy. Similarly, [ ] compared the results obtained by sliding-window analysis using 10 different correlation metrics. To the best of our knowledge, no studies have comprehensively compared results across the most common dFC assessment methods (state-based and state-free). \n\nTo address these challenges, we developed a comprehensive comparison framework applicable to state-based and state-free methods. This framework compares methods based on spatial, temporal, and overall similarity. We implemented the 7 selected dFC assessment methods in a coherent Python package, providing the first open-source implementation of its kind. The 7 implemented methods were then used to assess dFC using the resting-state fMRI data of 395 subjects from the Human Connectome Project (HCP) dataset [ ,  ]. The outputs were standardized into a common array format to allow for comparison of results from methods with different output formats. The resulting dFC arrays were then compared using the comparison framework. This framework employs different similarity metrics, including nonparametric metrics such as Spearman correlation, to deal with the different distributions that result from different dFC methods. This framework was developed to evaluate the variability of the results using 2 levels of comparison, including subject level and intersubject level. Beyond assessing temporal and spatial variability on a subject level, assessing intersubject similarity enabled us to evaluate the ability of methods to capture a common biological phenomenon by examining the consistency of their intersubject correlations. This is particularly relevant for studies focused on identifying population biomarkers. For a complete description of the comparison framework, see \u201cAnalytical Flexibility Assessment\u201d in the Methods and Materials section. \n\nTo support researchers engaged in this endeavor, we implemented our framework as an open-source Python toolbox termed   PydFC  , which simplifies the implementation of multianalysis dFC assessment. The toolbox enables users to apply various dFC assessment methods to their data and experiment with different hyperparameters, allowing for a comprehensive analysis of dFC variability over methods and hyperparameters. Users can compare the results of different methods within a single package, making it easier to explore and evaluate dFC assessment techniques. This toolbox is unique in providing an open-source implementation of commonly used dFC methods and could be a valuable resource for researchers seeking to explore and compare different dFC assessment techniques. The toolbox is available on GitHub [ ] and is designed to be an open and collaborative package (MIT license), where contributors are welcome and the implementation of additional methods can be integrated. \n\nOur findings have important implications for the field of dFC and can guide future studies in several ways. First, by comprehensively comparing 7 widely used dFC assessment methods, we shed light on their analytical flexibility and the variability of their results, particularly when compared to the inherent variability of the biological phenomenon they aim to capture. This understanding is crucial for researchers and practitioners when choosing an appropriate method for their specific research question or clinical application. Second, our study provides a standardized framework for comparing dFC methods, addressing the challenges posed by their diverse assumptions, mathematical foundations, and output formats. This framework, which is implemented as an open-source Python toolbox, can serve as a basis for future comparative studies and facilitate the development and implementation of new or other dFC assessment methods (e.g., [ ,  ]). Lastly, our investigation of intersubject similarity consistency provides insights into the ability of different methods to capture a common biological phenomenon, which is vital for identifying reliable biomarkers of brain function and disorders. \n\n\n## Methods and materials \n  \n### Data \n  \nThe data used in this study are BOLD time series of resting-state fMRI data of 395 young and healthy subjects (age range: 22\u201336\u00a0years) from the S1200 release of the 3T HCP dataset [ ,  ], preprocessed as described in [ ]. Each subject was scanned during 4 sessions on 2 different days. Each day included two 15-minute scans, one acquired with left-to-right (LR) phase encoding direction and the other one with right-to-left (RL). In this study, except the overall similarity matrices, where we use data from all 4 sessions, all other main results are shown using data from the first session   Rest1_LR  . \n\nEach scan consists of 1,200 time points with repetition time   TR  \u00a0=\u00a00.720 seconds.\u00a0The other fMRI acquisition parameters are as follows: sequence: gradient-echo EPI; echo time   TE  \u00a0=\u00a033.1\u00a0ms; flip angle   FA  \u00a0=\u00a052 degrees; field of view   FOV  \u00a0=\u00a0208 \u00d7 180\u00a0mm (RO \u00d7 PE); matrix = 104 \u00d7 90 (RO \u00d7 PE); slice thickness = 2.0\u00a0mm; 72 slices; 2.0-mm isotropic voxels; multiband factor = 8; echo spacing   ES  \u00a0=\u00a00.58\u00a0ms; bandwidth   BW  \u00a0=\u00a02,290\u00a0Hz/Px (for more details, see [ ]). We used the HCP FIX-denoised data, which include additional denoising steps (i.e., de-trending, head motion correction, and denoising via spatial independent component analysis (ICA) compared to the minimally preprocessed data available in the HCP database) [ ,  ]. Furthermore, the downloaded FIX-denoised volumetric data underwent minimal spatial smoothing with a full width at half maximum (FWHM) of 4\u00a0mm [ ]. \n\nThe data were then parcellated into 333 regions of interest (ROIs) using the Gordon parcellation [ ], an atlas widely used in the literature. Each of the ROIs belongs to a specific resting-state network (RSN). Among these 333 ROIs, 47 did not belong to any brain network and therefore were excluded, resulting in 286 ROIs. Additionally, the parcellated data were high-pass filtered with a cutoff frequency of 0.01\u00a0Hz [ ]. For computational reasons, we have uniformly downsampled these 286 ROIs to 96 ROIs. This downsampling process involved selecting approximately one-third of the ROIs from each RSN in a manner ensuring uniform coverage across the area of that specific RSN and an equal number of ROIs from each hemisphere (see   for a visualization of the selected 96 ROIs). Each ROI time series was   z  -standardized before the analysis. \n\n\n### State-free methods \n  \nThese methods are model free and therefore do not need to be implemented at the group level before dFC assessment. They were applied to each subject separately. See Fig.\u00a0  for an illustration of state-free methods and their dFC matrices. \n\n#### Sliding window (SW) [ ] \n  \nA sliding tapered window of length 44s, or 60 time points (following [ ]), and 50% overlap was used to find the FC of ROI pairs over time. The tapered window was generated by convolving a rectangle of length 44s with a Gaussian curve with \u03c3\u00a0=\u00a03 TRs following [ ] and then moved along 1,200 time points with a 30 time points overlap. This procedure resulted in 38 windows and hence a 38 \u00d7   ROI   \u00d7   ROI   dFC matrix. The main hyperparameters of this method are window length, overlap ratio, and tapered or rectangular window. The values of these hyperparameters were chosen following [ ]. The overlap ratio of 0.5 was chosen to balance the temporal resolution of dFC assessment and computational demands. \n\n\n#### Time-frequency (TF) [ ] \n  \nThe wavelet transform was performed by applying   k  \u00a0=\u00a0101 wavelet kernels on each ROI time course, resulting in a wavelet time series with   k   frequency scales. Next, the wavelet transform coherence (WTC) was computed between the time courses of each ROI pair for each frequency scale and averaged across all frequency scales following [ ]. The resulting pairwise WTC time courses formed the corresponding dFC matrices of shape 1,200 \u00d7   ROI   \u00d7   ROI  . Note that following [ ], only the WTC values outside the cone of influence were considered for the final dFC matrix. The hyperparameters of this method include number of frequency scales, wavelet type, significance level of coherence magnitude, and considering the cone of influence or not. Following [ ], a Morlet wavelet at 101 frequency scales was employed. The significance level was set to 0.95, and only the WTC indices outside the cone of influence were considered. \n\n\n\n### State-based methods \n  \nSince state-based methods assume a finite number of FC states recurring over time and all subjects, they initially need to be applied at a group level to identify the group-level FC states. Each state is represented by a state FC matrix of shape   ROI   \u00d7   ROI  , which corresponds to the FC pattern at the time points that the state occurs. Next, the fitted models are applied to each individual subject, and individual dFC matrices are obtained. Applying the fitted models on subject-level data assigns each time point to one of the group-level FC states, resulting in a state time course. The state FC matrix of each state is then placed at the time points that belong to that state to build the dFC matrix of that subject. There is still no consensus on the number of brain states. In this study, to make the results more comparable, the number of FC states was assumed to be 12 for all state-based methods following [ ].   through   show the state FC matrices obtained by each state-based method. See Fig.\u00a0  for an illustration of state-based methods and their state FC matrices and state time courses. \n\n#### Coactivation patterns (CAP) [ ] \n  \nThe CAP method is a point-process analysis with individual time point time resolution and very few assumptions. The original CAP method used activation thresholding within a seed region and subsequent averaging of the BOLD time series at significant time points [ ]. The original method does not directly yield dFC matrices. The extended version of CAP analysis [ ] applies   k  -means clustering directly to BOLD time series. In the present study, for computational reasons, the clustering was performed in 2 stages following a process similar to [ ]. First, we clustered the time points of each subject (vectors of   length  \u00a0=\u00a0  ROI  ) to find subject-level cluster centroids. Next, we clustered the resulting cluster centroids from all subjects to identify 12 group-level cluster centroids, corresponding to 12 FC states. Finally, we obtained the state FC matrices following the implementation proposed by [ ], by calculating the   ROI   \u00d7   ROI   outer-product matrix of centroids with themselves. The clustering labels of time points were considered the state time courses. The shape of the final dFC matrix was 1,200 \u00d7   ROI   \u00d7   ROI  . The hyperparameters of this method are the number of subject-level clusters and the number of FC states. The number of subject-level clusters was set to 20 based on [ ]. \n\n\n#### Sliding window + clustering (SWC) [ ] \n  \nThis method relies on the dFC matrix assessed using the sliding-window method. Therefore, we initially assessed the dFC matrix using the sliding-window method as described above, which had a shape of 38 \u00d7   ROI   \u00d7   ROI  . Next, we considered each time point of the dFC matrix as a sample and vectorized it to a feature vector of length   ROI   \u00d7 (  ROI   \u2212 1)/2. Then, using a 2-level   k  -means clustering procedure similar to the one described for the CAP method, we clustered feature vectors into 12 clusters corresponding to 12 FC states. The FC matrix of each state was then obtained by reshaping the centroid vectors to their original shape of   ROI   \u00d7   ROI  . The resulting clustering label sequences were considered the state time courses. The shape of the final dFC matrix was 38 \u00d7   ROI   \u00d7   ROI  . The hyperparameters of this method are, in addition to the hyperparameters of the sliding-window method, the number of subject-level clusters, as well as the number of FC states. The values for sliding-window hyperparameters were chosen as in the sliding-window method, and the number of subject-level clusters was set to 20, consistent with the CAP method. \n\n\n#### Continuous hidden Markov model (CHMM) [ ] \n  \nIn this method, a continuous hidden Markov model (continuous HMM or CHMM) with a Gaussian observation model was used. BOLD time series from resting-state fMRI data were directly used as the continuous observation sequences of the HMM. Subsequently, 12 hidden states were identified, each corresponding to a FC state. Each hidden state was represented by a multivariate Gaussian model. The mean and covariance of each hidden state were inferred by fitting the model on the concatenated BOLD time series of all subjects. Next, the fitted model was applied on the subject-level data to infer the sequence of hidden states for each subject. The inferred sequence was then used as the state time course, and the covariance matrix of each hidden state was considered the corresponding state FC matrix. The shape of the final dFC matrix was 1,200 \u00d7   ROI   \u00d7   ROI  . The only hyperparameters of this method are the observation model type (e.g., Gaussian, or autoregressive) and number of FC states. A Gaussian model was chosen as the observation model following [ ]. \n\n\n#### Discrete hidden Markov model (DHMM) [ ] \n  \nFor this method, a discrete hidden Markov model (discrete HMM or DHMM) with a categorical observation model was used. Since this method is based on the results of the clustering method, we initially assessed dFC matrices using the clustering method, which had a shape of 38 \u00d7   ROI   \u00d7   ROI  . The number of FC states assumed for this initial clustering analysis was equal to the number of observations assumed for the discrete HMM method and not the number of final FC states. Furthermore, the DHMM used here requires a discrete observation sequence. Therefore, the state time courses obtained by the clustering method were used as the discrete observation sequences of the discrete HMM. The HMM was then fitted to the observation sequences to identify 12 hidden states corresponding to the 12 FC states. The resulting hidden state sequences were used as the state time courses, and the FC matrix of each FC state was obtained by averaging all FC matrices assigned to that FC state in the dFC matrices obtained by the clustering method. The shape of the final dFC matrix was 38 \u00d7   ROI   \u00d7   ROI  . The hyperparameters of this method include the hyperparameters of the clustering method, number of observations assumed in the observation model, and number of FC states. For the clustering method hyperparameters, the same values as the clustering method were chosen, and the number of observations to number FC states ratio, 16/24, was adopted from [ ]. \n\n\n#### Window-less (WL) [ ] \n  \nThis method relies on estimating the dominant linear patterns in the sample space of all BOLD time-series values. Each dominant linear pattern corresponds to one of the FC states. To estimate the dominant linear patterns, a sparse dictionary learning algorithm, the   k-SVD   algorithm [ ], was applied to the group-level data. Dominant linear patterns are each represented by a dictionary element. The 12 dictionary elements corresponding to the 12 FC states were stored in the dictionary matrix   D  . Each time point was approximated by a linear combination of these dictionary elements. The coefficients of the linear combinations for each time point were stored in rows of the mixing matrix   M  . A hard sparsity constrain was applied to the algorithm so that it assigns one and only one dictionary to each time point, suggesting that rows of   M   were sparse. The state FC matrices were obtained by calculating the outer-product matrices of the dictionary elements in the columns of   D  . The state time course was calculated using the mixing matrix   M  . The shape of the final dFC matrix was 1,200 \u00d7   ROI   \u00d7   ROI  . The only hyperparameter of this method is the number of FC states. \n\n\n\n### Analytical flexibility assessment \n  \nWe used Python to implement all 7 methods and estimate the dFC matrix for each of the 395 preprocessed fMRI subjects\u2019 data, resulting in a total of 2,765 dFC matrices. Fig.\u00a0  shows representative dFC matrices obtained by different methods using the BOLD data of 1 subject. To ensure comparability, as sliding window\u2013 based methods (SW, SWC, and DHMM) downsample the time samples, the dFC matrices of other methods were uniformly downsampled prior to further analysis to match the resolution of the sliding window\u2013based methods. The output of each method was converted to a common format of a 38 \u00d7 96 \u00d7 96 dFC matrix, resulting in 7 dFC matrices of the same size per subject. This resulted in a dFC results array of dimensions   dFC   (  subject, method, time, ROI, ROI  ) \u2208 (395, 7, 38, 96, 96). The dFC results array was also reshaped in some cases to   dFC   (  subject, method, time, functionalConnection  ) \u2208 (395, 7, 38, 4560) by vectorizing the lower triangle of 2-dimensional FC matrices of shape   ROI   \u00d7   ROI   into   functionalConnection   \u00d7 1. To assess the analytical flexibility of the dFC results across methods, we calculated the 7 \u00d7 (7 \u2212 1)/2 pairwise similarity using several similarity metrics, including Spearman correlation, Pearson correlation, Euclidean distance, and mutual information. We evaluated the similarity between each pair of methods in terms of correlation of their dFC matrices   dFC   (  subject, method  , :, :, : ) (overall similarity), time courses of functional connections   dFC   (  subject, method, :, ROI, ROI  ) (temporal similarity), FC patterns at each time point   dFC   (  subject, method, time  , :, : ) (spatial similarity), and graph properties such as degree and clustering coefficient (see   and  ). The equations\u00a0used to calculate each of these similarity metrics are as follows: \n\nAdditionally, we compared the correspondence between the intersubject correlations of different methods to obtain the intersubject similarity: \n\nTo identify groups of methods that produce similar results, we used hierarchical clustering with the Ward method to analyze the similarity values calculated using the aforementioned metrics (Spearman correlation, Pearson correlation, Euclidean distance, and mutual information). For correlation-based metrics, 1 \u2212   correlation   was used as the distance between the methods. The hierarchical clustering allowed us to summarize the measured similarity matrices and, moreover, group together methods that exhibited a higher degree of similarity. \n  \nA sample segment of dFC matrices of 1 subject obtained by the implemented methods: each row shows the dFC matrix obtained by each method, and each column corresponds to a time point, or TR index. Each FC matrix has a size of   ROI   \u00d7   ROI   and ROIs are divided into 12 RSNs. To account for the different value distributions of each method and better comparability, the dFC matrices were normalized by ranking the values, similar to the approach used when calculating Spearman correlation. \n  \n\n\n## Results \n  \n### DFC assessment methods can be grouped into 3 categories based on the similarity of their results \n  \nFigure\u00a0  shows the overall similarity obtained by Spearman correlation of the subject-specific dFC matrices computed using the 7 selected methods (an illustration of sample dFC matrices obtained by each method can be seen in Fig.\u00a0 ). The correlation values were averaged over subjects and repeated for each session, as indicated in equation\u00a0  (for results obtained by other metrics, see Supplementary material: Pearson correlation,  ; Euclidean distance,  ; and mutual information,  ; see   for the results of 2-way ANOVA test on the effect of session [day and direction] on the overall similarity values). Correlation values show a range from weak to strong similarity between dFC methods. The average Spearman similarity of all pairs over all subjects was 0.38, indicating a moderate degree of similarity. However, the corresponding standard deviation was high (0.18; variance: 0.032), about half of the average similarity value. This variability was also significantly larger than the average variance of pairwise similarities over subjects (SD: 0.076, variance: 0.0058). In other words, dFC similarity variability over method pairs was 5 times higher than over subjects. \n  \nSimilarity between dFC patterns obtained from the 7 examined methods as assessed by Spearman correlation. (A) The overall (combined spatial and temporal) similarity values averaged over subjects exhibit considerable variation over different method pairs for all sessions. (B\u2013E) Hierarchical clustering based on (B) average overall similarity, obtained by comparing the entire dFC matrices; (C) average spatial similarity, obtained by comparing FC matrices at each time point; (D) average temporal similarity, obtained by comparing time courses of each functional connection; and (E) average intersubject similarity, obtained by comparing intersubject correlation values, measured by Spearman correlation. The hierarchical clustering results suggest that the methods can be grouped into 3 groups: (i) clustering, continuous HMM, and discrete HMM: orange; (ii) CAP and Window-less: red; and (iii) sliding window and time-frequency: green. The horizontal dashed lines represent the clustering cutoff values. A slightly different pattern was obtained through temporal similarity assessment, which is due to decreased similarity of continuous HMM and time-frequency with the methods in their group. The general similarity between the methods was relatively low, particularly for intergroup comparisons. For results obtained by other metrics, see Supplementary material: Pearson correlation,  ; Euclidean distance,  ; and mutual information,  . \n  \nWe used hierarchical clustering analysis on the pairwise similarity matrices to investigate and summarize variation between dFC methods. The hierarchical clustering based on these average correlation matrices (Fig.\u00a0 ) suggests that the methods can be classified into 3 groups: (i) clustering, continuous HMM, and discrete HMM; (ii) CAP and window-less; and (iii) sliding window and time-frequency. To obtain these groups, we applied a cutoff value equal to 0.7 \u00d7 the maximum distance (Ward distance) observed between different clusters (shown as a horizontal dashed line in the hierarchical clustering figures). While the definition of these groups depends on the specific clustering cutoff value used, our observations revealed pronounced intragroup similarities and comparatively lower intergroup similarities for these 3 identified groups (for results obtained by other metrics, see Supplementary material: Pearson correlation,  ; Euclidean distance,  ; and mutual information,  ). Most subjects exhibited the same hierarchical clustering pattern as the one observed in the average pattern across all subjects ( ). \n\nThe distribution of these similarity patterns over subjects ( ) indicates that the similarity between certain pairs of methods, notably those involving time-frequency, displays greater variability over subjects. This observation suggests that the observed similarity between these methods is more likely influenced by individual differences in BOLD signals than mathematical similarity of their analyses. In other words, the variation in similarity across subjects implies that individual-specific characteristics may play an important role in the similarity between these methods. However, for other pairs of methods, more consistent similarity profiles were observed over subjects. \n\n\n### Similarity in spatial patterns of dFC results follows the overall similarity patterns \n  \nThe spatial similarity between the dFC matrices obtained from different methods was estimated using Spearman correlation between their corresponding spatial patterns (FC matrices) at each time point for each subject (see equation\u00a0 ). The resulting spatial similarity was then averaged over both time and subjects. Hierarchical clustering analysis of the average spatial similarity matrix (see Fig.\u00a0 ) revealed the same hierarchical structure as the one revealed by average overall similarity. The clustering analysis identified the same 3 groups, suggesting that their spatial similarities follow the same intra- and intergroup pattern. \n\n\n### Across methods dFC assessments reveal lower temporal similarity compared to spatial similarity \n  \nThe temporal similarity between dFC matrices of each pair of methods was assessed using Spearman correlation between the time courses obtained by the methods for each functional connection (see equation\u00a0 ). The resulting temporal similarity matrices were then averaged over functional connections (  ROI   \u00d7   ROI  ) and subjects. While 2 methods may produce dFC matrices that have similar spatial patterns, the corresponding temporal patterns may differ. Across methods, spatial similarity focuses on the spatial patterns and values of functional connections at a given time, while temporal similarity focuses on the consistency of the time evolution of dFC for each functional connection. The hierarchical clustering based on the average over subjects\u2019 temporal similarity matrix (Fig.\u00a0 ) reveals an overall decrease in similarity between methods compared to spatial (and overall) similarity. This was particularly noticeable for the similarities between CHMM and TF with other methods in their groups, which yielded considerably lower temporal similarity compared to the corresponding spatial similarity. This suggests that although CHMM and TF exhibit similar spatial patterns to the methods in their groups, they do not exhibit equally similar temporal dynamics (see   and  ). \n\n\n### Intersubject similarities reflect the previously observed overall similarity patterns \n  \nTo assess an intersubject similarity between methods, dFC matrices estimated by each method were used to measure intersubject correlations (  values) (see equation\u00a0 ). The intersubject values obtained for each method were then compared and the similarity between methods was measured using Spearman correlation (see equation\u00a0 ). The resulting correlation values (Fig.\u00a0 ), indicating intersubject correlation correspondence between methods, revealed the same 3 groups of methods in terms of their similarity. This implies that if one method identifies 2 subjects as similar based on their dFC patterns, it is more likely that another method from the same group will also identify those 2 subjects as similar. This finding suggests that the methods grouped together not only demonstrated similarity in capturing subject-level patterns but also exhibited consistency in capturing intersubject patterns. For results obtained using fractional occupancy (FO) as the feature used for assessing the intersubject correlations, see  . \n\n\n### The variability over method is comparable to the variability over time for most functional connections \n  \nThe variance of dFC,   dFC   (  subject, method, time, functionalConnection  ), was calculated over time and method, across functional connections and subjects. To account for the different value distributions of each method, the dFC matrices for each subject,   dFC   (  subject  ,   method  ,   time, functionalConnection  ), were normalized by ranking the values, similar to the approach used when calculating Spearman correlation. We calculated variance over time,   var   (  dFC   (  subject, method, :, functionalConnection  )), averaging over method, and the variance over method,   var   (  dFC   (  subject, :, time, functionalConnection  )), averaging over time. Therefore, both calculations resulted in an array of   subject   \u00d7   functionalConnection   values (1 \u201ctemporal variance\u201d and 1 \u201cmethods variance\u201d value per functional connection and per subject). The results, shown in Fig.\u00a0 , indicate that the variation over dFC methods was comparable to the variation over time for most functional connections and subjects, leading to an average ratio of   var  /  var  \u00a0=\u00a00.95, or an average ratio of   SD  /  SD  \u00a0=\u00a00.97. For the variability of the results obtained across method pairs and method groups, see   and  . Moreover, Fig.\u00a0  highlights the pair of RSNs with functional connections that exhibited higher variability over method than over time. These functional connections mainly include connections between the default mode and other networks, such as parieto-occipital, frontoparietal, salience, cingulo-opercular, medial-parietal, dorsal attention, and ventral attention networks, as well as most intranetwork connections, with the exception of the cingulo-opercular network. \n  \n(A) A scatterplot of the variance over methods versus the variance over time for each functional connection and each subject (  subj   \u00d7 (  ROI   \u00d7 (  ROI   \u2212 1)/2) points in total) indicates that the variance over dFC methods is comparable to the variance over time, with an average ratio of   var  /  var  \u00a0=\u00a00.95 (  SD  /  SD  \u00a0=\u00a00.97). (B) Ratios of variance over method divided by variance over time across functional connections averaged over subjects. The ratios were subtracted by 1 (  ratio   \u2212 1) so that zero values (white) correspond to equal variance over method and time. The current figure\u00a0highlights resting-state network (RSN) pairs with functional connections that are more variable over method than time (red) and those more variable over time than method (blue). The variance values corresponding to functional connections belonging to each pair of RSNs were averaged to yield a single variance value prior to computing the ratios. The plot shows that the functional connections between RSNs (such as the frontoparietal and ventral attention networks) exhibited equal variance values over time and method, while the functional connections between RSNs (such as the default mode and parieto-occipital, as well as default mode and frontoparietal networks) and most intranetwork connections exhibited higher variation over method than over time. \n  \nWe also compared the variability over method with the variability over subject. After normalizing the dFC matrices by ranking their values, we calculated the variance over method,   var   (  dFC   (  subject, :, time, functionalConnection  )), averaging over time and subject, and the variance over subject,   var   (  dFC   (:,   method, time, functionalConnection  )), averaging over time and method. Both calculations resulted in an array of   functionalConnection   values. This yielded an average ratio of   var  /  var  \u00a0=\u00a00.90, or an average ratio of   SD  /  SD  \u00a0=\u00a00.94 (see  ). \n\n\n\n## Discussion \n  \n### The variability observed in dFC assessment encourages multianalysis studies \n  \nIn the present study, our main aim was to assess the analytical flexibility of dFC assessment methods. One of the primary challenges of comparing dFC assessment methods is the lack of a biological reference to determine the significance of the observed variability over methods. While no clear biological reference exists for resting-state fMRI data, we compared the assessed variability over methods with connection variation over time as well as intersubject variability. The results (Fig.\u00a0  and  ) suggest that the variance over methods is on average 0.95 of the variance over time and 0.90 of the variance over subjects. These findings indicate that changing the assessment method may lead to a dFC value that is on average as different as a dFC value obtained at another time point or from another subject using the same method. Moreover, although these biological scales may not be appropriate for every situation, they still can serve as a valid point of reference. Specifically, in the case of comparison with temporal variability, the variation of dFC over time is the main biological phenomenon that the dFC methods aim to measure. These results indicate the variation due to the choice of methodology has an impact as large as the scale of the underlying biological phenomenon of interest. \n\nFor further investigation of the analytical flexibility, we conducted a comprehensive comparison of the dFC estimates obtained by different methods using the following approaches: (i) subject-wise comparison of dFC matrices in terms of overall similarity (Fig.\u00a0 ), (ii) time point-wise comparison of FC matrices in terms of their spatial similarity (Fig.\u00a0 ), (iii) functional connection-wise comparison of time courses in terms of their temporal similarity (Fig.\u00a0 ), and (iv) comparison in terms of intersubject correlation similarity (Fig.\u00a0 ). Our similarity analysis identified 3 groups of methods in terms of the similarity of the obtained dFC patterns. The examined methods, while exhibiting fair intragroup similarities, exhibited considerable intergroup variability. \n\nThe identified intra- and intergroup similarity profiles can be largely attributed to the underlying assumptions of the examined methods. For example, both WL and CAP disregard the temporal ordering of the BOLD data, allow for instantaneous reconfiguration of FC states, and do not impose a locality assumption. These assumptions enable them to capture more rapid reconfigurations in FC patterns. Conversely, SWC, CHMM, and DHMM, take into account the temporal ordering of the data and assume locality of neighboring time points, resulting in smoother changes over time (see  ). These assumptions allow these methods to accurately quantify the temporal dependencies between FC patterns at different time points and the slower dynamics of FC. Lastly, SW and TF do not assume the presence of recurring group-level FC patterns, which allows them to capture the individual subject variability to a greater extent. See Table\u00a0  for a summary of the assumptions of each method. These assumptions are rarely invoked in the literature applying dFC technique in a specific study. \n\nThe patterns of similarity observed in this study do not imply the superiority of any dFC assessment method or group of methods. Instead, they reveal 3 groups of methods, each characterized by their specific assumptions, advantages, and disadvantages. These results show that a single analysis or group of analyses may not capture the richness of dFC and that the use of multiple methods from different groups may reveal different features of dFC. In this regard, developing specialized tools to facilitate the conjoint use of multiple dFC methods, such as the one developed in this study, will aid to fully characterize dFC. For instance, by using one method from the SWC, CHMM, and DHMM group; one from the WL and CAP group; and one from the SW and TF group, one can capture rapid FC patterns, as well as temporal dependencies of FC patterns, and subject-specific information. \n\nThis approach is particularly important when classifying subjects based on features derived from dFC, as shown in our intersubject similarity results (Fig.\u00a0 ). We found that using methods from 2 different groups (e.g., CAP and SWC) can lead to different intersubject similarity patterns, consequently leading to different clusters of subjects. Hence, we recommend that clustering is performed using multiple methods from different groups. This can help uncover meaningful subgroups or relationships that may not be apparent when using a single method and ensure that the identified clusters are not solely dependent on the choice of a specific method. \n\n\n### Understanding temporal complexity in dynamic functional connectivity assessment: what lies behind the variations in dynamic functional connectivity? \n  \nEvaluating the overall similarity among the outcomes of various methods offers a perspective on the intermethod similarity relationships. However, it remains unclear to what extent these similarities can be attributed to the spatial and temporal aspects of dFC. Based on our results, in most cases, while the spatial comparison of dFC patterns obtained by different methods (Fig.\u00a0 ) exhibited strong similarity between methods, the comparison in terms of temporal dynamics exhibited moderate similarity (Fig.\u00a0 ). Even the methods with the highest spatial similarity, SWC and DHMM, showed low similarity in the time domain. This suggests that capturing the temporal variations of FC may be more challenging than capturing the spatial patterns of dFC.   shows that although methods having higher spatial similarity are more likely to have higher temporal similarity, the level of temporal similarity is smaller than the level of spatial similarity in most cases. CHMM, as a particular example, exhibited a high spatial similarity with SWC and DHMM but a low temporal similarity with these methods (also supported by   showing the similarity of intertime correlations). \n\nOur supplementary material results suggest that in several cases, pairs of methods did not exhibit a significantly greater similarity compared to the similarity obtained when the dFC matrices were randomly shuffled with respect to time ( ; note that the fractional occupancy of the states was preserved for the shuffled dFC matrices). Pairs of methods exhibiting strong similarity between their time-shuffled dFC matrices indicate that the average similarity between all pairs of their spatial patterns, or FC matrices, even at different time points, is high. For instance, CHMM-SWC exhibited a relatively high overall similarity, but their similarity did not change significantly when the dFC matrices were time-shuffled. This implies that the dFC matrices of CHMM and SWC did not exhibit more consistency in terms of their patterns of variation over time than the time-shuffled dFC matrices and that the observed strong similarity between them was mostly a result of the strong similarity between their spatial patterns. On the other hand, WL-CAP, despite having a low overall similarity, showed significantly greater similarity when compared to the shuffled-time similarity distribution. This implies that their temporal variations exhibited more consistent patterns than those of the time-shuffled dFC matrices, indicating that their low overall similarity was caused by low similarity of their spatial patterns. These observations highlight that the variability in the dFC results may spread differently across the temporal and spatial dimensions, and strong similarity in one dimension does not necessarily imply similarity for the other dimension. It also suggests that comparing the overall similarity of dFC results or comparing only their spatial patterns may not provide a comprehensive understanding of the relation between methods. \n\nFuture research should conduct more in-depth comparisons of dFC assessment methods, focusing on the temporal dynamics of their outputs, to shed light on the reason for the observed variability over methods. This is crucial, as temporal dynamics play a significant role in dFC and have already been a source of controversy regarding their origins. Our results suggest that a part of these temporal variations may originate from the methodology used for assessing them. \n\nPrevious studies have demonstrated that physiological factors, such as respiration, cardiac activity, and motion artifacts, also modulate the temporal variations of dFC [ ,  ]. These nonneural sources of variability can confound the interpretation of dFC patterns and potentially lead to erroneous conclusions. Future research could develop advanced techniques, including denoising algorithms, physiological signal regression, and data-driven approaches, to effectively isolate the neural-driven part of dFC variations from the physiological sources. By disentangling these sources, researchers could gain a more precise understanding of the genuine neural dynamics underlying dFC, enhancing the reliability of dFC studies and their potential applications in clinical diagnostics and treatment evaluations. \n\n\n### Study limitations and future directions \n  \nPotential future work should review external validation techniques and develop a validation framework to assess the accuracy of dFC assessments in more controlled paradigms, such as predicting cognitive state of the subjects, using simulated data, and assessing the consistency of the result with the neural activation patterns derived from simultaneous electrophysiological recordings. Evaluating the dFC assessment methods using such paradigms will lead to a better understanding of the reasons behind the observed variability between the results yielded by different dFC methods. Furthermore, it would shed light on the varying levels of method variability observed across different RSNs by identifying the factors that contribute to higher variability in certain RSN pairs compared to others. Our hypothesis is that the distinct signal-to-noise ratios (SNRs) among the BOLD signals of different RSNs (e.g., due to varying susceptibility to physiological signals) could contribute to this observation [ ]. For instance, the default mode network (DMN) encompasses highly vascular areas and regions that are part of the central autonomic network [ ,  ], and this can lead to a different level of SNR and therefore methodological variability in DMN compared to other networks. Moreover, the pronounced time-varying connectivity patterns of the DMN, potentially arising from its role as a relay between different networks [ ,  ], challenge methods aiming to accurately capture FC dynamics, thereby leading to larger methodological variability. However, a comprehensive interpretation and validation of these hypotheses require further investigation through simulation studies and controlled paradigms. Additionally, using such paradigms would also provide a more reliable biological reference for quantifying the magnitude of the observed methods\u2019 variability. One of the limitations of the current study is the lack of a clear biological reference. The nature of resting-state data makes it challenging to establish expected patterns or variations in dFC over time or across subjects. This is primarily because subjects are free to engage in any mental activity during the resting state [ ,  ]. In contrast, controlled paradigms, such as the ones mentioned earlier, involve specific instructions or tasks, resulting in more deterministic dFC patterns. For instance, in task-based paradigms, subjects perform specific tasks, leading to more comparable dFC patterns and enhanced interpretability of intersubject variability. Similarly, simultaneous fMRI and electrophysiological recordings can provide a more reliable biological reference through the integration of electrophysiological activity. Therefore, future work should prioritize the use of such paradigms to facilitate the utilization of more interpretable biological references. \n\nIt is worth noting that in our study, we adopted the hyperparameter values recommended by the original study or consensus among the community for each method, which may contribute to the observed variability in our results. Different hyperparameter choices could lead to different similarity patterns among methods and varying levels of variability. Therefore, future work should also investigate the sensitivity of dFC assessment results to the choice of hyperparameters and their effect on the observed variability. \n\nAssessing the robustness of neuroscience results with respect to dFC analytical flexibility should be strongly recommended. We propose the utilization of multianalysis approaches, preferably using methods that show less similar results, for assessing dFC and reporting a more comprehensive view of the data, made easier with the Python toolbox released with this article. While the use of several methods may cause interpretation and statistical challenges, assessing the variability of the results is important. As this may not always be feasible, it is also reasonable to select a single dFC method based on the specific research objectives, method strengths and limitations, compatibility with the study design, and data characteristics. \n\nWhile this study does not permit unequivocal recommendations regarding an optimal methodology, given the absence of a clear ground truth, researchers may adopt a pragmatic approach by considering the assumptions and individual properties outlined for each method in alignment with their specific analytical needs. For example, given the relatively similar results produced by WL and CAP, one might favor WL over CAP due to its significantly shorter computation time (refer to  ). The choice between methods such as SWC and DHMM, given their similar results, depends on the preference for implementation complexity; SWC may be preferred for simplicity, while DHMM offers a more comprehensive assessment. In cases where the dependency between time points is a critical consideration, selecting a method from the SWC-CHMM-DHMM group or the SW-TF group is advisable over a method from the WL-CAP group, while in the cases where capturing rapid transitions of FC is critical, choosing a method from the WL-CAP group may be insightful (refer to Table\u00a0  and  ,  , and  ). \n\n\n\n## Conclusions \n  \nIn conclusion, the present study aimed to evaluate the analytical flexibility of dFC measurement methods and establish how analytical flexibility compares to biological variability. The comparison results show a wide range of similarity patterns across methods. The variability found in the results highlights the importance of carefully motivating and validating the choice of a specific dFC assessment method. The use of multiple methods would mitigate the issues arising from analytical flexibility and better characterize the richness of dFC measurements. Future work should aim to develop a validation framework and evaluate the accuracy of dFC assessments through external validation techniques. \n\n\n## Availability of Source Code and Requirements \n  \n PydFC   is an open-source toolbox available on GitHub [ ].   PydFC   is registered with the SciCrunch Registry ( ) and bio.tools Registry (biotoolsID:   biotools:pydfc  ). \n  \nProject name:   PydFC  \n  \nDOI: 10.5281/zenodo.10161176 \n  \nProgramming language: Python \n  \nOperating System(s): Platform independent \n  \nSource code:  \n  \nbiotoolsID: biotools:pydfc \n  \nRRID:   SCR_024729  \n  \nLicense: MIT License \n  \n\n## Supplementary Material \n  \n \n", "metadata": {"pmcid": 11000510, "text_md5": "b9a793f190ee3d617a699545fa8ab333", "field_positions": {"authors": [0, 65], "journal": [66, 77], "publication_year": [79, 83], "title": [94, 166], "keywords": [180, 302], "abstract": [315, 2201], "body": [2210, 61519]}, "batch": 3, "pmid": 38587470, "doi": "10.1093/gigascience/giae009", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11000510", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=11000510"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11000510\">11000510</a>", "list_title": "PMC11000510  On the variability of dynamic functional connectivity assessment methods"}
