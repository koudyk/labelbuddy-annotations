{"text": "Gentile, Giovanni and Bj\u00f6rnsdotter, Malin and Petkova, Valeria I. and Abdulkarim, Zakaryah and Ehrsson, H. Henrik\nNeuroimage, 2015\n\n# Title\n\nPatterns of neural activity in the human ventral premotor cortex reflect a whole-body multisensory percept\n\n# Keywords\n\n\n\n# Abstract\n \nPrevious research has shown that the integration of multisensory signals from the body in fronto-parietal association areas underlies the perception of a body part as belonging to one's physical self. What are the neural mechanisms that enable the perception of one's   entire   body as a unified entity? In one behavioral and one fMRI multivoxel pattern analysis experiment, we used a full-body illusion to investigate how congruent visuo-tactile signals from a single body part facilitate the emergence of the sense of ownership of the entire body. To elicit this illusion, participants viewed the body of a mannequin from the first-person perspective via head-mounted displays while synchronous touches were applied to the hand, abdomen, or leg of the bodies of the participant and the mannequin; asynchronous visuo-tactile stimuli served as controls. The psychometric data indicated that the participants perceived ownership of the entire artificial body regardless of the body segment that received the synchronous visuo-tactile stimuli. Based on multivoxel pattern analysis, we found that the neural responses in the left ventral premotor cortex displayed illusion-specific activity patterns that generalized across all tested pairs of body parts. Crucially, a tripartite generalization analysis revealed the   whole-body   specificity of these premotor activity patterns. Finally, we also identified multivoxel patterns in the premotor, intraparietal, and lateral occipital cortices and in the putamen that reflected multisensory responses specific to individual body parts. Based on these results, we propose that the dynamic formation of a whole-body percept may be mediated by neuronal populations in the ventral premotor cortex that contain visuo-tactile receptive fields encompassing multiple body segments. \n   Highlights  \n  \nWe examine the neural and perceptual correlates of whole-body ownership. \n  \nBehavioral findings describe the formation of a whole-body multisensory percept. \n  \nWe use multivoxel pattern analysis of fMRI data to explore the linked neural basis. \n  \nActivity patterns in the ventral premotor cortex reflect a whole-body percept. \n  \n \n\n# Body\n \n## Introduction \n  \nFew things are as thoroughly engrained in our perceptual experience of the world as our own body, and the origins of the sense of bodily self have intrigued philosophers and scientists for centuries ( ). Recent advances have associated the integration of spatio-temporally interrelated visual, tactile, and proprioceptive signals in multisensory brain regions with the experience of a limb as a part of one's body ( ). However, these accounts of limb ownership cannot fully characterize the perception of one's   entire   body as a unified entity, i.e., a multisensory percept that extends beyond a fragmented set of individual anatomical segments ( ). Recently, cognitive neuroscientists have employed \u201cfull-body illusions\u201d to examine how a whole-body percept is formed ( ). Based on the characterization of the perceptual rules that govern the elicitation of these illusions and the identification of the corresponding illusion-specific brain responses, relevant insights can be gained regarding the processes that underlie whole-body perception under natural conditions ( ). \n\nIn the full-body illusion paradigm introduced by  , the delivery of synchronous touches to the body of a mannequin viewed from the first-person perspective and the corresponding location on the participant's unviewed body elicits a perception of ownership of the mannequin's body. A plethora of subsequent studies has suggested that this illusion can be explained within a multisensory theoretical framework in which the brain integrates spatio-temporally congruent signals in egocentric spatial reference frames ( ). Neuroimaging evidence suggests that the generalization of ownership may be mediated by neuronal populations in the ventral premotor cortex that contain large visuo-somatic receptive fields encompassing multiple body segments ( ). However, the previous behavioral ( ; see also  ) and neuroimaging ( ) studies that have addressed the key issue of the generalization of ownership from the stimulated body part to the entire body included only a single pair of body segments: the abdomen and the hand. However, the characterization of this generalization of ownership requires the systematic examination of an illusion across at least three anatomically distant body segments to enable inferences regarding the mechanisms that pertain to the whole body. \n\nHere, we adapted   full-body illusion paradigm and conducted one behavioral and one fMRI experiment to investigate the generalization of ownership across three separate body parts: the right hand, the abdomen, and the right leg. The psychometric data confirmed that the participants experienced ownership of all body parts, regardless of which parts received visuo-tactile stimulation. More importantly, the fMRI experiment revealed multivoxel patterns in the left ventral premotor cortex that reflect ownership across all combinations of body parts (hand to/from abdomen; hand to/from leg; and leg to/from abdomen). Crucially, tripartite generalization analysis identified illusion-specific patterns across all three stimulation sites. Taken together, these results suggest a potential cortical mechanism underlying the formation of a whole-body percept via the integration of multisensory signals across multiple body segments. \n\n\n## Materials and methods \n  \n### Participants \n  \nTwenty-two healthy participants (5 females, age range 19\u201341\u00a0years) were recruited for the behavioral experiment (Experiment 1). A different group of 16 healthy participants (5 females, age range 20\u201359\u00a0years) participated in the functional brain imaging experiment (Experiment 2). All participants were right-handed, exhibited normal or corrected-to-normal vision and reported no history of neurological or sensory disorders. Informed consent was obtained from all participants prior to the experimental sessions, and all participants received monetary compensation. The Regional Ethical Review Board of Stockholm approved this study. \n\n\n### Experiment 1: behavioral investigation of the generalization of the perception of body ownership \n  \n#### Experimental setup \n  \nWe adapted a previously validated experimental paradigm to elicit the perceptual illusion of owning an entire artificial body ( ). In this paradigm, the participant wore a pair of head-mounted displays (45 degree field-of-view in the horizontal plane) through which a stereoscopic image of the body of a mannequin was projected ( A). Both the participant and the mannequin were placed comfortably in a supine position, which was consistent with the posture of the participants during the fMRI experiment. Furthermore, the participant observed the body of the mannequin from the first-person perspective, thereby ensuring a match between the viewed and perceived positions of the artificial and veridical bodies, respectively. A trained experimenter applied touches to one of three different body parts (hand, abdomen, or leg;  A) on the bodies of both the participant and the mannequin. The visuo-tactile stimuli were delivered in a synchronous (full temporal overlap) or asynchronous (fully non-overlapping) manner for 2-minute intervals. The synchronous mode of visuo-tactile stimulation induces the illusion of ownership of the mannequin's body, whereas the asynchronous mode serves as a control for otherwise equivalent conditions ( ). The 3\u00a0\u00d7\u00a02 factorial design (body part\u00a0\u00d7\u00a0visuo-tactile stimulation mode) resulted in 6 experimental conditions, the order of which was randomized across the participants. At the end of each 2-minute interval of visuo-tactile stimulation, the participants were presented with a questionnaire composed of 8 separate statements that were rated on a 7-point Likert scale, which ranged from \u2212\u00a03 (\u201c  I fully disagree with the statement  \u201d) to +\u00a03 (\u201c  I fully agree with the statement  \u201d). The complete list of questionnaire items is reported in  . The first two statements (S1 and S2) captured the illusory referral of somatic sensations to the virtual body for each of the three body parts investigated. Statements S3, S4, and S5 probed the perceptual generalization of the perception of body ownership from the stimulated body part to the whole body in a manner that was compatible with the emergence of a whole-body percept. Finally, statements S6, S7, and S8 served as controls for task compliance and suggestibility. To maintain the corresponding psychometric and neural assessments of the generalization of the feeling of ownership as independent from each other as possible, the behavioral and neuroimaging experiments were performed on two separate groups of na\u00efve participants. Although this approach did not enable a within-group examination of the relationship between the psychometric and neuroimaging data, it assured the full independence of the findings from the two experiments. \n\n\n#### Behavioral data analysis \n  \nThe questionnaire data were assessed for normality using the Kolmogorov\u2013Smirnov test in SPSS 20 (IBM Corporation, USA). For data that did not pass the test for normality, we used non-parametric statistics to evaluate the significance of the comparisons of interest. The individual ratings for statements S1, S2, S3, S4, and S5 (see   for details) did not pass the Kolmogorov\u2013Smirnov test for normality and were analyzed using non-parametric tests (results reported in  C, D,  A, and B). Wilcoxon signed-ranks tests were used to compare the condition-specific ranks, and positive correlations were evaluated for significance using Kendall's tau bivariate correlation tests. All statistical tests comprised planned comparisons between the conditions of interest and the control conditions (  Synch   vs.   Asynch  ), and the planned correlation analyses were also formulated as a priori hypotheses. Based on our strong a priori predictions regarding the direction of the behavioral results ( ), we report one-tailed tests throughout the presentation of the results. The significance threshold was set to 5%. \n\n\n\n### Experiment 2: neural mechanisms of the generalization of the feeling of body ownership \n  \n#### Experimental setup \n  \nWe used a previously validated experimental setup to induce the perceptual illusion of owning an entire virtual body in the environment of an MRI scanner ( ). The participants laid comfortably in a supine position on the bed of the MRI scanner. Their head was propped up (~\u00a030\u00b0) using a custom-made wooden wedge and foam pads to allow the participants to look directly into a pair of MR-compatible head-mounted displays (Nordic Neuro Lab, Bergen, Norway; field of view 30\u00b0 horizontal\u00a0\u00d7\u00a023\u00b0 vertical; resolution 800\u00a0\u00d7\u00a0600), which was positioned in front of their eyes. The visual stimuli were presented to the participants via the head-mounted displays using a computer running Presentation software (version 13.1, NeuroBehavioral System, Pennsylvania, USA) and consisted of a series of pre-recorded videos that featured the experimental conditions of interest (details in the subsequent section). The visual stimuli were recorded using a red/blue stereoscopic camera (Novo Minoru, Salford, United Kingdom) and were presented to the participants as three-dimensional stimuli by superimposing red and blue filters in front of the left and right head-mounted displays, respectively. Tactile stimuli were manually applied by a trained experimenter who was positioned on the participant's right side at all times during the acquisition session. The experimenter was trained to minimize the range of motion associated with the delivery of the tactile stimuli, thereby avoiding potential motion-induced artifacts in the acquired images. The experimenter received auditory instructions related to the timing and location (hand, abdomen, or leg) of the tactile stimuli during each trial. Importantly, the auditory cues were designed to ensure that the experimenter was blinded to the sequence and type (synchronous vs. asynchronous) of each condition. The na\u00efve participants were instructed to passively observe the visual stimuli presented via the head-mounted displays and to not engage in any task. \n\n\n#### Experimental conditions and design \n  \nAnalogous to the behavioral experiment, the visuo-tactile stimuli were applied to three different body parts on both the 3D-video image of the body of the mannequin (in view) and the corresponding part of the participant's body (not in view). Under the experimental conditions of interest, the participants were presented with three-dimensional video recordings of the body of the mannequin viewed from the first-person perspective in a manner that ensured a match between the viewed and perceived postures of the virtual and veridical bodies, respectively ( A). The visuo-tactile stimuli were applied to the right hand, the right side of the abdomen, or the right upper leg for a period of 35\u00a0s ( B). Each trial contained 30 individual visuo-tactile stimuli, which consisted of brisk strokes delivered by the experimenter's right index finger and spanned a 5-cm trajectory on the corresponding body part. The visuo-tactile stimuli were delivered either completely synchronously (  Hand Synch  ,   Abdomen Synch  , and   Leg Synch  ) or asynchronously, in which a delay of approximately 1\u00a0s was introduced between the visual and tactile stimuli (  Hand Asynch  ,   Abdomen Asynch  , and   Leg Asynch  ). The synchronous mode of visuo-tactile stimulation induces the full-body ownership illusion, whereas the asynchronous mode serves as a control for the otherwise equivalent experimental conditions ( ). Furthermore, the participants were presented with trials in which the mannequin's virtual body was removed, with the exception of the right arm, which was presented in an implausible detached posture (  Detached Hand  ;  A). Identical periods of visuo-tactile stimulation were delivered to the detached virtual right arm in either a synchronous (  Detached Hand Synch  ) or asynchronous manner (  Detached Hand Asynch  ). A previous study revealed that this condition significantly reduces the perceptual illusion of owning the mannequin's body ( ). Importantly, the   Detached Hand   condition provides an experimental term of comparison to elucidate the multisensory integrative effects that are specific to the context of an entire body. Moreover, it enables rigorous control for potential differences in brain activity produced by the two modes of visuo-tactile stimulation (synchronous vs. asynchronous) that do not reflect the illusion-specific perceptual integration of the visual and tactile signals in the context of an entire body ( ). Thus, the experimental design consisted of eight different conditions presented in a random order. The trials were grouped in two blocks of eight during each acquisition session. A 3-second baseline interval that consisted of a black screen and no visuo-tactile stimuli was inserted between consecutive trials, whereas an identical 20-second baseline interval was inserted between the two blocks of trials during each session. Four sessions were acquired, which resulted in eight repetitions of each of the eight experimental conditions of interest. \n\n\n#### FMRI data acquisition \n  \nFMRI acquisition was performed using a Siemens TIM Trio 3\u00a0T scanner equipped with a 12-channel head coil. Gradient echo T2*-weighted EPIs with BOLD contrast were used as an index of brain activity ( ). The functional image volume was composed of 47 continuous near-axial slices of 3\u00a0mm thickness (with a 0.1\u00a0mm interslice gap), which ensured that the entire brain was within the FOV (58\u00a0\u00d7\u00a076 matrix; 3.0\u00a0mm\u00a0\u00d7\u00a03.0\u00a0mm in-plane resolution; TE\u00a0=\u00a040\u00a0ms; and flip angle\u00a0=\u00a090\u00b0). One complete volume was collected every 3\u00a0s (TR\u00a0=\u00a03000\u00a0ms). The first three volumes of each session were discarded to account for non-steady state magnetization. To facilitate the anatomical localization of statistically significant activations, a high-resolution structural image was acquired for each participant at the end of the experiment (3D MPRAGE sequence: voxel size\u00a0=\u00a01\u00a0mm\u00a0\u00d7\u00a01\u00a0mm\u00a0\u00d7\u00a01\u00a0mm; FOV\u00a0=\u00a0250\u00a0mm\u00a0\u00d7\u00a0250\u00a0mm; 176 slices; TR\u00a0=\u00a01900\u00a0ms; TE\u00a0=\u00a02.27\u00a0ms; and flip angle\u00a0=\u00a09\u00b0). \n\n\n#### Data preprocessing \n  \nThe functional imaging data were processed using SPM8 (Wellcome Trust Center for Neuroimaging, London, UK) and Matlab scripts, which were adapted from the Princeton Multi-Voxel Pattern Analysis Toolbox ( ). The functional volumes were realigned to the first volume of each series, corrected for slice-timing errors, and co-registered to the high-resolution structural image. The high-resolution structural image was segmented into gray matter, white matter, and cerebrospinal fluid regions and normalized to the standard MNI space. Then, the identical transformation was applied to all functional images, which were re-sliced to a resolution of 2\u00a0mm\u00a0\u00d7\u00a02\u00a0mm\u00a0\u00d7\u00a02\u00a0mm and spatially smoothed using an 8\u00a0mm FWHM Gaussian kernel. The response of each voxel was normalized to the average time course within each scan. To enable the induction of the illusion of owning the virtual mannequin's body, the first 10\u00a0s of each trial were excluded from the multivoxel analyses. This procedure has been validated in a series of previously published behavioral and fMRI experiments ( ). Prior to the multivoxel analyses, single-trial estimates were calculated by averaging the BOLD response across the remaining 25\u00a0s of visuo-tactile stimulation in each trial for each condition separately. Given the long duration of each trial and the exclusion of the first 10\u00a0s from the multivoxel analyses, we did not explicitly model the hemodynamic response function in the single-trial estimation. \n\n\n#### Multivoxel pattern analyses \n  \nWe employed locally multivariate mapping ( ) to investigate the neural mechanisms underlying the construction of a unified perceptual representation of one's own body from the representation of its individual parts. Individual functional volumes were randomly partitioned into approximately spherical search volumes displaying a radius of 3\u00a0voxels. In each search volume, multivoxel classification analysis was applied, yielding a decoding accuracy for the analysis of interest (see below for details). Then, each voxel was assigned the average decoding accuracy calculated across all search volumes, including the given voxel. Multivoxel classification was performed using a linear support vector machine (in the LIBSVM implementation using fixed regularization parameter C\u00a0=\u00a01;  ). \n\nFirst, we performed multivoxel pattern analysis to identify the voxels whose BOLD response patterns encoded the illusion-specific integration of visual and tactile signals   across   the different body parts that received multisensory stimulation (hand, abdomen, or leg). Thus, this analysis identified the voxels that generalized the illusory integrations of visuo-tactile signals across multiple body parts in a manner that was compatible with the construction of a multisensory percept of the whole owned body. This result would be expected from neuronal populations containing visuo-tactile receptive fields that encompass multiple body segments or the entire body. Linear classifiers were trained to decode the differences in the BOLD response patterns generated by the   Synch   and   Asynch   conditions for a given body part in each participant (  Hand Synch   vs.   Hand Asynch  ;   Abdomen Synch   vs.   Abdomen Asynch  ; and   Leg Synch   vs.   Leg Asynch  ). Then, the trained classifiers were tested on the untrained data from the remaining body parts. For example, a classifier trained to decode   Hand Synch   vs.   Hand Asynch   was evaluated with respect to the response patterns generated by   Abdomen Synch   vs.   Abdomen Asynch   and   Leg Synch   vs.   Leg Asynch   ( C). Then, we calculated the average decoding accuracy for a given pairwise classification (e.g., the average decoding accuracy of a classifier trained on   Hand   and tested on   Abdomen   and, inversely, a classifier trained on   Abdomen   and tested on   Hand  ). This procedure generated three average pairwise decoding maps (  Hand and Abdomen  ,   Hand and Leg  , and   Abdomen and Leg  ) for each participant. Then, the chance level (50%) was subtracted from each decoding map, followed by spatial smoothing using an 8\u00a0mm FWHM Gaussian kernel. Next, the maps were evaluated via group random effect analysis using SPM8 to test for voxelwise statistical significance. The whole brain significance threshold was set to a p-value of 0.05 corrected for multiple comparisons using the family-wise error rate (FWE). Given our strong a priori hypotheses, we performed small-volume corrections (at the same threshold of p\u00a0<\u00a00.05 FWE) in a left ventral premotor region of interest derived from a previous study ( ). This approach ensured that none of the analyses performed were statistically circular. The same procedure was applied to all further analyses described in the following section. For descriptive purposes only, we report the peak decoding accuracies for the analyses of interest in  . The individual decoding accuracies were extracted from a 10-mm radius sphere centered on the group peaks reported in  , and the group averages and standard errors were calculated and are reported for the sake of completeness. \n\nSecond, we performed a multivoxel analysis that included the   Detached Hand   condition as a control analysis (as described above). The identical linear classifiers as those defined above, which were trained to detect the response patterns that were specific to the perceptual integration of the visual and tactile signals from a given body part (  Hand Synch   vs.   Hand Asynch  ;   Abdomen Synch   vs.   Abdomen Asynch  ; or   Leg Synch   vs.   Leg Asynch  ), were tested on the response patterns generated by   Detached Hand Synch   vs.   Detached Hand Asynch  . The inverse procedure was also performed. This analysis allowed us to test the hypothesis that the multivoxel patterns identified by the previous analysis preferentially reflected the perceptual integration of visuo-tactile information from a given body part in the whole-body context. Furthermore, this analysis enabled us to rule out non-specific differences in the response patterns between the   Synch   and   Asynch   conditions, which might otherwise contribute to the results of the primary multivoxel analyses. \n\nThird, we built upon the generalization analysis described above to further evaluate the hypothesis that the neuronal populations whose illusion-specific response patterns were generalized across the three body parts were associated with multisensory receptive fields that encompass all three body parts. In light of the previous set of analyses alone, it cannot be conclusively ruled out that the pairwise generalization findings obtained from the above analyses, namely,   Hand\u2013Abdomen  ,   Hand\u2013Leg  , and   Abdomen\u2013Leg  , might be ascribed to neuronal populations containing visuo-tactile receptive fields that incorporate only two of the three body parts investigated. To test for the existence of neuronal populations containing visuo-tactile receptive fields that are sufficiently large to encompass all three body parts, and are, therefore, compatible with the construction of a whole-body percept, we conducted a new set of multivoxel analyses. Specifically, linear classifiers were first trained to detect differences between the response patterns between the   Synch   and   Asynch   stimulation conditions across two of the three body parts (for example,   Hand Synch, Abdomen Synch   vs.   Hand Asynch, Abdomen Asynch  ). Then, the classifiers were tested on the untrained data from the remaining body part (for example,   Leg Synch   vs.   Leg Asynch  ). If the response patterns from which a classifier was trained arose from neuronal populations containing visuo-tactile receptive fields that extended to only two body parts (the hand and the abdomen in the example provided above), then no significant generalization to the third tested body part would be expected (the leg in the example provided above). Hence, significant results from this analysis would identify the neuronal populations containing multisensory receptive fields that are sufficiently large to encompass all three anatomically distant body parts. \n\nFourth, we performed an independent set of multivoxel analyses to identify the multisensory response patterns that are specific to only one of the body parts investigated. Unlike the analyses described above, this investigation was targeted at neuronal populations containing visuo-tactile receptive fields that are restricted to a specific body part and its surrounding area. This finding would be compatible with the well-known existence of neuronal populations that integrate congruent visual and tactile signals to generate body part-specific representations of different body segments ( ). We first trained and tested linear classifiers to decode the differences in the patterns of brain activity that corresponded to all pairwise comparisons between the three body parts under the   Synch   stimulation conditions (  Hand Synch   vs.   Abdomen Synch  ;   Hand Synch   vs.   Leg Synch  ; and   Abdomen Synch   vs.   Leg Synch  ;  A). A 10-fold cross-validation procedure was used to compute the decoding accuracies for each pairwise comparison. Next, we applied an equivalent classification analysis to the corresponding pairwise comparisons under the   Asynch   stimulation conditions (  Hand Asynch   vs.   Abdomen Asynch  ;   Hand Asynch   vs.   Leg Asynch  ; and   Abdomen Asynch   vs.   Leg Asynch  ). Then, we performed a second-level analysis by combining the data from the three pairwise comparisons into average decoding maps for the   Synch   and   Asynch   conditions and by subtracting the map for the   Asynch   condition from the map for the   Synch   condition. These second-level analyses were performed using SPM8 according to the procedure described above. Small volume corrections (p\u00a0<\u00a00.05 FWE) were performed around peaks based on an earlier study ( ). For descriptive purposes only, in  , we also report the significant pairwise peaks for the   Synch   decoding maps that were associated with the significant group decoding peaks from the average   Synch   minus   Asynch   analysis. These peaks were masked exclusively with the regions associated with the   Asynch   pairwise decoding maps, which were thresholded at p\u00a0<\u00a00.01, uncorrected for multiple comparisons. \n\n\n\n\n## Results \n  \n### Behavioral results: the emergence of the whole-body multisensory percept \n  \nWe adopted a previously validated setup to induce the perceptual illusion of ownership of a mannequin's body viewed from the first-person perspective via a set of head-mounted displays ( ). In contrast to previous behavioral studies, we induced this illusion by applying synchronous visuo-tactile stimulation to one of three different body parts\u2014the right hand, abdomen, or leg\u2014and then systematically assessed the strength of the subjective feeling of ownership of each of the three body parts. We tested the hypothesis that the subjective feeling of ownership generalizes from the stimulated body part to the entire body. \n\nWe first analyzed the average subjective ratings for statements S1 and S2 ( ) to confirm the successful induction of the perceptual illusion of referring somatic sensations to an artificial body regardless of the body part that received the visuo-tactile stimulation (hand, abdomen, or leg). Because these statements referred to the perceptual integration of the visual and tactile stimuli, this analysis served as an initial assessment of the overall efficacy of the experimental manipulation employed to elicit this illusion, which was performed prior to the evaluation of the generalization of the feeling of ownership to the non-stimulated body parts (subsequent paragraph). We performed repeated measures analysis of variance on the factors   Statement Type   (  Illusion  , average of S1 and S2;   Control  , average of S6, S7, and S8) and   Stimulation Mode   (  Synch  ;   Asynch  ) after pooling the data for the three different body parts. We detected a significant interaction between these two factors (F(1,21)\u00a0=\u00a05.89; p\u00a0=\u00a00.024;  B). Furthermore, a post-hoc   t  -test revealed a significant difference in the average subjective ratings for the illusion statements (S1 and S2) between the   Synch   and   Asynch   conditions (t(21)\u00a0=\u00a03.15, p\u00a0=\u00a00.002;  B). Identical results were found for each of the three body parts when analyzed separately (Hand: Z\u00a0=\u00a0\u2212\u00a02.696, p\u00a0=\u00a00.003; Abdomen: Z\u00a0=\u00a01.876, p\u00a0=\u00a00.030; and Leg: Z\u00a0=\u00a0\u2212\u00a02.489, p\u00a0=\u00a00.006; all Wilcoxon signed-ranks tests;  C). Moreover, there was no significant difference in the average illusion scores between S1 and S2, which were computed as the difference between the ratings for the   Synch   and   Asynch   conditions between all pairs of stimulated body parts (all p\u00a0>\u00a00.3). Thus, these findings confirmed that the participants experienced a referral of somatic sensations to the artificial body regardless of the body segment that received the visuo-tactile stimulation. The subjective strength of this illusory perceptual experience did not differ based on the body part that received visuo-tactile stimulation. Finally, we detected positive linear correlations between the subjective ratings (average of S1 and S2;   Synch   minus   Asynch  ) associated with the visuo-tactile stimulation of one body part and the corresponding ratings associated with the visuo-tactile stimulation of the other two body parts (Hand and Abdomen, Kendall's tau\u00a0=\u00a00.634, p\u00a0<\u00a00.001; Hand and Leg, tau\u00a0=\u00a00.253. p\u00a0=\u00a00.055; and Abdomen and Leg, tau\u00a0=\u00a00.495, p\u00a0=\u00a00.001;  D). \n\nSecond, we examined whether the perceptual integration of visuo-tactile signals from one body part would generate a subjective feeling of ownership over the artificial body that generalized to the entire body, i.e., including the body segments that were not stimulated. Thus, we analyzed the subjective ratings for statements S3, S4, and S5, which referred to the strength of the experienced feeling of ownership of the hand, abdomen, or leg, respectively ( ; see   for details), under the   Synch   and   Asynch   conditions. We first averaged the subjective ratings across the two body parts that did   not   receive the visuo-tactile stimulation under the condition of interest (for example, the strength of the feeling of ownership of the abdomen and the leg after stimulation of the hand). Then, we compared these scores between the   Synch   and   Asynch   conditions and detected a significant difference (t(21)\u00a0=\u00a04.822, p\u00a0<\u00a00.001). Significantly different ratings between the   Synch   and   Asynch   conditions, respectively, were detected for each body part, regardless of the body segment that received the visuo-tactile stimulation (all p\u00a0<\u00a00.05;  A). Furthermore, we found that the illusion scores (  Synch   minus   Asynch  ) for a given body part did not differ between the conditions in which the given body part received visuo-tactile stimulation and the conditions in which it did not (Hand: p\u00a0>\u00a00.5, Abdomen: p\u00a0>\u00a00.2, and Leg: p\u00a0>\u00a00.1). Finally, we detected significant positive correlations between the strength of the feeling of ownership (  Synch   minus   Asynch  ) of the stimulated body part and the strength of the feeling of ownership of the two non-stimulated body parts for all possible body part pairs (all p\u00a0<\u00a00.05;  B). Thus, the strength of the subjective feeling of ownership of the body part that received the visuo-tactile stimuli significantly predicted the magnitude of the generalization of ownership to the two remaining body parts that did   not   receive the visuo-tactile stimuli. In summary, the feeling of ownership systematically generalized from the stimulated body part to body segments that did not receive visuo-tactile stimulation in a manner that was compatible with the emergence of a feeling of ownership of the entire body. \n\n#### Multivoxel patterns in the ventral premotor cortex generalize across all pairs of body parts \n  \nWe performed an fMRI experiment that extended a previously validated experimental paradigm based on virtual reality tools to induce the feeling of ownership of an entire body viewed from the first-person perspective ( ;  A). We searched for patterns of neural activity in the ventral premotor cortex that reflected the integration of congruent visual and tactile signals from one's body that were invariant with respect to the stimulated anatomical location. These activity patterns would be suggestive of the neural mechanisms that result in the construction of a whole-body multisensory percept. Thus, we trained linear classifiers to detect illusion-specific BOLD response patterns that generalize across all three pairs of stimulated body segments ( C; see   for details). A second-level random effect analysis of the pairwise decoding maps revealed that voxels in a region of the left ventral premotor cortex exhibited illusion-specific activation patterns that were invariant with respect to the stimulated body part (Hand\u00a0\u21d4\u00a0Abdomen, t\u00a0=\u00a06.89, p \u00a0=\u00a00.002, peak MNI coordinates [X\u00a0=\u00a0\u2212\u00a064, Y\u00a0=\u00a0\u2212\u00a03, Z\u00a0=\u00a027]; Hand\u00a0\u21d4\u00a0Leg, t\u00a0=\u00a04.70, p \u00a0=\u00a00.047, peak [X\u00a0=\u00a0\u2212\u00a064, Y\u00a0=\u00a0\u2212\u00a09, Z\u00a0=\u00a035]; and Abdomen\u00a0\u21d4\u00a0Leg, t\u00a0=\u00a04.91, p \u00a0=\u00a00.036, peak [X\u00a0=\u00a0\u2212\u00a064, Y\u00a0=\u00a0\u2212\u00a03, Z\u00a0=\u00a027];  A;  ). When considering the entire brain as a search space, no other region yielded decoding accuracies at the group level across all three body parts that survived the correction for multiple comparisons. Thus, the patterns of neural activity in the ventral premotor cortex reflected the integration of visual and tactile signals that were associated with the feeling of ownership over the entire body, regardless of the body segment that received the multisensory stimulation. Importantly, none of these illusion-specific activity patterns extended to the   Detached Hand   condition (no significant decoding at p\u00a0<\u00a00.001, uncorrected for multiple comparisons in all pairwise maps;  A and B). This finding demonstrates that the generalization detected in the primary analysis described above was restricted to the context of an entire body, which is consistent with the notion that the visual impression of an entire body is a necessary factor for the generation of a whole-body percept. Furthermore, the failure to detect a significant difference between the   Synch   and   Asynch   activation patterns under the   Detached Hand   condition rules out a non-specific effect of the synchronous visuo-tactile stimulation mode. In summary, we generated evidence supporting the notion that neuronal populations in the ventral premotor cortex contain visuo-tactile receptive fields that encompass multiple body segments, which potentially mediate the construction of a multisensory whole-body percept. \n\n\n#### Multivoxel patterns in the ventral premotor cortex reflect a tripartite generalization across all three body segments \n  \nNext, we extended the pairwise decoding results described above. Specifically, we tested the hypothesis that the activity patterns in the ventral premotor cortex generalize across all three body parts in a tripartite manner. Evidence for multivoxel patterns would be consistent with our hypothesis regarding the engagement of neuronal populations containing visuo-tactile receptive fields that are sufficiently large to encompass all body segments investigated, as opposed to only two of the three body parts tested, which could be the case for separated pairwise analyses alone. Thus, we trained linear classifiers on the illusion-specific activity patterns from two body parts and tested them on the illusion-specific patterns from the remaining body part ( C). Importantly, this analysis revealed that the voxels in the left ventral premotor cortex described above were associated with significant decoding accuracies, which supports a genuine generalization across all 3 body parts (Hand, Abdomen\u00a0\u21d2\u00a0Leg, t\u00a0=\u00a08.54, p \u00a0<\u00a00.001, peak [X\u00a0=\u00a0\u2212\u00a060, Y\u00a0=\u00a0\u2212\u00a03, Z\u00a0=\u00a033]; Hand, Leg\u00a0\u21d2\u00a0Abdomen, t\u00a0=\u00a06.84, p \u00a0=\u00a00.002, peak [X\u00a0=\u00a0\u2212\u00a060, Y\u00a0=\u00a0\u2212\u00a05, Z\u00a0=\u00a023]; and Abdomen, Leg\u00a0\u21d2\u00a0Hand, t\u00a0=\u00a05.93, p \u00a0=\u00a00.006, peak [X\u00a0=\u00a0\u2212\u00a064, Y\u00a0=\u00a0\u2212\u00a09, Z\u00a0=\u00a035];  C;  ). Thus, we speculate that these activity patterns originate from neuronal populations containing visuo-tactile receptive fields that are sufficiently large to encompass all 3 body parts. \n\n\n#### Body part-specific convergence of congruent visual and tactile signals \n  \nWe investigated the existence of neuronal populations containing visuo-tactile receptive fields that are restricted to a single body segment. Thus, we performed a new set of multivoxel analyses to detect patterns of brain activity associated with the integration of congruent visual and tactile signals from a single body segment. We found that activity patterns in several key multisensory regions distinguished between the stimulated body parts significantly better under the   Synch   condition than under the   Asynch   condition ( ). These activity patterns were localized to cortical regions that lined the junction of the right intraparietal and postcentral sulci (p\u00a0=\u00a00.011 corrected), the left dorsal premotor cortex (p\u00a0=\u00a00.037 corrected), the left lateral occipital cortex (p\u00a0=\u00a00.024 corrected), and the left putamen (p\u00a0=\u00a00.041 corrected;  B;  ). This finding was confirmed when we further examined the decoding maps for each potential \u201cpairwise\u201d comparison of the investigated body parts in a purely descriptive manner ( C). At a lower threshold, we observed the same results in the left postcentral gyrus, the posterior medial parietal cortex, and the right cerebellar cortex (p\u00a0<\u00a00.001 uncorrected for multiple comparisons;  ). In summary, multivoxel patterns of neural activity in crucial multisensory nodes across cortical and subcortical areas displayed response properties that are compatible with the integration of congruent visual and tactile signals from a specific body part and its immediately surrounding space. Thus, these results suggest the existence of neuronal populations that construct disjointed multisensory representations of individual body parts. \n\n\n\n\n## Discussion \n  \nWe employed a full-body perceptual illusion in conjunction with multivoxel pattern analysis of neuroimaging data to characterize the processes that support the feeling of ownership of an entire body. There were two important findings of the present study. First, we provided psychometric evidence for the generalization of ownership from one of three anatomically distant body parts (hand, abdomen, or leg) to the entire body. Second, multivoxel pattern analysis revealed a potential neural substrate for this whole-body percept. Specifically, we characterized the activity patterns in the ventral premotor cortex that generalized across three anatomically distant body parts, specifically in the context of full-body ownership. These findings are consistent with the hypothesis that the perception of one's body as a unified entity\u2014a whole-body percept\u2014is supported by neuronal populations containing visuo-somatic receptive fields that encompass multiple body segments. \n\n### A potential neurophysiological mechanism that contributes to the emergence of the whole-body percept \n  \nWe identified BOLD activity patterns in the left ventral premotor cortex that were associated with the integration of multisensory signals from one's own body. These activity patterns generalized across three different body segments, depended on the temporal congruence of the visuo-tactile signals, and were specific to the context of the visual integrity of the body (i.e., the observation of a whole body as opposed to a single detached limb). In light of these findings, we propose that a region of the premotor cortex encodes the occurrence of a multisensory event on the body in a manner that is specific to one's own body but is invariant with respect to the anatomical location from which the sensory signals originate. This finding extends beyond the previous study by Petkova et al., in which the investigation was limited to the multivoxel patterns that generalized between the abdomen and the hand ( ). Here, we demonstrated that this pairwise generalization was present for all pairs of body parts investigated (abdomen from/to hand, hand from/to leg, and leg from/to abdomen). Furthermore, we also generated evidence for multivoxel patterns that reflect the tripartite generalization of these body parts. This finding suggests that the human premotor cortex processes information that corresponds to the perception of ownership of the entire body. \n\nWhat are the neurophysiological underpinnings of these BOLD activity patterns? Electrophysiological recordings in non-human primates have characterized premotor neurons containing multisensory receptive fields that are sufficiently large to encompass multiple body segments or the entire body surface ( ). In light of their receptive field properties, these neuronal populations are ideally suited to combine visuo-tactile-proprioceptive signals across multiple body segments, in contrast to multisensory neurons that contain receptive fields that are restricted to individual body parts ( ). The present results suggest the existence of neuronal populations in the human ventral premotor cortex that contain multisensory receptive fields that are reminiscent of those characterized in non-human primates. We speculate that these neuronal populations are pivotal to the construction of a whole-body percept via the integration of multisensory information across multiple body segments. The activation of neurons containing such receptive fields would enable the synthesis of congruent multisensory information from several body segments, thereby facilitating the formation of a coherent representation of the entire body. \n\nConsistent with previous results ( ), the present findings shed light on the role of the left ventral premotor cortex in the feeling of ownership of one's own body. When the results of the multivoxel pattern analyses of interest across the entire brain were examined, only a region of the left ventral premotor cortex reached statistical significance following correction for multiple comparisons. When the results from the key multivoxel pattern analyses across the entire brain were examined using a lower statistical threshold (p\u00a0<\u00a00.001 uncorrected for multiple comparisons for each analysis of interest), no other brain region, with the exception of the left ventral premotor cortex, exhibited consistent results across all multivoxel analyses ( ). The left-sided localization of these multivoxel patterns differed from the bilateral premotor activations that were described in previous univariate fMRI experiments, which investigated variants of the rubber hand illusion induced on the right hand ( ; but see, for example,   for contralateral activations only) and the full-body illusion induced by stimulating a single right-sided body part (see experiments 1 and 2 in  ). However, the apparent anatomical lateralization of the multivoxel patterns to the left premotor cortex in the present full-body illusion experiments must be interpreted with caution because of the experimental design. In particular, the visuo-tactile stimuli were delivered exclusively to right-sided body parts (right hand, right upper leg, and right side of the abdomen; i.e., contralateral to the anatomical location of the left ventral premotor region of interest). The methodological selection of right-sided-only stimulation sites could potentially account for the anatomical lateralization of the multivoxel patterns to the left ventral premotor cortex. Notably, before any conclusions can be drawn regarding a potentially genuine hemispheric lateralization, future experiments must compare multivoxel patterns between the left and right premotor cortices using a paradigm in which the full-body illusion is elicited by stimulating both left- and right-sided body parts. Finally, it is likely that the neural and perceptual integration of multisensory signals across both sides of the body would engage additional inter-hemispheric mechanisms ( ) than those observed when exclusively examining left- or right-sided body parts. Future studies should shed light on this issue by investigating the neural and perceptual mechanisms underlying the integration of multisensory signals across both sides of one's own body and the associated functional role of the bilateral ventral premotor cortices. \n\n\n### From body part-specific to whole-body multisensory representations \n  \nOur neuroimaging results indicate the co-existence of multisensory representations of restricted body segments alongside representations of substantially larger portions of the body (or the entire body). We suggest that this finding reflects the diversity of multisensory receptive fields, which range from body-part-specific, to specific to large segments of the body and the entire body. A recurring characteristic of the organization of sensory systems is the hierarchical arrangement of neuronal receptive fields, which range from small and simple to large and complex, that is typical of both the visual ( ) and somatosensory ( ) systems. An extensive collection of neurophysiological and neuroimaging research in monkeys and humans has characterized the convergence of multisensory signals in higher-order cortical and subcortical brain regions ( ). These regions are characterized by receptive fields that are typically larger and more complex than those in early sensory cortices ( ), facilitating the convergence of spatio-temporally aligned multisensory inputs ( ). \n\nIn human neuroimaging, most of the available evidence relates to the representation of individual body parts, such as the upper limb ( ) or the face ( ). The convergence of multisensory signals from these body parts has been associated with regions of the parietal and premotor cortices, as well as the putamen, which is consistent with the present findings of body part-specific activity patterns in these areas. Furthermore, a region of the lateral occipital cortex has been shown to contain a topographical representation of individual body segments that receives converging input regarding touch, vision, and proprioception ( ). Although the present study was not designed to obtain a multisensory topographical map of the different body segments ( ), our results support the convergence of spatio-temporally congruent visual and somatosensory signals onto disjointed multisensory representations of individual body parts. These representations are pivotal for manifold functions, such as the ability to interact with objects in the external environment ( ), defend the body from potential threats ( ), and mediate the self-attribution of individual body segments ( ). \n\nIn contrast to the representation of individual body parts, the evidence supporting multisensory representations of the entire body is scarce. To the best of our knowledge, the present study is the first to provide evidence for the convergence of visuo-tactile signals across multiple body segments in the human association cortex. As indicated above, the interpretation of this finding with respect to the existence of neuronal populations containing multisensory receptive fields that encompass a large portion of the body is compatible with neurophysiological data ( ). Furthermore, the illusion-specificity of the premotor activity patterns that generalize across the three investigated anatomically distant body parts provides new evidence for the contribution of this region to the construction of a multisensory percept of one's entire body. Future studies should investigate the interaction between the unified representation of multiple body segments in the premotor cortex, the encoding of one's body orientation in the gravitational field, which is thought to involve the temporo-parietal junction ( ), and allocentric representations of bodily self-location, which speculatively involve the medial temporal and posterior parietal cortices (  Decoding illusory out-of-body experiences. Society for Neuroscience: conference abstract). Finally, we note that the co-existence of body part-specific and whole-body representations is relevant to behaviors that rely on the coordination of multiple body segments. The maintenance of updated representations of both individual body segments and large portions of the body likely facilitates the coordination of complex, goal-directed and defensive actions ( ). \n\n\n### Behavioral evidence for the emergence of the multisensory whole-body percept \n  \nImportantly, the results from the neuroimaging experiment are consistent with those obtained from the behavioral experiment. Because the behavioral and neuroimaging data were obtained from two separate experiments in two different groups of participants, we could not perform direct correlation analyses to investigate the potential systematic relationships between the information content in the multivoxel patterns and the subjective reports of the perception of full-body ownership. Nevertheless, both experiments contribute valuable novel results that are consistent with our a priori hypothesis. In particular, the subjective reports suggest that the feeling of ownership is not restricted to the body part that receives the multisensory stimuli, but rather is systematically generalized to encompass the entire body. In an extension of previous studies that interpreted physiological responses, such as threat-evoked skin conductance responses ( ) or temperature variations ( ), as indirect proxies of whole-body percepts, here, we provide direct psychometric evidence for the generalization of ownership across the entire body. In particular, we demonstrated that the subjectively rated ownership of the stimulated body part predicts the strength of ownership of the two   non  -stimulated body parts. Importantly, this result is difficult to explain solely in terms of inter-individual differences in the perceptual traits associated with the ability to integrate visual and tactile signals, which could lead to similarly vivid feelings of ownership for the different body parts that receive visuo-tactile stimuli. Consistent with the neuroimaging data described above, the present behavioral findings provide insights into the multisensory processes that underlie the perception of an entire body viewed from the first-person perspective as one's own ( ), and, broadly speaking, emphasize the importance of cross-modal cues for bodily self-consciousness ( ). \n\n\n\n## Conclusions \n  \nConverging psychometric and neuroimaging results suggests that the integration of multisensory information across multiple body segments contributes to the emergence of the perception of ownership of an entire artificial body. Furthermore, this percept corresponds to specific activity patterns in the ventral premotor cortex. These findings support the existence of specific cortical mechanisms underlying the emergence of a unified percept of one's own entire body. \n\n \n", "metadata": {"pmcid": 4349631, "text_md5": "bf5a9d0bfd7cc3382cc4ff14e66c1412", "field_positions": {"authors": [0, 113], "journal": [114, 124], "publication_year": [126, 130], "title": [141, 247], "keywords": [261, 261], "abstract": [274, 2450], "body": [2459, 51645]}, "part": 1, "chapter": 12, "page": 8, "pmid": 25583608, "doi": "10.1016/j.neuroimage.2015.01.008"}, "display_title": "pmcid: <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4349631>4349631</a> \u2014 Part 1 Chapter 12 Page 8", "list_title": "1.12.8  Patterns of neural activity in the human ventral premotor cortex reflect a whole-body multisensory percept"}
