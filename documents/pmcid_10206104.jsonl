{"text": "Schirner, Michael and Deco, Gustavo and Ritter, Petra\nNat Commun, 2023\n\n# Title\n\nLearning how network structure shapes decision-making for bio-inspired computing\n\n# Keywords\n\nNetwork models\nIntelligence\nComputational models\nDynamical systems\nBiophysical models\n\n\n# Abstract\n \nTo better understand how network structure shapes intelligent behavior, we developed a learning algorithm that we used to build personalized brain network models for 650 Human Connectome Project participants. We found that participants with higher intelligence scores took more time to solve difficult problems, and that slower solvers had higher average functional connectivity. With simulations we identified a mechanistic link between functional connectivity, intelligence, processing speed and brain synchrony for trading accuracy with speed in dependence of excitation-inhibition balance. Reduced synchrony led decision-making circuits to quickly jump to conclusions, while higher synchrony allowed for better integration of evidence and more robust working memory. Strict tests were applied to ensure reproducibility and generality of the obtained results. Here, we identify links between brain structure and function that enable to learn connectome topology from noninvasive recordings and map it to inter-individual differences in behavior, suggesting broad utility for research and clinical applications. \n  \nBetter understanding of a trade-off between the speed and accuracy of decision-making is relevant for mapping biological intelligence to machines. The authors introduce a brain-inspired learning algorithm to uncover dependencies in individual fMRI networks with features of neural activity and predict inter-individual differences in decision-making. \n \n\n# Body\n \n## Introduction \n  \nDo intelligent people think faster? Strong correlations between reaction times and intellectual performance support this idea, providing a cornerstone for intelligence research for over one century . Here, we show an important exception in empirical data and provide an explanation based on brain simulation (Supplementary Movie\u00a0 ). Participants with higher intelligence were only faster when the test was simple. Conversely, in hard tests that required problem solving over several seconds or minutes without time limit, participants with higher intelligence used more, not less time to arrive at correct solutions. We reproduced this link between reaction time and performance in personalized multi-scale brain network models  (BNMs) that couple each participant\u2019s structural white-matter connectivity (SC) with a generic neural circuit for decision-making (DM) and working memory (WM). Simulation results indicate that decision-making speed is traded with accuracy, resembling influential theories from the fields of economy and psychology on fast and slow thinking . \n\nIntelligence is here defined as the performance in psychometric tests in cognitive domains like verbal comprehension, perceptual reasoning or working memory. A consistent finding is that individuals who perform well in one domain tend to perform well in the others, which led to the derivation of a general factor of intelligence called   g  -factor . While the   g  -factor also targets learned skills like verbal fluency, the term fluid intelligence (FI) refers to abilities related to solving new problems independently of acquired knowledge . Reaction time (RT) as a measure of cognitive processing speed provides strong evidence in support of the idea that people are more intelligent because they have faster brains . A meta-analysis over 172 studies and 53,542 participants reported strong negative correlations between general intelligence and diverse measures of RT . RT and intelligence are also linked over the lifespan: RT increases with age and is strongly correlated with decline in other domains . Intriguingly, RT is a more powerful predictor of death than well-known risk factors like hypertension, obesity, or resting heart rate: RT is the second most important predictor of death after smoking  and explains two-thirds of the relationship between general intelligence and death . After adjusting for smoking, education, and social class, RT was an even stronger predictor of death than intelligence. However, these results do not imply that PS is the causal factor underlying intelligence: an important counterargument is that training and improving PS does not transfer to untrained measures . \n\nWe found that participants with higher intelligence were only quicker when responding to simple questions, while they took more time to solve hard questions. This became apparent in the Penn Matrix Reasoning Test (PMAT), which consists of a series of increasingly difficult pattern matching tasks for quantifying FI . While PS tests are typically so simple that people would not make any errors if given enough time, FI tests like PMAT can be unsolvable even without time limit. PMAT requires to infer hidden rules that govern the figure, which involves a recursive decomposition of complex problems into easier subproblems, forming a hierarchy of DM processes . To solve the problem, it is required to make decisions about tentative solution paths while storing previous progress in WM. Sub-problems higher up in the hierarchy need to be held longer in WM as evidence from lower in the hierarchy needs to be integrated later in time . Therefore, taking decisions on higher-level problems must be held out until evidence from sub-problems was integrated to not prematurely jump to a conclusion. This form of cognition can be contrasted with the flexibility required by PS tests where it is actually advantageous if decisions do not rely on extensive accumulation of evidence and memories can be flexibly overwritten. \n\nHere, by closely fitting brain models to each subject\u2019s functional connectivity (FC), we identify a fast mode of cognition for rapid decision-making and flexible working memory and contrast it with a slow mode of cognition that supports prolonged integration of information and more stable working memory. Importantly, by identifying a smooth and monotonous relationship between structural and functional neural network architecture it was possible to devise a network fitting algorithm that allows to simultaneously and precisely control the state of synchronization between every pair of network nodes, allowing to tune each connection from full antisynchronization to full synchronization, enabling a close reproduction of whole-brain subject-specific FC. In the following, we first provide behavioral findings that link intelligence test results with processing speed and FC (Fig.\u00a0  and Table\u00a0 ). Then we demonstrate a computational framework for closely fitting BNMs to personal FC (Figs.\u00a0  and  ), and subsequently explain the empirical data based on the in silico identified biological candidate mechanisms (Figs.\u00a0 \u2013  and Supplementary Figures). For the fitting we created a parameter learning algorithm that makes use of our observation that FC and synchronization between two simulated brain areas can be smoothly and monotonically tuned via their long-range excitation-inhibition balance (E/I-ratio). We then show that the internal dynamics of the fitted models correlated with the empirical cognitive performance of the subjects (Fig.\u00a0 ). In addition, E/I-balance modulated the amplitude and synchrony of large-scale synaptic currents in a way that modulated DM winner-take-all races and WM persistent activity in accordance with the empirical observations (Figs.\u00a0  and   and Supplementary Fig.\u00a0 ). Phase space analysis of the resulting model dynamics allowed to frame the trade-off between speed and accuracy in terms of generic dynamical systems behavior in dependence of the E/I-balance of long-range brain network topology, which may jointly explain individual variability in FC, intelligence, and processing speed (Supplementary Figs.\u00a0  and   and Supplementary Movie\u00a0 ).    Correlations between intelligence, RTs and FC.  \n a  ,   b   Group-average   g  -factor (30 groups, based on g-factor,   N  \u2009=\u2009650 subjects) versus RT for correct responses in PMAT questions #1 (very easy,  ) and #24 (very hard,  ).   c  ,   d   Group-average and subject-level correlations between   g  /PMAT24_A_CR and the RT for correct responses in each individual PMAT question. Subjects with higher   g  /PMAT24_A_CR were quicker to correctly answer easy questions, but they took more time to correctly answer hard questions (questions sorted according to increasing difficulty; sign of correlation flips at question #9).   e   Group-average   g  -factor versus mean FC (20 groups, based on   g  -  f  actor,   N  \u2009=\u2009650 subjects,  ).   f   Group-average PMAT24_A_RTCR versus mean FC (20 groups, based on PMAT24_A_RTCR,   N  \u2009=\u2009650 subjects,  ).   g  ,   h   Group-average (20 groups, based on PMAT24_A_RTCR) and subject-level correlations between mean FC and RT for correct responses in each PMAT question. Subjects that took more time to correctly answer test questions had a higher FC, independent of whether the question was easy or hard.   P   values of two-sided Pearson\u2019s correlation test: *  p  \u2009<\u20090.05, **  p  \u2009<\u20090.01, ***  p  \u2009<\u20090.001; including only   p   values that remained significant after controlling for multiple comparisons using the Benjamini\u2013Hochberg procedure with a False Discovery Rate of 0.1. \n    \nCorrelation coefficients between intelligence, RT, and PS on an individual-subject level (  N  \u2009=\u20091176) \n  \nAbbreviations of cognitive tests are introduced in Table\u00a0 . Note that PMAT24_A_RTCR measures RTs (larger values indicate longer times), while CardSort_Unadj and ProcSpeed_Unadj are PS tests that measure the inverse of time (larger values indicate shorter times), hence signs of the correlation coefficients are reversed.   P   values of two-sided Pearson\u2019s correlation test: *  p  \u2009<\u20090.001. \n     Modeling outline.  \n a   379-nodes large-scale BNMs were constructed from person-specific white matter connectomes estimated with dwMRI tractography. In addition, a simplified network with only two nodes (but identical node dynamics) was used to create E/I-ratio tuning curves (Fig.\u00a0 ).   b   In previous BNM studies long-range white matter coupling from excitatory to inhibitory populations was often absent. Adding these connections allowed to tune the relative strength of long-range excitatory-to-excitatory versus long-range excitatory-to-inhibitory connections, enabling to precisely tune the E/I-ratio of synaptic inputs between each pair of BNM nodes. Importantly, setting the E/I-ratio allowed to monotonically and smoothly control the FC between all nodes (Fig.\u00a0 ). Underlying predicted fMRI time series, the E/I-ratio allowed to smoothly tune synchronization and amplitude of synaptic currents (Fig.\u00a0 ).   c   By systematically tuning E/I-ratios, the fit between simulated and empirical FC can be increased until full similarity (Fig.\u00a0 ).   d   Upon fitting each participant\u2019s BNM with their empirical FC, each BNM was coupled with a smaller scale frontoparietal circuit for simulating DM and WM. Subpopulations in prefrontal cortex (PFC) and posterior parietal cortex (PPC) are mutually and recurrently coupled to encode two decision options A and B. For example, evidence for option A recurrently excited the populations A  and A  (red connections) while it led to an inhibition of the populations B  and B  (blue connections). Importantly, instead of independent noise, we used the activity of the PFC and PPC regions of the 379-nodes large-scale network to drive the DM circuit, which allowed to analyze how local decision-making and working memory performance can be modulated by large-scale brain network topology. Panel   a   is adapted from ref.  . and used under a CC BY 4.0 license ( ). \n     Identification of a smooth, monotonic relationship between E/I-ratio and FC to fit brain network models.  \n a   Tuning curves for a reduced model with only two nodes, but otherwise identical to the 379-nodes BNM. FC (that is, correlation) between the two nodes increased smoothly and monotonically as a function of their E/I-ratio  . The relationship between E/I-ratio and FC persisted when the strength of noise   (upper panel; Eqs.\u00a0  and  ) and the strength of structural coupling   (lower panel; Eqs.\u00a0  and  ) were modulated for test purposes (both are fixed parameters during the fitting of the full 379-nodes model).   b   Fitting results for the full 379-nodes model for one exemplary FC. Empirical (upper triangular portion of the matrix) versus simulated (lower triangular portion of the matrix) FC and joint distributions without E/I-tuning (upper panel) and with E/I-tuning (lower panel).   c   Pearson correlations and root-mean-square errors between all   N  \u2009=\u2009650 empirical and simulated FCs for three different model variants: EI-tuning (the tuning algorithm applied on both   and  ), E-tuning (the tuning algorithm applied only on  ), original (tuning of a scalar global coupling scaling factor to rescale  ). \n     Model dynamics correlate with empirical cognitive performance. FC, synchrony, amplitude and variance of neural population activity depend on E/I-ratios.  \n a   PMAT24_A_RTCR versus strength of correlation of input currents in the full 379-nodes large-scale BNMs. The models of slower subjects had a higher synchrony between the time series of synaptic currents   ( ).   b   PMAT24_A_RTCR versus input amplitude. The models of slower subjects had a lower average synaptic current amplitude  ).   c   E/I-ratio versus parameter settings in the simplified two-node large-scale model. The E/I-ratio of a connection is defined by the quotient of long-range excitation  (black) and feedforward inhibition  (black).   J   values (green) were obtained by FIC.   d   E/I-ratio versus FC for active (black) and inactive FIC (blue). A monotonic relationship between E/I-ratio and FC only emerged when FIC was active.   e   E/I-ratio versus correlation of input currents.   f   E/I-ratio versus input amplitude. With FIC input amplitudes peaked at relatively low E/I-ratios and then continued to monotonically decrease for increasing E/I-ratios   g   E/I-ratio versus input variance showed an inverse pattern compared to   f  .   h   Amplitude versus variance of inputs. FIC coupled the variance of synaptic inputs with the amplitude of synaptic inputs: the higher the variance (resulting from stronger coupling), the lower the amplitude.   i  ,   j   Firing rate (Eq.\u00a0 ) and input current (Eq.\u00a0 ) time series after injecting 10-Hz sinusoidal waves with increasing variance for active (black) and inactive FIC (blue). FIC compensated higher input variances (which were modulated by the fitting algorithm via the multiplicative coupling parameters   w   and   w  ) with a lower mean (  h  ). This was necessary as the upper half-wave of the input continued to grow in amplitude for increasing E/I-ratios, while the lower half-wave was bounded by 0\u2009Hz f ring (gray to black lines), which required FIC to increase   J   to arrive at the same target average firing rate of 4\u2009Hz. Data in panels c-h are presented as mean values +/- SD derived from   N  \u2009=\u2009100 simulations with different random number generator seeds. Obtained   p   values of two-sided Pearson\u2019s correlation test: *  p  \u2009<\u20090.001; including only   p   values that remained significant after controlling for multiple comparisons using the Benjamini-Hochberg procedure with a False Discovery Rate of 0.1. \n     DM performance depends on amplitude and synchrony of input currents to the isolated frontoparietal DM circuit. Decreased amplitude of PFC and PPC noise and increased synchrony of PPC noise led to more correct decisions and longer integration time in the DM circuit.  \n a   Percent correct decisions for varying the mean amplitudes of the input noise time series to the PFC and PPC modules of the DM circuit   and  .   b   Evidence integration times for varying mean amplitudes of the input noise time series   and  .   c   Percent correct decisions for varying correlation coefficients between input noise time series   and  .   d   Evidence integration times for varying correlation coefficients between input time series   and  . \n     Multiscale modeling: coupling PFC and PPC nodes of the person-specific BNMs with the corresponding modules of the generic DM circuit. The models of subjects with higher PMAT24_A_CR (fluid intelligence) made fewer mistakes, but were slower, echoing the empirically observed trade-off.  \n a   Distribution of significant correlations between mean input of all BNM nodes and PMAT24_A_CR (  p  \u2009<\u20090.05 for 35 of 379 nodes), respectively PMAT24_A_RTCR (  p  \u2009<\u20090.05 for 26 of 379 nodes) over all   N  \u2009=\u2009650 models.   b  ,   c   Group-average PMAT24_A_CR versus DM performance (  r  \u2009=\u20090.77,  ), respectively DM time (  r  \u2009=\u20090.69,  ), for an exemplary combination of PFC and PPC nodes. Data are presented as mean values +/\u2212 SD over all   N  \u2009=\u2009650 models each simulated 100 times with different random number generator see  d  s.   d   Distribution of significant correlations between group-average PMAT24_A_CR and DM time (  p  \u2009<\u20090.05 for 57 of 90 possible combinations), respectively, DM performance (  p  \u2009<\u20090.05 for 19 of 90 possible combinations) over all   N  \u2009=\u2009650 models. Including only correlations that remained significant after controlling for multiple comparisons using the Benjamini-Hochberg procedure with a False Discovery Rate of 0.1. \n  \n\n\n## Results \n  \n### Higher intelligence: taking complex decisions slowly \n  \nWe analyzed correlations between   g  -factor, FI (PMAT24_A_CR), RT for correct responses in the FI test (PMAT24_A_RTCR), and processing speed for 1176 participants of the Human Connectome Project (HCP) Young Adult study (Table\u00a0 ) . FI was measured by the number of correct responses in PMAT (PMAT24_A_CR) . Processing speed was measured by the NIH Toolbox tests Dimensional Change Card Sort  and Pattern Completion Processing Speed  (CardSort_Unadj and ProcSpeed_Unadj). For findability we use the same abbreviations for the cognitive tests as used in the HCP (Table\u00a0 ).   \nAbbreviations of the used cognitive tests \n  \n\nReproducing established results , individuals with higher   g   and FI (PMAT24_A_CR) were faster in the simple processing speed tests. However, they needed more, not less time (PMAT24_A_RTCR) to form correct decisions in the harder FI test (PMAT24_A_CR, Table\u00a0 ). This observation is remarkable as it challenges the notion that higher intelligence is the result of a faster brain. \n\nThe observation may however have a trivial explanation: PMAT questions are arranged in order of increasing difficulty and the test is discontinued if the participant makes five incorrect responses in a row. People with higher intelligence could have a higher RT simply because they advanced until the more difficult questions. To exclude this explanation, we correlated intelligence with the RTs for each individual PMAT question, which shows the impact of problem difficulty on RT: for the first eight questions participants with higher   g   and PMAT24_A_CR were faster to give correct answers, but slower for the remaining sixteen questions (Fig.\u00a0 ). \n\n\n### Slow solvers have higher resting-state functional connectivity \n  \nNext, we compared cognitive performance with mean FC (average correlation between all region-wise fMRI time series) in a subset of   N  \u2009=\u2009650 participants with complete data and where no quality control issues were identified by the HCP consortium (see Methods). We have selected mean FC for the subsequent analyses as it is a compact representation of whole-brain FC and related to E/I-balance per our analysis (Figs.\u00a0  and  ). Mean FC had no significant correlation with g on single-subject level (  r  \u2009=\u20090.02,   p  \u2009=\u20090.69) and group level (Fig.\u00a0  and Supplementary Fig.\u00a0 ). On the single-subject level there was a significant correlation between mean FC and PMAT24_A_RTCR (  r  \u2009=\u20090.13,   p  \u2009=\u20090.0012). Multiple regression to compute the coefficient of multiple correlation between all reported behavioral variables (  g  , PMAT24_A_CR, PMAT24_A_RTCR, ProcSpeed, CardSort) and mean FC yielded   r  \u2009=\u20090.16 (  p  \u2009<\u20090.001), which was only slightly higher than the univariate correlation between mean FC and PMAT24_A_RTCR. \n\nImportantly, independent of the complexity of the question there were strong positive correlations between mean FC and the times to correctly answer each individual PMAT question (Fig.\u00a0 ): slower participants tended to have higher mean FC, regardless of whether the question was easy or hard, indicating that FC (or properties of the brain network underlying FC) could be related to the modulation of processing speed, which we studied with computational models below. \n\n\n### Excitation-inhibition balance controls functional connectivity \n  \nWhich neurophysiological processes underly the observed correlations between intelligence, RT, and FC? To study neuronal processing in silico we created BNMs for the 650 subjects using a tuning algorithm that fits each participant\u2019s simulated FC with their empirical FC (Figs.\u00a0  and  ). The BNMs use coupled neural mass models to simulate the electric, synaptic, firing, and hemodynamic (fMRI) activity of a 379-nodes whole-brain network. Each node consists of one excitatory and one inhibitory population that mutually and recurrently interact. To simulate long-range white matter coupling, the neural masses were connected by each participant\u2019s SC, which were estimated by dwMRI tractography. Importantly, we added feedforward inhibition to increase biological realism : while in previous BNM studies there was typically only long-range coupling between excitatory populations, here, excitatory masses additionally targeted inhibitory populations (Fig.\u00a0  and \u201cMethods\u201d). In addition, the strength of local inhibitory feedback from the inhibitory to the excitatory population of each node was controlled by inhibitory synaptic plasticity , which was set to tune each excitatory population\u2019s long-term average firing rate to 4\u2009Hz in a process called Feedback Inhibition Control (FIC) . By tuning the ratio of long-range excitation (LRE; strength of long-range excitatory-to-excitatory coupling  , Eq.\u00a0 ) to feedforward inhibition (FFI; strength of long-range excitatory-to-inhibitory coupling  , Eq.\u00a0 ) between each pair of brain regions it was possible to precisely control the synchrony, respectively functional connectivity, of the entire brain network (Fig.\u00a0  and Supplementary Movie\u00a0 ). Although many parameters are simultaneously tuned, which may raise concerns about overfitting, we show below that the fitting procedure robustly predicts the same model dynamics over different re-initializations and that the fitted models produce generalizable mechanistic insights and meaningfully comparable predictions over the subject cohort. While in previous models the values of   and   were implicitly set to the same scalar constant for every pair of brain regions, with this approach E/I ratios can be justified in a principled and data-driven way, in agreement with the direct relationship that we identified between E/I ratios and FC: increasing E/I-ratios led to increasingly positive FC up to full synchronization; vice versa, decreasing E/I-ratios decreased the correlation between the simulated fMRI time series until full anti-synchronization (Fig.\u00a0 ). By simultaneously tuning the E/I-ratios of every connection to minimize the error between empirical and simulated FC, it was possible to considerably improve FC fits to a point where the simulated FCs of all 650 individual BNMs became almost indistinguishable from their empirical counterparts, explicitly reproducing even intricate and subtle patterns (Fig.\u00a0 ). In comparison to the original model (Fig.\u00a0 , green curves), where E/I-ratios were left untuned at their default settings (  and  ) from Deco et al. , and compared to a variant where only   values were tuned (Fig.\u00a0 , red curves), tuning both   and   at the same time allows to smoothly set the state of synchronization between each pair of brain regions (Figs.\u00a0  and\u00a0 ), which can be used to considerably reduce the root-mean-square error between simulated and empirical FC (Fig.\u00a0 , blue curves). It is important to point out that E/I-ratio here refers only to the ratio of the long-range coupling strength parameters   without considering the effect of local inhibitory connectivity  . Due to FIC the E/I-ratio of the total sums of long-range and local currents that arrive at excitatory populations ( , Eq.\u00a0 ) is always in a balanced state, which ensures an average firing rate of 4\u2009Hz of the excitatory population even in the case that long-range connections are unbalanced. \n\nSummarizing, the long-range E/I-ratios between network nodes control the direction (positive versus negative) and strength of their synchronization and FC; tuning these E/I-ratios enables simulation of person-specific empirical FCs with average correlations  . \n\n\n### Simulated brain activity correlates with cognitive performance \n  \nTo identify processes relevant for intelligence, we correlated the dynamics of each subject\u2019s BNM with their PMAT24_A_RTCR. On the single-subject level we found only a low negative correlation between PMAT24_A_RTCR and the mean amplitude of synaptic currents (  r  \u2009=\u2009\u22120.11,   p  \u2009=\u20090.0068) and a low positive correlation with the mean correlation between synaptic currents (  r  \u2009=\u20090.13,   p  \u2009<\u20090.001). For the two processing speed measures CardSort_Unadj and ProcSpeed_Unadj no significant correlations were obtained on the single-subject level. \n\nOn the group-average level correlations with PMAT24_A_RTCR were however large showing that the models of slower subjects had on average a lower amplitude of synaptic currents, but a higher synchrony between synaptic currents (Fig.\u00a0  and Supplementary Fig.\u00a0 ). Importantly, synaptic currents had an almost linear relationship with FC on an individual-subject level (Supplementary Fig.\u00a0 ), indicating that E/I-ratios also control amplitude and synchrony of synaptic currents, which possibly points towards brain network mechanisms for explaining the observed differences in cognition. To better isolate the involved mechanisms, we again studied a reduced version of the 379-nodes BNM with only two-nodes. \n\n\n### How E/I-ratios control FC \n  \nTo study how E/I-ratios modulate FC in isolation we tuned E/I-ratios from 0.01 to 100 in the two-node model. The two-node model is a simplified version of the 379-node large-scale brain model to study the effect of large-scale E/I-balance with a simpler network structure (Fig.\u00a0 ). The two-node model (Eqs.\u00a0 \u2013 ) differed from the functional frontoparietal decision-making circuit  (DM circuit, Eqs.  \u2013 ) further introduced below. The two-node model simulated mutual and recurrent interaction between one excitatory and one inhibitory population as in the 379-nodes large-scale model, but with a simpler network of only two nodes to produce tuning curves (Fig.\u00a0 ). In contrast, the DM circuit is an existing frontoparietal circuit model to simulate winner-take-all competition resulting from cross-inhibition of two excitatory populations via one inhibitory population, which we studied in isolation (Fig.\u00a0 ), and after coupling with the 379-nodes large-scale model to form the multiscale model (Fig.\u00a0 ). Dynamics of the two-node model were identical to the full 379-regions model but with only two nodes   that had a mutual coupling strength of  . To increase E/I-ratios we increased   and decreased   under the constraint   to keep the total sum of inputs constant (Fig.\u00a0 ). As before, FIC was used to tune average firing-rates of the excitatory populations to a biologically plausible rate of 4 Hz . As before (Fig.\u00a0 ), increasing the E/I-ratio increased FC from a strong negative to a strong positive correlation (Fig.\u00a0 ). Underlying the simulated fMRI, also the correlation between simulated synaptic inputs increased monotonically from negative to positive (Fig.\u00a0 ). This monotonic relationship enabled fitting the models to empirical FC using a simple learning rule that increased or decreased E/I-ratios based on the strength of FC of each connection (Methods). Interestingly, the monotonic relationship only emerged when FIC was active (Fig.\u00a0 , black curves). When FIC was disabled (Fig.\u00a0 , blue curves), a complex nonlinear relationship between E/I-ratios and FC appeared, which would prevent the fitting with empirical FC. That is, without FIC, increasing the E/I-ratio could either increase or decrease the FC, and vice versa, while with FIC FC can be smoothly increased by increasing the E/I-ratio and vice versa. These observations underline the importance of FIC: only when FIC was active synaptic correlations increased and synaptic amplitude decreased for increased E/I-ratios, respectively FC (Fig.\u00a0 ). Therefore, only with FIC a concordant effect of amplitude and correlation on decision times and decision accuracy was obtained that is in line with empirical data. Supplementary section How E/I-ratios control synchrony and amplitude of synaptic currents describes the involved mechanisms in more detail. \n\n\n### E/I-ratios switch between fast and accurate DM \n  \nTo better understand how E/I-ratios modulate DM and WM we used an existing  frontoparietal circuit model for winner-take-all DM and persistent activity WM called DM circuit in the following (see Supplementary section Studying DM and WM with a frontoparietal circuit model). In the DM circuit NMDAergic and GABAergic synaptic dynamics of prefrontal cortex (PFC) and posterior parietal cortex (PPC) decision populations are explicitly modeled, while uncorrelated and independent noise from an Ornstein-Uhlenbeck process is used to simulate AMPA synapses . However, a more realistic assumption is that synaptic inputs are not uncorrelated, but that populations receive correlated inputs from shared presynaptic groups . Furthermore, inputs might not necessarily be fully balanced and centered at zero. Rather, our BNM simulations suggest that input amplitudes and correlations vary heterogeneously across brain areas and subjects and are strongly related to FC (Supplementary Fig.\u00a0 ). Consequently, we systematically varied amplitude and correlation of AMPA noise inputs and found that they switch the DM circuit between fast-but-faulty and precise-but-slow modes of DM (Fig.\u00a0 ). Decreasing the mean amplitude of inputs increased decision accuracy as well as integration time (Fig.\u00a0 ). Similarly, increasing the correlation of input noise to the two PPC populations also led to increased performance and integration time (Fig.\u00a0 ). Integration times followed an inverted U-shape and were at their maxima for intermediate levels of noise correlation ( , Fig.\u00a0 ). In contrast, input correlation to the two PFC populations had no relevant effects (Fig.\u00a0 ). These results indicate that DM performance depends on synaptic inputs in line with our empirical data: participants with higher FC (corresponding to lower amplitudes, but higher input correlations in the model) were slower (Fig.\u00a0 \u2009g, h) but made fewer errors (Fig.\u00a0 ). They also corroborate the identified link between empirical PMAT24_A_RTCR and synaptic inputs in the BNM simulations, where higher input synchrony and lower input amplitudes correlated with longer PMAT24_A_RTCR (Fig.\u00a0  and Supplementary Fig.\u00a0 ). The underlying dynamic mechanisms are described in supplementary sections How input amplitude modulates DM performance and How input correlation modulates DM performance (see also Supplementary Figs.\u00a0  and   and Supplementary Movie\u00a0 ). \n\n\n### E/I-ratios switch between stable and flexible WM \n  \nWe also tested the effect of input amplitude on WM in the DM circuit and created bifurcation diagrams that visualize dynamical regimes of the system as a function of net recurrent synaptic currents   (recurrent excitation minus cross-inhibition) and stimulus strength   (Supplementary Fig.\u00a0 ). Memories were induced by a brief stimulus to one of the PPC populations, which created persistent activity in the memory-encoding population. At   t  \u2009=\u20091.5\u2009s after the target stimulus a distracting stimulus was applied to the other population, to test the robustness of the memory-encoding persistent activity. The WM state was robust if the memory-encoding population maintained its persistent high firing activity and it was fragile if the persistent firing was disrupted. Varying   and   parameters gave rise to three dynamical regimes in the bifurcation diagram: robust WM, disrupted WM, or no induction of WM at all (Supplementary Fig.\u00a0 ). We found that the thresholds for WM induction and robustness shifted in dependence of input amplitude. Decreasing the input amplitude increased the thresholds for WM induction and disruption, which in turn requires larger stimuli to induce or overwrite WM content (Supplementary Fig.\u00a0 ). A decreased input amplitude therefore makes WM less flexible, which is again in line with our empirical observations: slower subjects had a higher FC (Fig.\u00a0  and Supplementary Fig.\u00a0 ), which was related to decreased input amplitude via BNM simulations (Fig.\u00a0  and Supplementary Figs.\u00a0  and  ) and two-node model simulations (Fig.\u00a0 ). Vice versa, higher input was related to lower thresholds for the induction and overwriting of working memories, which made WM more flexible to support simple but time-sensitive tasks. \n\n\n### Coupling the DM circuit with the large-scale BNMs \n  \nTo predict DM performance of each individual, we coupled the DM circuit with each of the 650 BNMs with the effect that the PFC and PPC modules of the DM circuit were driven by large-scale PFC and PPC inputs instead of the independent noise that was used in the isolated circuit (replacing Eq.\u00a0  from the original DM circuit model  by Eq.\u00a0 ). Correlations between PMAT24_A_RTCR, respectively PMAT24_A_CR, and the input amplitudes of the 379 BNM regions indicate that the amplitudes encode information about individual cognitive performance (Fig.\u00a0 ). For coupling we identified 10 PFC and 9 PPC atlas regions  that were activated during n-back task performance, which combines aspects of WM and DM (PFC: a9-46v, 9-46d, p9-46v, 8\u2009C, i6-8, s6-8, 8Av, SFL, and 8BM. PPC: AIP, LIPd, IP1, IP2, 7PL, 7Pm, 7Am, POS2, PFm, and PGs). Simulation results predicted empirical performance for several of the 90 possible PPC-PFC combinations (Fig.\u00a0 ). Multiscale models of participants with higher FI (PMAT24_A_CR) also had a higher DM accuracy and needed more time to take the decisions, reproducing the empirical data. \n\n\n### Model validation \n  \nTo test the robustness of the fitting procedure we ran it 1000 times with random initial conditions and noise generator seeds using the average SC and FC from all subjects. The minimum correlation between all 1000 simulated FCs was   r  \u2009=\u20090.9946 and their average correlation with the empirical FC was   r  \u2009=\u20090.9973, which shows that the procedure consistently led to a high fit. Next, we simulated one hour of fMRI with the 1000 fitted models, this time using the same noise. The average correlation between all resulting fMRI time series over all 379 brain regions was   r  \u2009=\u20090.9962, showing that the fitting led to consistent fMRI predictions although there existed a variance in the obtained model parameters (average coefficients of variation   CV  \u2009=\u2009  0.5   and   CV  \u2009=\u2009  0.72  ). Although the repeated fitting runs did not converge to a unique parameter set the simulated time series were nevertheless robustly reproduced as a general result of the fitting procedure. \n\nTo test whether DM performance predictions can be robustly reproduced we divided all subjects into six groups according to PMAT24_A_RTCR and fitted each 100 times, randomizing seeds and initial conditions as above. In all 100 tests mean amplitudes decreased and correlations increased from low to high PMAT24_A_RTCR (Supplementary Fig.\u00a0 ; Friedman test rejected the null hypothesis that distributions are equal with   p  \u2009=\u20090; post-hoc multiple comparison analysis using Nemenyi\u2019s test showed that the six groups were significantly different with   p  \u2009<\u20090.001 for all pairs), confirming that the identified link to empirical performance is a general result of the fitting procedure. \n\nTo test whether there is a robust relationship and comparability between inferred synaptic inputs across the subject population we trained regression models on one half of the cohort and then applied the model on the second half to estimate its generalizability and repeated this process 1000 times to obtain a statistic over different random train and test groups. Predicting subject-wise mean FC from mean synaptic inputs yielded correlations of   r  \u2009=\u20090.67\u2009\u00b1\u20090.025 for the training sets and   r  \u2009=\u20090.66\u2009\u00b1\u20090.025 for the test sets. Next, using the mean inputs from the ten areas with highest correlation with mean FC as independent variables yielded a fit of   r  \u2009=\u20090.79\u2009\u00b1\u20090.018 with the training sets and   r  \u2009=\u20090.73\u2009+\u2009/\u22120.055 with the test sets. Lastly, we computed regression models for every single FC connection (  N  \u2009=\u200971,631) using the mean input currents from the ten areas with highest correlation with the respective FC connection as independent variables. Over all connections, this yielded an average fit of   r  \u2009=\u20090.61\u2009+\u2009/\u22120.1 for the training and   r  \u2009=\u20090.52\u2009+\u2009/\u22120.13 for the test set. The stability of prediction qualities in test versus train sets in above tests indicates that the inferred properties are meaningfully comparable across the subject population. \n\n\n\n## Discussion \n  \nWe propose that FC and synchrony between brain areas directly depend on the ratio of their mutual excitation and inhibition. This theoretical observation yielded a parameter optimization algorithm that enabled to fit whole-brain simulated FCs to their empirical counterparts based on a Hebbian learning rule that implements homeostatic plasticity of excitation-inhibition balance in brain network models . The dynamics of the resulting   N  \u2009=\u2009650 models were then linked with the subjects\u2019 empirical intelligence test scores and used to explain individual differences in cognitive performance. The research yields an implementation of multiscale brain network models that are able to perform decision-making tasks, both of which have recently been identified as crucial steps to explain the relationship between microscopic phenomena, large-scale brain function, and behavior as well as generating brain digital twins for personalized medical interventions . The obtained insights held true independent of any parameter fitting in subsequent tests with isolated circuits. In addition, strict tests were employed to ensure the generality of the fitting procedure. Although we here focus on individual variability in DM and intelligence of healthy individuals, the insight that E/I-balance can be used to precisely set FC in brain models indicates a general-purpose method for inferring healthy and pathological neural mechanisms underlying functional brain networks. This is particularly relevant for clinical applications as impaired E/I-balance has now become a refined framework for understanding neurological diseases including autism spectrum disorders, schizophrenia, neurodegenerative diseases, and neuropsychiatric disorders . \n\nIt must be mentioned as a limitation that BNMs are high-dimensional models with thousands of parameters and the identified mechanism may be one out of a potentially infinite number of mechanisms that could explain the observed data. As with any scientific hypothesis, it is therefore crucial to validate and falsify theory with dedicated experiments. Since the used brain network model simulates detailed properties of neural systems like input currents, firing rates, synaptic activity, and fMRI, it is directly amenable for further validation or falsification with empirical data from different modalities. By integrating diverse empirical findings into a unifying computational framework that can be iteratively refined (or refuted) dynamic models provide an avenue out of the \u2018reproducibility crisis\u2018 . BNMs are limited when it comes to their resolution, as they are typically based on connectivity data obtained from non-invasive imaging techniques like MRI and limited computational power to simulate large networks. These problems are addressed with multiscale models where only some parts of the brain are simulated at a finer scale (for example, at the level of spiking neurons ) while the remaining parts are simulated by a coarser network to save computational resources. In addition, by integrating connectivity and other microstructural information from finer scale studies, for example, from invasive rodent studies  or post-mortem human atlases , it becomes possible to further constrain parameters and test the plausibility of simulation results. In this regard, we note that the described relationship between E/I-balance and FC (respectively population synchronization) appears independent of the spatial and temporal scales of the network, and may be used to generally tune also finer-scale or coarser-scale networks, as it is based on generic dynamical primitives of neural mass action applicable to describe dynamics across spatial and temporal scales . Although BNMs employ abstractions, like all models, further advances may emerge precisely where the assumptions break down. For example, the used ensemble models capture neural population dynamics primarily when coherence is sufficiently weak that individual spikes can be ignored or when coherence is sufficiently strong that variance can be considered small, while scale-free dynamics with unbounded variance resist mean-field reductions and may require alternative ensemble methods . Despite these limitations, BNMs are in contrast with artificial neural networks specifically designed to explain the underlying biology, using typically observed features of the empirical system as targets for validation and falsification (Supplementary Fig.\u00a0 ) to achieve an incrementally improved computer model of the empirical system. \n\nIn this work, we found that DM accuracy can be traded with DM speed in dependence of brain network configuration. Faster is therefore not necessarily better, but rather the ability to switch between fast and deep modes of information processing\u2014depending on the nature of the problem and the involved brain areas. The idea that decision-making speed is traded with accuracy is supported by numerous empirical findings in the fields of economy, ecology, psychology, and neuroscience . \n\nOur modeling results now cast this idea in terms of neural network interaction: FC depends on E/I-ratios, E/I-ratios modulate synaptic inputs, which in turn modulates evidence integration in winner-take-all circuits. Decreased synaptic inputs prolong the time window for integration and make DM more dependent on the buildup of slowly reverberating activity between PFC and PPC regions, pointing to a general mechanism that gives higher-order populations top-down control. Slowing down the timescale may bring DM under conscious control, enabling to modulate DM by attentional processes, which is supported by empirical results that associate top-down attention with amplification of PPC activity and increased correlation between PFC and PPC . This idea was formulated as the \u2018ignition\u2019 theory of conscious processing, stating that while most of the brain\u2019s early computations can be performed in a non-conscious mode, conscious perception is associated with long-distance integration of activity in frontoparietal circuits . Importantly, the specific markers that contrast conscious from nonconscious processing overlap with those needed for DM slowing in our model. In the experimental literature conscious perception is systematically associated with surges of prefrontal activity followed by top-down parietal amplification: conscious access crucially depends on a sudden, late, all-or-none ignition of prefronto-parietal networks and subsequent amplification of sensory activity . The most consistent correlate of conscious perception was a late (~300\u2013500\u2009ms) positive waveform in prefrontal regions that reactivated parietal regions along with increased long-distance synchronization in the frontoparietal network , which strongly resembles our model\u2019s behavior: in the slow DM mode ramping of PFC was necessary to amplify activity in PPC, while in the fast DM mode PPC ramping preceded the ramping of prefrontal cortex (Supplementary Figs.\u00a0  and   and Supplementary Movie\u00a0 ). Similarly, monkey recordings showed that WM content in PFC neurons was multiplexed with signals that reflected the subject\u2019s covert attention . Together with the observation that subjects\u2019 performance and WM load correlated with the degree of prefronto-parietal synchronization , the conclusion can be drawn that these processes may reflect top-down prefrontal attentional mechanisms that modulate processing in posterior cortex. Likewise, these results also integrate with the parieto-frontal integration theory of intelligence, which roughly states that after basic processing in temporal and occipital lobes, sensory information is collected in parietal cortex, which then interacts with frontal regions to perform hypothesis tests on attempted solutions to select an optimal solution . \n\nAnother relevant perspective is provided by the distinction into effortful versus automatic cognition: while effortful tasks require synchronization or parietal regions with PFC, the synchronization suddenly drops as soon as subjects move into a routine mode of task execution . Similarly, harder decisions required slow integration in the model\u2019s PFC-PPC network, while simpler decisions were quickly taken by the PPC module. A number of FC studies come to similar conclusions: FC became more integrated during challenging tasks and remained more segregated during simple tasks . Likewise, work on short-term synaptic plasticity suggests that FC is changed to form temporary task-relevant circuits, which comes with energetic and computational advantages , similar to the influential Communication through Coherence theory , which proposes phase synchronization as an essential and generic mechanism for controlling selective information flow in multiplexed brain networks. \n\nMore generally, our study indicates that areas with higher FC may interact on a slower time scale than areas with lower FC. These different time scales could give rise to a hierarchical information processing cascade where intermediate results from faster processes are integrated by slower processes, which is reflected in the emerging view that cortex posits a timescale-based topography with integration windows increasing from sensory to association areas . As receptive windows are progressively enlarged along the hierarchy, DM integration is extended from local to long-range circuits integrating increasingly widespread information, which is supported by studies that show how slow (<0.1\u2009Hz) power fluctuations reliably track the accumulation of complex sensory inputs in higher-order regions . \n\nSummarizing, in the present work we identified a monotonic and smooth relationship between the structural and the functional architecture of neural networks: by tuning the E/I-ratio it became possible to precisely and simultaneously tune the FC between any pair of network nodes to the desired target configuration from full antisynchronization to full synchronization. We believe this is important, as the link between FC and structural brain architecture is often described as unclear and many research streams aim for inferring structural network topology . We therefore expect that the described smooth and monotonic link between network architecture and FC, and the derived learning rule, will be useful to better understand and infer structural network mechanisms underlying healthy and pathological cognition . \n\n\n## Methods \n  \n### Large-scale brain network model \n  \nThe used large-scale BNM simulates brain activity based on the network interaction of population models that represent brain areas. Each brain area is simulated by coupled excitatory and inhibitory population models based on the dynamical mean field model, which was derived from a detailed spiking neuronal network model . Populations are connected by structural connectomes estimated from dwMRI data via fiber tractography. Here, we extended the model using two additional parameters   and   that allow the balancing of long-range excitatory and feedforward inhibitory synaptic currents. The model equations read as follows.  denotes the population firing rate of the excitatory ( ) and inhibitory ( ) population of brain area  .   identifies the average excitatory, respectively inhibitory, synaptic gating activity of each brain area. The sum of all input currents to each area are identified by   (units nA).   are the overall effective external input currents to excitatory, respectively inhibitory, populations, and   the local excitatory recurrence.   and   are parameters that quantify the strengths of excitatory synaptic coupling and local feedback inhibitory synaptic coupling, respectively. Feedback inhibition control using inhibitory synaptic plasticity modulates   of each region such that the long-term average firing rate   of the corresponding excitatory population is   Hz (see section Feedback Inhibition Control). We extended the original model by Deco et al. . by introducing the parameters   and  , which are matrices with the same dimensions as the structural connectome   (regions \u00d7 regions) that describe the strengths of long-range excitation and feedforward inhibition, respectively. Equations\u00a0  and   are sigmoidal functions that convert input currents into firing rates.   and   specify the time scales and rate of saturation of excitatory and inhibitory synaptic activity, respectively.   is noise drawn from the standard normal distribution. Table\u00a0  lists all state variables as well as parameters and their settings. BOLD activity was simulated by inputting excitatory synaptic activity   into the Balloon-Windkessel hemodynamic model , which is a dynamical system that describes the transduction of neuronal activity into perfusion changes and the coupling of perfusion to BOLD signal. The model is based on the assumption that the BOLD signal is a static non-linear function of the normalized total deoxyhemoglobin voxel content, normalized venous volume, resting net oxygen extraction fraction by the capillary bed, and resting blood volume fraction. Please refer to Deco et al.  for the specific set of Ballon\u2013Windkessel model equations that we used in this study. \n\n\n### Multi-scale brain network model \n  \nTo form the multiscale model, we connected the two-module DM circuit functional WM/DM circuit  to the large-scale regions that simulate PPC and PFC. To connect the large-scale network with the mesoscopic network, we augmented the noise terms of the DM circuit network by large-scale BNM inputs to PPC and PFC. The equations of the DM circuit read as follows. \n\nParameter values and state variables have the corresponding meanings as in the equations for the large-scale models (see also Supplementary Table\u00a0  for an overview of quantities and values). Equation\u00a0  shows the original DM circuit model input equation with noise term  . To couple the DM circuit to the large-scale network, the noise term   was replaced by the term   in Eq.\u00a0 . The term adds the noise process from the DM circuit model (Eq.\u00a0 ) to the large-scale BNM input to drive the DM circuit: \n\nSimilar to Eq.\u00a0  the input from the BNM to the DM circuit populations consists of the sum of local recurrent excitation, global network input and local recurrent inhibition. For each region this input is range normalized to bring the range of amplitudes from the 650 individual models into a range suitable for the DM circuit as identified in Fig.\u00a0 , with   and  . For each region the amplitude ranges from the 10th percentile to the 90th percentile over the 650 BNMs was mapped into the range  . To the resulting amplitude the individual Ornstein\u2013Uhlenbeck noise processes were added in order to make one variant of this input for each of the two nodes of one DM circuit module. \n\nDecision-making performance was computed as in the original publication of the DM circuit by Murray et al. by modeling the strength of evidence as an external current to the two parietal populations   A   and   B   as follows: where   nA scales the overall strength of the input and  , referred to as the strength of evidence or contrast, determines which of the two populations   A   or   B   receives higher evidence (  A   received the higher evidence), which reflects the saliency of the target with respect to that of distractors. As in Murray et al. , when one of the two action populations   A   or   B   reaches a firing rate threshold of 40\u2009Hz the decision for option   A   or   B   is taken and a reaction time is registered. We repeated the decision-making task 1000 times in order to compute the percentage of times for which the decision was made correctly (number of times   A   crossed the firing-rate threshold divided by the total number of trials) and the average time until the threshold was reached. \n\n\n### Fitting algorithm \n  \nThe fitting algorithm is based on the observation (Fig.\u00a0 ) that the correlation between the fMRI time series from two different model brain regions can be modulated by the relative strengths of long-range excitation versus feedforward inhibition. This ratio, as outlined in the section Large-scale brain network model, can be adjusted in our model by the parameters   and  , which are multiplicative factors that re-scale the structural connectivity connection weights  , between each pair of connected regions   and  .   modulates the amount of excitation conveyed via long-range connections to distant excitatory populations, or long-range excitation, while   modulates the amount of excitation provided via long-range connections to distant inhibitory populations, and their resulting feedforward inhibitory effect on the accompanying excitatory population, or feedforward inhibition. The goal of the fitting algorithm is to fit weights   and   such that FC computed from simulated fMRI time series matches a target FC as closely as possible. The goal is that the difference between each entry   of the target FC matrix   and   of the simulated FC matrix   should be as small as possible. The basic idea of the fitting algorithm is to increase   and to decrease   if   and, vice versa, to decrease   and to increase   if  . While the overall parameter optimization approach followed a standard gradient descent schema, importantly, the gradients are based on the direct monotonic and smooth relationship that we identified between E/I-ratios and FC, respectively population synchronization (Fig.\u00a0 ), creating a direct biologically interpretable link between brain network structure (specifically the E/I-ratios between network nodes) and the emerging brain network dynamics when simulating the model. In pseudocode the algorithm can be written as follows. \n\n####  Algorithm  \n  \n EI_tuning  ( ,  , M) \n\n Input  : (n x n) target FC matrix \n\n\u2009\u2009\u2009\u2009\u2003\u2003 : scalar learning rate \n\n\u2009\u2003\u2003\u2009\u2009\u2009\u2009M: brain network model \n\n Returns  ,  : (n x n) matrices long-range excitation, feedforward inhibition \n\n for   fmri_time_step = 1   to   simulation_length   do  \n\n\u2009\u2009\u2009\u2009\u2009\u2003simulate one fMRI time step using M \n\n\u2009\u2009\u2009\u2009\u2009\u2003compute simulated FC  \n\n \u00a0 \u00a0 \u00a0 \u00a0\u00a0for   i = 1   to   n   do  \n\n\u2009\u2009\u2009\u2009\u2003\u00a0 \u00a0 \u00a0 \u00a0\u00a0\u2009rmse_i = root-mean-square deviation between matrix rows i in   and  : \n\n \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0for   j\u2009=\u20091 to number of connections of node i   do  \n\n\u2009\u2009\u2009\u2009\u2003\u2009\u2009\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0diff_FC =   -  \n\n\u2009\u2009\u2009\u2009\u2003\u2009\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  =  +  x diff_FC x rmse_i \n\n\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2003\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0  =   -   x diff_FC x rmse_i \n\n\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2003\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0  if   do  \n\n\u2009\u2009\u2009\u2009\u2009\u2009\u2009\u2003\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0  if   do  \n\nreturn  ,  \n\nThe algorithm iterates over all connections   of the BNM and computes the difference between target and simulated FC for each connection. This difference is rescaled by the learning rate  , which is gradually decreased over the course of the tuning. Furthermore, the difference is re-scaled by the root-mean-square deviation (RMSE) between the correlation coefficient values of region   with all remaining regions (i.e. the RMSE between rows   of matrices   and  ), which can be compared to the temperature parameter in a simulated annealing heuristic. The factor has the purpose to decrease the change in   and   as the fit of the row-wise FC increases and we approach an optimum. Furthermore, the factor differentially weights the changes in   ( ) and   ( ) with the purpose that the region (either   or  ) that has a better fit at the current tuning iteration is changed less than the other one, since the change of connection strengths between one region pair has an effect on the FC between all other region pairs. By decreasing the step size for the better-fitting region, we ensure that respective parameters stay closer to the local optimum. In the present paper this heuristic is used as an online parameter tuning rule, which means that parameters are updated after each new BOLD fMRI time step is computed. We tested different values for the learning rate parameter  , and devised a tuning workflow in which initially the parameter space is sampled with large steps (large learning rate) using FC that is based on a short time window. The tuning lasted over six stages where each stage was simulated for 10\u2009hours of biological time. The learning rate   was halved and the window size of simulated FC   was doubled in each stage, starting with a learning rate of  \u2009=\u20090.1 and a window size of 150 TRs. The wall time for simulating one hour of biological activity on one standard CPU was roughly two hours, which led to a computational cost of   to tune a single model and a total cost of 78,000 CPU hours to tune all 650 models. Fitting runs were executed in parallel on high performance computers. The costs for running subsequent DM and WM experiments with the fitted and coupled multiscale models were negligible and performed on a standard laptop as only a few seconds of activity were needed to simulate one DM or WM experiment. \n\n\n\n### Feedback inhibition control \n  \nThe firing rate of the large-scale neural masses (Eqs.\u00a0  and  ) depends on synaptic input currents (Eqs.\u00a0  and  ), which are, to a large degree, determined by the structural connectome  , that is, large-scale inputs, and associated parameters (  and  ). To compensate for excess or lack of excitation, which would result in implausible firing rates, a local regulation mechanism, called feedback inhibition control (FIC), was used. The approach was previously successfully used to significantly improve FC prediction, and for increasing the dynamical repertoire of evoked activity and the accuracy of external stimulus encoding . To implement FIC we used a learning rule for inhibitory synaptic plasticity that was shown to balance excitation and inhibition in sensory pathways and memory networks . The learning rule modulated all connection strengths from inhibitory to local excitatory populations once every 720\u2009ms (corresponding to 1 fMRI repetition time) to achieve a target average firing rate of 4\u2009Hz in excitatory populations. The learning rule can be summarized as where   denotes the change in synaptic strength,   and   are the pre- and postsynaptic firing rates,   is the learning rate and   is the target firing rate for the postsynaptic excitatory population. If postsynaptic firing rate   is larger than the target firing rate  , the learning rule increases the inhibitory weight  , to decrease the postsynaptic firing rate. Conversely, if the postsynaptic firing rate is lower than the target firing rate, the learning rule decreases the inhibitory weight. The change of the inhibitory weight is modulated by the presynaptic firing rate  : if presynaptic firing is large, then a higher weight change is needed to get the desired effect than when presynaptic firing is low. The learning rate   was found by trial and error. \n\n\n### Data and preprocessing \n  \nWe used the publicly available HCP Young Adult data release , which includes behavioral and 3\u2009T MR imaging data from healthy adult participants (age range 22\u201335 years). Informed consent forms, including consent to share deidentified data, were collected for all subjects (within the HCP) and approved. Data collection was approved by a consortium of institutional review boards in the United States and Europe, led by Washington University (St Louis) and the University of Minnesota (WU-Minn HCP Consortium). The experiments were performed in compliance with the relevant laws and institutional guidelines and were approved by the medical ethical committee of the Charit\u00e9 Medical Center in Berlin (EA4/184/20). All data were collected on a 3\u2009T Siemens Skyra scanner with gradients customized for the HCP. We restricted our analysis to 650 subjects (360 female, 290 male, based on self-report during data collection by the HCP; no analyses regarding sex or gender were performed as the goal of this study was to elucidate mechanisms that are independent of sex or gender) with complete MRI data including all four sessions of resting-state fMRI, structural MRI (T1w and T2w), diffusion-weighted MRI (dwMRI) as well as the behavioral measures PMAT24_A, CardSort, ProcSpeed and Flanker were available, and which were not identified with quality issues by HCP. The HCP publishes lists with subjects where quality control issues were identified ( ), which involved 151 subjects at the time of writing. Furthermore, we identified one additional subject that had absent connections that was more than four standard deviations away from the mean over all subjects. Resting-state fMRI data were acquired in four separate 15-min runs on two different days (two per day) with a 2-mm isotropic spatial resolution (FOV: 208\u2009mm \u00d7 180\u2009mm, Matrix: 104 \u00d7 90 with 72 slices covering the entire brain) and a 0.73-s temporal resolution. For correction of EPI distortions, additionally two spin echo EPI images with reversed phase encoding directions were acquired. dwMRI had a resolution of 1.25\u2009mm isotropic, 128 diffusion gradient directions, and multiple q-space shells with diffusion-weightings of b\u2009=\u20091000\u2009s/mm2, b\u2009=\u20092000 s/mm  and b\u2009=\u20093000\u2009s/mm . For correction for EPI and eddy-current-induced distortions two phase-encoding direction-reversed images for each diffusion direction were acquired. From HCP, we downloaded preprocessed fMRI, structural MRI and dwMRI data that underwent HCP\u2019s preprocessing pipelines, which combine tools from FSL, FreeSurfer and the HCP Connectome workbench to perform distortion correction and alignment across modalities . For high-resolution (0.7-mm isotropic) T1-weighted and T2-weighted MR scans HCP pipelines corrected for distortions using a B0 field map and then linearly registered the anatomy with a common MNI template. Individual surface registration was achieved by combining cortical surface features and a multimodal surface matching algorithm . fMRI pipelines include distortion-correction, motion correction, registering fMRI data to structural data, reduction of the bias field, normalization to a global mean, brain masking, re-sampling of fMRI time series from the volume into the gray-ordinates standard space, and denoising using FSL\u2019s ICA-FIX method. Corrected time series were then sampled into HCP\u2019s 91,282 standard grayordinates (CIFTI) space, which is a combined representation of a cortical surface triangulation (32k vertices per hemisphere) and a standard 2\u2009mm subcortical segmentation . We parcellated grayordinate fMRI time series using HCP\u2019s multimodal parcellation  and computed region-wise average time series and FC matrices. For dwMRI data, HCP pipelines normalize the b0 image intensity across runs; remove EPI distortions, eddy-current-induced distortions, and subject motion; correct for gradient-nonlinearities; perform registration with structural data, resamples into 1.25\u2009mm structural space; and mask the data with a brain mask. For dwMRI tractography we employed our own pipelines  based on the tractography toolbox MRtrix3 . Structural MRI images were segmented into five tissue types to aid Anatomically-Constrained Tractography, a MRtrix3 function that removes anatomically implausible tracks. Multi-shell, multi-tissue response functions were estimated using MRtrix3 software dwi2response, followed by multi-Shell, Multi-Tissue Constrained Spherical Deconvolution using dwi2fod. For each subject full-brain tractograms with 25 Million tracks were generated using tckgen, subsequently filtered with tcksift2, and mapped to the HCP MMP parcellation used for computing fMRI FC to produce matching structural connectomes. The   g  -factor was computed using the code of Dubois et al. who performed factor analysis of the scores on 10 cognitive tasks from the HCP data set to derive a bi-factor model of intelligence, which is the standard in the field of intelligence research . \n\n\n### Statistical tests \n  \nTo test whether simulated data samples that we obtained for the different RT groups have the same or different distributions we used the nonparametric Friedman test (implemented by the function friedmanchisquare() in the Python package SciPy stats) followed by a posthoc multiple comparison analysis using Nemenyi\u2019s test (using the function posthoc_nemenyi_friedman() implemented in the Python package scikit-posthocs). Data samples were not normally distributed (tested with Lilliefors test) and contained repeated measurements (each group model was fitted 500 times with different initial conditions and then simulated). To test whether medians are equal for data with unequal sample sizes and without repeated measurements we used the Kruskal\u2013Wallis test followed by posthoc Conover\u2019s test (implemented as SciPy functions kruskal() and posthoc_conover()) for pairwise multiple comparisons. \n\n\n### Reporting summary \n  \nFurther information on research design is available in the\u00a0  linked to this article. \n\n\n\n## Supplementary information \n  \n\n\n\n\n \n", "metadata": {"pmcid": 10206104, "text_md5": "18af10cdf6a19edd4ccb69d0109c07d1", "field_positions": {"authors": [0, 53], "journal": [54, 64], "publication_year": [66, 70], "title": [81, 161], "keywords": [175, 261], "abstract": [274, 1747], "body": [1756, 66404]}, "batch": 1, "pmid": 37221168, "doi": "10.1038/s41467-023-38626-y", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10206104", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=10206104"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10206104\">10206104</a>", "list_title": "PMC10206104  Learning how network structure shapes decision-making for bio-inspired computing"}
