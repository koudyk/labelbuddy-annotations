{"text": "Murden, Raphiel J. and Zhang, Zhengwu and Guo, Ying and Risk, Benjamin B.\nFront Neurosci, 2022\n\n# Title\n\nInterpretive JIVE: Connections with CCA and an application to brain connectivity\n\n# Keywords\n\ncanonical correlation analysis\ndata integration\nfunctional connectivity\nHuman Connectome Project\njoint and individual variance explained\nprincipal component analysis\nstructural connectivity\n\n\n# Abstract\n \nJoint and Individual Variation Explained (JIVE) is a model that decomposes multiple datasets obtained on the same subjects into shared structure, structure unique to each dataset, and noise. JIVE is an important tool for multimodal data integration in neuroimaging. The two most common algorithms are R.JIVE, an iterative approach, and AJIVE, which uses principal angle analysis. The joint structure in JIVE is defined by shared subspaces, but interpreting these subspaces can be challenging. In this paper, we reinterpret AJIVE as a canonical correlation analysis of principal component scores. This reformulation, which we call CJIVE, (1) provides an intuitive view of AJIVE; (2) uses a permutation test for the number of joint components; (3) can be used to predict subject scores for out-of-sample observations; and (4) is computationally fast. We conduct simulation studies that show CJIVE and AJIVE are accurate when the total signal ranks are correctly specified but, generally inaccurate when the total ranks are too large. CJIVE and AJIVE can still extract joint signal even when the joint signal variance is relatively small. JIVE methods are applied to integrate functional connectivity (resting-state fMRI) and structural connectivity (diffusion MRI) from the Human Connectome Project. Surprisingly, the edges with largest loadings in the joint component in functional connectivity do not coincide with the same edges in the structural connectivity, indicating more complex patterns than assumed in spatial priors. Using these loadings, we accurately predict joint subject scores in new participants. We also find joint scores are associated with fluid intelligence, highlighting the potential for JIVE to reveal important shared structure. \n \n\n# Body\n \n## 1. Introduction \n  \nModern biomedical and scientific studies often collect multiple datasets in which the number of variables may greatly exceed the number of participants. This is common in neuroimaging studies, where multiple neuroimaging data types, referred to as modalities, as well as behavioral and demographic data, are often collected (Mueller et al.,  ; Glasser et al.,  ). The importance of such multi-dataset studies underscores the urgent need for quantitative methods capable of simultaneous analysis of these datasets. \n\nA fundamental goal in neuroimaging is understanding the similarities between structural connectivity (SC) and functional connectivity (FC), where FC can be quantified by cross correlations between brain region time series revealed through functional magnetic resonance imaging (fMRI) and SC by measures of anatomical connections revealed using diffusion-weighted MRI (dMRI) (Honey et al.,  ). Studies have reported that brain regions with strong SC demonstrate more reliable functional connections (Honey et al.,  ; Kemmer et al.,  ), and incorporating SC information leads to more reproducible FC network estimation (Higgins et al.,  ). However, additional research is needed to elucidate the information shared between measures of connectivity and the information unique to structural or functional connectivity. \n\nUnsupervised methods are commonly used to reduce the dimensionality of imaging datasets, which is often a key step in the joint analysis of multi-modal imaging data. Principal Components Analysis (PCA) finds components of maximum variance. It has been used to extract eigenimages from a group of individuals (Penny et al.,  ) and as a means of dimension reduction prior to employing a supervised learning method (L\u00f3pez et al.,  ). Independent Component Analysis (ICA) is used to find components that are as independent as possible. It is commonly used to estimate resting-state networks, or regions that share a high degree of functional coupling in resting-state fMRI (Biswal et al.,  ). Non-negative matrix factorization (NNMF) constrains components to have positive entries. NNMF was used to decompose structural images from dMRI into brain regions that consistently co-varied across individuals (Sotiras et al.,  ). Auto-encoders (AEs) use neural networks for unsupervised dimension reduction. AEs have been used to learn latent feature representations from gray matter volumes extracted from structural MRI images, intensities from 18-fluoro-deoxyglucose positron emissions tomography (FDG-PET), and cerebrospinal fluid biomarkers (Suk et al.,  ). Recently, increasing attention has been paid to data integration and data fusion methods (Sui and Calhoun,  ), which may provide insight into the relationship between structural and functional MRI without imposing a priori spatial constraints. \n\nStatistical approaches to data integration date back to the 1930s with canonical correlation analysis (CCA) (Hotelling,  ). Smith et al. ( ) used PCA and CCA to integrate fMRI and behavioral data from the Human Connectome Project (HCP). Recently, novel methods that assess the shared structure between datasets have arisen (Li et al.,  ; Witten et al.,  ), including several which also explore structure unique to each dataset (Lock et al.,  ; Zhou et al.,  ; Feng et al.,  ; Gaynanova and Li,  ; Shu et al.,  ). A recent application of CCA developed a novel approach to jointly analyze functional and structural connectomes while assessing differences between groups of participants (Zhang et al.,  ). \n\nJoint and Individual Variation Explained (JIVE) is an unsupervised method that has been used in neuroimaging (Yu et al.,  ; Zhao et al.,  ), genetic data (O'Connell and Lock,  ; McCabe et al.,  ), and for other applications (Lock et al.,  ). JIVE is similar to PCA in that subject scores are extracted, but unlike PCA, JIVE estimates scores that are shared across datasets (joint scores) and scores that are unique to each dataset (individual scores). Common and orthogonal basis extraction (COBE), which is closely related to JIVE (Zhou et al.,  ), was applied to multi-subject resting-state correlation matrices where individual structure was used in connectome fingerprinting (Kashyap et al.,  ). Throughout the remainder of this manuscript, we will refer to the JIVE implementation in Lock et al. ( ) and the follow-up paper O'Connell and Lock ( ) as R.JIVE. An alternative algorithm and rank-estimation routine for JIVE were recently proposed in Angle-based JIVE (AJIVE) (Feng et al.,  ). AJIVE uses matrix perturbation theory (Wedin,  ) to determine when two similar directions of variation represent noisy estimates of the same direction, and it uses a non-iterative algorithm that can decrease computational costs. \n\nDespite the advancement in JIVE, there are limitations that may hinder its widespread application. JIVE is formulated as a subspace decomposition with shared structure captured by equivalent score subspaces, and the results can be difficult to interpret. For instance, singular value decompositions (SVDs) of joint matrices (called block-specific scores) result in subject scores that differ across datasets. The relative importance of the components of the estimated joint subspace requires an alternative representation. If JIVE is used for biomarker development, as in Sandri et al. ( ), researchers may want to estimate a subject score for a new patient, which can then be used to classify their risk. Additionally, simulation studies examining the accuracy of the rank selection procedures and estimated components are needed to provide guidance to scientific applications. \n\nOur contributions are the following. \n  \nWe provide an intuitive view of AJIVE as averaging the canonical variables from the canonical correlation analysis of the principal component scores. We present a permutation test for the joint structure, and we call this alternative perspective and permutation test Canonical JIVE (CJIVE). The use of the phrase \u201cinterpretive JIVE\u201d in the title of this manuscript emphasizes how we re-interpret the JIVE framework, and it is a play on the phrase \u201cinterpretive dance\u201d and the original meaning of the jive dance from the 1930s. \n  \nWe evaluate three methods for predicting joint scores in new subjects, and demonstrate that these methods are effective at predicting joint scores in new subjects. \n  \nSimulation studies show that, in AJIVE and CJIVE, overestimating the signal ranks can generally lead to underestimation of the joint ranks. AJIVE and CJIVE tend to outperform R.JIVE when the joint signal is small. \n  \nWe apply JIVE to the integration of functional and structural connectivity using a state-of-the-art pipeline applied to 998 subjects from the Human Connectome Project. JIVE reveals new insights into the shared variation, in particular revealing relationships that go beyond conventional spatial priors. We accurately predict joint subject scores in new subjects, and joint scores are related to fluid intelligence. \n  \nSection 2 describes the statistical methodology employed in AJIVE, R.JIVE, and sparse CCA (sCCA), and introduces CJIVE. Section 3 conducts simulation studies. Section 4 analyzes the HCP data. We discuss our findings and recommendations in Section 5. \n\n\n## 2. Statistical methodology \n  \nA table of the notation we will use is given in  . \n  \nNotation used throughout the manuscript. \n  \n### 2.1. JIVE decomposition \n  \nConsider a collection of   K   data blocks/matrices,  , where   n   is the number of subjects and   p   the number of features or variables in the   kth   dataset. Each data block can be written as   X   =   J  +  A  +  E  , where   J   represents the joint signal common to both data blocks,   A   represents the block-individual signal, which is unique to the   k   data block, and   E   represents full-rank isotropic noise. The JIVE model assumes that each rank-reduced signal matrix   X  \u2212  E   [with rank   r   < min(  n, p  )] can be decomposed into a subspace of \u211d  that is common across   X   (the joint subspace) and a subspace that is unique to the   kth   dataset and orthogonal to the joint subspace (the individual subspaces) (Feng et al.,  ). In our presentation, we expand on one of three ways to represent the joint subspace, called the \u201ccommon normalized score\u201d representation in Feng et al. ( ). We emphasize this representation because it results in a correspondence between the joint components of each dataset, whereas the other representations are arguably less interpretable. The common basis,  , is derived from joint analysis of all data blocks, and the other,   from the part that remains after joint analysis, where   r   =   r  \u2212  r  . Let   I   be the   d  \u00d7  d   identity matrix and 0 a matrix of zeros. Furthermore, let the joint and individual signal matrices of the   k   data block take the form   J   =   ZW   and   A   =   B   W  , respectively. Then the JIVE model corresponds to the matrix decomposition \n\nWe call   Z   joint subject scores and   W   joint variable loadings. Individual subject scores are given by   B   and individual variable loadings by   W  . Intuitively, this decomposition is similar to a singular value decomposition on each dataset but with part of the basis constrained to be equal in the two decompositions. \n\nIn this representation, we do not enforce orthogonality between   B   and  . Later, we propose a permutation test for the joint rank,   r  , that determines when the correlation between signal is sufficiently large to be deemed joint, but allows insignificant correlation between individual subject scores. Our proposed approach will also result in an intuitive ordering of components by the strength of evidence that they are joint. Also note that in (1), the rows of the loadings matrices   W   are not orthogonal. \n\nFor the HCP network data that we examine in Section 4, we can translate each row of the score (  Z  ,   B  ) matrix into a low-dimensional vector summary of a participant's   kth   network data (e.g., FC). The joint scores   Z   summarize information that is common across modalities, while   B   comprise information unique to an individual modality. For instance, Section 4.3 shows that CJIVE joint scores are more strongly associated with a measure of fluid intelligence than individual scores. The   lth   row of the loading matrix   W   exhibits the magnitude with which network edges contribute to the   lth   column of the summary scores in   Z  . In Section 4.4, we examine variable loadings to develop insight into latent structures that are common within both modalities and those which are unique to each. \n\n#### 2.1.1. R.JIVE estimation \n  \nR.JIVE uses an iterative algorithm that simultaneously estimates joint and individual matrices. Each dataset is column-centered and scaled by its Frobenius norm. In our data application, we standardize the variance of each variable prior to scaling by the Frobenius norm. The algorithm iterates between estimating the joint subspaces and individual subspaces; details are in the Web Appendix A.1.1 ( ). The ranks of the joint and individual matrices are selected using permutation tests. In the default R.JIVE implementation, the individual subspaces are orthogonal (O'Connell and Lock,  ). \n\n\n#### 2.1.2. AJIVE estimation \n  \nIn AJIVE, the joint rank   r   is determined using principal-angle analysis (PAA) and requires user-specified signal ranks   r   =   r  +  r   and   r   =   r  +  r  . The main idea is to investigate when basis vectors in the signal subspaces should be considered \u201cnoisy\u201d estimates of the same direction. This problem can be translated into finding the singular values of the concatenated signal bases that exceed a given threshold. \n\nFor the remainder of this paper, we standardize the columns of   X   and   X   to have mean zero and variances equal to one, as commonly done in PCA. Note R.JIVE performs an additional normalization by the Frobenius norm. \n\nFirst, the user specifies the ranks used in PCA of   X   and   X  . Let   U   and   U   denote the   r   and   r   left singular vectors of   X   and   X  . Define   C   = [  U  ,   U  ]. Let   U   denote the left singular vectors of   C  . Feng et al. ( ) develop two bounds to determine whether the   j  th column of   U   represents a joint direction of variance. These bounds are discussed in the Web Appendix A.1.2 ( ). \n\n\n\n### 2.2. Using CCA to interpret JIVE: CJIVE \n  \n#### 2.2.1. Equivalence of estimators \n  \nWe review CCA and describe how it relates to the AJIVE algorithm. For data matrices   X   and   X  , CCA seeks vectors   \u03c9   and   \u03c9   to maximize Corr(  X   \u03c9  ,   X   \u03c9  ). Subsequent canonical vectors,  , arise from a similar optimization problem with the additional constraint   for all   j  <  j  \u2032. If   X   and   X   are centered and semiorthogonal matrices, then the CCA problem can be written as \n\nThen the solutions to (2), which we denote as   and  , are given by the left and right singular vectors of  , which are unique up to a change in sign (Mardia et al.,  ). Additionally,   is the   j  th canonical correlation. \n\nClassic CCA can not be applied to   p  >  n  . Sparse CCA is one alternative (Witten et al.,  ), and it turns out JIVE is a reduced-rank alternative. Feng et al. ( ) show that the   jth   joint subject score from AJIVE is equivalent to the average of the   jth   canonical variables of the CCA of the scores from the separate PCAs, up to scaling. Our theorem, below, formalizes their finding. A proof is provided in the Web Appendix A.3 ( ). \n\n Let the columns of   U   and   U   represent orthonormal bases for the signal matrices   X  \u2212  E   and   X  \u2212  E   . Let   be the   jth   joint subject score from AJIVE analysis. Let   and   represent the canonical vectors from the CCA of   U  ,   U   . Let   \u03c3  denote the   j   th singular value of   C   = [  U  ,   U  ]  . Then  \n\n Additionally, the canonical correlation  . \n\nIn summary, the   jth   joint score vector from AJIVE is equivalent to a scaled average of the   jth   canonical variables of the principal component scores. This perspective is illustrated in  , and we define CJIVE (CCA JIVE) in the next section. \n  \nSchematic of the CJIVE decomposition for obtaining joint subject scores and loadings. Quantities specific to   X   are shown in blue; those specific to   X  , orange. Gray boxes illustrate scores, with a green outline for joint scores. Checked and dotted boxes represent loadings. Steps are outlined in  . Separately, SVD is applied to each data block (far left) to obtain low-rank PC scores (all score matrices are shown as gray boxes). Next, CCA is applied to the PC scores with the number of components chosen using a permutation test. Joint subject scores are equivalent to a weighted average of the resultant canonical variables. Joint loadings result from the matrix product between joint subject scores and data blocks, i.e., regression of the data blocks onto joint subject scores. \n  \n\n#### 2.2.2. CJIVE: Ordering, permutation test, and unique components \n  \nThe CCA perspective on the signal subspaces provides a useful way to interpret the joint components. We view the canonical correlations defined in Theorem 2.1 as a measure of the strength of the corresponding joint component, which provides an ordering. \n\nThis motivates the use of a permutation test of the canonical correlations of the PCs. For   b   = 1, \u2026,   n  , let   represent a copy of   U   with the rows permuted so that they no longer represent the same ordering of participants as in   U  . We then obtain the null distribution of the canonical correlations from the max of the singular values of  ,   b   = 1, \u2026,   n  . For each component, we calculate a   p  -value as the proportion of maximal null correlations which exceed that component's canonical correlation. By using the max across all singular values, the family-wise error rate is controlled at the specified \u03b1-level. Once we have estimated   r   via   the permutation test, we calculate joint scores using the results of Theorem 2.1 and estimate the signal matrices using the same procedure in AJIVE.   describes how to conduct the CJIVE procedure. \n  \nCJIVE Procedure. \n  \nHere, we summarize the CJIVE procedure depicted in  . \n\nCJIVE provides a unique decomposition of   and   (up to sign) when the canonical correlations differ across components, as expected to occur in data. In the JIVE model given by (1), it is assumed that the joint subject score subspaces are equivalent. Then, the components are not unique. As in AJIVE (Feng et al.,  ), the joint scores represent an orthogonal basis for the joint column space. Therefore, an orthogonal transformation of these scores will result in the same joint column space. \n\n\n#### 2.2.3. Predicting joint scores in new participants \n  \nAn important problem is how to apply the results from JIVE analysis to a new participant. For example, if JIVE is used for biomarker development, we may want to estimate a subject score for a patient, which can then be used to classify their risk. \n\nOne straightforward way of using JIVE to predict new joint scores is to regress each new pair of observations onto the generalized inverse of joint loadings to obtain block-specific joint scores and then compute their average. Let  ,   k   = 1, 2, represent joint loadings from applying JIVE on the data blocks   X  and  X  . Let   and   be data for a new participant. Then define predicted joint scores as \n\nwhere   represents the g-inverse of  . Define this method as \u201cG-inverse prediction.\u201d To our knowledge, this prediction approach has not been evaluated. \n\nR.JIVE-prediction (Kaplan and Lock,  ) estimates subject scores in new participants using an iterative process that aims to minimize the sum of squared errors between the new data matrices and noise-decontaminated JIVE signal by alternatively estimating new subject scores with the loadings from a previous JIVE analysis. \n\nA third approach is based on the canonical variables given in Theorem 2.1, hereafter, CJIVE-prediction. First, we predict the PC scores for a new subject; second, we estimate the canonical variables of the PC scores from each dataset; third, we sum the canonical variables and normalize to length one. Let   represent a rank   r   SVD of   X  . Using CCA on   U   and   U   yields matrices of canonical vectors:   and  . The predicted estimate for each canonical variable is given by   and  . Then the   jth   joint score is \n\nfor   j   = 1, \u2026,   r  . \n\nWe apply and evaluate these three prediction methods in both the simulation study of Section 3 and analysis of the HCP data (Section 4). \n\n\n\n\n## 3. Simulation study \n  \n### 3.1. Simulations comparing JIVE methods \n  \nWe conduct simulation studies to address the following gaps in the current understanding of the performance of R.JIVE and AJIVE: (1) accuracy when the joint signal strength is low vs. high; (2) rank selection when the number of joint components is >1; and (3) the impact of the initial signal rank selection on joint rank selection. We use a full factorial design with the following factors: \n  \nThe number of features in   X  : with levels (a)   p   = 200 and (b)   p   = 10000, \n  \nJoint Variation Explained in   X  : with levels (a)   and (b)  , \n  \nJoint Variation Explained in   X  : with levels (a)   and (b)  . \n  \nThe joint rank was 3, individual ranks were 2, and   n   = 200 in all settings. The entries of the error matrices   E   and   E   were randomly drawn from a standard Gaussian distribution. The number of features in   X   and the individual variation explained for both data blocks were held constant at   p   = 200 and  , respectively. \n\nExperimental factor 1 (i.e.,   p  ) allows us to assess the impact of   p   on the accuracy subspace estimation and   r   estimates. Factors 2 and 3 (i.e.,   and  ) allow us to examine the impact of the joint signal's magnitude within each dataset. \n\nFor each simulation, the subject score matrix [  Z  ,   B  ,   B  ] was drawn from a Bernoulli distribution, with probability 0.2 for   Z   and 0.4 for   B  . The use of two values is similar to the toy examples from Feng et al. ( ), which used \u00b11. Next, we defined loading matrices   W   and   W   with entries from independent, mean 0 multivariate Gaussian distributions with covariance matrices diag(9, 4, 1) and diag(4, 1), respectively. The values along the diagonals were chosen to ensure the strength of components within each joint/individual signal diminished from first to last. Note that this set-up results in approximately orthogonal   A   and   A  . In R.JIVE, we use the option enforcing this orthogonality. This set-up may favor the rank-selection procedure in AJIVE since principal angles between   A  and  A   are large and corresponding singular values are unlikely to exceed the Wedin and random bounds described in Section 2.1.2. \n\nIn order to achieve the desired values of   and  , we rescale the joint and individual matrices such that   X   =   d   J  +  c   A  +  E   for appropriate constants   c   and   d  , as described in Web Appendix B ( ). \n\nThe chordal subspace norm is a distance metric for linear subspaces that has been generalized to matrices, say, true joint scores  , of possibly different ranks (Ye and Lim,  ) and can be calculated as \n\nwhere   and \u03b8  are the principal angles between the column space of   Z   and  . We use this metric in our simulation studies to describe the accuracy of JIVE estimates. Note when the column space of   Z   is contained in the column space of  ,  . Therefore, comparing results from different methods requires examination of rank estimates and subspace estimates. \n\nWe performed 100 simulations using the following methods: (1) AJIVE-  r  , where we used the true total number of components   r   (joint rank + individual rank) as input; (2) AJIVE-Over, where the total number of components was chosen to retain 95% of the variance; (3) R.JIVE-Oracle, which uses both the true   r   and   r   as input; and (4) R.JIVE-Free, with its permutation based algorithm for choosing ranks. We also defined (5) CJIVE-  r   and (6) CJIVE-Over using the same approach for total signal ranks and selecting the joint rank using our permutation test with   n   = 500 and \u03b1 = 0.05. \n\nTo investigate the prediction methods outlined in Section 2.2.3, the subjects for each simulation were randomly divided into training and test subjects, both with sample sizes   n  /2 = 100. AJIVE, CJIVE, and R.JIVE, all with true signal ranks used as inputs, were applied on the training datasets. Subject scores were predicted for new subjects, represented by the test datasets. We then assessed performance by calculating the Pearson correlation coefficient between predicted joint scores for the test datasets and true joint scores for the same datasets for each of the   r   joint score components. \n\n\n### 3.2. Simulation results \n  \n,  show that CJIVE-  r   and AJIVE-  r   chose the correct joint rank in nearly 100% of simulations in all settings except for the low-signal lower-dimensional case. Further investigation indicated the joint rank selection in AJIVE tends to be driven by the random direction bound, rather than the Wedin bound (see Web Appendix A.1.2 in  ). AJIVE-Over and CJIVE-Over both routinely underestimated the number of joint components in all scenarios except lower dimensional high-signal case. When an estimate of   r   is very large, the correlation between permuted datasets can be very large, such that zero joint components are significant. The joint rank estimated in R.JIVE is equal to 2 in a majority of simulations when the joint signal in both datasets is relatively large (bottom-right panels in  , :  ), while it is mostly 0 or 1 in the other scenarios. \n  \nResults of simulation studies:   (A)   p   = 200,   (B)   p   = 10, 000. Each sub-figure shows the estimated joint signal rank for each method and combination of simulation settings. True joint rank equals 3 in all simulations.   and   represent the true joint variation controlled in simulations. We held the sample size and individual variation explained constant at   n   = 200 and  , respectively. Importantly, AJIVE-  r   and CJIVE-  r   are not possible in practice, as the signal ranks must all be estimated. \n  \nCJIVE-  r   and AJIVE-  r   joint score subspace errors trended less than R.JIVE, CJIVE-Over, and AJIVE-Over in all settings, as shown in  . Although the chordal distances for joint loading subspaces from R.JIVE trended less than those from AJIVE-  r  , the lack of accurate joint rank estimates from R.JIVE may indicate that estimated subspaces partially lie within true subspaces. \n  \nResults of simulation studies:   (A,B)   p   = 200,   (C,D)   p   = 10, 000. Each sub-figure exhibits boxplots of chordal norms for each of the post-JIVE measurements described in Section 2.1. Methods with chordal norms equal to 1 result when the estimated joint rank is 0 for all replicates.   and   represent the true joint variation controlled in simulations. We held the sample size, joint rank, and proportions of individual variation explained constant at   n   = 200,   r   = 3, and  , respectively. The left column   (A,C)  , show chordal norms between true and estimated subject scores. The right column   (B,D)  , show chordal norms between true and estimated variable loadings. \n  \nTo summarize, we find that CJIVE-  r   and AJIVE-  r   chose the joint rank correctly in most simulations. For both CJIVE-Over and AJIVE-Over, including too many initial signal components generally resulted in a noise-contaminated signal for each data matrix, which resulted in too few joint components or none at all. Moreover, CJIVE-  r   and AJIVE-  r   estimates of joint score and loading subspaces tended to be more accurate than both R.JIVE-Free and R.JIVE-Oracle. In simulations, AJIVE-  r   is equivalent to AJIVE-Scree plot because the signal rank is identified from the scree plots (Web Appendix Figure S2 in  ). \n\nOut-of-sample subject score estimates were more accurate across joint components using CJIVE-prediction compared to G-inverse prediction ( ). However, R.JIVE-prediction results were most accurate when the joint signal in at least one dataset was relatively strong, i.e.,   for   k   = 1or2. The Pearson correlation coefficients tend to be close to 1, on average, for the first joint component of subject scores across all simulation settings. The third component was predicted poorly in all methods when the joint signal is relatively weak, i.e.,   Recall data were simulated so that the proportion of variance attributable to the   jth   joint component in   X  ,   k   = 1, 2,   j   = 1, 2, 3 is given by  . Therefore, components are ordered (from highest to lowest) by the proportion of joint variation that they contribute, which may contribute to the trend in poorer prediction as   j   increased. \n  \nResults of simulation studies:   (A)   p   = 200,   (B)   p   = 10, 000. Boxplots of absolute Pearson correlations between predicted joint scores and true joint scores in simulation study.   and   represent the true joint variation controlled in simulations. We held the sample size and individual variation explained constant at   n   = 200 and  , respectively.   (A)   shows results for   p   = 200,   p   = 200.   (B)   shows results for   p   = 200,   p   = 10, 000. Data were simulated so that the proportion of variance attributable to the   jth   joint component in   X  , (  k   = 1, 2;  j   = 1, \u2026  r  ) is given by  . \n  \n\n\n## 4. Joint analysis of structural and functional connectivity in the human connectome project data \n  \n### 4.1. Human connectome project data and processing \n  \nOur data application uses measures of FC and SC from   n   = 998 study participants (532 females) in the young adult Human Connectome Project (HCP). Web Appendix Table S4 in   provides demographics. We applied R.JIVE, AJIVE, CJIVE, and sCCA to examine multivariate relationships across brain networks as measured by Fisher z-transformed correlations from rs-fMRI (FC) and log-transformed streamline counts from dMRI (SC). \n\nHCP rs-fMRI data comprise two left-right phase encoded and two right-left phase encoded 15-min eyes-open rs-fMRI runs (Glasser et al.,  ). Each run used 2-mm isotropic voxels with 0.72 s repetition time. For each run, we calculated the average time series for each of the 68 cortical regions of interest (ROIs) from Desikan et al. ( ) plus the 19 subcortical gray-matter ROIs from Glasser et al. ( ). For each participant and pair of ROIs, the Pearson correlation was calculated, Fisher z-transformed, and then averaged across the four runs. The lower diagonal of each subject's connectivity matrix was vectorized, resulting in   p   = 3, 741. \n\nFor each HCP participant, three left-right and three right-left phase-encoded runs of dMRI from three shells of   b   = 1, 000, 2, 000, and 3, 000 s/mm  with 90 directions and 6   b   acquisitions interspersed throughout were acquired (Glasser et al.,  ). Whole-brain tractography for each participant was conducted using probabilistic tractography as detailed in Zhang et al. ( ). On average, around 10  voxels occurring along the white matter/gray matter interface were identified as seeding regions for each participant. Sixteen streamlines were initiated for each seeding voxel, resulting in ~10  streamlines for each participant. Nodes of the SC networks were defined from the same ROIs as the rs-fMRI. Edges were represented by the number of viable streamlines between ROIs, with viability determined by three procedures: (1) each gray matter ROI is dilated to include a small portion of white matter region; (2) streamlines connecting multiple ROIs were cut into pieces such that no streamlines pass through ROIs; and (3) apparent outliers were removed. Finally, edges where at least 99% of subjects had zero streamlines were removed, and the remaining streamline counts were log transformed. There were   p   = 3, 330 edges in the resultant SC data matrix. Plots of the mean FC and SC appear in the Web Appendix Figure S5 ( ). \n\n\n### 4.2. Dimension selection and joint and individual variation explained \n  \nBoth AJIVE and CJIVE with the scree-plot method for choosing total ranks estimated two joint components ( ), which implies that results from these methods are equivalent. Similarly, both AJIVE and CJIVE estimated 0 joint components when the total ranks were chosen to result in retaining 95% of the variation. R.JIVE with its permutation tests estimated 1 joint component. \n  \nEstimated joint and total signal ranks and joint and individual variation explained in the functional connectivity (Pearson correlations) and the dMRI (streamline counts) HCP data. \n  \nFC, functional connectivity; SC, structural connectivity. \n  \nThe canonical correlations were \u03c1  = 0.31 and \u03c1  = 0.21 using 1,000 permutations in CJIVE-Scree plot. n CJIVE-Scree plot, we also examined the breakdown of the joint variances by component: the proportion of variation attributable to joint component 1 was 0.094 in FC and 0.017 in SC ( ). For component 2, the values were 0.018 and 0.015, respectively. \n\nIn addition to the previous analysis, we performed an irregular grid search to examine the impact of the signal rank selection on the estimation of the joint rank when using CJIVE and AJIVE. Specifically, we examined {2, 5, 7, 10, 15, 20, 25, 30, 39, 40, 50, 75, 100, 200, 225, 500, 990} for FC, where 39 and 225 capture 80 and 95% of the variance, respectively, and {2, 5, 7, 10, 15, 20, 25, 30, 40, 50, 75, 100, 200, 330, 500, 683, 990} for SC, where 330 and 683 capture 80 and 95% of the variance. The proportion of variation explained by the corresponding number of PCs are given in Web Appendix Table S3 ( ). The joint rank estimates for each pair of signal ranks are displayed in  . The joint rank in CJIVE and AJIVE tended to increase initially. When 80% of the variance was retained in FC and SC (  r   = 39 and   r   = 330), CJIVE and AJIVE estimated   r  = 3 and 4, respectively. The joint ranks were maximized at   r   = 225 and   r   = 75, with CJIVE selecting   r   = 11 and AJIVE   r   = 12 ( ). The joint rank estimated by AJIVE and CJIVE depends on the choice of total signal rank, but hereafter we focus on the more parsimonious representation from  , which is easier to interpret. \n  \nJoint ranks chosen by   (A)   CJIVE and   (B)   AJIVE. Gray boxes show when a JIVE implementation produced an error. \n  \n\n### 4.3. Subject scores \n  \nJoint subject scores from CJIVE-Scree plot, R.JIVE (R.JIVE using permutation tests for both joint and individual signal ranks), and sCCA, and individual scores from CJIVE-Scree plot and R.JIVE were examined for associations with fluid intelligence (gF). In the HCP, gF was measured as the number of correct responses to the Penn Progressive Matrices Test. We selected this variable as it has previously been examined in Finn et al. ( ), Smith et al. ( ), and our prior study Risk and Gaynanova ( ), and no other behavioral variables were examined. Here, AJIVE-Scree plot results are equivalent to CJIVE-Scree plot, since both methods chose two joint components. We used the R-package   rsq   to calculate the adjusted partial R-squared from the multiple regression predicting fluid intelligence from the joint and individual scores (Zhang,  ), and then take the square root to obtain the partial correlation coefficients. We also estimated two pairs of canonical variables with sCCA. In order to compare results from sCCA to CJIVE, we averaged canonical variables across datasets to obtain a single subject score vector for each joint component. In sCCA, permutations tests resulted in sparsity parameters equal to 0.1 using the   PMA   R package (Witten et al.,  ). \n\nAmong the joint scores, CJIVE-Scree plot resulted in the highest partial correlation coefficient (  r   = 0.251). Partial correlation coefficients for individual scores (  r   = 0.248) and the overall correlation of total scores (joint + individual,   r   = 0.363) were highest in R.JIVE ( ). R.JIVE contained a total of 151 components while CJIVE-Scree plot included 15 components. \n  \nMultiple regression of fluid intelligence onto joint subject scores estimated with CJIVE-Scree plot, R.JIVE, and sCCA. AJIVE and CJIVE are equivalent as both methods selected two joint components. Numbers in parentheses indicate the rank. \n  \nIn all three methods, only the first joint component and no individual components were significantly associated with fluid intelligence after correction for multiple comparisons (CJIVE-Scree plot: first joint component   p   = 10 , Bonferroni corrected for 15 comparisons; R.JIVE:   p   = 10  for the joint component, corrected for 153 comparisons; sparse-CCA:   p   = 10  for the first joint component, corrected for 2 comparisons). \n\n\n### 4.4. Variable loadings \n  \nSince edges from FC and SC networks comprise the features in our input data blocks, loadings are imposed onto symmetric matrices. The sign indeterminacy of the joint loadings for each component was chosen to result in positive skewness. In  , we see that there were strong positive loadings throughout the FC. Overall, there was no clear spatial correspondence between FC and SC, and the correlation between loadings was \u22120.04. Instead, overall higher FC was associated with higher SC in many regions, particularly frontal-frontal and frontal-subcortical, with SC loadings in the opposite direction in certain connections between occipital, parietal, temporal, and subcortical. Plots of the joint loadings for the second component and individual loadings appear in Web Appendix Figures S3\u2013S5 ( ). \n  \n (A)   Variable loadings for the first component of the joint signal space estimated by CJIVE and displayed on heatmaps.   (B)   Displays the top 25  th   percent of L1 norms of the variable loadings related to each cortical ROI for joint component 1. CMF, caudal middle frontal; FUS, fusiform; INFP, inferior parietal; IT, inferior temporal; INS, insula; LOCC, lateral occipital; LORB, lateral orbito-frontal; MT, middle temporal; PCUN, precuneus; PSTS, postcentral; PC, posterior cingulate; POPE, pars opercularis; PORB, pars orbitalis; PTRI, pars triangularis; RMF, rostral middle frontal; SF, superior frontal; SP, superior parietal. \n  \nTaking the L1 norm of each row within each loading matrix reduces the number of features to the number of nodes, which provides a more detailed examination of the patterns. In this analysis, we are particularly interested in L1 norms that are large in both the left and right hemispheres, which suggests the loadings are capturing meaningful biological structure. In the FC loadings,   shows that the most prominent cortical regions in the first joint component correspond to ROIs from the frontal, occipital, and temporal lobes, with extensive left-right hemispheric correspondence. In the SC loadings, we again see left-right hemispheric correspondence, this time in the parietal and temporal lobes, as well as regions that did not exhibit hemispheric correspondence. L1 norms of subcortical regions (not shown) were large in the left and right accumbens, left caudate, and left putamen in both modalities. Additionally, the right putamen and right caudate were prominent in FC, while both left and right hippocampus were prominent in SC. FC and SC loadings for the individual components are depicted in Web Appendix Figures S4, S5 ( ). FC individual component 2 has large loadings on cortical to subcortical edges, and component 5 has large subcortical to subcortical loadings. SC individual component 3 has prominent loadings in both subcortical-subcortical and cortical-subcortical edges. \n\n\n### 4.5. Reproducibility and prediction of new subjects \n  \nSubjects from the HCP data were split into two sets of equal sample size (  n   = 499) to examine the reproducibility of our results. We will refer to the first sub-sample as \u201csample A\u201d and the second as \u201csample B.\u201d CJIVE-Scree plot found   r   = 1 for both samples, while AJIVE-Scree plot found   r   = 2 for sample A and   r   = 1 for sample B. The correlations between the joint loadings from sample A and B were equal to 0.61 for FC and 0.65 for SC (CJIVE-Scree plot and AJIVE-Scree plot are equivalent). When a second joint component was estimated, the correlation of the FC loadings was 0.29 and the SC loadings was 0.38. \n\nWe evaluated the three prediction methods from Section 2.2.3. We compared the predicted joint scores (using the out-of-sample loadings) to those from the scores extracted from a separate analysis of sample B ( ). Pearson correlations between the G-inverse predicted subject scores and CJIVE-Scree plot subject scores were 0.52 and 0.15 for components 1 and 2, respectively. Pearson correlations between subject scores estimated on sample B and those predicted for sample B using R.JIVE-predict were \u22120.02 and \u22120.03 for components 1 and 2, respectively. Using CJIVE-prediction, Pearson correlations were 0.67 and 0.22 for components 1 and 2, respectively. Similar results were achieved when CJIVE loadings from sample B data were used to predict subject scores for sample A. Recall that in simulations R.JIVE-prediction tended to outperform other methods when the joint signal was relatively large in at least one data set ( ). Future research should explore the conditions that may favor R.JIVE-prediction vs. CJIVE-prediction. \n  \nJoint subject scores using CJIVE-predict for sample B from sample A vs. joint subject scores estimated from the full CJIVE analysis of sample B. Gray bands are 95% prediction interval. \n  \n\n### 4.6. Computation time \n  \nThe computation time of CJIVE-Scree plot including the rank permutation test was 99 s. AJIVE-Scree plot with its joint rank selection took 157 s. Using pre-specified scree plot ranks and joint rank = 2, the run time for R.JIVE was over 4 h. These computation times mirrored those in our simulation study, where, on average, CJIVE was twice as fast as AJIVE and ranged from 2 to 50 times faster than R.JIVE (Web Appendix Table S1 in  ). \n\n\n\n## 5. Discussion \n  \nWe propose CJIVE, an adaptation to AJIVE which improves interpretation: (1) the joint scores are an average of the canonical variables of the principal component scores of each dataset; (2) joint scores are ordered by canonical correlations; (3)   p  -values from permutation tests indicate the significance of each joint component; (4) the proportion of variance explained for each of the joint and individual components complements this information. The joint and individual scores estimated using the CJIVE algorithm are equivalent to those estimated using AJIVE when the ranks are specified, while the R.JIVE algorithm results in different estimates of the JIVE model. CJIVE goes beyond CCA by also estimating individual components, which in some applications provides additional biological insight. Our primary contributions are improved interpretation and a faster permutation test. This provides a data-driven method to choose the joint components when conducting PCA and CCA. Simulation study results indicate that when total signal ranks are correctly specified, AJIVE and CJIVE accurately estimated the number of joint components and provided accurate estimates of the subspaces of interest. \n\nWe applied CJIVE to obtain novel insight into the relationship between structural and functional connectivity. Interestingly, we did not find a correspondence between prominent edges in FC and those in SC. However, the biological relevance of subject scores was revealed by their association with fluid intelligence, and reproducibility was demonstrated through the data splitting and prediction of the joint scores. Similarly, a recent joint analysis of FC and SC in preterm and full-term infants identified different edges in FC vs. SC (Zhang et al.,  ). Recent studies suggest that the correlation between the weighted edges in FC and SC is roughly 0.20 (Li\u00e9geois et al.,  ), which is much lower than a landmark study that contained just five subjects (Honey et al.,  ). In the current analyses, calculating the correlation between FC (averaged across subjects, as in Web Appendix Figure S3,  ) and SC was 0.22, and canonical correlations from CJIVE-Scree plot were 0.31 and 0.21. Note these approaches treat the edge as the unit of observation, and the correlations are not comparable to the variation explained in  , in which the units of observation are the subject connectivity matrices and variance is across subjects. Some models assume that higher SC for a given edge leads to higher FC (Higgins et al.,  ), which we refer to as spatial priors. CJIVE allows the extraction of patterns of covariation to provide novel insight not assumed by spatial priors. \n\nWe found that CJIVE joint scores were more strongly related to fluid intelligence than joint scores from R.JIVE or sCCA. The overall correlation from R.JIVE joint and individual components was higher than CJIVE (0.36 vs. 0.28). Note R.JIVE used more components (151 vs. 15). When examining fluid intelligence and all pair-wise resting-state correlations (FC only) in the Web Explorer \u201cHCP820-MegaTrawl,\u201d no edges survive corrections for multiple comparisons, and using the elastic net,   r   = 0.21. Initial studies with a subsample of the HCP rs-fMRI subjects found correlations between predicted and observed fluid intelligence ranging from   r   = 0.4 to   r   = 0.5 (Finn et al.,  ; Smith et al.,  ). Previous studies did not examine the relationship between fluid intelligence, FC, and SC. Interestingly, CJIVE individual scores were not related to fluid intelligence. This may suggest that FC and SC are simultaneously associated with fluid intelligence in a manner that neither is independently. This result combined with the ability to predict out-of-sample subject scores suggests that JIVE is a possible direction for extracting biomarkers from multimodal neuroimaging. JIVE decompositions may result in fewer components than ICA or related non-Gaussian approaches. Simultaneous non-Gaussian component analysis (SING) of working memory task maps and functional connectivity matrices resulted in dozens of joint components that appeared to correspond to smaller regions with greater network specificity (Risk and Gaynanova,  ). A possible limitation of JIVE is that the joint components may reflect brain connections involved in a variety of processes, including fluid intelligence, which may have less network specificity than ICA and non-Gaussian approaches. \n\nIn the definitions given by Chen et al. ( ), multiview analyses align datasets by subjects, whereas linked data analyses align datasets by features. Our application corresponds to multiview analysis. Kashyap et al. ( ) used Common and Orthogonal Basis Extraction (COBE), which is similar to JIVE, in a linked data application. They derived connectome fingerprints from the individual components extracted by treating each individual's FC matrix as a data block. In a single modality study from multiple groups of subjects (e.g., two sites with different subjects), one could explore common structure by applying CJIVE to the features aligned across the two sites, and then examining whether the individual components represent site-specific/batch effects. Recently, methods similar to JIVE have been proposed to conduct such analyses (Lock et al.,  ; Zhang et al.,  ). Instead of permuting subject scores, one could consider permutation tests in the feature signal subspace for testing joint components. Related, group ICA can be viewed as a linked data analysis version of AJIVE treating the space-by-time matrix from each subject as a block and including an additional step that rotates group components. Group ICA first conducts PCA on each subject's space-by-time matrix, concatenates the spatial eigenvectors, then conducts a second PCA to arrive at group components. This procedure is also used in the AJIVE algorithm, except that in group ICA the PC steps are performed on aligned features rather than aligned subjects. Group ICA then performs an additional step in which the group components are rotated to maximize their \u201cindependence,\u201d which improves interpretability. \n\nIn practice, choosing the total signal rank remains a challenge. In simulations, the total signal rank chosen for a data block   via   R.JIVE permutation tests varied with the level of joint signal and the number of features within that block (Web Appendix Figure S1 in  ), and the estimated number of components was relatively large in the real data. Additionally, scree plots of simulated data provide a much clearer distinction between eigenvalues that correspond to signal and those lying outside the signal subspace when compared to scree plots of real data. Most pertinent to our analyses is the result that both the CJIVE and AJIVE methods for estimating the joint rank are sensitive to estimates of the total signal ranks. If   r   approaches   n  , the maximum correlation between permuted datasets is very high, which can lead to the estimation of zero joint components. In fact, when   r   =   n  , the correlation between permuted datasets equals one, and hence zero components are selected by CJIVE. The same issue occurs in AJIVE. \n\nFurther research is needed to explore connections between CJIVE and AJIVE estimates for more than two datasets. Multiset CCA (mCCA) (Li et al.,  ) extends CCA to multiple datasets by maximizing the sum of pairwise correlations. A CJIVE variant on mCCA may provide novel insights into individual structure. A related issue is that for more than two datasets, joint signal may be shared by a subset of datasets (Gaynanova and Li,  ). When combining more than two datasets, future research should examine optimal ways of combining the canonical variables of the PC scores. \n\n\n## Data availability statement \n  \nData was provided, in part by the Human Connectome Project, WU-Minn Consortium (Principal Investigators: David Van Essen and Kamil Ugurbil;1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University. The datasets analyzed for this study can be found at:  . Requests to access these datasets should be directed to Human Connectome Project,  . \n\n\n## Author contributions \n  \nRM, ZZ, YG, and BR contributed to conception and design of the study. RM, ZZ, and BR processed the data. RM conducted the data analysis and simulation studies. RM and BR wrote the manuscript. All authors contributed to the article and approved the submitted version. \n\n\n## Funding \n  \nThis work was supported by R21 AG066970 to ZZ and BR, R01 MH105561 to YG, and R01 MH129855 to BR. \n\n\n## Conflict of interest \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n\n## Publisher's note \n  \nAll claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. \n\n\n## Author disclaimer \n  \nThe content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. \n\n \n", "metadata": {"pmcid": 9614436, "text_md5": "1e488347dc7c770880f2401d4c9eaa37", "field_positions": {"authors": [0, 73], "journal": [74, 88], "publication_year": [90, 94], "title": [105, 185], "keywords": [199, 389], "abstract": [402, 2159], "body": [2168, 51775]}, "batch": 1, "pmid": 36312020, "doi": "10.3389/fnins.2022.969510", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9614436", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9614436"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9614436\">9614436</a>", "list_title": "PMC9614436  Interpretive JIVE: Connections with CCA and an application to brain connectivity"}
