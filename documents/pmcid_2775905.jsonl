{"text": "Adank, Patti and Devlin, Joseph T.\nNeuroimage, 2010\n\n# Title\n\nOn-line plasticity in spoken sentence comprehension: Adapting to time-compressed speech\n\n# Keywords\n\nLearning\nAuditory systems\nFunctional MRI\nPrefrontal cortex\nTemporal cortex\n\n\n# Abstract\n \nListeners show remarkable flexibility in processing variation in speech signal. One striking example is the ease with which they adapt to novel speech distortions such as listening to someone with a foreign accent. Behavioural studies suggest that significant improvements in comprehension occur rapidly \u2014 often within 10\u201320 sentences. In the present experiment, we investigate the neural changes underlying on-line adaptation to distorted speech using time-compressed speech. Listeners performed a sentence verification task on normal-speed and time-compressed sentences while their neural responses were recorded using fMRI. The results showed that rapid learning of the time-compressed speech occurred during presentation of the first block of 16 sentences and was associated with increased activation in left and right auditory association cortices and in left ventral premotor cortex. These findings suggest that the ability to adapt to a distorted speech signal may, in part, rely on mapping novel acoustic patterns onto existing articulatory motor plans, consistent with the idea that speech perception involves integrating multi-modal information including auditory and motoric cues. \n \n\n# Body\n \n## Introduction \n  \nWhen meeting someone with a heavy foreign or regional accent, listeners may find themselves struggling to understand them at first, but comprehension becomes easier within a few minutes. After interacting even longer, one may not even be aware of the speaker's accent anymore. This situation illustrates a remarkable faculty of the speech comprehension system: the ability to quickly adapt to the acoustic consequences of a wide variation in sources when perceiving speech. Listeners have been found to adapt to foreign-accented speech ( ), noise-vocoded speech ( ), spectrally shifted speech ( ), synthetic speech ( ), and time-compressed speech ( ) to name a few. This ability to adapt to distortions of the speech signal in general, has been studied extensively using time-compressed speech, which is a method for artificially shortening the duration of an audio signal without affecting the fundamental frequency of that signal ( ). Listeners are quickly able to adapt to sentences compressed up to 35% of their original duration, within 10\u201320 sentences ( ). Even though the distortion of the acoustic signal associated with time-compressing speech differs from, for instance, variations caused by speaking with a foreign accent, time-compressed speech has been used to study adaptation processes, as it is easy to create speech samples at a wide variety of compression rates. Furthermore, it allows for using the same speaker in time-compressed and uncompressed conditions, which is often not possible using foreign-accented speech. \n\nBehaviourally, perceptual adaptation to distorted speech has often been described as an attention-weighing process in which listeners shift their attention from task-irrelevant to task-relevant cues ( ). More specifically, it has been argued that learning of time-compressed speech is characterised by the recalibration of the boundaries between speech sounds to accommodate the faster speech rate ( ). In other words, the adaptation is believed to occur primarily at an auditory level using increased attentional resources. \n\nAlthough previous studies have investigated the neural bases associated with comprehending time-compressed speech, none have investigated the adaptation process that occurs when listeners are first confronted with this unusual manipulation of the speech stream. For instance,   reported that processing time-compressed speech strongly recruits bilateral auditory cortices, among other regions. Similarly,   found that activation in left superior temporal sulcus (STS) increased as sentence compression rate increased up to 30% of the original duration. Further compression, however, rendered the speech unintelligible and reduced activation in left STS. In contrast, right STS activation increased linearly, even at the highest levels of compression where speech was no longer intelligible. These results suggest two different processing mechanisms: a left hemisphere linguistic component responding to the content of the sentences and a right hemisphere acoustic component responding primarily to the complexity of the acoustic signal. Neither study, however, investigated the adaptation process \u2014 in fact, Peelle et al. familiarised listeners with the sound of time-compressed speech prior to taking part in the fMRI experiment specifically to avoid this confound. As a result, it is unclear which neural systems are responsible for this rapid perceptual adaptation. \n\nIn the present study, we aimed to address this question by monitoring the on-line adaptation process while participants performed a speeded sentence verification task on time-compressed sentences. The goal of the present study, therefore, was to better understand the neural mechanisms underlying the adaptation process itself, instead of the specific neural activation pattern for processing time-compressed speech, as was the case in previous studies. \n\nIn the field of speech comprehension research, there has been a longstanding debate about which mechanisms are required for speech processing. One theory holds that only auditory processes are required for effective speech perception ( ). A competing theory claims there is an additional role for the motor (i.e. speech production) system and is derived from Liberman's Motor Theory of Speech Perception ( ). In its original form, MTSP claimed: first, that speech tokens such as words, phonemes or phonetic features can only be recognized by mapping acoustic patterns onto articulatory (motor) plans and second, that speech processing involves a tight coupling between auditory and motor processes. The former claim is clearly incorrect ( ). Recent studies, however, have found support for a tight coupling between perception and production systems ( ) by showing the involvement of the speech motor system in speech perception tasks ( ).   provided perhaps the clearest evidence by using transcranial magnetic stimulation to show that stimulation of left ventral premotor cortex (PMv) disrupted speech perception when syllables were embedded in noise without affecting a similar control task of detecting tones in noise. In short, there is renewed interest in the involvement of the motor (i.e. articulatory) system in speech perception, although not in the form of Liberman's original Motor Theory. \n\nCrucially, the two accounts make different predictions about the neural mechanisms involved in the adaptation process. The former predicts that it is done purely acoustically by recognizing distorted signals as instances of abstract auditory prototypes such as phonemes or phonological word forms. Consequently, adaptation-related activation changes would be expected solely in auditory regions associated with speech perception ( ). The latter, however, predicts that the distorted acoustic signal is recognized at least in part by mapping it onto articulatory motor plans \u2014 a form of sensorimotor integration that implicitly simulates the motor patterns used to produce a comparable spoken sentence. In this case, adaptation-related activation would be expected in both auditory regions as well as in ventral premotor regions associated with speech production ( ). \n\n\n## Materials and methods \n  \n### Participants \n  \nTwenty-two participants (13M, 9F) took part in the study although four (2M, 2F) were subsequently excluded due to: i) excessive head motion (>\u00a010\u00a0mm), ii) an unexpected brain abnormality, iii) chance level performance in the scanner, and iv) an error acquiring the scanning data. The 18 remaining participants were right-handed, native speakers of British English (mean 26.7\u00a0years, median 22.5\u00a0years, range 18\u201360\u00a0years) without any history of neurological or psychiatric disease. The behavioural and neuroimaging data from the older participant (the one 60\u00a0year-old) did not differ qualitatively from the younger participants and therefore was included in all analyses. None had any form of oral or written language impairment or any previous experience with time-compressed speech. None of the participants reported any hearing difficulties, but were not audiometrically screened. In-scanner preliminary testing revealed that all participants could hear the stimuli clearly enough to perform the task (see  , below). All gave written informed consent and were paid for their participation. The study was approved by the NHS Berkshire Research Ethics Committee. \n\n\n### Task \n  \nThe task was a computerized version of the Speech and Capacity of Language Processing Test, or SCOLP ( ). Participants listened to a simple sentence and decided whether it was true or false, indicating their response with a button press. In all cases, the validity of the sentence was obvious (e.g., \u201cBedroom slippers are made in factories\u201d vs. \u201cNuns are made in factories\u201d) with invalid sentences generated by changing participants and predicates from true sentences (see  ) for additional task details). Accuracy and response times were recorded per trial and adaptation to time-compressed speech was operationalized as the increase in the speed of sentence verification times. \n\n\n### Stimuli \n  \nThe auditory stimuli were recordings of 200 SCOLP sentences, 100 true and 100 false, by a male Southern Standard British English speaker. The recordings were made in an anechoic room directly onto digital auditory tape (DAT), while the digital output from the DAT recorder was fed to the digital input of the sound card in the PC. Next, all sentences were saved into separate files with the beginning and ends trimmed at zero crossings as closely as possible to the onset/offset of the initial/final speech sounds and re-sampled at 22050\u00a0Hz. The time-compressed sentences were obtained using PSOLA ( ), as implemented in the Praat software package ( ). Two versions of each recorded sentence were created: sentences resynthesized at 100% of their original duration (normal-speed sentences) and resynthesized sentences shortened to 45% of their original duration (time-compressed sentences). The normal sentences were resynthesized to ensure that any differences between the two types of sentences were due solely to the time compression and not the resynthesis process. The sentences consisted of 6.5 syllables on average (range 3\u201312 syllables, range 477\u20131221\u00a0ms) and the average speech rate of the normal-speed sentences was 4.1 syllables per second, and the average speech rate of the time-compressed sentences was 9.2 syllables per second. Finally, each sentence was peak-normalized at 99% of its maximum amplitude and scaled to 70\u00a0dB SPL using Praat. Stimulus presentation and response time measurement were performed using Presentation (Neurobehavioral Systems, Albany, CA). \n\n\n### Design and procedure \n  \nThe main experiment used an atypical block design in which all the normal-speed sentences (  n  \u00a0=\u00a064) occurred in the first half of the experiment and all the time-compressed sentences (  n  \u00a0=\u00a064) in the second half. This was necessary because pilot testing in the scanner demonstrated that alternating blocks of normal-speed and time-compressed sentences during scanning prevented behavioural adaptation \u2014 in fact, participants found both types of speech much more difficult. Consequently, the design shown in   was used to allow listeners to get used to the task and to the scanner noise during the presentation of the 64 normal-speed sentences and to allow them to efficiently tune into the time-compressed sentences in the second block. Such a design is similar to pharmacological fMRI studies where the time course of the pharmacological agent often makes it impossible to alternate between drug and non-drug conditions. Like those studies, we specifically looked for interactions between our experimental conditions and time to exclude non-specific effects of time such as scanner drift and physiological noise aliasing ( ). \n\nA single trial began with a tone signal of 100\u00a0ms, followed by a pause of 100\u00a0ms, and then the auditory sentence ( ). The inter-trial interval varied randomly between 4000\u20136000\u00a0ms providing a jittered sampling of the evoked haemodynamic response function ( ). Although the stimuli were presented and analysed in an event-related design, trials occurred in short mini-blocks of four sentences followed by a silent baseline trial (duration randomly varied from 4000\u20136000\u00a0ms) to maximize statistical power. The entire duration of the run was 17\u00a0min. \n\nAfterwards, a second (behavioural) test was run outside the scanner to determine whether adaptation was stable after the scanning session or whether it continued in the quieter environment. Participants were tested individually in a quiet room using headphones (Philips SBC HN110) immediately following the fMRI experiment. 64 new time-compressed sentences were presented. Presentation of all three sets of 64 sentences (normal-speed, time-compressed, and the time-compressed sentences in the post-task) was counter-balanced across subjects. Each set consisted of 32 true and 32 false sentences. The sentences were presented in a semi-randomised order per participant and true and false sentences were counter-balanced across experimental blocks. \n\n\n### fMRI data acquisition \n  \nScanning was performed at the Birkbeck-UCL Neuroimaging (BUCNI) Centre on a 1.5\u00a0T MR scanner (Siemens Avanto, Siemens Medical Systems, Erlangen, Germany). The experiment began by acquiring a high-resolution structural scan (3D Turbo-FLASH, TR\u00a0=\u00a012\u00a0s, TE\u00a0=\u00a05.6\u00a0ms, 1\u00a0\u00d7\u00a01\u00a0\u00d7\u00a01\u00a0mm resolution) used for anatomical localisation. Next, participants were familiarised with the task during a brief practice run using six normal-speed sentences not included in the rest of the experiment. They were instructed to respond through a button press with their right index finger when the sentence was true and with their right middle finger when the sentence was false. The sentences were presented over electro-static headphones (MRConFon, Magdeburg, Germany) during continuous scanner acquisition (GE-EPI, TR\u00a0=\u00a03\u00a0s, TE\u00a0=\u00a050\u00a0ms, 192\u00a0\u00d7\u00a0192 FOV, 64\u00a0\u00d7\u00a064 matrix, 35 axial slices, yielding a notional 3\u00a0\u00d7\u00a03\u00a0\u00d7\u00a03\u00a0mm resolution) \u2014 in other words, over the noise of the scanner. The main experiment lasted just under 17\u00a0min and on average, 332\u00a0volumes (range: 330\u2013336) were collected per participant. The presentation of the four blocks of normal sentences lasted on average 172\u00a0volumes (43 per block) for the normal-speed sentences, and 151\u00a0volumes (38 per block) for the time-compressed sentences. In other words, slightly less data were collected for the time-compressed sentence conditions because, by definition, the duration of the sentences was shorter. In theory, this may slightly reduce BOLD signal sensitivity for time-compressed relative to normal-speed sentences, but this was unavoidable given the nature of the experiment. \n\nThe choice of continuous, rather than sparse, sampling was based on a trade-off between the ability to reliably detect adaptation-related changes in blood oxygen level dependent (BOLD) signal and the length of the experiment. Continuous sampling results in both acoustic masking of the auditory sentences ( ) and contamination of the BOLD signal response in auditory regions ( ). The former, however, was not a problem as a relatively quiet acquisition sequence (\u223c\u00a080\u00a0dB SPL) coupled with sound attenuating headphones (\u223c\u00a030\u00a0dB attenuation) ensured that the sentences were easily heard. Indeed, all participants confirmed their ability to hear and understand the sentences during this practice session. Contamination of the BOLD signal was potentially more problematic because scanner noise elevates BOLD responses in auditory areas ( ), and these effects need not be identical across regions ( ). In the current experiment, however, we were specifically interested in reductions in BOLD signal that index adaptation-related changes. As a result, elevated BOLD responses   per se   were not problematic; only responses driven to saturation levels by the scanner noise would reduce sensitivity and previous studies have clearly shown that typical EPI sequences reduce, but do not eliminate, the dynamic range of the BOLD response ( ). Moreover, although some \u201csilent\u201d imaging protocols exist ( ) they are not yet widely available. fMRI systems without these protocols (such as our own) require silent periods between volume acquisitions lasting between 16 and 32\u00a0s to avoid scanner-noise contamination and ensure an adequate sampling of the evoked haemodynamic response function (HRF) ( ). A sparse design would therefore result in our experiment lasting between 54 and 90\u00a0min, which was deemed likely to seriously reduce participant's performance due to fatigue. As a result, we chose to use a continuous sampling paradigm instead. One consequence of this choice was that the adaptation task was performed over the background noise of the scanner, and it became an empirical question whether embedding its noise would alter the typical behavioural profile of rapid adaptation. \n\n\n### Analyses \n  \nResponse times (RT) were measured from the end of each audio file, following  , and RTs beyond 3000\u00a0ms were trimmed without replacement (0.4%). Each set of sentences was divided into four blocks of 16 so that the time course of adaptation could be examined. A 16 sentence block-size was used because pilot testing revealed that learning was typically stable after 14\u201318 sentences and smaller windows reduce the accuracy of estimating induced BOLD signal responses ( ). The mean RT of correct responses was used in the group analyses. Both accuracy and RTs were evaluated with a repeated-measures 2\u00a0\u00d7\u00a04 ANOVA with Speech Type (normal-speed, time-compressed) and Block (1\u20134) as independent factors. Obviously, adaptation to the time-compressed sentences was only possible in the second half of the experiment. Consequently, our   a priori   hypothesis was that we would observe adaptation effects only for time-compressed and not normal-speed sentences. \n\nThe functional imaging data were analysed using FSL ( ). After deleting the first three volumes of each run to allow for T1 equilibrium, the functional images were realigned to correct for small head movements ( ). The images were then smoothed with a 6\u00a0mm FWHM Gaussian filter and pre-whitened to remove temporal auto-correlation ( ). The resulting images were entered into a subject-specific general linear model with eight conditions of interest: four blocks of normal-speed and four blocks of time-compressed sentences. Each sentence was convolved with a double gamma \u201ccanonical HRF\u201d ( ) to generate the regressors. The onset of this HRF function was aligned with the onset of every sound file and the duration of every sentence was included in the model. Temporal derivatives were also included to better fit small deviations in the expect time course. Both the data and the model were high-pass filtered at 1/200\u00a0s to remove low frequency signal drifts such as aliased cardiac or respiratory signals without affecting the more rapid, experimentally-induced frequencies such as those between mini-blocks and blocks of stimuli. Finally, each anatomical T1 scan was registered to the MNI-152 template using an affine transformation ( ), which was then applied to the first-level parameter and variance estimates. These were fed into a second-level mixed-effects analysis for inferring across the population ( ). \n\nLinear weighted contrasts were used to identify three effects of interest. First, the main effect of processing auditory sentences relative to scanner noise (when no sentence was presented) was computed to identify task-relevant brain regions using a contrast of [+\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01] where the first four conditions are the four blocks of normal-speed sentences and the last four of the blocks of time-compressed sentences. Significant activations were assessed with a cluster-based correction for multiple comparisons using a height threshold of   Z  \u00a0>\u00a03.5 and a corrected   p  \u00a0<\u00a00.05 cluster-extent ( ). This corresponded to a minimum of 123 contiguous 2\u00a0\u00d7\u00a02\u00a0\u00d7\u00a02\u00a0mm voxels with   Z  -scores of 3.5 or greater. Next, we identified the regions within this system that were significantly more active for time-compressed relative to normal speech using the same statistical criteria and a contrast of [\u2212\u00a01/4 \u2212\u00a01/4 \u2212\u00a01/4 \u2212\u00a01/4 +\u00a01/4 +\u00a01/4 +\u00a01/4 +\u00a01/4]. Finally, the critical analysis aimed to identify areas within this system involved in adapting to time-compressed speech. To do this, we used a contrast that followed the behavioural profile of adaptation, namely greater activation for the first block of time-compressed sentences than the remaining three blocks [0\u00a00\u00a00\u00a00 +\u00a01 \u2212\u00a0 /  \u2212\u00a0 /  \u2212\u00a0 / ]. It is worth noting, however, that this contrast may be confounded with linear time effects such as scanner drift or physiological noise that are not completely removed by high-pass filtering. Consequently, the contrast was inclusively masked (at   Z  \u00a0>\u00a03.5) by two other contrasts to ensure the effects were due to adaptation rather than scanner drift. The first was the main effect of sentence processing, to limit the results to areas specifically involved in the task [+\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01 +\u00a01], while the second was the contrast between the first block of time-compressed sentences and the last block of normal-speed sentences [0 0 0 \u2212\u00a01 +\u00a01 0 0 0]. Here we assumed that time-compressed sentences would significantly increase processing demands relative to normal sentences, consistent with the reaction time cost of switching to time-compressed sentences (see below). Importantly, this difference goes in the opposite direction to the time confound in the main contrast and helps to exclude activation unrelated to adapting to time-compressed speech. Significance was assessed using a small volume correction ( ) based on the smoothness and volume of the intersection of the inclusive masks. Within this reduced volume, a voxel-wise height threshold of   Z  \u00a0>\u00a03.0 corresponded to   p  \u00a0<\u00a00.05, one tailed. To illustrate the regional activation profiles, the mean parameter estimates per condition per participant were extracted from the activation cluster. Note that post-hoc t-tests are Bonferroni corrected to adjust for multiple comparisons except where correcting was less conservative (as stated in the text) and significance was assessed at   p  \u00a0<\u00a00.05. \n\n\n\n## Results \n  \n### Behaviour \n  \n shows the results for the error rates and the response times recorded inside and outside the scanner. In order to illustrate the time course of adaptation, data are shown averaged over each mini-block of four trials by a filled-in circle and error bars indicating the standard error of the mean. Data from four consecutive mini-blocks was then averaged and displayed as a bar plot. These bars corresponded to the blocks of 16 sentences used in the analyses. The data from the mini-blocks were included to provide a more fine-grained temporal resolution of the adaptation process than provided by the larger blocks of 16 sentences and are shown for illustration purposes only; all statistical analyses were performed on the averages across the larger blocks of 16 sentences only. What should be clear from the figure is that despite the noisy environment of the scanner, participants were able to perform the task well. Error rates for normal-speed sentences were only 3% while time-compressed sentences were more difficult, with an average error rate of 16%. This main effect of Speech Type was significant (  F  (1,17)\u00a0=\u00a0196.8,   p  \u00a0<\u00a00.0001, partial   \u03b7  \u00a0=\u00a00.92), but the main effect of Block (  F  (3,51)\u00a0=\u00a01.7,   p  \u00a0=\u00a00.172, partial   \u03b7  \u00a0=\u00a00.09) and the interaction (  F  (3,51)\u00a0=\u00a01.1,   p  \u00a0=\u00a00.378, partial   \u03b7  \u00a0=\u00a00.06) were not. In order to determine whether there were any adaptation effects that may have been hidden by the omnibus ANOVA, the normal-speed and time-compressed sentences were re-analysed separately. Normal-speed sentences showed an effect of Block (  F  (3,51)\u00a0=\u00a05.6,   p  \u00a0=\u00a00.03, partial   \u03b7  \u00a0=\u00a00.25), indicating that participants got better at the task over time. Interestingly, there was no equivalent effect for time-compressed sentences (  F  (3,51)\u00a0=\u00a01.1,   p  \u00a0=\u00a00.306, partial   \u03b7  \u00a0=\u00a00.06), suggesting that by the time these sentences began, the participants were essentially acclimated to the task and environment. This is consistent with the fact that errors in the post-scan behavioural test did not significantly differ across blocks (  F  (3,51)\u00a0=\u00a02.1,   p  \u00a0=\u00a00.115, partial   \u03b7  \u00a0=\u00a00.11). In other words, the error rates suggest that participants successfully acclimated to the task within the noisy environment of the scanner before the time-compressed sentences were introduced. \n\nThe analysis of RTs revealed a main effect of Speech Type (  F  (1,17)\u00a0=\u00a080.8,   p  \u00a0<\u00a00.0001, partial   \u03b7  \u00a0=\u00a00.83), indicating that responses to time-compressed sentences were significantly slower than normal-speed sentences (790 vs. 386\u00a0ms). There was also a main effect of Block (  F  (3,51)\u00a0=\u00a05.0,   p  \u00a0=\u00a00.004, partial   \u03b7  \u00a0=\u00a00.23) that was largely driven by the slowed responses to the first block of time-compressed sentences. When the two types of speech types were analysed separately, normal-speed sentences showed no effect of Block (  F  (3,51)\u00a0=\u00a01.58,   p  \u00a0=\u00a00.226, partial   \u03b7  \u00a0=\u00a00.09), indicating that listeners did not vary significantly in their response times across the four blocks. On the other hand, the analysis of the time-compressed sentences did reveal a significant effect of Block (  F  (3,17)\u00a0=\u00a05.0,   p  \u00a0=\u00a00.004, partial   \u03b7  \u00a0=\u00a00.23). A series of planned   t  -tests showed that responses to the first block of time-compressed sentences were significantly longer than those to subsequent blocks (all paired   t  -tests,   p  \u00a0<\u00a00.05). In other words, within the first 16 trials, participants had adapted to the atypical speech signal as evidenced by the fact that RTs in the subsequent blocks were on average 150\u00a0ms faster than the first block of time-compressed sentences. This was further confirmed when the RTs in the post-scan behavioural test did not show a significant effect of Block (  F  (3,17)\u00a0=\u00a02.34,   p  \u00a0=\u00a00.085, partial   \u03b7  \u00a0=\u00a00.13), confirming that adaptation asymptoted during the 64 trials that occurred within the scanner. \n\n\n### Neuroimaging \n  \nTo begin, we compared blood oxygen level dependent (BOLD) signal across the eight auditory sentence task conditions to fixation in order to identify the system of regions involved in the task. Like previous studies ( ), we found robust activation in primary auditory and auditory association cortices bilaterally, as well as in the deep frontal operculum bilaterally, left prefrontal and premotor cortices, and pre-SMA extending ventrally into the cingulate sulcus (see   for the complete list). The activation in the operculum bilaterally corresponds with earlier findings reported on processing degraded/noisy speech input ( ). \n\nNext, we identified the regions within this system that were more active for time-compressed relative to normal speech ( A and  ). This revealed separate posterior and anterior temporal lobe foci bilaterally. One was located in the superior temporal sulcus (STS) posterior to Heschl's gyrus while the other was located in the lateral portion of Heschl's gyrus as it joins the anterior superior temporal gyrus (STG). In other words, time-compressed sentences produced greater levels of activation in STS and STG compared to normal-speed sentences, consistent with previous reports that activation in these regions increased with the level of speech compression ( ). In addition, we observed activation in pre-SMA (0, +\u00a012, +\u00a060,   Z  \u00a0=\u00a04.0). \n\nOf primary interest, however, were the neural changes associated with adapting to time-compressed speech ( B). Four regions showed adaptation-related activation profiles, illustrated in  . In the left hemisphere, one cluster was located within a region of the ventral bank of posterior STS. Within this area, there was a significant main effect of Stimulus Type (  F  (1,17)\u00a0=\u00a015.5,   p  \u00a0=\u00a00.001, partial   \u03b7  \u00a0=\u00a00.48) indicating greater activation for compressed relative to normal speech, a main effect of Block (  F  (3,51)\u00a0=\u00a05.0,   p  \u00a0=\u00a00.004, partial   \u03b7  \u00a0=\u00a00.23) and a significant interaction (  F  (3,51)\u00a0=\u00a04.3,   p  \u00a0=\u00a00.008, partial   \u03b7  \u00a0=\u00a00.20). When the two types of speech were analysed separately, normal-speed sentences showed no effect of Block (  F  (3,51)\u00a0=\u00a00.68,   p  \u00a0=\u00a00.568, partial   \u03b7  \u00a0=\u00a00.04), indicating that activation was greater than baseline and stable over all four blocks, mirroring the response time findings. The time-compressed sentences, however, did show an effect of Block (  F  (3,51)\u00a0=\u00a05.1,   p  \u00a0=\u00a00.004, partial   \u03b7  \u00a0=\u00a00.23) which was driven by a significant increase in the magnitude of the activation during the first block of time-compressed sentences (  t  (17)\u00a0=\u00a04.6,   p  \u00a0<\u00a00.001). Activation levels in the first block of time-compressed sentences more than tripled, signifying a considerable increase in processing demands. By the third block of time-compressed sentences, however, activation had returned to normal sentence processing levels (  t  (17)\u00a0=\u00a01.0,   p  \u00a0=\u00a00.319 uncorrected). A second left hemisphere cluster located on the crest of the pre-central gyrus, a region of ventral premotor cortex (PMv), showed essentially the same pattern. Again there were significant main effects of Stimulus Type (  F  (1,17)\u00a0=\u00a07.4,   p  \u00a0=\u00a00.014, partial   \u03b7  \u00a0=\u00a00.31) and Block (  F  (3,51)\u00a0=\u00a03.9,   p  \u00a0=\u00a00.014, partial   \u03b7  \u00a0=\u00a00.19), as well as a significant interaction (  F  (3,51)\u00a0=\u00a03.7,   p  \u00a0=\u00a00.016, partial   \u03b7  \u00a0=\u00a00.18). Normal sentences showed no effect of Block (  F  (3,51)\u00a0=\u00a00.38,   p  \u00a0=\u00a00.762, partial   \u03b7  \u00a0=\u00a00.02), whereas time-compressed sentences did (  F  (3,51)\u00a0=\u00a04.5,   p  \u00a0=\u00a00.007, partial   \u03b7  \u00a0=\u00a00.21). As in the pSTS region, activation levels increased significantly for the first block of time-compressed sentences (  t  (17)\u00a0=\u00a04.0,   p  \u00a0=\u00a00.004) and then returned to normal levels by the third block (  t  (17)\u00a0=\u00a00.4,   p  \u00a0=\u00a00.679 uncorrected). In short, the activation profile in both left pSTS and left PMv closely matched the response time data. \n\nAdaptation-related changes in the two right hemisphere clusters, on the other hand, showed a slightly different pattern. The first region was located on the anterior crest of STG and extended into the dorsal bank of STS while the other was located more posterior in the ventral bank of STS. In both regions, activation was significantly greater than baseline for normal sentences but was not stable over the four blocks of normal sentences \u2014 instead it monotonically decreased. This was confirmed by a significant main effect of Block (both   F  (3,51)\u00a0\u2265\u00a035.0,   p  \u00a0<\u00a00.0001, partial   \u03b7  \u00a0\u2265\u00a00.67) which was also present when normal sentences were analysed separately (  F  (3,51)\u00a0\u2265\u00a02.8,   p  \u00a0\u2264\u00a00.050, partial   \u03b7  \u00a0\u2265\u00a00.14). In both regions, the first block of time-compressed sentences significantly increased activation levels (anterior:   t  (17)\u00a0=\u00a07.0,   p  \u00a0<\u00a00.001; posterior:   t  (17)\u00a0=\u00a05.7,   p  \u00a0<\u00a00.001), but only in the more posterior cluster did these return to normal levels (for blocks 3 and 4:   t  (17)\u00a0=\u00a01.8, 1.0,   p  \u00a0=\u00a00.092 and 0.352 uncorrected). In the more anterior region, activation remained significantly greater for all blocks of time-compressed relative to normal sentences (for blocks 2\u20134:   t  (17)\u00a0=\u00a04.6, 3.5, 3.8, all   p  \u00a0\u2264\u00a00.012 corrected). In sum, the activation in the left and right-lateralised regions increased strongly for the time-compressed sentences before showing a sharp decline after the first blocks of time-compressed speech. However, the left and right regions differed in their activation pattern for the normal sentences with activation in the left-lateralised regions remaining constant, while activation in the right-lateralised regions declined. This was confirmed by a significant Hemisphere\u00a0\u00d7\u00a0Block interaction (  F  (3,54)\u00a0=\u00a02.9,   p  \u00a0=\u00a00.045) for normal-speed sentences that used mean BOLD signal from the two left and two right hemisphere areas showing adaptation effects. It is worth noting that the theoretical question of reduced statistical sensitivity for time-compressed sentences appears not to be a major concern in practice, given the large effect sizes and small error variances seen in  . In other words, the sensitivity was sufficient to detect significant BOLD signal effects for both time-compressed sentences as well as the effects of adaptation. \n\nA final set of analyses investigated whether any of the results were related to the presence of semantic violations (by virtue of including true and false sentences together). This analysis modelled true and false sentences separately to avoid the potential confound associated with semantic violations. Although the effect sizes were smaller due to the lower number of cases, the results showed a pattern identical to the analysis with the true and false sentences combined. In other words, the activations associated with adapting to time-compressed speech cannot be attributed to semantic violations present in the false sentences. \n\n\n\n## Discussion \n  \nThe current results confirm and extend previous behavioural studies that demonstrate rapid on-line adaptation to atypical speech signals. After hearing just 16 sentences, participants' comprehension was both accurate and much faster than their initial responses to time-compressed speech, despite the concurrent, on-going noise of the MRI scanner. Moreover, the final behavioural test outside of the scanner demonstrated that the adaptation process completed within the first 64 trials as no additional learning took place after scanning. Instead, there was a trend towards slightly faster RTs which did not reach significance but may point to a re-tuning process that occurs after adaptation had been completed ( ), perhaps due to different acoustic environments (i.e. with or without scanner noise). \n\nAdaptation-related changes in neural activation were observed in four separate areas: two in the right hemisphere and two in the left. In the right, the regions were both auditory association areas located in anterior and posterior portions of the STS, respectively. Both showed significant adaptation to normal sentences, with activation decreasing over the first four blocks. When time-compressed sentences were introduced, activation increased dramatically at first and then decreased after the first block, although it did not return to normal levels. This pattern of responses suggests that adaptation may have occurred at an acoustic, rather than linguistic, level for three reasons. First, the initial BOLD signal adaptation coupled with increasing accuracy rates for normal sentences appears to reflect a gradual acclimation to hearing sentences in a noisy environment. This may reflect adaptation occurring at an acoustic, rather than linguistic, level due to the energetic masking of the scanner noise ( ). Second, the fact that the BOLD response did not return to levels associated with normal-speed sentences suggests that activation in these areas may be driven primarily by the condensed acoustic signal rather than by its content. This interpretation is consistent with the findings of  , who demonstrated a linear increase in activation within right STS with increasing time compression, even when the compression level rendered the auditory sentence unintelligible. Finally, a recent study reported stronger interactions between scanner noise and acoustic processing in right hemisphere auditory areas ( ), suggesting greater sensitivity to acoustic over linguistic processing in right auditory cortex. \n\nIn contrast, adaptation-related changes in the left hemisphere may be more directly related to comprehending speech. In both pSTS and PMv, activation was stable over the first four blocks of normal sentences before increasing by 2\u20133 fold for the first block of time-compressed sentences. Activation then decreased to the levels seen for normal sentences. This pattern more closely matched the behaviour and subjective experience of the participants who reported no difficulty with the normal-speed sentences and no difficulty for the time-compressed sentences \u201conce they got used to them.\u201d Again, this result is consistent with those from   who reported a convex response profile for activation in left STS. As time compression increased from 60% to 30% of the original sentence duration, BOLD signal increased. At 15% of a sentence's original duration it was no longer comprehensible and left STS activation reduced to baseline levels. Together with the current results, both studies suggest that adaptation in the left hemisphere regions appears to be at a linguistic level. Moreover, both studies highlight an apparent difference between right and left STS in responding to time-compressed speech: right STS appears to be driven more by the complexity of the acoustic signal while left STS responds more strongly to its linguistic content. This difference is consistent with the theoretical framework of   in which two distinct anatomical streams are involved in processing speech signals. A ventral stream runs along the STS and is primarily concerned with the content of the speech signal while the dorsal stream links posterior auditory cortex to anterior motor regions involved in articulation. Critically, the latter is strongly left lateralised, includes both pSTS and PMv, and provides an anatomical substrate for mapping acoustic speech signals onto frontal lobe articulatory networks. With respect to sensorimotor interactions, it is proposed that sensorimotor integration is subserved by the dorsal stream. \n\nThe anatomy of regions involved in adaptation to time-compressed sentences helps to shed light on the nature of the adaptation mechanism. Specifically, pSTS is a region of auditory association cortex involved in speech perception ( ), as well as perceiving other complex, non-linguistic sounds ( ). In contrast, the pre-central gyrus is part of the premotor cortex, which is involved in the selection and execution of complex motor sequences ( ). PMv, in particular, is closely linked with articulatory motor patterns due to its strong, reciprocal connectivity to the ventral areas of primary motor cortex, which enervate the face, larynx, and tongue ( ). Speech production tasks robustly activate this region ( ). The fact that both sensory and motor areas demonstrate adaptation-related activation profiles, suggests that adapting to atypical speech involves changing sensitivity not only to auditory, but also to motoric cues. One possibility is that the novel acoustic patterns of compressed speech are mapped onto articulatory motor plans as an implicit form of motor simulation. This may aid in recognizing the speech tokens, particularly in challenging listening situations. Indeed, situations such as when the speech signal is either impoverished ( ), masked ( ) or ambiguous ( ) may preferentially recruit speech production regions to aid speech comprehension. \n\nAdapting to time-compressed speech has often been classified as an attention-weighing process in which listeners learn to shift their attention from task-irrelevant to task-relevant auditory cues ( ). Our results indicate that this specific form of perceptual learning may be supported by sensorimotor integration between auditory and speech production areas. For instance, the process of adjusting to distorted acoustic cues may place greater demands on verbal working memory, which engages this left sensorimotor circuit ( ). This account is certainly consistent with the current findings showing increased PMv activation to the initial time-compressed sentences and raises the possibility that adapting to the compressed speech signal depends at least in partly on implicit articulatory simulation to recognize speech tokens in the atypical auditory input. \n\nFinally, it is worth noting that the current findings are consistent with some, but not all, aspects of Liberman's MTSP ( ). Like previous studies, our data demonstrate a clear role of auditory cortex in speech comprehension. According to the original MTSP, this auditory component would be a highly specialised speech-specific module separate from the rest of the auditory system and dedicated to conveying speech to the motor system where it would be identified as a series of articulatory gestures ( ). In contrast, our data identifies a particular region of posterior STS that has also been shown to be involved in processing complex non-speech sounds (e.g.,  ) and thus runs counter to a core theoretical claim of MTSP. Our finding of significant activation in PMv when adapting to time-compressed speech, on the other hand, tends to support the notion that speech production regions may be preferentially recruited to aid speech comprehension in challenging listening situations such as a distorted, degraded or masked speech signal ( ). For example,   showed that transcranial magnetic stimulation (TMS) to left PMv disrupted speech perception when syllables were embedded in noise without affecting a similar control task of detecting tones in noise. Additional studies are, however, required to establish whether these regions are   essential   for the adaptation process. \n\nIn summary, although ideal listening conditions facilitate speech perception, they rarely occur in real life. Normal environments are noisy with poor acoustics that degrade an incoming speech signal. As a result, the human speech recognition system seems to have evolved an opportunistic decoding approach that takes advantage of whatever information is available to assist in comprehension. Primarily this relies on auditory information, but other systems including vision ( ), somatosensation ( ) and the motor system (D' ) may provide important additional cues as well. \n\n \n", "metadata": {"pmcid": 2775905, "text_md5": "224c3ebd5bf34825d5455b0c519958fd", "field_positions": {"authors": [0, 34], "journal": [35, 45], "publication_year": [47, 51], "title": [62, 149], "keywords": [163, 238], "abstract": [251, 1447], "body": [1456, 42429]}, "part": 1, "chapter": 5, "page": 1, "pmid": 19632341, "doi": "10.1016/j.neuroimage.2009.07.032"}, "display_title": "pmcid: <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2775905>2775905</a> \u2014 Part 1 Chapter 5 Page 1", "list_title": "1.5.1  On-line plasticity in spoken sentence comprehension: Adapting to time-compressed speech"}
