{"text": "Song, Hayoung and Shim, Won Mok and Rosenberg, Monica D\neLife, 2023\n\n# Title\n\nLarge-scale neural dynamics in a shared low-dimensional state space reflect cognitive and attentional dynamics\n\n# Keywords\n\nbrain states\ndynamical systems\nfunctional networks\nevent boundaries\nattention\nHuman\n\n\n# Abstract\n \nCognition and attention arise from the adaptive coordination of neural systems in response to external and internal demands. The low-dimensional latent subspace that underlies large-scale neural dynamics and the relationships of these dynamics to cognitive and attentional states, however, are unknown. We conducted functional magnetic resonance imaging as human participants performed attention tasks, watched comedy sitcom episodes and an educational documentary, and rested. Whole-brain dynamics traversed a common set of latent states that spanned canonical gradients of functional brain organization, with global desynchronization among functional networks modulating state transitions. Neural state dynamics were synchronized across people during engaging movie watching and aligned to narrative event structures. Neural state dynamics reflected attention fluctuations such that different states indicated engaged attention in task and naturalistic contexts, whereas a common state indicated attention lapses in both contexts. Together, these results demonstrate that traversals along large-scale gradients of human brain organization reflect cognitive and attentional dynamics. \n \n\n# Body\n \n## Introduction \n  \nA central goal in cognitive neuroscience is understanding how cognition arises from the dynamic interplay of neural systems. To understand how interactions occur at the level of large-scale functional systems, studies have characterized neural dynamics as a trajectory in a latent state space where each dimension corresponds to the activity of a functional network ( ;  ;  ;  ). This dynamical systems approach revealed two major insights. First, neural dynamics operate on a low-dimensional manifold. That is, neural dynamics can be captured by a small number of independent latent components due to covariation of neural activity within a system ( ;  ). Second, neural activity does not just continuously flow along a manifold, but rather systematically transitions between recurring latent \u2018states,\u2019 or hidden clusters, within the state space ( ;  ;  ;  ). Initial work used resting-state neuroimaging ( ;  ;  ;  ;  ;  ;  ) and data simulations ( ;  ;  ) to describe dynamic interactions among brain regions in terms of systematic transitions between brain states. \n\nLess is known about how our mental states\u2014which constantly ebb and flow over time\u2014arise from these brain state transitions. Recent work in human neuroimaging suggests that brain state changes reflect cognitive and attentional state changes in specific contexts ( ;  ). For example, work has identified neural states during a sustained attention task ( ) or a working memory task ( ;  ). Dataset-specific latent states occurred during different task blocks as well as moments of successful and unsuccessful behavioral performance. Another line of work identified latent states during naturalistic movie watching and demonstrated how neural dynamics relate to contents of the movies ( ) or participants\u2019 ongoing comprehension states ( ). An open question is whether the   same   latent states underlie cognitive states across all contexts. For example, does the same brain state underlie successful attention task performance and engaged movie watching? If brain activity traverses a common set of latent states in different contexts, to what extent do the functional roles of these states also generalize? \n\n demonstrated that neural activity traverse a common low-dimensional manifold across seven cognitive tasks. The dynamics within this common manifold were aligned to exogenous task blocks and related to individual differences in cognitive traits. Here we expand on this work by probing a common set of latent states that explain neural dynamics during task, rest, and naturalistic contexts in five independent datasets. We also identify the nature of this shared latent manifold by relating it to the canonical gradients of functional brain connectome ( ). Finally, we relate neural state dynamics to   ongoing   changes in cognitive and attentional states to probe how neural dynamics are adaptively modulated from stimulus-driven and internal state changes. \n\nWe collected human fMRI data, the   SitcOm, Nature documentary, Gradual-onset continuous performance task (SONG) neuroimaging dataset  , as 27 participants rested, performed attention tasks, and watched movies. We characterized latent state dynamics that underlie large-scale brain activity in these contexts and related them to changes in cognition and attention measured with dense behavioral sampling. Each participant performed seven fMRI runs over 2 d: two eye-fixated resting-state runs, two gradual-onset continuous performance task (gradCPT) runs with either face or scene images, two runs of comedy sitcom watching, and a single run of educational documentary watching. The gradCPT measures fluctuations of sustained attention over time ( ;  ) as participants respond to images (every 1 s) from a frequent category (90% of trials) and inhibit response to images from an infrequent category (10%). The sitcom episodes were the first and second episodes of a South Korean comedy sitcom,   High Kick Through the Roof  . The educational documentary described the geography and history of Korean rivers. \n\n\n## Functional brain activity transitions between states in a common latent manifold \n  \n### Large-scale neural activity transitions between discrete latent states \n  \nTo infer latent state dynamics, we fit a hidden Markov model (HMM) to probabilistically infer a sequence of discrete latent states from observed fMRI activity ( ). The observed variables here were the BOLD signal time series from 25 parcels in a whole-brain parcellation of the cortex (17 functional networks) ( ) and subcortex (8 regions) ( ) sampled at a 1 s TR resolution ( , left). Parcel time courses were   z  -normalized within each participant and concatenated across all fMRI runs from all participants. The model inferred two parameters from these time series: the emission probability and the transition probability (see \u2018Materials and methods  \u2019  ). We assumed that the emission probability of the observed variables follows a mixture Gaussian characterized by the mean and covariance of the 25 parcels in each latent state ( , right). The inferred parameters of the model were used to decode latent state sequences. Four was chosen as the number of latent states (  = 4) based on the optimal model fit to the data when tested with leave-one-subject-out cross-validation (chosen among   of 2\u201310;  ). \n   Latent state space of the large-scale neural dynamics.  \n(  A  ) Schematic illustration of the hidden Markov model (HMM) inference. (Left) The HMM infers a discrete latent state sequence from the observed 25-parcel fMRI time series. (Right) The fMRI time course can be visualized as a trajectory within a 25-dimensional space, where black dots indicate activity at each moment in time. The HMM probabilistically infers discrete latent clusters within the space, such that each state can be characterized by the mean activity (blue dots) and covariance (blue shaded area) of the 25 parcels. (  A  ) has been adapted from Figure 1A from  . (  B  ) Four latent states inferred by the HMM fits to the SONG dataset. Mean activity (top) and pairwise covariance (bottom) of the 25 parcels\u2019 time series is shown for each state. See   for replication with the Human Connectome Project (HCP) dataset. (  C  ) Conceptualizing low-dimensional gradients of the functional brain connectome as a latent manifold of large-scale neural dynamics. Each dot corresponds to a cortical or subcortical voxel situated in gradient space. The colors of the brain surfaces (inset) indicate voxels with positive or negative gradient values with respect to the nearby axes. Data and visualizations are adopted from  . (  D  ) Latent neural states situated in gradient space. Positions in space reflect the mean element-wise product of the gradient values of the 25 parcels and mean activity patterns of each HMM state inferred from the SONG (circles) and HCP (triangles) datasets. \n \n   The choice of the number of states (K) in latent state inference.  \n(  A  ) To determine a value of K that optimizes hidden Markov model (HMM) state inference from the SONG dataset, we iteratively calculated the Calinski\u2013Harabasz scores using leave-one-subject-out cross-validation with K ranging from 2 to 10. Specifically, the HMM was trained on data from all participants but one to estimate parameters: emission and transition probabilities. The model was then applied to decode the latent state sequence of the held-out participant. With the held-out participant\u2019s fMRI time series, the BOLD pattern similarity of the within- versus across- latent states were compared using the Calinski\u2013Harabasz score, such that higher score indicates higher within-state cluster cohesion compared to the across-state dispersion ( ;  ;  ). The line indicates the mean of the cross-validated Calinski\u2013Harabasz scores and the error bars indicate SEM. (  B  ) HMM latent neural states inferred from the SONG dataset using a different choice of K (K = 7). When more states were inferred, we observed subdivisions of and additions to the four neural states in  . The dorsal attention network (DAN), somatosensory motor (SM), and base states appeared with similar activity patterns (  r   = 0.678, 0.923, and 0.445, respectively). The default mode network (DMN) state was subdivided into two DMN states. The DMN-A corresponded to the DMN core and the medial temporal subsystem. The DMN-B corresponded to the dorsal medial subsystem ( ). Two additional neural states were inferred: one which exhibited the highest activity at the frontoparietal network (FPN) and the other showing activity in both the DMN and visual network (VIS). \n  \n\n   Latent state inference conducted separately to each condition of the SONG dataset.  \n(  A  )   Rest   includes the two resting-state runs (600 TR \u00d7 2 for every 27 participants), (  B  )   GradCPT   includes the two gradCPT runs with face (511 TR) and scene (443 TR) images, (  C  )   Sitcom episode   includes the two sitcom-episode-watching runs (episode 1: 1486 TR; episode 2: 1465 TR), and (  D  )   Documentary   corresponds to the single documentary-watching run (1281 TR). The states are ordered based on the activation pattern similarity to the default mode network (DMN), dorsal attention network (DAN), somatosensory motor (SM), and base states inferred from the full dataset ( ). The pattern similarities are as follows in the order of DMN, DAN, SM, and base states:   Rest: r   = 0.801, 0.332, 0.722, 0.369;   GradCPT: r   = 0.956, 0.747, 0.928, 0.276;   Sitcom ep: r   = 0.486, 0.600, 0.737, 0.882;   Documentary: r   = 0.526, 0.847, 0.747, 0.663. \n  \n\n   Examples of the null latent states derived from the hidden Markov models (HMMs) conducted on the surrogate fMRI time series of the SONG dataset (1000 iterations).  \nThe 25 parcel time courses from each fMRI run and participant were circular-shifted, separately for each parcel, which disrupts the covariance across parcels while retaining the temporal characteristics of each individual parcel. Compared to the latent states derived from the actual fMRI time series ( ), these null states did not show systematic activity patterns and exhibited weaker covariance strengths. In  , the somatosensory motor (SM) state exhibited the highest covariance strength (SONG: 52.570; Human Connectome Project [HCP]: 58.196), followed by comparable default mode network (DMN) state (SONG: 37.277; HCP: 28.353) and dorsal attention network (DAN) state (SONG: 37.303; HCP: 29.525), whereas the base state exhibited the lowest covariance strength (SONG: 27.603; HCP: 25.426). On the contrary, the mean covariance strengths of the four surrogate covariance matrices were in the range of 3.215\u20134.432 for SONG and 0.986\u20132.204 for HCP datasets over 1000 iterations. \n  \n\n   Latent state inference using a different whole-brain parcellation scheme.  \nIn the main text, we chose a fairly low-dimensional parcellation scheme (17 cortical and 8 subcortical) because the hidden Markov model (HMM) produces a poorer fit when the dimensionality of the time series increases. The reason is that the number of parameters that need to be inferred for emission probability,   increase exponentially with the increase in the number of parcel dimension  . Here, we test the robustness of the four latent states by using 200 cortical and 50 subcortical parcels, but applied dimensionality reduction to these 250 parcel time series prior to using them as inputs to the HMM. The matrices were randomly projected to 25-dimensional time series matrices by multiplying the time-by-250 matrix with the randomly generated 250-by-25 matrices. Random projection is a validated dimensionality reduction tool ( ) that does not impose any constraints on how the latent dimensions should be (e.g., the principal component analysis should find latent dimensions that maximize explained variance and are orthogonal to one another). The HMM fit was conducted 500 times. For each iteration, after the HMM fit, we inverse-projected 25-dimensional mean activation patterns to 250 dimensions. The decoded latent state sequence of each iteration was compared to the decoded state sequence of the 25-parcel time series that we report in the manuscript. By finding the latent state sequence that shows the highest sequence similarity (mean 40.7 \u00b1 3.45%, given a chance of 25%), we reordered the estimated mean activations and averaged across 500 iterations. The Pearson\u2019s correlations between these average activation patterns and the inferred latent states in   are default mode network (DMN): 0.549; dorsal attention network (DAN): 0.406; somatosensory motor (SM): 0.487; and base: 0.178. Thus, we see similar states in the SONG dataset even when input time series do not come from canonical functional networks. The DMN, DAN, SM, and base states are not specific to the parcellation scheme presented in the main text. \n  \n\n   The inferred latent states and their dynamics are robust to the choice of the fMRI preprocessing approach.  \n(  A  ) We conducted hidden Markov model (HMM) on preprocessed fMRI time series that did not undergo global signal regression. The output time series were highly similar with or without global signal regression, resulting in similar neural state dynamics (93.96% of the time points the same when assigned to the best-matching state, given a chance of 25%) and similar activity patterns of the four latent states (  r   = 0.999, 1.0, 0.997, and 0.997, respectively). (  B  ) We conducted HMM on the preprocessed fMRI time series that were temporally band-pass filtered (0.009 <   f   < 0.08 Hz) rather than high-pass filtered (  f   > 0.009 Hz). The inferred neural states had similar activity patterns (  r   = 0.961, 0.709, 0.883, and 0.757), though their dynamics were not as similar as in (  A  ) (28.59% of the time points the same). However, for all results reported in the article, we validated that the results were replicated in the band-pass filtered version of the analysis. \n  \n\n   Latent state inference on the Human Connectome Project (HCP) dataset.  \n(  A  ) Four latent states inferred by the hidden Markov model (HMM) fits to the HCP dataset. The figure complements  . (  B  ) Comparison of the latent states inferred from the SONG ( ) and HCP datasets. The default mode network (DMN), dorsal attention network (DAN), and somatosensory motor (SM) states showed similar mean activity patterns. We refrained from making interpretations about the base state\u2019s activity patterns because the mean activity of most of the parcels was close to   z   = 0. The covariance patterns were similar throughout all pairwise neural states, although covariance strength values differed across neural states. To further validate the similarity of the SONG- and HCP-identified latent states, we trained the HMM on each dataset and applied it to decode the latent state sequence of the other dataset. When the SONG-trained HMM decoded the latent state sequence of the HCP dataset, 61.18% of the time points were the same as the latent state sequence identified from the HCP-trained HMM (with a chance of 25%). When the HCP-trained HMM decoded the latent state sequence of the SONG dataset, 61.67% of the time points were the same as the latent state sequence identified from the SONG-trained HMM. (  C  ) Calinski\u2013Harabasz score calculated from the HCP dataset (leave-one-subject-out cross-validation with K ranging from 2 to 10). (  D  ) HMM latent states inferred from the HCP dataset using K = 3. The DMN, DAN, and SM states occurred for both the choice of K = 3 and K = 4 (activity pattern similarity:   r   = 0.981, 0.984, and 0.911, respectively). \n  \n\n   The position in predefined gradient space at every time point grouped by hidden Markov model (HMM) latent state.  \n(  A  ) Schematic illustration of the timepoint distribution and the speed and dispersion measurements. Each black dot indicates 25-parcel BOLD activity patterns situated in the two-dimensional gradient space. Speed characterizes Euclidean distance between the gradient positions at time   t-1   and   t  , such that fast speed indicates large Euclidean distance. Dispersion characterizes Euclidean distance between the gradient position at time   t   and the centroid (i.e., mean position of each latent state, indicated with a cross). (  B  ) Activity at every time point (TR) of the SONG (top) and Human Connectome Project (HCP) (bottom) datasets situated in gradient space, categorized based on the latent state assignment at each moment. Positions in the space reflect the element-wise product of the gradient values and the z-normalized BOLD activity of the 25 parcels, which are stacked as a 2D histogram. The colored crosses indicate the means of the distribution in predefined gradient 1 and 2 axes. Mean speeds of the four states are: (SONG) default mode network (DMN): 0.715, dorsal attention network (DAN): 0.710, somatosensory motor (SM): 0.797, base: 0.672; (HCP) DMN: 0.568, DAN: 0.535, SM: 0.712, base: 0.554. Mean dispersions of the four states are: (SONG) DMN: 0.964, DAN: 1.0, SM: 1.139, base: 0.830; (HCP) DMN: 0.946, DAN: 0.835, SM: 1.257, base: 0.889. The Euclidean distances are calculated in the two-dimensional predefined gradient space, thus the relative units between the latent states are of importance. The SM state exhibited the fastest neural dynamics and the largest deviance from the mean, whereas the base state exhibited the slowest neural dynamics near the center of the mean. \n  \n\n   Comparisons between predefined and data-specific gradients.  \n(  A  ) (Left) Visualization of the Margulies et al.\u2019s (2016) first two gradient embeddings (left). The predefined gradients were downloaded from  . Visualization of the first two gradient embeddings defined from the SONG data (middle) and the Human Connectome Project (HCP) data (right). The gradients were computed from the mean 1054 ROI-by-ROI functional connectivity matrix of all participants in each dataset. The 1054 parcels include 1000 cortical ROIs of the   atlas and 54 subcortical ROIs of   atlas. (  B  ) Pearson\u2019s correlations between the top 5   gradient embeddings and the SONG data (top) and HCP data (bottom) gradient embeddings. The gradient embeddings were estimated from 1054 ROIs. (  C  ) Variance of the SONG data participants\u2019 average functional connectivity explained by the SONG-specific gradients (solid line). Variance of the HCP data participants\u2019 average functional connectivity explained by the HCP-specific gradients (dashed line). (  D  ) (Left) Variance of the SONG data fMRI time series (1054 ROIs) explained by the first two SONG data gradients (black) and   gradients (gray). (Right) Variance of the HCP data fMRI time series explained by the first two HCP data gradients (black) and   gradients (gray). The explained variance was calculated by the mean of squared Pearson\u2019s correlations ( ) between the 1054 ROI fMRI time series and the gradient-projected time series. \n  \n \n illustrates the four latent neural states inferred by the HMM in the SONG dataset (see   for condition-specific latent states). We labeled three states the default mode network (DMN), dorsal attention network (DAN), and somatosensory motor (SM) states based on high activation of these canonical brain networks ( ). (Note that these state labels are only applied for convenience. Each state is characterized by whole-brain   patterns   of activation, deactivation, and covariance, rather than simply corresponding to activation of the named network.) The fourth state was labeled the \u2018base\u2019 state because activity was close to baseline (  z   = 0) and covariance strength (i.e., the sum of the absolute covariance weights of the edges) was comparatively low during this state. The SM state, on the other hand, exhibited the highest covariance strength, whereas the covariance strengths of the DMN and DAN states were comparable. Compared to null latent states derived from surrogate fMRI time series, the four states exhibited activity patterns more similar to large-scale functional systems ( ;  ;  ;  ) and significantly higher covariance strength (see   for examples of null latent states). These states were replicated with 250 regions of interest (ROIs) consisting of 200 cortical ( ) and 50 subcortical regions ( ), albeit with a caveat that the HMM provides a poorer fit to the higher-dimensional time series ( ). Neural state inference was robust to the choice of   ( ) and the fMRI preprocessing pipeline ( ) and consistent when conducted on two groups of randomly split-half participants (Pearson\u2019s correlations between the two groups\u2019 latent state activation patterns: DMN: 0.791; DAN: 0.838; SM: 0.944; base: 0.837). \n\nTo validate that these states are not just specific to the SONG dataset, we analyzed fMRI data from the Human Connectome Project (HCP; N = 119) ( ) collected during rest, seven block-designed tasks\u2014the emotion processing, gambling, language, motor, relational processing, social cognition, and working memory tasks ( )\u2014and movie watching ( ). The same HMM inference was conducted independently on the HCP dataset using   = 4 ( ). HCP states closely mirrored the DMN, DAN, SM, and base states (Pearson\u2019s correlations between activity patterns of SONG- and HCP-defined states: DMN: 0.831; DAN: 0.814; SM: 0.865; base: 0.399). Thus, the latent states are reliable and generalize across independent datasets. \n\n\n### Latent state dynamics span low-dimensional gradients of the functional brain connectome \n  \nThe HMM results demonstrate that large-scale neural dynamics in diverse cognitive contexts (tasks, rest, and movie watching) are captured by a small number of latent states. Intriguingly, the DMN, DAN, and SM systems that contribute to these states tile the principal gradients of large-scale functional organization. In a seminal paper,   applied a nonlinear dimensionality reduction algorithm to capture the main axes of variance in the resting-state static functional connectome of 820 individuals. They found that the primary gradient dissociated unimodal (visual and SM regions) from transmodal (DMN) systems. The secondary gradient fell within the unimodal end of the primary gradient, dissociating the visual processing from the SM systems. These gradients, argued to be an \u2018intrinsic coordinate system\u2019 of the human brain ( ), reflect variations in brain structure ( ;  ;  ), gene expressions ( ), and information processing ( ). \n\nWe hypothesized that the spatial gradients reported by   act as a low-dimensional manifold over which large-scale dynamics operate ( ;  ;  ;  ), such that traversals within this manifold explain large variance in neural dynamics and, consequently, cognition and behavior ( ). To test this idea, we situated the mean activity values of the four latent states along the gradients defined by   (see \u2018Materials and methods\u2019). The brain states tiled the two-dimensional gradient space with the base state at the center ( ,  ). The Euclidean distances between these four states were maximized in the two-dimensional gradient space compared to a chance where the four states were inferred from circular-shifted time series (p<0.001). For the SONG dataset, the DMN and SM states fell at more extreme positions on the primary gradient than expected by chance (both FDR-p-values=0.004; DAN and SM states, FDR-p values=0.171). For the HCP dataset, the DMN and DAN states fell at more extreme positions on the primary gradient (both FDR-p values=0.004; SM and base states, FDR-p values=0.076). No state was consistently found at the extremes of the secondary gradient (all FDR-p values>0.021). \n\nWe asked whether the predefined gradients explain as much variance in neural dynamics as latent subspace optimized for the SONG dataset. To do so, we applied the same nonlinear dimensionality reduction algorithm to the SONG dataset\u2019s ROI time series. Of note, the SONG dataset includes 18.95% rest, 15.07% task, and 65.98% movie-watching data, whereas the data used by   was 100% rest. Despite these differences, the SONG-specific gradients closely resembled the predefined gradients, with Pearson\u2019s correlations observed for the first (  r   = 0.876) and second (  r   = 0.877) gradient embeddings ( ). Gradients identified with the HCP data also recapitulated Margulies et al.\u2019s (2016) first (  r   = 0.880) and second (  r   = 0.871) gradients. We restricted our analysis to the first two gradients because the two gradients together explained roughly 50% of the variance of the functional brain connectome (SONG: 46.94%; HCP: 52.08%), and the explained variance dropped drastically from the third gradients (more than 1/3 drop compared to the second gradients). The degrees to which the first two predefined gradients explained whole-brain fMRI time series (SONG:   = 0.097; HCP: 0.084) were comparable to the amount of variance explained by the first two data-specific gradients (SONG:   = 0.100; HCP: 0.086;  ). Thus, the low-dimensional manifold captured by Margulies et al.\u2019s (2016) gradients is highly replicable, explaining brain activity dynamics as well as data-specific gradients, and is largely shared across contexts and datasets. This suggests that the state space of whole-brain   dynamics   closely recapitulates low-dimensional gradients of the   static   functional brain connectome. \n\n\n### Transient global desynchrony precedes neural state transitions \n  \nNeural state transitions can be construed as traversals in a low-dimensional space whose axes are defined by principal gradients of functional brain organization. When and how do these neural state transitions occur? What indicates that the system is likely to transition from one state to another? \n\nWe predicted that neural state transitions are related to changes in interactions between functional networks. To test this account, we computed cofluctuation between all pairs of parcels at every TR (1 s). Cofluctuation operationalizes the time-resolved interaction of two regions as an absolute element-wise product of their activity at every time step after   z  -normalization of their time series ( ;  ;  ). We time-aligned cofluctuation values to moments of neural state transitions estimated from the HMM ( ). A decrease in cofluctuation prior to the neural state transitions (at time   t-1  ) was observed for every pair of cortico-cortical networks (  z   = 645.75, FDR-p=0.001). Cortico-subcortical pairs (  z   = 424.05, FDR-p=0.001) and subcortico-subcortical connections (  z   = 64.85, FDR-p=0.037) also showed decreased cofluctuation before state transitions, although the effects were less pronounced, especially for subcortico-subcortical connections (paired Wilcoxon signed-rank tests comparing the degrees of cofluctuation change, FDR-p-values<0.001). Results were replicated with the 250-ROI parcellation scheme as well as with the HCP dataset ( ). Furthermore, repeating this analysis with null HMMs on circular-shifted time series suggests that the effect is not simply a by-product of the chosen computational model ( ). These results are consistent with prior empirical findings that desynchronization, a \u2018transient excursion away from the synchronized manifold\u2019 ( ), allows the brain to switch flexibly between states ( ;  ;  ;  ). \n   Neural state transitions.  \n(  A  ) Changes in cofluctuation of the parcel pairs, time-aligned to hidden Markov model (HMM)-derived neural state transitions. State transitions occur between time   t  -1 and   t  . Purple lines indicate the mean cofluctuation of cortico-cortical (left), cortico-subcortical (middle), and subcortico-subcortical (right) parcel pairs across fMRI runs and participants, and the thick black line indicates the mean of these pairs. The shaded gray area indicates the range of the null distribution (mean \u00b1 1.96 \u00d7 standard deviation), in which the moments of state transitions were randomly shuffled (asterisks indicate FDR-p<0.05). (  B  ) Transition matrix indicating the first-order Markovian transition probability from one state (row) to the next (column), averaged across all participants\u2019 all fMRI runs. The values indicate transition probabilities, such that values in each row sums to 1. The colors indicate differences from the mean of the null distribution where the HMMs were conducted on the circular-shifted time series. (  C  ) Mean degrees of global cofluctuation at moments of latent neural state occurrence. The measurements at each time point were averaged within participant based on latent state identification, and then averaged across participants. The bar graph indicates the mean of all participants\u2019 all fMRI runs. The error bars indicate standard error of the mean (SEM). Gray dots indicate individual data points (7 runs of 27 participants). The shaded gray area indicates the range of the null distribution, in which the analyses were conducted on the circular-shifted latent state sequence. See   for replication with the Human Connectome Project (HCP) dataset. \n \n   Neural state transitions of the Human Connectome Project (HCP) dataset.  \nThe figure complements  , which shows the results of the SONG dataset. (  A\u2013C  ) See   for legends. \n  \n\n   Cofluctuations of all pairs of 25 parcels of the (  A  ) SONG and (  B  ) Human Connectome Project (HCP) datasets, time-aligned to the hidden Markov model (HMM)-derived neural state transitions, compared to a null distribution that was generated differently than  .  \nInstead of shuffling the moments of neural state transitions ( ), we circular-shifted the parcel time series prior to the HMM inference (1000 iterations, two-tailed non-parametric permutation tests, FDR-corrected for the number of time points). This way of creating null distribution allowed us to ask whether the HMM, by the nature of the model, detects state transitions based on transient decrease in the global synchrony. We observed a decrease in cofluctuation between cortico-cortical and cortico-subcortical regions prior to null state onset (difference between the mean cofluctuation at time   t+3   and   t-1   aligned to new state onset, bootstrapped p-values<0.001). However, this decrease was less dramatic than that observed in the actual fMRI time series (two-tailed non-parametric permutation tests, FDR-p-values<0.002, corrected for the three pair types). Thus, decreases in cofluctuation prior to state transitions are not simply a byproduct of the computational model. \n  \n\n   Transition matrix of the (  A  ) SONG and (  B  ) Human Connectome Project (HCP) datasets indicating transition probability from one state (row) to the next (column), such that values in each column sums to 1.  \nComplementing  , which indicates the probability of transitioning   to   a certain brain state from each of the states (values in each row sums to 1), this figure indicates the probability of transitioning   from   each brain state. The colors indicate differences from the mean of the null distribution where the hidden Markov models (HMMs) were conducted on the circular-shifted time series (asterisks indicate FDR-p<0.05). \n  \n\n   Mean head motion (framewise displacement [FD]) at moments of latent neural state occurrence in the (  A  ) SONG and (  B  ) Human Connectome Project (HCP) datasets.  \nFD measured at each time point was averaged within a participant based on the latent state identification, and then averaged across participants. The bar graph indicates the mean of FD from all fMRI runs and participants. The shaded gray area indicates the range of the null distribution (mean \u00b1 1.96 \u00d7 standard deviation), in which the analyses were conducted on the circular-shifted latent state sequence. FD was measured after motion correction. Higher FD was observed at TRs assigned to the somatosensory motor (SM) state than at TRs assigned to other states (paired   t  -tests, SONG:   t  (187) > 4, HCP:   t  (3091) > 22, both FDR-p-values<0.001, corrected for the number of pairwise states), but FD at moments of default mode network (DMN), dorsal attention network (DAN), and base states were comparable (SONG:   t  (187) < 1.5, HCP:   t  (3093) < 2, both FDR-p-values>0.15). \n  \n \n\n### The base state acts as a flexible hub in neural state transitions \n  \nTo further address how neural state transitions occur, we analyzed the HMM\u2019s transition matrix, which indicates the probability of a state at time   t-1   transitioning to another state or remaining the same at time   t  . The probability of remaining in the same state was dominant (>85%), whereas the probability of transitioning to a different state was less than 8% ( ,  ). To investigate whether certain state transitions occurred more often than expected by chance, we compared the transition matrix to a null distribution where the HMM was conducted on circular-shifted fMRI time series. The DMN, DAN, and SM states were more likely to transition to and from the base state and less likely to transition to and from one another than would be expected by chance ( ,  ; FDR-p-values<0.05). The result suggests that the base state acts as a hub in neural state transitions, replicating a past finding of the base state as a transitional hub in resting-state fMRI data ( ). \n\nGiven that global desynchrony indicates moments of neural state transitions ( ), we used this measure to validate the role of the base state as a \u2018transition-prone\u2019 state. Cofluctuation between every pair of parcels was computed at every TR, which was averaged across parcel pairs to represent a time-resolved measure of global cofluctuation ( ). When comparing the degree of global cofluctuation across the four latent states, we found that the base state exhibited the lowest degree of global cofluctuation (paired   t  -tests comparing cofluctuation in base state vs. DMN, DAN, and SM states, SONG:   t  (187) > 61, HCP:   t  (3093) > 170, FDR-p-values<0.001), which was significantly below chance (FDR-p-values<0.001). This suggests that the base state was the most desynchronized state among the four, potentially operating as a transition-prone state. Low global synchrony during the base state was not driven by spurious head motion ( ). Thus, the base state, situated at the center of the gradient space, is a flexible \u2018hub\u2019 state with a high degree of freedom to transition to other functionally specialized states. \n\n\n\n## Neural state dynamics are modulated by ongoing cognitive and attentional states \n  \n### Latent state dynamics differ across contexts and are synchronized during movie watching \n  \nWe identified four latent states that recur during rest, task performance, and movie watching. Although the latent manifold of neural trajectories may be shared across contexts, latent states may be occupied to different degrees across contexts. For example, one state may occur more frequently in one context but not in others. We asked whether the pattern with which brain activity \u2018visits\u2019 the four states differed across contexts. \n\nWe used the HMM to infer the latent state sequence of each fMRI run ( ) and summarized the fractional occupancy of each state (i.e., proportion of time that a state occurred) ( ; see   for dwell time distributions). All four states occurred in all fMRI runs, with no state occurring on more than 50% of time points in a run. Thus, these states are common across contexts rather than specific to one context. Fractional occupancy, however, differed across rest, task, and naturalistic contexts, with strikingly similar values between runs of similar contexts (e.g., rest runs 1 and 2). In contrast to the similar fractional occupancy values of the two sitcom-episode runs, fractional occupancy in the documentary-watching condition differed despite the fact that it also involved watching an audiovisual stimulus. During the documentary, the base state occurred less frequently, whereas the SM state occurred more frequently than during the sitcom episodes. \n   Latent neural state dynamics in the seven fMRI runs.  \n(  A  ) Latent state dynamics inferred by the hidden Markov model (HMM) for all participants. Colors indicate the state that occurred at each time point. (  B  ) Fractional occupancy of the neural states in each run. Fractional occupancy was calculated for each individual as the ratio of the number of time points at which a neural state occurred over the total number of time points in the run. Distributions indicate bootstrapped mean of the fractional occupancies of all participants. The chance level is at 25%. (  C  ) Synchrony of latent state sequences across participants. For each pair of participants, sequence similarity was calculated as the ratio of the number of time points when the neural state was the same over the total number of time points in the run. Box and whisker plots show the median, quartiles, and range of the similarity distribution. \n \n   Dwell times of the latent neural states, measured as the duration (s) for which a neural state continuously persisted before transitioning to a different state.  \n(  A  ) Mean dwell times of each latent state in every run of the SONG dataset. The mean dwell times of the null distribution, computed on the hidden Markov models (HMMs) conducted on the circular-shifted 25-parcel time series, are indicated in red. The significance of the two-tailed non-parametric permutation tests are indicated with asterisks (1000 iterations, FDR-p<0.05, corrected for 28 comparisons). For the resting-state runs, the dwell times of the base state were lower than the null dwell times. For the gradCPT runs, the dwell times of the dorsal attention network (DAN) state were higher whereas the dwell times of the somatosensory motor (SM) state were lower than the null. For the sitcom-episode-watching runs, the dwell times of the base state were higher, whereas the dwell times of the SM state were lower than the null. Lastly, for the documentary-watching run, base state dwell time was significantly lower than the null. (  B  ) Histogram of all latent states\u2019 dwell times. The dwell times of the state time course concatenated across 27 participants\u2019 seven runs had a mean of 7.293 \u00b1 5.680 s, median 6 s, ranging from 1 to 71 s. \n  \n\n   Inferred neural state dynamics of the external datasets from the hidden Markov model (HMM) trained on the SONG dataset.  \nTo verify that the inferred neural states are not specific to these datasets, we applied the SONG-trained HMM (i.e., the inferred emission and transition probabilities) to decode latent sequences of the three independent datasets that targeted specific task contexts: the resting-state and gradCPT of   (N = 25), television episode watching of   (N = 16), and story listening of   (N = 25). (  A  ) Fractional occupancy of the four latent states per dataset. (  B  ) Latent state sequence similarity of all pairs of participants in each dataset. Intersubject synchrony of the latent state sequence was high during television episode watching ( ) (39.24 \u00b1 3.34%, FDR-p<0.001; comparable to synchrony during the SONG sitcom episodes) and story listening ( ) (33.84 \u00b1 3.08%, FDR-p<0.001). In comparison, intersubject similarity during rest ( ) was near chance (25.84 \u00b1 3.79%, though statistically significant FDR-p<0.001). The analysis follows  . \n  \n \nLatent state dynamics were synchronized across participants watching the comedy sitcom episodes (mean pairwise participant similarity: episode 1: 40.81 \u00b1 3.84%, FDR-p=0.001; episode 2: 40.79 \u00b1 3.27%, FDR-p=0.001; paired comparisons, non-parametric p=0.063;  ). Less synchrony was observed between participants watching the educational documentary (30.39 \u00b1 3.38 %, FDR-p=0.001; paired comparisons with the two sitcom episodes, both p<0.001). No significant synchrony was observed during the resting-state runs (run 1: 25.81 \u00b1 4.00 %, FDR-p=0.230; run 2: 25.84 \u00b1 4.08 %, FDR-p=0.183). \n\nThese results were replicated when we applied the SONG-trained HMM to decode latent sequences of the three independent datasets ( ). The four neural states occurred in every run of every dataset tested, with maximal fractional occupancies all below 50%. Intersubject synchrony of the latent state sequence was high during movie watching and story listening but at chance during rest. Together the results validate that neural states identified from the SONG dataset generalize not only across contexts but also to independent datasets. \n\nPrior studies reported that regional activity ( ;  ) and functional connectivity ( ;  ;  ) are synchronized across individuals during movie watching and story listening, and that attentional engagement modulates the degree of intersubject synchrony ( ;  ;  ). Our results indicate that the intersubject synchrony occurs not only at regional and pairwise regional scales, but also at a global scale via interactions of functional networks. Furthermore, stronger entrainment to the stimulus during sitcom episodes compared to documentary-watching condition suggests that overall attentional engagement may mediate the degree of large-scale synchrony (mean reports on overall engagement from a scale of 1 [not at all engaging] to 9 [completely engaging]: sitcom episode1: 6.78 \u00b1 1.05, episode2: 6.93 \u00b1 1.41, documentary: 3.59 \u00b1 1.21). Indeed, demonstrating a relationship between neural state dynamics and narrative engagement, participant pairs that exhibited similar engagement dynamics showed similar neural state dynamics (sitcom episode 1: Spearman\u2019s   r   = 0.274, FDR-p=0.005; episode 2:   r   = 0.229, FDR-p=0.010; documentary:   r   = 0.225, FDR-p=0.005). \n\n\n### Neural state dynamics are modulated by narrative event boundaries \n  \nLatent state dynamics are synchronized across individuals watching television episodes and listening to stories, which suggests that latent neural states are associated with shared cognitive states elicited by an external stimulus. How are these neural state dynamics modulated by stimulus-driven changes in cognition? \n\nOur comedy sitcom episodes had unique event structures. Scenes alternated between two distinct storylines (A and B) that took place in different places with different characters. Each episode included 13 events (seven events of story A and six events of B) ordered in an ABAB sequence. This interleaved event structure required participants to switch between the two storylines at event boundaries and integrate them in memory to form a coherent narrative representation ( ;  ;  ). \n\nWe asked if any latent state consistently occurred at narrative event boundaries ( ). In both sitcom episodes, the DMN state was more likely to occur than would be expected by chance after event boundaries (~50% probability, FDR-p<0.01), complementing past work that showed the involvement of the DMN at event boundaries ( ;  ;  ). The base state, on the other hand, was less likely to occur after event boundaries (~10% probability). DAN and SM state occurrences were not modulated by event boundaries ( ). These results replicated when the SONG-defined HMM was applied to a 50 min story-listening dataset ( ) in which 45 events were interleaved in an ABAB sequence ( ). A transient increase in hippocampal BOLD activity occurred after event boundaries ( ), replicating previous work ( ;  ;  ;  ). Together, our results suggest that event boundaries affect neural activity not only at a regional level, but also at a whole-brain systems level. \n   Neural state occurrence and transitions at narrative event boundaries.  \n(  A  ) The proportion of the default mode network (DMN) (top) and base state (bottom) occurrences time-aligned to narrative event boundaries of sitcom episodes 1 (left) and 2 (right). State occurrence at time points relative to the event boundaries per stimulus was computed within participant and then averaged across participants. The dark gray shaded areas around the thick black line indicate SEM. The dashed lines at   t   = 0 indicate moments of new event onset and the lines at   t   = 5 account for hemodynamic response delay of the fMRI. The light gray shaded areas show the range of the null distribution in which boundary indices were circular-shifted (mean \u00b1 1.96 \u00d7 standard deviation), and the black lines on top of the graphs indicate statistically significant moments compared to chance (FDR-p<0.01). (  B  ) The proportion of the DMN (top) and base state (bottom) occurrence time-aligned to narrative event boundaries of audio narrative. Latent state dynamics were inferred based on the hidden Markov model (HMM) trained on the SONG dataset. Lines at   t   = 4 account for hemodynamic response delay. (  C  ) Schematic transitions to the DMN state at narrative event boundaries (dashed lines) compared to the normal trajectory which passes through the base state (solid lines). See   for results of statistical analysis. \n \n   Neural state occurrence and hippocampal BOLD activity time-aligned to narrative event boundaries.  \n(  A, B  ) Neural state occurrence after event boundaries. This figure complements  , which only showed default mode network (DMN) and base state occurrence proportions. Consistent across (  A  ) the sitcom episodes 1 and 2 runs in the SONG dataset and (  B  ) the external dataset,  , no change in the dorsal attention network (DAN) state occurrence was found after event boundaries. No change in the somatosensory motor (SM) state occurrence was found for the sitcom episodes 1 and 2. An increase in SM state occurrence after event boundaries is likely to be due to ~6 s of silent pauses in the audio in between the events. Given that the SM state occurred at intermittent rests in between the task blocks ( ), the increase in the SM state after event boundaries may be due to a blank period rather than the narrative event change. (  C, D  ) BOLD activity of the hippocampal ROI time course (  z  -normalized), time-aligned to narrative event boundaries of the (  C  ) SONG dataset\u2019s sitcom episodes and (  D  ) audio story. The hippocampal ROI mask of the MNI template was adopted from  . \n  \n\n   Transitions to the default mode network (DMN) state at narrative event boundaries.  \nThis figure complements  , which visualizes the schematics of these results. (  A  ) The proportion of the dorsal attention network (DAN), somatosensory motor (SM), and base states that occurred prior to the DMN state occurrence during the sitcom episodes 1 (left) and 2 (right). Transitions to the DMN state were categorized based on whether the DMN state occurred 5\u201315 TRs after the event boundaries (event boundary; eb) or not (non-event boundary; non-eb). Paired Wilcoxon signed-rank tests were conducted between the event boundary and non-event boundary conditions per neural state, and the significant difference is indicated with a colored shade (FDR-p<0.05). (  B  ) Same as (  A  ) but in   dataset. Transitions to the DMN state 4\u201312 TRs after the event boundaries were compared to those that occurred at the rest of the moments. The proportions were averaged across participants for visualization. \n  \n \nHow does brain activity transition to the DMN state at event boundaries? To investigate how event boundaries perturb neural dynamics, we compared transitions to the DMN state that occurred at event boundaries (i.e., between 5 and 15 s after boundaries) to those that occurred at the rest of the moments (non-event boundaries) ( ). At non-event boundaries, the DMN state was most likely to transition from the base state, accounting for more than 50% of the transitions to the DMN state. Interestingly, however, at event boundaries, base-to-DMN state transitions significantly dropped while DAN-to-DMN and SM-to-DMN state transitions increased ( ). A repeated-measures ANOVA showed a significant interaction between the latent states and the event boundary conditions (sitcom episode 1: F(2,50) = 10.398; episode 2: F(2,52) = 12.794; Chang et al.: F(2,48) = 31.194; all p-values<0.001). Thus, although the base state typically acts as a transitional hub ( ), neural state transitions at event boundaries are more likely to occur directly from the DAN or SM state to the DMN state without passing through the base state due to the DMN state\u2019s functional role at event boundaries. These results illustrate one way in which neural systems adaptively reconfigure in response to environmental demands. \n\n\n### Neural state dynamics reflect attention dynamics in task and naturalistic contexts \n  \nIn addition to changes in cognitive states, sustained attention fluctuates constantly over time ( ;  ;  ;  ;  ;  ). Previous studies showed that large-scale neural dynamics that evolve over tens of seconds capture meaningful variance in arousal ( ;  ) and attentional states ( ;  ). We asked whether latent neural state dynamics reflect ongoing changes in attention in both task and naturalistic contexts. To infer participants\u2019 attentional fluctuations during the gradCPT, we recorded response times (RT) to every frequent-category trial (~1 s). The RT variability time course was used as a proxy for fluctuating attentional state, with moments of less variable RTs (i.e., stable performance) indicating attentive states ( ). Paying attention to a comedy sitcom, on the other hand, involves less cognitive effort than attending to controlled psychological tasks, more akin to a \u2018flow\u2019-like state compared to controlled tasks that require top-down exertion of control ( ;  ;  ;  ). Attending to a narrative is further affected by a rich set of cognitive processes such as emotion ( ;  ), social cognition ( ;  ), or causal reasoning ( ;  ). To assess participants\u2019 fluctuating levels of attentional engagement during the sitcom episodes and documentary, we asked participants to continuously self-report their levels of engagement on a scale of 1 (not engaging at all) to 9 (completely engaging) as they rewatched the stimuli outside the fMRI ( ;  ). \n   Relationship between latent neural states and attentional engagement.  \n(  A  ) Schematic illustration of the gradCPT and continuous narrative engagement rating. (Top) Participants were instructed to press a button at every second when a frequent-category image of a face or scene appeared (e.g., indoor scene), but to inhibit responding when an infrequent-category image appeared (e.g., outdoor scene). Stimuli gradually transitioned from one to the next. (Bottom) Participants rewatched the sitcom episodes and documentary after the fMRI scans. They were instructed to continuously adjust the scale bar to indicate their level of engagement as the audiovisual stimuli progressed. (  B  ) Behavioral measures of attention in three fMRI conditions. Inverse RT variability was used as a measure of participants\u2019 attention fluctuation during gradCPT. Continuous ratings of subjective engagement were used as measures of attention fluctuation during sitcom episodes and documentary watching. Both measures were   z  -normalized across time during the analysis. (  C\u2013G  ) Degrees of attentional engagement at moments of latent state occurrence. The attention measure at every time point was categorized into which latent state occurred at the corresponding moment and averaged per neural state. The bar graphs indicate the mean of these values across participants. Gray dots indicate individual data points (participants). The mean values were compared with the null distributions in which the latent state dynamics were circular-shifted (asterisks indicate FDR-p<0.01). (  C, E, G  ) Results of the fMRI runs in the SONG dataset. (  D, F  ) The hidden Markov model (HMM) trained on the SONG dataset was applied to decode the latent state dynamics of (  D  ) the gradCPT data by   (N = 25), and (  F  ) the Sherlock television watching data by   (N = 16). \n \n   Latent state dynamics during cognitive task blocks, decoded from the hidden Markov model (HMM) trained on the SONG dataset.  \n(  A  ) Latent state dynamics of the gradCPT data collected by   (N = 25). The data consists of three runs, with each run consisting of four 3 min task blocks interleaved with 30 s of fixation. A boxcar plot indicates durations of the task and fixation blocks, shifted in time (5 TR; 5 s) to account for hemodynamic response delay. White areas indicate missing fMRI runs. (  B  ) Fractional occupancies of the four states were calculated during task and fixation blocks separately and averaged across participants. The bar graph indicates the mean of fractional occupancies calculated per participant. The default mode network (DMN), dorsal attention network (DAN), and base states occurred more frequently during task than fixation blocks (paired   t  -tests,   t  (24) > 6, FDR-p-values<0.001), whereas the SM state occurred more frequently during fixation blocks (  t  (24) = 12.565, FDR-p<0.001). We observed a significant main effect of neural states (repeated-measures ANOVA: F(3,72) = 85.479, p<0.001) and an interaction between neural states and block types (F(3,72) = 119.392, p<0.001). The error bars indicate SEM. (  C  ) Latent state dynamics of the Human Connectome Project (HCP) working memory (WM) task runs in left-to-right (LR; N = 110) and right-to-left (RL; N = 108) phase encoding sessions. Each session consists of a single run, with four 2-back WM (25 s), four 0-back WM (25 s), and three fixation blocks (15 s) interleaved, which are indicated in the boxcar plots shifted in time (6 TR; 4.32 s). (  D  ) Fractional occupancies of the four states calculated at moments of 2-back WM, 0-back WM, and fixation blocks. In both sessions, DAN state occurrence decreased (paired   t  -tests for all block pairs, LR:   t  (109) > 13, RL:   t  (107) > 10, FDR-p-values<0.001), whereas the DMN and SM state occurrence increased (LR:   t  (109) > 3, RL:   t  (107) > 5, FDR-p-values<0.001), from 2-back to 0-back to fixation blocks as blocks required less cognitive control and memory load. The base state, on the other hand, occurred comparably during the 2-back and 0-back WM task blocks (LR:   t  (109) = 1.804, FDR-p=0.074, RL:   t  (107) = 1.486, FDR-p=0.140), whereas it occurred less at fixation blocks (LR:   t  (109) > 10, RL:   t  (107) > 9, FDR-p-values <0.001). The repeated-measures ANOVA showed the main effect of the neural states (LR: F(3,327) = 117.445, p<0.001; RL: F(3,321) = 126.702, p<0.001) and the interaction effect (LR: F(6,654) = 261.987, p<0.001; RL: F(6,642) = 149.786, p<0.001). \n  \n \nWe asked whether neural state occurrence reflected participants\u2019 attentional states. For each participant, we averaged time-resolved measures of attention based on the latent neural states that occurred at particular moments of time. \n\n#### Distinct states correspond to engaged attention during tasks and movies \n  \nDifferent brain states accompanied successful task performance and engaged movie watching. During the gradCPT, participants were in a high attentional state when the DMN state occurred ( ). Results replicated when the SONG-trained HMM was applied to the gradCPT data collected by   ( ). This finding conceptually replicates previous work that showed the DMN involvement during in-the-zone moments of the gradCPT ( ;  ) and supports the role of the DMN in automated processing of both the extrinsic and intrinsic information ( ;  ;  ). \n\nOther neural states indicated moments of high attention during movie watching. During comedy sitcoms, the base state was associated with engaged attention ( ). Results replicated when the SONG-trained HMM was applied to television episode watching data collected by   (N = 16) ( ). To our knowledge, the involvement of the base state at engaging moments of movie watching has not been reported previously. During the educational documentary, on the other hand, the DAN state was associated with engaged attention ( ). When watching a less engaging but information-rich documentary, focusing may require goal-directed and voluntary control of attention ( ). Together, the results imply that different neural states indicate engaged attention in different contexts. \n\n\n#### A common state underlies attention lapses during tasks and movies \n  \nIn contrast to moments of engaged attention, moments of attention lapses were associated with the same brain state during gradCPT performance and movie watching. The SM state occurred during moments of poor gradCPT performance in the SONG (with the exception of the gradCPT scene run which had the shortest run duration, FDR-p=0.589;  ) and   datasets ( ). It also occurred during periods of disengaged focus on the comedy sitcoms ( ), the television episode of   (N = 16) ( ), and the educational documentary ( ). Higher head motion was observed during the SM state compared to the three other states ( ). However, the latent states consistently predicted attention when head motion was included as a predictor in a linear model (main effect of HMM latent states,   F   > 3, p-values<0.05 for 7 fMRI runs in  ; whereas the effect of head motion was inconsistent), demonstrating that the effects were not driven by motion alone. \n\nTo further investigate the role of the SM state, we applied the trained HMM to two external datasets, one containing gradCPT runs interleaved with fixation blocks ( ), and the other containing working memory task runs interleaved with fixation blocks ( ;  ). In both the gradCPT and working memory task, the SM state occurred more frequently during intermittent rest breaks in between the task blocks, whereas the DMN, DAN, and base states occurred prominently during the task blocks ( ). These results suggest that the SM state indicates a state of inattention or disengagement common across task contexts. \n\n\n\n\n## Discussion \n  \nOur study characterizes large-scale human fMRI activity as a traversal between latent states in a low-dimensional state space. Neural states spanned predefined gradients of functional brain organization, with the state at the center functioning as a transitional hub. These gradients explained significant variance in neural dynamics, suggesting their role as a general latent manifold shared across cognitive processes. Global desynchronization marked moments of neural state transitions, with decreases in cofluctuation of the pairwise functional networks preceding state changes. The same latent states recurred across fMRI runs and independent datasets, with distinct state-traversal patterns during rest, task, and naturalistic conditions. Neural state dynamics were synchronized across participants during movie watching and temporally aligned to narrative event boundaries. Whereas different neural states were involved in attentionally engaged states in task and naturalistic contexts, a common neural state indicated inattention in both contexts. Together, our findings suggest that human cognition and attention arise from neural dynamics that traverse latent states in a shared low-dimensional gradient space. \n\nTaking a dynamical systems approach, systems neuroscientists have theorized that hierarchically modular systems of the brain communicate and process information dynamically ( ). This framework, which characterizes the dynamics of systems-level interactions as a trajectory within a state space, has opened a new avenue to understanding the functional brain beyond what could be revealed from the univariate activity of local brain regions or their pairwise connections alone ( ). Although a dynamical systems approach has been adopted in non-human animal studies to understand behavior during targeted tasks ( ;  ;  ;  ), there is still a lack of understanding of how human cognition arises from brain-wide interactions, with a particularly sparse understanding of what gives rise to naturalistic, real-world cognition. \n\nUsing fMRI data collected in rest, task, and naturalistic contexts, we identified four latent states that tile the principal gradient axes of functional brain connectome. Are these latent states\u2014the DMN, DAN, SM, and base states\u2014generalizable states of the human brain? When the HMM was applied to data from each condition separately, the inferred latent states differed ( ). However, when the HMM was applied to datasets including diverse fMRI conditions like the SONG and HCP, the four states consistently reappeared, regardless of analytical choices ( ;   and  ). We propose a framework that can unify these observations and theories: large-scale neural dynamics traverse canonical latent states in a low-dimensional manifold captured by the principal gradients of functional brain organization. \n\nThis perspective is supported by previous work that has used different methods to capture recurring low-dimensional states from spontaneous fMRI activity during rest. For example, to extract time-averaged latent states, early resting-state analyses identified task-positive and task-negative networks using seed-based correlation ( ). Dimensionality reduction algorithms such as independent component analysis ( ) extracted latent components that explain the largest variance in fMRI time series. Other lines of work used time-resolved analyses to capture latent state dynamics. For example, variants of clustering algorithms, such as co-activation patterns ( ;  ), k-means clustering ( ), and HMM ( ;  ;  ;  ), characterized fMRI time series as recurrences of and transitions between a small number of states. Time-lag analysis was used to identify quasiperiodic spatiotemporal patterns of propagating brain activity ( ;  ). A recent study extensively compared these different algorithms and showed that they all report qualitatively similar latent states or components when applied to fMRI data ( ). While these studies used different algorithms to probe data-specific brain states, this work and ours report common latent axes that follow a long-standing theory of large-scale human functional systems ( ). Neural dynamics span principal axes that dissociate unimodal to transmodal and sensory to motor information processing systems. \n\nPrior systems neuroscience research on low-dimensional brain states was primarily performed on data from rest or a single task. Thus, the extent to which a latent manifold underlying brain states is common or different across contexts was unknown. It was also unclear how brain states reflected cognitive dynamics. Our results show that neural dynamics in different cognitive contexts can be coarsely understood as traversals between latent states in a context-general manifold. However, the state dynamics, or most likely \u2018paths\u2019 between states, differ with context and functional demands, potentially giving rise to our diverse and flexible cognitive processes. \n\nOur study adopted the assumption of low dimensionality of large-scale neural systems, which led us to intentionally identify only a small number of states underlying whole-brain dynamics. Importantly, however, we do not claim that the four states will be the optimal set of states in every dataset and participant population. Instead, latent states and patterns of state occurrence may vary as a function of individuals and tasks ( ). Likewise, while the lowest dimensions of the manifold (i.e., the first two gradients) were largely shared across datasets tested here, we do not argue that it will always be identical. If individuals and tasks deviate significantly from what was tested here, the manifold may also differ along with changes in latent states ( ). Brain systems operate at different dimensionalities and spatiotemporal scales ( ), which may have different consequences for cognition. Asking how brain states and manifolds\u2014probed at different dimensionalities and scales\u2014flexibly reconfigure (or not) with changes in contexts and mental states is an important research question for understanding complex human cognition. \n\nPrevious studies reported functional relevance of latent state dynamics during controlled ( ;  ;  ;  ;  ) and naturalistic tasks ( ;  ). The current study aimed to unify these findings by generalizing the latent state model to multiple fMRI runs and datasets spanning rest, task, and naturalistic contexts. Intriguingly, the latent states commonly occurred in every scan type ( ), but their functional roles differed depending on context. For example, during monotonous tasks that required constant exertion of sustained attention, the DMN state accompanied successful, stable performance whereas the DAN state characterized suboptimal performance ( ). The antagonistic activity and functional relationship between the DMN and DAN has been reported in past studies that used resting-state ( ;  ) or task fMRI ( ;  ;  ). In contrast, in naturalistic contexts, the DMN state indicated low attentional engagement to narratives ( ) and tended to follow event boundaries ( ). The DAN state, on the other hand, indicated high attentional engagement during documentary watching ( ) and was not modulated by event boundaries ( ). Our results indicate that the functional relationship between the DMN and DAN states shows more nuanced dependence to contexts. (Though our observations align with previous work on the functional roles of the default mode and dorsal attention networks, it is important to keep in mind that the two states are not just characterized by activation of these networks but by patterns of activation and covariation of the whole brain networks. They should be interpreted as \u2018states\u2019 rather than isolated functional networks.) The findings highlight the need to probe both the controlled and naturalistic tasks with dense behavioral sampling to fully characterize the functional roles of these neural states ( ). \n\nIn contrast to the context-specific DMN and DAN states, the SM state consistently indicated inattention or disengagement. The SM state occurred during poor task performance and low narrative engagement ( ) as well as during intermittent task breaks ( ). The result implies that whereas the optimal neural state may vary with information processing demands, a suboptimal state is shared across contexts. \n\nPrevious work showed that time-resolved whole-brain functional connectivity (i.e., paired interactions of more than a hundred parcels) predicts changes in attention during task performance ( ) as well as movie watching and story listening ( ). Future work could investigate whether functional connectivity and the HMM capture the same underlying \u2018brain states\u2019 to bridge the results from the two literatures. Furthermore, though the current study provided evidence of neural state dynamics reflecting attention, the same neural states may, in part, reflect fluctuations in arousal ( ;  ). Complementing behavioral studies that demonstrated a nonlinear relationship between attention and arousal ( ;  ;  ), future studies collecting behavioral and physiological measures of arousal can assess the extent to which attention explains neural state dynamics beyond what can be explained by arousal fluctuations. \n\nPast resting-state fMRI studies have reported the existence of the base state.   used the HMM to detect a state that had \u2018less apparent activation or deactivation patterns in known networks compared with other states.\u2019 This state had the highest occurrence probability among the inferred latent states, was consistently detected by the model, and was most likely to transition to and from other states, all of which mirror our findings here. The authors interpret this state as an \u2018intermediate transient state that appears when the brain is switching between other more reproducible brain states.\u2019 The observation of the base state was not confined to studies using HMMs.   used topological data analysis to represent a low-dimensional manifold of resting-state whole-brain dynamics as a graph, where each node corresponds to brain activity patterns of a cluster of time points. Topologically focal \u2018hub\u2019 nodes were represented uniformly by all functional networks, meaning that no characteristic activation above or below the mean was detected, similar to what we observe with the base state. The transition probability from other states to the hub state was the highest, demonstrating its role as a putative transition state. \n\nHowever, the functional relevance of the base state to human cognition had not been explored previously. We propose that the base state, a transitional hub ( ) positioned at the center of the gradient subspace ( ), functions as a state of natural equilibrium. Transitioning to the DMN, DAN, or SM states reflects incursion away from natural equilibrium ( ;  ), as the brain enters a functionally modular state. Notably, the base state indicated high attentional engagement ( ) and exhibited the highest occurrence proportion ( ) as well as the longest dwell times ( ) during naturalistic movie watching, whereas its functional involvement was comparatively minor during controlled tasks. This significant relevance to behavior verifies that the base state cannot simply be a by-product of the model. We speculate that susceptibility to both external and internal information is maximized in the base state\u2014allowing for roughly equal weighting of both sides so that they can be integrated to form a coherent representation of the world\u2014at the expense of the stability of a certain functional network ( ;  ). When processing rich narratives, particularly when a person is fully immersed without having to exert cognitive effort, a less modular state with high degrees of freedom to reach other states may be more likely to be involved. The role of the base state should be further investigated in future studies. \n\nThis work provides a framework for understanding large-scale human brain dynamics and their relevance to cognition and behavior. Neural dynamics can be construed as traversals across latent states along the low-dimensional gradients, driven by interactions between functional networks. The traversals occur adaptively to external and internal demands, reflecting ongoing changes of cognition and attention in humans. \n\n\n## Materials and methods \n  \n### SitcOm, Nature documentary, Gradual-onset continuous performance task (SONG) neuroimaging dataset \n  \n#### Participants \n  \nTwenty-seven participants were recruited in Korea (all native Korean speakers; two left-handed, 15 females; age range 18\u201330 y with mean age 23 \u00b1 3.16 y). Participants reported no history of visual, hearing, or any form of neurological impairment, passed the Ishihara 38 plates color vision deficiency test ( ) for red-green color blindness, provided informed consent before taking part in the study, and were monetarily compensated. The study was approved by the Institutional Review Board of Sungkyunkwan University. None of the participants were excluded from analysis. \n\n\n#### Study overview \n  \nParticipants visited twice for a 3 hr experimental session per day. Sessions were separated by approximately 1 wk on average (mean 8.59 \u00b1 3.24 d, range 2\u201315 d). Two participants returned for an additional scan and behavioral session because technical difficulties prevented them from completing the experiment within the 2 d. \n\nDuring the first scan session, participants watched the first episode of a sitcom as well as a documentary clip during fMRI. Scan order was counterbalanced. One participant\u2019s sitcom episode 1 fMRI run was not analyzed because the data were not saved. Structural T1 images were collected after EPI acquisitions. Immediately after the MRI scan session, participants completed behavioral tasks in a different room. They first completed free recall of the two movie clips in the order of viewing. These data are not analyzed here but were used to confirm that the participants were awake during the scans. Participants then were asked to complete continuous engagement ratings while rewatching the same audiovisual stimuli in the same order. This fMRI experiment lasted approximately 1 hr, and the post-scan behavioral experiment lasted approximately 1.5\u20132 hr. \n\nThe second scan session began with two 10 min resting state runs in which the participants were asked to fixate on a centrally presented black cross on a gray background. Next, participants completed the gradCPT with face images, watched the second sitcom episode, and performed the gradCPT with scene images. After fMRI, participants completed two runs of a recognition memory task for the scene images that were viewed during gradCPT and a free recall of the sitcom episode 2. These data were not analyzed here. The continuous engagement rating for the second sitcom episode was not collected during this session due to time limitations. 18 of the 27 participants returned to the lab to complete the continuous engagement rating task for the second sitcom episode. One participant\u2019s behavioral data during the gradCPT run with face images were not saved. The fMRI experiment lasted approximately 1.5 hr, and the post-scan behavioral experiment lasted approximately 1 hr. \n\n\n#### Sitcom episodes and documentary watching \n  \n##### Stimuli \n  \nTwo episodes of the comedy sitcom and one educational documentary clip were used as audiovisual stimuli. The sitcom,   High Kick Through the Roof  , is a South Korean comedy sitcom that was aired in 2009\u20132010 on a public television channel, MBC ( ). The duration of the first episode was 24 min 36 s, and the second episode was 24 min 15 s. These episodes were chosen because the narrative followed an interleaved ABAB sequence. Events of a story A (e.g., which took place in a forest and centered around two sisters) happened independently from events of a story B (e.g., which took place in a city and followed members of a large family), and the two storylines occurred in different times and places and included different characters. To avoid a transient increase in fMRI activity upon a sudden video presentation, we included a 30 s of a dummy video clip from the Minions Mini Movies (2019) ( ) prior to the presentations of the sitcom episodes that was discarded in analysis. \n\n Rivers of Korea, Part 1   (21 min 33 s) is a documentary that aired in 2020 by a public educational channel EBS Docuprime in South Korea. The documentary introduces the history and geography of the two largest Korean rivers, the Han and Nakdong Rivers. This stimulus was chosen because while it has rich and dynamically changing audiovisual and narrative content, it elicits an overall low degree of engagement due to its educational purpose (although individuals may vary in the degree to which they find it engaging). The first 22 s of the documentary was not included in the analysis to account for a sudden increase in brain activity upon video presentation. \n\nThe audiovisual stimuli were presented at a visual dimension of 1280 \u00d7 720 and frame rate of 29.97 Hz on a black background. 30 s of center fixation was included at the end of every naturalistic stimulus run. No additional task was given to participants during fMRI except for an instruction to stay vigilant and attentive to the video. \n\n\n##### Continuous engagement rating \n  \nParticipants rewatched the videos in a behavioral testing room while they were instructed to continuously adjust the scale bar from scale of 1 (not at all engaging) to 9 (completely engaging) that was visible on the bottom of the monitor. Participants were instructed to report their experience as closest to when they have watched the stimulus during the fMRI. The definition of engagement was given to participants following   as: I find the story engaging when (i) I am curious and excited to know what\u2019s coming up next, (ii) I am immersed in the story, (iii) My attention is focused on the story, and (iv) The events are interesting; whereas I find the story not engaging when (i) I am bored; (ii) Other things pop into my mind, like my daily concerns or personal events; (iii) My attention is wandering away from the story; (iv) I can feel myself dozing off; and (v) The events are not interesting. Participants were encouraged to adjust the scale bar whenever their subjective engagement changed during the sitcom episodes or documentary. All participants completed a practice session with a clip from a Korean YouTube channel ( ). Stimuli were presented with Psychopy3 ( ) on a MacBook 13-inch laptop. Participants were given freedom to turn on or turn off the light or have the headphone or speaker on. Upon completion of continuous engagement ratings, participants were asked to give an overall engagement score of the stimulus using the same 1\u20139 Likert scale. \n\nContinuous engagement rating time courses, ranging from 1 to 9, were   z  -normalized across time per participant and convolved with the canonical hemodynamic response function to be related with the neural state dynamics. \n\n\n\n\n### Gradual-onset continuous performance task (gradCPT) \n  \n#### Task with face images \n  \nGrayscale face images (nine females and one male unique faces) were selected from the MIT Face Database ( ;  ), cropped to a circle at a visual dimension of 300 \u00d7 300, and presented on a gray background. 500 trials (450 female and 50 male face trials) were included in the run, with each unique face image appearing 50 times in a random sequence. No repeats of the images were allowed on consecutive trials. On each trial, an image gradually transitioned from one to the next using a linear pixel-by-pixel interpolation. The transition took 800 ms, and the intact face image stayed for 200 ms when fully cohered. The task was to press a button on each trial when a female face appeared (90% of trials) but to inhibit making a response when a male face appeared (10% of trials). A fixation cross appeared for the first 1 s of the run, and the trial sequence started with a dummy stimulus (scrambled face). The run ended with a 10 s of center-fixation and lasted 8 min 33 s in total. A practice session was completed with the same face images prior to the scans. \n\n\n#### Task with scene images \n  \nColored scene images (300 indoor, 300 outdoor) were selected from the SUN database ( ;  ). The stimulus was presented at a visual dimension of 500 \u00d7 500 on a gray background. Each individual saw 360 trial-unique images in a random order, with 300 (83.33%) coming from a frequent category (e.g., indoor) and 60 (16.67%) from an infrequent category (e.g., outdoor). Whether the indoor or outdoor scenes corresponded to the frequent category was counterbalanced across participants. Images transitioned in a pixelwise interpolation, with a transition occurring over 500 ms and the intact image lasting 700 ms. Participants were asked to press \u20181\u2019 for frequent-category and \u20182\u2019 for infrequent-category scene images. A fixation cross appeared at first 1 s of the run, and the trial started with a dummy stimulus (scrambled scene). The run ended with a 10 s of center-fixation and lasted 7 min 25 s in total. A practice session was completed with a different set of scene images prior to the scans. \n\n\n#### Response time assignment algorithm \n  \nEach gradCPT trial included moments when an image was interpolated with the previous trial\u2019s image followed by the fully cohered image. A maximum of two responses were recorded per trial. For most trials, a single response or no response was recorded within the trial time window. However, if two responses were recorded in a trial (2.35% and 0.27% of all trials from tasks with face and scene images) and the response for the previous trial was missing, then the first response was regarded as a response for the previous trial and the second response as the response for the current trial. In cases when two responses were recorded but the response for the previous trial was not missing, or when the response for a single response trial happened before 40% of image coherence, we chose a response that favored a correct response. For trials where there were errors in image presentation (two participants during gradCPT scene runs: 1 trial and 18 consecutive trials out of 360 trials) or participants did not respond for consecutive trials (one participant during gradCPT face run: 66 trials out of 500 trials), the accuracy and response times for that trials were treated as NaNs. \n\n\n#### Response time variability \n  \nTo calculate an RT variability time course for each gradCPT run, the response times for incorrect and no-response trials were treated as NaNs, which were then filled by 1D linear interpolation. The response time course was linearly detrended, and RT variability was calculated by taking the deviance from the mean RT at every TR. Because the trial duration of the gradCPT scene runs was 1.2 s, the RT variability time course was resampled to match the TR resolution of 1 s. Each participant\u2019s mean RT variability was appended as the value corresponding to the first TR. The RT variability time course was   z  -normalized across time within run and convolved with the canonical hemodynamic response function to be related with the neural state dynamics. \n\n\n\n### FMRI image acquisition and preprocessing \n  \nParticipants were scanned with a 3T scanner (Magnetom Prisma; Siemens Healthineers, Erlangen, Germany) with a 64-channel head coil. Anatomical images were acquired using a T1-weighted magnetization-prepared rapid gradient echo pulse sequence (repetition time [TR] = 2200 ms, echo time [TE] = 2.44 ms, field of view = 256 mm \u00d7 256 mm, and 1 mm isotropic voxels). Functional images were acquired using a T2*-weighted echo planar imaging (EPI) sequence (TR = 1000 ms, TE = 30 ms, multiband factor = 3, field of view = 240 mm \u00d7 240 mm, and 3 mm isotropic voxels, with 48 slices covering the whole brain). The number of TRs per run are as follows: resting-state run 1 (602 TR) and run 2 (602 TR), gradCPT with face (513 TR) and scene images (445 TR), sitcom episode 1 (1516 TR), episode 2 (1495 TR), and documentary (1303 TR). Visual stimuli were projected from a Propixx projector (vPixx Technologies, Bruno, Canada), with a resolution of 1920 \u00d7 1080 pixels and a refresh rate of 60 Hz. Auditory stimuli were delivered by MRI compatible in-ear headphones (MR Confon; Cambridge Research Systems, Rochester, UK). \n\nStructural images were bias-field corrected and spatially normalized to the Montreal Neurological Institute (MNI) space using FSL. The first two images of the resting-state and gradCPT runs, 30 for sitcom episodes and 22 for documentary were discarded to allow the MR signal to achieve T1 equilibration. Functional images were motion-corrected using the six rigid-body transformation parameters. The functional images were intensity-normalized, and the FMRIB\u2019s ICA-based X-noiseifier (FIX) was applied to automatically identify and remove noise components ( ;  ;  ). The images were registered to MNI-aligned T1-weighted images. We additionally regressed out low-frequency components (high-pass filtering,   f   > 0.009 Hz), linear drift, and the global signal. The raw datasets of the SONG,  , and   were all preprocessed with the same pipeline. Results replicated when processing included band-pass filtering in place of high-pass filtering (0.009 <   f   < 0.08 Hz) and when preprocessing did not include global signal regression ( ). All analyses were conducted in volumetric space. \n\n\n### Human Connectome Project (HCP) dataset \n  \nWe used 3-Tesla and 7-Tesla data from 184 young adult participants in the HCP dataset. 3-Tesla data included four resting-state runs (  REST1   and   REST2   in the left-to-right and right-to-left phase encoding directions) and two runs each of the seven tasks (  EMOTION  ,   GAMBLING  ,   LANGUAGE  ,   MOTOR  ,   RELATIONAL  ,   SOCIAL  , and   WORKING MEMORY  ). 7-Tesla data included four resting-state runs (  REST1_PA  ,   REST2_AP  ,   REST3_PA  ,   REST4_AP  ) and four movie-watching runs (MOVIE1  _AP  , MOVIE2  _PA  , MOVIE3  _PA  , MOVIE4  _AP  ). The combined data included 8400 TRs of the resting-state runs, 3880 TRs of task runs, and 3655 TRs of the movie-watching runs per participant. Of these 184 individuals, we excluded 19 who had not completed any of the scan runs, and 6 whose scan run was aborted earlier than others. Additionally, 40 participants\u2019 data were discarded due to excessive head motion; having at least one fMRI run with more than 20% of the time points\u2019 framewise displacement (FD) \u2265 0.5 or mean FD \u2265 0.5. This resulted in the analysis of 119 participants in total. We downloaded the MNI-aligned, minimally preprocessed structural and functional MRI images from the HCP repository ( ). Additionally, the global signal, white matter, and cerebrospinal fluid time courses, 12 head motion parameters (provided by Movement_Regressors.txt), and a low-frequency component (high-pass filtering,   f   > 0.009 Hz) were regressed from the data. For details on fMRI image acquisitions and task procedures, see  ;  ;  . \n\n\n### Hidden Markov model (HMM) \n  \nWe used the HMM to characterize the dynamics of latent neural states that underlie large-scale functional brain activity ( ). First, we parcellated the whole brain into 17 cortical networks ( ) and 8 subcortical regions ( ) and averaged the BOLD time series of the voxels that corresponded to these parcels. The 25 parcel time courses of all participants\u2019 every run were   z  -normalized within-run and concatenated. \n\nExpectation-maximization ( ) of the forward-backward algorithm was used to estimate the optimal model parameters: (i) the emission probability   p  (  |  ) of the observed fMRI time series {   \u2026   } from the hidden latent sequence {   \u2026   }, and (ii) the first-order Markovian transition probabilities   p  (  |  ) for 1  ,  . The emission probability was modeled using a mixture Gaussian density function (hmmlearn.hmm.GaussianHMM), such that   p  (  |  ) ~   =   per discrete   number of latent state   \u2208 {   \u2026   }, where   =   and   =   for a set of observed fMRI time steps {   \u2026   } identified as the latent state  . The   and   represent the mean activation and covariance patterns of the 25 parcels per each state ( ). The transitions between the hidden states were assumed to have a form of a first-order Markov chain, such that if   represents the probability of transitioning from state   i   to state   j  , then   = 1. The inference procedure terminated if there was no longer a gain in log-likelihood during the re-estimation process of the forward-backward algorithm or if the number of maximum 1000 iterations was reached. We initialized the HMM parameters using the output of k-means clustering to overcome the problem of falling into a local minima (sklearn.cluster.kMeans). \n\nThe estimated transition and emission probabilities were applied to decode the most probable latent state sequence conditioned on the observed fMRI time series using a Viterbi algorithm ( ). The Viterbi algorithm estimates the probability of each latent state being the most likely state at a specific time point. We chose the state with the highest probability at every time step (TR), thus discretizing the latent sequence. \n\nTo choose the optimal number of latent states (K), a hyperparameter that needed to be selected in advance, we conducted the HMM in a leave-one-subject-out cross-validated manner where we trained the HMM on all participants but one to infer transition and emission probabilities, and applied the HMM to decode the latent state dynamics of the held-out participant. A Calinski\u2013Harabasz score was compared across the choice of K from 2 to 10 ( ;  ;  ;  ). The K with the largest mean Calinski\u2013Harabasz score across cross-validations was selected, and we conducted the HMM on all participants\u2019 data with the chosen K. The HMM inference and decoding procedure was repeated 10 times, and the instance with the maximum expected likelihood was chosen as a final result. \n\nThe surrogate latent sequence was generated by having 25-parcel time series circular-shifted across time respectively for each parcel, thereby disrupting meaningful covariance between parcels while retaining temporal characteristics of the time series, and applying the same HMM fitting and decoding algorithms 1000 times. The maximum number of estimations was set as the number of iterations that was reached during the actual HMM procedure (1000 for SONG and 248 for HCP). \n\nUnless otherwise noted, the HMM parameter inference was conducted on the SONG and HCP datasets respectively and the model decoded latent state sequence of the same dataset. However, for analyses validating the functional roles of the latent states, the parameters inferred from SONG data were used to decode the latent state sequence of external datasets collected by ( ),   ( ,  ),   ( ), and working memory runs of the HCP dataset ( ;  ;  ). \n\n shows mean activity and covariance patterns derived from the Gaussian emission probability estimation. The brain surfaces were visualized with nilearn.plotting.plot_surf_stat_map. The parcel boundaries in   are smoothed from the volume-to-surface reconstruction. \n\nCovariance strength was operationalized as the sum of the absolute covariance weights of all possible pairwise edges. Covariance strength calculated for each latent state was compared to chance distributions generated from covariance matrices estimated from the HMMs conducted on the circular-shifted 25 parcel time series (1000 iterations, two-tailed non-parametric permutation tests, FDR-corrected for the number of latent states). \n\n\n### Predefined and data-driven functional connectivity gradients \n  \nThe gradients of the cortical and subcortical voxels estimated by   were downloaded from the repository ( ). The gradient values of the voxels within each of the 25 parcels were averaged to represent each parcel\u2019s position in the gradient space. To situate the latent states in Margulies et al.\u2019s (2016) gradient axes, we took the mean of element-wise product between these gradient values and the mean activity loadings of the 25 parcels inferred by the HMM. To ask whether the four latent states are maximally distant from one another, we computed the Euclidean distance between every pair of latent states in the two-dimensional gradient space. The mean distance between all pairs of states was compared to a chance distribution where the null latent states were derived from HMM inferences on the circular-shifted 25 parcel time series (1000 iterations, two-tailed non-parametric permutation tests). Furthermore, to test whether the latent states were positioned at more extreme ends of the gradients than expected by chance, we situated the same null latent states in the gradient space. Each latent state\u2019s position on each gradient axis was compared to a chance distribution. The significance was FDR-corrected for eight comparisons (four latent states on two-dimensional axes). \n\nWe evaluated how well these predefined gradients captured large-scale neural dynamics compared to data-driven gradients defined from the SONG and HCP datasets. To do so, we extracted fMRI time series from the 1000 cortical ROIs of   and 54 subcortical ROIs of  . The 1054 ROI time series were   z  -normalized across time, and the time series from multiple scan runs were concatenated within each participant. All participants\u2019 1054 ROI-by-ROI functional connectivity matrices were averaged. As in  , the average functional connectivity matrix was thresholded row-wise at 90% for sparseness. The affinity matrix was computed using cosine distance and then decomposed using diffusion embedding. The variance of the functional connectome explained by each gradient was computed by taking the ratio of its eigenvalue to the sum of all eigenvalues. \n\nFirst, to compare the predefined gradients and data-specific gradients, we calculated Pearson\u2019s correlations across the two 1054 parcels\u2019 gradient embeddings. Next, we computed the variance that the predefined and data-specific gradients explained in the 1054 ROI time series of the SONG and HCP datasets. The fMRI time series were projected onto the first two gradient axes by taking the mean of element-wise product between the fMRI time series (time \u00d7 1054 ROIs) and the gradient embeddings (1054 ROIs \u00d7 2). The explained variance was calculated by the mean of squared Pearson\u2019s correlations ( ) between the 1054 ROI fMRI time series (time \u00d7 1054 ROIs) and the gradient-projected time series (time \u00d7 2). All participants\u2019 all runs were concatenated to compute one   per gradient axis. The explained variance of the first two gradients was equal to the sum of two   values. \n\n\n### Cofluctuation time course time-aligned to neural state transitions \n  \nCofluctuation, the absolute element-wise product of the normalized activity in two regions, was computed based on  ;  . We normalized the time courses of the two regions among the 25 parcels,   and   ( =1 ... T and   = 1 ... T), such that   =  , where   =  \u2009and   =  . The cofluctuation time series between   and   was computed as the absolute of the element-wise product, |   |, which represents the magnitude of moment-to-moment cofluctuations between region   and   based on their baseline activities. Cofluctuation was computed for every pair of parcels, resulting in a time-resolved, 25 (parcel) \u00d7 25 \u00d7 T (number of TRs) matrix for each fMRI run, with a symmetric matrix at every time point. \n\nWe categorized the 25-parcel pairs to cortico-cortical (136 pairs), cortico-subcortical (136 pairs), and subcortico-subcortical (28 pairs) connection categories. The cofluctuation time courses were time-aligned to multiple moments of state transitions indicated by the HMM inference, which were averaged within a participant. The time-aligned mean cofluctuation of each pair was then averaged across all runs of the entire participants. \n\nThe chance distributions were created in two ways. First, cofluctuation time courses were time-aligned to the circular-shifted indices of neural state transitions (1000 iterations;  ). Second, we circular-shifted the 25-parcel time series, thereby disrupting their covariance structure, and conducted HMM inference on these null time series (1000 iterations;  ). The time-aligned cofluctuation of every pair of parcels was averaged per category and was compared to chance distributions using   z  -statistics and two-tailed non-parametric permutation tests. The significance at each time point was FDR-corrected for the number of time points (i.e., \u20133 to 3 from the onset of new latent states). Furthermore, to compare the degrees of cofluctuation change between cortico-cortical, cortico-subcortical, and subcortico-subcortical connection categories, mean cofluctuation difference at time   t-1   and   t+3   was taken per category and the values were compared across categories using paired Wilcoxon signed-rank tests (FDR-corrected for three pairwise comparisons). \n\n\n### Neural state transition probabilities \n  \nThe   T-1   number of transitions in each participant\u2019s latent state sequence were categorized based on which state it transitioned from (at   t-1  ) and which state it transitioned to (at   t  ) as a 4 (\u2018from\u2019 state) \u00d7 4 (\u2018to\u2019 state) transition-count matrix. We controlled for the number of state occurrences by either dividing each element by the sum of each row, which identified the probabilities of transitioning \u2018to\u2019 one of the four latent states ( ), or dividing by the sum of each column, which identified the probabilities of transitioning \u2018from\u2019 one of the four latent states ( ). The transition probability matrices estimated from every participant\u2019s every run were averaged. The chance distribution was created by conducting the HMM fits on the circular-shifted 25 parcel time series (1000 iterations). Significance was computed for each state pair of the transition matrix using the two-tailed non-parametric permutation tests (FDR-corrected for 16 pairs). \n\n\n### Global cofluctuation of the latent states \n  \nCofluctuation time courses of all pairs of parcels were averaged within a run of each participant. This global cofluctuation measure at every TR was categorized based on the HMM latent state identification, which was then averaged per state ( ). Cofluctuation values of the base state of all participants\u2019 entire runs were compared with the DMN, DAN, and SM states\u2019 using the paired   t  -tests (FDR-corrected for three comparisons). The values at each latent state were averaged and compared to a chance distribution in which the analysis was repeated with a circular-shifted latent state sequence (1000 iterations, two-tailed non-parametric permutation tests, FDR-corrected for the number of states). \n\n\n### Fractional occupancy of the latent states \n  \nUsing the HMM-derived latent state sequence, we calculated fractional occupancy of the latent states for all participants\u2019 every run. Fractional occupancy is the probability of latent state occurrence over the entire fMRI scan sequence, with a chance value of 25% when K = 4. The mean of all participants\u2019 fractional occupancy values was bootstrapped (10,000 iterations) for visualization in  . \n\n\n### Pairwise participant similarity of the latent state sequence \n  \nThe similarity between pairs of participants\u2019 latent state sequences was computed as the ratio of the times when the same state occurred over the entire time course. The mean similarity was compared to the chance distribution in which participants\u2019 neural state dynamics were circular-shifted 1000 times (FDR-corrected for the number of fMRI runs). To compare the degree of synchrony across conditions, we bootstrapped the same pairs of participants with replacement   iterations, where N = number of participants) in paired conditions and took the differences of bootstrapped participant pairs\u2019 latent state sequence similarities. The median of these differences was extracted 1000 times, and the distribution was compared to 0 non-parametrically. \n\n\n### Neural state dynamics at narrative event boundaries \n  \nNarrative event boundaries were marked by the experimenter at moments in the sitcom episodes when an event of a storyline transitioned to another event of a different story. Both sitcom episodes comprised 13 events (seven events of story A and six events of story B), and thus 12 event boundaries. The latent state sequences at   t-2   and   t+20   TRs from each of the 12 event boundaries were extracted, and the mean probability of state occurrence across these event boundaries was computed for every latent state within a participant. The probabilities were then averaged across participants. The state occurrence probability at every time step was compared to a chance distribution that was created by relating neural state dynamics to circular-shifted moments of event boundaries (1000 times, two-tailed non-parametric permutation tests, FDR-corrected for number of time points). An audio-story listening data of   comprised 45 interleaved events. Because TR resolution (TR = 1.5 s) was different from the SONG dataset, latent neural states from   t-2   to   t+16   TRs from event boundaries were used in analysis. \n\nNext, we compared transitions made to the DMN state at event boundaries to transitions made to the DMN state at moments other than event boundaries. We categorized every transition to the DMN state (i.e., from the DAN, SM, or base state) based on whether it occurred 5\u201315 TRs (for  , 4\u201312 TRs) after a narrative event boundary or not. The proportions of DAN-to-DMN, SM-to-DMN, and base-to-DMN state transitions at event boundaries and non-event boundaries were compared using paired Wilcoxon signed-rank tests (FDR-corrected for three comparisons). The interaction between the DMN-preceding latent states and event boundary conditions was tested using the repeated-measures ANOVA. \n\n\n### Neural state dynamics related to attention dynamics \n  \nWe measured participants\u2019 attention fluctuations during gradCPT and movie-watching fMRI scans. Fluctuations during gradCPT performance were inferred from the inverted RT variability time course (  z  -normalized) collected concurrently during the gradCPT scans with face and scene images, as well as during gradCPT in the   dataset. Continuous engagement rating time courses (  z  -normalized) collected after the sitcom episode and documentary watching scans were used to infer changes in the degree to which the naturalistic stimuli were engaging over time. Engagement ratings of the Sherlock dataset ( ) were collected by   from an independent group of participants. \n\nTo relate attentional dynamics to the occurrence of neural states, we categorized each person\u2019s attention measure at every TR based on the HMM latent state identification, which was averaged per state. The mean attention measures of the four states were averaged across participants and compared to a chance distribution in which the attention measures were circular-shifted to be related to the latent state dynamics (1000 iterations, two-tailed non-parametric permutation tests, FDR-corrected for the number of states). For Sherlock dataset only, a single group-average engagement time course was related to the latent state sequence of each fMRI participant because we did not have fMRI participant-specific behavioral ratings. \n\nLinear mixed-effects models were conducted on the seven fMRI runs ( ), where the model predicted attention measure at every time step from the inferred HMM state indices and head motion (framewise displacement computed after fMRI preprocessing). The participant index was treated as a random effect. The significance of the two main effects and their interaction were computed using ANOVA. \n\nTo investigate the role of the SM state, we analyzed the gradCPT data collected by   and two sessions of the HCP working memory task ( ). The   dataset (N = 25) included gradCPT task blocks separated by intervening fixation blocks. The working memory task run of the HCP dataset included 2-back and 0-back working memory task blocks and fixation blocks (N = 119). Nine participants\u2019 left-to-right phase encoding runs and 11 participants\u2019 right-to-left phase encoding runs in the HCP working memory dataset were discarded in the analysis either because their block orders differed from the other HCP participants\u2019 or because the experiment log was not saved in the dataset repository. Latent state fractional occupancy values were computed for each task block within a participant. Comparisons of a state\u2019s fractional occupancies across block types were based on paired   t  -tests (FDR-corrected for the number of states). The interaction between latent neural states and task block types was tested using repeated-measures ANOVA. \n\n\n \n", "metadata": {"pmcid": 10400080, "text_md5": "164b7463b6a0a895e4373c518c7e2ecd", "field_positions": {"authors": [0, 55], "journal": [56, 61], "publication_year": [63, 67], "title": [78, 188], "keywords": [202, 286], "abstract": [299, 1488], "body": [1497, 103860]}, "batch": 1, "pmid": 37395724, "doi": "10.7554/eLife.85487", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10400080", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=10400080"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10400080\">10400080</a>", "list_title": "PMC10400080  Large-scale neural dynamics in a shared low-dimensional state space reflect cognitive and attentional dynamics"}
