{"text": "Oldham, Stuart and Murawski, Carsten and Fornito, Alex and Youssef, George and Y\u00fccel, Murat and Lorenzetti, Valentina\nHum Brain Mapp, 2018\n\n# Title\n\nThe anticipation and outcome phases of reward and loss processing: A neuroimaging meta\u2010analysis of the monetary incentive delay task\n\n# Keywords\n\nanticipation\nloss\nmonetary incentive delay task\noutcome\nreward\n\n\n# Abstract\n \nThe processing of rewards and losses are crucial to everyday functioning. Considerable interest has been attached to investigating the anticipation and outcome phases of reward and loss processing, but results to date have been inconsistent. It is unclear if anticipation and outcome of a reward or loss recruit similar or distinct brain regions. In particular, while the striatum has widely been found to be active when anticipating a reward, whether it activates in response to the anticipation of losses as well remains ambiguous. Furthermore, concerning the orbitofrontal/ventromedial prefrontal regions, activation is often observed during reward receipt. However, it is unclear if this area is active during reward anticipation as well. We ran an Activation Likelihood Estimation meta\u2010analysis of 50 fMRI studies, which used the Monetary Incentive Delay Task (MIDT), to identify which brain regions are implicated in the anticipation of rewards, anticipation of losses, and the receipt of reward. Anticipating rewards and losses recruits overlapping areas including the striatum, insula, amygdala and thalamus, suggesting that a generalised neural system initiates motivational processes independent of valence. The orbitofrontal/ventromedial prefrontal regions were recruited only during the reward outcome, likely representing the value of the reward received. Our findings help to clarify the neural substrates of the different phases of reward and loss processing, and advance neurobiological models of these processes. \n \n\n# Body\n \n## INTRODUCTION \n  \nIndividuals must constantly make effective decisions that minimise harm and enhance well\u2010being (Fellows,  ). Reward processing is crucial for directing actions towards positively valanced stimuli like rewards, while loss processing (also termed negative reward processing), facilitates the avoidance of negative outcomes, such as punishments (Lutz & Widmer,  ). Reward and loss processing can be characterised by two distinct temporal phases\u2014an anticipation phase, where the prospect of a reward/loss is initially encountered, and an outcome phase (also called the receipt phase), where the reward/loss is received or omitted (Haber & Knutson,  ; Knutson, Westdorp, Kaiser, & Hommer,  ; Knutson, Fong, Adams, Varner, & Hommer,  ; Lutz & Widmer,  ). \n\nMany functional Magnetic Resonance Imaging (fMRI) studies have examined the neural correlates of reward and loss processing (Wang, Smith, & Delgado,  ). Several meta\u2010analyses have synthesised the results of hundreds of fMRI studies examining reward and loss processing in healthy human adults (Bartra, McGuire, & Kable,  ; Clithero & Rangel,  ; Diekhof, Kaps, Falkai, & Gruber,  ; Knutson & Greer,  ; Liu, Hairston, Schrier, & Fan,  ) and adolescents (Silverman, Jedd, & Luciana,  ), with two key findings emerging so far. First, anticipating and receiving a reward recruits the ventral striatum, likely representing an initial prediction signal, and a positive prediction error signal (i.e., \u2018a better than expected outcome\u2019) respectively (Diekhof et al., 2012; Galtress, Marshall, & Kirkpatrick,  ; Haber & Knutson,  ; O'Doherty et al.,  ). Receiving a reward recruits the orbitofrontal (OFC) and ventro\u2010medial prefrontal (vmPFC) cortical regions (due to the uncertain anatomical and functional distinctions between the OFC and vmPFC, we present these as synonymous unless otherwise noted), which represent the subjective reward value (Galtress et al.,  ; Levy & Glimcher,  ; Peters & B\u00fcchel,  ). Yet, outstanding issues prevent the understanding of the neural substrates of reward and loss processing. It remains unclear whether reward and loss anticipation are dissociable or overlapping at a neural level, and whether the OFC/vmPFC are involved in either the anticipation of reward, its receipt, or both. \n\nThe evidence to date does not address whether the neural substrates of anticipation/receipt of loss   and   reward either dissociate or overlap as the findings are mixed. Some studies ascribe reward and loss processing (across both anticipation and receipt) to dissociable neural systems including the ventral striatum, and anterior insula and amygdala, respectively (Hardin, Pine, & Ernst,  ; Knutson, Fong, Bennett, Adams, & Hommer,  ; Liu et al.,  ; Yacubian et al.,  ). Other studies suggest striatal activity is engaged during loss and reward processing, especially their anticipation (Breiter, Aharon, Kahneman, Dale, & Shizgal,  ; Carter, Macinnes, Huettel, & Adcock,  ; Cho et al.,  ; Kohls et al.,  ; Pfabigan et al.,  ), where midbrain dopamine systems engage during stimulus approach or avoidance (Brooks & Berns,  ; Pfabigan et al.,  ; Salamone & Correa,  ). Behavioural and psychological data have also not shown clear distinctions between these processes (Baron & Galizio,  ), thus similar neural mechanisms may underlie both. Previous meta\u2010analytic work on reward and loss anticipation has been limited in their ability to establish how similar or distinct reward and loss processing are, due to limited examination of loss processing (Bartra et al.,  ; Knutson & Greer,  ), or not examining temporal and valence interactions (Liu et al.,  ). \n\nWhile the evidence to date shows that the OFC/vmPFC plays a key role in reward processing (Bartra et al.,  ; Diekhof et al.,  ; Knutson & Greer,  ; Liu et al.,  ), it remains unclear if the OFC/vmPFC is implicated during the anticipation or the receipt of rewards (or both). Some studies show responses specific to receiving rewards (Bjork, Smith, Chen, & Hommer,  ; Kirk, Brown, & Downar,  ; Knutson et al.,  ,  ), yet others report it is active during both phases of reward processing (Breiter et al.,  ; Haber & Knutson,  ; Kim, Shimojo, & O'Doherty, 2011; Liu et al.,  ; Peters & B\u00fcchel,  ; Rushworth, Noonan, Boorman, Walton, & Behrens,  ). More work is needed to elucidate whether the OFC/vmPFC are linked to specific temporal phases of reward processing. \n\nMethodological limitations in the literature to date may prevent accurate mapping of the neural substrates of reward processing (i.e., striatal recruitment during reward and loss anticipation; OFC/vmPFC involvement in reward anticipation versus receipt). First, meta\u2010analyses of reward/loss processing to date have used outdated Activation Likelihood Estimation (ALE) techniques affected by within\u2010experiment bias and implementation errors, increasing the risk of false positives (Eickhoff et al.,  ; Eickhoff, Laird, Fox, Lancaster, & Fox,  ; Turkeltaub et al.,  ), though recently available ALE techniques address this issue. \n\nSecond, heterogeneous reward processing tasks and task stimuli may systematically confound the findings to date. Tasks used to measure reward/loss could vary substantially in their complexity. For instance, some tasks required only a single, rapid response to obtain a reward, whereas in others a correct response needed to be selected from multiple alternatives and the optimal alternative would need to be learned overtime. Different reward/loss tasks types require different cognitive demands and abilities, which in turn recruit different neural patterns of activity within and outside the reward and loss systems (Balodis & Potenza,  ; DePasque Swanson & Tricomi,  ; Lutz & Widmer,  ; Richards, Plate, & Ernst,  ). This includes OFC/vmPFC activity, which can vary with probability contingencies, effort and the temporal delay between response and outcome (Haber & Knutson,  ). Additionally, heterogeneous task stimuli (e.g. monetary, verbal feedback or food), may engage distinct cognitive processes and reward related networks (Bartra et al.,  ; Clithero & Rangel,  ; Liu et al.,  ). For example, monetary rewards, compared to food and erotica, engage less activity in the amygdala/insula and uniquely engage the anterior OFC (Sescousse, Cald\u00fa, Segura, & Dreher,  ). \n\nThis meta\u2010analysis builds upon previous work to map the neurobiology of reward and loss processing in healthy adults by addressing limitations of previous meta\u2010analyses to date. We aimed to address the confounding effect of task and stimuli heterogeneity by focusing on one specific task; the Monetary Incentive Delay Task (MIDT, explained in Figure  ). \n  \nThe structure of the MIDT. (a) Examples of cues signifying trial type (e.g. a square with two lines indicates a punishment trial where $5 can potentially be lost, a circle with a single line indicates a reward trial where $1 can potentially be obtained). (b) Time course of a trial on the MIDT. In the cue stage (first screen), corresponding to the anticipation phase of reward/loss processing, a symbol appears indicating the trial type (reward, loss or neutral). After a delay (second screen) a target appears (third screen), and participants are instructed to press a button as quickly as possible when the target appears. If participants press the button quickly enough they gain money (reward trials) or avoid losing money (loss trials) and are informed of this during the feedback stage (fourth screen), corresponding to the outcome phase. The time window within which the participant has to make a response to obtain a successful outcome is constantly adjusted such that the participant succeeds on an expected 60\u201066% of trials (Knutson et al.,  ). Note that the timings depicted are an example only. These timings vary from study to study \n  \nThe MIDT is the most consistently used task to probe the neural substrates of reward and punishment processing in humans (about 200 MRI studies so far) (Lutz & Widmer,  ) and has been developed based on pre\u2010clinical findings that anticipating a reward engages dopaminergic neurons in the ventral tegmental area (VTA) (Knutson et al.,  ). Advantages of focusing on the MIDT include: (i) it allows modelling the interaction between valence and temporal phase (i.e. reward and loss anticipation, reward and loss outcome); (ii) it requires a simple decision, minimising cognitive confounds (e.g. complex decision making) (Balodis & Potenza,  ; Knutson & Greer,  ; Lutz & Widmer,  ); and (iii) it robustly engages the striatum, which is critical in reward processing (Haber & Knutson,  ) and can be difficult to image when using fMRI (Knutson & Cooper,  ; O'Doherty,  ; Walter, Stadler, Tempelmann, Speck, & Northoff,  ). \n\nBased on the issues summarised, we aim to identify patterns of neural activity of reward and loss anticipation, and for reward anticipation and receipt, by conducting a meta\u2010analysis of 50 studies that used the MIDT in healthy adults, with an updated version of the ALE technique that minimise positive biases (Eickhoff et al.,  ). Based on the evidence to date, we examine if reward and loss anticipation would recruit a common neural substrate\u2014the striatum\u2014or if these processes are clearly distinguishable. Secondly, we explore whether the OFC/vmPFC would be engaged only during reward receipt or reward anticipation as well. \n\n\n## METHOD \n  \n### Sample selection \n  \nWe conducted searches in PubMed and Scopus using the terms \u201cMonetary Incentive Delay Task AND fMRI\u201d on 22 July 2016 and identified 300 studies (173 for PubMed and 127 for Scopus), which was reduced to 182 unique studies when duplicates were removed. In addition, if it was evident that studies used overlapping or the same sample (e.g. Boecker\u2010Schlier et al.,  ; Boecker et al.,  ; Hommer et al., 2003; Knutson et al.,  ) then only one of those was used (either the first published or one for which activation coordinates could be obtained). \n\nFMRI studies of healthy human adults were selected if they included the following contrasts: reward anticipation versus neutral anticipation/no\u2010incentive anticipation (reward anticipation phase), punishment/loss anticipation versus neutral anticipation/no\u2010incentive anticipation (loss anticipation phase), and successful reward/gain outcome versus unsuccessful reward outcome/neutral trial outcome (reward outcome phase). We did not examine the contrast loss outcome versus avoided loss outcome/neutral outcome (loss outcome phase), as this was reported by less than 20 studies, which is insufficient for robust ALE meta\u2010analytic estimates (Eickhoff et al.,  ). \n\nThe ALE meta\u2010analysis technique assumes that the activation foci are obtained through a whole brain analysis. We thus excluded results from region\u2010of\u2010interest analyses. As shown in Table  , we included studies using modified versions of the original MIDT (Knutson et al.,  ) (and classified each study according to the original MIDT version), if these (i) retained the same basic task structure and key stages\u2014specifically, a cue stage where the cue is visualised and no choice or action has to be made; a target stage, where a response is made as fast as possible to an appearing target; and a feedback stage presenting the trial outcome; (ii) assessed a contrast of interest in a relevant stage; (iii) participants played for their own gain. If a study used the original MIDT version in a hybrid format with additional elements, the study was classified as having used the original version. \n  \nStudies included in the present meta\u2010analysis \n    \nMost MIDT studies that we included used the same contrast for examining reward/loss anticipation to neutral anticipation, where neutral trials led to no win/loss of money regardless of performance. We also included two studies (Bustamante et al.,  ; Costumero et al.,  ) that compared reward/loss anticipation versus no\u2010incentive anticipation\u2014whereby a cue informs that the trial is a \u2018no\u2010incentive type\u2019 and the task does not have to be performed, as no target will follow the cue. Therefore, a no\u2010incentive trial type may lack any activity related to action planning, which has a key role in reward/loss processing (Cooper & Knutson,  ). To ensure that the use of no\u2010incentive trials was not biasing the result, we ran the analysis both with and without the studies that used such a contrast. \n\nWe used two different types of contrasts to examine the construct of \u2018reward receipt\u2019 (i) \u201csuccessful (i.e., gain of reward on a reward trial) versus unsuccessful (not gaining a reward during a reward trial)\u201d, (ii) \u201csuccessful versus neutral (neutral outcome received on a neutral trial)\u201d. Using either contrast alone would have resulted in an underpowered analysis. However, we ran an exploratory ALE conjunction and subtraction analysis to compare these two contrast types to see if they produced different patterns of activation. \n\nWe also included one study (Bjork, Smith, Chen, & Hommer,  ) that used a contrast of successful versus unsuccessful reward outcome for reward trials\u2014but masked out the neural activity from the outcome of \u201cHit\u201d trials (i.e., notifying participants, after target response, they would not receive a monetary reward regardless of performance). This construct was conceptually similar to the contrasts of interest, as the \u201cHit\u201d trials resembled a neutral trial outcome. \n\nVariability across studies in terms of the length of reward anticipation trials may confound results, since activation in some regions, such as the OFC/vmPFC, may only occur during lengthy anticipation phases (Diekhof et al.,  ). We performed additional analyses to ascertain whether this activation was driven by either the length of interval between reward\u2010anticipatory cue and feedback, or by a jittered time interval in trials between cue and feedback. Specifically, we grouped studies by the length of reward anticipation\u2014defined as the time from initial exposure to the reward cue until presentation of the target within a trial. Anticipation trials were less than 3000ms in duration for 18 studies (short duration), and between 3000ms and 6000ms in duration for 22 studies (long duration). The cut\u2010off of 3000ms was chosen as it represented a clear threshold discriminating anticipation durations of different studies, and choosing a lower/higher cut off point would have led to an underpowered analysis (as at least one of the groups would be substantially below the recommended number of studies). We then ran a single ALE analysis separately for the short duration and long duration groups of studies, followed by a conjunction/subtraction ALE analysis to determine the similarities/difference in activation when different anticipatory durations are used. \n\nIf a study used different magnitudes (e.g. $1 and $5), then only the result where both magnitudes were combined into a single contrast was used. If this combined contrast was unavailable, then only the result for the highest magnitude was used. An additional analysis was conducted to assess if similar patterns of activation likelihood during reward anticipation are observed when only a low magnitude (less than $2 USD or equivalent) is used, in order to determine whether the results of our meta\u2010analysis were driven by using studies using different reward magnitudes. There was an insufficient number of studies that reported loss anticipation with low magnitudes to conduct a meaningful analysis for this contrast. \n\nFinally, we converted all foci that were in Talairach space to MNI space using the Lancaster transformation function (Lancaster et al.,  ), so the results were in the same coordinate space. \n\n\n### Activation likelihood estimation (ALE) \n  \n#### Single analysis \n  \nWe performed the meta\u2010analysis using the ALE technique implemented in the GingerALE software package (version 2.3.6,  ) (Eickhoff et al.,  ; Eickhoff, Bzdok, Laird, Kurth, & Fox,  ; Eickhoff et al.,  ). ALE treats activation foci from each given brain coordinate as a three\u2010dimensional spatial Gaussian probability density with a full\u2010width half maximum (FWHM) derived from the number of subjects in each study, so that using more subjects results in a smaller FWHM, with increased certainty that an activation occurred at that voxel. This method accounts for the spatial uncertainty associated with neuroimaging results (Eickhoff et al.,  ; Eickhoff et al.,  ). \n\nWe used the analysis pipeline outlined below (termed a single analysis) to examine neural activity relative the following contrasts: reward anticipation versus neutral anticipation/no\u2010incentive anticipation (i.e. reward anticipation), punishment anticipation versus neutral anticipation/no\u2010incentive anticipation (i.e. loss anticipation), and successful reward outcome versus unsuccessful reward outcome/neutral trial outcome (i.e. reward outcome). \n\nThe non\u2010additive ALE method was used to create a Modelled Activation (MA) map for each experiment (Turkeltaub et al.,  ). This method takes the maximum value of the Gaussian distributions encompassing a given voxel (as multiple Gaussians may overlap a single voxel), and thereby reduces the chance that the final ALE result is overly biased by any one single experiment. Then, the MA maps were combined to produce a statistical whole\u2010brain map where each voxel has an ALE value indicating its probability of activation. Next, non\u2010linear histogram integration was used to find the null distribution of ALE values under spatial independence, to ensure the results were not due to random convergence (Eickhoff et al.,  ). For this step, each MA map was converted to a histogram, thus removing spatial information. This histogram contained all the possible MA\u2010values sorted into bins. These histograms were then divided by the total number of voxels in the MA map and produced a probability of obtaining a given MA value. A table of   p  \u2010values for each ALE value\u2014indicating the probability of obtaining a particular value\u2014was then computed by combining these probabilities for each individual experiment. \n\nTo identify significant clusters of activation, cluster\u2010level inference was used (Eickhoff et al.,  ). First, a cluster\u2010forming threshold of 0.001 uncorrected was applied to identify areas of significant activation. A false\u2010discovery rate (FDR) threshold, which has often been used in previous meta\u2010analyses, was not used as this method is highly susceptible to false\u2010positives (Chumbley & Friston,  ; Eickhoff et al.,  ,  ). Next, these clusters were compared to an empirically derived null distribution of cluster sizes. To do this, a random data set was created with the same number of experiments, foci per experiment and subjects per experiment as the real data, but with the foci coordinates randomly distributed amongst these groups. An ALE analysis was then run on the randomised data (using the cluster\u2010forming threshold to identify clusters of activation). This process was repeated 5,000 times to create a null distribution of cluster sizes. The clusters identified in the real data were then assigned a   p  \u2010value based on the number of clusters in the null distribution which exceeded it in size. We used a cluster\u2010level threshold of 0.05 (i.e. a cluster was significant if less than 5% of all randomly formed clusters were greater in size) to identity significant clusters of activation (Eickhoff et al.,  ). Notably, this method, known as \u2018cluster\u2010level family\u2010wise error (FWE) correction\u2019, recently had an implementation error corrected (which could lead to non\u2010significant small clusters being incorrectly labelled as significant) in the 2.3.6 release of GingerALE (Eickhoff et al.,  ). Simulations using empirical data have found cluster\u2010level FWE corrections to be most appropriate for statistical inference (Eickhoff et al.,  ). \n\n\n#### Conjunction and subtraction analysis \n  \nConjunction analyses were run to identify areas of shared activation between reward anticipation and loss anticipation, and between reward anticipation and reward outcome, by taking the minimum value at each voxel of the two ALE maps, as calculated in the single analysis step. For these contrasts, a subtraction analysis was run to identify distinct areas of activation (Eickhoff et al.,  ), by repeating the following process 5,000 times: (i) all the results that contributed to either of the two contrasts being examined, were pooled and randomly split into two groups that were the same size as in the original data, (ii) for each of these randomly derived groups, an ALE score was calculated at each voxel, (iii) the difference between these ALE scores was recorded. Once finished, the ALE values were collated across all permutations to yield an empirical null distribution that was used for statistical inference. Next, a   p  \u2010value was assigned to each voxel based on how many times the difference in the null distribution exceed the actual difference between the two groups. Finally, a threshold of   p  \u2009<\u20090.001 uncorrected with a minimum cluster size of 100mm  was applied to identify significant differences between the two contrasts and a   Z  \u2010score was also obtained at each voxel to indicate the size of any such differences. \n\n\n\n\n## RESULTS \n  \n### MIDT and sample characteristics \n  \nWe meta\u2010analysed 50 studies that comprised a total of 1,271 participants (718 males). Table   indicates the characteristics of each study including: the number of participants, the MIDT type used the contrasts used from each study. Of the included studies, 43 studies were obtained via a literature search, and seven via cross\u2010referencing (Bjork et al.,  ,  ; Filbey, Dunlop, & Myers,  ; Knutson, Adams, Fong, & Hommer,  ; Knutson, Fong, et al.,  ; Samanez\u2010Larkin et al.,  ; Wrase et al.,  ). Individual studies had samples composed of between 8 and 162 healthy participants. Handedness was reported in 31 studies, of which 29 studies included only right\u2010handed participants, and two included also a minority of left\u2010handed and ambidextrous participants. Most studies reported a spatial resolution of between 3\u20134mm , ranging from 3.75mm \u00d7 3.75mm \u00d7 7mm to 1.5mm \u00d7 1.5mm \u00d7 3mm. \n\nAll studies offered actual monetary reward, which was dependent on successful performance. Also, all studies manipulated (in a different fashion) the success/hit rates of the MIDT by controlling the duration of the target/the time required for a successful response. Most studies (38 of 50) used tasks that had a set success rate of 65\u201367%, while a minority used a set success rate of 50% (Dillon et al.,  ; Figee et al.,  ; Pfabigan et al.,  ) or 60% (Yau et al.,  ). Other studies used data from practice trials to inform reaction times, and used a success rates of 40\u201380% (Bustamante et al.,  ; Choi et al.,  ; Costumero et al.,  ; Jung et al.,  ; Kirk et al.,  ; Weiland et al.,  ). The remaining studies did not report the task success rate, but reported participants\u2019 were successful on approximately 55\u201080% of trials (Behan, Stone, & Garavan,  ; Boecker et al.,  ). \n\nSix studies reported non\u2010significant results, including five for reward outcome and one for loss outcome (see Table  ). As the ALE method cannot incorporate null findings, these were excluded from the analysis. We thereby examined 49 studies for reward anticipation (609 foci, 1,082 participants), 32 for loss anticipation (333 foci, 681 participants) and 22 for reward outcome (264 foci, 691 participants). \n\n\n### ALE analysis \n  \nWe ran nine different analyses to identify areas of increased activation likelihood during reward anticipation, loss anticipation, reward outcome, and common and distinct regions between reward and loss anticipation, as well as between reward anticipation and outcome (Table  ). Each contrast used in the analysis has been assigned a label (e.g. RA, LA\u2010RA) to assist in keeping track of which contrast is being referred to in the results. \n  \nTypes of contrasts used for each ALE analysis \n    \n#### Single analysis \n  \nFirst, we performed an ALE analysis on each single contrast type (contrast RA, LA and RO). The result of reward anticipation (contrast RA) revealed a large cluster of brain regions around the striatal\u2010thalamic regions of the brain, encompassing the ventral, including the nucleus accumbens (NAcc), and the dorsal striatum, extending to the bilateral amygdala (Figure  a). The insula, supplementary motor area, premotor cortex, occipital cortex, and cuneus were other regions of note where greater likelihood of activation was seen during reward anticipation (Table  ). When this analysis was repeated using the eleven studies that only used a low magnitude reward (Behan et al.,  ; Carl et al.,  ; Choi et al.,  ; Damiano et al.,  ; Dillon et al.,  ; Figee et al.,  ; Jung et al.,  ; Kappel et al.,  ; Knutson, Bhanji, Cooney, Atlas, & Gotlib,  ; Pfabigan et al.,  ; Romanczuk\u2010Seiferth, Koehler, Dreesen, W\u00fcstenberg, & Heinz,  ), we also found increased activation likelihood in the bilateral ventral and dorsal striatum, left supplementary motor and premotor areas and right insula (Table S , Supporting Information). \n  \nALE single analysis results. (a) Single analysis of reward anticipation (contrast LA). (b) Single analysis of loss anticipation (contrast LA). (c) Single analysis of reward outcome (contrast RO). Single analyses were conducted with a cluster\u2010forming threshold of   p   < .001 uncorrected and a cluster\u2010level threshold of   p   < .05 [Color figure can be viewed at  ] \n    \nALE results for activations during reward anticipation (contrast RA) \n    \nSecond, loss anticipation (contrast LA) also showed a cluster of increased likelihood of activation in striatal\u2010thalamic\u2010amygdala regions (Figure  b). Greater probability of activation also was found in the insula, supplementary motor area, premotor cortex and occipital cortex (Table  ). \n  \nALE results for activations during loss anticipation (contrast LA) \n    \nFinally, the contrast of reward outcome (contrast RO) showed a large cluster in the ventral striatum which extended into the subcallosal, followed by another large cluster in the OFC/vmPFC, and a smaller clusters in the dorsal PCC and amygdala cortex (Figure  c and Table  ). \n  \nALE results for activations during reward outcome (contrast RO) \n    \n\n#### Conjunction and subtraction analysis \n  \n##### Reward and loss anticipation \n  \nAn ALE conjunction analysis was run to identify regions engaged in both reward and loss anticipation contrasts. Reward and loss anticipation (contrast RA\u2009+\u2009LA) showed overlap in two large clusters of greater activation probability in the striatal\u2010thalamic region, encompassing the dorsal and ventral striatum and the amygdala, followed by smaller clusters in the anterior insula and supplementary motor area (Figure  c, Table  ). Additionally, the region of the ventral striatum where overlapping activation between reward and loss anticipation resided is considered to be part of the NAcc core (Xia et al.,  ). \n  \nALE results for the conjunction and subtraction analysis between of reward anticipation and loss anticipation. (a) Subtraction analysis of reward anticipation relative to loss anticipation (contrast RA\u2010LA). (b) Subtraction analysis of loss anticipation relative to reward anticipation (contrast LA\u2010RA). (c) Conjunction analysis of reward anticipation and loss anticipation (contrast RA\u2009+\u2009LA). Subtraction analyses were conducted with a significance level of   p   < .005 [Color figure can be viewed at  ] \n    \nALE results for conjunction analyses between reward and loss anticipation (contrast RA\u2009+\u2009LA) and reward anticipation and outcome (contrast RA\u2009+\u2009RO) \n  \nReward anticipation and loss anticipation showed no difference in their neural substrates (contrasts RA\u2010LA and LA\u2010RA). At a less conservative threshold of   p  \u2009<\u2009.005, loss anticipation in contrast to reward anticipation activated the caudate body/medial\u2010dorsal thalamus (Figure  a, Table  ), while reward anticipation contrasted with loss anticipation engaged the left supplementary motor area, left occipital lobe and a part of the right ventral NAcc which corresponds to the NAcc shell (Figure  b, Table  ) (Xia et al.,  ). \n  \nALE results for subtraction analyses between reward anticipation and loss anticipation (contrast RA\u2010LA and contrast LA\u2010RA) \n    \n\n##### Reward anticipation and outcome \n  \nThe conjunction analysis examining common regions to reward anticipation and outcome (contrast RA\u2009+\u2009RO) showed engagement the ventral striatum and amygdala (Figure  c, Table  ). Subtraction analyses showed, for (i) reward anticipation versus reward receipt (contrast RA\u2010RO), activity of the caudate/dorsal striatum, supplementary motor area, thalamus and right anterior insula (Figure  a, Table  ); while (ii) reward receipt versus reward anticipation (contrast RO\u2010RA) engaged the OFC/vmPFC and PCC (Figure  b, Table  ). \n  \nALE results for the conjunction and subtraction analysis between reward anticipation and reward outcome. (a) Subtraction analysis of reward anticipation relative to reward outcome (contrast RA\u2010RO). (b) Subtraction analysis of reward outcome relative to reward anticipation (contrast RO\u2010RA). (c) Conjunction analysis of reward anticipation and reward outcome (contrast RA\u2009+\u2009RO). Subtraction analyses were conducted with a significance level of   p   < .001 [Color figure can be viewed at  ] \n    \nALE results for the subtraction analyses between reward anticipation and outcome (contrast RA\u2010RO and contrast RO\u2010RA) \n    \n\n\n#### Additional ALE analyses \n  \nWe ran post\u2010hoc analyses to disentangle the potential impact of several possible confounders that may have biased the results (these are presented in Tables S \u2010S , Supporting Information). The inclusion of reward/loss versus no\u2010incentive contrasts might be biased by action planning, which has a central role in appetitive motivation. We therefore reran all single and conjunction/subtraction analyses presented thus far (i.e. all those presented in Table  ) after excluding the two studies using non\u2010incentive trials instead of neutral trials. The results remained unaltered, with activation of striatal\u2010thalamic, insula, amygdala and supplementary motor regions during reward and loss anticipation (Table S , Supporting Information). \n\nSecond, we aimed to disentangle whether the specificity of OFC/vmPFC activation for feedback depended on either the length of interval between reward\u2010anticipatory cue and feedback or the jittered time interval in trials between cue and feedback. We therefore contrasted studies that had an anticipation duration (time from initial exposure to the cue to the presentation of the target) of less than 3000ms (short duration) with those which had a duration of between 3000ms to 6000ms (long duration) for reward anticipation contrasts. Eighteen studies used an anticipation phase of a short duration (Bjork et al.,  ; Bustamante et al.,  ; Costumero et al.,  ; Enzi et al.,  ; Juckel, Schlagenhauf, Koslowski, W\u00fcstenberg, et al.,  ; Kappel et al.,  ; Knutson, Adams, et al.,  ; Knutson et al.,  ,  ; Knutson, Fong, et al.,  ; Maresh, Allen, & Coan,  ; Mori et al.,  ; Mucci et al.,  ; Rademacher et al.,  ; Saji et al.,  ; Wrase et al.,  ; Yan et al.,  ) whereas 22 used a long duration (Carter et al.,  ; Choi et al.,  ; Damiano et al.,  ; Funayama et al.,  ; H\u00e4gele et al.,  ; Juckel et al.,  ; Jung et al.,  ; Kaufmann et al.,  ; Kirk et al.,  ; Pfabigan et al.,  ; Samanez\u2010Larkin et al.,  ; Schlagenhauf et al.,  ; Stoy et al.,  ,  ; Treadway, Buckholtz, & Zald,  ; Weiland et al.,  ; Wu, Samanez\u2010Larkin, Katovich, & Knutson,  ; Yau et al.,  ). Within each condition, studies with both a long and short duration showed increased activation likelihood in striatal, amygdala and insula regions. Studies that used a short duration also showed increased likelihood in supplementary motor, premotor and dorsolateral prefrontal areas while those that used longer durations had occipital and posterior thalamic activation. The conjunction analysis of long and short reward anticipation durations found increased activation likelihood in striatal, amygdala and insula areas (see Table S , Supporting Information). The subtraction analysis found no significant differences. \n\nOf the 22 studies that examined reward receipt in some form, 13 used a contrast of successful reward outcome versus unsuccessful reward outcome (Bjork et al.,  ,  ,  ; Bjork, Smith, & Hommer,  ; Boecker et al.,  ; Jung et al.,  ; Kirk et al.,  ; Knutson et al.,  ,  ; Romanczuk\u2010Seiferth et al.,  ; Wu et al.,  ; Yan et al.,  ) and nine used successful reward outcome versus neutral trial outcome (Bustamante et al.,  ; Carl et al.,  ; Damiano et al.,  ; Dillon et al.,  ; Figee et al.,  ; Filbey et al.,  ; Hanssen et al.,  ; Mucci et al.,  ). To check if there was a difference between these two contrast types an additional ALE analysis was done. First, condition\u2010specific analyses were performed on each contrast type. Successful reward outcome versus unsuccessful reward outcome showed significant activations in the ventral striatum, OFC/vmPFC, PCC, the right amygdala and in the medial prefrontal cortex area (Table S , Supporting Information), which correspond to similar regions as the combined contrast (successful reward outcome versus unsuccessful reward outcome and successful reward outcome versus neutral trial outcome). However, the single ALE analysis for successful reward outcome versus neutral trial outcome revealed no significant activation, precluding a subsequent conjunction/subtraction analysis. \n\n\n\n\n## DISCUSSION \n  \nWe performed a neuroimaging ALE meta\u2010analysis of results from studies using the MIDT, to examine brain regions that are implicated in reward anticipation, loss anticipation, as well as reward outcome. First, we found considerable overlaps in the networks activated during reward and loss anticipation, including the dorsal and ventral striatum, amygdala, insula and supplementary motor cortex. Second, we identified neural networks engaged by reward receipt\u2014including the ventral striatum, the OFC/vmPFC, amygdala, and PCC. \n\n### Common neural substrates of reward and loss anticipation \n  \nWe found that anticipation of reward and loss have a common neural substrate (i.e., striatum, thalamus, insula and amygdala). Previous meta\u2010analyses reported partly comparable results as the striatum and thalamus were found to be common to both processes, but not the amygdala and insula (Bartra et al.,  ; Knutson & Greer,  ; Liu et al.,  ). Previous studies also implicate the striatum in the anticipation of positive or negative outcomes, regardless of stimulus type\u2014monetary (Carter et al.,  ; Delgado, Jou, Ledoux, & Phelps,  ; Guitart\u2010Masip et al.,  ; Pfabigan et al.,  ; Stark et al.,  ; Tom, Fox, Trepel, & Poldrack,  ), social (Kohls et al.,  ), or physical (Delgado, Jou, & Phelps,  ). Overall, these and our results suggest that a generalised system\u2014centred on the striatum\u2014is implicated in approach and avoidance behaviour and has considerable overlap with what is typically considered to be reward circuitry (Brooks & Berns,  ; Jensen et al.,  ; Kohls et al.,  ; Lammel, Lim, & Malenka,  ; Pfabigan et al.,  ; Salamone & Correa,  ). \n\nThe ventral striatum has been conventionally ascribed to reward processing primarily, but mounting evidence\u2014including the results from this study\u2014points to broader functions (Brooks & Berns,  ; Lammel et al.,  ; Salamone & Correa,  ). The ventral striatum (and mesolimbic dopamine system more generally) has been linked to motivational processes independent of stimulus valence, such as behavioural activation, exertion of effort and sustained task engagement (Boureau & Dayan,  ; Salamone & Correa,  ). Many of these motivational processes are required during the anticipation trials of the MIDT to perform the task successfully (Pfabigan et al., 2014). As these processes occur in the MIDT, ventral striatal activity is robustly observed when such processes are occurring, and the ventral striatum is associated with these motivational processes, our results are aligned with evidence that the ventral striatum is involved in the motivational aspect of valence independent outcome anticipation (Kohls et al.,  ; Mogenson, Jones, & Yim,  ; Pfabigan et al.,  ; Salamone & Correa,  ). Also supporting this, ventral striatal activity has also previously been linked to the amount of effort required to obtain an outcome (Bjork & Hommer,  ; Guitart\u2010Masip et al.,  ; Kurniawan, Guitart\u2010Masip, Dayan, & Dolan,  ). Overall, these findings suggest that a general motivation system\u2014with the striatum playing a critical role\u2014is engaged when anticipating either rewards or losses. \n\nVentral striatal activity during both reward and loss anticipation was localised to the dorsolateral NAcc, which is recruited when anticipating salient stimuli, irrespective of their valence (Zink, Pagnoni, Chappelow, Martin\u2010Skurski, & Berns,  ; Zink, Pagnoni, Martin\u2010Skurski, Chappelow, & Berns,  ; Zink, Pagnoni, Martin, Dhamala, & Berns,  ) and has a key role in motivational processes (Salamone & Correa,  ). Recent work has identified the dorsolateral proportion of the NAcc to correspond to the NAcc core (Xia et al.,  ), a region thought to encode the motivational salience of stimuli, and which mediates cognitive functions such as orientation towards the stimuli, cognitive control, action selection, and effort (Bromberg\u2010Martin, Matsumoto, & Hikosaka,  ). Thus, the NAcc, and specifically its core, may be a key hub for motivational processing in response to potentially rewarding or aversive stimuli. \n\nThough previous MIDT work has largely focused on the ventral striatum (Balodis & Potenza,  ), our findings also implicate the dorsal striatum in reward and loss processing, aligning with previous work (Balleine, Delgado, & Hikosaka,  ; Palminteri et al.,  ). While anticipating an outcome, the ventral striatum encodes the expected value of the outcome (Delgado, Li, Schiller, & Phelps,  ; Jensen et al.,  ,  ; O'Doherty et al.,  ; Sch\u00f6nberg, et al., 2007). These expected value signals subsequently modulate motivational processes, potentially via the dorsal striatum (den Ouden, Kok, & de Lange,  ; Jensen et al.,  ; Kim,  ; Kurniawan et al.,  ; Miller, Shankar, Knutson, & McClure,  ; Niv, Daw, Joel, & Dayan,  ; Schmidt, Lebreton, Cl\u00e9ry\u2010Melin, Daunizeau, & Pessiglione,  ; Vassena et al.,  ), which is involved in motivational processes such as selecting/initiating motor responses aimed to achieve optimal outcomes (Atallah, Lopez\u2010Paniagua, Rudy, & O'Reilly, 2007; Balleine et al.,  ; Kurniawan et al.,  ; O'Doherty et al.,  ; Palminteri et al.,  ). \n\nThe anticipation of rewards and losses engaged other brain areas including the anterior insula and the thalamus (and amygdala as discussed further below), in line with previous work (Bartra et al.,  ; Diekhof et al.,  ; Knutson & Greer,  ; Liu et al.,  ). The anterior insula is implicated in responding to outcome uncertainty (Bossaerts,  ; Rolls, McCabe, & Redoute,  ), a key element in the MIDT as the success rate is pre\u2010set so that a set so participants can never be certain they will succeed on any given trial. Similarly, the thalamus plays a role in anticipating rewards and losses. It has been suggested that the thalamus represents an \u201calerting\u201d signal to respond to valanced stimuli, which converges with introspective information from the insula to the striatum, where an appropriate action response is selected (Cho et al.,  ). \n\nThis is the first time for a meta\u2010analysis to detect amygdala activation during both reward and loss anticipation, as this region is typically associated with loss processing. Our finding is consistent with evidence that suggests the amygdala responds to stimulus arousal, rather than stimulus valence (Anderson et al.,  ; Haber & Knutson,  ; Hardin et al.,  ; Small et al.,  ). It is possible that anticipation of an uncertain outcome engages arousal to enhance spatial attention towards valence\u2010related stimuli (Ousdal et al.,  ; Peck & Salzman,  ) and maximise task performance (i.e., gaining rewards and avoiding losses). \n\nOverall, our results fit with findings that show signals within the anterior insula, thalamus, and amygdala project to and converge within the ventral striatum (Haber & Knutson,  ) to update predictions of the best outcomes and allow appropriate action selection, while the dorsal striatum selects the optimal choice (Atallah et al.,  ; Cho et al.,  ; Delgado et al.,  ; Mogenson et al.,  ; O'Doherty et al.,  ). All of these elements putatively form a general motivation system in the brain that devises a response to a stimulus regardless of its valence. \n\nThe anticipation of an outcome did not recruit the OFC/vmPFC area in our study, which contrasts previous results (Bartra et al.,  ; Liu et al.,  ). This may be due to the fact that the OFC/vmPFC is recruited in reward tasks where one must select from multiple options/choices (Doll, Simon, & Daw,  ; Hampton, Bossaerts, & O'Doherty,  ; Peters & B\u00fcchel,  ), and in meta\u2010analyses including reward processing tasks with decision making/comparative elements OFC/vmPFC activity was found during anticipation (Bartra et al.,  ; Clithero & Rangel,  ; Liu et al.,  ). Our results on the lack of OFC/vmPFC recruitment are consistent with those from studies using tasks that require no selection between distinct options (Plassmann, O'Doherty, & Rangel, 2007; Schoenbaum, Takahashi, Liu, & Mcdannald,  ) such as the MIDT, and in meta\u2010analyses of tasks/contrasts that do not include decision making elements (Diekhof et al.,  ; Knutson & Greer,  ). Thus, the OFC/vmPFC may be implicated only in reward processing tasks requiring selection between multiple choices and decision making. \n\nAdditionally, the uncertainty in achieving an outcome on the MIDT may also explain why the OFC/vmPFC were not involved during the anticipation stage. If it is highly likely that a reward will be obtained following the presentation of a cue, the cue will take on the property of the received reward, as per classical conditioning principles. Thus, the cue will activate regions involved during reward outcome, e.g., the OFC/vmPFC (Diekhof et al.,  ). In support of this, one study which used a similar paradigm to the MIDT, but in which the outcome was highly certain, reported OFC/vmPFC activity during reward anticipation (Kim et al.,  ). Given enough time, individuals may also begin to mentally imagine obtaining the reward and this mental stimulation may also activate the OFC/vmPFC (Bray, Shimojo, & O'Doherty,  ). In a task like the MIDT, the anticipation stage is relatively short, preventing participants from engaging in such mental activities (Diekhof et al.,  ). \n\nWe found no differences between reward and loss anticipation at our nominal significance threshold, but some differences emerged with a more liberal threshold (  p  \u2009<\u2009.005 as opposed to   p  \u2009<\u2009.001) during anticipation of reward but not loss. Specifically, reward anticipation engaging an area of the ventral striatum possibly corresponding to the NAcc shell (Xia et al.,  ). NAcc shell activity has been ascribed to reward processing specifically and may reflect learning of the reward value (Bromberg\u2010Martin et al.,  ) and hedonic response to the stimuli (Castro & Berridge,  ; Pecina & Berridge,  ). \n\nWhen investigating loss anticipation (versus reward anticipation) using the reduced statistical threshold, we found increased activation likelihood in the caudate body/dorsal\u2010medial thalamus. This may represent the prediction of an aversive outcome, as existing work shows that this area codes punishment\u2010based prediction errors (Mattfeld, Gluck, & Stark,  ). However further characterisation of loss processing is needed to determine what the activity in this area may indicate. \n\nAdditional analyses were performed to examine the impact of various potential confounds. We found no evidence for a bias associated with inclusion of studies that compared reward/loss anticipation to non\u2010incentive MIDT trials. We also found that the exclusion of studies that used a non\u2010incentive trial did not alter the findings. The use of short vs long durations in the anticipation phase were also not associated with differences in activation, but we could only run this analysis on a relatively small dataset (\u223c20 studies in each condition), so further confirmation is required. Identifying the impact of the anticipatory phase duration on subsequent brain activity facilitate optimization of task design (e.g., in determining optimal trial length) and shed light on how anticipatory activity unfolds over time. \n\n\n### Brain activity during reward outcome \n  \nReward outcome was linked to activity in a range of brain regions including the ventral striatum, OFC/vmPFC, PCC, subcallosal cortex, and thalamus, consistent with previous evidence (Bartra et al.,  ; Clithero & Rangel,  ; Diekhof et al.,  ; Knutson & Greer,  ; Liu et al.,  ). Of these regions, increased likelihood of OFC/vmPFC and PCC activity was observed only during reward outcome and not during reward anticipation. \n\nVentral striatal activity during rewarding outcomes has been observed consistently (Bartra et al.,  ; Clithero & Rangel,  ; Diekhof et al.,  ; Knutson & Greer,  ; Liu et al.,  ). This ventral striatal activity likely represents a prediction error signal that tracks the difference between the expected and received reward (Haber & Knutson,  ; Knutson, Fong, et al.,  ) when contingencies are uncertain (McClure, York, & Montague,  ; Yacubian et al.,  ). Such a signal would be critical for reward processing and learning, increasing the likelihood a behaviour that leads to a better than expected outcome will be repeated (McClure et al.,  ; Schultz &Dickinson,  ; Yacubian et al.,  ), like in the MIDT. \n\nWe found that the anterior portion of the prefrontal cortex\u2014including the OFC/vmPFC and subcallosal cortex\u2014were implicated in reward outcome (but not reward anticipation). This is in line with previous findings that implicate these areas in the receipt of abstract rewards, like money (Kringelbach & Rolls,  ; Sescousse et al.,  ). The OFC/vmPFC may represent the subjective value of a received reward (Bartra et al.,  ; Diekhof et al.,  ; Haber & Knutson,  ; Levy & Glimcher,  ; Peters & B\u00fcchel,  ) and the subcallosal cortex may represent the subjective experience of pleasure (Anderson et al.,  ), especially as its dysfunction is linked to anhedonia (Hamani et al.,  ; Young et al.,  ). While the OFC and vmPFC are often presented as synonymous in function (Levy & Glimcher,  ; Rushworth et al.,  ), they may have dissociable roles. The OFC is potentially engaged in processing the value of a gain, and the vmPFC in encoding/strengthening the relationship between a stimulus and outcome (Walton, Chau, & Kennerley,  ). However, research into the distinct roles of these regions is limited, thus this will need to be addressed in order to properly understand reward/loss processing. \n\nReceiving a reward also implicated the PCC, consistent with previous work and further suggests this region is crucial for reward processing (Bartra et al.,  ; Clithero & Rangel,  ; Diekhof et al.,  ; Liu et al.,  ; Pearson, Heilbronner, Barack, Hayden, & Platt,  ). The PCC is implicated in monitoring the environment and remembering past outcomes, thus may track the outcomes achieved and signal required behavioural changes when optimal outcomes are no longer being achieved (Nakao, Ohira, & Northoff,  ; Schacter, Addis, & Buckner,  ). This information would be projected to prefrontal regions, which devises new responses to maximise outcomes (Pearson, Hayden, Raghavachari, & Platt,  ; Pearson et al.,  ). Notably, the PCC is linked to self\u2010referential activation and is part of the default mode network (Brewer, Garrison, & Whitfield\u2010Gabrieli,  ; Northoff et al.,  ), thus PCC activity may represent positive self\u2010appraisal upon receipt of a reward. \n\n\n### Limitations and future use of the MIDT \n  \nWhile the MIDT avoids several potential cognitive confounds, there are still some limitations in using the task to understand reward and loss processing (Balodis & Potenza,  ; Limbrick\u2010Oldfield, Van Holst, & Clark,  ). First, using the neutral trial as a baseline to contrast reward and loss trials might not be optimal as a successful neutral trial may be experienced as rewarding. For example, a participant might find performing the task intrinsically rewarding, regardless if a monetary outcome is at stake (Lutz & Widmer,  ). This may elicit a similar neural response to both neutral and reward/loss cues. The structure of the MIDT could also affect brain activity during neutral trials. For example, neutral outcomes could have a positive valence (i.e., absence of loss) or a negative valence (i.e., absence of reward) if loss trials are or are not present in the task, respectively (Hardin et al.,  ; Limbrick\u2010Oldfield et al.,  ; Nieuwenhuis et al.,  ). \n\nIndividual differences like learning rate could also produce different neural activity. Individuals who are still learning how the MIDT works would be expected to show less anticipatory but greater outcome activity, as they have not developed the proper neural responses needed to successfully predict the outcome, compared to those who have learnt the task (Balodis & Potenza,  ). Computational modelling may be able to be used to assess how learning changes over the course of the task (O'Doherty, et al., 2007). \n\nFinally, while the MIDT is cognitively simple task there may be some cognitive factors which could be further addressed. For instance, during the anticipation stage of the standard MIDT (Knutson et al.,  ) there is activity related to both motivational processes and the prediction/expectation of an outcome (Limbrick\u2010Oldfield et al.,  ). It is possible to develop the task to have a secondary anticipatory stage occurring after the participant responds to the target, but prior to feedback delivery (Andrews et al.,  ; Balodis et al.,  ; Bjork et al.,  ). Characterising the differences between these two types of anticipation will help more clearly disentangle motivational processes, which should not need recruiting after a response is made, from prediction/expectation signals. Another possible confound could be working memory demands due to participants having to remember what the different symbols in the MIDT mean, but this could be addressed by using words instead (Andrews et al.,  ; Balodis et al.,  ). \n\nFinally, many of the meta\u2010analysed studies used gradient\u2010echo sequences, which are vulnerable to MR susceptibility artefacts (Ojemann et al.,  ) and could have caused signal loss in areas targeted by the MIDT that are close to sinuses e.g., ventral striatum, amygdala, OFC/vmPFC (O'Doherty,  ). Only a few studies (Adcock, Thangavel, Whitfield\u2010Gabrieli, Knutson, & Gabrieli,  ; Knutson et al.,  ; Weiland et al.,  ; Wu et al.,  ; Yau et al.,  ) minimised these artefacts using a spiral in/out sequence (Glover & Law,  ), and we recommend future MIDT studies to use such susceptibility artefact\u2010reducing methods (e.g., spin\u2010echo, z\u2010shimming, optimisation of the echo time and spatial resolution) to further refine the spatial specificity, though other factors should be considered if choosing to employ such artefact\u2010reduction methods (e.g., for instance spin\u2010echo can result in a loss of sensitivity at field strengths of 3T or below)(Glover,  ; Norris,  ; Weiskopf, Hutton, Josephs, Turner, & Deichmann,  ). \n\nDespite these limitations, the MIDT is a valuable tool to investigate reward and loss processing in both healthy and psychiatric populations (Balodis & Potenza,  ; Knutson & Heinz,  ; Lutz & Widmer,  ), especially as many of the aforementioned issues could be addressed by studies through careful design or improved analysis techniques. The MIDT has been used to investigate the neural correlates of reward processing in a number of psychiatric disorders (Knutson & Heinz,  ) including: substance abuse (Balodis et al.,  ; Balodis & Potenza,  ; Bjork et al.,  ; Jia et al.,  ; Patel et al.,  ), pathological gambling (Balodis et al.,  ; Romanczuk\u2010Seiferth et al.,  ), depression (Knutson et al.,  ), schizophrenia (Juckel, Schlagenhauf, Koslowski, W\u00fcstenberg, et al.,  ), binge eating (Balodis et al.,  ,  ), and ADHD (Stoy et al.,  ). In addition to investigating psychiatric disorders, the MIDT has also been used to investigate both typical development of reward and loss processing neurobiology (Bjork et al.,  ,  ; Cho et al.,  ; Lutz & Widmer,  ; Rademacher, Salama, Gr\u00fcnder, & Spreckelmeyer,  ; Richards et al.,  ; Samanez\u2010Larkin et al.,  ), as well as atypical development (Guyer et al.,  ; Peters et al.,  ; Schneider et al.,  ). The results of the present study should assist researchers in establishing what brain activations are expected when the MIDT is used and inform new hypothesis/directions of research. \n\nOur results further stress the importance of examining the temporal phases (i.e. anticipation and receipt) of reward/loss processing separately, as we showed dissociable neural substrates. This is particularly relevant for psychiatric conditions where distinct temporal phases or reward and loss are affected. For instance, relative to controls, individuals with substance addiction show decreased and increased striatal activation during reward anticipation and receipt, respectively (Luijten, Schellekens, K\u00fchn, Machielse, & Sescousse,  ). Additionally, different valences should also be used. A dysfunctional ventral striatal response to both reward and loss anticipation has been observed in patients with substance abuse (Balodis & Potenza,  ), problem gambling (Balodis et al.,  ; Romanczuk\u2010Seiferth et al.,  ), and schizophrenia (Juckel, Schlagenhauf, Koslowski, Filonov, et al.,  ). As our results show reward and loss anticipation are neurobiological similar, this altered activity may be caused by abnormalities in the general motivation system rather than deficits specific to one type of valence (Salamone & Correa,  ). To properly evaluate this, both reward and loss trials should be used and analysed when employing the MIDT, especially when psychiatric populations are being investigated, to further characterise similarities and differences between reward and loss processing neurobiology. Thus, investigating the interaction between valence and temporal phase is likely to lead to much more insightful results regarding psychiatric populations. \n\n\n### Limitations \n  \nThe ALE method is a coordinate\u2010based meta\u2010analysis (CBMA) technique which only incorporates information regarding sample size and points of activation. An optimal approach would use an image\u2010based meta\u2010analysis, which uses the full statistical parametric map when conducting the analysis, avoiding the information loss that is inherent to CBMA techniques, allowing for a more powerful and detailed analysis (Salimi\u2010Khorshidi, Smith, Keltner, Wager, & Nichols,  ). However, conducting such a meta\u2010analysis is currently problematic, as statistical parametric maps from other studies are often difficult to acquire. Recent advances in neuroimaging databases (Poldrack & Gorgolewski,  ), will hopefully make obtaining such data significantly easier. This is an opportunity that research teams investigating the neurobiology of reward and loss processing should seek to implement in future. Also, as the ALE approach does not take account of null findings, we did not include the results from a small number of studies that reported no activations during reward outcome. This may have caused a slight bias towards positive findings. \n\nWe could not investigate MIDT studies that had examined loss received against loss avoided/neutral outcome as too few had conducted or reported this contrast. Future studies should aim to explore this contrast to improve our understanding of reward and loss processing. \n\nAnother limitation is that we did not extensively examine the impact of reward magnitude on the results, which may increase activity in some regions (ventral striatum) but not other regions (e.g., insula, amygdala) (Diekhof et al.,  ; Knutson, Adams, et al.,  ). Unfortunately, few studies reported results using a single magnitude, and most studies using multiple magnitudes collapsed these trials together without segregating individual magnitudes. Thus, we cannot rule out that our results in some regions may be partly driven studies that used larger magnitudes in their design. Nonetheless, we observed striatal (both dorsal and ventral), amygdala, anterior insula and supplementary motor area activation during reward anticipation using a low magnitude (for the 11 studies which used a low magnitude), corroborating the validity of the reported effects on the striatum. \n\nFinally, we included studies with heterogeneous success rates. Most studies (  n  \u2009=\u200938) used a 66\u201367% hit rate, but the other studies used hit rates of anywhere between 40\u201380%, preventing a direct comparison of the varying hit rate level (as too few studies used a consistent hit rate other than 66\u201367%). Theses varying rates may affect the probability and uncertainty of outcomes, and ultimately neuronal activity (Fiorillo, Tobler, & Schultz,  ; O'Doherty et al.,  ). For example, more uncertain outcomes could produce increased ventral striatal activity during anticipation and more certain outcomes could produce reduced ventral striatal activity during receipt and possibly produced OFC/vmPFC activity during anticipation. A systematic investigation of the effect of hit\u2010rate will help to clarify these effects. \n\n\n### Summary \n  \nThe present meta\u2010analysis used the MIDT to examine the neural substrates of reward and loss processing, in particular to assess if there was a specific or generalised system to these processes. We found the striatum, thalamus, amygdala and insula were activated during both reward and loss anticipation, indicating a generalised system is activated during this processing phase. This system likely plays a key role in generating motivation responses that allow an optimal outcome to be achieved. Unlike some previous studies, our results did not implicate the OFC/vmPFC during anticipation (but did during reward outcome), suggesting the OFC/vmPFC is engaged in the anticipation of rewards if there are multiple choices to be made or if outcomes are highly certain. Future research is warranted to further investigate the overlaps and differences between reward and loss processing to better understand learning, approach, and avoidance behaviours. \n\n\n\n## CONFLICT OF INTEREST \n  \nAll authors report no conflict of interest. \n\n\n## Supporting information \n  \n \n", "metadata": {"pmcid": 6055646, "text_md5": "57fae840d37342d5e6ef30b545bd2977", "field_positions": {"authors": [0, 117], "journal": [118, 132], "publication_year": [134, 138], "title": [149, 281], "keywords": [295, 358], "abstract": [371, 1905], "body": [1914, 60591]}, "batch": 2, "pmid": 29696725, "doi": "10.1002/hbm.24184", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6055646", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6055646"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6055646\">6055646</a>", "list_title": "PMC6055646  The anticipation and outcome phases of reward and loss processing: A neuroimaging meta\u2010analysis of the monetary incentive delay task"}
{"text": "                               Study    N  ... Loss Outcome MIDT type\n0                Adcock et al. (???)   12  ...            \u2013         A\n1               Balodis et al. (???)   14  ...            \u2713         B\n2                 Beck et al. (2009)   19  ...            \u2013         A\n3                 Behan et al. (???)   20  ...            \u2013         E\n4                 Bjork et al. (???)   12  ...            \u2013         A\n5                 Bjork et al. (???)   23  ...            \u2013         F\n6                 Bjork et al. (???)   24  ...            \u2713         H\n7                 Bjork et al. (???)   23  ...            \u2013         G\n8               Boecker et al. (???)  162  ...            \u2013         A\n9            Bustamante et al. (???)   18  ...            \u2013         D\n10                 Carl et al. (???)   20  ...            \u2013         A\n11               Carter et al. (???)   17  ...            \u2013         A\n12                 Choi et al. (???)   15  ...            \u2013         A\n13            Costumero et al. (???)   44  ...            \u2013         D\n14              Damiano et al. (???)   31  ...            \u2013         A\n15               Dillon et al. (???)   32  ...            \u2013         B\n16                 Enzi et al. (???)   15  ...            \u2013         A\n17                Figee et al. (???)   19  ...            \u2013         A\n18               Filbey et al. (???)   27  ...            \u2713         I\n19             Funayama et al. (???)   20  ...            \u2013         B\n20               H\u00e4gele et al. (???)   54  ...            \u2013         B\n21              Hanssen et al. (???)   57  ...            \u2013         E\n22              Juckel et al. (???b)   10  ...            \u2013         A\n23               Juckel et al. (???)   13  ...            \u2013         A\n24                 Jung et al. (???)   20  ...            \u2013         A\n25               Kappel et al. (???)   20  ...            \u2013         A\n26             Kaufmann et al. (???)   19  ...            \u2013         B\n27                 Kirk et al. (???)   44  ...            \u2013         B\n28             Knutson et al. (???a)    8  ...            \u2013         A\n29             Knutson et al. (???b)    9  ...            \u2013         A\n30              Knutson et al. (???)   12  ...            \u2013         C\n31              Knutson et al. (???)   12  ...            \u2013         B\n32               Maresh et al. (???)   84  ...            \u2013         A\n33                 Mori et al. (???)   15  ...            \u2013         C\n34                Mucci et al. (???)   22  ...            \u2013         A\n35             Pfabigan et al. (???)   25  ...            \u2013         B\n36           Rademacher et al. (???)   28  ...            \u2013         A\n37  Romanczuk\u2013Seiferth et al. (2015)   17  ...            \u2013         B\n38                 Saji et al. (???)   18  ...            \u2013         A\n39      Samanez\u2013Larkin et al. (2007)   12  ...            \u2013         C\n40         Schlagenhauf et al. (???)   10  ...            \u2013         A\n41                 Stoy et al. (???)   12  ...            \u2013         A\n42                 Stoy et al. (???)   15  ...            \u2013         B\n43              Str\u00f6hle et al. (???)   10  ...            \u2013         B\n44             Treadway et al. (???)   38  ...            \u2013         A\n45              Weiland et al. (???)   12  ...            \u2013         A\n46                Wrase et al. (???)   14  ...         \u2713???         A\n47                   Wu et al. (???)   52  ...            \u2013         C\n48                  Yan et al. (???)   22  ...            \u2713         A\n49                  Yau et al. (???)   20  ...            \u2013         A\n\n[50 rows x 7 columns]", "metadata": {"pmcid": 6055646, "title": "The anticipation and outcome phases of reward and loss processing: A neuroimaging meta\u2010analysis of the monetary incentive delay task", "journal": "Hum Brain Mapp", "publication_year": 2018}, "display_title": "pmcid: <a href='https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6055646'>6055646</a>", "list_title": "PMC6055646 - The anticipation and outcome phases of reward and loss processing: A neuroimaging meta\u2010analysis of the monetary incentive delay task"}
