{"text": "Yeung, Andy Wai Kan and Robertson, Michaela and Uecker, Angela and Fox, Peter T and Eickhoff, Simon B\nHum Brain Mapp, 2023\n\n# Title\n\nTrends in the sample size, statistics, and contributions to the BrainMap database of activation likelihood estimation meta-analyses: An empirical study of 10-year data.\n\n# Keywords\n\nactivation likelihood estimation\nfMRI\nmeta-analysis\nneuroimaging\nreproducibility\nstatistical threshold\n\n# Abstract\nThe literature of neuroimaging meta-analysis has been thriving for over a decade. A majority of them were coordinate-based meta-analyses, particularly the activation likelihood estimation (ALE) approach. A meta-evaluation of these meta-analyses was performed to qualitatively evaluate their design and reporting standards. The publications listed from the BrainMap website were screened. Six hundred and three ALE papers published during 2010-2019 were included and analysed. For reporting standards, most of the ALE papers reported their total number of Papers involved and mentioned the inclusion/exclusion criteria on Paper selection. However, most papers did not describe how data redundancy was avoided when multiple related Experiments were reported within one paper. The most prevalent repeated-measures correction methods were voxel-level FDR (54.4%) and cluster-level FWE (33.8%), with the latter quickly replacing the former since 2016. For study characteristics, sample size in terms of number of Papers included per ALE paper and number of Experiments per analysis seemed to be stable over the decade. One-fifth of the surveyed ALE papers failed to meet the recommendation of having >17 Experiments per analysis. For data sharing, most of them did not provide input and output data. In conclusion, the field has matured well in terms of rising dominance of cluster-level FWE correction, and slightly improved reporting on elimination of data redundancy and providing input data. The provision of Data and Code availability statements and flow chart of literature screening process, as well as data submission to BrainMap, should be more encouraged. ", "metadata": {"id": 36479854, "text_md5": "a3fd14da32769bc24aa42f9ca7c066cd", "field_positions": {"authors": [0, 101], "journal": [102, 116], "publication_year": [118, 122], "title": [133, 301], "keywords": [315, 417], "abstract": [430, 2091], "body": [2100, 2100]}, "batch": 3, "pmid": 36479854, "doi": "10.1002/hbm.26177", "pmid_url": "https://pubmed.ncbi.nlm.nih.gov/36479854/", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=36479854"}, "display_title": "pmid: <a href=\"https://pubmed.ncbi.nlm.nih.gov/36479854/\">36479854</a>", "list_title": "PMID36479854  Trends in the sample size, statistics, and contributions to the BrainMap database of activation likelihood estimation meta-analyses: An empirical study of 10-year data."}
{"text": "Yeung, Andy Wai Kan and Robertson, Michaela and Uecker, Angela and Fox, Peter T and Eickhoff, Simon B\nHuman brain mapping, 2023\n\n# Title\n\nTrends in the sample size, statistics, and contributions to the BrainMap database of activation likelihood estimation meta-analyses: An empirical study of 10-year data.\n\n# Keywords\n\nactivation likelihood estimation \nfMRI \nmeta-analysis \nneuroimaging \nreproducibility \nstatistical threshold \n\n\n# Abstract\n\nThe literature of neuroimaging meta-analysis has been thriving for over a decade. A majority of them were coordinate-based meta-analyses, particularly the activation likelihood estimation (ALE) approach. A meta-evaluation of these meta-analyses was performed to qualitatively evaluate their design and reporting standards. The publications listed from the BrainMap website were screened. Six hundred and three ALE papers published during 2010-2019 were included and analysed. For reporting standards, most of the ALE papers reported their total number of Papers involved and mentioned the inclusion/exclusion criteria on Paper selection. However, most papers did not describe how data redundancy was avoided when multiple related Experiments were reported within one paper. The most prevalent repeated-measures correction methods were voxel-level FDR (54.4%) and cluster-level FWE (33.8%), with the latter quickly replacing the former since 2016. For study characteristics, sample size in terms of number of Papers included per ALE paper and number of Experiments per analysis seemed to be stable over the decade. One-fifth of the surveyed ALE papers failed to meet the recommendation of having >17 Experiments per analysis. For data sharing, most of them did not provide input and output data. In conclusion, the field has matured well in terms of rising dominance of cluster-level FWE correction, and slightly improved reporting on elimination of data redundancy and providing input data. The provision of Data and Code availability statements and flow chart of literature screening process, as well as data submission to BrainMap, should be more encouraged. \n", "metadata": {"pmid": "36479854", "journal": "Human brain mapping", "publication_year": "2023", "title": "Trends in the sample size, statistics, and contributions to the BrainMap database of activation likelihood estimation meta-analyses: An empirical study of 10-year data.", "keywords": "activation likelihood estimation \nfMRI \nmeta-analysis \nneuroimaging \nreproducibility \nstatistical threshold \n", "abstract": "The literature of neuroimaging meta-analysis has been thriving for over a decade. A majority of them were coordinate-based meta-analyses, particularly the activation likelihood estimation (ALE) approach. A meta-evaluation of these meta-analyses was performed to qualitatively evaluate their design and reporting standards. The publications listed from the BrainMap website were screened. Six hundred and three ALE papers published during 2010-2019 were included and analysed. For reporting standards, most of the ALE papers reported their total number of Papers involved and mentioned the inclusion/exclusion criteria on Paper selection. However, most papers did not describe how data redundancy was avoided when multiple related Experiments were reported within one paper. The most prevalent repeated-measures correction methods were voxel-level FDR (54.4%) and cluster-level FWE (33.8%), with the latter quickly replacing the former since 2016. For study characteristics, sample size in terms of number of Papers included per ALE paper and number of Experiments per analysis seemed to be stable over the decade. One-fifth of the surveyed ALE papers failed to meet the recommendation of having >17 Experiments per analysis. For data sharing, most of them did not provide input and output data. In conclusion, the field has matured well in terms of rising dominance of cluster-level FWE correction, and slightly improved reporting on elimination of data redundancy and providing input data. The provision of Data and Code availability statements and flow chart of literature screening process, as well as data submission to BrainMap, should be more encouraged. ", "authors": "Yeung, Andy Wai Kan and Robertson, Michaela and Uecker, Angela and Fox, Peter T and Eickhoff, Simon B"}, "display_title": "pmid: <a href=\"https://pubmed.ncbi.nlm.nih.gov/36479854\">36479854</a>", "list_title": "PMID36479854 Trends in the sample size, statistics, and contributions to the BrainMap database of activation likelihood estimation meta-analyses: An empirical study of 10-year data."}
