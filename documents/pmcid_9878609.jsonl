{"text": "Luckett, Patrick H. and Lee, John J. and Park, Ki Yun and Raut, Ryan V. and Meeker, Karin L. and Gordon, Evan M. and Snyder, Abraham Z. and Ances, Beau M. and Leuthardt, Eric C. and Shimony, Joshua S.\nFront Neurol, 2022\n\n# Title\n\nResting state network mapping in individuals using deep learning\n\n# Keywords\n\ndeep learning\nmachine learning\nresting state functional MRI\nrepresentation of function\nbrain mapping\n\n\n# Abstract\n \n## Introduction \n  \nResting state functional MRI (RS-fMRI) is currently used in numerous clinical and research settings. The localization of resting state networks (RSNs) has been utilized in applications ranging from group analysis of neurodegenerative diseases to individual network mapping for pre-surgical planning of tumor resections. Reproducibility of these results has been shown to require a substantial amount of high-quality data, which is not often available in clinical or research settings. \n\n\n## Methods \n  \nIn this work, we report voxelwise mapping of a standard set of RSNs using a novel deep 3D convolutional neural network (3DCNN). The 3DCNN was trained on publicly available functional MRI data acquired in   n   = 2010 healthy participants. After training, maps that represent the probability of a voxel belonging to a particular RSN were generated for each participant, and then used to calculate mean and standard deviation (STD) probability maps, which are made publicly available. Further, we compared our results to previously published resting state and task-based functional mappings. \n\n\n## Results \n  \nOur results indicate this method can be applied in individual subjects and is highly resistant to both noisy data and fewer RS-fMRI time points than are typically acquired. Further, our results show core regions within each network that exhibit high average probability and low STD. \n\n\n## Discussion \n  \nThe 3DCNN algorithm can generate individual RSN localization maps, which are necessary for clinical applications. The similarity between 3DCNN mapping results and task-based fMRI responses supports the association of specific functional tasks with RSNs. \n\n \n\n# Body\n \n## 1. Introduction \n  \nIt is well known that intrinsic neural activity is temporally correlated within widely distributed brain regions that simultaneously respond to imposed tasks ( ). This phenomenon is known as resting functional connectivity, and the associated topographies are known as resting state networks (RSNs) or intrinsic connectivity networks ( ,  ). Resting state functional connectivity can be studied using both invasive and non-invasive electrophysiology ( ,  ). However, the majority of research on resting state functional connectivity focuses on blood oxygen level dependent (BOLD) functional magnetic resonance imaging (fMRI), which, in the absence of specific tasks (e.g., finger tapping), is referred to as resting state fMRI (RS-fMRI). Correlation analysis of these fluctuations identifies spatial patterns of functional connectivity widely known as RSNs ( ,  ). \n\nRS-fMRI studies have yielded a better understanding of normal brain functional organization and the pathological changes that occur in neuropsychiatric disorders, e.g., Alzheimer's disease, HIV infection, autism, Parkinson's disease, Down syndrome, and others ( \u2013 ). RS-fMRI mapping also has applications in pre-surgical planning of operative procedures for the treatment of brain tumors and repetitive trans-cranial magnetic stimulation for depression ( \u2013 ). However, reliable results often need a large amount of data which can be difficult to acquire in some patient populations ( ,  ). \n\nDeep learning (DL) is a branch of machine learning that has become widely used in multiple domains. DL is a form of artificial neural networks comprising multiple \u201chidden\u201d layers between the input and output, which simultaneously perform feature selection and input/output mapping by adjusting network weights during training. DL models have achieved state-of-the-art performance on numerous tasks, often times comparable to or exceeding human performance ( \u2013 ). This development has led to the adoption of DL in medical research, with the ultimate goal of achieving precision medicine at the individual patient level ( \u2013 ). Applications of deep learning to neuroimaging data range from artifact removal, normalization/harmonization, quality enhancement, and lowering radiation/contrast dose ( \u2013 ). \n\nDefining RSNs accurately is important and difficult and there is no established method to do so. Thus, in this study we trained a deep three-dimensional convolutional neural network (3DCNN) utilizing a large cohort of healthy participants (  n   = 2,010) across a wide age range to generate maps that represent the probability membership of a voxel belonging to a particular RSN. These maps are referred to herein as voxelwise RSN membership probability maps. Model results were compared to publicly available RS-fMRI ( ) and aggregated task fMRI (T-fMRI) mappings compiled in the Neurosynth platform ( ) ( ). The trained model was further evaluated for stability given varying quantities of resting state fMRI data and levels of added noise. Voxelwise RSN membership probability maps (group mean and standard deviation) were derived using the model results from all available data and are made publicly available. The 3DCNN algorithm can generate individual RSN localization maps, which are necessary for clinical applications ( ,  ). \n\n\n## 2. Materials and methods \n  \n### 2.1. Data \n  \nNormal human RS-fMRI data (  N   = 2,010) were obtained from the control arms of primary studies designed, conducted, and analyzed external to the derivative study described herein. These include the Brain Genomics Superstruct Project ( ) (GSP) and ongoing studies at Washington University in St. Louis, including healthy control data from the Alzheimer's Disease Research Center and Neurodegeneration studies ( ). All participants were cognitively normal based on study-specific performance testing. The appropriate Institutional Review Board approved all studies, and all participants provided written informed consent for the given study, which also allowed de-identified data for use in this derivative study. \n  \nCharacteristics of training data. \n  \n\n### 2.2. Magnetic resonance imaging (MRI) acquisition \n  \nAll neuroimaging was performed on 3T Siemens scanners (Siemens AG, Erlangen, Germany) equipped with the standard 12-channel head coil ( ). A high-resolution, 3-dimensional, sagittal, T1-weighted, magnetization-prepared rapid gradient echo scan (MPRAGE) (echo time [TE] = 1.54\u201316 ms, repetition time [TR] = 2200\u20132,400 ms, inversion time = 1,000\u20131,100 ms, flip angle = 7\u20138\u00b0, 256 \u00d7 256 acquisition matrix, 1.0\u20131.2 mm  voxels) and T2-weighted fast spin echo sequence (FSE) (TR = 3,200 ms, TE = 455 ms, 256 x 256 acquisition matrix, 1 mm isotropic voxels) were acquired. RS-fMRI scans were collected using a gradient spin-echo sequence (voxel size = 3\u20134 mm , TR = 2,200\u20133,000 ms, FA = 80\u201390\u00b0) sensitive to BOLD contrast. Statistical analysis of network functional connectivity (evaluated within the default mode and dorsal attention network) between the different data sets revealed no major group differences ( ). Each participant contributed ~7\u201314 min of resting state fMRI data, processed using standard methods developed at Washington University ( ).   provides study-specific details related to RS-fMRI image acquisition. \n\n\n### 2.3. MRI processing \n  \nRS-fMRI data were preprocessed using previously described techniques including non-linear atlas registration ( ). Dynamic fMRI data was adjusted to obtain consistent imaging intensities across slices, thereby accounting for interleaved acquisitions and differential timings across slices. fMRI data was also adjusted for head motion within scan sessions and across scan sessions for each subject using rigid-body transformations. We further censored fMRI time frames by excluding frames exceeding 0.5% of the root-mean-squared intensity variation of scanned frames ( ,  ). All fMRI data were affinely transformed to a standardized atlas generated from T1-weighted images historically acquired from healthy, young adults on Siemens Trio scanners at Washington University ( ). Whenever available (HIV and ADRC), affine transformations used T2-weighted images for refinement of spatial normalization. Typical composite transformations provided affine mappings of fMRI to T2-weighted images to MPRAGE to the standardized atlas. Spatial normalization also involved exclusion of transient magnetization precessions in the initial five frames of fMRI, Gaussian filtering with isotropic kernels of 6 mm full-width at half-maximum, removal of linear fMRI signal trends within scan sessions, low pass filtering at 0.1 Hz, removal of linear regressions for head motion, removal of fMRI time series localized to white matter or CSF, and removal of fMRI time series averaged over the whole brain. The latter global signal regression ensured that subsequent calculations of correlation-related measures were zero-centered partial correlations controlling for brain-wide variances ( ). Volume-dependent nuisance regressors derived from segmentations generated by FreeSurfer for each subject ( ). For visualizations, all imaging was affinely transformed to high-resolution MNI atlases. \n\n\n### 2.4. 3DCNN \n  \nA 3D convolutional neural network (3DCNN) with 74 layers was trained to classify each gray matter voxel to a given RSN. The 3DCNN was implemented in Matlab R2019b ( ). It had a densely connected architecture ( ), with residual layers ( ) nested within each of the three dense blocks. Within the network, 1 \u00d7 1 \u00d7 1, 3 \u00d7 3 \u00d7 3, and 7 \u00d7 7 \u00d7 7 convolutions were performed. The final output, as well as the output from each dense block was directly connected to the cross entropy layer after global average pooling and 20% dropout. This training strategy has been shown to prevent overfitting through structural regularization, is more robust to spatial translations of the input, and requires fewer learnable parameters ( ,  ). Batch normalization was used prior to convolutional operations within the network. Leaky rectified linear units were used after convolutions. Both max and average pooling were used between dense blocks for dimensionality reduction. Combining max and average pooling has been shown in some studies to outperform either technique on its own ( ). Each pooling layer was 2 \u00d7 2 \u00d7 2 with a stride of 2.   shows the 3DCNN architecture. Because the number of samples from each class (RSN) was not constant, the 3DCNN used a cross entropy loss function with weighted classification such that each class contributed equally to the loss function. Training was terminated if the accuracy did not improve after three validations. \n\n\n### 2.5. Training data \n  \nPredefined seed regions of interest ( ) (300 ROIs,  ) were used to assign voxels to one of 13 RSNs for generation of training data. The networks include dorsal somatomotor (SMD), lateral somatomotor (SML), cinguloopercular (CON), auditory (AUD), default mode (DMN), parietal memory (PMN), visual (VIS), frontoparietal (FPN), salience (SAL), ventral attention (VAN), dorsal attention (DAN), medial temporal (MTL), and reward (REW). Training sample connectivity maps for each RSN were generated by random sampling of voxels within ROIs of a given network. The RS-fMRI signal within these voxels was averaged and used to extract a whole brain 3D similarity map. For example, for a given network (X) and an individual scan, we generate a single training sample by subsampling ROIs known to belong to X, averaging those ROIs together, and calculating the similarity of the mean signal with the rest of the voxels in the brain. Similarity was calculated by computing both the Pearson product moment correlation and Euclidean Distance between the mean of the subsampled RS-fMRI signals and all other voxels in the brain. The 3D similarity map was then assigned to the selected RSN (after confirming that it had the highest correlation between the mean subsampled signal and the mean signal for each network). The assigned network labels were used for classification during training of the 3DCNN. This process was applied in numerous iterations for each network and for each participant.   shows examples of 3D similarity maps of the DMN, FPN, and SMD used for training. A total of 1,313,140 training instances (~100,000 per network) were generated across all networks. During training, samples were augmented by a combination of 3D random affine transformations [rotations (\u00b15 degrees), translations (\u00b13 pixels)], intensity scaling (between 0.9 and 1.1), shearing (\u00b13Degrees), and adding gaussian noise. Data augmentation has been shown in numerous studies to improve out of sample testing and prevent overfitting ( ). Two hundred fMRI scans from our training data set (approximately 10% of the data) stratified based on age, gender, and study were reserved for generating validation data for the 3DCNN, and validation samples were generated in the same manner as above. Approximately 200,000 validation samples (~15,000 per network) were generated from the held out scans. \n\n\n### 2.6. Testing data \n  \nAfter training, model outputs were compared using RS-fMRI data from the Midnight Scan Club ( ) (MSC) collected at Washington University. The MSC contains high quality data collected from 10 participants, each scanned for 30 min in 10 separate sessions. The MSC data are freely avaliable ( ) and have been thoroughly characterized in numerous studies ( ,  \u2013 ). MSC data were used to evaluate model performance given a reduced quantity of fMRI data, and to evaluate model performance after noise addition. Unstructured noise addition was performed by adding the scaled fMRI data to scaled pink noise. For example, to achieve 10% noise injection, the fMRI data was rescaled to a [\u22120.9 0.9] interval, the noise signal was scaled to a [\u22120.1 0.1] interval, and the signals were added together. A new noise signal was generated for each voxel. Similarity between results was measured using the multiscale structural similarity index (MSSI) ( ). MSSI estimates similarity of a pair of 3D volumes by first estimating similarity of the pair for successively down-sampled versions of the pair, typically down-sampling by factors of 2, 4, 8, 16, and 32. Down-samplings are weighted according to a Gaussian distribution peaked at the middle spatial factor to mimic human visual sensitivity for spatial patterns. In the current state of the art, RSN topographies are identified, and distinguished from noise or artifacts, by human visual assessments. Whether by seed correlations, factorizations such as independent component analysis, or community detection algorithms, final adjudication involves prior expectations of RSN topographies derived from reported studies. MSSI represents one of the best performing implementations of objective structural similarity indices which posit that human visual assessments are effectively ground truths. Structural similarity provides better metrics of human visual assessments than simpler metrics such as mean squared error, peak signal-to-noise ratio, and their variations that invoke penalizations. Structural similarity indices are especially suited for assessment of RSN features because it compares imaging instances with arbitrary reference imaging providing effective ground truths ( ). For visualization purposes the final outputs were mapped to an average surface space with the methods described in using \u201cConte69 atlas fs_LR\u201d surface using HCP workbench ( ,  ). \n\n\n### 2.7. RSN characterization \n  \nMean voxelwise RSN membership probability maps were generated by averaging the 3DCNN output for each subject in our sample for each RSN separately. The same data set was used to generate a voxelwise standard deviation (STD) map and a voxelwise map of the mean divided by the STD. These maps were then used to create RSN summary measures as the area included in each RSN, averages of the mean and mean/STD over the extent of each RSN based on the winner take all maps (see below). \n\nTo evaluate our results in the context of traditional, seed-based correlation analysis, we correlated RSN membership probabilities produced by the 3DCNN and compared those to traditional time series correlation matrices. The 3DCNN correlation matrices were generated by correlating the softmax output probabilities, while the functional connectivity matrices were generated by correlating the RS-fMRI time series at both the voxel and ROI level. \n\n\n### 2.8. Comparison data \n  \nAs a partial validation of our method we compared our results with two different schemes. First, we compared our results with RSN maps published by Dworetsky et al. ( ). Their study generated probabilistic mappings of RSNs by using data from five independent data sets, one for data-driven network discovery and template creation, the second for template matching and probability mapping, and the final three for replication of the probabilistic maps. Second, we compared our results with T-fMRI results generated in the Neurosynth platform. The Neurosynth platform (neurosynth.org) can generate statistical maps of significance of T-fMRI responses to behavioral paradigms ( ). In brief, Neurosynth parses texts of published T-fMRI studies to generate aggregrated task activation data linked to user-selected search terms, e.g., \u201clanguage.\u201d Neurosynth maintains a large database of publications on T-fMRI, which it parses for a set of pre-defined term and activations related to brain function paradigms. When an article uses a term, Neurosynth attempts to extract brain regions that were consistently reported in the tables of that study. The list of terms used in our analysis were \u201cattention\u201d (corresponding to DAN), \u201cauditory,\u201d \u201cdefault mode,\u201d \u201clanguage\u201d (corresponding to VAN), \u201cmotor\u201d (corresponding to SMD), \u201creward,\u201d and \u201cvisual.\u201d For both comparisons, similarity was measured using the MSSI. \n\n\n\n## 3. Results \n  \nParticipant demographics are shown in  . A majority of the cohort were Caucasian (69%) females (59%), with an average age of 44.6 \u00b1 23.5 years and 14.8 \u00b1 2.2 years of education.   shows the age distribution based on the studies used in the analysis. \n\n### 3.1. Model results \n  \nThe model achieved 99% accuracy on training data and 96% accuracy on out of sample validation data after eight epochs ( ). After training, data from all 2,010 participants were processed with the 3DCNN, and mean and standard deviation maps were generated from those results.   shows the RSN segmentation based on the winner take all (WTA) of softmax probabilities produced by the 3DCNN averaged across all 2010 participants. Similarly,   displays the segmentation results projected onto the cortical surface, and   shows the mean voxelwise RSN membership probability maps for each network (0.2 threshold).   shows the per-network voxel count based on a given probability threshold. \n  \nVolumetric segmentation of resting state networks based on maximum probability produced by the 3DCNN averaged across 2010 participants. SMD, dorsal somatomotor; SML, lateral somatomotor; CON, cinguloopercular; AUD, auditory; DMN, default mode; PMN, parietal memory; VIS, visual; FPN, frontoparietal; SAL, salience; VAN, ventral attention; DAN, dorsal attention; MTL, medial temporal; and REW, reward. \n    \n (A)   Surface segmentation of resting state networks based on maximum probability produced by the 3DCNN averaged across 2,010 participants.   (B)   Probability maps of individual resting state networks averaged across 2,010 participants. SMD, dorsal somatomotor; SML, lateral somatomotor; CON, cinguloopercular; AUD, auditory; DMN, default mode; PMN, parietal memory; VIS, visual; FPN, frontoparietal; SAL, salience; VAN, ventral attention; DAN, dorsal attention; MTL, medial temporal; and REW, reward. \n  \n\n### 3.2. Model stability \n  \nThe model was evaluated for stability of results based on the number of RS-fMRI time points and signal noise.   shows the result of reducing the total number of RS-fMRI time points averaged over the MSC data. On average, the model maintained a 0.9 MSSI when comparing 8,000 time points to ~150 time points (~5:30 min). However, stability varied across networks ( ).   shows the effect on MSSI similarity on varying levels of added pink noise. Overall, the model maintained 0.9 similarity even after the addition of 25\u201330% noise in the original RS-fMRI signal. \n  \n (A)   Result of reducing the total number of BOLD time points. On average, the model maintained a 0.9 structural similarity when comparing 8,000 time points to ~150 time points.   (B)   Structural similarity when comparing model results with various amounts of noise added to the BOLD signal. The model maintained 0.9 structural similarity even after injecting 25\u201330% noise in the original bold signal. \n  \n\n### 3.3. RSN characterization \n  \n shows the mean, STD, and mean/STD probability maps for the DMN (masked based on WTA probabilities from  ). These results show that a large number of voxels show high mean probabilities. However, the STD maps show that the majority of those voxels have a relatively high STD, likely due to individual subject variability and limited signal to noise ratio in the data. Scaling the mean values by the STD, a measure akin to signal to noise ratio, demonstrates higher certainty of RSN membership centrally and the expected uncertainty present at the margins of the WTA regions. \n  \nMean, standard deviation (STD), and mean/STD probability maps for the default mode network (DMN). The mean results show a large number of voxels with high probabilities. STD maps show the majority of voxels have a relatively high STD. When scaling the mean values by the STD, the regions with high relative probabilities becomes significantly smaller. \n  \n shows the mean probability values averaged over each RSN based on the mean WTA probability mask as shown in  . The highest average probabilities were observed in AUD, VIS, and somatomotor networks. Similarly, 5B shows the average values for the mean scaled by the standard deviation, indicating which networks have higher vs. lower individual subject variability. Lastly, 5C shows the total area for each network calculated by dividing the total number of voxels belonging to each network ( ) by the total number of voxels considered in the gray matter mask. VIS, DMN, and FPN covered the greatest area. \n  \nNetwork summary measures.   (A)   Mean probability values averaged over each RSN based on the argmax probability ( ). The highest average probabilities were observed in AUD; VIS; and somatomotor networks.   (B)   Average values for the mean scaled by the standard deviation.   (C)   Total area for each network. VIS; DMN; and FPN covered the greatest area. SMD, dorsal somatomotor; SML, lateral somatomotor; CON, cinguloopercular; AUD, auditory; DMN, default mode; PMN, parietal memory; VIS, visual; FPN, frontoparietal; SAL, salience; VAN, ventral attention; DAN, dorsal attention; MTL, medial temporal; and REW, reward. \n  \n\n### 3.4. Comparison with prior task and resting state and task results \n  \n shows the comparison of the 3DCNN results computed over the MSC data with functional maps generated from the Neurosynth platform. This comparison provides clear evidence of the similarity, at the group level, between task based functional responses and RSNs, with all spatial similarity measures being <0.83 (SMD) and peaking at 0.92 (DMN) as measured by the MSSI.   shows the MSSI similarity comparisons to the Dworetsky et al. ( ) segmentation including off-diagonal terms. The diagonal elements are all >0.8, demonstrating a high degree of overlap between RSNs determined using these two different methodologies. The strongest similarities were seen in AUD, VIS, SMD, and SML. \n  \n3DCNN results computed over the MSC data and functional maps generated from the Neurosynth platform. Of the networks evaluated, default mode (DMN), auditory (AUD), and attention [corresponding to dorsal attention (DAN)] showed the greatest structural similarity as measured by the MSSI. \n    \n3DCNN results compared to maps published by Dworetsky et al. ( ). The strongest similarities were seen in AUD; VIS; SMD; and SML. SMD, dorsal somatomotor; SML, lateral somatomotor; CON, cinguloopercular; AUD, auditory; DMN, default mode; PMN, parietal memory; VIS, visual; FPN, frontoparietal; SAL, salience; VAN, ventral attention; DAN, dorsal attention; MTL, medial temporal; and REW, reward. \n  \n\n### 3.5. Correlation analysis \n  \n shows a comparison between correlated RSN membership probabilities produced by the 3DCNN and the traditional functional connectivity matrices produced from Pearson's correlation of the time series. These results are averaged over all 2010 data samples at both the voxel level (top row) and the ROI level (bottom row). By first processing the fMRI data with the 3DCNN and then correlating softmax inferences, we see much higher correlations and greater orthogonality between regions as compared to directly correlating the fMRI time series. The greater orthogonality demonstrates the improved ability of the 3DCNN to separate between the RSN. \n  \nThe 3DCNN allows for novel similarity measures. Softmax marginal probabilities can be correlated to generate alternative connectivity matrices between functional regions. Correlations between 3DCNN softmax probabilities are compared to correlations between BOLD time series for voxels   (top row)   and ROIs   (bottom row)  . The 3DCNN shows higher correlations and greater contrast between regions compared to conventional BOLD correlations. SMD, dorsal somatomotor; SML, lateral somatomotor; CON, cinguloopercular; AUD, auditory; DMN, default mode; PMN, parietal memory; VIS, visual; FPN, frontoparietal; SAL, salience; VAN, ventral attention; DAN, dorsal attention; MTL, medial temporal; and REW, reward. \n  \n\n\n## 4. Discussion \n  \nOur research defines a robust voxelwise classification model of RSNs. We showed 96% validation accuracy in classifying RSNs in a large cohort of healthy participants covering a broad age range. These results were achieved on data collected from multiple scanner types and sequence parameters ( ). Further, the model was resilient to both noisy data and fewer time points ( ). Robustness to limited and noisy data is important in clinical work and in neuroimaging studies with limited scanner time, as the reliability of functional connectivity mapping strongly depends on both the quantity and quality of available resting state data ( ,  ). \n\nThe 3DCNN can be viewed as an algorithm that increases model accuracy by selecting relevant features and disregarding irrelevant, redundant, or noisy features ( ). In application to RSN localization, the feature of interest is the correlation structure of multivariate data.   shows a matrix depicting 3DCNN RSN membership probabilities in comparison to fMRI time series correlations at both the voxel and ROI levels. In this context, the 3DCNN can be viewed as a supervised feature extraction method optimized over the 13 networks with RSN membership probability as the extracted feature. The key feature in   is the contrast between the RS-fMRI functional connectivity matrix, which shows strong, predominantly negative values in the off-diagonal blocks, vs. the result generated by the 3DCNN, which shows only minimal values in the off-diagonal blocks. The significance of this difference relates to the hierarchical structure of RSNs ( ,  ). Such hierarchical organization mandates that signals generally are shared across multiple RSNs, hence, the appearance of correlations and anti-correlations in off-diagonal blocks of correlation matrices. Moreover, the total number of discrete RSNs is theoretically infinite ( ) although models comprising 2, 7, and 17 RSNs exhibit particularly favorable goodness of fit criteria ( ,  ). After training on a selected set of discrete RSNs, the 3DCNN assigns approximately unique RSN membership to each part of the brain. In effect the 3DCNN orthogonalizes the intrinsically hierarchical correlation structure of resting state BOLD fMRI data. \n\nA goal of this research was to provide voxelwise group statistics based on all participants to identify ROIs with the highest network membership probabilities. Several different methods have been developed in the literature for the identification of functional connected networks using RS-fMRI data in groups and in individuals ( ,  ,  ,  ). These techniques have been expanded to include sub-cortical structures, the cerebellum, and combined with other imaging modalities ( \u2013 ). Although there is no recognized gold standard for network mapping, our results are similar to results obtained using different methodologies ( ,  ,  ). Our published maps contribute to this literature and, given the large sample size and model robustness, provide an advantageous set of ROIs for group level RS-fMRI analysis that could be used in future studies. \n\nWe compared our results with probabilistic maps derived from multiple RS-fMRI data-sets recently published by Dworetsky et al. ( ) ( ). The AUD, VIS, SMD, and SML networks show the highest correspondence between the RSN maps proposed by Dworetsky et al. ( ) and the present results. The same networks show the greatest consistency across subjects (expressed in terms of SNR) in  . Thus, RSNs involving primary cortical areas exhibit the greatest consistency across individuals and datasets whereas RSNs involving \u201chigher order\u201d functional systems, e.g., those associated with cognitive control (CON) and memory (DMN), are topographically more variable. These observations are consistent with prior results showing that association system RSNs are more variable across individuals in comparison to RSNs representing sensory and motor functions ( ). In contrast, functional connectivity within primary cortical areas is more variable within individuals and across sessions, a phenomenon most likely reflecting differences in levels of arousal ( ,  ). \n\nResting state functional connectivity analysis began with the observation that the topography of spontaneous activity correlations within the somatomotor system replicates finger-tapping task responses ( ). This result was later extended to other tasks, giving rise to the notion that RSNs can be associated with specific sensory, motor, and cognitive functions ( ). However, with respect to \u201chigher order\u201d RSNs, these associations appear to be incompletely specific and dependent on the details of the imposed task ( ,  ). Thus, the objective of associating RSNs with specific cognitive processes is far from trivial. In this context, we report a comparison of a subset of current RSNs with task-based responses aggregated in the Neurosynth platform ( ). The key word used to search Neurosynth is listed at the left of each row. This comparison provides clear evidence of the similarity, at the group level, between task based functional responses and RSNs, with all spatial similarity measures being at least 0.83. The results shown in   do not include all 13 present RSNs. However, they suggest the possibility that a more complete account of the associations between 3DCNN-mapped RSNs and specific cognitive processes may be feasible. Achieving this objective is of great importance from the clinical and research perspectives. \n\nFrom the clinical perspective, secure functional localization can serve as the basis for expanding the use of RS-fMRI for pre-surgical applications ( ,  ). There are numerous advantages of using RS-fMRI for clinical brain mapping in comparison to task based paradigms. While preoperative fMRI can significantly improve long term survival in the setting of surgical resection of malignant brain tumors, its dependence on patient participation limits who can access the mapping (i.e., children and modestly impaired patients) ( ,  ). The need for personnel to administer the scans and the long duration of acquisition limits how often the task-based techniques are available. Also, when clinically applied for preoperative brain mapping task-based fMRI has a high failure rate. The limitations of current mapping methods are obviated by the use of RS-fMRI generally. RS-fMRI is robust, highly efficient, requires minimal task compliance, and has a substantially reduced failure rate when used clinically (when compared to task-based methods). Our method has the potential to further simplify and streamline brain mapping by automating functional localization and limiting the need for significant technical and scientific expertise that are required with more classic approaches (e.g,. seed-based mapping). \n\nA number of limitations and future directions exist in relation to the present study. The current study primarily focused on results in the context of group averages. While we have provided STD maps which reflect voxelwise variability between subjects, future work should focus on a more detailed analysis of individual subject variability between probability maps produced by the 3DCNN. Similarly, differences in networks due to demographics, such as age and gender should be investigated. Second, while there was a high degree of similarity between our results and other published resting state and task network maps, there were some differences. Future work could involve an in-depth comparison of the topographical differences observed among the various published network maps. Lastly, our model showed little difference when comparing results derived using 8,000 time points (~300 min) compared to results from ~150 time points (~5 min). While these results are promising, future work should focus specifically on models optimized for producing probability maps based on data sets with fewer BOLD time points. This could include investigating different network architectures and hyperparameters and their impact on classification accuracy, as well as identifying the optimal number of samples required for the given network. \n\n### 4.1. Conclusion \n  \nIn this work, we have demonstrated the utility of deep learning for accurate probabilistic mapping of resting state networks in the brain. This method is robust to noisy and small data sets. We demonstrate the similarity between our results and other previously published task and resting state segmentations. RSN probability maps are made publicly available, and maybe helpful for future studies interested in ROIs computed from a large data set (>2,000) of normal adults. \n\n\n\n## Data availability statement \n  \nThe original contributions presented in the study (mean and STD probability maps) are included in the article/ , further inquiries can be directed to the corresponding author. \n\n\n## Ethics statement \n  \nThe studies involving human participants were reviewed and approved by Washington University Institutional Review Board. The patients/participants provided their written informed consent to participate in this study. \n\n\n## Author contributions \n  \nPL: conceptualization, methodology, software, validation, formal analysis, investigation, data curation, writing\u2014original draft, and visualization. JL: methodology, software, formal analysis, data curation, writing\u2014original draft, and visualization. KP and RR: software, resources, data curation, writing\u2014original draft, and visualization. KM: conceptualization. EG: methodology and writing\u2014original draft. AS: software, writing\u2014original draft, and supervision. BA: resources, writing\u2014original draft, supervision, project administration, and funding acquisition. EL: conceptualization, resources, writing\u2014original draft, supervision, project administration, and funding acquisition. JS: conceptualization, methodology, writing\u2014original draft, supervision, project administration, and funding acquisition. All authors contributed to the article and approved the submitted version. \n\n \n", "metadata": {"pmcid": 9878609, "text_md5": "9494205374897f28216dd55b40ae499b", "field_positions": {"authors": [0, 200], "journal": [201, 213], "publication_year": [215, 219], "title": [230, 294], "keywords": [308, 409], "abstract": [422, 2116], "body": [2125, 35976]}, "batch": 2, "pmid": 36712434, "doi": "10.3389/fneur.2022.1055437", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9878609", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9878609"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9878609\">9878609</a>", "list_title": "PMC9878609  Resting state network mapping in individuals using deep learning"}
