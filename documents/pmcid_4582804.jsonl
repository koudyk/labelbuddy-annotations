{"display_title": "PMID: 25497693 batch: 10", "list_title": "batch 10 PMID25497693 Semantic retrieval during overt picture description: Left anterior temporal or the parietal lobe? ", "metadata": {"batch_nb": 10, "journal": "Neuropsychologia", "origin_file": "documents_season_1.jsonl", "pmcid": 4582804, "pmid": 25497693, "publication_year": 2014, "text_md5": "c332e006a873413e8854d3d1e970cfc9", "title": "Semantic retrieval during overt picture description: Left anterior temporal or the parietal lobe?"}, "text": "PMID25497693        TITLE         Semantic retrieval during overt picture description: Left anterior temporal or the parietal lobe?        ABSTRACT           Retrieval of semantic representations is a central process during overt speech production. There is an increasing consensus that an amodal semantic \u2018hub\u2019 must exist that draws together modality-specific representations of concepts. Based on the distribution of atrophy and the behavioral deficit of patients with the semantic variant of fronto-temporal lobar degeneration, it has been proposed that this hub is localized within both anterior temporal lobes (ATL), and is functionally connected with verbal \u2018output\u2019 systems via the left ATL. An alternative view, dating from Geschwind's proposal in 1965, is that the angular gyrus (AG) is central to object-based semantic representations. In this fMRI study we examined the connectivity of the left ATL and parietal lobe (PL) with whole brain networks known to be activated during overt picture description. We decomposed each of these two brain volumes into 15 regions of interest (ROIs), using independent component analysis. A dual regression analysis was used to establish the connectivity of each ROI with whole brain-networks. An ROI within the left anterior superior temporal sulcus (antSTS) was functionally connected to other parts of the left ATL, including anterior ventromedial left temporal cortex (partially attenuated by signal loss due to susceptibility artifact), a large left dorsolateral prefrontal region (including \u2018classic\u2019 Broca's area), extensive bilateral sensory-motor cortices, and the length of both superior temporal gyri. The time-course of this functionally connected network was associated with picture description but not with non-semantic baseline tasks. This system has the distribution expected for the production of overt speech with appropriate semantic content, and the auditory monitoring of the overt speech output. In contrast, the only left PL ROI that showed connectivity with brain systems most strongly activated by the picture-description task, was in the superior parietal lobe (supPL). This region showed connectivity with predominantly posterior cortical regions required for the visual processing of the pictorial stimuli, with additional connectivity to the dorsal left AG and a small component of the left inferior frontal gyrus. None of the other PL ROIs that included part of the left AG were activated by Speech alone. The best interpretation of these results is that the left antSTS connects the proposed semantic hub (specifically localized to ventral anterior temporal cortex based on clinical neuropsychological studies) to posterior frontal regions and sensory-motor cortices responsible for the overt production of speech.           BODY            1.\u2003Introduction    Spoken language comprehension and production are dependent on widely distributed sensory, motor and linguistic systems comprising functionally specialized components (  ). However, language is nothing without access to semantic representations.  proposed that the expansion of the human parietal lobe relative to that of other primates and mammalian species, its polysensory connections, its independence from the limbic system, and its anatomical connections with Wernicke's area in the posterior temporal lobe made it the most likely region that linked object words with their multiple perceptual semantic representations. This hypothesis still has its strong proponents in an era of imaging white matter tracts in the living human brain by the use of diffusion tensor imaging (  ). These two authors resurrected the Broca\u2212Wernicke\u2212Lichtheim model, one never abandoned by neurologists. Although Lichtheim had linked speech input (Wernicke's area) to output (Broca's area) via a third region that stored concepts (that is, semantic memories), this was never localized by him to a specific cortical area. Hence, the two eponymous areas of Broca and Wernicke were not accompanied by a third, \u2018Lichtheim's area\u2019. Based on Geschwind's hypotheses,  placed access to semantic representations, during both speech comprehension and production, in the left inferior parietal cortex, which they labeled as \u2018Geschwind's region\u2019.    This role for left inferior parietal cortex has been widely accepted by the clinical neurological community, but based on little direct evidence. The \u2018gold standard\u2019 when determining the role of a brain region in cognitive processing is to examine the behavioral consequences of focal lesions, usually infarcts. Strokes confined to the left parietal lobe are rare. For example,  performed behavioral analyses on 50 patients with aphasic strokes, but none had lesions confined to the parietal lobe alone.    It was patients with the semantic variant of fronto-temporal lobar degeneration (svFTD) that drew attention to the possibility that it is anterior temporal cortex that provides an amodal route through which semantic representations are accessed (  ;  ;  ;  ;  ). These patients have a striking and progressive loss of semantic knowledge, irrespective of the modality of stimulus presentation (verbal, environmental sounds, pictures, etc.) (  ). The maximum area of atrophy in these patients is the anterior temporal lobes (ATL), usually with greater atrophy on the left (  ). Based on the behavioural sequelae in patients with asymmetrical atrophy, that can manifest as more prominent loss of semantic knowledge in a specific modality (e.g. verbal vs. visual), some have suggested that verbal semantics is more dependent on the left ATL while non-verbal semantics is more dependent on the right ATL (  ). Others have argued that these findings reflect differences in the strength of connectivity from a bilaterally distributed semantic hub to modality-specific input/output systems. The latter systems for speech production are lateralized to the left hemisphere (  ). Based on this assertion, it is reasonable to expect that a semantic hub would show functional connectivity with speech \u2018output\u2019 systems during retrieval of semantic knowledge while speaking.    As with the inferior parietal lobe, due to vascular anatomy it is rare for the anterior temporal lobe alone to be the location of a stroke. Consequently, lesion-deficit analyses on aphasic stroke patients alone had not identified a role for this region in semantic processing. Furthermore, patients with anterior temporal lobectomy, an operation commonly performed to treat temporal lobe epilepsy, show, at most, only a limited impairment on semantic tasks, the most prominent being anomia (  ). This may be because chronic pre-surgical focal epileptic discharges reorganize the normal functional neuroanatomy of the semantic system. An alternative view is that bilateral pathology may be necessary for major impairments of semantic memory (  ); and bilateral temporal lobe surgery for epilepsy has been avoided since lessons from the effects on declarative memory of the consecutive, bilateral medial temporal lobe resections on patient H.M. were revealed. Thus, the argument is that right anterior temporal atrophy contributes to the progressive impairment in svFTD even when the left anterior temporal atrophy is more prominent. However, it could be (and has been) argued that other cortical regions, including parietal cortex, will also have pathological changes, and it may be that diffuse mild atrophy is at least contributing to the semantic deficit. Nevertheless, the same argument would apply to patients with posterior cortical atrophy, a variant of Alzheimer's disease, in whom bilateral occipital, parietal and posterior temporal atrophy is most evident. In addition to their prominent visuo-spatial deficits, these patients develop a progressive linguistic rather than semantic impairment, the reverse of what is observed in patients with svFTD (  ).    Therefore, there are good arguments for a major role for the anterior temporal lobe, or lobes, in semantic processing. Initially, it was hoped that functional neuroimaging results from normal subjects might resolve the debates arising from clinical studies. This has not been realized. Meta-analyses have demonstrated widely distributed cortical regions involved in semantic processing (  ). Nevertheless, functional magnetic resonance imaging (fMRI) has probably underestimated any contribution from ventral anterior temporal cortex to semantic processing, as signal from this region is lost with conventional fMRI using gradient-echo echo-planar imaging, the consequence of local magnetic field inhomogeneity (susceptibility artifact) (  ). Different techniques have been adopted to minimize this effect (  ), with some success. In contrast, functional neuroimaging performed with positron emission tomography (PET), although a more cumbersome and limited technique, can recover signal from this region (  ); and PET studies of narrative language comprehension (spoken and written) and narrative speech production, have clearly demonstrated activity in anterior temporal cortex (  ). Nevertheless, the ventral AG was also activated in response to narrative language in both these studies, and any differences in function of anterior temporal and inferior parietal cortices could not be determined from the design of these studies.    One possibility is that a component of inferior parietal cortex is part of a system exerting task-dependent control over access to semantic representations, and that activity in this region observed in functional imaging studies of semantic processing reflects this control rather than activation of the semantic system itself (  ). These proposals have been based on lesion studies, in both stroke patients with \u2018semantic aphasia\u2019 (  ), who have difficulty accessing largely intact semantic representations, and after the induction of temporary partial lesions in normal participants using transcranial magnetic stimulation (  ). It is also a conclusion from the reinterpretation of published functional neuroimaging studies (  ). This evidence is further backed up by demonstrations of functional connectivity between left inferior parietal, posterior temporal and posterior frontal cortices during spoken language production (  ), connectivity that is also captured by analyses of \u2018rest state\u2019 functional neuroimaging data (  ).    A further factor that has to be considered is the role of inferior parietal cortex in episodic memory. A review of functional imaging studies that investigated episodic memory retrieval discussed the activity of lateral parietal cortex and the medial retrosplenial and posterior cingulate cortices and the precuneus (  ). Studies of narrative speech comprehension and production have consistently demonstrated bilateral AG activity, although often rather more prominent on the left. The narrative tasks depended on retrieval of episodic memories, either personal autobiographic memories or stories that had been illustrated by picture cards prior to scanning that had to be recalled during scanning to elicit narrative speech production (  ). Listening to narratives results in both encoding and retrieval of episodic information, as the comprehension of an unfolding story only makes sense if later passages can be related to information conveyed earlier in the course of the narrative. In contrast, it can be envisaged that naming or briefly describing a picture weights the task towards semantic memory retrieval and incidental episodic memory encoding, but not on retrieval. Therefore, the dependency on the two forms of declarative memory will be influenced by the specific task used to elicit speech from a participant.    In this fMRI study of overt picture description, we used multivariate analyses of a functional imaging dataset to identify sub-regions within both the left ATL and the left PL. The task required the participants to generate a few facts about the attributes of the object depicted, a task that places little if any explicit demand on episodic memories. However, the pictures, and what the participant chose to say about them, would have been encoded as episodic memories. The functional connectivity of these regions (left ATL and PL) with widely-distributed whole-brain networks that may be engaged during the task were then determined. The ATL signal was optimized, as far as possible, by using a dual-echo acquisition sequence (  ). In keeping with studies by  and  , we hypothesized that the left ATL, but not the left PL, would predominantly show connectivity with whole-brain \u2018output\u2019 systems known to be strongly activated during task-dependent access to semantics, attributed to the anterior part of Broca's area (Brodmann's area 45) (  ), pre-articulatory processes prior to articulation, located to the posterior part of Broca's area (BA44) (  ), and overt articulation itself, located to primary sensory-motor systems (  ). The functional signature for this system would be significantly greater activity during overt picture description (Speech) when compared with a rest-state baseline (Rest) and two other baseline conditions that were included: counting aloud (Counting) and a \u2018yes/no\u2019 decision on simple visual stimuli (Decision).      2.\u2003Methods     2.1. Participants and fMRI procedure    Twenty-five right-handed fluent English-speaking participants (8 male, average age: 57 years, range: 37\u201378 years) without neurological illness were recruited for the fMRI study. Approval for the study was provided by the National Research Ethics Service Committee-West London.    A Siemens Magnetom Trio 3T scanner was used to derive MRI data using T2*-weighted, gradient-echo, echoplanar, dual-echo parallel imaging (GRAPA) sequence with whole-brain coverage. Thirty-six contiguous axial slices were acquired in an interleaved order (slice thickness, 3\u00a0mm; resolution, 3.5\u00d73.5\u00d73.0\u00a0mm3; field of view, 225\u00d7225\u00d7108\u00a0mm3; repetition time (TR), 10\u00a0s; acquisition time, 2\u00a0s; first echo time (TE1), 13\u00a0ms; second echo time (TE2) 31\u00a0ms; flip angle, 90\u00b0). Quadratic shim gradients were used to correct for magnetic field inhomogeneities within the brain. A high resolution 1\u00a0mm3T1-weighted whole-brain structural image, and field maps were also obtained for each subject.      2.2. Task fMRI paradigm    The task fMRI was identical to that published in (  ). Briefly, a \u201csparse\u201d fMRI design (  ) was used to minimize movement- and respiratory-related artifact associated with spoken language production (  ). Tasks were performed in response to specific visual stimuli during an epoch of 7\u00a0 seconds (s). Following this, a fixation cross was displayed which was the cue for the subjects to discontinue the task. 1\u00a0s later whole brain functional imaging data was acquired over 2\u00a0s. The cycle was then repeated.    During each scan, the subjects performed three runs of the task. Each run consisted of 71 trials containing 4 conditions; 20 overt picture description (Speech), 16 counting (Count), 16 non-verbal decision response (Decision), and 15 silent rest baseline (Rest). Each condition was pseudo-randomly grouped into blocks of two or four trials.    Of the 25 healthy subjects studied, 22 were scanned again under the same conditions, after a mean interval of 98 days (range 64\u2013173 days) for test retest reliability and as part of a larger ongoing study into aphasic stroke. There was no between session difference in both the BOLD activations, and the in-scanner performances during, the scanning conditions. Therefore to increase the power of this study, the data from both sessions were combined in a mixed effect general linear model.    During the Speech trials, subjects were required to define colored pictures of noun objects selected from a standardized picture set over a 7\u00a0s epoch (  ). A total of 120 different pictures representing monosyllabic nouns were displayed at each trial. The participants were instructed to generate as much verbal information pertaining to the given object as possible. The nouns matched across each of the runs and scanning sections with respect to imageability, concreteness, familiarity, and Kucera\u2013Francis frequency based on measures derived from the Medical Research Council psycholinguistic database (  ). As an example of one Speech trial, the participants would view a colored drawing of car and proceed to overtly describe it as \u201c   you drive around in it, it has an engine and four wheels, it is mostly made of metal   \u201d.    During the Count trials, the participants saw a sign \u201c1\u2026\u201d printed in large black font for 7\u00a0s, during which time they were required to count up from 1 at a rate of 1/s. During the Rest trials the subjects saw a fixation cross for the entire 8\u00a0s before data acquisition. The Decision trials were presented in blocks of four consecutive trials, preceded by a trial containing an instruction page, with a simple written and pictorial instruction, reminding the subjects of the task. The subjects were instructed to press a button placed in the left hand, every time they saw a blue square, and ignore orange circles. During the 7\u00a0s, either a blue square or an orange circle was presented at the center of the screen in a random order, each displayed up to a maximum of 1.5\u00a0s. The next stimulus followed with a gap of 0.5\u00a0s either after 1.5\u00a0s had elapsed, or if the subject made a response. The percentage correct responses were calculated. The task itself required no explicit verbal or linguistic processing; audio recording during the Decision task confirmed that less than 0.5% of the decision trials across all subjects involved any overt verbalization.      2.3. Behavioral analysis    The speech output was recorded using an MR-compatible microphone (Optoacoustics FOMRI-III noise cancelling microphone). The recordings of Speech trials were transcribed verbatim. The number of appropriate information carrying words (AICW) as defined by the Comprehensive Aphasia Test battery (  ) and the syllables produced per trial were calculated. AICWs are defined as words or word units that convey information, and therefore mainly consist of nouns, verbs, adjectives and adverbs. Any errors of production were excluded in the breakdown of AICWs, but they were included when calculating the rate of syllable production. Fillers (\u2018um\u2019, \u2018er\u2019, etc.) were not included in the count. A Pearson correlation analysis was used to identify the relationship of AICWs to syllables in both runs. These measures were correlated with activations in the brain systems derived from the functional connectivity analysis.      2.4. Data preprocessing    Prior to standard preprocessing, fMRI images acquired at the early and late echo times were added together (  ). This has been shown to improve the signal from the anterior temporal lobes (  ) which is particularly vulnerable to field inhomogeneities and magnetic susceptibility differences (  ). Next, a signal intensity normalization of alternate slices was performed, to correct for the effects of interleaved slice acquisition and 10\u00a0s TR, that does not allow for T1 stabilization of spins.    Standard preprocessing was carried out in FMRI Expert Analysis Tool (FEAT) Version 6.00, part of FMRIB's Software Library (FSL,  ) in the following manner: motion correction using MCFLIRT (  ); non-brain voxels removal with Brain Extraction Tool (  ); spatial smoothing using a 5\u00a0mm full-width half-maximum Gaussian kernel; grand-mean intensity normalization of the entire four dimensional dataset by a single multiplicative factor; and high pass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma=50\u00a0s) to correct for baseline drifts in the signal. Registration of EPI images to high resolution structural images was carried out by Boundary-Based Registration (  ) and fieldmap based distortion correction which is expected to further improve the signal from the anterior temporal lobes. The high-resolution structural images were registered to the Montreal Neurological Institute standard space images (MNI 152) using FMRIB's Linear Image Registration Tool (FLIRT). To remove motion related noise, variance associated with six motion variables was removed from the whole brain functional data using ordinary least squares linear regression.      2.5. Overview of the connectivity analysis    The outcome of whole brain univariate and multivariate analysis of this study has been published previously (  ). In the current paper, we were specifically interested in identifying sub-regions within the left ATL and PL exhibiting functional connectivity with brain systems known to be engaged by the production of propositional speech. We first used a spatially restricted Independent Component Analysis (ICA) to define functional regions of interest (ROI) within the left ATL and left PL. Next a dual regression analysis was performed based on these individual ROIs to identify spatiotemporal signals that matched the time-course of each ROI (for similar methods see  ;  ;  ). The spatiotemporal signals (here referred to as systems) that spatially resembled known whole-brain distributed networks that were hypothesized to be activated in the Speech task were identified and their associated subject-specific time courses were regressed against the general linear model design matrices and tested for significance. These will be described in more detail below.      2.6. Using a spatially restricted Independent Component Analysis (ICA) to define regions of interest (ROI) within the left ATL and PL    We first defined   a priori   a spatial mask for the left ATL and PL, and subsequently extracted 15 functional ROIs with separable temporal signals within each mask using an ICA (  ). For the PL mask, we started with a functionally derived mask of a large parietal lobe region that we have previously shown to be engaged in overt picture description with an independent dataset (region number 3 from Fig. 3 of  )). This was composed of a large lateral parietal region encompassing both the superior and the inferior lobes (supramarginal gyrus and dorsal two thirds of the left angular gyrus (AG)), which in a whole brain ICA, demonstrated functional connectivity with dorsolateral frontal and posterior inferolateral temporal regions during a spoken language production task (  ). In order to have full coverage of the whole inferior parietal lobe, we supplemented this mask with the anatomical mask of the left AG derived from the Harvard-Oxford Cortical structural atlas. Therefore, the final PL mask contained the entire AG, supramarginal gyrus and the superior parietal lobule.    For the ATL, a region not apparent in the whole-brain analysis published by  , the mask was defined anatomically. We combined the left hemisphere anatomical masks available from the Harvard-Oxford cortical structural atlas (  ) to create an ATL mask encompassing the temporal pole, anterior portions of the superior temporal, middle temporal, inferior temporal, fusiform and parahippocampal gyri in addition to the entire hippocampus (  ).    We then performed a spatially-restricted ICA within the PL and ATL masks using group concatenation Probabilistic Independent Component Analysis (  ), as implemented in Multivariate Exploratory Linear Decomposition into Independent Components (MELODIC) Version 3.10, part of FSL. The following data pre-processing was further applied to the input data: masking of non-brain voxels, voxel-wise de-meaning, normalization of the voxel-wise variance. Pre-processed data were whitened and projected into a 15-dimensional subspace using Principal Component Analysis. The whitened observations were decomposed into sets of vectors which describe signal variation across the temporal domain (time-courses), the session/subject domain and across the spatial domain (maps) by optimizing for non-Gaussian spatial source distributions using a fixed-point iteration technique (  ). Estimated component maps were divided by the standard deviation of the residual noise and thresholded by fitting a mixture model to the histogram of intensity values (  ).    ICA is a multivariate technique that takes advantage of fluctuations in the fMRI data to separate the signal into multiple maximally independent spatiotemporal signals, which may spatially overlap. It has distinct advantages compared to univariate analyses, as it decomposes data in functionally heterogeneous regions, such as the parietal lobe (  ), where components that respond to the task may overlap anatomically with components of other systems that are either not activated by the task, or even deactivated (  ). The total variance in the 4D fMRI data is separated amongst the different spatiotemporal components. Each component has a time-course that may relate to a coherent neural signaling associated with a specific task, artifact, or both. For a more detailed explanation of the application of ICA to speech production tasks, see  .      2.7. Dual regression analysis-functional connectivity with the ROIs from the left ATL and PL    A variant on dual regression was performed on the ROIs that resulted from the ICA decomposition of the PL and ATL. This modified dual regression has been used previously to investigate whole brain connectivity with other brain regions (  ). This process involves two regression steps: first, a regression is performed with the 4D fMRI dataset as the dependent variable, and the 15 ROI spatial maps (from the spatially constrained ICA) as the independent variables. For each run for each subject, this first step results in 15 time courses (one for each ROI spatial map). This can be thought of as finding 15 independent temporal signals for each run (each corresponding to a different, but possibly overlapping, ROI). The second regression step again uses the 4D FMRI data as the dependent variable, and the 15 time courses (from the first regression analysis) are the independent variables. This generates 15 statistics for each voxel, assessing how strongly functionally connected the voxel is to each of the ROIs, resulting in 15 whole-brain statistical maps. In this paper we refer to these functional connectivity maps as \u2018systems\u2019. These maps were corrected for multiple comparisons using a family wise error rate (   FWE)   of   P   <0.01,   t   >5.6.      2.8. Distributed brain systems engaged in the Speech task that were functionally connected to the left PL or ATL    The whole-brain functional connectivity maps of each of the 15 ROIs of the ATL and PL were identified using the dual regression process detailed above. These maps were inspected and excluded from further analyses if: (1) there was a predominant contribution from sources of noise either from movement, CSF, white matter, or variation in head size (  ); (2) the system was restricted to the cortex immediately surrounding the ROI and/or the homotopic region in the contralateral hemisphere; (3) it resembled components of the default mode network (DMN). The last criterion may appear contentious, as posterior components (lateral inferior parietal cortices and midline cortex posterior to the splenium of the corpus callosum) have been strongly implicated in semantic processes, based on functional neuroimaging results (  ). However, our previous whole-brain ICA analyses of speech production did not show any components within these regions that were activated by speech; in fact, the reverse, as the posterior components of the DMN were significantly deactivated during picture description (  ). For connectivity maps of regions with functional connectivity with all of the 15 PL and 15 ATL ROIs, see  . These exclusion criteria resulted in only one ROI from the left ATL, located in the left anterior superior temporal sulcus (antSTS), and one ROI in the left PL, located in the superior parietal lobe (supPL).    Finally, a general linear model was applied to the time course of the system functionally connected to each of these two ROIs, to determine whether the signal was significantly associated with the Speech condition: the run-specific time courses for each subject calculated in the first stage of the dual regression were used as the dependent variable, and the design matrix for the tasks (independent variable) was regressed against them. The resulting   \u03b2   coefficient was the estimate of BOLD signal evoked for the different task conditions. The design matrix modeled the time course of Speech, Count, Decision, and Decision Instruction trials at the beginning of each Decision block. Rest trials were the implicit baseline. The run-specific   \u03b2   coefficients for each individual were then tested for significance in a mixed effects model (using fitlme in Matlab, with subject modeled as random intercept) in order to identify components where activity was greater during Speech, compared to Rest (Speech>Rest) or Speech contrasted with the higher-level baseline conditions of Count and Decision (Speech>Count+Decision), using one-tailed   t   -test).      2.9. Testing the replicability of the whole-brain systems connected to the ATL and PL ROIs    To test the robustness of the two whole-brain systems that connect to the left ATL and PL, we repeated the analysis by varying the dimensionality of the spatially restricted ICA to derive 10 and 25 ROIs within the ATL and PL. The dimensionality of the ICA is usually driven by previous published work, and is chosen somewhat arbitrarily (  ). Previous studies using a spatially constrained ICA have used 7, 10, 15 and 24 decomposition (  ). Networks defined at lower dimensionalities have, in some cases, been shown to split at higher dimensionality into sub-networks (  ), whilst higher-dimensional ICA will account for noise more accurately by extracting variations in the data as additional components (  ).       3.\u2003Results     3.1. Behavioral results    In-scanner speech recording was not available from one subject. For the remaining subjects, across each scanning run, participants spoke 7.42 appropriate information-carrying words (standard deviation or   SD   =1.54) per 7\u00a0s trial and 2.64 syllables per second (   SD   =0.59). The two measures significantly correlated with each other (   r   =0.81,   P   <0.0001). There was no significant difference between the two scanning sessions with respect to the syllable rate and appropriate information-carrying words (paired   t-   test,   P>   0.05).    During the Decision task, subjects correctly identified the blue square target on 98.8% of trials, and correctly inhibited a response to the orange circles on 99% of trials, indicating a ceiling effect with respect to task difficulty. During the Count trials the participants spoke 7.17 words per 7\u00a0s trial (   SD   =1.5).      3.2. Whole brain systems engaged in Speech that functionally connect with the ATL    We first set out to identify whole brain systems that functionally connected with one or more of the 15 anterior temporal lobe ROIs and that may be engaged in semantic retrieval when verbally describing objects. These ROIs are shown in  (with the two mask regions shown in blue and the specific ROIs shown in red). As described in the methods only one ROI in the ATL and one in the PL mask matched the criteria for further evaluation. The red ATL ROI in  is located in the anterior superior temporal sulcus (antSTS). This was functionally connected to the distributed whole-brain system shown in  (also see  ).    This system included activity in: a large left inferior frontal gyrus region, including pars triangularis and opercularis; bilateral primary and association auditory cortices, including planum temporale and Heschel's gyrus; left more than right insular activity extending into putamen; bilateral primary sensory-motor cortices. A small, but statistically significant, region of activity was also seen in the supplementary motor area. Other temporal lobe regions included the left hippocampus and parahippocampal gyrus, extending into temporal fusiform cortex. There was no activity in the right temporal cortex. The activity in the left posterior superior temporal cortex merged with the most ventral part of the left PL.    A mixed-effect analysis confirmed that activity in this network was significantly greater during the contrast of Speech against the baseline conditions (Speech>Rest:   t   =1.8,   P   =0.04; Speech>Count+Decision:   t   =2.0,   P   =0.025). In addition, the activity in this system, showed a significant positive relationship with both the average number of AICW (   t   =1.76,   P   =0.04, 1-tailed, 43 DF) and the syllable rate (   t   =2.08,   P   =0.02, 1-tailed, 43 DF), although there was no significant relationship between either variable with activity, when partialling out the effect of the other. This is not surprising as syllable rate and AICW are not orthogonal in normal subjects. Inevitably the analysis of such a task may be unable to separate semantic from sensory (auditory and somatosensory) and motor processes associated with overt speech production. On the other hand this system was significantly more active for Speech than the higher-level baseline tasks of Counting and Decision (both requiring sensory-motor responses to execute the task, and in the case of Counting with the same word production rate as in Speech (   P   =0.40).      3.3. Whole brain systems engaged in Speech that functionally connect with the PL    The ROI in the PL (  ) was located in the superior parietal lobe (supPL). This ROI was functionally connected to the distributed whole brain system shown in  . This system predominantly incorporated regions known to be involved in processing of the visual stimuli. Posterior areas of activity related to visual processing included: bilateral lateral occipital cortices, extending superiorly to superior parietal lobe; bilateral posterior midline cortices (the cuneus) and visual cortices extending anteriorly to the posterior fusiform/lingual gyri. Some of these regions are known to be part of the dorsal attention network (DAN) that has been linked to attentional processing of visual stimuli (  ). Activity was also observed in the frontal eye fields in the left and right posterior superior frontal sulci. In addition, there was activity in the dorsal anterior cingulate gyrus and adjacent superior frontal gyrus, with activity also in bilateral posterior inferior frontal gyri. This system, known as the cingulo-opercular system or salience network (  ), is a frontal executive system involved in cognitive control. There was a large cluster of activity in the left posterior supramarginal gyrus extending to the inferior AG. Additional small clusters of activity were observed in the bilateral superior temporal gyri (left more than right), and in pre- and post-central gyri (see  ).    A mixed-effect analysis confirmed that activity in this network was significantly more during the contrast of Speech against higher-level baseline conditions (Speech>Count+Decision;   t   =3.6,   P   <0.001). There was no correlation of activity in this system with measures of speech production, namely AICW or syllable rate (   P   >0.5).    Specifically, none of the ROIs that at least partially overlapped with the AG mask from the Harvard-Oxford Cortical structural atlas (  , PL ROIs: 2, 6, 7, 8, 9, 10, 11, 14), showed connectivity with systems that were significantly more activated during Speech.      3.4. Robustness of the brain systems connected to the ATL and PL    ICA splits up the variance in the fMRI data into a number of spatially separable but possibly partially overlapping components. The number of these components is dependent on the specified dimensionality of the ICA. Setting a higher dimensionality in ICA decomposes larger networks into more discrete sub-networks (  ). In order to test the stability of the two systems that connect to the antSTS and supPL respectively, we performed the spatially restricted ICA on the ATL and PL at a lower (10) and a higher (25) dimensionality.    For the ATL ROIs, a system connecting with the antSTS and with a high spatial correlation to that shown in  was identified at each dimensionality (   r   >0.88 for 10 ROIs and   r   >0.75 for 25 ROIs) (  , top three rows). For the 25 component decomposition of the left ATL, the time course of this system remained significantly associated with the Speech trials (Speech>Rest:   t   =3.0,   P   =0.02; Speech>Count+Decision:   t   =1.8,   P   =0.04). A similar trend was identified when decomposing the left ATL to 10 ROIs although it failed to reach significance (Speech>Rest:   t   =1.2,   P   =0.12; Speech>Count+Decision:   t   =1.18,   P   =0.12).    With regards to the PL ROIs, a system connecting with the left supPL and with a high spatial correlation to that shown in  was identified at each dimensionality (   r   >0.93 for 10 ROIs and   r   >0.86 for 25 ROIs) (  , bottom three rows). For both the 10 and 25 component decomposition of the left PL, the time course of this system remained significantly associated with the Speech trials compared to high-level baselines (10 ROIs Speech>Count+Decision:   t   =2.83,   P   =0.007. 25 ROIs Speech>Count+Decision:   t   =3.92,   P   <0.001).    We also performed the analysis by deriving the ROIs from a resting state data set (see  ) and found qualitatively similar results. These analyses suggest the systems illustrated in  are spatially robust, and connected to the antSTS and supPL respectively.       4.\u2003Discussion    The speech production task involved the participants viewing a colored-drawing of an object while selecting, under time pressure, from amongst the many items of semantic knowledge that they possessed about that object, before translating that selection into a few overt phrases. At the end of this period, lasting 7\u00a0s, a whole-brain functional image was acquired. Therefore, the recorded BOLD signal will have contained activity associated with many processes, from early visual processing through to the sensory-motor processes involved in articulation. This will have included semantic and linguistic processes, systems involved in attention and domain-general cognitive control (  ); and those engaged when making selections from among competing alternative semantically related responses, (  ).    The purpose was to identify from these many activated systems the one or a few by which attributes were selected from semantic memory and processed through to speech production. In terms of topography, the study was designed to demonstrate whether one or more components in either the left PL or ATL were functionally connected to the left inferior frontal gyrus (known to be activated during selection of competing semantic responses) and the sensory-motor cortices responsible for the overt expression of those response.    The functional connectivity results supported the hypothesis that it was a component of the left ATL, namely the antSTS, that plausibly connects the proposed semantic hub in anterior temporal cortex with selection signals from the left inferior frontal gyrus, coupled with signal that encompassed the frontal operculum and bilateral sensory-motor cortices responsible for pre-articulatory and articulatory processes, respectively. Additional activity in bilateral primary and association auditory cortices is explained by the response to the sound of overt speech production.    It is evident that this component conflated a number of different cognitive, motor and sensory processes. Nevertheless, the result is compatible with the hypothesis that a semantic hub, located in ventral ATL, is functionally connected via the ant STS with the inferior frontal gyrus. The connections will be reciprocal. It has been proposed that amodal semantic processing takes place in bilateral ATL (  ) and more specifically the ventral ATL (  ), but only a left-lateralised response in the ventromedial ATL was observed in this study; compatible with the notion that lateralization is imposed by the \u2018output\u2019.    Therefore, based on this result we propose that the anterior STS, a subcomponent of the ATL, connects the left ventromedial ATL to the inferior frontal gyrus during the performance of a verbal semantic task based on a visual stimulus. This pathway has been promoted as the \u2018ventral\u2019 language pathway, the consequence of studies in both non-human primates (e.g.  ) and humans (e.g.  ), reviewed by  . The dorsal bank of the STS is recognized as multisensory cortex, both in primates (  ) and in humans (  ).  used combined tracer techniques and diffusion spectrum imaging on monkey brains, and demonstrated that the STS is connected to BA 45 and 47 via the extreme capsule. Further evidence for the structural connectivity between the ventral ATL and inferior frontal gyrus via the antSTS, comes from an in vivo human tractography study by  . Despite considerable intra-temporal connectivity within the let temporal lobe, the study failed to identify a direct white matter tract between the ventral ATL and Broca's area. Instead, superior temporal gyrus (including the antSTS) showed considerable connectivity to both ATL and inferior frontal gyrus. In all probability, components of the left IFG that showed strong connectivity with the ATL, mediated multiple functions including both domain-specific (encoding the retrieved semantic attributes as verbal messages) and domain-general executive control involved in selection of responses (  ).    Based on PET metabolic imaging in patients with svFTD,  proposed that the anterior fusiform gyrus, probably incorporating a lateral extension of perirhinal cortex (a heteromodal region strongly connected to third order sensory association cortices), constitutes the semantic \u2018hub\u2019. Perirhinal cortex has a central role in object association memory in the monkey (e.g.  ). This ATL region is precisely where it is difficult to recover signal because of susceptibility artifact, accounting for the relatively weak, and truncated, signal from the ventral ATL in this (and many other) fMRI studies (  ). On the assumption that there was, in reality, much greater activity in this region, then the results from this study can be interpreted as demonstrating functional connections between ventral ATL including perirhinal cortex, polysensory antSTS, and, via the extreme capsule, the left inferior frontal gyrus. Thus the weakened ventral ATL signal from an ROI (ICA component) localized to this region may not have been able to capture its whole brain connectivity. Instead, the ROI based on the antSTS was able to show connectivity with both the inferior frontal and ventral ATL regions.    In addition to the evidence gathered from studies of patients with svFTD, referred to in the introduction, evidence form several other techniques support the contribution of the ATL to semantic processing. First, voxel-based lesion-symptom mapping in patients with post-stroke aphasia, has implicated the left ATL in naming and semantic deficits (  ). Second, repetitive transcranial magnetic stimulation (rTMS) over the lateral ATL, has been shown to mirror picture naming deficits observed in svFTD, in neurologically intact participants (  ). Third, neurophysiological recordings from intracranial electrodes in patients with epilepsy have implicated the ventral ATL in picture naming (  ) and semantic processing (  ).    In contrast to the ATL, one component of the left parietal lobe, activated specifically by the Speech condition and located in the superior parietal lobe (supPL), was functionally connected to systems known to be predominantly engaged in recognising, scanning, and focusing attention on the pictorial stimuli. Activity was observed in bilateral ventral temporal cortex, responsible for the processing of the visual features of the coloured pictures, the perceptual \u2018input\u2019 system, and dorsal regions comprising those responsible for exploratory eye movements and the dorsal attention network (  ). There was additional co-activation of the left AG and left inferior frontal sulcus, which were connected to this predominantly \u2018input\u2019 processing system. In contrast to the connectivity of the antSTS, there was only restricted regions activated in bilateral sensory-motor and premotor cortices and bilateral inferior frontal gyri. No ROIs localized entirely or in part with the left AG were activated solely by the Speech condition.    The activity in the AG and inferior frontal sulcus are consistent with the proposed involvement of these regions in cognitive control (  ) and more specifically semantic control (  ;  ) required in the Speech task. Importantly, unlike the \u2018output\u2019 system connected to the left antSTS, the activity in this predominantly \u2018input\u2019 system did not correlate with the number of AICW produced for each picture. The AG is a functionally heterogeneous region and has been implicated in many domains other than semantics (  ).  proposed a dorsal vs. ventral division within the parietal lobe with the dorsal regions (superior parietal lobe and intraparietal sulcus) being associated with executive-demand processes such as top-down attention, and phonological and semantic decisions. More ventrally the AG was associated with automatic tasks, episodic memory retrieval, sentence level processing as well as the DMN, whilst the supramaginal gyrus was associated with bottom-up attentional processes.    Therefore, the analysis was able to separate these two very broad \u2018input\u2019 (with connectivity to the PL) and \u2018output\u2019 (with connectivity to the ATL) systems, despite the fMRI signal being obtained after both systems had become active. The use of temporally slow \u2018sparse\u2019 sampling in this way was necessary because of the unacceptable noise associated with overt articulation of connected speech. This prevented the use of what would otherwise have been the preferred method, in which rapid event-related functional imaging is used to sample signal weighted towards different time points over the time course of initial stimulus presentation through to response.      Appendix A.\u2003Supplementary material", "utf8_text_md5_checksum": "c332e006a873413e8854d3d1e970cfc9"}
