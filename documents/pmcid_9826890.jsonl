{"text": "Sartin, Samantha and Ranzini, Mariagrazia and Scarpazza, Cristina and Monaco, Simona\nCurr Res Neurobiol, 2022\n\n# Title\n\nCortical areas involved in grasping and reaching actions with and without visual information: An ALE meta-analysis of neuroimaging studies\n\n# Keywords\n\nMeta-analysis\nVentral stream\nDorsal stream\nGrasping\nReaching\n\n\n# Abstract\n \nThe functional specialization of the ventral stream in Perception and the dorsal stream in Action is the cornerstone of the leading model proposed by Goodale and Milner in 1992. This model is based on neuropsychological evidence and has been a matter of debate for almost three decades, during which the dual-visual stream hypothesis has received much attention, including support and criticism. The advent of functional magnetic resonance imaging (fMRI) has allowed investigating the brain areas involved in Perception and Action, and provided useful data on the functional specialization of the two streams. Research on this topic has been quite prolific, yet no meta-analysis so far has explored the spatial convergence in the involvement of the two streams in Action. The present meta-analysis (N\u00a0=\u00a053 fMRI and PET studies) was designed to reveal the specific neural activations associated with Action (i.e., grasping and reaching movements), and the extent to which visual information affects the involvement of the two streams during motor control. Our results provide a comprehensive view of the consistent and spatially convergent neural correlates of Action based on neuroimaging studies conducted over the past two decades. In particular, occipital-temporal areas showed higher activation likelihood in the Vision compared to the No vision condition, but no difference between reach and grasp actions. Frontal-parietal areas were consistently involved in both reach and grasp actions regardless of visual availability. We discuss our results in light of the well-established dual-visual stream model and frame these findings in the context of recent discoveries obtained with advanced fMRI methods, such as multivoxel pattern analysis. \n   Graphical abstract  \n  Image 1   \n   Highlights  \n  \nAn influential model on the specialization of ventral and dorsal visual stream in Perception and Action was proposed in 1992 by Goodale and Milner. \n  \nThe advent of functional magnetic resonance imaging (fMRI) has allowed investigating the brain areas involved in Perception and Action. \n  \nThis meta-analysis reveals the spatial convergence in the involvement of the two streams in Action, and the influence of visual information. \n  \nYet very little attempt has been made so far to identify consistent neuroimaging results across the available literature. \n  \n \n\n# Body\n \n## Introduction \n  \nOver the last three decades, the investigation of the neuroanatomical substrates of goal-directed hand action has received increasing attention. Indeed, hand movements not only allow us to interact with our surroundings, but also enable us to satisfy our basic needs. A deep and comprehensive understanding of the neural mechanisms underlying goal-directed hand action is crucial for advancements in many research areas, such as the ever-growing field of brain-computer interfaces for individuals who have limited or no ability to perform volitional movements. \n\nOne of the most prominent theories about action and perception was put forward by Goodale and Milner in 1992 and is based on behavioural and neuropsychological findings that show a specialization of the dorsal stream in action and the ventral stream in perception ( ). Specifically, the original model describes the functional specialization of the parietal cortex in processing spatial information that is relevant for planning and executing action, and the temporal-occipital cortex in recognition of contents. The proposed two-visual streams model has received much interest, including support and criticism, and it has been a matter of debate for almost three decades (see  ;  ). \n\nThe advent of functional magnetic resonance imaging (fMRI) has allowed investigating the brain areas involved in action and perception and provided useful data on this topic. Despite the challenges related to studying the execution of motor actions with neuroimaging techniques, among which the confined environment of the MR and the risk of inducing motion artifacts, research on the functional specialization of the two streams has been quite prolific (e.g.,  ;  ;  ,  ;  ;  ;  ;  ;  ). Yet very little attempt has been made so far to determine the consistency in neuroimaging results across the published studies, with only one recent study which summarizes the existing data with systematic research and a meta-analytical approach ( ). \n\nIn addition to the specialization of the dorsal and ventral stream in action and perception, respectively, according to the dual-stream theory both streams are involved in processing vision for action, but with different purposes ( ;  ). Specifically, while the dorsal visual stream is specialized in the online control of visually-guided actions, the ventral visual stream processes short-term maintenance of the object representation in memory, and, as a consequence, it is thought to support the guidance of delayed actions in absence of online visual information (i.e. when the brief visual presentation of a stimulus and the action towards it are separated by a delay). Seminal evidence comes from neuropsychological observations of patients suffering from optic ataxia ( ), on the one side, and patients suffering from visual agnosia, on the other side ( ). Optic ataxia is due to dorsal stream lesions and consists of a deficit in reaching towards objects in the visual periphery. Visual agnosia is caused by ventral stream lesions which impair the visual recognition of objects and shapes. Importantly, while optic ataxia patients perform more accurate actions with than without a delay ( ,  ), visual agnosia patients show the opposite pattern ( ), in line with the idea that while the dorsal stream is crucial for online control of immediate actions, the ventral stream permits maintenance of object representation in memory for delayed actions. The importance of such findings about delayed actions resides in the fact that in principle they comprise a big portion of the actions that we perform in our everyday life. For example, when we grab our car keys from a pocket or change the shift while keeping our eyes on the street, we need to retrieve information from memory about our keys and car shift as we cannot directly look at them while we plan and perform the action. \n\nVentral and dorsal visual streams are also differently recruited for immediate and delayed actions. Specifically, while the dorsal stream (i.e., intraparietal sulcus) plays a role in immediate and delayed actions, the ventral stream (i.e., lateral temporal-occipital cortex) might have a more prominent role in delayed actions only. In particular, neuroimaging studies showed that during delayed actions areas in the dorsal and ventral stream are re-activated when a movement is performed in absence of visual information ( ;  ;  ). In addition to these findings, some fMRI studies showed that the early visual cortex (EVC), on or slightly above the Calcarine sulcus, is reactivated during delayed actions in the dark ( ;  ;  ). Further, transcranial magnetic stimulation (TMS) studies determined that while the dorsal stream has a causal role in performing immediate and delayed actions ( ;  ), the ventral stream is crucial for delayed but not immediate actions ( ). \n\nOne of the controversies about previous findings on the involvement of dorsal and ventral stream areas in goal-directed hand actions arises from the fact that not all results point to the involvement of the ventral stream and the EVC in delayed actions without online visual feedback. Indeed, some fMRI studies found reactivation in dorsal but not ventral stream areas during the execution of an action after a delay ( ), while other studies found reactivation in the ventral stream and EVC during action execution in the dark after a delay ( ;  ;  ). Further, the reactivation in visual areas for delayed actions in the dark was higher for grasping than reaching actions, perhaps because grasping requires the retrieval of more detailed information, such as size and shape, than reaching. Yet, no attempt has been made to assess the consistency of results across the literature in a systematic manner. \n\nIn this study we exploited the potential of coordinate-based Activation Likelihood Estimation (ALE) meta-analysis of neuroimaging studies ( ;  ), to explore the neural bases of hand reaching and grasping, performed with and without online visual feedback (i.e., after a delay following the presentation of the target object or in total darkness). We focused on studies investigating hand reaching and grasping because reach-to-grasp is probably the most representative human skilled-action, and it has been extensively investigated to test and confirm the dual-visual stream theory ( ). We based our literature search and article selection on a recent study by  , where a systematic review and meta-analysis of neuroimaging studies on the execution of reach and grasp actions has been provided for a comparison between brain areas involved in number processing and grasping and reaching actions. Meta-analytical studies have proven to be important for the assessment of consistency across neuroimaging studies ( ). Indeed, they enable us to get a summary of the brain areas (i.e., activation clusters) that are active during a particular task, or involved in a cognitive domain, across all the studies published so far. \n\nThe main objective of the current study was to elucidate the brain areas consistently recruited during the execution and guidance of skilled actions, specifically hand reaching and grasping actions, when visual information of the target object and/or the hand is available, and when it is not. More specifically, the present work aimed at addressing two main aims. First, we investigated whether activation in the ventral stream and EVC is found only during the execution of actions with vision or also in complete darkness (aim 1). The former hypothesis would be expected based on the wide body of evidence showing the involvement of temporal-occipital areas in the processing of visual information ranging from simple to complex visual features. The latter hypothesis is suggested by findings that show reactivation of ventral stream areas and EVC during delayed actions performed in complete darkness after a brief presentation of a stimulus ( ). This reactivation is likely related to memory components. To address this aim, we performed two meta-analyses, one including all the studies investigating the execution of reaching and grasping with online visual feedback, and the other one including the experiments exploring the execution of the same actions without visual feedback, and therefore relying on memory. We then directly compared (through a contrast analysis) the two sets of studies (i.e., reaching and grasping with vision vs. without vision) to identify the visual areas that show consistently higher activation for actions executed with as compared to without visual input. Given the well-known role of the ventral stream and EVC in visual perception, we expected to find it consistently activated during actions executed with online visual feedback, as the visual input of the target or the hand approaching the target are being processed ( ;  ). The critical question was whether the ventral stream and early visual areas also show consistent activation during actions performed without visual feedback, given the divergent results on the involvement of ventral stream areas in delayed actions (i.e.,  ;  ). Second, we assessed whether reaching and grasping differentially recruit ventral and dorsal stream areas (aim 2). Some studies have shown that grasping elicits higher activation than reaching actions in the ventral stream and EVC ( ;  ). This might be related to the fact that grasping, but not reaching, requires detailed information about the object properties, such as size and shape, to perform an accurate movement. Although in these studies the visual component of the object is ruled out by the contrast of Grasp vs. Reach, the way in which the object is processed differs between the two actions. Indeed, grasping requires processing the object by taking into account also cognitive aspects, for instance: 1) where to place the digits on the object for accurate, stable, and comfortable grasp; 2) the size of the object; 3) the texture of the object to determine whether it is slippery. Some of these properties are known to be processed in ventral stream areas ( ;  ;  ). As such, we hypothesized consistently higher activation in ventral stream and early visual areas for grasp than reach tasks. To address this aim, we performed two meta-analyses including the experiments investigating: grasping, on one side, and reaching, on the other side. Lastly, we ran a contrast analysis between grasping and reaching (i.e., grasping vs. reaching). \n\n\n## Materials and methods \n  \n### Studies selection \n  \nThe procedure used for the selection of the studies is described in detail in  . The data associated with this study is publicly available and can be found at: \n\n. \n\nTo summarize, the literature search was conducted until December 30, 2020 (for a detailed description of the literature searching process, see PRISMA flow diagram, Annex A). To the best of our knowledge, there was no study published after this date that could be included in this meta-analysis. We identified 565 studies through a database search with Pubmed and bioRxiv on hand reaching and grasping. Further, 454 studies were identified with the use of the \u201crelated articles\u201d function, available in the Pubmed database, and the backward and forward snowballing search strategy, i.e., reference list and citations of primary articles, reviews, and meta-analyses. This selection process led to a total of 1020 studies. After removing duplicates, a total of 954 studies were originally identified to undergo further scrutiny at a later stage. \n\nStudies had to respect the following inclusion criteria to be included in the current meta-analysis:   \nto have written the paper in the English language. \n  \nto use a hand reaching and/or grasping task. \n  \nto investigate brain activity during the action execution phase (i.e., studies that focused on brain activity during the planning phase were excluded). This ensured consistency across the selected studies, where the elicited activation reflected somatosensory feedback and motor outputs, which are absent during the planning phase preceding action execution. This criterion was added to the ones used in the study by  , where the execution as well as the planning phase preceding the movement were considered. As such, five studies were excluded from our meta-analysis ( ,  ;  ;  ;  ). \n  \nto use fMRI or positron emission tomography (PET) to collect data about neural activity. \n  \nto have conducted whole-brain analyses (e.g., studies that use a region of interest (ROI) approach were excluded, as it focuses on predefined areas of the image rather than reporting all activated clusters and could thus bias the result of the meta-analysis;  ). \n  \nto have performed univariate analyses (i.e., papers that conducted multivoxel pattern analysis (MVPA) or functional connectivity analyses were not included). It is important to note that MVPA and univariate analysis produce different types of data (i.e., percentage of classification accuracy vs. extent of activation). Therefore, the meta-analysis of multivariate data is based on values of decoding accuracies (e.g.,  ), which cannot be collapsed with univariate results. To date, the number of MVPA studies on this topic is not large enough to conduct a meta-analytic procedure ( ,  ,  ;  ;  ,  ;  ). \n  \nto report a contrast that shows larger activation level for reaching or grasping than the control condition, i.e., when the contrast shows activation rather than deactivation. The control condition differs from the experimental condition only in the dimension of interest. As such, it depends on the task used in each original study. Examples of control conditions are passive viewing (look), reach, colour detection, simple fingers movement, etc. \n  \nto report findings in either Talairach ( ) or Montreal Neurologic Institute (MNI) coordinate space (i.e., studies not reporting results in a standardized coordinate space were excluded). \n  \nto have included only healthy adults in the experiment. \n  \nto test a sample size of at least 5 participants. \n  \n\n\n### Systematic review \n  \nThe literature was screened in detail and the articles that met the inclusion criteria were selected in accordance with PRISMA guidelines ( ) by  . We checked that the screening procedure was in line with the updated PRISMA guidelines that have been recently published ( ). In addition, we followed recent recommendations on how to conduct a proper neuroimaging meta-analysis ( ). The screening procedure is described in more detail in the PRISMA flow diagram available in Annex A. For the current meta-analysis, 53 studies met the inclusion criteria reported in the previous section. The complete list of included studies is presented in Annex B. \n\nData were extracted from the studies and then checked. We then created a database containing the following information of the selected articles on hand reaching and grasping actions: the sample size, the percentage of females, the mean age of participants, the technique (either fMRI or PET), the experimental task (only grasp, only reach, or reach and grasp), the control task, additional information about the task and stimuli, the relevant contrast selected, the coordinate system, the coordinates of foci and their anatomical labels, the p-value criteria (corrected, uncorrected), and the related statistic (z score, t value). \n\nIn the case of multiple contrasts performed in a single study and on the same group of participants, only the most relevant one was considered (i.e., the contrast that best represents the process under investigation in the present meta-analysis). This approach ensures that there is no dependence across the activation maps of the included experiments which would instead negatively impact the validity of meta-analytic results ( ). As a result of the application of this approach, we eventually selected only one contrast from each of the eligible studies, thus yielding a final list of 53 experiments (i.e., contrasts), consisting of 528 foci, included in the current meta-analysis. We then divided the studies into four categories consisting of two movements (Grasp and Reach) and two levels of visual information (Vision and No vision), as described here below. \n\n\n### Data categorization \n  \nFor the purpose of the current meta-analysis, we further analysed each of the 53 studies in order to extract additional information about the experimental task and the contrast used. In fact, while   performed a meta-analysis of the areas involved in grasping and reaching actions by collapsing the availability of visual information, we further categorized the 53 studies depending on the level of visual information isolated by the contrast. Further, we performed a direct comparison between grasping and reaching studies that was not performed by  . \n\nReaching tasks consisted of moving the hand towards the object with the pointing finger or the knuckles. Grasping tasks consisted of moving the hand towards the object and grasping it with a precision or a whole hand grasp. While some of the studies in this meta-analysis employed either reach or grasp tasks, others included both movement types. Some studies also included ad-hoc control conditions (i.e., passive viewing of the target object). Tasks consisting in moving the arm and hand to the target, without a grip component, were categorized as Reach. Tasks that included the grip component, with or without the movement of the arm towards the target, were categorized as Grasp. For example, the contrasts of: (Grasp vs. Reach), and (Grasp vs. Passive viewing) were both labelled as Grasp, as they both included the grip component (note that this procedure partially differs from the one of  , where a distinction between reach-only, grasp-only, and reach-to-grasp studies was made). \n\nWe then assessed whether the experimental paradigm required participants to perform goal-directed hand actions in total darkness (i.e., participants could not see their moving hand or the target object; No vision condition) or in a dimly light room (i.e., participants could see their own hand moving and the target object or a visual stimulus projected onto a screen; Vision condition). For experiments performed under dim light illumination sufficient to process visual stimuli during action execution, we determined whether the contrast used in the study allowed subtracting neural activity elicited by the visual stimuli and/or the hand performing the movement. If so, we included these contrasts in the No vision condition along with the studies in which participants performed goal-directed movements in complete darkness. \n\nAs a result, we classified the selected studies into the following categories: 1) reaching experiments that isolated neural activity elicited by the somato-motor component of the reaching movement without vision (Reach No vision; number of studies (N)\u00a0=\u00a013); 2) reaching experiments in which visual information about the hand or the target was present in addition to the somato-motor component of the reaching movement (Reach Vision; N\u00a0=\u00a03); 3) grasping experiments that isolated neural activity elicited by the somato-motor component of the grasping movement without vision (Grasp No vision; N\u00a0=\u00a020); 4) grasping experiments in which vision was present in addition to the somato-motor component of the grasping movement (Grasp Vision; N\u00a0=\u00a017). The No vision category includes studies in which vision was not available during the task, as well as studies in which vision of the object was available before movement execution but was removed by the contrast used. The Vision category includes visual processing of the object, hand, or both. Specifically, there are studies where vision was available: 1) before action execution, allowing only vision of the target (i.e.,  ); 2) during the execution of the movement, allowing vision of the target and the moving hand (i.e.,  ); and 3) throughout the movement, and the contrast used (Grasp\u00a0>\u00a0Reach) removed information about the object but not visual processing of the grasping hand (i.e.,  ). The Grasp category includes studies in which the grip component is isolated with or without the transport component. The Reach category includes studies where a grip component is not present. \n\n reports a summary of the studies, contrasts, and isolated components included in each category.   \nComponents isolated by the contrasts used in the studies included for each category in the meta-analysis. \n  Table 1     \n\n\n### Activation likelihood estimation meta-analysis \n  \nWe conducted a coordinate-based meta-analysis (CBMA) which uses the coordinates of activation peaks (i.e., activation foci) reported in a standardized coordinate space. We employed the ALE method ( ;  ) to conduct the coordinate-based meta-analysis of selected fMRI and PET experiments. In particular, the revised version of the ALE algorithm ( ,  ) was run with BrainMap GingerALE software version 3.0.2 (Research Imaging Institute; http://brainmap. org/ale/). The MNI coordinates of activation peaks were converted into Talairach space before performing the meta-analysis. We transformed the coordinate space for as few studies as possible. Since more than half of the studies included in this meta-analysis (30 out of 53) reported coordinates in TAL space, we converted the MNI coordinates to TAL space. \n\nThe ALE algorithm aims at evaluating the brain areas of spatial convergence of activated foci across neuroimaging experiments using the coordinates of the peak activations extracted from individual studies. In particular, the algorithm models the reported activated foci of each experiment as three-dimensional Gaussian probability distributions. The number of participants in each experiment is considered to compute the size of the probability distributions. The uncertainty associated with the spatial location of activated foci due to between-study variances (e.g., between-subject and between-template variances;  ) is considered, quantified and used by the ALE algorithm to compute the width of each Gaussian distribution. The probability distributions of all activation foci extracted from an experiment are then combined voxelwise to obtain a Modelled Activation (MA) map, that is a map (i.e., 3D volume) of activation likelihood that is generated for each included experiment. For each meta-analysis, all the MA maps are combined voxelwise to create an ALE map. Each voxel of this image contains an ALE score which represents the spatial convergence of activated foci at exactly that position ( ). The ALE scores are then tested against a null hypothesis according to which the concordance in spatial activation between experiments can occur by chance and is therefore random (noise;  ), by applying a random-effects spatial inference (i.e., random effects model) instead of a fixed-effects inference to evaluate the agreement on activation peaks across studies. The ALE algorithm uses a permutation procedure to assign each voxel a P value which stems from the probabilities of obtaining an ALE value not equal to the ALE value of the very same voxel based on the null-distribution. We employed Mango software ( ), a multi-image analysis program, to visualize the results of the meta-analysis by overlaying ALE maps onto an anatomical image in Talairach space. \n\n#### Single dataset and contrast analyses \n  \nWe ran four single dataset and two contrast analyses to examine the areas involved in the execution of reaching and grasping movements with and without the availability of visual information. While single dataset analysis indicates the main results of the studies included in each category, the contrast analysis allows comparing results between two different categories (i.e., datasets). In order to examine which areas are consistently involved in visual and non-visual reaching and grasping actions, we performed two meta-analyses separately for each of the two visual conditions across action types: 1) Reach and Grasp Vision, and 2) Reach and Grasp No vision. Further, to investigate which areas are selectively involved in online visual processing during action execution, we performed a contrast analysis of: 3) Reach and Grasp Vision\u00a0>\u00a0Reach and Grasp No vision. To investigate the cortical areas specifically involved in grasping and reaching tasks, regardless of the availability of visual information, we ran two single dataset analyses for each action type (Grasp, Reach) across the two visual conditions: 4) Grasp Vision and No vision, 5) Reach Vision and No vision. Lastly, to determine which areas consistently show higher activation for grasping than reaching movements, we ran the contrast analysis of: 6) Grasp\u00a0>\u00a0Reach. \n\nFor the single dataset meta-analyses, all the resulting statistical ALE maps were thresholded by means of a cluster-level family-wise error (cFWE) correction at p\u00a0<\u00a00.05 (5,000 permutations) with a cluster-forming threshold of p\u00a0<\u00a00.001 (uncorrected), in line with the latest recommendations for neuroimaging meta-analyses ( ). \n\nTo perform the contrast analyses, we followed the recommendation of   according to which two datasets are comparable when one is at most four times bigger than the other one (and vice versa), in terms of number of studies. Therefore, the sample size of studies included in the contrast analyses was: Reach and Grasp Vision (N\u00a0=\u00a020) vs. Reach and Grasp No vision (N\u00a0=\u00a033), and Grasp (N\u00a0=\u00a037) vs. Reach (N\u00a0=\u00a016). During the analysis, the ALE algorithm repeatedly and randomly splits the pooled list of foci into two separate sets of data while keeping their original sizes. Afterwards, an ALE map is generated for each new dataset, and one is subtracted from the other one (and vice versa); eventually, for each voxel the difference is computed between this new experimental ALE map and the original ALE map. For the current meta-analysis, the ALE algorithm used 10,000 permutations to perform the contrast analyses. The uncorrected threshold and the minimum cluster volume were set at p\u00a0<\u00a00.05 and to 100\u00a0mm^3, respectively. \n\n\n\n\n## Results \n  \nAn overview of all areas involved in the execution of reaching and grasping actions, regardless of whether or not vision is available, can be found in   (see in the article by  : Figure 2, Panel b; Figure 4, Panels a and b). \n\n### Meta-analytical map of Reach and Grasp Vision \n  \nThe Reach and Grasp Vision ALE meta-analysis included a total of 298 subjects, and 168 foci extracted from 20 eligible experiments. Results showed five significant clusters ( , Panel a;  ).   \nSchematic representation of the results for the Reach and Grasp Vision meta-analysis (Panel a), Reach and Grasp No vision meta-analysis (Panel b), and the Reach and Grasp Vision and Reach and Grasp No vision contrast analysis (i.e., Reach and Grasp Vision\u00a0>\u00a0Reach and Grasp No vision; Panel c). Results are shown in the axial view. TAL z coordinates are shown above the slices. Numbers within the slices (1\u20136) refer to clusters (Panel a: 1\u00a0=\u00a0left precentral gyrus, left postcentral gyrus, left inferior parietal lobule, 2\u00a0=\u00a0left and right medial frontal gyrus, 3\u00a0=\u00a0right cerebellum, 4\u00a0=\u00a0left middle temporal gyrus, left inferior temporal gyrus, left middle occipital gyrus, 5\u00a0=\u00a0right precentral gyrus, right inferior frontal gyrus; Panel b: 1\u00a0=\u00a0left insula, left postcentral gyrus, left inferior parietal lobule, left supramarginal gyrus, left precuneus, left precentral gyrus, left superior parietal lobule, left sub-gyral, left middle frontal gyrus, left superior frontal gyrus, 2\u00a0=\u00a0left and right medial frontal gyrus, 3\u00a0=\u00a0right precuneus, right superior parietal lobule, 4\u00a0=\u00a0right sub-gyral, right middle frontal gyrus, right superior frontal gyrus, right precentral gyrus, 5\u00a0=\u00a0right precuneus, right sub-gyral, 6\u00a0=\u00a0right inferior parietal lobule, right supramarginal gyrus; Panel c: 1\u00a0=\u00a0left precentral gyrus, left postcentral gyrus, 2\u00a0=\u00a0right precentral gyrus, right inferior frontal gyrus, right insula, 3\u00a0=\u00a0right cerebellum, 4\u00a0=\u00a0right medial frontal gyrus, 5\u00a0=\u00a0left inferior temporal gyrus, left middle occipital gyrus). \n  Fig. 1     \nSchematic representation of the results for the Grasp meta-analysis (Panel a), the Reach meta-analysis (Panel b), and the Grasp and Reach contrast analysis (i.e., Grasp\u00a0>\u00a0Reach; Panel c). Results are shown in the axial view. TAL z coordinates are shown above the slices. Numbers within the slices (1\u20136) refer to clusters (Panel a: 1\u00a0=\u00a0left precentral gyrus, left postcentral gyrus, left inferior parietal lobule, left supramarginal gyrus, 2\u00a0=\u00a0right cerebellum, 3\u00a0=\u00a0left and right medial frontal gyrus, left and right paracentral lobule, 4\u00a0=\u00a0right precentral gyrus, right postcentral gyrus, 5\u00a0=\u00a0left Inferior temporal gyrus, left inferior occipital gyrus, left middle occipital gyrus, left middle temporal gyrus, 6\u00a0=\u00a0right precentral gyrus, right inferior frontal gyrus; Panel b: 1\u00a0=\u00a0left precuneus, left inferior and superior parietal lobule, left precentral and postcentral gyrus, left sub-gyral, left paracentral lobule, left middle frontal gyrus, left superior frontal gyrus, 2\u00a0=\u00a0left and right precuneus, right superior and inferior parietal lobule, right sub-gyral, right paracentral lobule, right postcentral gyrus, 3\u00a0=\u00a0right middle frontal gyrus, right sub-gyral, right superior frontal gyrus, right middle frontal gyrus, right precentral gyrus 4\u00a0=\u00a0left medial frontal gyrus, 5\u00a0=\u00a0left and right cingulate gyrus, left and right medial frontal gyrus, 6\u00a0=\u00a0left middle occipital gyrus, left middle temporal gyrus; Panel c: 1\u00a0=\u00a0right cerebellum, 2\u00a0=\u00a0right postcentral gyrus). \n  Fig. 2     \nResults of the single dataset meta-analysis on Reach and Grasp Vision. TAL: Talairach; Hemi: hemisphere; BA: Brodmann Area; Cluster size: size of clusters in mm^3. \n  Table 2   \n\nThe most significant peaks of activity were located in the left precentral gyrus (cluster 1; TAL coordinates: \u221232, \u221230, 56, BA4), the right medial frontal gyrus (cluster 2; TAL coordinates: 2, \u221212, 50, BA6), the right cerebellar dentate (cluster 3; TAL coordinates: 16, \u221250, \u221220), the left inferior temporal gyrus (cluster 4; TAL coordinates: \u221244, \u221268, 2, BA37), and the right inferior frontal gyrus (cluster 5; TAL coordinates: 50, 6, 14, BA44). Cluster 1 (5776\u00a0mm^3) showed two activation peaks in the left hemisphere, and it extended from the postcentral gyrus (42.3% of experiments) to the precentral gyrus (38.4%), and the inferior parietal lobule (19.4%). Cluster 2 (1280\u00a0mm^3) consisted of two activation peaks, and it spanned both the left and right hemispheres (52% and 48% of experiments, respectively); more precisely, it was located in the medial frontal gyrus (BA6; 97.3%), and it spread slightly to the paracentral lobule (BA31; 2.7%). Cluster 3 (1264\u00a0mm^3) was found with one activation peak in the right cerebellar hemisphere; the cluster spanned the anterior lobe (98.7%), and slightly spread to the posterior lobe of the cerebellum (1.3%). Cluster 4 (1064\u00a0mm^3) consisted of one activation peak in the left hemisphere; it was primarily located in the inferior temporal gyrus (40.4%), the middle temporal gyrus (29.8%), and the middle occipital gyrus (29.8%). Cluster 5 (720\u00a0mm^3) was found with one activation peak in the right hemisphere; it was located mainly in the precentral gyrus (BA44; 66.7%), and the inferior frontal gyrus (BA6; 33.3%). \n\n\n### Meta-analytical map of Reach and Grasp No vision \n  \nThe Reach and Grasp No vision ALE meta-analysis included a total of 476 subjects, and 360 foci extracted from 33 eligible experiments. Results showed six significant clusters ( , Panel b;  ).   \nResults of the single dataset meta-analysis on Reach and Grasp No vision. TAL: Talairach; Hemi: hemisphere; BA: Brodmann Area; Cluster size: size of clusters in mm^3. \n  Table 3   \n\nThe most significant peaks of activity were located in the left postcentral gyrus (cluster 1; TAL coordinates: \u221234, \u221230, 50, BA3), the left medial frontal gyrus (cluster 2; TAL coordinates: \u22126, \u221212, 54, BA6), the right precuneus (cluster 3; TAL coordinates: 12, \u221268, 48, BA7), the right middle frontal gyrus (cluster 4; TAL coordinates: 22, \u22128, 56, BA6), the right precuneus (cluster 5; TAL coordinates: 28, \u221246, 46, BA7), and the right supramarginal gyrus (cluster 6; TAL coordinates: 54, \u221236, 36, BA40). Cluster 1 (21,288\u00a0mm^3) showed twelve activation peaks in the left hemisphere; it extended across the postcentral gyrus (32.5% of experiments), the inferior parietal lobule (18.6%), the precuneus (15.2%), the precentral gyrus (14.6%), the superior parietal lobule (12.3%), and it slightly spread to the middle frontal gyrus (3.5%), the sub-gyral (1.7%) and the insula (1%). Cluster 2 (3536\u00a0mm^3) consisted of three activation peaks, and it spanned both the left and right hemispheres (73.5% and 26.5% of experiments, respectively); more precisely, it was located in the medial frontal gyrus (73.5%), the cingulate gyrus (25.2%), and the paracentral lobule (1.3%). Cluster 3 (2056\u00a0mm^3) had two activation peaks in the right hemisphere; the cluster was located primarily in BA7, and particularly, it spanned the precuneus (69.3%), and the superior parietal lobule (30.7%). Cluster 4 (1744\u00a0mm^3) consisted of three activation peaks in the right hemisphere; it was located in the middle frontal gyrus (54.6%), the precentral gyrus (16.7%), the superior frontal gyrus (14.8%), the sub-gyral (12%), and the medial frontal gyrus (1.9%). Cluster 5 (1664\u00a0mm^3) had one activation peak in the right BA7; in particular, it spanned the precuneus (65.3%) and the superior parietal lobule (34.7%). Cluster 6 (896\u00a0mm^3) consisted of two activation peaks in the right hemisphere; it was primarily located in the inferior parietal lobule (84.8%), and it spread slightly to the supramarginal gyrus (8.7%), and the postcentral gyrus (6.5%). \n\n\n### Contrast: Reach and Grasp Vision\u00a0>\u00a0No vision \n  \nThe contrast meta-analysis (Reach and Grasp Vision\u00a0>\u00a0Reach and Grasp No vision) pooled data from a total of 528 foci, extracted from an overall group of 53 experiments and 774 participants (Reach and Grasp Vision: 168 foci, 20 experiments, 298 subjects; Reaching and Grasp No vision: 360 foci, 33 experiments, 476 subjects). The analysis revealed five significant ALE clusters. The results are represented in   (Panel c); for more details, see  .   \nResults of the contrast analysis (Reach and Grasp Vision\u00a0>\u00a0No vision). TAL: Talairach; Hemi: hemisphere; BA: Brodmann Area; Cluster size: size of clusters in mm^3. \n  Table 4   \n\nThe most significant peaks of activation were found in the left precentral gyrus (cluster 1; TAL coordinates: \u221231, \u221228, 55, BA4), the right precentral gyrus (cluster 2; TAL coordinates: 49, 2, 12, BA44), the culmen of the right cerebellum (cluster 3; TAL coordinates: 22, \u221248, \u221222), the right medial frontal gyrus (cluster 4; TAL coordinates: 4, \u221214, 54, BA6), and the left inferior temporal gyrus (cluster 5; TAL coordinates: \u221248, \u221270, 2). Cluster 1 (648\u00a0mm^3) was found with one peak in the left hemisphere, and it was located in the precentral gyrus (BA4; 58%), and the postcentral gyrus (BA3; 42%). Cluster 2 (576\u00a0mm^3) consisted of three peaks of activation in the right hemisphere, and it was mainly located in the precentral gyrus (BA44), and the inferior frontal gyrus (BA44). Cluster 3 (344\u00a0mm^3) showed one activation peak in the right cerebellar hemisphere; it was located in the cerebellar culmen (88.4%), and slightly extended into the cerebellar dentate nucleus (11.6%). Cluster 4 (128\u00a0mm^3) revealed one activation peak in the right hemisphere, and it was located in the medial frontal gyrus (BA6; 100%). Cluster 5 (112\u00a0mm^3) showed one activation peak in the left hemisphere; it was located in the inferior temporal gyrus (61.5%), the middle occipital gyrus (30.8%), and the middle temporal gyrus (7.7%). \n\n\n### Meta-analytical map of Grasp \n  \nThe Grasp ALE meta-analysis included a total of 563 subjects, and 294 foci extracted from 37 eligible experiments. Results showed five significant clusters ( , Panel a;  ).   \nResults of the single dataset meta-analysis on Grasp. TAL: Talairach; Hemi: hemisphere; BA: Brodmann Area; Cluster size: size of clusters in mm^3. \n  Table 5   \n\nThe most significant peaks of activity were located in the left postcentral gyrus (cluster 1; TAL coordinates: \u221234, \u221230, 56, BA3), the right cerebellar dentate (cluster 2; TAL coordinates: 16, \u221250, \u221220), the left medial frontal gyrus (cluster 3; TAL coordinates: 0, \u221210, 52, BA6), the right precentral gyrus (cluster 4; TAL coordinates: 36, \u221226, 48, BA3), and the left inferior temporal gyrus (cluster 5; TAL coordinates: \u221244, \u221266, 2, BA37). Cluster 1 (12,528\u00a0mm^3) showed six significant activation peaks in the left hemisphere; it was located in the postcentral gyrus (46.7% of experiments), the inferior parietal lobule (27.5%), the precentral gyrus (22.7%), and the superior parietal lobule (1.9%). Cluster 2 (2200\u00a0mm^3) consisted of one peak of significant activation in the right cerebellar hemisphere; the cluster was mainly located in the anterior lobe of the cerebellum (96.7%) and only slightly spread to the posterior lobe (3.3%). Cluster 3 (2024\u00a0mm^3) was found with one peak of activation in both the left and right hemispheres (76.9% and 23.1%, respectively); the cluster was located primarily in the medial frontal gyrus (BA6; 98.5%) and activation also spread slightly to the paracentral lobule (BA31; 1.5%). Cluster 4 (1352\u00a0mm^3) consisted of two activation peaks in the right hemisphere; it was located in the postcentral gyrus (73.3%), the precentral gyrus (25.6%), and activation also spread slightly to the inferior parietal lobule (1.2%) Cluster 5 (1104\u00a0mm^3) was found with two peaks in the left hemisphere; it was located in the inferior temporal gyrus (45%), the middle temporal gyrus (27.5%), the middle occipital gyrus (20%), the fusiform gyrus (5%), and the inferior occipital gyrus (2.5%). \n\n\n### Meta-analytical map of Reach \n  \nThe Reach ALE meta-analysis included a total of 211 subjects, and 234 foci extracted from 16 eligible experiments. Results showed six significant clusters ( , Panel b;  ).   \nResults of the single dataset meta-analysis on Reach. TAL: Talairach; Hemi: hemisphere; BA: Brodmann Area; Cluster size: size of clusters in mm^3. \n  Table 6   \n\nThe most significant peaks of activity were located in the left precuneus (cluster 1; TAL coordinates: \u221220, \u221262, 52, BA7), the right precuneus (cluster 2; TAL coordinates: 26, \u221246, 46, BA7), the right sub-gyral (cluster 3; TAL coordinates: 26, \u22124, 54, BA6), the left medial frontal gyrus (cluster 4; TAL coordinates: \u22124, \u221212, 52, BA6; cluster 5; TAL coordinates: \u22124, 4, 52, BA6), and the middle temporal gyrus (cluster 6; TAL coordinates: \u221244, \u221270, 6, BA37). Cluster 1 (12,320\u00a0mm^3) showed eight peaks of activity in the left hemisphere; it was located in the precuneus (29.1% of experiments), the precentral gyrus (19%), the postcentral gyrus (18.4%), the superior parietal lobule (18.2%), the middle frontal gyrus (10.8%), the sub-gyral (2.7%), and the inferior parietal lobule (1.7%). Cluster 2 (5088\u00a0mm^3) consisted of six activation peaks, and it spanned primarily the right hemisphere (96.6%) and, to a lesser extent, the left hemisphere (3.4%); more precisely, it was located in the precuneus (59.9%), the superior parietal lobule (24.1%), the sub-gyral (7.6%), the postcentral gyrus (6.3%), and the cuneus (1.3%). Cluster 3 (2144\u00a0mm^3) was found with two activation peaks in the right hemisphere, particularly in BA6; the cluster spanned the middle frontal gyrus (55.3%), the superior frontal gyrus (22%), the sub-gyral (14.6%), the precentral gyrus (5.7%), and the medial frontal gyrus (2.4%). Cluster 4 (928\u00a0mm^3) consisted of two activation peaks in the left hemisphere; it was primarily located in the medial frontal gyrus (BA6; 82.9%), and the cingulate gyrus (BA24, BA31; 17.1%). Cluster 5 (864\u00a0mm^3) was found with three activation peaks in both the right and left hemispheres (50.9% and 49.1%, respectively). The latter cluster was located mainly in the medial frontal gyrus (79.2%), and activity also spread slightly to the superior frontal gyrus (13.2%), and the cingulate gyrus (7.5%). Cluster 6 (624\u00a0mm^3) showed one activation peak in the left hemisphere; it was located in the middle occipital gyrus (58.8%), the middle temporal gyrus (32.4%), and the inferior temporal gyrus (8.8%). \n\n\n### Contrast: Grasp\u00a0>\u00a0Reach \n  \nThe contrast ALE meta-analysis (Grasp\u00a0>\u00a0Reach) included a total of 774 participants and 528 foci, extracted from an overall group of 53 experiments (Grasp: 294 foci, 37 experiments, 563 subjects; Reach: 234 foci, 16 experiments, 211 subjects). The analysis revealed two significant ALE clusters for activation. The results are represented in  , Panel c; for more details, see  .   \nResults of the contrast analysis (Grasp\u00a0>\u00a0Reach). TAL: Talairach; Hemi: hemisphere; BA: Brodmann Area; Cluster size: size of clusters in mm^3. \n  Table 7   \n\nThe most significant peaks of activation were found in the right cerebellar dentate nucleus (cluster 1; TAL coordinates: 16.8, \u221251.2, \u221224.8), and in the right postcentral gyrus (cluster 2; TAL coordinates: 44, \u221224, 52, BA3). Cluster 1 (1488\u00a0mm^3) was found with five peaks in the right cerebellum; this cluster was located in the anterior lobe (97.8%) and activation spread slightly into the posterior lobe (2.2%) of the cerebellum. Cluster 2 (184\u00a0mm^3) consisted of two peaks of activation in the right hemisphere, and it was primarily located in the parietal lobe, more specifically in the postcentral gyrus (BA3; 100%). \n\n\n\n## General discussion \n  \nIn the present study we conducted a coordinate-based meta-analysis to investigate the brain areas consistently recruited during hand reaching and grasping with and without online visual feedback, with a focus on ventral stream and early visual areas. As for the dorsal stream, we found that it was consistently involved in grasping as well as reaching actions, regardless of the availability of visual information. This is in line with the dual-stream theory, postulating that the dorsal stream is involved in the execution of reach and grasp actions. As for the ventral stream, we found that it was involved in actions executed with but not without online visual feedback. Specifically, the temporal-occipital cortex showed higher activation likelihood for the Vision than No vision condition. In addition, the ventral stream showed comparable activation likelihood for grasping and reaching actions. Below, we discuss the main findings of the present meta-analysis and the potential functional role of ventral stream areas in action guidance and execution. \n\n### Processing of visual information during goal-directed hand actions \n  \nThe two single-dataset meta-analyses on actions with and without vision, and the contrast analysis between Vision and No vision enabled us to examine the role of vision in temporal-occipital areas during action execution (aim 1). \n\nThe meta-analytical map on hand reaching and grasping with vision ( , Panel a) revealed consistent activation across the studies in frontal, parietal, and right cerebellar regions, as well as in the occipito-temporal cortex. These findings are expected given the known role of the dorsal stream in action and the ventral stream in perception. Indeed, the inferior temporal gyrus (ITG) and the lateral occipital cortices are known to be involved in visual perception and recognition of object categories and body parts, including the hand ( ;  ;  ;  ; for reviews see  ;  ). Similarly, the posterior areas of the middle temporal gyrus (MTG) process category and motion-related information ( ). These results are consistent with the fact that in the selected Vision conditions participants viewed the target and their moving hand while approaching the target. \n\nAs for actions performed without online visual feedback, the meta-analytical map showed significant activation in six cortical clusters covering both the left and right hemispheres; specifically, they included parietal areas, such as bilateral inferior parietal lobule (IPL), precuneus, superior parietal lobule (SPL), and left postcentral gyrus (PoCG), and frontal areas like bilateral precentral gyrus (PreCG), middle frontal gyrus (MFG), superior frontal gyrus (SFG), and left insula. The clusters in the posterior parietal cortex for the No vision category are likely related to motor planning and reliance on somatosensory feedback. Another possible and non-exclusive interpretation is related to the recruitment of working memory mechanisms in the parietal cortex that support the guidance of actions in absence of visual information ( ;  ). Importantly, no cluster was found in the ventral visual stream ( , Panel b). Therefore, despite some evidence supporting the involvement of the ventral stream in goal-directed actions performed in the dark after a delay ( ;  ), there is no consistency in support of the recruitment of ventral visual stream areas during the control and execution of skilled actions in the absence of visual input. In line with this result, the contrast analysis did not reveal any cluster in the temporal-occipital cortex ( , Panel c). Interestingly, the contrast did reveal clusters of activation spanning the left PreCG and PoCG, two clusters in the right hemisphere located mainly in frontal areas, such as PreCG, inferior and middle frontal gyrus (IFG and MFG, respectively), and an additional cluster in the anterior lobe of the right cerebellar hemisphere. Therefore, these areas are more engaged when visual information is available as opposed to when it is not. The higher consistency in brain activation for Vision than No vision in motor-related areas is in line with a seminal neurophysiology study in primates by  , which demonstrated the presence of bimodal visual and tactile neurons in macaques' ventral premotor cortex, typically known to be involved in motor control. Our results suggest that bimodal neurons might also be present in humans\u2019 premotor cortex, which is recruited by vision of a target to be acted upon that requires the processing of affordances and spatial information for accurate action performance. \n\nWe found no activation cluster in the EVC for Vision and No vision conditions. The lack of activation clusters in the EVC in the Vision condition can be explained by the fact that some of the studies included in the Vision condition used a contrast of Grasp\u00a0>\u00a0Look. Therefore, the visual processing of the object was removed by the contrast. Since in such tasks vision of the hand was available throughout the movement, we included these studies in the Vision condition. However, the inclusion of contrasts subtracting some activity related to visual processing might have reduced the sensitivity to detect activation in early visual areas. Also, while univariate analysis might lack the sensitivity to reveal activation in ventral stream areas and EVC under lack of vision, recent MVPA studies have shown different representations for grasping and reaching action planning with and without visual information in ventral stream and early visual areas ( , ;  ,  . This difference in results indicates that univariate and multivariate analysis provide complementary and not necessarily equivalent information, with MVPA being more sensitive to distributed representation of information of content, and univariate analysis that shows more sensitivity to the overall engagement in a task ( ;  ;  ). \n\nOverall, these results indicate the consistent involvement of the parietal and frontal cortex in the execution of grasping and reaching actions regardless of the availability of visual information, while the temporal-occipital cortex is recruited only when vision is available. Notably, the same frontal and parietal areas have been recently shown to process magnitude representations ( ). Consistently, grasping and reaching actions require the processing of space-related magnitude information, such as the location of the target in space for reaching, as well as its size for grasping. \n\n\n### Processing of grasping and reaching \n  \nThe second aim of the current study was to assess whether ventral and dorsal stream areas are differentially recruited during the execution of reaching and grasping (aim 2). \n\nThe meta-analytical map of hand grasping revealed consistent activation clusters in the frontal and parietal cortex, as well as in the anterior lobe of the right cerebellar hemisphere ( , Panel a). Moreover, a significant cluster of activation was located in the left inferior temporal cortex, more precisely in the ITG, and the fusiform gyrus. The inferior temporal cortex, including the ITG, plays a well-known role in the visual perception and recognition of objects, scenes, and hands ( ;  ;  ;  ) and it has been shown that the fusiform gyrus might store semantic information about the object shape ( ; see also  ). Therefore, neural activation in these areas might underpin the visual processing of object properties and semantic representation during grasping actions. \n\nSimilarly, the meta-analytical map of hand reaching revealed five cortical clusters covering both hemispheres ( , Panel b). Specifically, a network of frontal, parietal, and temporal-occipital regions was consistently activated across the literature. Moreover, the network for reaching appeared more bilateral than the one for grasping, in line with previous findings that show a lateralization of the activation for grasping movements ( ;  ). \n\nAlthough we initially hypothesized that the ventral stream may show more clusters of activation for grasping than reaching, the results of our contrast do not support our hypothesis. Indeed, no temporal-occipital area was found in the meta-analytical contrast of Grasp vs. Reach ( , Panel c). A possible explanation is related to the fact that the single dataset analyses for grasping and reaching showed similar results. This could be due to the inclusion of tasks that isolated the grip as well as the transport component (12 out of 37 studies) in our Grasp category. Further, the anterior intraparietal sulcus (aIPS), typically known to be involved in grasping actions, does not show any activation cluster with the contrast of Grasp vs. Reach. This (lack of) finding can be explained by the fact that the aIPS is sensitive to the precision required by a grasping movement, rather than the number of digits or lift component ( ). Part of the studies included in our Grasp category have contrasted between types of grasps that required different hand configurations but the same precision (e.g., gentle precision grip vs. firm precision grip,  ). Overall, these meta-analyses revealed that reaching and grasping under the two visual conditions recruited similar networks that span the temporal-occipital and frontal-parietal cortex. Indeed, the contrast analysis showed only a few clusters in the right cerebellum and precentral gyrus, likely related to the finer motor control of the fingers during a grasping as compared to a reaching movement. The right lateralization of the post-central gyrus for the contrast of Grasp vs. Reach is unexpected and could be due to the use of grasp tasks that required moving the left hand ( ;  ;  ). \n\n\n### Strengths and limitations of the study \n  \nThe present meta-analysis has important strengths, as it is the first work to define the consistency across neuroimaging studies on goal-directed hand actions with and without online visual information over the last two decades. In addition, this study provides a further confirmation of the brain areas involved in the control of skilled actions ( ;  ; for additional meta-analytical results, see also  ). Furthermore, we provide an overview of the areas recruited while reaching out and grasping objects, with and without online visual feedback. This aspect is of particular importance. Indeed, despite the consensus in the literature on the involvement of the frontal and parietal cortex in the guidance of reaching and grasping, there is compelling evidence suggesting that also the temporal-occipital cortex might play a role (e.g.,  ;  ;  ;  ), especially in recent neuroimaging studies that have employed multivariate analysis which allows identifying representations rather than extent of activation ( ,  ;  ;  ,  ;  ). Therefore, our meta-analysis attempted to clarify the debate on the potential involvement of the temporal-occipital cortex in the guidance of skilled actions as investigated with univariate analysis. \n\nThere are also some limitations to our work. One of them consists in the fact that half of the experiments categorized as Grasp Vision used a contrast that included visual processing elicited by the view of the reaching limb and grasping hand (i.e., Grasp\u00a0>\u00a0Look) or view of the grasping hand only (i.e., Grasp\u00a0>\u00a0Reach, Grasp\u00a0>\u00a0Point, Grasp\u00a0>\u00a0Touch, Grasp\u00a0>\u00a0Different grasp). However, this fine-grained categorization might have hampered the possibility to find consistent activation in brain areas associated with visual processing during action execution in presence of vision. As a consequence, it might have likely hindered the contrast analysis between the two vision conditions (i.e., Reach and Grasp Vision\u00a0>\u00a0No vision) which did not show any significant cluster of activation associated with visual processing in the EVC. \n\n\n\n## Conclusion \n  \nTo the best of our knowledge, this coordinate-based meta-analysis is the first attempt to investigate spatial convergence across the available literature in relation to the involvement of temporal-occipital and frontal-parietal cortex in reaching and grasping actions performed with and without online visual feedback. Our findings reconcile the existing neuroimaging literature on actions that employed standard univariate analysis, by emphasizing the complementary role of more recent techniques, such as multivoxel pattern analysis, to the current knowledge on cortical areas involved in hand movements. \n\n\n## CRediT authorship contribution statement \n  \n Samantha Sartin:   Data curation, Formal analysis, Methodology, Project administration, Resources, Software, Visualization, Writing \u2013 original draft.   Mariagrazia Ranzini:   Investigation, Data curation, Writing \u2013 review & editing.   Cristina Scarpazza:   Writing \u2013 review & editing.   Simona Monaco:   Conceptualization, Methodology, Project administration, Resources, Supervision, Validation, Writing \u2013 review & editing. \n\n\n## Declaration of competing interest \n  \nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. \n\n \n", "metadata": {"pmcid": 9826890, "text_md5": "481a197a787995b5f4dc546d417abdb6", "field_positions": {"authors": [0, 84], "journal": [85, 103], "publication_year": [105, 109], "title": [120, 258], "keywords": [272, 333], "abstract": [346, 2715], "body": [2724, 57471]}, "batch": 2, "pmid": 36632448, "doi": "10.1016/j.crneur.2022.100070", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9826890", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9826890"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9826890\">9826890</a>", "list_title": "PMC9826890  Cortical areas involved in grasping and reaching actions with and without visual information: An ALE meta-analysis of neuroimaging studies"}
