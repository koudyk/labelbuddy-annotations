{"text": "Plow, Ela B. and Cattaneo, Zaira and Carlson, Thomas A. and Alvarez, George A. and Pascual-Leone, Alvaro and Battelli, Lorella\nFront Hum Neurosci, 2014\n\n# Title\n\nThe compensatory dynamic of inter-hemispheric interactions in visuospatial attention revealed using rTMS and fMRI\n\n# Keywords\n\nvisual extinction\ninter-hemispheric interaction\nvisuospatial attention\nTMS\nfMRI\n\n\n# Abstract\n \nA balance of mutual tonic inhibition between bi-hemispheric posterior parietal cortices is believed to play an important role in bilateral visual attention. However, experimental support for this notion has been mainly drawn from clinical models of unilateral damage. We have previously shown that low-frequency repetitive TMS (rTMS) over the intraparietal sulcus (IPS) generates a contralateral attentional deficit in bilateral visual tracking. Here, we used functional magnetic resonance imaging (fMRI) to study whether rTMS temporarily disrupts the inter-hemispheric balance between bilateral IPS in visual attention. Following application of 1 Hz rTMS over the left IPS, subjects performed a bilateral visual tracking task while their brain activity was recorded using fMRI. Behaviorally, tracking accuracy was reduced immediately following rTMS. Areas ventro-lateral to left IPS, including inferior parietal lobule (IPL), lateral IPS (LIPS), and middle occipital gyrus (MoG), showed decreased activity following rTMS, while dorsomedial areas, such as Superior Parietal Lobule (SPL), Superior occipital gyrus (SoG), and lingual gyrus, as well as middle temporal areas (MT+), showed higher activity. The brain activity of the homologues of these regions in the un-stimulated, right hemisphere was reversed. Interestingly, the evolution of network-wide activation related to attentional behavior following rTMS showed that activation of most occipital synergists adaptively compensated for contralateral and ipsilateral decrement after rTMS, while activation of parietal synergists, and SoG remained competing. This pattern of ipsilateral and contralateral activations empirically supports the hypothesized loss of inter-hemispheric balance that underlies clinical manifestation of visual attentional extinction. \n \n\n# Body\n \n## Introduction \n  \nVisual attention depends upon the balance of tonic inhibition exerted between bilateral posterior parietal cortices (Kinsbourne,  ; Muri et al.,  ; Battelli et al.,  ). Unilateral lesions can disrupt this balance, resulting in visual extinction, the inability to perceive contra-lesional targets when competing targets are presented bilaterally (Vallar et al.,  ). One hypothesis is that the damaged posterior parietal cortex is unable to \u201ccompete\u201d against the uninhibited activity of the intact homologue, which in turn hyper-orients attention to the ipsi-lesional visual field leading to extinction of targets in the contra-lesional space (Kinsbourne,  ). Still,   direct   evidence of inter-hemispheric competition in posterior parietal cortices is limited. Inferences have been drawn from clinical neuropsychological observations (Battelli et al.,  ; Corbetta et al.,  ). However, this approach is severely limited because lesions have widespread, unpredictable effects that make it challenging to disentangle their direct sequel from ensuing disruptions in inter-hemispheric balance (Pascual-Leone et al.,  ). \n\nNeurophysiological techniques can help determine the cause-effect relation between activity of posterior parietal cortices and behavior more reliably (Pascual-Leone et al.,  ; Walsh and Cowey,  ) and, to this aim, repetitive transcranial magnetic stimulation (rTMS) can transiently disrupt activity in targeted posterior parietal cortex and induce reversible behavioral impairments (Hilgetag et al.,  ; Muri et al.,  ; Thut et al.,  ; Dambeck et al.,  ; Fierro et al.,  ; Battelli et al.,  ). For instance, we have previously used rTMS to study inter-hemispheric balance between bilateral posterior parietal cortices in sustained visual attention (Battelli et al.,  ). Transient disruption of unilateral posterior intra-parietal sulcus (IPS) with low-frequency rTMS worsened contra-lateral visual attention. Since this effect only manifested during a task that required bilateral attention, simulating \u201cvisual extinction\u201d (Vallar et al.,  ), we hypothesized that rTMS disrupted the balance of inter-hemispheric inhibition exerted between bilateral IPS during full-field attention (Battelli et al.,  ). \n\nHowever, since effects of rTMS are not limited to the directly targeted region, but instead they may also affect distant cortical and subcortical structures (Fox et al.,  ), ascribing behavioral impairments to inter-hemispheric competition between homologous pairs of IPS based on use of rTMS alone was only speculative. It still remains unclear whether the impairment was caused by disruption of activity of the directly targeted cortical locus (IPS), or its competition with its homologue, or if in fact TMS temporarily altered the network-wide balance between all areas involved in sustained attention (Ruff et al.,  ; Blankenburg et al.,  ). \n\nRecent evidence combining TMS with functional neuroimaging suggests that TMS may have causal influence that extends beyond the targeted locus, involving remote synergists as well as homologous and heterologous regions in the non-targeted hemisphere (Blankenburg et al.,  ). We thus posited that examining the effects of TMS with functional neuroimaging would clarify our speculations regarding network-wide effects of TMS (Ruff et al.,  ; Fox et al.,  ). \n\nTo gather   direct   evidence that extinction induced with low-frequency rTMS targeting IPS evolves from modulated inter-hemispheric balance, we created a new empirical design as a follow up to our previous protocol. Briefly, low-frequency 1 Hz rTMS or sham was delivered to the left IPS, promptly followed by 3 experimental runs of functional magnetic resonance imaging (fMRI) while subjects performed sustained bilateral attention involving visual tracking. We chose bilateral visual attention since recent fMRI studies have demonstrated that when stimuli presented in both right and left hemifields are task relevant, requiring high attentional competition, then left and right IPS are equally activated (Geng et al.,  ). Disruption of IPS prior to bilateral visual attention, we believed, would amplify the inter-hemispheric imbalance we note with fMRI activation. We chose to deliver low-frequency rTMS to left IPS because we were extending our previous results where experimentally induced extinction was greater with rTMS to the left than to the right IPS (Battelli et al.,  ). Still, we used a slightly different visual stimulus than in our previous study (Carlson et al.,  ; Battelli et al.,  ) because the present stimulus was more likely to elicit fMRI activation in early visual areas. Their study in network-wide effect was important as they are strongly influenced by attention (Somers et al.,  ). \n\nOverall, we hypothesized that our protocol of rTMS-induced contralateral visual extinction, when studied with fMRI, would potentially demonstrate: (a) reduced fMRI activation of targeted IPS with exaggerated activation of its homologue, indicating disrupted inter-hemispheric balance underlying extinction, (b) besides IPS, a network-wide shift in inter-hemispheric activation of areas involved in sustained visual attention, which would demonstrate that extinction involves synergistic areas extending beyond targeted IPS and (c) an association between extinction and its alleviation with evolution of activation of synergists would reveal the type of functional role they exert in supporting IPS sustain bilateral attention. Study of an experimental protocol examining extinction rather than neglect is significant because while visual neglect is known to result from right parietal lesion (Battelli et al.,  ; Mort et al.,  ), lesions underlying visual extinction are less clear (Stone et al.,  ). \n\n\n## Materials and methods \n  \n### Subjects \n  \nTen healthy subjects (mean age \u00b1   SD   27.72 \u00b1 5.99 years, 7 males) participated in the experiment; one subject was excluded from analysis due to excessive head motion in the MRI scanner. All subjects had normal or corrected-to-normal vision. All participants met all TMS (Rossi et al.,  ) and MRI screening criteria and provided written informed consent in accordance with the Institutional Review Board of the Beth Israel Deaconess Medical Center, Boston, MA. \n\n\n### Behavioral task \n  \nEach subject participated in a total of six experimental runs simultaneous with fMRI- three following rTMS and three following sham conducted on 2 separate days in a counter-balanced order. During each fMRI run, subjects performed bilateral visual tracking (Figures  ) as in our previous work (Carlson et al.,  ; Battelli et al.,  ). Bilateral visual tracking typically involves sustained attention, a well-studied behavioral paradigm with clear neural correlates (Culham et al.,  ; Battelli et al.,  ; Drew and Vogel,  ). In this task, high-contrast pairs of pinwheels were displayed on either side of central fixation. On each pinwheel, targets were represented as a randomly selected spoke cued briefly. Following disappearance of cues, both pinwheels rotated at a fixed rate, pre-determined by individual's threshold for performing at 85% accuracy. Subjects tracked the target spokes bilaterally for 3 s, after which the pinwheels stopped. When they stopped, the pinwheels were displayed upright. All spokes re-appeared as probes (in the form of a cross) on the target pinwheel. Subjects were asked to respond using a four-alternative forced-choice key-press (\u201cup,\u201d \u201cdown,\u201d \u201cleft,\u201d or \u201cright\u201d keys) which probe represented the originally cued target spoke. Stimuli were generated in MATLAB using functions of the Psychophysics Toolbox (Brainard,  ; Pelli,  ) and displayed on a PC laptop with a 17\u201d monitor screen projected with a rear-view mirror attached to the head coil in the scanner. A total of 35 trials were presented for each experimental run. \n  \n Behavioral Task - Design and Results. (A)   Visual tracking task. Stimuli were high-contrast pairs of pinwheels displayed on either side of a central fixation cross.   (B)   At the start, the targets (a randomly selected spoke on each pinwheel) were cued briefly. Following the cues disappearance, the pinwheels rotated at a fixed rate, determined by individual subjects' threshold for 85% correct performance, while subjects tracked the targets. After 3 s, both pinwheels stopped and were aligned so that all probes on the target pinwheel appeared as a cross. Subjects responded using a four-alternative forced-choice paradigm (\u201cup,\u201d \u201cdown,\u201d \u201cleft,\u201d or \u201cright\u201d keys) to report which of the probes represented the originally-cued target.   (C)   Results of tracking accuracy: contra, contralateral (right hemifield); ipsi, ipsilateral (left hemifield); y-axis, tracking accuracy following rTMS as a proportion of that following sham; x-axis, experimental runs (1 through 3). Values below 1 represent a decrement and above 1 show improvement following rTMS vs. sham. \n  \n\n### rTMS \n  \nTMS was applied using a MagStim device (MagStim, Whitland, Wales, UK) with a 70-mm figure-of-eight coil. It was guided by neuronavigation to the individually defined left IPS and it was calculated as the average MRI-defined stereotaxic coordinates from our prior study (Battelli et al.,  ) [Talairach (mean \u00b1   SD  ):   X   (\u221223.37 \u00b1 5.24),   Y   (\u221267.60 \u00b1 4.25) and   Z   (52.88 \u00b1 2.47) mm]. These pre-defined coordinates were translated into individual's native brain space using frameless stereotaxic image guidance (Brainsight\u2122, Rogue Research Inc., Montreal, QC, Canada). The TMS coil was held with the handle pointing posteriorly at an angle of 45\u00b0 to the inter-hemispheric fissure, at an orientation that aligned it perpendicular to the left IPS. Low-frequency 1 Hz rTMS was applied for 15-min at 75% of the maximum stimulator output. For the sham condition we placed the edge of the coil at an angle perpendicular to the head, while stimulation was delivered at the same intensity as in the rTMS session. Experimental runs involving bilateral visual tracking concurrent with fMRI were initiated within four minutes from completion of rTMS/sham. \n\n\n### fMRI \n  \nMRI and Blood Oxygen Level-Dependent (BOLD) fMRI data was acquired in a whole-body 3T Phillips scanner equipped with 22 mT/m field gradients with a slew rate of 120 T/m/s. FMRI scan parameters were: TR = 2 s, TE = 55 ms, flip angle = 90\u00b0, imaging matrix = 96 \u00d7 96, FOV = 23 cm and 20 slices. Slices were 4 mm thick with an in-plane resolution of 2.4 \u00d7 2.4 mm and a gap of 0.5 mm. Gradient-echo planar imaging (EPI) sequence was used with a standard head coil. Structural MRI data was collected in an MPRAGE high resolution,   T  -weighted format in sagittal orientation. The total number of slices sampled was 170. Parameters of MPRAGE data were: FOV- 240 \u00d7 256 \u00d7 204 mm; TR = 7 ms; spatial resolution- 1 \u00d7 1 \u00d7 1.2 mm with no gap. \n\n\n### Data and statistical analysis \n  \n#### Behavior \n  \nBehavioral accuracy was computed as percent correct response. For each run, percentage accuracy following rTMS was normalized to that following corresponding sham run. Values below 1 indicate impairment following rTMS while those above 1 indicate improvement. This normalized accuracy value was compared between contralateral (right) and ipsilateral (left) hemifields, and between one run and another using pairwise, within-group comparisons (using Student's   t  -test). \n\n\n#### fMRI \n  \nAnalysis was conducted using Brain Voyager QX 1.10 (Brain Innovation, Maastricht, Netherlands). Functional data was preprocessed for 3-D motion correction (Cox and Hyde,  ), removal of temporal linear trends, and correction for slice time acquisition and then spatially smoothed (Gaussian kernel, 3.0 mm FWHM). Individual subjects' data was normalized to Talairach space (Goebel et al.,  ). A single-factor design matrix was generated including the predictor of interest, visual tracking. The predictor was derived by convolving a box-car waveform with a double-gamma hemodynamic response function (Friston et al.,  ). General Linear Model (GLM) was applied to time series data for each subject and a statistical map of \u201cbilateral visual attentional tracking\u201d and its \u201cvariability\u201d was computed. \n  \n fMRI: Statistical Parametric map of rTMS vs. Sham (as displayed in Figure   and Table   ) The contrast of visual tracking and its associated standard errors were included in a group (multi-subject) Fixed Effects GLM analysis (Soleymani et al.,  ) since it is sensitive for studies with a limited subject pool (Friston et al.,  ). The multi-subject GLM included all runs, and all 35 trials belonging to each run (1, 2, and 3), following rTMS and following sham. This GLM investigated whether greater signal change in bilateral tracking follows rTMS vs. sham. The GLM analysis yielded a statistical parametric map at a threshold of Bonferroni-corrected \u03b1 = 0.01 with a spatial cluster threshold of 100 mm . Figure   and Table   define its results demonstrating across the entire group of 10 subjects which areas show higher activation across pooled runs following rTMS than sham. Whereas red/yellow colors emphasize areas showing higher activity, blue-to-green colors indicate areas with lower activity following rTMS vs. sham (Figure  ). The overall map was classified into functional cortical regions of interest (ROIs) using Brodmann area (BA) nomenclature derived from Talairach localization (Talairach Daemon) (Lancaster et al.,  ). \n  \n fMRI- Analysis of homologous ROIs:   While multi-subject GLM gave an overview of differential activation of rTMS vs. sham across both hemispheres, we next compared intensities of voxels on the left vs. those on the right. For this, we chose to study ROIs from multi-subject analyses that were active in both hemispheres (Table  ). Voxels active in left ROI (targeted hemisphere) were mirrored on the right (sign for Talairach x-coordinate was reversed). We chose to mirror ROI from left upon right because left hemisphere had larger ROIs (Figure  ). From mirrored ROIs, for instance for mirrored pair of IPS, we identified \u201chomologous\u201d voxels, i.e., a common set of voxels that were significantly active across pooled runs in left as well as the right hemispheres. We compared   t  -values of intensity between voxels on the left with their homologues on the right using pairwise comparisons. For each pair, mean \u00b1 se of intensity is plotted in Figure  . \n  \n fMRI: Activation-Accuracy correlation:   We next investigated activation of which ROIs ultimately relates to behavioral accuracy in each hemifield, and the chronology of such association. Exploring these serial effects is important because it could highlight the nature of the functional role exerted by a region in sustained attention. Unlike multi-subject (Figure  ) and homologous ROI analysis (Figures  ) described above, where pooled runs were compared between rTMS and sham across all subjects, associations were analyzed separately for each run across individual subjects. ROIs defined by multi-subject analysis (Figure  ) were evaluated for each subject. We determined normalized activation of their ROI, i.e., volume of activation following each run of rTMS vs. corresponding run of sham. Their normalized accuracy- accuracy following each run of rTMS vs. corresponding run of sham (as in Figure  )- was also noted. We computed the association (Pearson's correlation) between normalized accuracy within contralateral and ipsilateral hemifields and normalized activation of each ROI (Figure  ). We first examined correlations for IPS. Subsequently, as   post-hoc   exploratory analyses, we examined associations between accuracy and activation of other ROIs from multi-subject analysis (Figure  ). \n    \n fMRI-Regions of interest analysis (ROIs) identified from Multi-Subject Fixed Effects GLM analysis.   FMRI Activation Maps displaying results of Multi-subject fixed effects GLM with comparisons between pooled runs (1, 2, and 3) of rTMS vs. sham. Locus of rTMS targeting is shown as filled purple circle over the left IPS. Red-to-yellow: activation following rTMS > sham; blue-to-green: activation following rTMS < sham. Abbreviations are expanded in Table  . \n    \n fMRI-Regions of interest analysis (ROIs) identified from Multi-Subject Fixed Effects GLM analysis (Figure  )  . \n  \nROIs and their clusters, location (Talairach x, y, and z in mm) and intensities following concatenated runs (1, 2, and 3) of rTMS vs. sham. PMC, premotor cortex; M1 primary motor cortex; IPL, inferior parietal lobule; SPL, superior parietal lobule; IPS, intra parietal sulcus; MT, medial temporal; SoG, superior occipital gyrus; MoG, medial occipital gyrus; MFG, middle frontal gyrus; IFG, inferior frontal gyrus; AG, angular gyrus. Items 1\u201318: areas in the left hemisphere and items 17\u201331: areas in the right hemisphere. \n    \n Analysis of Homologous ROIs.   Quantitative comparison of   t  -values of intensities of homologous ROIs. For homologous ROIs of comparable size (number of voxels noted in parentheses),   t  -values of intensity on left (targeted hemisphere) are compared with those of their homologues on right.   (A)   Comparison of homologous voxels pairs in parietal lobes.   (B)   Comparison of homologous voxels pairs in occipital and temporal regions. While IPS, IPL and MoG show lower intensities in targeted hemisphere, SPL, SoG, Lingual and MT+ show higher intensities in targeted than right hemisphere. These results confirm findings in Figure  . \n    \n Activation-accuracy relationships for IPS and Parietal regions.   Figure shows relationship between accuracy in contralateral and ipsilateral fields in runs 1 and 2 and volumes of activation of parietal ROIs. Note that accuracy in each hemifield is represented as accuracy following rTMS normalized to that following sham. Similarly, volume of activation of an ROI or its intensity is computed as that following rTMS vs. that following sham. Pearson's   r   values are listed in Table  . Relationships are denoted between   (A)   contralateral (Right Field) accuracy and activation of Right IPS in Run 1,   (B)   ipsilateral (Left Field) accuracy and activation of Right IPS in Run 1,   (C)   contralateral accuracy and activation of Left IPS in Run 2,   (D)   ipsilateral accuracy and activation of Right IPS in Run 2, and   (E)   ipsilateral accuracy and activation of Left IPL in Run 2. \n    \n Activation-accuracy relationships for other ROIs.   Figure shows relationship between accuracy in contralateral and ipsilateral fields in run 2 and volumes of activation of occipito-temporal ROIs. Note that accuracy in each hemifield is represented as accuracy following rTMS normalized to that following sham. Similarly, volume of activation of an ROI or its intensity is computed as that following rTMS vs. that following sham. Pearson's   r   values are listed in Table  . Relationships are denoted between   (A)   contralateral (Right Field) accuracy and activation of Right Lingual in Run 2,   (B)   ipsilateral (Left Field) accuracy and activation of Right Lingual in Run 2,   (C)   contralateral accuracy and activation of Left MoG in Run 2,   (D)   ipsilateral accuracy and activation of Left Lingual in Run 2,   (E)   contralateral accuracy and activation of Right SoG in Run 2, and   (F)   ipsilateral accuracy and activation of Right MT in Run 2. \n    \n Activation-accuracy relationship  . \n  \nResults of Pearson's correlation between normalized activation of a region (volume of activation following rTMS vs. sham) and normalized accuracy in a hemifield (accuracy following rTMS vs. sham). The relationships are presented for ROIs identified in multi-subject analysis. These ROIs were tested subject-by-subject and the resultant volume that was active following rTMS vs. sham was analyzed for correlation with their accuracy in the right and left hemifields. Significant correlations or trends toward significance have been highlighted in gray. Although a few other regions appeared to have a significant relation, for instance left MT with left field accuracy in Run 1, on close analysis, these correlations were removed as they were driven by individual outlier values. \n  \n\n\n### Summary of fMRI analyses and their relation to study hypotheses \n  \nThe three levels of fMRI analysis discussed above align with our original hypotheses. We hypothesized that following rTMS of left IPS: \n  \nMulti-subject analysis, and comparison of intensities of homologous voxels of IPS would show reduced fMRI activation of targeted IPS with an opposite response of right IPS \n  \nMulti-subject analysis, and analysis of intensities of homologous ROIs would show that regions known as synergists of IPS in sustaining bilateral attention also demonstrate a shift in their inter-hemispheric activation analogous to the IPS \n  \nNature of correlation between tracking accuracy and activation of IPS, and its network-wide synergists, would evolve in line with their role in sustaining bilateral attention. \n  \n\n\n## Results \n  \n### Behavioral task \n  \nAccuracy in both visual fields, contralateral and ipsilateral, was impaired immediately following rTMS (Run 1) (0.82 \u00b1 0.10 and 0.93 \u00b1 0.18, respectively). Relative to sham, the impairment tended to be considerable, albeit only approaching significance, for contralateral [  t   = 1.652,   p   = 0.066] but not in the ipsilateral field [  t   = 0.374,   p   = 0.35] (Figure  ). For the 2nd run, accuracy in the contralateral field tended to improve but it was still reduced (0.92 \u00b1 0.12). Relative to sham, however, its performance was not significantly different [  t   = 0.598,   p   = 0.28]. Also, although accuracy in the ipsilateral field resumed (1.1 \u00b1 0.2), it was not significantly different relative to sham [  t   = 0.469,   p   = 0.325]. For the 3rd experimental run, accuracy in both ipsilateral and contralateral fields resumed to levels noted following sham (1.05 \u00b1 0.19 and 1.01 \u00b1 0.20, Figure  ). \n\n\n### fMRI results \n  \nStatistical parametric map (Figure  ) of the multi-subject fixed effects GLM analysis illustrated various ROIs that were differentially active following rTMS vs. sham across left and right hemispheres (Table   and Figure  ). We will first present results for multi-subject fixed effects GLM analysis, followed by analysis of homologous ROIs and activation-accuracy relationship for IPS. Later, we will describe these analyses for all other ROIs revealed with statistical parametric map. \n\n#### IPS \n  \nMulti-subject fixed effects GLM analysis showed that left lateral IPS (BA 39) demonstrated lower activation following rTMS vs. sham, while in the right hemisphere, the pattern was reversed (Figure  ). When we compared voxels in left and right comprising the homologous IPS pair, we found that intensity of voxels on the left was significantly lower than ones on the right [  t   = 139.71,   p   < 0.001] (Figure  ). \n\nActivation of IPS was related to behavioral accuracy in runs 1 and 2 only, but not in run 3. In particular, activation of right IPS was related to accuracy in the right hemifield (Figure  ) and left hemifield in run 1 (Figure  ), whereas in run 2, activation of left IPS was positively related with accuracy in the right hemifield (Figure  ) and activation of right IPS was positively related with performance in the left hemifield (Figure  ). In run 2, activation of left IPL was also significantly related to accuracy in the left field (Figure  ). \n\n\n#### Other ROIs \n  \nNetwork-wide ROI analysis (Figure  ) demonstrated that in the left hemisphere, parietal regions that lay medial to targeted (left) IPS, such as the Superior Parietal Lobule (SPL) (BA 5, 7) and the Precuneus (BA7), demonstrated higher activation following rTMS vs. sham, while those lying lateral and inferior to IPS, such as inferior-parietal lobule (IPL, BA40) showed lower activation. Occipito-temporal regions, Superior Occipital Gyrus (SoG) (BA19), Lingual gyri (BA18), Cuneus and Medial Temporal area (MT+) (BA37) showed higher activation, while Middle Occipital Gyrus (MoG) (BA19) demonstrated diminished response following rTMS vs. sham. In the right hemisphere, however, activation pattern of majority of these network-wide areas was reversed: SPL (BA5) demonstrated lower activation, while IPL showed higher activation following rTMS vs. sham (Figure  ). Similarly, SoG, Lingual and MT+ demonstrated lower activation, while MoG showed greater activation following rTMS vs. sham. Therefore, multi-subject analysis showed that following rTMS vs. sham, activation of IPL, SPL, SoG, Lingual, MoG and MT+ areas modulated at an inter-hemispheric level as well, analogous to IPS. The direction of modulation, however, i.e., increase in one hemisphere vs. decrease in another, varied. \n\nThe homologous ROI analysis confirmed findings of the multi-subject GLM (Figure  ). In comparing voxels commonly active in both hemispheres, we found that IPL, SPL (BA5), SoG, Lingual, MoG, and MT+ were affected at inter-hemispheric level as well similar to IPS (Figures  ). Their intensities in TMS-targeted hemisphere were significantly different from those on the right. Intensity of voxels in the targeted left hemisphere was significantly lower than that of corresponding voxels in the right for IPL [  t   = 106.81,   p   < 0.001] and MoG [  t   = 64.8,   p   < 0.001], while intensity was higher on the left than right for SPL [  t   = 86.2,   p   < 0.001], SoG [  t   = 57.46,   p   < 0.001], Lingual [  t   = 72.31,   p   < 0.001], and MT+ [  t   = 57.87,   p   < 0.001]. Areas as cuneus and precuneus were not differentially modulated across hemispheres. \n\nDifferent ROIs demonstrated varying relationships between their activation and the accuracy in left and right hemifields. These relationships evolved from one run to the next. Whereas activation of right IPS and its relationship to accuracy in left and right hemifields (Figures  ) was significant in run 1, relationship between activation of other ROIs and accuracy only manifest for run 2. In run 2, contralateral (right hemifield) accuracy was positively related to activation of right Lingual (Figure  ), left MoG (Figure  ), and right SoG (Figure  ), while ipsilateral (left field) accuracy was related to activation of right lingual (Figure  ), left lingual (Figure  ) and right MT+ (Figure  ). \n\n\n\n\n## Discussion \n  \nWe used fMRI to determine whether rTMS over the left IPS directly alters inter-hemispheric interactions that may explain transient TMS-induced decrement in sustained visual attention, or extinction (Battelli et al.,  ). Our results suggest the following in relation to our original hypotheses. (1) After rTMS, activity of targeted IPS is lower while that of right IPS is exaggerated, reinforcing that inter-hemispheric balance of its activation is indeed disrupted with rTMS. (2) Besides IPS, inter-hemispheric balance of the network involved in bilateral sustained attention- parietal, temporal and occipital synergists- is also disrupted. IPL and MoG show lowered activation and SPL, MT+ and SoG show higher activation in TMS-targeted hemisphere, while response of their homologues is opposite. The transient attentional decrement induced with rTMS thus emerges from a network-wide disruption of inter-hemispheric balance. (3) The evolution of activation of IPS and its network-wide synergists relates to changes in attentional accuracy over serial runs; whereas, immediately, activation of right IPS is associated with right and left field accuracy, subsequently, synergists as IPL, Lingual gyrus, SoG, MoG, and MT+ likely relate to recovery. Although we did not find a strong decrement in behavioral performance, unlike our previous study, we noted with fMRI that network-wide activation of IPS, IPL and occipito-temporal synergists may help adaptively compensate for, and alleviate, contralateral and ipsilateral decrement after rTMS. Therefore, our model of combined rTMS and fMRI offers direct empirical demonstration of altered inter-hemispheric balance, a likely explanation of the clinical manifestation of visuospatial extinction, and the nature of such balance during attentional behavior. \n\n### Intra-parietal sulcus (IPS): inter-hemispheric competition in bilateral visual attention \n  \nIPS is implicated in resolving competition between bilateral stimuli (Culham et al.,  ; Muri et al.,  ; Muggleton et al.,  ; Battelli et al.,  ), an ability that emerges from tonic inhibitory influence exerted by one IPS upon another (Kinsbourne,  ). That rTMS targeting IPS intensifies this inter-hemispheric competition has traditionally been inferred from behavioral observations (Hilgetag et al.,  ; Muri et al.,  ; Thut et al.,  ; Dambeck et al.,  ; Fierro et al.,  ; Battelli et al.,  ). Here, we demonstrate for the first time that TMS targeting left IPS indeed reduces activity of left and increases activity of right IPS. TMS likely weakens inhibition exerted by left upon right IPS, which in turn is disinhibited. As a novel finding here, with the use of fMRI measurement of offline effects of rTMS, we generate empirical support for the theory of inter-hemispheric rivalry, shedding new light on the basis of clinically witnessed extinction-like effects (Kinsbourne,  ; Corbetta et al.,  ). \n\nInterestingly, increased activity of right IPS relates positively with accuracy in hemifields ipsilateral as well as contralateral to targeted IPS. While the former finding aligns with the belief that uninhibited activity of \u201cundamaged\u201d parietal cortex leads to hyper-oriented attention to the unimpaired field, the latter is in contradiction to its corollary. Hyper-oriented attention to the unaffected field is long-thought to limit attention to the impaired field even further. \n\nWe however have failed to observe a \u201cnegative\u201d effect of over-activation of right IPS upon right-field attention potentially for the following reasons. First, we elicited weaker right-field extinction with rTMS in our present study compared to our previous (Battelli et al.,  ). The time lapse between end of rTMS and beginning of behavioral task in the scanner could have mitigated the impairment, which may have affected over-activation of right IPS, hence its ability to hyper-attend to left and limit attention to right field. Second, since right IPS is specialized to subtend visual attention in both hemifields (Mesulam,  ), its disinhibition may in fact have a compensatory role- alleviating rTMS-induced decrement in right-field visual attention. Therefore, \u201cdisinhibition\u201d of right parietal cortex, since it subtends attention to left as well as right fields, may have led to a milder level of right-field extinction following inactivation of the left parietal cortex. Understanding whether inactivating right IPS exaggerates the right-field decrement would be important to confirm our speculation. Thus, fMRI combined with offline rTMS to unilateral left IPS generates empirical support for the theory of inter-hemispheric rivalry (Corbetta et al.,  ). \n\n\n### Inter-hemispheric competition across network involved in bilateral visual attention \n  \nAlthough IPS was the target locus, activity of several important parieto-occipito-temporal synergists modulated differentially across both hemispheres indicating that rTMS of left IPS influences inter-hemispheric balance of the entire visuo-attentional network. Even more importantly, our model combining offline fMRI following rTMS demonstrated that inter-hemispheric profile of activation of these synergists aligns with the nature of their interaction with IPS in sustaining bilateral visual attention. Whether the activation of a region was in line with or opposite to that of targeted IPS indicates its role in supporting visual attention (Sheremata et al.,  ). For instance, IPL's inter-hemispheric activation pattern coincides with that of the IPS, suggesting their paired role in visual attention (Cicek et al.,  ) and involvement with visuo-spatial neglect (Mort et al.,  ). On the other hand, SPL and Precuneus show opposite inter-hemispheric activation pattern than IPS and IPL, which reinforces the theory of dynamic competition between these pairs. Medial-dorsal regions, such as SPL and Precuneus, are anatomically segregated and functionally competing in a push-pull manner with lateral-ventral parietal regions, as IPS and IPL (Sestieri et al.,  ). While SPL and Precuneus trigger transient attentional shifts to bilateral loci, IPS and IPL are involved in sustaining attention to both visual fields (Battelli et al.,  ; Kelley et al.,  ). Thus, while IPS and IPL showed a similar inter-hemispheric response to rTMS, SPL, and precuneus demonstrated the opposite with their respective homologues (Figures  ,  ). \n\nOccipital synergists showed varying inter-hemispheric response as well, in line with the nature of their relation with IPS. We witnessed opposing responses of SoG from the IPS- exaggerated facilitation on left, with inhibition on right, following rTMS. Activation of early visual areas as SoG is functionally coupled yet dynamically competing to that of posterior parietal regions (Ruff et al.,  ), which would explain their contrasting response to rTMS. Dynamic interactions were not only visible between homologous pairs, but also between non-homologous synergists. For instance, left MoG and right lingual showed opposite response to rTMS; while lingual became more active in the left hemisphere, MoG became more active in the right following rTMS. MoG and lingual in different hemispheres maintain a competitive dynamic that has been described previously in the context of visual motion perception (Brandt et al.,  ). The presence of a contralateral moving visual stimulus has been associated with MoG activation that is paired with that of ipsilateral lingual gyrus. Such an inverse relation between non-homologous regions as that modulated in our protocol is believed to arise from transcallossal transfer of visual attention information (Brandt et al.,  ). \n\nIt is finally interesting to notice the temporal evolution of activation across regions. How the activation of a region evolves with attentional behavior indicates what type of role it exerts in visual attention. Immediately following rTMS, intensity of activation of right IPS was positively related to that of accuracy in contralateral (right) and ipsilateral fields. In the 2nd run, participants showing higher activation of left MoG and right Lingual showed higher right-field accuracy, indicating inter-hemispheric interactions of these non-homologous occipital synergists may serve to adaptively compensate for rTMS-induced deficits. \n\nOverall, thus, empirical use of fMRI with offline rTMS directly supports Kinsbourne's hemispheric rivalry in bilateral sustained visual attention, suggesting its potential link to clinical visual extinction. We have noted that empirical visual extinction induced by rTMS to IPS is subtended not only by an inter-hemispheric imbalance at the level of IPS, but also its functional network involving parietal, temporal and occipital synergists. Competitive inter-hemispheric profile was witnessed for IPL, SPL, SoG, MT+, MoG besides IPS. Following rTMS, the similarity between the response of a synergist and that of targeted IPS, and the evolution of such response, alludes to the nature of their mutual interactions in bilateral visual attention- competing or compensatory. While competitive coupling is noted for IPS/IPL vs. SPL/Precuneus and IPS vs. SoG, adaptive interactions of MoG and Lingual gyrus with IPS may help alleviate behavioral decrement. Therefore, our model combining rTMS and fMRI offers direct empirical insight into altered coupling believed to explain clinical phenomena, and the nature of such coupling in the performance of normal behavior. \n\n\n\n## Conclusions \n  \nUsing a protocol of offline rTMS combined with fMRI, we studied network-wide mechanisms of rTMS targeting IPS in bilateral sustained visual attention. We showed proof-of-concept for classical theory of hemispheric rivalry that manifests in bilateral attention, by showing competing activation between hemispheres across areas critical to visual attention. Further, by illustrating intra- and inter-hemispheric interactions with the targeted locus, we suggest transient compensatory phenomena that could attenuate the behavioral effects of inactivating IPS. Such intra- and inter-hemispheric connectivity empirically supports the clinical extinction noted with damage to posterior parietal cortices and workings of distributed neural systems that potentially favor recovery from focal damage. Finally, these findings have important implications for potentially using rTMS as a rehabilitation technique for severe and persistent attentional deficits following parietal stroke. \n\n\n## Conflict of interest statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nItem\tROI\tVolume\tX\tY\tz\tt-value sham\tt-value rTMS\nrTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\n1\tL MFG BA6\t2250\t\u221212\t\u221210\t58\tt = 28.03, p < 0.001\tt = 44.54, p < 0.001\n2\tL M1 BA4\t2107\t\u221222\t\u221221\t62\tt = \u22124.09, p = NS\tt = 12.30, p < 0.001\n3\tL SPL BA5 cluster 1\t2648\t\u221227\t\u221242\t59\tt = 16.84, p < 0.001\tt = 33.23, p < 0.001\n4\tL SPL BA5 cluster 2\t1851\t\u221232\t\u221238\t43\tt = 25.89, p < 0.001\tt = 36.25, p < 0.001\n5\tL SoG BA19\t1876\t\u221224\t\u221276\t30\tt = 41.74, p < 0.001\tt = 57.64, p < 0.001\n6\tL Precuneus BA7\t4923\t\u221211\t\u221269\t49\tt = 8.58, p < 0.001\tt = 24.45, p < 0.001\n7\tL Cuneus BA18\t5577\t\u22127\t\u221278\t22\tt = \u221227.79, p < 0.001\tt = \u22127.47, p < 0.001\n8\tL Lingual BA17\t2137\t\u22126\t\u221289\t1\tt = 13.82, p < 0.001\tt = 30.18, p < 0.001\n9\tL MT\t1819\t\u221243\t\u221270\t3\tt = 63.70, p < 0.001\tt = 76.45, p < 0.001\nSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\n10\tL PMC BA6\t2423\t\u221231\t\u22122\t48\tt = 39.80, p < 0.001\tt = 20.94, p < 0.001\n11\tL IPL BA40 Cluster2\t667\t\u221241\t\u221233\t38\tt = 31.93, p < 0.001\tt = 16.68, p < 0.001\n12\tL IPL BA40 Cluster3\t1103\t\u221251\t\u221241\t41\tt = 0.68, p = NS\tt = \u22129.30, p < 0.001\n13\tL IPL BA40 Cluster5\t650\t\u221239\t\u221252\t45\tt = \u22121.66, p = NS\tt = \u22129.66, p < 0.001\n14\tL IPS BA39\t1318\t\u221233\t\u221262\t43\tt = \u22120.02, p = NS\tt = \u221210.1, p < 0.001\n15\tL Angular Gyrus BA39\t2124\t\u221234\t\u221279\t31\tt = 16.64, p < 0.001\tt = 5.41, p < 0.001\n16\tL MoG BA19\t1069\t\u221230\t\u221284\t18\tt = 55.86, p < 0.001\tt = 39.44, p < 0.001\nrTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\trTMS > SHAM\n17\tR MFG BA6\t967\t7\t10\t49\tt = 25.48, p < 0.001\tt = 38.54, p < 0.001\n18\tR IPL BA 40\t3035\t41\t\u221239\t48\tt = 22.38, p < 0.001\tt = 35.49, p < 0.001\n19\tR IPS\t3178\t32\t\u221271\t41\tt = 3.63, p = NS\tt = 21.43, p < 0.001\n20\tR Precuneus BA7 Cluster1\t1309\t11\t\u221272\t55\tt = 14.46, p < 0.001\tt = 26.95, p < 0.001\n21\tR Precuneus BA7 Cluster2\t872\t25\t\u221281\t42\tt = 34.14, p < 0.001\tt = 43.91, p < 0.001\n22\tR Precuneus BA31\t719\t19\t\u221260\t25\tt = \u221219.00, p < 0.001\tt = \u22128.77, p < 0.001\n23\tR Cuneus BA 18\t4987\t8\t\u221271\t11\tt = \u221221.76, p < 0.001\tt = \u22125.48, p < 0.001\n24\tR MoG BA19\t743\t29\t\u221287\t7\tt = 16.08, p < 0.001\tt = 27.47, p < 0.001\nSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\tSHAM > rTMS\n25\tR PMC BA6\t1970\t23\t\u22122\t51\tt = 45.419, p < 0.001\tt = 25.296, p < 0.001\n26\tR MFG BA6 Cluster1\t985\t39\t\u22127\t49\tt = 56.827, p < 0.001\tt = 39.885, p < 0.001\n27\tR IFG BA6\t1119\t44\t4\t24\tt = 31.85, p < 0.001\tt = 16.172, p < 0.001\n28\tR SPL BA 5\t812\t26\t\u221240\t54\tt = 33.862, p < 0.001\tt = 23.058, p < 0.001\n29\tR SoG BA19\t632\t23\t\u221279\t27\tt = 47.460, p < 0.001\tt = 34.959, p < 0.001\n30\tR Lingual Gyrus BA18\t611\t8\t\u221275\t\u22125\tt = 45.970, p < 0.001\tt = 31.715, p < 0.001\n31\tR MT\t1482\t44\t\u221272\t10\tt = 50.504, p < 0.001\tt = 34.403, p < 0.001\n### Caption\nfMRI-Regions of interest analysis (ROIs) identified from Multi-Subject Fixed Effects GLM analysis (Figure 2).\n### Footer\nROIs and their clusters, location (Talairach x, y, and z in mm) and intensities following concatenated runs (1, 2, and 3) of rTMS vs. sham. PMC, premotor cortex; M1 primary motor cortex; IPL, inferior parietal lobule; SPL, superior parietal lobule; IPS, intra parietal sulcus; MT, medial temporal; SoG, superior occipital gyrus; MoG, medial occipital gyrus; MFG, middle frontal gyrus; IFG, inferior frontal gyrus; AG, angular gyrus. Items 1\u201318: areas in the left hemisphere and items 17\u201331: areas in the right hemisphere.\n", "metadata": {"pmcid": 4029023, "text_md5": "bb2a3369f99b11a8fdcd18f0e8fe6c27", "field_positions": {"authors": [0, 126], "journal": [127, 145], "publication_year": [147, 151], "title": [162, 275], "keywords": [289, 369], "abstract": [382, 2201], "body": [2210, 39188], "tables": [39201, 42597]}, "batch": 2, "pmid": 24860462, "doi": "10.3389/fnhum.2014.00226", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029023", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4029023"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029023\">4029023</a>", "list_title": "PMC4029023  The compensatory dynamic of inter-hemispheric interactions in visuospatial attention revealed using rTMS and fMRI"}
{"text": "Jansma, Johan Martijn and van Raalten, Tamar R. and Boessen, Ruud and Neggers, Sebastiaan F. W. and Jacobs, Richard H. A. H. and Kahn, Ren\u00e9 S. and Ramsey, Nick F.\nPLoS One, 2013\n\n# Title\n\nfMRI Guided rTMS Evidence for Reduced Left Prefrontal Involvement after Task Practice\n\n# Keywords\n\n\n\n# Abstract\n \n## Introduction \n  \nCognitive tasks that do not change the required response for a stimulus over time (\u2018consistent mapping\u2019) show dramatically improved performance after relative short periods of practice. This improvement is associated with reduced brain activity in a large network of brain regions, including left prefrontal and parietal cortex. The present study used fMRI-guided repetitive transcranial magnetic stimulation (rTMS), which has been shown to reduce processing efficacy, to examine if the reduced activity in these regions also reflects reduced involvement, or possibly increased efficiency.  \n\n\n## Methods \n  \nFirst, subjects performed runs of a Sternberg task in the scanner with novel or practiced target-sets. This data was used to identify individual sites for left prefrontal and parietal peak brain activity, as well as to examine the change in activity related to practice. Outside of the scanner, real and sham rTMS was applied at left prefrontal and parietal cortex to examine their involvement novel and practiced conditions.  \n\n\n## Results \n  \nPrefrontal as well as parietal rTMS significantly reduced target accuracy for novel targets. Prefrontal, but not parietal, rTMS interference was significantly lower for practiced than novel target-sets. rTMS did not affect non-target accuracy, or reaction time in any condition.  \n\n\n## Discussion \n  \nThese results show that task practice in a consistent environment reduces involvement of the prefrontal cortex. Our findings suggest that prefrontal cortex is predominantly involved in target maintenance and comparison, as rTMS interference was only detectable for targets. Findings support process switching hypotheses that propose that practice creates the possibility to select a response without the need to compare with target items. Our results also support the notion that practice allows for redistribution of limited maintenance resources.  \n\n \n\n# Body\n \n## Introduction \n  \nPerforming a task for the first time typically is slow and prone to errors, while the amount of information that can be processed is limited. However, even relative short periods of practice can result in a striking improvement in performance if a task environment is consistent, in the sense that a certain stimulus always requires an identical response [ ] [ , ]. Such tasks are also called \u201cconsistent mapping\u201d (\u2018CM\u2019) tasks. In contrast, if a task environment is inconsistent, and a stimulus may sometime require one response and at other ties another, practice may have almost no effect on performance [ ]. These task are also referred to as \u2018varied mapping\u2019 (\u2018VM\u2019) tasks. \n\nPrevious imaging studies have shown that practice CM tasks is also associated with a widespread reduction of brain activity [ - ]. FMRI studies are however limited in providing information about underlying causes of changes in brain activity. For instance, it is possible that reduced activity after practice reflects reduced involvement of these regions. It is however also possible that involvement of these regions hasn\u2019t changed, but that the reduction is for instance a result of increased efficiency, or the loss of redundant activity. \n\nTranscranial magnetic stimulation (TMS) can be used to briefly affect processing efficacy in a brain region, thereby revealing a causal relationship between cortical function and behavior [ ]. For this reason, TMS is especially well suited to examine involvement of brain regions in task execution. Although the precise working mechanism of TMS is still somewhat unclear, a disruption of function is expected when the TMS induced current is remote from the operations that are normally performed by the neuronal tissue under investigation. This can for instance be achieved by inducing a train of repetitive short stimuli [ ]. This technique, known as repetitive TMS (\u2018rTMS\u2019), is understood to add noise to the intricate process of neuronal signaling, thereby reducing the processing efficacy in that brain region [ , , ]. \n\nHere we present, to our knowledge, the first study that uses fMRI guided rTMS to examine the effect of practice on the involvement of specific brain regions. For this study, we focused on the left prefrontal and parietal cortex, as it has been shown that for the Sternberg task that we used [ ], novel performance consistently induces robust activation in these regions, while practiced consistently reduces activity in these regions [ - ]. We used fMRI to identify a focus site for each subject within the left prefrontal and the left parietal cortex that showed maximal activity during novel performance. We then applied rTMS to those individual focus sites. \n\nWe hypothesized that the previously shown reduction of activity in left prefrontal and parietal cortex reflected reduced involvement of these regions. Based on this hypothesis, our expectation was that rTMS of the left prefrontal as well as left parietal cortex would interfere measurably with performance when the target-set was novel, as these regions are highly active in that condition. We expect that this interference would be significantly lower for practiced targets, as these regions are less active in this condition, and we hypothesize that this reduced activity reflects reduced involvement.  \n\n\n## Materials and Methods \n  \n### Participants \n  \nNineteen adult volunteers (10 male, 9 female; mean age = 22.8 years; sd = 3.03 years, range = 19-31 years) participated in the study after giving written informed consent. Subjects were recruited from the university campus through advertisement and rewarded for their participation. The Mini International Neuropsychiatric Interview (M.I.N.I.) [ ] was used to exclude subjects with a history of neurological illness, psychiatric disorders, or substance abuse. All participants were tested for right-handedness using the Edinburgh Handedness Index [ ]. The study was approved by the local medical ethics committee (\u2018Medisch-ethische toetsings commissie Universitair Medisch Centrum Utrecht\u2019), in accordance with the Declaration of Helsinki (2008). Participants tolerated the rTMS protocol well and did not report any lasting adverse effects. \n\n\n### Paradigm \n  \nWe measured the difference in performance and brain activity associated with practice using a paradigm that had been successfully applied in previous studies [ - ]. The paradigm is based on a Sternberg task [ ], but is specifically designed to register practice effects related to performing a consistent mapping task. For this purpose, the paradigm compares task performance of novel and practiced target sets. The two conditions are identical, except that subjects have had previous experience with the target-set in the practiced condition during a practice session. The training session is expected to induce improved performance [ ], and reduced brain activity [ ] for this specific target-set.  \n\nWe used a fixed set of ten consonants to create three target and non-target sets of five items for the practiced condition. One set was used during the fMRI session and the two other sets were used for the prefrontal and parietal rTMS sessions. We created all novel target-sets from the remaining ten consonants to prevent interference with the practiced target-sets. Novel target-sets were varied per block.  \n\n\n### Task \n  \nWe presented both the novel and practiced condition in runs of one target-set of five items, followed by ten probes (see  ). Target-sets were presented for 5000 msec, probes were presented for 1200 msec and separated by an asterisk that was presented for 1000 msec. The occurrence of targets and non-targets was evenly distributed per run. We instructed subjects to memorize the target-set, and then use the right hand to press the left button of a pneumatic MRI compatible push-button box when probes matched the memory set (targets) or the right button if the probe did not match the memory set (non-targets). In the rTMS sessions, we instructed subjects to press the M on a QWERTY keyboard to targets and the X to non-targets. Both keys were clearly marked with an easily found ribbon to prevent searching during performance of the task. Subjects rested their left and right index fingers of the right hand on the keys during the entire session \n   The temporal sequence is shown for the Sternberg task.  \nEach run starts with the presentation a fixed memory set and is followed by ten probes. Subjects press a left button to targets and a right button to non-targets. For the novel condition, the target-set was varied for each run. For each practice run, the same target-set was used as in the practice session. For the baseline condition, the memory set consisted of two arrows (\u2018< \u2018>\u2019) and probe stimuli were single arrows (\u2018<\u2019 or \u2018>\u2019). The task involved eight runs of each condition in a pseudorandom order. For the rTMS sessions, magnetic stimulation or sham stimulation was applied for 500 msec, starting 50 msec after the presentation of a probe. \n  \nSubject also performed a baseline condition, where subjects responded to the symbols \u2018 <\u2019 and \u2018>\u2019 by using the right hand to make a left or right button press respectively. The baseline condition required perceptual and motor processing, but no maintenance of a target-set. The baseline condition was used in the fMRI sessions to exclude perceptual and motor activity. All task versions used in the experiment were programmed in Presentation 9.9 running on a Windows operating system. \n\n\n### Experimental procedure \n  \nSubjects performed a scan session to determine individual target regions for TMS coil navigation, followed by two separate TMS sessions for the prefrontal and parietal stimulation sites (see  ). In each of the two TMS sessions both a sham and real TMS stimulation was performed in random and balanced order. Each session was preceded by a training session that lasted approximately 25 minutes. In the training sessions, subjects performed the Sternberg task with a fixed target-set for 5 runs with 100 probes each. Each experiment session consisted of four sections separated by 32-second passive rest conditions. Each section started and ended with a baseline condition, and had two practiced and novel condition blocks in between, in balanced order for a total of 8 blocks of each condition in each session.  \n   The experimental design.  \nSubjects participated in one fMRI and two rTMS sessions, one for parietal and for prefrontal rTMS. Each session started with a practice session with a unique fixed target-set. \n  \n\n### Functional MRI \n  \n#### FMRI data acquisition \n  \nFMRI was performed on a Philips 3 T Intera scanner. We reduced head movement by using a strap around the forehead and foam padding. A video projector located outside the scanner room projected the tasks on a 1m-wide through-projection screen, which subjects could view through a mirror attached to the head coil. Functional scans used a PRESTO SENSE pulse sequence image in two continuous runs of each 832 scans (parameters: TE = 32.4 msec, TR = 21.75 msec, voxel size = 4mm x 4mm x 4mm, 32 sagittal slice, scan duration of 500 msec) [ ]. We acquired a T1-weighted anatomical image for spatial localization and to guide TMS coil navigation.  \n\n\n#### FMRI analysis \n  \nAfter reconstruction, functional and anatomical data were processed off-line using SPM5 software. Scans were corrected for motion, co-registered to the anatomy image, and spatially smoothed with a Gaussian kernel with FWHM of 8 mm. Individual statistical activation maps were generated in native space using a general linear model analysis. Separate regressors were used to model activity for the probe presentation period for each of the three conditions using a blocked paradigm approach [ , ]. We used the novel-baseline contrast t-maps in native space to identify rTMS focus site coordinates in the left prefrontal and the parietal cortex, based on the voxel with the maximum signal change. The individually derived rTMS target coordinates were also transformed into MNI space coordinates for visualization purposes (see  ).  \n   The individual stimulation locations in the left prefrontal (shown in red) and the left parietal cortex (shown in green) are displayed in MNI space for all participants in the study in a lateral (left) and a superior view (right).  \nIndividual stimulation locations were based on the voxel with the highest signal change in the novel-baseline contrast in the fMRI session. Numbers in blue represent MNI coordinates.  \n  \nIn order to test if subjects showed reduced activity at each rTMS focus site, we calculated the fMRI signal for the novel and practiced condition at each of these positions. Additionally, we spatially normalized the activation maps to MNI space to create group activation patterns. These maps were used to examine regions showing a change in the signal after practice (activity threshold: |t| = 4.6, p < 0.0001 uncorrected), in order to test if there was any increase in activity in the practiced condition, compared to the novel condition. Presence of increased activity in the practiced condition could reduce the validity of our study, as it could mean that the focus site for rTMS that is chosen based on the novel condition, may not be valid for the practiced condition  \n\n\n\n### TMS \n  \n#### Data acquisition \n  \nA frameless stereotactic neuronavigator (The Neural Navigator, http://www.neuralnavigator.com) from Brain Science Tools BV, the Netherlands, was used for coil positioning.\u00a0(See   for details of the technique.) This device enables anatomical landmarks on the skin of the participants to be co-registered with the same landmarks on a skin rendering based on their MRI scans. We used the voxels with the highest signal change in the left prefrontal and parietal cortex in the novel-baseline fMRI contrast as rTMS target coordinates (see  ). Each participant wore a tightly fitting swimming cap, where we marked the areas on the scalp directly overlying the rTMS target coordinates. Borders of the search areas were not strictly defined, but guided by the individual activation patterns. We refer to these regions as \u201cfrontal\u201d and \u201cparietal\u201d for the remainder of the manuscript.  \n\nWe applied rTMS with a train of five rTMS pulses, separated by 100 msec (10 Hz). The pulses started 50 msec after the onset of each probe (see  ) and covered the full response period for that probe, in order to reduce only the processing efficacy of that specific probe. A Neopulse TMS device (Neotonus Inc, Atlanta) with an iron core coil was used (see Epstein et al, 2002 for details). The iron core is embedded at the center of a rectangular figure of eight coil, parallel to the wiring at the center. Advantages of this coil are that the ferromagnetic cores cause the generated magnetic field to be stronger and to penetrate deeper into the brain (Epstein and Davey, 2002). The pulse intensity was 110% of the individual motor threshold, which was defined before the experiment as the minimum intensity that would induce a visible muscle twitch in the contra lateral hand on at least five out of ten occasions (see   for details).  \n\nIn order for us to control for nonspecific rTMS effects such as tactile and auditory sensations, participants also performed a session with a sham coil. The order of stimulation site (prefrontal and parietal) and session type (rTMS, sham) was balanced over subjects, to prevent a bias due to learning, fatigue, or habituation effects. \n\n\n#### Data analysis \n  \nWe obtained individual reaction time and accuracy data (proportion of correct responses) for each condition (novel, practiced, baseline), each site of stimulation (prefrontal, parietal), and each session (rTMS, sham). For the remainder of this manuscript, we refer to the difference in performance between the rTMS and sham session as the \u2018rTMS effect\u2019.  \n\n\n\n### Hypotheses tests \n  \nFor our hypotheses tests, we used the accuracy and reaction data for targets and non-targets for the prefrontal and parietal rTMS sessions. We determined all effects using a General Linear Model with univariate tests for repeated measures (SPSS17 \u00ae). Effects of practice were tested using the main effects of condition (novel versus practiced). Effects of rTMS were tested using the main effect of stimulation (rTMS versus sham). Our main hypotheses, namely that the effect of rTMS would be smaller in the practiced condition than in the novel condition, was tested using the interaction effect of stimulation and condition. Furthermore we performed follow-up tests for the novel and practice condition separate. \n\n\n\n## Results \n  \n### FMRI \n  \nIndividual stimulation locations in the prefrontal and parietal cortex in MNI space for each participant are displayed in  . Regions showing significantly different activity between the novel and practiced condition are summarized in   and visualized in  . As expected, practice significantly reduced activity in a network of regions including left inferior parietal, left precentral gyrus. In addition, there were three regions that showed increased activity: the medial part of the right superior frontal cortex, the left precuneus, and the left angular gyrus.   illustrates that also in these three regions activity was closer to rest for the practiced condition than for the novel condition.  \n   Overview of regions showing signal change in novel-practiced contrast.         Summary of the fMRI results.  \na. regions showing significant difference between novel and practice condition (red: novel < practiced, blue: practiced > novel). Three regions showed an increase in activity for the practiced condition compare to the novel condition (a. right medial superior frontal cortex (rMSFC), b. left precuneus (lPCun), c. left Angular Gyrus (lAG).  \n\nb. Signal change (baseline: rest) for the three regions where we found higher activity for practiced targets than for novel targets. The graph shows that in all three regions activity was below resting state activity for the novel condition, and closer to resting state for the practiced condition. Thus, none of these regions showed new or increased activity in the practiced condition, compared to the novel condition.  \n\nc. fMRI signal measured at the individual prefrontal and parietal target regions for rTMS, based on the novel-baseline contrast. Both at the prefrontal and parietal regions, subjects showed significantly lower activity for practiced than for novel target-sets.  \n  \n shows the average signal for the novel and practiced condition at the selected individual focus sites for the rTMS stimulation. Focus sites for rTMS showed a significant lower activity in the practiced than in the novel condition for both prefrontal (t = 5.53, p < 0.001) and parietal cortex (t = 5.42; p < 0.001).  \n\n\n### rTMS and accuracy \n  \n#### Prefrontal rTMS session \n  \nResults are graphically displayed in  . For target accuracy, we found a significant main effect of condition (novel, practiced; F(1.18) = 62.05; p < 0.001) as well as a significant main effect of stimulation (rTMS, sham; F(1.18) = 16.13; p = 0.001). rTMS interference was significantly higher in the novel condition than in the practiced condition (F(1.18) = 9.04; p = 0.008).  \n   Effect of rTMS on accuracy.  \nGraphs illustrate that practice increased accuracy for both targets and non-targets. Prefrontal rTMS reduced with target accuracy, and this effect was larger in the novel than in the practiced condition. Parietal rTMS also reduced target accuracy, but there was no difference between the novel and practiced condition. a. accuracy during prefrontal rTMS; b. accuracy during parietal rTMS. \n  \nFor non-targets, we also found a significant main effect of condition (novel, practiced; F(1.18) = 21.85; p < 0.001), but no main effect of stimulation (rTMS, sham; F(1,18) = 0.67; p = 0.43). Also, there was no difference in the prefrontal rTMS effect on non-target accuracy between the novel and practiced condition (F(1.18) = 0.007; p = 0.93) \n\n\n#### Parietal rTMS session \n  \nFor target accuracy, we also found a main effect of condition (novel, practice; F(1.18) = 33.26; p < 0.001), as well as a significant main effect of stimulation (rTMS, sham; F(1.18) = 9.40; p = 0.01). The parietal rTMS effect did not differ between the novel and practiced condition for target accuracy (F(1.18) = 0.21; p = 0.65). \n\nFor non-target accuracy, we also found a significant main effect of condition (novel, practiced; F(1.18) = 12.83; p < 0.001). We did not find a main effect of stimulation (rTMS, sham; F(1.18) = 0.57; p = 0.46), and no difference in parietal rTMS interference between the novel and practiced condition (F(1.18) = 0.21; p = 0.65) \n\n\n\n### rTMS and reaction time \n  \n#### Prefrontal rTMS session \n  \nResults are graphically displayed in  . For target reaction times, we found a significant main effect of condition (novel, practiced; F(1.18) = 29.32; p < 0.001). There was no main effect of stimulation (rTMS, sham; F(1.18) = 0.59; p = 0.45). Also, prefrontal rTMS effects were not different in the novel and practiced condition for target reaction times (F(1.18) = 1.12; p = 0.30).  \n   Effect of rTMS on reaction time.  \nGraphs illustrate that reaction time was lower in the practiced than in the novel condition, but rTMS had no effect on reaction times. a. reaction time during prefrontal rTMS; b. reaction time during parietal rTMS. \n  \nFor non-target reaction times, we also found a significant main effect of condition (novel, practiced; F(1.18) = 42.72; p < 0.001), but no main effect of stimulation (rTMS, sham; F(1.18) = 0.015; p = 0.91). Also, there was no difference in prefrontal rTMS effects in the novel and practice condition for non-target reaction times (F(1.18) = 1.28; p =0.27) \n\n\n#### Parietal rTMS session \n  \nFor target reaction times, we found a significant main effect of condition (novel, practiced; F(1.18) = 61.2; p < 0.001), but no main effect of stimulation (rTMS, sham; F(1.18) = 0.12; p = 0.73). There was also no difference in parietal rTMS interference on target reaction times for the novel and practiced condition (F(1.18) = 0.04; p = 0.85). \n\nFor non-target reaction times, we also found a significant main effect of condition (novel, practiced; F(1.18) = 81.21; p < 0.001), no main effect of stimulation (rTMS, sham; F(1.18) = 0.58; p = 0.45), and no difference in parietal rTMS effect in the novel and practiced condition (F(1.18) = 0.23; p = 0.64) \n\n\n#### Summary \n  \nReaction time was reduced and accuracy increased in the practiced condition, compared to the novel condition, for both targets and non-targets. Prefrontal rTMS effects on target accuracy were significantly lower in the practiced condition than in the novel condition. Parietal rTMS effects on target accuracy were not significantly different in the practiced and novel condition. Both prefrontal and parietal rTMS did not affect reaction times, nor did they affect accuracy results for non-targets. \n\n\n\n\n## Discussion \n  \nWe used rTMS, guided by fMRI, to test the hypothesis that practice in a consistent task environment reduces involvement of the left prefrontal and left parietal regions of the brain. To do this, we compared the degree to which rTMS applied at these regions affected performance of a Sternberg task with novel and practiced target-sets.  \n\nThe main finding of our study is that the degree to which prefrontal rTMS reduced subjects\u2019 accuracy in detecting targets was significantly lower for practiced target-sets, than for novel sets. The interference resulting from parietal rTMS was not significantly different between novel and practiced target-sets. Additional findings included that neither prefrontal nor parietal rTMS interfered with non-target accuracy. Also, neither prefrontal nor parietal rTMS interfered with reaction times. Our results support the hypothesis that practice reduces the involvement of left prefrontal cortex in task execution [ , , ].  \n\nOur rTMS results for the novel condition are in line with previous studies, which have consistently demonstrated interference effects of prefrontal rTMS for verbal working memory [ , ], as well as spatial working memory [ , ]. Our fMRI results indicated that practiced target-sets evoked less activity than novel target-sets in an extensive network of brain regions, including the left prefrontal cortex and left inferior parietal cortex\u2014the rTMS focus sites. This result reproduces previous imaging results with this paradigm [ , ],[ ] as well as with other paradigms [ , , , ]. FMRI results also confirmed that the individually selected rTMS focus sites were less activated after practice.  \n\nWith regard to parietal involvement, we found no evidence that it diminished after practice: rTMS interference effects were not different in the novel and practiced condition. This could be viewed as surprising, in light of the fact that fMRI studies have consistently shown reduced activity in parietal regions after practice, just as in prefrontal regions [ ]. Possibly, the reduced activity in parietal cortex after practice is related to increased processing efficiency, without reduction in involvement. It has to be noted however, that the effect of parietal rTMS was relatively small in both the novel and practiced conditions. This is in line with previous studies that have demonstrated strong effects in prefrontal cortex, but negligible effects in parietal cortex for non-spatial cognitive tasks [ , ]. If parietal interference effects could be demonstrated, they were specific for spatial tasks [ , ]. There could be several explanations for the lower rTMS effect in parietal cortex. First, it could be that the left parietal cortex is indeed less crucial for verbal task performance then the left prefrontal cortex. A second reason could be that the left parietal cortex is part of a more extensive brain network, in which interference with a single \u201cnode\u201d\u2014as happens in rTMS\u2014is insufficient to disrupt performance [ ]. This is in line with the fact that our fMRI results showed bilateral parietal activity, while prefrontal activity was predominantly left lateralized.  \n\nOur study yielded several additional findings. First, interference from rTMS was only detectable for targets, and not for non-targets. Second, rTMS interference was measurable for accuracy, but not for reaction times. This second finding replicates previously published effects of rTMS in delayed cognitive tasks [ , ]. The specific effect of prefrontal rTMS on target accuracy indicates that rTMS did not interfere with probe processing, as that would have affected non-target probes as well as targets. Similarly, it indicates that rTMS did not interfere with processes related to attention, motor execution, or inhibition, as these would also have affected non-targets and not just accuracy but also reaction time.  \n\nOne mechanism that is in line with all our findings is that left prefrontal rTMS temporarily disturbs access to the maintained target-set. Such an effect would cause target-probes to be mistaken for non-targets, while non-targets would not be affected. This is what we observed in our experiment. Reaction times would also not be affected, and this we also observed. This mechanism would also be in line with a previously published finding that the regions showing reduced activity in the practiced condition of a Sternberg paradigm are predominantly related to encoding and maintenance of the target-set [ ].  \n\nPreviously proposed mechanisms of practice either suggest that practice improves the involved processes themselves (\u2018process improvement mechanism\u2019, [ - ]), or that they are replaced by other, more efficient processes (\u2018process switching mechanism\u2019), either deliberately, or involuntary as the new process strengthens [ ]. Two important process switching mechanisms that are capable of explaining many behavioral practice effects are \u2018Item based learning\u2019 and \u2018Category Comparison Strategy\u2019. The Item-based learning mechanism, also referred to as automatic processing, proposes that with practice we learn to associate a particular stimulus with a particular response [ , , ]. Thus, after practice, a response can be selected without using the target-set. The Category Comparison Strategy argues that with practice we learn new categories. After practice, responses can be selected by assigning a category to a probe, also without use of target information. Importantly, for the task applied in this study it has been noted previously that there is no discernible difference between the two process switching mechanisms (Logan et al, 1988). \n\nOur results appear to support process switching mechanisms, as the finding that prefrontal cortex appears to be less involved after practice, suggests a process switch. Additionally, the finding that TMS only interfered with target detection in the novel condition, suggests that the regions that the targeted prefrontal region was involved in either maintenance or comparison of targets, and that it is specifically this process that becomes obsolete after practice.  \n\nOur results do not appear to support mechanisms that are based on process improvement. According to these mechanisms, one should not expect a large difference in interference effects of TMS for novel and practiced performance, as the same brain regions should be involved in novel as well as in practices performance. Yet this is not what we found for the left prefrontal cortex.\u2019 \n\nOur findings are in line with the notion that practice can play a pivotal role in performance of complex cognitive tasks that at first sight may not appear to have a consistent environment. Complex cognitive tasks can however in many occasions be organized as a combination of many simple consistent as well as well as varied mapping sub-tasks, At first, practice may only have a direct effect on the consistent mapping sub-tasks, as performance will improve and involvement of the prefrontal cortex will reduce after practice. In turn, as there are more resources available after practice, individuals can however also show improved performance on the varied mapping sub-tasks, Thus performance on every level of the complex task may improve due to practice. This interpretation is also in line with a previous study that demonstrated that the level to which brain activity is reduced after practice is a predictor of how a subject will perform on a second unpracticed task done simultaneously [ ].  \n\nSeveral methodological considerations should be taken into account. Subjects reported that they were aware of the different effects of sham and rTMS coils. This could have affected our results. However, the fact that both non-target accuracy and reaction times were similar for sham and rTMS sessions argues against the occurrence of expectation effects. The differential effects of prefrontal and parietal rTMS further support the notion that the effects of prefrontal rTMS were indeed due to electromagnetic disruption. In the present study we selected rTMS target regions based on individual activity maps rather than group based activity maps, to ensure that we targeted individual \"hotspots\" as closely as possible. An unanticipated result in the present study is the large variability in individual parietal hotspots ranging from inferior to superior cortices. It is possible that the hotspot may not have reflected the same underlying function, and this could have affected our results for the parietal rTMS sessions.  \n\nIn conclusion, our study showed that rTMS on left prefrontal and left parietal cortex reduced accuracy specifically for novel target-sets. Only for prefrontal rTMS, the rTMS interference effect was significantly smaller for practiced target-sets. These findings indicate that practiced performance relies less on involvement of the left prefrontal cortex. The findings support the notion that in novel performance, left prefrontal cortex is predominantly involved in maintenance comparison with the target-set, and suggest that consistent practice allows individuals to select a response without referring to the target-set. Our results also support the notion that consistent practice allows for redistribution of limited maintenance resources, and can thus be crucial in performance of complex cognitive tasks. \n\n \n\n# Table(s)\n## ID: pone-0080256-t001\n### Label: Table 1\nROI\tROI.1\tdescription\tdescription.1\tabb.\tBA\tSize\tMNI coordinates\tMNI coordinates.1\tMNI coordinates.2\nnovel > practiced\tnovel > practiced\t(AAL atlas)\t(AAL atlas)\t\t\t(cm3)\tX\tY\tZ\n1\t1\tleft inferior parietal gyrus\tleft inferior parietal gyrus\tlIPG\t40.0\t16.6\t-32\t-52\t44\n2\t2\tleft precentral gyrus\tleft precentral gyrus\tlPCG\t6.0\t12.2\t-44\t0\t36\n3\t3\tright angular gyrus\tright angular gyrus\trAG\t7.0\t10.1\t36\t-56\t48\n4\t4\tright inferior frontal gyrus, triangular part\tright inferior frontal gyrus, triangular part\trIFGtri\t45.0\t5.2\t44\t32\t28\n5\t5\tleft supplementary motor area\tleft supplementary motor area\tlSMA\t6.0\t5.0\t-4\t8\t52\n6\t6\tright insula\tright insula\trINS\t47.0\t4.0\t40\t20\t0\n7\t7\tleft insula\tleft insula\tlINS\t47.0\t3.3\t-36\t20\t0\n8\t8\tright calcarine fissure\tright calcarine fissure\trCALC\t18.0\t3.1\t16\t-84\t0\n9\t9\tright middle frontal gyrus\tright middle frontal gyrus\trMFG\t8.0\t2.8\t28\t4\t56\npracticed > novel\tpracticed > novel\t\t\t\t\t\t\t\t\na\ta\tright superior frontal gyrus, medial part\tright superior frontal gyrus, medial part\trMSFG\t9.0\t19.2\t8\t48\t40\nb\tb\tleft precuneus\tleft precuneus\tlPCun\t23.0\t15.9\t-4\t-56\t24\nc\tc\tleft Angular gyrus\tleft Angular gyrus\tlAG\t39.0\t4.3\t-52\t-68\t28\n### Caption\nOverview of regions showing signal change in novel-practiced contrast.\n### Footer\nMNI coordinates in table 1 refer to the voxel with maximum level which was also used to determine the name, using the AAL atlas [39]. Names should only be considered as descriptive with no anatomical meaning, as activity is based on a group average.\n", "metadata": {"pmcid": 3869649, "text_md5": "bd3b7d5dfc3900f80b97192adf429721", "field_positions": {"authors": [0, 162], "journal": [163, 171], "publication_year": [173, 177], "title": [188, 273], "keywords": [287, 287], "abstract": [300, 2230], "body": [2239, 32614], "tables": [32627, 34161]}, "batch": 2, "pmid": 24376494, "doi": "10.1371/journal.pone.0080256", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3869649", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3869649"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3869649\">3869649</a>", "list_title": "PMC3869649  fMRI Guided rTMS Evidence for Reduced Left Prefrontal Involvement after Task Practice"}
{"text": "Lu, Liyan and Li, Fengfang and Chen, Huiyou and Wang, Peng and Zhang, Hong and Chen, Yu-Chen and Yin, Xindao\nBrain Imaging Behav, 2020\n\n# Title\n\nFunctional connectivity dysfunction of insular subdivisions in cognitive impairment after acute mild traumatic brain injury\n\n# Keywords\n\nMild traumatic brain injury\nCognitive impairment\nFunctional magnetic resonance imaging\nInsula subdivision\n\n\n# Abstract\n \n## Purpose \n  \nThis study aimed to investigate the early functional connectivity alterations between insula subdivisions and other cortical regions in patients with acute mild traumatic brain injury (mTBI) and subsequently to explore the relationship between functional connectivity changes of insula subdivisions with other cortical regions and cognitive function. \n\n\n## Methods \n  \nFifty-three mTBI patients and 37 age-, gender- and education level- matched healthy controls were included in this study. All participants obtained resting state functional magnetic resonance imaging (rs-fMRI) and clinical and neuropsychological evaluations (Montreal cognitive assessment, MoCA) at the acute stage. Functional connectivity alterations of insula subdivisions and correlations with MoCA were further explored by seed-voxel functional connectivity. \n\n\n## Results \n  \nCompared with healthy controls, patients with acute mTBI showed significantly decreased functional connectivity between the L-vAI and the left middle temporal gyrus and right superior frontal gyrus and significantly decreased functional connectivity between the R-vAI and the right middle frontal gyrus and right hippocampus. While significantly decreased functional connectivity were observed between the L-dAI and the right superior frontal gyrus. In addition, significantly increased functional connectivity was observed between the R-PI and the left inferior frontal gyrus. Furthermore, the mTBI group demonstrated positive correlations between performances in orientation and insula and middle temporal gyrus and superior frontal gyrus and middle frontal gyrus functional connectivities. Abstraction scores for mTBI patients positively correlated with functional connectivity between insula and middle frontal gyrus. \n\n\n## Conclusions \n  \nThe present study demonstrated functional connectivity dysfunction of insula subdivisions and correlations between these alterations and cognitive performance, which provide a novel insight into the neurophysiological mechanism of cognitive impairment in patients with mTBI at the acute stage. \n\n \n\n# Body\n \n## Introduction \n  \nMild traumatic brain injury (mTBI) accounts for at least 75% of traumatic brain injury (Gardner and Yaffe  ). Moreover, a proportion of mTBI patients frequently develop cognitive deficitis following acute mTBI and may persist for months and even years after the initial injury, thus imposes an excessive societal burden (Stenberg et al.  ). However, the underlying pathophysiology of cognitive disorders remains controversial, partly because the cognitive symptoms are not specific because these patients often perform normal neuropsychological test and lack of structural brain damage on conventional anatomical brain computer tomography (CT) and magnetic resonance imaging (MRI)(Scheibel  ). Therefore, research on pathophysiological mechanisms of cognitive impairment may help to provide strategy for the early diagnosis and treatment of cognitive deficit following acute mTBI. \n\nInsular cortex, traditionally is considered to be responsible for integrating internal and external processes (Tops and Boksem  ; Uddin et al.  ). However, growing findings showed that the insula plays a crucial role in response for salience events and mediates the control of cognition (Uddin et al.  ). Our previous work observed that the gray matter volume was significantly reduced in the insula in acute mTBI patients and the functional connectivity of insula with other brain regions was impaired in mTBI patients during the acute stage (Li et al.  ; Lu et al.  ). Following mTBI, previous neuroimaging studies have shown structural and functional connectivity abnormalities in the insula, such as smaller volume, decreased regional homogeneity (ReHo) and cerebral blood flow (CBF), and these alterations were related to cognitive scores. Meanwhile, a large body of literature indicated that insula, as a key node of SN salience network (SN) for initiating network switching, could mediate other important intrinsic connectivity networks (ICNs) such as the default mode network (DMN) and central executive network (CEN) (Seeley et al.  ). For mTBI patients, abnormal insular connectivity within the SN and dysfunctional interactions with DMN and CEN, and aberrant functional connectivity correlated with neurocognitive functioning were shown by several studies (Sours et al.  ; Vakhtin et al.  ; Chand et al.  ). \n\nFurthermore, parcellation studies using resting state fMRI (rs-fMRI) data revealed that the human insula can be subdivided into the anterior insula (a.i.) and the posterior insula (PI) which are involved in a wide range of cognitive processes, especially in restoring the cognitive functions (Iaria et al.  ; Taylor et al.  ; Lu et al.  ). Recent evidence consistently highlighted that a.i. is in response for cognitive function (Taylor et al.  ; Chand et al.  ; Peng et al.  ; Lu et al.  ). Additionally, we have previously shown decreased grey matter volumes of a.i. and disrupted functional connectivity of a.i. with other brain regions in mTBI patients during the acute stage (Li et al.  ; Lu et al.  ). All these results indicated the vital role of a.i. in the mechanisms of cognitive impairment. Mover, a.i. primarily comprises of the ventral anterior insula (vAI) and dorsal anterior insula (dAI), both of them are associated with arousal/interoceptive awareness, cognitive emotional processing, the dorsal anterior portion is specifically more involved in high level cognitive processes (Peng et al.  ). Meanwhile, the posterior insular (PI) is a cortical region related to processing of multimodal information such as interoceptive/exteroceptive information and sensory information (Peng et al.  ). Thus, it is necessary to explore the functional connectivity between the insula subdivisions and other brain regions to explain the cognitive symptoms of mTBI. However, to the best of our knowledge, whether there exist changes of functional connectivity between insula subdivisions and other cortical regions and whether the altered functional connectivity contributed to the pathophysiology of cognitive impairment have not been studied in acute mTBI patients. It is still mixed and not clear whether or how insula subdivisions alterations in patients with cognitive impairment following acute mTBI. To address these issues, we selected the bilateral insula as seed for analysis. \n\nTherefore, the purpose of this study was to examine the abnormalities of functional connectivity between insula subdivisions and other cortical regions at the acute stage and subsequently to explore the association between functional connectivity changes of insula subdivisions and the cognitive test in these patients compared to healthy controls. We hypothesized that (1) patients following acute mTBI have disrupted functional connectivity between insula subdivisions and other cortical regions (2) these alterations would be associated with changes in neuropsychological assessment of cognitive functioning. \n\n\n## Materials and methods \n  \n### Participants \n  \nThis study was approved by the Institutional Review Board of Nanjing Medical University. All participants provided written informed consent before undergoing MR imaging. Between December 2017 and May 2019, patients with a diagnosis of mTBI within 2 weeks after trauma were prospectively enrolled in this study. mTBI was defined based on the American Congress of Rehabitation Medicine. Inclusion criteria were as follows: (a) patients aged 18 or older; (b) loss of consciousness <\u200930\u2009min, Glasgow Coma Score (GCS) of 13\u201315 and post-traumatic amnesia \u2009<\u200924\u2009h. Exclusion criteria were: (a) previous head injury; (b) history of pre-existing neurological or psychiatric disease; (c) history of illicit drug use or substance abuse; (d) dental appliances that might distort the functional MR images; (e) left-handed. The healthy control participants were recruited through local advertisements who met the same exclusion criteria applied to the patient group. \n\n\n### Cognitive assessment \n  \nGiven the emergency care setting, it was not feasible to perform a full battery of neuropsychological assessment. Therefore, a short instrument called the Montreal Cognitive Assessment (MoCA) was used to assess the patients\u2019 neurocognitive status (de Guise et al.  ). The MoCA is a sensitive cognitive screening test following mTBI and it only requires limited training to administer. The MoCA assesses eight cognitive domains including visuospatial/executive, naming, attention, language, abstraction, memory, and orientation. This test is administered in about 10 min and is scored on a maximum of 30 points. More than 26 was regarded as normal value with a lower score indicating greater cognitive deficit (Wang et al.  ). All participants completed the MoCA test within 12 h of MRI examination. \n\n\n### Imaging methods \n  \nA 3.0 T magnetic resonance imaging scanner (Ingenia, Philips Medical Systems, Netherlands) with an 8-channel head coil was used for this study and the parallel imaging was employed. Functional images were obtained axially using a gradient echo-planar imaging sequence as follows: repetition time (TR)\u2009=\u20092000 ms; echo time (TE)\u2009=\u200930 ms; slices\u2009=\u200936; thickness\u2009=\u20094 mm; gap\u2009=\u20090 mm; field of view (FOV)\u2009=\u2009240 mm\u2009\u00d7\u2009240 mm; acquisition matrix\u2009=\u200964\u2009\u00d7\u200964; and flip angle (FA)\u2009=\u200990\u00b0. The fMRI sequence took 8 min and 8 s. Three-dimensional turbo fast-echo (3D-TFE) T1WI sequence with high resolution: TR\u2009=\u20098.1 mm; TE\u2009=\u20093.7 ms; slices\u2009=\u2009170; thickness\u2009=\u20091 mm; gap\u2009=\u20090 mm; FA\u2009=\u20098\u00b0; acquisition matrix\u2009=\u2009256\u2009\u00d7\u2009256; FOV\u2009=\u2009256 mm\u2009\u00d7\u2009256 mm; Fluid-attenuated inversion recovery(FLAIR):TR\u2009=\u20097000 ms; TE\u2009=\u2009120 ms; slices\u2009=\u200918; slice thickness\u2009=\u20096 mm; gap\u2009=\u20091.3 mm; FA\u2009=\u2009110\u00b0; Voxel size\u2009=\u20090.65\u2009\u00d7\u20090.95\u2009\u00d7\u20096 mm . SWI: TR\u2009=\u200922 mm; TE\u2009=\u200934 ms; FA\u2009=\u200920; matrix\u2009=\u2009276\u2009\u00d7\u2009319; slice thickness\u2009=\u20091 mm; FOV\u2009=\u2009220 mm\u2009\u00d7\u2009220 mm. SWI used 3D gradient echo (GRE) sequence. Diffusional tensor imaging (DTI): TR\u2009=\u20093000 mm; TE\u2009=\u2009100; slice thickness\u2009=\u20092.5 mm; gap\u2009=\u20090; b-values\u2009=\u20090 and 1000s/mm ; diffusion gradient directions\u2009=\u200932; matrix\u2009=\u2009128\u2009\u00d7\u2009128; FOV\u2009=\u2009256 mm\u2009\u00d7\u2009256 mm. \n\n\n### Image processing \n  \nData Processing & Analysis for Resting-State Brain Imaging (DPABI_V2.3_170105) with the following stages was applied for data analysis (Yan et al.  ). The first 10 volumes were discarded and the remaining 230 consecutive volumes were used for data analysis. Afterwards, slice-timing adjustment and realignment for head motion correction were performed. mTBI and healthy control participant who had a head motion greater than 3.0 mm or a rotation in the x, y, or z directions higher than 3.0\u25e6 were excluded. Data were spatial normalized to the Montreal Neurological Institute (MNI) template (resampling voxel size\u2009=\u20093\u2009\u00d7\u20093\u2009\u00d7\u20093 mm ) and smoothed with a Gaussian kernel of 6 mm full width at half maximum (FWHM) to increase signal-to-noise ratio. \n\nFunctional connectivity was analyzed using the REST software. To examine functional connectivity for sub-regions of insula, six spherical 6 mm radius seeds were defined centered on the coordinates for each ROI in Montreal Neurological Institute (MNI 152) space which was showed on Fig.  , including: left ventral anterior insula (L-vAI, red, MNI\u2009=\u2009\u2212\u200933, 13, \u2212\u20097), right ventral anterior insula (R-vAI, orange, MNI\u2009=\u200932, 10, \u2212\u20096), left dorsal anterior insula (L-dAI, green, MNI\u2009=\u2009\u2212\u200938, 6, 2), right dorsal anterior insula (R-dAI, purple, MNI\u2009=\u200935, 7, 3), left posterior insula (L-PI, blue, MNI\u2009=\u2009\u2212\u200938, \u2212\u20096, 5) and right posterior insula (R-PI, pink, MNI\u2009=\u200935, \u2212\u200911, 6)(Peng et al.  ). These coordinates of insular sub-regions seeds were reported previously(Deen et al.  ). The mean time series of each ROI was acquired for reference time course. Then, Pearson\u2019s correlation coefficients were computed between the mean signal change of each ROI and the time series of each voxel. Functional connectivity was computed between each insular subregion seed and all vertices on the whole brain surface space for each participant. The Fisher\u2019s r-to-z transformed correlation map was then averaged within each group for each seed region to generate the mean functional connectivity distribution (Peng et al.  ). \n\n  \nThe sub-regions of insula were shown, including: left ventral anterior insula (L-vAI, red), right ventral anterior insula (R-vAI, orange), left dorsal anterior insula (L-dAI, green), right dorsal anterior insula (R-dAI, purple), left posterior insula (L-PI, blue) and right posterior insula (R-PI, pink) \n  \n\n\n### Statistical analysis \n  \nTo investigate the abnormal functional connectivity between the patients with acute mild traumatic brain injury and healthy controls, two-sample t-test for each seed region was estimated. Then, surface-based cluster-wise correction for multiple comparisons was performed at the significance threshold of p\u2009<\u20090.001 and the cluster size threshold of 13 mm , which was determined by Monte Carlo. For a follow-up analysis, we investigated the relationship between fMRI data and MoCA scores in acute mTBI patients. Pearson\u2019s correlation analyses were performed in a voxel-wise manner using REST software. The statistical threshold was set at corrected p\u2009<\u20090.001 using the same parameters as the group comparison analysis. \n\nDifferences in demographic data between mTBI patients and healthy controls were analyzed using between-group t-test for means and two-test for proportions. P\u2009<\u20090.05 was considered to be statistically significant, corrected for age, sex and years of education. Bonferroni correction was used for multiple comparisons in the correlation analyses. \n\n\n\n## Results \n  \nDuring the study period, 78 patients with the diagnosis of mTBI after head injury (range, 0\u201310 days, average, 2.95 days) were recruited. Among these patients, 25 participants were excluded due to pre-existing neurological or psychiatric disease (n\u2009=\u200905), previous head injury (n\u2009=\u200902), dental appliance (n\u2009=\u200905), image artifact (n\u2009=\u200904), or excess head movement (n\u2009=\u200909). The remaining 53 patients were finally analyzed. 37 age, gender and education level matched healthy control participants were also recruited in this study. No significant difference existed in age (P\u2009=\u20090.149), gender (P\u2009=\u20090.138), education level (P\u2009=\u20090.098) and GCS score for both groups. Table   is a summary of the basic demographic characteristics of mTBI group and healthy control group. No visible traumatic brain lesions were seen on conventional imaging such as T2 or susceptibility weighted imaging (SWI). \n\n  \nDemographic characteristics and cognitive performance in patients with mTBI and healthy controls \n  \nData are the mean\u2009\u00b1\u2009standard deviation;   p  \u2009<\u20090.05. mTBI, mild traumatic brain injury; GCS, Glasgow Coma Scale; MoCA, Montreal Cognitive Assessment \n  \n\nFigure   revealed the functional connectivity maps of four insula seed ROIs (L-vAI, R-vAI, L-dAI, L-PI) in both mTBI patients and healthy controls. The insula subdivisions mainly exhibited positive functional connectivity with the middle temporal gyrus, frontal, parietal and cingulate cortex. \n\n  \nThe functional connectivity maps of four insula seed ROIs (L-vAI, R-vAI, L-dAI, L-PI) were revealed in both mTBI patients and healthy controls \n  \n\nCompared with healthy controls, patients with mTBI demonstrated significantly decreased functional connectivity between the L-vAI and the left middle temporal gyrus and right superior frontal gyrus and significantly decreased functional connectivity between the R-vAI and the right middle frontal gyrus and right hippocampus. While significantly decreased functional connectivity were observed between the L-dAI and the right superior frontal gyrus. Additionally, patients with mTBI demonstrated significantly decreased functional connectivity was observed between the L-PI and the left inferior frontal gyrus (Fig.  ; Table  ). \n\n  \nSignificantly decreased functional connectivity of four insula seed ROIs (L-vAI, R-vAI, L-dAI, L-PI) in mTBI patients compared with healthy controls \n  \n\n  \nBrain regions showing significant differences between mTBI and healthy controls \n  \nA corrected threshold of   p  \u2009> determined by Monte Carlo simulation was taken as measuring that there was significant difference between groups. BA, Brodmann area; MNI, Montreal Neurological Institute; L, Left; R, Right \n  \n\nAs demonstrated in Fig.  , the mTBI group demonstrated positive correlations between performances in orientation and insula functional connectivity with middle temporal gyrus and superior and middle frontal gyrus. Abstraction scores for mTBI patients positively correlated with functional connectivity between insula and middle frontal gyrus. The brain regions associated with MoCA sub-scores were described in Table  . \n\n  \nVoxel-wise correlations showed that the mTBI group demonstrated positive correlations between orientation performances and insular functional connectivity with middle temporal gyrus and superior and middle frontal gyrus. Abstraction scores in mTBI patients positively correlated with functional connectivity between the insula and middle frontal gyrus \n  \n\n  \nBrain regions associated with MoCA subscores in mTBI patients \n  \nA corrected threshold of   p  \u2009> determined by Monte Carlo simulation was taken as measuring that there was significant difference between groups. BA, Brodmann area; MNI, Montreal Neurological Institute; L, Left; R, Right \n  \n\n\n## Discussion \n  \nWe have previously observed that the functional connectivity of a.i. with other brain regions is impaired in mTBI patients during the acute stage (Li et al.  ; Lu et al.  ). However, the connectivity patterns of insula subdivisions to other brain regions within mTBI patients as compared to healthy controls have not been further studied. In this study, we not only found that insular sub-regions were abnormally connected with regions of the superior frontal gyrus, middle frontal gyrus, middle temporal gyrus and hippocampus but also found correlation between MoCA sub-scores and functional connectivity of insular subdivisions. These findings may shed new light to understand the pathophysiology of cognitive impairment following acute mTBI. Clinically, these features which show more accurate and comprehensive information may serve as objective biomarkers to achieve clinically-relevant capabilities for the diagnosis and treatment of mTBI, finally to improve the prognosis of mTBI. \n\n\n## Insula-Hippocampal connectivity \n  \nIn our study, the patients with mTBI presented decreased functional connectivity between the right vAI and right hippocampus. We also find in the literature examples where TBI patients exhibit smaller hippocampal volumes when compared to controls (Monti et al.  ; Zhang et al.  ; Sampedro et al.  ). These results can be explained by the fact that hippocampus is believed disproportionately affected by mTBI because it is located in the medial temporal lobe of brain, which makes it more vulnerable to impact forces (Monti et al.  ). Further, it is also particularly susceptible to excitotoxic injury, which often occurs in TBI. In addition to moderate and severe TBI, mTBI also could induce diffused hippocampal neuronal damages and apoptosis (Monti et al.  ; Spielberg et al.  ). And hippocampal neurodegeration in patients with mTBI linked to cognitive function decline is reported by previous studies (Monti et al.  ; Zuo et al.  ). However, the present analysis did not show any functional connectivity between the insula and hippocampus was significantly correlated with the MoCA score. Such inconsistency can be only partially explained by differences in the parameters used for image acquisition, the procedures used for data processing and analysis, and small sample sizes. \n\n\n## Insula-Frontal connectivity \n  \nCompared to healthy controls, the current findings showed decreased functional connectivity between the insula and frontal gyrus in patients with mTBI, which is consistent with the fact that insula functionally connected with adjacent frontal regions. In many previous research, reduced neural activity in the inferior frontal gyrus, middle and superior frontal gyrus were found in mTBI (Iaria et al.  ; Wang et al.  ). One previous fMRI meta-analysis demonstrated a reason of a frontal vulnerability to mTBI, compared to controls (Eierud et al.  ). The frontal lobes, which participate in frontal-subcortical circuits, play a critical role in cognitive function (Iaria et al.  ). Meanwhile, our study demonstrated the functional connectivity between the insula and frontal gyrus had a significantly positive correlation with MoCA sub-scores including the orientation and abstraction scores. That is, the lower the functional connectivity, the lower the MoCA score. The mTBI possibly have damage on the frontal-subcortical circuits or white matter tracts, thereby inducing cognitive impairment. Compared with other domains of MoCA, orientation and abstraction are the cognitive processes found often to be affected after injury. Furthermore, abstract thinking was the most affected and showed minimal improvement at the time of discharge, but orientation showed maximum improvement. In fact, the parietal gyrus mainly controls the orientation function, and the frontal gyrus functionally and structurally connects with the parietal gyrus. Therefore, frontal gyrus affects the orientation and abstraction scores may via the relationship with the parietal gyrus. More related studies must be performed in the future. \n\n\n## Insula-Temporal connectivity \n  \nIn our data, the insula was found to be negatively connected with temporal gyrus, which matches the fact of a strong projection between the insula and temporal gyrus. Previous literature reported volume loss of gray matter in the temporal gyrus in mTBI (Babcock et al.  ; Wang et al.  ). Unsurprisingly, we observed decreased functional connectivity between the insula and temporal gyrus in patients with mTBI, compared with control group. As noted above, the frontal gyrus and the temporal gyrus play an important role in a variety of cognitive functions. These brain areas are also known to be the site of the pathophysiological foundations of cognitive impairment caused by the early stages of the disease. Moreover, previous literature found notable accumulations of amyloid in the temporal gyrus in patients who sufferer with significant cognitive dysfunction which suggests partial reason why temporal gyrus is related to cognitive performance (Mohamed et al.  ). In addition, our study showed positive correlations between functional connectivity of insula and temporal gyrus and orientation score. In fact, orientation function is mainly charged by the parietal gyrus, the relationship between the insula or the temporal gyrus and orientation function is unclear. We presumed that the orientation function was affected by the insula or the temporal gyrus via the parietal gyrus because the posterior superior part of temporal gyrus is connected with parietal gyrus. However, the relationship between the temporal gyrus and parietal gyrus in acute mTBI patients must be further investigated. \n\n\n## Limitations \n  \nThere existed a number of limitations in our study. First, this study is limited to homogeneity in research populations of mTBI patients with different injury mechanisms and various brain injury sites. Second, GCS score was used to identify the severity of head injury. However, duration of loss of consciousness as an injury index is not considerable for most mTBI patients. Finally, this study only investigated functional connectivity dysfunction of insula subdivisions with other cortical regions at the acute stage, sub-acute and chronic data are necessary to improve to understand the development of damage and recovery. It may be important in future work. \n\n\n## Conclusions \n  \nTaken together, our current and past work suggest that patients with acute mTBI suffer from functional connectivity dysfunction of insula subdivisions with other cortical regions including the hippocampus, frontal gyrus and temporal gyrus in comparison with healthy controls. Additionally, these patients showed significantly positive correlations between function connectivity of insula with above regions and cognitive performance. \n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table 1\nCharacteristics\tmTBI(n\u2009=\u200953)\tControl(n\u2009=\u200937)\tP Value\nAge (y)\t37.96\u2009\u00b1\u200910.708\t41.41\u2009\u00b1\u200911.243\t0.149\nGender(male/female)\t27/26\t13/24\t0.138\nEducation (y)\t12.81\u2009\u00b1\u20093.058\t13.59\u2009\u00b1\u20093.122\t0.098\nGCS Score\t15\t15\t\nTime since injury(d)\t2.95\u2009\u00b1\u20091.611\t--\t\nMoCA Score\t25.15\u2009\u00b1\u20092.214\t26.03\u2009\u00b1\u20092.154\t0.064\nVisuospatial/executive\t3.89\u2009\u00b1\u20090.847\t4.11\u2009\u00b1\u20091.048\t0.291\nNaming\t2.94\u2009\u00b1\u20090.233\t2.81\u2009\u00b1\u20090.397\t0.060\nAttention\t5.62\u2009\u00b1\u20090.627\t5.76\u2009\u00b1\u20090.495\t0.281\nLanguage\t2.38\u2009\u00b1\u20090.657\t2.49\u2009\u00b1\u20090.559\t0.413\nAbstraction\t1.77\u2009\u00b1\u20090.423\t1.95\u2009\u00b1\u20090.229\t0.026*\nMemory\t2.64\u2009\u00b1\u20091.317\t2.81\u2009\u00b1\u20091.543\t0.578\nOrientation\t5.83\u2009\u00b1\u20090.379\t5.92\u2009\u00b1\u20090.277\t0.228\n### Caption\nDemographic characteristics and cognitive performance in patients with mTBI and healthy controls\n### Footer\nData are the mean\u2009\u00b1\u2009standard deviation; *p\u2009<\u20090.05. mTBI, mild traumatic brain injury; GCS, Glasgow Coma Scale; MoCA, Montreal Cognitive Assessment\n\n\n## ID: Tab2\n### Label: Table 2\nBrain region\tBA\tPeak MNI coordinates x,y,z(mm)\tt value\tVoxels\nL-vAI\t\t\t\t\nL middle temporal gyrus\t21.0\t-57,-33,-3\t-4.4124\t24.0\nR superior frontal gyrus\t9.0\t18,51,27\t-3.9607\t13.0\nR-vAI\t\t\t\t\nR middle frontal gyrus\t46.0\t45,27,42\t-4.0827\t28.0\nR hippocampus\t35.0\t30,-18,-9\t-4.108\t25.0\nL-dAI\t\t\t\t\nR superior frontal gyrus\t10.0\t21,51,33\t-5.2372\t113.0\nL-PI\t\t\t\t\nL middle frontal gyrus\t46.0\t-33,-9,48\t-4.2604\t13.0\n### Caption\nBrain regions showing significant differences between mTBI and healthy controls\n### Footer\nA corrected threshold of p\u2009> determined by Monte Carlo simulation was taken as measuring that there was significant difference between groups. BA, Brodmann area; MNI, Montreal Neurological Institute; L, Left; R, Right\n\n\n## ID: Tab3\n### Label: Table 3\nBrain region\tBA\tPeak MNI coordinates x,y,z(mm)\tPeak R value\tVoxels\nL-dAI and MoCA-Orientation\t\t\t\t\nL superior frontal gyrus\t10.0\t-27,36,36\t0.50869\t28.0\nL-PI and MoCA-Orientation\t\t\t\t\nL middle temporal gyrus\t21.0\t-54,-15,-6\t0.50849\t15.0\nL middle frontal gyrus\t46.0\t-30,36,33\t0.52059\t34.0\nR-PI and MoCA-Abstraction\t\t\t\t\nL middle frontal gyrus\t46.0\t-27,27,45\t0.54749\t23.0\n### Caption\nBrain regions associated with MoCA subscores in mTBI patients\n### Footer\nA corrected threshold of p\u2009> determined by Monte Carlo simulation was taken as measuring that there was significant difference between groups. BA, Brodmann area; MNI, Montreal Neurological Institute; L, Left; R, Right\n", "metadata": {"pmcid": 7275020, "text_md5": "cc259e3c945128ffc37a6940337aa23d", "field_positions": {"authors": [0, 108], "journal": [109, 128], "publication_year": [130, 134], "title": [145, 268], "keywords": [282, 388], "abstract": [401, 2509], "body": [2518, 24694], "tables": [24707, 27048]}, "batch": 2, "pmid": 32304021, "doi": "10.1007/s11682-020-00288-5", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7275020", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7275020"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7275020\">7275020</a>", "list_title": "PMC7275020  Functional connectivity dysfunction of insular subdivisions in cognitive impairment after acute mild traumatic brain injury"}
{"text": "Togo, Hiroki and Rokicki, Jaroslav and Yoshinaga, Kenji and Hisatsune, Tatsuhiro and Matsuda, Hiroshi and Haga, Nobuhiko and Hanakawa, Takashi\nFront Neurosci, 2017\n\n# Title\n\nEffects of Field-Map Distortion Correction on Resting State Functional Connectivity MRI\n\n# Keywords\n\nresting state fMRI\nfield map\ndistortion correction\nfunctional connectivity\nspectrogram\n\n\n# Abstract\n \nMagnetic field inhomogeneities cause geometric distortions of echo planar images used for functional magnetic resonance imaging (fMRI). To reduce this problem, distortion correction (DC) with field map is widely used for both task and resting-state fMRI (rs-fMRI). Although DC with field map has been reported to improve the quality of task fMRI, little is known about its effects on rs-fMRI. Here, we tested the influence of field-map DC on rs-fMRI results using two rs-fMRI datasets derived from 40 healthy subjects: one with DC (DC+) and the other without correction (DC\u2212). Independent component analysis followed by the dual regression approach was used for evaluation of resting-state functional connectivity networks (RSN). We also obtained the ratio of low-frequency to high-frequency signal power (0.01\u20130.1 Hz and above 0.1 Hz, respectively; LFHF ratio) to assess the quality of rs-fMRI signals. For comparison of RSN between DC+ and DC\u2212 datasets, the default mode network showed more robust functional connectivity in the DC+ dataset than the DC\u2212 dataset. Basal ganglia RSN showed some decreases in functional connectivity primarily in white matter, indicating imperfect registration/normalization without DC. Supplementary seed-based and simulation analyses supported the utility of DC. Furthermore, we found a higher LFHF ratio after field map correction in the anterior cingulate cortex, posterior cingulate cortex, ventral striatum, and cerebellum. In conclusion, field map DC improved detection of functional connectivity derived from low-frequency rs-fMRI signals. We encourage researchers to include a DC step in the preprocessing pipeline of rs-fMRI analysis. \n \n\n# Body\n \n## Introduction \n  \nMagnetic resonance images (MRIs) are inherently subject to geometric distortions caused by magnetic field inhomogeneity, and excessive magnetic field inhomogeneity can even result in signal loss (Ojemann et al.,  ). A main source of magnetic inhomogeneity is variability of various tissues' magnetic susceptibility, and geometric distortions are especially pronounced at tissue borders/edges. Susceptibility to magnetic field inhomogeneity depends substantially on MRI sequence, shimming levels, and environmental and experimental factors. Single-shot echo planar imaging (EPI) is one of the most vulnerable MRI sequences to distortion, although it is the fastest common MRI acquisition technique (Mansfield,  ) and is now used extensively for functional MRI (fMRI). EPI's vulnerability comes from the way in which it fills in the k-space (i.e., the grid of raw data that yields the MRI after Fourier transformation). In single-shot, gradient-echo EPI, a slice's k-space is filled at once after a single excitation following a radiofrequency (RF) pulse; then, rapid gradient switching is used to acquire gradient-echo signals during a free induction decay (FID) period. On the one hand, because this signal is sensitive to magnetic inhomogeneity (i.e., T2 -weighted), EPI is useful for fMRI detection of blood oxygenation level-dependent (BOLD) signals coupled with neural/synaptic activity changes in the brain. On the other, phase encoding errors due to magnetic inhomogeneity accumulate during the FID period, resulting in mislocalization of signal sources. Hence, EPI data distortion is pronounced in the phase encoding direction (Jezzard and Balaban,  ). This characteristic contrasts with other MRI sequences for which phase encoding errors can be compensated (e.g., with a 180\u00b0 RF pulse) after each RF pulse used to fill the k-space. \n\nA few methods have been proposed to correct for distortion in EPI. One is to acquire EPI in two different encoding directions (Andersson et al.,  ). A more conventional method uses a field map (Jezzard and Balaban,  ; Jezzard and Clare,  ; Cusack et al.,  ), which is an image that represents magnetic field intensity across the space. A field map can be measured for each subject's brain, and it provides knowledge about the distribution of the static magnetic field (B0) to correct for geometric distortion in MRI. Distortion correction (DC) has two advantages: it improves registration between functional and structural images, and it reduces the variability of distortion between subjects after spatial normalization to a standard space. Despite its merits, DC is not routinely performed in many types of fMRI studies, especially when the areas of interest are not particularly vulnerable to distortion. Some of the most vulnerable areas in brain MR are the frontal lobe proximal to the paranasal sinuses and temporal lobe proximal to the mastoid air cells and ear canals (Jezzard and Balaban,  ; Hutton,  ). Signal loss may also be found in these areas (Devlin et al.,  ; Deichmann et al.,  ). \n\nDC effectively improves the quality of results of task-fMRI with motor tapping and auditory tasks (Cusack et al.,  ). To our knowledge, however, no direct evidence has shown the extent to which DC is effective for resting-state fMRI (rs-fMRI), an emerging fMRI method that examines intrinsic brain activity as slow (typically 0.01\u20130.1 Hz), spontaneous BOLD signal fluctuations in at-rest fMRI time series. A pioneering study by Biswal et al. ( ) established that over a dozen resting-state networks (RSNs) can be identified as brain regions with correlated temporal patterns of BOLD signals (Fox et al.,  ; Smith et al.,  ). Because of the task-free nature of rs-fMRI, it has many advantages for clinical application over task fMRI and is a powerful tool to provide biomarkers for many neuropsychiatric disorders (Takamura and Hanakawa,  ). \n\nHere, we hypothesized that DC would increase the useful signal-to-noise ratio for rs-fMRI at the group level, thereby increasing rs-fMRI's detection efficiency for RSNs near the edges of different tissues. To test this hypothesis, we analyzed rs-fMRI datasets with and without DC (DC+ and DC\u2212, respectively) and characterized the areas and the extent to which DC improves rs-fMRI quality. Specifically, we performed independent component analysis followed by dual regression (Filippini et al.,  ) to compare functional connectivity in a set of RSNs of interest between the DC+ and DC\u2212 datasets. We also analyzed the quality of rs-fMRI signals using the ratio of low-frequency (0.01\u20130.1 Hz) to high-frequency (above 0.1 Hz) BOLD signal power, including rs-fMRI signals in which noise components predominated. \n\n\n## Material and methods \n  \n### Participants \n  \nA total of 40 healthy older adult participants (age 68.4 \u00b1 5.8 years, 24 male/16 female) were recruited. Each participant gave written informed consent to participate in the study in accordance with the Declaration of Helsinki. The study was approved by the Ethics Committee of the National Center of Neurology and Psychiatry. The exclusion criteria were as follows:\n   \nPreexisting neuropsychiatric disorders or head injuries. \n  \nContraindications to MRI. \n  \nMini-mental state examination score below 24 (Folstein et al.,  ). \n  \nLocal brain lesions (e.g., brain tumor or cerebral infarction) incidentally identified on MRI. \n  \n\n\n### Data acquisition \n  \nThe rs-fMRI experiments were performed on a 3-T scanner (Siemens, MAGNETOM Verio) at the Integrative Brain Imaging Center, National Center of Neurology and Psychiatry (Tokyo, Japan). All data were acquired using a 32-channel phased array head coil. In the scanner, foam cushions and earplugs were used to limit head motion and reduce scanner noise, respectively. Rs-fMRI scans were acquired using a gradient-echo EPI sequence with repetition time (TR) 2,500 ms, echo time (TE) 30 ms, flip angle 80\u00b0, 49 axial slices, slice thickness 3.2 mm (0.8-mm gaps), and a 64 \u00d7 64 acquisition matrix, resulting in a 3.3 \u00d7 3.3 \u00d7 4.0-mm  voxel size. EPI encoding proceeded in the posterior\u2013anterior direction. All subjects underwent a 10-min rs-fMRI scan (240 volumes). They were instructed to remain awake and not to think of anything particular with their eyes open and fixating on a cross hair. \n\nField map imaging was performed with a double-echo spoiled gradient echo sequence (gre_field_map; TR = 488.0 ms, TE = 4.92/7.38 ms, voxel size: 3.3 \u00d7 3.3 \u00d7 3.2 (0.8-mm gaps), flip angle 60\u00b0) that generated a magnitude image and 2 phase images. The field map image was computed from the 2 phase images. For registration, a whole-brain high-resolution T1-weighted anatomical scan was acquired using a magnetization prepared rapid gradient echo (MP-RAGE) sequence with the following parameters: TR = 1900 ms, TE = 2.52 ms, inversion time (TI) = 900 ms, flip angle = 9 \u00b0, field of view = 250 \u00d7 250 mm, acquisition matrix = 246 \u00d7 256, slice thickness = 1.0 mm without gap, axial slice number = 192, voxel dimension = 1.00 \u00d7 0.98 \u00d7 0.98, reconstructed as 1.00 \u00d7 1.02 \u00d7 0.98. \n\n\n### Data preprocessing \n  \nFor structural data preprocessing, we removed non-brain tissues and cerebrospinal fluid (CSF) using the Statistical Parametric Mapping software package version 12. \n\nFigure   shows an overview of the workflow. Rs-fMRI data preprocessing was carried out using FEAT (FMRI Expert Analysis Tool) Version 6.00, which is part of FSL (FMRIB's Software Library,  ). Initial preprocessing steps included deleting the first 3 volumes of each fMRI series to allow the magnetic field to reach a steady state, followed by motion correction, spatial smoothing using a 6-mm full-width-at-half-maximum Gaussian kernel, and high-pass temporal filtering with a cutoff frequency of 0.01 Hz. The functional images were coregistered to the high-resolution T1-weighted images using boundary-based registration (Greve and Fischl,  ). \n  \nWorkflow overview. \n  \nTo assess head motion and noise artifacts, two steps approach was taken. First, we performed a data quality check (especially in terms of head motion) separately for translation and rotation parameters using the following formula: \n\nwhere   M   is the total number of time points, and   x  ,   y  , and   z   are translations or rotations in the three axes at time point   i  , calculated with FEAT in preprocessing step. One subject was excluded from further analysis because of excessive head motion (i.e., translation > 0.3 mm or rotation > 0.3\u00b0) (Liu et al.,  ). \n\nNext, single-session independent component analysis (ICA) was performed using Multivariate Exploratory Linear Optimized Decomposition into Independ Components (MELODIC) to decompose the single-subject 4D datasets into sets of spatial and temporal components. Subsequently, to remove noise components from the 4D fMRI data, autoclassification of artifactual ICA spatial components was performed using the FMRIB's ICA-based Xnoiseifier (FIX) (Salimi-Khorshidi et al.,  ). FIX was trained according to the rs-fMRI data from 44 healthy subjects randomly selected from a database (including the participants of the present study) whose images were acquired on the same scanner. Signal vs. noise ICA components were identified by JR and HT using the procedures described by Kelly (Kelly et al.,  ). The identified noise components were regressed out of the data. \n\nThe field map correction was applied to the noise-cleaned rs-fMRI data with FMRIB's Utility for Geometrically Unwarping EPIs (FUGUE), part of FSL package. Before the correction procedure, the magnitude images were used to create brain masks, and the phase images were calibrated to units of radians/s. FUGUE produced an unwarping shift map that represented the magnitude of each voxel's shift from the original signal source in each EPI because of magnetic inhomogeneity. The unwarping direction depended on the phase encoding direction of EPI acquisition (posterior\u2013anterior). Then, EPIs with and without DC and the unwarping shift maps were registered to structural images and the MNI (Montreal Neurological Institute) atlas using FNIRT (nonlinear registration with FMRIB's Nonlinear Image Registration Tool) and resampled to 4 \u00d7 4 \u00d7 4-mm resolution. Two datasets, one with distortion correction (DC+) and the other without correction (DC\u2212), were concatenated across all subjects into a single 4D dataset for group ICA analysis. \n\n\n### Component identification and selection \n  \nGroup-spatial ICA was conducted on the rs-fMRI data including both DC+ and DC\u2212 versions to avoid a bias toward detecting resting state fluctuations characteristic of either the DC+ or DC\u2212 version. The estimation of the component dimension was performed automatically according to dimensionality estimation, resulting in 77 spatial components. Later, the components were identified visually (JR and HT) according to the Harvard-Oxford cortical atlas and subcortical structural atlases (Frazier et al.,  ; Desikan et al.,  ; Makris et al.,  ; Goldstein et al.,  ; Figure  ). Four of those were identified as the ICA components of interest [i.e., the anterior default mode network (DMN), basal ganglia network (BGN), cerebellum network (CBLN), and temporal pole network (TPN)] because these networks are near the paranasal sinuses or the mastoid air cells and vulnerable to distortion caused by magnetic inhomogeneity. \n  \nFour independent component analysis (ICA) components of interest. The most informative slices are shown. Green indicates extracted ICA networks,   (A)   anterior default mode network,   (B)   basal ganglia network,   (C)   cerebellum network,   (D)   temporal pole network. These networks are thresholded at approximate default threshold used by MELODIC for visualization purposes. \n  \n\n### Assessment of degrees of voxel shift after distortion correction \n  \nWe evaluated the estimated degree of shift applied to the rs-fMRI voxels using the unwarping shift map derived from the field map images. We calculated the mean and standard deviation of the degree of shift (mm per voxel) in the representative cluster of each ICA of interest (Figure  ). The representative cluster was defined as the largest cluster of each ICA map approximately at the default threshold used by MELODIC. \n\n\n### Assessment of spatial distribution of functional connectivity \n  \nAll 77 of the spatial maps from the group ICA were used to generate subject-specific versions of the spatial maps and associated time series using the dual regression approach (Filippini et al.,  ). First, for each subject, each single spatial map is regressed (as a spatial regressor in a multiple variable regression) onto the subject's 4D space\u2013time dataset. This procedure yielded subject-specific time series sorted into group-level spatial maps. Next, these time series were regressed (again, as temporal regressors in a multiple variable regression) onto the same 4D dataset, resulting in subject-specific spatial maps sorted into group-level ones. For comparison between the two groups, we used a paired   t  -test implemented in Permutation Analysis of Linear Models (PALM) tool (DC+ > DC\u2212 and DC\u2212 > DC+), which provided non-parametric family wise error (FWE) correction over multiple voxels, the 2 contrasts and the ICA masks of interest (Figure  ) simultaneously (Winkler et al.,  ,  ). For statistical inference, we used a threshold   p   < 0.05 corrected for FWE using threshold-free cluster enhancement (TFCE) (Smith and Nichols,  ). This approach is considered to be fairly conservative and strong against false positives. In the dual regression analysis, we also used a height-level threshold of   p   < 0.05 family-wise error (FWE) corrected for multiple comparisons to test the effects of different thresholding methods. \n\nTo assess the difference among methods to retrieve RSN, we also performed a seed-based correlation analysis focusing on the anterior DMN. The seed region corresponding to the anterior DMN was selected according to the group ICA map. For the statistical comparison between the DC+ and DC- datasets, we used a paired   t  -test implemented in the PALM. For the statistical inference, we used a height-level threshold of   p   < 0.05 FWE-corrected for multiple comparisons across the voxels and 2 contrasts (DC+ > DC\u2212 and DC\u2212 > DC+). \n\n\n### Assessment of rs-fMRI signal quality \n  \nWe examined how DC influenced the signal quality derived from resting-state BOLD signal fluctuations by finding the signal-to-noise ratio of the rs-fMRI time series. Specifically, we analyzed the BOLD signal spectrograms in the rs-fMRI time-series using Matlab 2013a (Mathworks Inc., USA). The temporal frequency of rs-fMRI signals of neuronal origin ranges 0.01\u20130.1 Hz, while the noise components of rs-fMRI time-series tend to show high-frequency components: for example, more than 50% of signal frequency components over 0.1 Hz is a criterion for rs-fMRI noise (Kelly et al.,  ). Thus, the ratio of low-frequency to high-frequency signal power (LFHF ratio) was considered to represent rs-fMRI's ability to detect BOLD fluctuations of neuronal origin over noise. The LFHF ratio was defined as the total power of rs-fMRI signals 0.01\u20130.1 Hz divided by the total power of rs-fMRI signals at frequencies >0.1 Hz (data acquisition was performed at 0.4 Hz). The LFHF ratio maps were calculated in both the DC+ and DC\u2212 datasets voxel-by-voxel. To evaluate the effects of DC on the LFHF ratio, we compared the LFHF ratio between the DC+ and DC\u2212 datasets in two ways. First, we computed the ratios of the voxel values in the DC+LFHF map to those in the DC\u2212LFHF map for each participant, then averaged the maps over participants for qualitative analysis. Second, for statistical comparison between the two groups, we used a paired   t  -test implemented in the PALM tool that was similar to the comparison of functional connectivity. We performed non-parametric FWE correction across voxels and 2 contrasts (DC+ > DC\u2212 and DC\u2212 > DC+). For statistical inference, we used a significance threshold of   p   < 0.05 corrected for FWE using TFCE and a height-level threshold. \n\n\n### Assessment of functional connectivity by synthetic data \n  \nWith the empirical analysis above, there is no way of knowing the grand truth. To overcome this limitation, we produced 30 synthetic fMRI data sets according to each individual's real fMRI data. First, a dummy 4D rs-fMRI time-series (237 volumes) was created for each participant using the same number of copies of the mean EPI image derived of each individual's real fMRI data. Second, we created two spherical volumes-of-interest (VOIs) with a 10-mm radius centered at the MNI coordinate of   x   = 2,   y   = 42,   z   = 4 (corresponding to the anterior cingulate cortex, ACC) and at the MNI coordinate of   x   = 2,   y   = \u221246,   z   = 28 in (corresponding to the posterior cingulate cortex, PCC). Synthetic time-series was created for each data set, serving as the time series data in all voxels of both masks. In other words, the all the voxels in the ACC and PCC mask VOI had the identical signal time-series in each dummy dataset. Then, white noises were added to the time series data of each voxel to mimic the thermal noise of the real fMRI data time series. The amplitude of the white noises was adjusted so that the signal-to-noise ratio was equal to one (arbitrarily). Third, these synthetic datasets created in the MNI space were transformed into each individual's original space, and were distorted using the inverse of the matrix that had been produced from each participant's field map. Two copies of the distorted synthetic datasets were created: one underwent the DC procedure by FUGUE (DC+) and the other did not (DC\u2212). The synthetic data with and without DC were both registered to structural images and the MNI atlas using FNIRT and resampled to 4 \u00d7 4 \u00d7 4-mm resolution. To identify spatial shift of VOIs in the DC+ and DC- datasets, group ICA analysis was conducted separately for each dataset. To assess the known functional connectivity, we performed a seed-based analysis, using the 10-mm radius spherical ACC VOI. For statistical comparison between the DC+ and DC- synthetic datasets, we used a paired   t  -test implemented in the PALM. We performed non-parametric FWE correction across voxels and 2 contrasts (DC+ > DC\u2212 and DC\u2212 > DC+). For statistical inference, we used a significance threshold of   p   < 0.05 corrected for FWE using peak-based thresholding method. \n\n\n\n## Results \n  \n### Degrees of voxel shift after distortion correction \n  \nWe first evaluated the estimated degree of shift applied to the rs-fMRI voxels using the unwarping shift map derived from the field map images. Almost all voxels in a representative anterior DMN cluster were shifted anterior\u2013posterior (2.7 \u00b1 1.6 mm, mean shift \u00b1 standard deviation) (Figure  ). Conversely, the voxels in a representative CBLN cluster were uniformly shifted in the posterior\u2013anterior direction (\u22122.4 \u00b1 1.2 mm). In contrast to the homogenous shift map within the DMN and CBLN, the shift direction of the BGN and TPN voxels depended on location within each cluster (mean shift in BGN: 1.3 \u00b1 1.5 mm; mean shift in TPN: \u22121.3 \u00b1 1.8 mm). Particularly, the voxels in the anterior sector of the BGN were shifted anterior\u2013posterior. \n  \nAveraged unwarping shift map of the whole brain   (Top)   used for field map correction and the same information restricted to the representative cluster of each independent component analysis of interest   (bottom)  . Red-yellow color: voxels were shifted anterior\u2013posterior (mm per voxel); Blue-light blue: voxels were shifted posterior\u2013anterior. After successful distortion correction, voxels with positive and negative values should be shifted anterior\u2013posterior and posterior\u2013anterior, respectively. DMN, Default mode network; BGN, basal ganglia network; CBLN, cerebellum network; TPN, temporal pole network. \n  \n\n### Functional connectivity analysis \n  \nWith the dual regression approach, we compared the strength of intra- and extra-network connectivity of the four RSNs between the DC+ and DC\u2212 datasets. Analysis of the anterior DMN showed significantly more connectivity in the DC+ than the DC\u2212 dataset in both the peak-level and TFCE thresholding methods (Figure  , Table  ). Areas with increased functional connectivity with the anterior DMN after DC included the ACC, which are important nodes of the DMN, in the height-level FWE corrected threshold (corresponding to voxel-level   p   = 0.0002). The CBLN's areas of increased functional connectivity after DC were found within the CBLN itself (i.e., intra-network) with the TFCE (cluster-level   p   = 0.012), but this increased functional connectivity was not found in the peak height-level thresholding method (voxel-level   p   = 0.089). At first glance, DC in the BGN seemed to result in significantly decreased connectivity in the anterior BGN in the height-level threshold (voxel-level   p   = 0.0004) (Figure  , Table  ). However, detailed observation revealed that most voxels with decreased functional connectivity in the DC+ dataset were found in white matter, extending only slightly into the anterior border of the basal ganglia (ventral caudate nucleus and nucleus accumbens). Hence, this finding mostly resulted from mislocalization of the BGN to white matter in the DC\u2212 dataset. No difference in functional connectivity was found in the TPN. \n  \nFunctional connectivity with field map correction greater than that without correction as revealed by the dual regression analysis.   (A)   Anterior default mode network and   (B)   basal ganglia network. Colored clusters indicate significantly increased connectivity after field map correction thresholded by threshold-free cluster enhancement (TFCE) (YELLOW or BLUE) and thresholded by peak (height)-based method (RED or GREEN) (both after multiple comparison familywise error correction across voxels, components of interest, and contrast;   p   < 0.05). \n    \nList of clusters with significantly changed functional connectivity with field map correction in the peak level threshold method (compared with no correction; multiple comparison family wise error correction across voxels, components of interest, and contrast;   p   < 0.05). \n  \nWith the seed-based analysis, the region of interest in anterior DMN showed significantly greater connectivity in the DC+ than the DC\u2212 dataset (Figure  ). Areas with increased functional connectivity were similar to the ICA-based approach and included ACC and PCC. \n  \nFunctional connectivity with the DC (compared without DC) in anterior default mode network as revealed by the seed-based approach. Red-yellow indicates the clusters of significantly increased connectivity after DC (multiple comparison familywise error correction across voxels and contrast;   p   < 0.05). Green color indicates the region of interest in anterior default mode network. \n  \n\n### Low frequency\u2013high frequency ratio \n  \nTo explain the above finding, we computed the LFHF ratio map from the viewpoint of DC+ and DC\u2212 rs-fMRI information quality (Figure  ). Compared with the DC\u2212 dataset, the DC+ dataset showed a greater LFHF ratio in the ACC and cerebellum. Some brain regions showed a lower LFHF ratio in the DC+ than the DC\u2212 data, but those areas corresponded to white matter or the edge of the brain/structure. Detailed visual inspection revealed that imperfect spatial normalization of the DC\u2212 dataset caused this finding, which agreed with the mislocalization of the anterior BGN into the white matter without DC. Figure   shows a statistical comparison of the LFHF ratio between the DC+ and DC\u2212 datasets. The ACC showed significantly higher LFHF ratio in the DC+ dataset than the DC\u2212 dataset in the height-level threshold (  p   = 0.0002). Only a few voxels in white matter near the precentral gyrus showed significantly lower LFHF ratio in the DC+ dataset than the DC\u2212 dataset. \n  \n (A)   Qualitative comparison map of the ratio of low-frequency to high-frequency signal power (LFHF ratio) between the datasets with and without field map correction. Red and blue indicate greater and lesser LFHF ratio after the correction, respectively.   (B)   Statistical comparison between LFHF ratio with and without field map correction. Colored clusters indicate significantly increased connectivity after field map correction thresholded by threshold-free cluster enhancement (TFCE) (YELLOW) and thresholded by peak (height)-based method (RED) (both after multiple comparison familywise error correction across voxels and contrast;   p   < 0.05). \n  \n\n### Analysis of the synthetic data \n  \nWe evaluated the functional connectivity of the synthetic data which had the identical signal time-series in the spherical VOI in ACC and PCC. Figure   showed the spatial similarity between the masks and the ICA map derived from the DC+ and DC\u2212 datasets. The DC+ group ICA map covered all voxels in both the ACC and PCC VOIs. However, the DC\u2212 group ICA map was shifted posterior to anterior and did not cover a few voxels in ACC and PCC. The distance was extremely greater between centers of gravity of the ACC VOI and anterior part of DC- group ICA, corresponding to ACC (4.4 mm) than those of the ACC VOI and anterior part of DC+ group ICA, corresponding to ACC (0.49 mm). \n  \nSynthetic MRI analysis.   (A)   The spatial correspondence between the masks and each group independent components analysis (ICA) map with distortion correction (DC+) and without DC (DC\u2212). All clusters are binarized. Green color indicates the sphere mask image of 10-mm radius centered at the MNI coordinate of x = 2, y = 42, z = 4 (corresponding to ACC) and x = 2, y = \u221246, z = 28 (corresponding to PCC). Red indicates DC+ group ICA map and Blue indicates DC \u2212 group ICA map. Yellow indicates the region overwrapped between the masks and DC+ group ICA map, and lightblue indicates the region overwrapped between the masks and DC\u2212 group ICA map.   (B)   Group mean map in dataset with distortion correction (DC) (Red) and without DC (Blue). Green color indicates the sphere mask image of ACC and PCC volumes-of-interest (VOIs) (multiple comparison family wise error correction across voxels and contrast;   p   < 0.05).   (C)   Functional connectivity on the synthetic DC+ and DC\u2212 dataset. These clusters are masked by the ACC and PCC mask image to be focused on the voxels overwrapped between the masks and the functional connectivity. Green color indicates the region of interest in ACC. Red-yellow color indicates clusters of significantly increased connectivity after field map correction in peak-based thresholds (multiple comparison familywise error correction across voxels and contrast;   p   < 0.05). Blue-lightblue color indicates clusters of significantly decreased connectivity with field map correction in peak-based thresholds. \n  \nSeed-based analysis showed significantly greater connectivity in the posterior part of the ACC mask (  p   = 0.0002) and also a part of PCC mask (  p   = 0.0002) in the DC+ than the DC\u2212 dataset (Figures  ). The functional connectivity in DC- showed significantly greater connectivity at the anterior edge of ACC mask (  p   = 0.0002), but none in PCC mask (Figure  ). These results supported superiority of localizing functional connectivity in the DC+ dataset over the DC- dataset. \n\n\n\n## Discussion \n  \nThis study investigated the effects of DC with field map on functional connectivity analysis in rs-fMRI. We performed group ICA using the DC+ and DC\u2212 datasets, generating an unbiased set of RSNs. We then focused on several RSNs, including areas susceptible to EPI distortion (i.e., the DMN, CBLN, BGN, and TPN). DMN showed higher functional connectivity in the DC+ dataset than in the DC\u2212 dataset. Some decreases in functional connectivity were noted in the BGN, primarily in white matter, indicating imperfect registration and normalization of the DC\u2212 dataset. These results were replicated with two different thresholding methods, the peak height-level thresholding and the TFCE. Moreover, supplementary seed-based and simulation analyses supported the results of the ICA-based functional connectivity analysis. We found a higher LFHF ratio after field map correction in the ACC, PCC, ventral striatum, and cerebellum. Overall, the results supported our hypothesis that the DC procedure increases the detectability of intra- and extra-network RSN connectivity, especially in regions susceptible to magnetic inhomogeneity. In task-fMRI studies, field map correction reduces variation in activated regions during motor or auditory tasks across subjects and improves statistical power (Cusack et al.,  ). To our knowledge, the present study is the first to show that DC improves the quality of findings in rs-fMRI analysis. Particularly, we demonstrated that detection of the RSN prototype (i.e., the DMN) was strongly affected by DC. \n\nConsistent with a previous study (Jezzard and Balaban,  ), the present shift map indicated strong effects of magnetic field inhomogeneity in the ventral/medial prefrontal areas/ACC, corresponding to the anterior DMN and cerebellum. In these areas, voxels were shifted by 75\u201385% of the original voxel size. Additionally, almost all voxels in the anterior DMN and cerebellum were shifted in the same direction: anterior\u2013posterior in the anterior DMN and posterior\u2013anterior in the cerebellum. As predicted, rs-fMRI analysis revealed more robust the functional connectivity in the DMN and CBLN in the DC+ dataset than in the DC\u2212 dataset, although the increased functional connectivity in CBLN was modest. These results contrasted with the findings in the TPN and BGN, in which no or only minor differences were found in functional connectivity between the datasets, as the direction of shift was more coherent in the anterior DMN and CBLN than in the TPN and BGN (e.g., Figure  ). \n\nDC improved RSN detection in regions vulnerable to susceptibility. To determine how DC changed the quality of rs-fMRI data, we examined how it influenced the quality of BOLD signals that carry information relevant to rs-fMRI analysis. To achieve this goal, we defined the LFHF ratio across the whole brain and compared it between the DC+ and DC\u2212 datasets. We employed this approach because low-frequency BOLD signal fluctuations have been used to distinguish RSN from artifact-related \u201cpseudo-networks\u201d (Robinson et al.,  ). In essence, fMRI analyzes signals in the gray matter wherever synaptic/neuronal activity correlates with BOLD signals (Logothetis et al.,  ), depending on the levels of oxygenation and cerebral blood volume/flow (collectively called \u201chemodynamic responses\u201d). This neurovascular coupling has been established in gray matter but not white matter (Rostrup et al.,  ; Preibisch and Haase,  ). Conventional rs-fMRI studies typically target functional connectivity below 0.1 Hz (Biswal et al.,  ; Fransson,  ; Fox et al.,  ). Moreover, low-frequency (0.01\u20130.1 Hz) BOLD signals contribute more than 90% of functional connectivity across regions, whereas high-frequency signals above 0.1 Hz reflect contributions from blood vessels, cerebrospinal fluid, and other physiological noise components (Cordes et al.,  ). Other studies also support the utility of the LFHF ratio as a marker of quality in rs-fMRI data: low-frequency fluctuations in white matter are reduced relative to those in gray matter by about 60% (Biswal et al.,  ). The signal's power spectrum within the CSF space is dominated by high-frequency fluctuations (Kelly et al.,  ), and the power spectrum of the rs-fMRI time series in the suprasellar cistern is higher than that of the PCC, especially in the higher-frequency range (Zou et al.,  ). In sum, the power spectrum of rs-fMRI time series in white matter and CSF is dominated by high-frequency fluctuations (>0.1 Hz), and that in gray matter is dominated by low-frequency fluctuations (0.01\u20130.1 Hz). Thus, the LFHF ratio reasonably represents the quality of rs-fMRI data for RSN detection. We found that areas with increased RSN detectability nicely corresponded to the areas with increased LFHF ratios after DC, which likely improves detection of RSN functional connectivity, by aligning gray matter signals and reducing contamination with signals from white matter and CSF. \n\nThese findings should facilitate improvement of registration and spatial normalization after DC, affecting the localization of gray matter, white matter, CSF, and the borders between these structures across participants (Hutton,  ). For example, improvement of the anterior DMN signal could result from more precise registration of the ventromedial prefrontal cortex/ACC, anterior lateral ventricle proximal to the ACC, and the surrounding white matter, which were moved anterior\u2013posterior to match them to the structural image. The improvement of registration after DC probably enhanced the detection of resting state functional connectivity of the anterior DMN with the ACC. We hypothesized that BGN would show greater functional connectivity with than without field map correction because the anterior parts of the ventral striatum are susceptible to inhomogeneity. Unexpectedly, however, the BGN analysis seemingly revealed the opposite results. The areas with decreased connectivity with the BGN corresponded mainly to white matter, extending only slightly into the anteromost part of the ventral striatum. The BGN voxels with decreased functional connectivity tended to show lower LFHF ratio in the data with than without DC, although the difference did not reach statistical significance. This indicates incorrect assignment of BGN voxels to white matter in the standard template because of imperfect normalization of the DC\u2212 dataset. In other words, the anterior parts of the ventral striatum were mislocalized to white matter in the DC\u2212 dataset, thereby producing \u201cpseudo intra-connectivity\u201d; as these voxels were shifted posteriorly to the correct location in the DC\u2212 dataset, the pseudo-connectivity disappeared and was correctly replaced by white matter signals. \n\nA limitation of this study was that we acquired EPI rs-fMRI images in the posterior\u2013anterior phase encoding direction only. The difference in phase encoding direction affects EPI distortion, but we concentrate on assessing the rs-fMRI protocol that is now widely used in Japanese cohort studies. Another limitation was that we only tested DC with field map. A recent study reported an alternative DC method that acquires EPIs in opposite phase encoding directions, resulting in opposite spatial distortion patterns, from which the unwarping field is computed (Andersson et al.,  ; Holland et al.,  ). In future studies, we should compare the effects of different phase encoding directions and DC methods on RSN detectability. \n\nIn summary, we performed ICA-based functional connectivity analysis of rs-fMRI data with and without field map DC, which improved statistical power for detection of functional connectivity analysis in the ACC associated with the DMN. In addition, these finding were supported by seed-based functional connectivity analysis and the simulation analysis. We did not find any significant drawbacks in the analysis with DC. We found a higher LFHF ratio in the ACC, PCC, ventral striatum, and cerebellum after DC, suggesting that improvement in signal assignment to anatomical segments improves the analysis. We suggest that researchers should include a field map DC step in the preprocessing pipeline, especially when they are interested in functional connectivity in the DMN. \n\n\n## Author contributions \n  \nGuarantors of integrity of entire study: THa; study concepts and study design: HT and THa; data acquisition: THi and HM; data analysis and statistical processing: HT, JR, and KY; interpretation of data for study: HT, JR, KY, NH, and THa, drafting of manuscript: HT and JR; supervising manuscript: THa, manuscript final version approval: HT, JR, KY, THi, HM, NH, and THa. \n\n### Conflict of interest statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nCluster size\tSignificance\tMNI coordinates of min p-value\tRegion\tLeft/Right\nDMN: significant increased functional connectivity with field map correction, compared to without correction\tDMN: significant increased functional connectivity with field map correction, compared to without correction\tDMN: significant increased functional connectivity with field map correction, compared to without correction\tDMN: significant increased functional connectivity with field map correction, compared to without correction\tDMN: significant increased functional connectivity with field map correction, compared to without correction\n47\t0.0002\t10, 38, \u22128\tAnterior Cingulate Cortex, Paracingulate Gyrus, Frontal Medial Cortex\tRight\nBGN: significant decreased functional connectivity with field map correction, compared to without correction\tBGN: significant decreased functional connectivity with field map correction, compared to without correction\tBGN: significant decreased functional connectivity with field map correction, compared to without correction\tBGN: significant decreased functional connectivity with field map correction, compared to without correction\tBGN: significant decreased functional connectivity with field map correction, compared to without correction\n8\t0.0004\t18, 18, \u221212\tCerebral White Matter, Putamen\tRight\n### Caption\nList of clusters with significantly changed functional connectivity with field map correction in the peak level threshold method (compared with no correction; multiple comparison family wise error correction across voxels, components of interest, and contrast; p < 0.05).\n### Footer\nNone\n", "metadata": {"pmcid": 5717028, "text_md5": "37cea29d5f4c80e826475fa2e7fc8418", "field_positions": {"authors": [0, 142], "journal": [143, 157], "publication_year": [159, 163], "title": [174, 261], "keywords": [275, 362], "abstract": [375, 2056], "body": [2065, 38267], "tables": [38280, 39928]}, "batch": 2, "pmid": 29249930, "doi": "10.3389/fnins.2017.00656", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5717028", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5717028"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5717028\">5717028</a>", "list_title": "PMC5717028  Effects of Field-Map Distortion Correction on Resting State Functional Connectivity MRI"}
{"text": "Emmerling, Franziska and Schuhmann, Teresa and Lobbestael, Jill and Arntz, Arnoud and Brugman, Suzanne and Sack, Alexander Thomas\nPLoS One, 2016\n\n# Title\n\nThe Role of the Insular Cortex in Retaliation\n\n# Keywords\n\n\n\n# Abstract\n \nThe insular cortex has consistently been associated with various aspects of emotion regulation and social interaction, including anger processing and overt aggression. Aggression research distinguishes proactive or instrumental aggression from retaliation, i.e. aggression in response to provocation. Here, we investigated the specific role of the insular cortex during retaliation, employing a controlled behavioral aggression paradigm implementing different levels of provocation. Fifteen healthy male volunteers underwent whole brain functional magnetic resonance imaging (fMRI) to identify brain regions involved in interaction with either a provoking or a non-provoking opponent. FMRI group analyses were complemented by examining the parametric modulations of brain activity related to the individual level of displayed aggression. These analyses identified a hemispheric lateralization as well as an anatomical segregation of insular cortex with specifically the left posterior part being involved in retaliation. The left-lateralization of insular activity during retaliation is in accordance with evidence from electro-physiological studies, suggesting left-lateralized fronto-cortical dominance during anger processing and aggressive acts. The posterior localization of insular activity, on the other hand, suggests a spatial segregation within insular cortex with particularly the posterior part being involved in the processing of emotions that trigger intense bodily sensations and immediate action tendencies. \n \n\n# Body\n \n## Introduction \n  \nAggression is defined as behavior intended to inflicting harm to another being, while the victim wants to avoid the harm [ ]. Different forms of aggression can be distinguished; proactive aggression refers to using aggression in an instrumental, goal-oriented way, whereas reactive aggression refers to retaliation, i.e. aggressive actions triggered by preceding provocation [ , ]. \n\nAggression and retaliation are complex social behaviors and their scientific assessments rely on social interaction paradigms that do not only measure the perception of\u2014or attention to\u2014specific social emotional cues, but also their behavioral consequences in an experimental setup. Ideally, such paradigms allow quantifying different levels of aggressive behavior within provocative and non-provocative interactions in a controlled way. One of the most widely used and validated behavioral aggression paradigms fulfilling these requirements is the Taylor Aggression Paradigm (TAP [ ]), which also proved feasible in an neuroimaging environment [ \u2013 ]. The TAP is set up as a reaction time game between two or more opponents in which the winner can administer an aversive feedback stimulus of variable intensity to the opponent. It measures aggressive behavior within direct social interactions in a controlled way. Several neuroimaging studies have aimed at identifying neural activity induced by the TAP, reporting predominantly prefrontal regions, parietal cortex, basal ganglia, thalamus [ ], and dorsal medial prefrontal cortex [ ] involvement during the interaction between opponents. Higher nucleus accumbens activation was shown to predict more aggressive retaliation [ ]. Prefrontal regions, striatum, and other parts of the reward network [ ] were activated when winning (versus losing) against the opponent. Furthermore, the insular cortex was especially associated with aggressive behavior [ , ] during this social interaction game. Insular cortex involvement has also been reported in many other contexts including the processing of positive emotions, action inhibition, mindfulness, and interoception [ ], questioning any functional specificity of its involvement. \n\nThe seemingly rather general involvement of insular cortex in a variety of emotional and cognitive paradigms led to the development of models which could potentially assign different functions to different parts of the insular cortex. For instance, a segregation along a posterior-to-anterior gradient representing the progressive integration of bodily feelings has been proposed [ ]: Whereas acute emotions or interoceptive components might be represented in the posterior parts of the insular cortex, the anterior parts seem to code for more abstract and highly integrated constructs. This suggests that\u2014opposite to the anterior insular cortex\u2014the posterior insular cortex is involved in the processing of emotions triggering intense bodily sensation and immediate action tendencies. \n\nBesides its segregation, the lateralization of insular activation is yet to be fully understood. Previous work suggested that the left hemisphere\u2014as opposed to the right\u2014might be involved in approach related motivational states such as anger processing and aggression [ , ]. It remains to be answered, however, whether this assumption holds true not only regarding overall fronto-cortical asymmetry, but also with respect to specific brain regions such as the insular cortex. \n\nFollowing this line of argumentation, we particularly expected the posterior parts of the insular cortex to be involved in retaliation during which intense bodily sensations, action-oriented emotional content, and immediate behavioral responses are mobilized. Furthermore, this activation was expected to be left-lateralized as retaliation is closely related to anger processing and approach motivation. The here presented study tested this hypothesis by assessing the parametric modulations of brain activity underlying retaliation in a controlled aggression paradigm during whole brain fMRI. \n\n\n## Materials and Methods \n  \nPlease note that other analyses based on the same data set were reported previously comparing the neural correlates of reactive aggression with those of motor impulsivity (measured with a go-/nogo task [ ]. The neural correlates of the employed aggression paradigm were not yet exhaustively analyzed previously. We, here, therefore focus on the complete analysis of the data related to the aggression paradigm, including the analysis of parametric modulations as well as group analyses of each trial\u2019s entire time course. \n\n### Participants \n  \nEighteen male university students volunteered, gave their written informed consent, and were paid for participating. A screening ensured that none of the participants had a previous history of neurological or psychiatric disorders. Data of two participants were excluded from the analyses as they did not follow the instructions of the experimenter and chose fixed button press pattern without considering the actual task. Data of another participant was excluded, since the participant did not show any variance in behavior and always chose the exact same answer. Data of fifteen participants were included in further analyses (mean age = 22.33; SD = 2.35). The study was approved by the local Ethical Committee of the Faculty of Psychology and Neuroscience at Maastricht University and has been conducted according to the principles expressed in the Declaration of Helsinki. \n\n\n### Taylor Aggression Paradigm (TAP) \n  \nIntroduced in its first version by Taylor in 1967 [ ], the TAP has become a common tool in behavioral aggression research and has also proven itself the most adaptable option for brain imaging studies [ , , \u2013 ]. The task is set up as a competitive reaction time game between two or more opponents. The players give each other feedback in form of an aversive noise stimulus after each reaction time trial. During the task, aggressive behavior is measured by recording the severity level of the feedback or retaliatory aggression participants assign to their virtual opponents. The level of provocation can be manipulated such that an opponent can choose a more or less aversive feedback for the other player. Whenever a player loses a reaction time trial, he is presented with the aversive noise chosen by the opponent. The Taylor Aggression Paradigm has shown to be high in construct, internal, discriminant as well as external validity [ \u2013 ]. \n\nDuring recruitment, participants were led to believe that the experiment investigated the impact of human feedback on reaction time performance. They were informed about playing a reaction time game (TAP) against two other participants. Before entering the scanner, the participant and the two opponents (collaborators of the experimenters) were introduced. The experimenter\u2019s collaborators were trained beforehand and acted according to a script in order to ensure equal treatment of all participants. Throughout the entire scan, the players communicated verbally via intercom between the experimental runs. Immediately after completion of the experiment, an exit interview was administered to ensure that participants were fully deceived by the experimental setup. Upon completion of the study, a written debriefing was provided. \n\nIn the implementation of the TAP employed in this study [ ],  ), the participant played reaction time trials against one of two alleged opponents. These opponents were collaborators of the experimenter and merely acted in their role as participants. Participants were told that whoever reacted faster to a target stimulus, won the trial. The loser of each trial was presented with an aversive feedback noise chosen by the winning opponent. At the beginning of each trial the volume of this noise was chosen on an 8-point scale. Feedback noises were adjusted to the individual threshold of endurability while running a functional sequence for each participant (a 10 noise was set to the loudness the participant reported subjectively as the ultimate limit of endurability). No noises above 100 decibel were administered to ensure that the hearing was not compromised. Participants randomly played against each of the putative opponents in 50% of the trials. One opponent always selected soft feedback noises (from 1 to 4; non-provoking opponent), while the other selected loud feedback noises (from 4 to 8; provoking opponent). Participants randomly won (and lost) in 50% of trials per opponent. Trials in which reaction times exceeded 500 msec always were losing trials. This ensured a realistic sensation of competing with a human opponent. \n   Taylor Aggression Paradigm (TAP).  \nAdapted from Dambacher et al., 2014 [ ]. During the decision phase, participants were presented with a screen that informed them against whom they were playing in this trial (in this case \u201cTim\u201d) and asked to choose the feedback noise level that should be administered to this opponent in case the opponent lost (\u201c12345678\u201d). During the outcome phase, participants were informed on whether or not they won and what feedback noise level the particular opponent had chosen for this trial. \n  \nEach trial of 27000 msec consisted of a decision phase (6000 msec), the actual reaction time game (jittered between 4500 and 7500 msec), and an outcome phase (6000 msec). A jittered resting period followed. During the decision phase, participants were presented with a screen that informed them against whom they were playing in this particular trial (\u201cRob\u201d or \u201cTim\u201d) and asked to choose the volume of the noise feedback they wanted to administer to this opponent in case he would lose. The actual reactive aggressive behavior was measured during the decision phase of the TAP. During the outcome phase, participants were informed about whether or not they lost in this particular trial and which feedback noise levels the particular opponent chose for this trial. Whenever they lost, they were presented with this noise at the end of the outcome phase. \n\nStimuli were presented in white (RGB 255/255/255; Arial pt 24) on a grey background (RGB 125/125/125). Participants performed 3 runs of the TAP including 28 trials (14 trials per opponent) each, leading to a total of 84 trials (42 trials per opponent). Stimuli were presented using Presentation software (Neurobehavioral Systems, Inc., Albany, USA). Behavioral statistical analyses were performed using SPSS19 (IBM Statistics, USA). \n\n\n### Technical details, fMRI acquisition and analysis \n  \nSee also [ ]. Stimulus material was presented using an LCD projector (Panasonic, No PT-EZ57OEL) mounted onto a frosted screen, positioned at rear of the scanner bore. Responses were registered with a standard MR compatible button box (Current Designs, 8-button response device, HHSC-2x4-C, Philadelphia, USA). \n\nImages were acquired with a 3 Tesla Siemens Prisma scanner. Structural (high resolution T1-weighted MPRAGE; isotropic voxel resolution 1x1x1 mm ; 192 sagittal slices) and functional whole-brain (Gradient-Echo-EPI-sequence; TR = 1500msec; TE = 26msec; FOV = 224mm; flip angle = 73\u00b0; matrix = 64x64; distance factor = 20%; 478 volumes per run for the GNGT, 512 volumes per run for the TAP) scans were recorded. Twenty-eight oblique transversal slices of 3.5x3.5x3.5mm voxels were obtained. Slices were tilted 30\u00b0 relatively to the anterior-posterior commissure plane to avoid signal dropout in frontal areas [ ]. \n\nFMRI data were analyzed with Brain Voyager QX (Brain Innovation BV, Maastricht, The Netherlands). Preprocessing included 3D-motion-correction (trilinear / sinc interpolation and intra-session alignment to the first functional volume recorded after the individual structural scan), cubic spline slice scan time correction, and the application of a temporal high pass filter (general linear model (GLM) with Fourier basis set of 3 cycles sine/cosine per run plus linear trend removal). Images were co-registered to the individual anatomical data sets and normalized to Talairach stereotaxic space [ ]. Volume time courses were spatially smoothed (6mm full width half maximum Gaussian kernel). \n\nThe first three trials per opponent were excluded to restrict the analyses to the trials in which participants were familiar with the distinct behavioral pattern of the two opponents (i.e. provoking versus non-provoking). \n\n\n### Random effects group analyses \n  \nA GLM was defined to analyze the behavior displayed during the decision and the outcome phase in the TAP. For these analyses, the retaliatory aggression displayed by the participants was grouped into low (level 1\u20133), middle (4 and 5), and high (level 6\u20138) retaliatory aggression. \n\nThe following conditions were included as predictors for the decision phase (for phases of TAP see  ): participant chooses high retaliatory aggression for the provoking opponent, participant chooses low retaliatory aggression for the non-provoking opponent. Some participants rarely or never chose a low or middle retaliatory aggression for the provoking opponent. Furthermore, not every participant chose a middle or high retaliatory aggression for the non-provoking opponent. These conditions could therefore not be taken into account on the level of group analyses. \n\nThe following conditions were included as predictors for the outcome phase (for phases of TAP see  ): all win trials, all lose trials, win trials against provoking opponent, lose trials against provoking opponent, win trials against non-provoking opponent, lose trials against non-provoking opponent. \n\nTo reduce error variance, one noise regressor consisting of the first eigenvariate time series from cerebrospinal fluid regions and motion artefacts were included into the analyses as covariates. Statistical maps were created using a threshold of p < .001 corrected for multiple comparisons by means of cluster threshold level estimation (1000 Monte Carlo simulation iterations [ ]). \n\n\n### Analyses of parametric modulations \n  \nFor these analyses, the feedback given by the participants was treated as a continuous linear variable (from 1 to 8). For the decision phase, a main and a parametric predictor for interaction with the provoking opponent and the non-provoking opponent were defined. For the outcome phase, a main and a parametric predictor for winning and losing against the provoking opponent and the non-provoking opponent were defined. Parametric predictors were weighted on a single trial bases according to the behavior the participant displayed (the retaliatory aggression displayed) in the respective trial. \n\nIn order to examine which brain regions were modulated by the chosen retaliatory aggression, the conjunction of the main and the parametric effect for each specific condition (decision and outcome phase) was inspected. \n\nStatistical maps were created using a threshold of p < .01 corrected for multiple comparisons by means of cluster threshold level estimation (1000 Monte Carlo simulation iterations [ ]). \n\n\n\n## Results \n  \n### Behavioral data \n  \nThe average feedback (i.e. aversive noise) selected by the participants for the opponents was of medium intensity (MEAN = 3.54; SD = .04). A significantly higher feedback was chosen for the provoking compared to the non-provoking opponent (provoking opponent: MEAN = 4.52, SD = .64; non-provoking opponent: MEAN = 2.56, SD = 1.17; t = 4.59, p = < .001). During the exit interview at the end of the experiment none of the participants reported doubting the proposed purpose of the study and all fifteen participants reported that they perceived one opponent as more provocative than the other. Twelve participants explicitly reported that they adapted their reaction to that perception (behavioral data previously reported in Dambacher et al. 2014). \n\n\n### Random effects group analyses \n  \nTalairach coordinates of the brain regions showing increased activation associated with the investigated contrasts are reported in   (reported are the center of gravity, the number of significant voxels per cluster, and the maximum statistical t-value; cluster are labeled according to Talairach Client [ , ]). Statistical maps of random effects group analyses are depicted in   for the decision and the outcome phase. \n   Random effects group analyses.  \nNeural activation for the specified contrasts containing significant activation during the decision phase (A) and the outcome phase (B, C) of the Taylor Aggression Paradigm. Statistical Maps: N = 15, p < .001, Cluster Threshold level corrected, radiological convention. \n     Talairach coordinates.  \nCenter of gravity, number of significant voxels per cluster, and maximum statistical t-value; clusters are labeled according to Talairach Client [ , ]. \n    \nWhen contrasting trials in which participants displayed high retaliatory aggression towards the provoking opponent with trials in which the participant displayed low retaliatory aggression towards the non-provoking opponent (provocation > no provocation; only contrast previously reported in Dambacher et al. 2014), increased activation in bilateral insular cortex, left parietal lobe, left-lateralized motor regions, the left frontal lobe, and cerebellum was observed. Furthermore, several subcortical regions (i.e., the right and left putamen/globus pallidus, left-lateralized thalamic regions and caudate) showed significant activation change associated to this contrast ( ,  ). The only significant activation change associated with the display of low retaliatory aggression towards the non-provoking opponent (no provocation > provocation) was observed in the right parietal lobe close to the postcentral gyrus and the right superior temporal gyrus. \n\nReplicating previous results [ ], during winning (all won trials > all lost trials), strong significant bilateral activation in the right superior frontal gyrus, the middle frontal gyri, the left precuneus, the inferior parietal lobes, and the striatum was observed. During losing (all lost trials > all won trials), strong significant bilateral activation in the superior temporal gyri and the parahippocampal gyri was observed. No differences in brain activity could be detected when winning against the provoking opponent as opposed to winning against the non-provoking opponent (won trials against the provoking opponent > won trials against the non-provoking opponent; won trials against the non-provoking opponent > won trials against the provoking opponent). When participants lost to the non-provoking opponent versus to the provoking opponent (lost trials against the non-provoking opponent > lost trials against the provoking opponent), significant bilateral activation in the parietal lobes around the postcentral gyri and the left middle temporal gyrus could be detected. When participants lost to the provoking opponent versus to the non-provoking opponent (lost trials against the provoking opponent > lost trials against the non-provoking opponent), no significant differential brain activity could be detected. \n\n\n### Parametric modulations \n  \nTalairach coordinates of the brain regions showing parametric modulations according to the displayed behavior are reported in  . Statistical maps of parametric modulations are depicted in  . \n   Parametric modulations.  \nRegions modulating their activity parametrically according to the displayed behavior, when interacting with both (blue), the provoking (red), or the non-provoking opponent (green) during the Taylor Aggression Paradigm. Statistical Maps: N = 15, p < .01, Cluster Threshold level corrected, radiological convention. \n  \nIn order to identify brain regions that modulate their activity according to the displayed behavior (volume of the aversive noise chosen for the opponent defined on an 8-point scale), we conducted additional analyses in which the predictors were weighted according to this behavior. During retaliation, activity in the left pre- and post-central gyri, thus motor activation associated to the movement of the right hand was most prominent (main effect of retaliation against provoking opponent, non-provoking opponent, or both ^ parametric effect of retaliation against provoking opponent, non-provoking opponent, or both; conjunction). When interacting with the provoking opponent, the left posterior insular cortex was modulated by the intensity of retaliatory aggression displayed towards the provoking opponent (main effect of retaliation against provoking opponent ^ parametric effect of retaliation against provoking opponent; conjunction). This could not be observed for the interaction with the non-provoking opponent. Finally, activation in the right cerebellum was parametrically modulated by retaliatory aggression when interacting with both the non-provoking and the provoking opponent (main effect of retaliation against provoking opponent or both opponents ^ parametric effect of retaliation against provoking opponent or both opponents; conjunction). \n\nDuring the outcome phase no significant parametric modulations due to the amount of retaliatory aggression displayed by the participants could be observed (main effect all win trials, win trials against provoking opponent, or win trials against non-provoking opponent ^ parametric effect all win trials, win trials against provoking opponent, or win trials against non-provoking opponent; conjunction). \n\n\n\n## Discussion \n  \nThe current study investigated the role of the insular cortex during retaliation and revealed that the left posterior insular cortex is specifically activated when interacting with a provoking\u2014as opposed to a non-provoking\u2014opponent. \n\n### The role, segregation, and lateralization of insular activation during retaliation \n  \nDuring an aggressive reaction to provocation mainly bilateral insular cortex and basal ganglia were activated. This replicates results described in previous work associating insular cortex with aggression and the processing of negative emotions [ , ]. Our study provides direct quantitative support for the notion that the insular cortex is playing a crucial role in aggressive behavior: We demonstrate that insular cortex activity is parametrically modulated by the level of aggression displayed when interacting with the provoking opponent; this means that the stronger the retaliation in highly provocative situations the more insular cortex is recruited. Note that our results cannot differentiate between mere provocation and actual retaliatory aggression, as the two always occur in combination during our paradigm. This would also be the case in most real life situation involving retaliation. \n\nWe could confirm our specific hypothesis that activation within the insular cortex related to retaliation is left-lateralized and mainly localized in the posterior segment: Although the entire insular cortex was activated during retaliation (group analyses), it was specifically the activation level of the left posterior insular cortex that varied with the amount of aggression displayed. This indicates functional involvement, lateralization, and segregation of the insular cortex specific to retaliation. \n\nCraig [ ] suggested, that the insular cortex is structured along a posterior-to-anterior gradient representing the progressive integration of bodily feelings. He argued that acute emotions or interoceptive components might be represented in the posterior parts of the insular cortex, while the anterior parts seem to code for more abstract and highly integrated constructs. Retaliation or reactive aggression trigger intense bodily sensation and immediate action tendencies and, thus, should activate the posterior insular cortex. A similar segregation of insular cortex was demonstrated for a concept rather opposite to aggression, namely love. While passionate love, which is closely related to intense body sensation and action-oriented, involves posterior parts of the insular cortex, companionate love involves more anterior parts [ , ]. \n\nAlthough these findings are consistent with Craig\u2019s [ ] view and shed light on the neural correlates of rather abstract concepts such as aggression and love, the question remains in how far insular involvement is specific to any of these functions. In fact, the insular cortex has been associated with even more functions that are seemingly contradictory to what is reported here such as self-awareness, motor inhibition, processing of positive emotions, processing of negative emotions, and others (for review see Craig 2009). In the context of cognitive control, the insular cortex has furthermore been described as a region modulating with stimulus saliency or urgency [ \u2013 ]. However, instead of focusing on rather isolated single processes, as often done in functional brain research, social and emotional contexts should be taken into account when explaining the functional roles of brain regions. For instance, Reynolds and Berridge [ ] demonstrated that varying emotional environments retunes the function of neural populations. They showed that neurons in the nucleus accumbens of rats encode alternately for fear or pleasure depending on the environment the animal is exposed to (home-like, versus low stress, versus high stress). This is a revolutionary finding, potentially suggesting that neural components alter their functional involvement according to the social situation in which they are recruited. The posterior insular cortex might not be exclusively involved in aggression, passionate love, or other concepts. Rather, it might be highly relevant in different circumstances of intense emotions which require consequent behavioral responses. Most probably, it adapts its function to whatever requirements have to be met. Further research, involving methodology reaching beyond hemodynamic neuroimaging techniques and taking into account varying emotional environments, is needed. Moreover, it should be noted that the insular cortex is highly interconnected with various brain regions and it will be of interest to investigate its specific functional interactions with those regions during different emotional and social contexts. \n\n\n### Further activation during the decision phase \n  \nThe insular cortex was not the only brain region activated during the decision phase; activation in superior temporal gyrus and primary motor cortex was also detected. \n\nActivation in the right superior temporal gyrus was detected, when reacting mildly to the non-provoking opponent. This brain region has been associated with processes linked to social cognition [ \u2013 ]. Such processes are expected to be active when the participant is confronted with the non-provoking opponent; compared to his mean companion, he is friendly, nice, and from the participants\u2019 point of view more understandable and accessible, thus an object for self-identification. \n\nAdditionally, primary motor cortex activity was detected during the decision phase. Low punishment levels (1,2,3,4) had to be selected by the left hand (leading to activation in the right primary motor cortex), whereas high levels of punishment (5,6,7,8) had to be selected by the right hand (leading to activation in left primary motor cortex). This mechanism is mirrored in our results: In the group analyses, the left motor cortex is activated during aggressive reactions towards the provoking opponent, while the right motor cortex is activated during non-aggressive reactions to the non-provoking opponent. Accordingly, activity in the right motor cortex modulated with the intensity of the chosen punishment independent of the provocation condition; the higher the chosen punishment, the more involvement of the left motor cortex was observed. It has to be emphasized that further left-lateralizations (e.g. of anterior insula activation) could also be interpreted in light of this motor dissociation. \n\n\n### Winning and losing \n  \nWinning was associated with vast neural activity in bilateral superior and middle frontal regions, the inferior parietal lobes, the left precuneus, and bilateral striatum. This replicates previous results [ ]. Striatal activation on one hand and the involvement of prefrontal areas on the other hand, strongly suggest the recruitment of the reward circuit in the brain [ ]. Winning during the TAP is rewarding in two ways: Outperforming the opponent in the given task (reaction time competition) might be rewarding in itself. Furthermore, winning means avoiding suffering from retaliatory aggression and at the same time administering retaliatory aggression to the opponent, which might also be a pleasurable experience. \n\nIn contrast, losing was associated with bilateral activation in the superior temporal gyri and the parahippocampal gyri. The former might simply reflect the anticipated auditory stimulus, which is to come every time a participant loses (and never, when the participant wins). Previously, the parahippocampal gyri were shown to be involved in scene recognition and the detection of paralinguistic speech profiles often related to the social component of the situation (e.g. sarcasm [ ]). This might reflect the paralinguistic and socially driven interpretation of the communication during the outcome phase; although the information presented during this phase is objective and seemingly neutral (\u201cyou won / you lost\u201d and \u201cyour opponent chose x\u201d), it contains social and paralinguistic cues related to the perception of the social opponent and the interpretation of his behavior. \n\nThe only opponent-specific activation regarding the outcome phase was detected when losing against the non-provoking opponent instead of the provoking opponent. When no highly aversive stimulus had to be expected, the parietal lobes and the left middle temporal gyrus were significantly activated. The participant might feel relief, when losing against the non-provoking opponent instead of the provoking opponent, as the noise feedback which is about to come is much less aversive. However, an association between the detected brain regions and the described processes has not been investigated yet. \n\nGenerally, the neural correlates of winning and losing were not linked to the individual levels of displayed aggression; no parametric modulations in any brain regions could be detected during the outcome phase. \n\n\n\n## Limitations \n  \nThe current results have to be interpreted considering the limitations of our experimental design: The main limitation of this study is the rather small sample size (N = 15) which makes the representativeness of our findings for the general male population challenging. We suggest continuing the investigation of social interaction by means of functional imaging based on larger samples (e.g., [ ]). Furthermore, only healthy, young, male students were examined rendering the generalization of our results to a gender-unspecific context or any clinical population impossible. One should also consider that the concrete implementation of the Taylor Aggression Paradigm in our study limited the variety of observable behavior. Firstly, participants did not react aggressively towards the non-provoking opponent making any analysis of proactive aggression and comparisons between proactive (non-provoked) and retaliatory aggression impossible. Secondly, in our paradigm mere provocation and the actual retaliation behavior could not be differentiated. Our interpretations are based on an understanding of retaliation and the provocative situation as a unity, thus, as one holistic social situation. Therefore, the interpretations resulting from the presented findings definitely lack in specificity. However, as pointed out previously [ ], it is unclear whether identifying neural components exclusively involved in the perception of provocation versus actual retalialiatory behavior would ultimately lead to a better understanding of real life aggression. In a naturalistic setting both concepts always co-occur. Finally, the handedness of our participants was not considered which might confound our interpretations, future studies in the field should take handedness in to account. \n\n\n## Conclusion \n  \nReplicating previous results in the field, this study demonstrates the crucial role of insular cortex in retaliation. We show that the left posterior insular cortex is a core brain region involved in retaliatory aggression; this was specifically demonstrated for provocative versus non-provocative social interactions. We employed random effects group analyses and examined parametric modulations of brain activity during a controlled behavioral aggression paradigm. The left-lateralization of insular activity during retaliation is in line with evidence from electro-physiological studies, suggesting left-lateralized fronto-cortical dominance during anger processing and aggressive acts [ ]. Furthermore, our results support the theory that particularly the posterior segment of insular cortex is involved in the processing of emotions triggering intense bodily sensations and immediate action tendencies [ ]. \n\n \n\n# Table(s)\n## ID: pone.0152000.t001\n### Label: Table 1\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tTalairach coordinates\tTalairach coordinates\tTalairach coordinates\tSize\tUnnamed: 6_level_0\nRegion\tUnnamed: 1_level_1\tx\ty\tz\tvoxel\tt\nRFX GLM\t\t\t\t\t\t\nAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\tAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\tAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\tAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\tAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\tAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\tAggressive reaction to provoking opponent > non aggressive reaction to non-provoking opponent\nAnterior insular cortex\tR\t27\t21\t10\t1126\t6.43\nAnterior insular cortex connected\tL\t-17\t-3\t9\t13798\t7.41\nInsular cortex connected\tL\t-17\t-3\t9\t13798\t7.41\nPutamen / globus pallidus connected\tR\t-17\t-3\t9\t13798\t7.41\nPutamen / globus pallidus connected\tL\t-17\t-3\t9\t13798\t7.41\nThalamus connected\tL\t-17\t-3\t9\t13798\t7.41\nCaudate connected\tL\t-17\t-3\t9\t13798\t7.41\nParietal lobe, postcentral gyrus\tL\t-38\t-34\t53\t30935\t9.96\nFrontal Lobe, paracentral lobe\tL\t-4\t-11\t47\t2900\t6.05\nCerebellum\tR\t12\t-65\t18\t7471\t7.87\nNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\tNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\tNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\tNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\tNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\tNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\tNon aggressive reaction to non-provoking opponent > aggressive reaction to provoking opponent\nParietal lobe, postcentral gyrus\tR\t36\t-31\t60\t1796\t6.52\nSuperior temporal gyrus\tR\t53\t4\t-7\t348\t6.04\nWon > lost\tWon > lost\tWon > lost\tWon > lost\tWon > lost\tWon > lost\tWon > lost\nSuperior frontal gyrus\tR\t21\t56\t18\t1056\t5.87\nMiddle frontal gyrus\tL\t-44\t54\t7\t449\t5.26\nMiddle frontal gyrus\tR\t29\t8\t51\t16489\t11.67\nMiddle frontal gyrus\tL\t-33\t6\t51\t17993\t8.20\nInferior parietal lobe, postcentral gyrus\tR\t38\t-56\t37\t17931\t8.07\nInferior parietal lobe, postcentral gyrus\tL\t-39\t-55\t37\t18740\t8.49\nParietal lobe, precuneus\tL\t0\t-63\t34\t721\t5.26\nStriatum\tR\t11\t8\t3\t761\t5.77\nStriatum\tL\t-16\t10\t3\t1865\t8.07\nLost > won\tLost > won\tLost > won\tLost > won\tLost > won\tLost > won\tLost > won\nSuperior temporal gyrus\tR\t48\t-15\t8\t35116\t12.37\nSuperior temporal gyrus\tL\t-49\t-20\t8\t18628\t9.87\nLimbic lobe, parahippocampal gyrus\tR\t18\t-50\t-2\t3383\t7.57\nLimbic lobe, parahippocampal gyrus\tL\t-20\t-55\t-1\t1552\t6.04\nWon against the provoking opponent > won against the non-provoking opponent\tWon against the provoking opponent > won against the non-provoking opponent\tWon against the provoking opponent > won against the non-provoking opponent\tWon against the provoking opponent > won against the non-provoking opponent\tWon against the provoking opponent > won against the non-provoking opponent\tWon against the provoking opponent > won against the non-provoking opponent\tWon against the provoking opponent > won against the non-provoking opponent\nNo significant modulation detected\t\t\t\t\t\t\nWon against the non-provoking opponent > won against the provoking opponent\tWon against the non-provoking opponent > won against the provoking opponent\tWon against the non-provoking opponent > won against the provoking opponent\tWon against the non-provoking opponent > won against the provoking opponent\tWon against the non-provoking opponent > won against the provoking opponent\tWon against the non-provoking opponent > won against the provoking opponent\tWon against the non-provoking opponent > won against the provoking opponent\nNo significant modulation detected\t\t\t\t\t\t\nLost against the provoking opponent > lost against the non-provoking opponent\tLost against the provoking opponent > lost against the non-provoking opponent\tLost against the provoking opponent > lost against the non-provoking opponent\tLost against the provoking opponent > lost against the non-provoking opponent\tLost against the provoking opponent > lost against the non-provoking opponent\tLost against the provoking opponent > lost against the non-provoking opponent\tLost against the provoking opponent > lost against the non-provoking opponent\nNo significant modulation detected\t\t\t\t\t\t\nLost against the non-provoking opponent > lost against the provoking opponent\tLost against the non-provoking opponent > lost against the provoking opponent\tLost against the non-provoking opponent > lost against the provoking opponent\tLost against the non-provoking opponent > lost against the provoking opponent\tLost against the non-provoking opponent > lost against the provoking opponent\tLost against the non-provoking opponent > lost against the provoking opponent\tLost against the non-provoking opponent > lost against the provoking opponent\nParietal lobe, around postcentral gyrus\tR\t35\t-32\t52\t2685\t7.64\nParietal lobe, around postcentral gyrus\tL\t-11\t-41\t68\t1508\t\nMiddle temporal gyrus\tL\t-41\t-64\t26\t665\t6.13\nPARAMETRIC MODULATIONS\t\t\t\t\t\t\nRetaliation independent of opponent\tRetaliation independent of opponent\tRetaliation independent of opponent\tRetaliation independent of opponent\tRetaliation independent of opponent\tRetaliation independent of opponent\tRetaliation independent of opponent\nInferior parietal lobe, pre- and postcentral gyrus\tL\t-38\t-36\t51\t29148\t6.16\nCerebellum\tR\t14\t-49\t-20\t1350\t3.98\nRetaliation interacting with provoking opponent\tRetaliation interacting with provoking opponent\tRetaliation interacting with provoking opponent\tRetaliation interacting with provoking opponent\tRetaliation interacting with provoking opponent\tRetaliation interacting with provoking opponent\tRetaliation interacting with provoking opponent\nInferior parietal lobe, pre- and postcentral gyrus\tL\t-36\t-34\t56\t17268\t6.14\nCerebellum\tR\t11\t-53\t-19\t1703\t4.79\nInsular cortex\tL\t-39\t-8\t15\t1562\t6.13\nRetaliation interacting with non-provoking opponent\tRetaliation interacting with non-provoking opponent\tRetaliation interacting with non-provoking opponent\tRetaliation interacting with non-provoking opponent\tRetaliation interacting with non-provoking opponent\tRetaliation interacting with non-provoking opponent\tRetaliation interacting with non-provoking opponent\nInferior parietal lobe, pre- and postcentral gyrus\tL\t-41\t-38\t47\t10864\t4.21\nWon\tWon\tWon\tWon\tWon\tWon\tWon\nNo significant modulation detected\t\t\t\t\t\t\nWon against provoking opponent\tWon against provoking opponent\tWon against provoking opponent\tWon against provoking opponent\tWon against provoking opponent\tWon against provoking opponent\tWon against provoking opponent\nNo significant modulation detected\t\t\t\t\t\t\nWon against non-provoking opponent\tWon against non-provoking opponent\tWon against non-provoking opponent\tWon against non-provoking opponent\tWon against non-provoking opponent\tWon against non-provoking opponent\tWon against non-provoking opponent\nNo significant modulation detected\t\t\t\t\t\t\n### Caption\nTalairach coordinates.Center of gravity, number of significant voxels per cluster, and maximum statistical t-value; clusters are labeled according to Talairach Client [21,22].\n### Footer\nNone\n", "metadata": {"pmcid": 4838249, "text_md5": "ca3b3ae9ff021e487707a76fb7272637", "field_positions": {"authors": [0, 129], "journal": [130, 138], "publication_year": [140, 144], "title": [155, 200], "keywords": [214, 214], "abstract": [227, 1755], "body": [1764, 34820], "tables": [34833, 42299]}, "batch": 2, "pmid": 27096431, "doi": "10.1371/journal.pone.0152000", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4838249", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4838249"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4838249\">4838249</a>", "list_title": "PMC4838249  The Role of the Insular Cortex in Retaliation"}
{"text": "Lee, Seonjin and Kim, Jooyeon and Tak, Sungho\nFront Behav Neurosci, 2020\n\n# Title\n\nEffects of Autonomous Sensory Meridian Response on the Functional Connectivity as Measured by Functional Magnetic Resonance Imaging\n\n# Keywords\n\nautonomous sensory meridian response\nfunctional connectivity\nfunctional magnetic resonance imaging\ndefault mode network\naffective touch network\nself-network\n\n\n# Abstract\n \nAutonomous sensory meridian response (ASMR) is a sensory phenomenon in which audio-visual stimuli evoke a tingling sensation and is accompanied by a feeling of calm and relaxation. Therefore, there has been an increasing interest in using stimuli that elicit ASMR in cognitive and clinical neuroscience studies. However, neurophysiological basis of sensory-emotional experiences evoked by ASMR remain largely unexplored. In this study, we investigated how functional connectivity is changed while watching ASMR video, compared to resting state, and assessed its potential association with affective state induced by ASMR. 28 subjects participated in fMRI experiment consisting of 2 sessions (resting-state and task of viewing ASMR-eliciting video). Using a seed-based correlation analysis, we found that functional connections between the posterior cingulate cortex, and superior/middle temporal gyri, cuneus, and lingual gyrus were significantly increased during ASMR compared to resting state. In addition, we found that with the pregenual anterior cingulate cortex seed region, functional connectivity of the medial prefrontal cortex was increased during ASMR condition, relative to resting state. These results imply that ASMR can be elicited and maintained by ongoing interaction between regional activity that are mainly involved in the mentalizing and self-referential processing. We also found that ASMR-induced affective state changes (high activation negative and high activation positive state) were negatively correlated with functional connectivity involved in visual information processing, suggesting that visual information processing in response to high arousal states can be weakened by ASMR-eliciting stimuli. \n \n\n# Body\n \n## Introduction \n  \nStress is common in everyday life, and is believed to affect individual health and happiness ( ;  ). As a result, the development of stress management approaches has become an important endeavor of preventing stress-related health problems and accomplishing psychological well-being. In recent years, the autonomous sensory meridian response (ASMR) videos have been widely used in the management of stress, by inducing relaxation and sleep ( ;  ). Specifically, ASMR is a sensory phenomenon in which individuals experience a tingling in the head and neck, in response to specific triggering audio and visual stimuli ( ). The ASMR triggers lead to response of psychologically pleasant effects such as feeling of relaxation, reduction in anxiety, and sleep induction ( ;  ;  ). \n\nSeveral studies have explored the neurophysiological basis of ASMR using functional magnetic resonance imaging (fMRI) ( ,  ;  ). Specifically,   examined the brain activation during ASMR, and observed significant activation in regions of the medial prefrontal cortex (mPFC), dorsal anterior cingulate cortex, supplementary motor area, and insular cortex during ASMR condition, compared to the brain activity during resting state. \n\n,   investigated the differences of resting-state network between ASMR experienced and non-ASMR experienced individuals. Using an independent component analysis ( ), they found that participants with ASMR had less connections of the precuneus with other regions of the default mode network (DMN) than controls. These previous studies demonstrated the associations of ASMR with the changes in regional activity and networks of resting state. However, it is still unclear how connections among brain regions are explicitly modulated by ASMR. \n\nTo address this issue, this paper focuses on the investigation of ASMR condition-specific functional connectivity changes in a brain network, compared to the resting-state functional connectivity, using 3T functional magnetic resonance imaging (fMRI). Functional connectivity was assessed using a seed-based correlation approach ( ;  ). We hypothesized that ASMR condition would change the functional connectivity within the brain network involved in mentalization and self-referential processing as a meditation effect of ASMR. This is based on a previous study ( ) reporting that sitting quietly while watching relaxed scenes to arouse ASMR for a certain period of time could be regarded as a form of mindfulness. Mindfulness meditation can arouse relaxed and calm states by developing a level of mentalization that controls emotion using a capacity for resilience in the face of distressed conditions ( ;  ). Also, the meditation has been known to induce positive emotion using self- and other-referential processing ( ). The previous study ( ) has shown that participants who experienced mindfulness meditation had self-positive bias that led to positively affective responses during experimental self- and other-referential processing. Therefore, based on an association of ASMR and meditation conditions, we tested our hypothesis by investigating the ASMR condition-specific connectivity changes in the DMN that are involved in the mentalizing ( ;  ), and the self- and other-networks that are associated with self- and other-referential processing ( ;  ). The self-network has a function of self-specific processing, indicating non-self-/self-distinction to comprehend self in domain of perception, emotion, and cognition ( ). The other-network has a function of other-specific processing that represents other-/self-distinction in understanding others\u2019 mental and emotional states across the domains of perception, emotion, and cognition ( ). \n\nIn addition, since the ASMR triggers have been known to induce a tingling sensation as a secondary phenomenon resulting from intensely positive emotion ( ), we explored the changes in the functional connectivity of the affective touch network while watching the ASMR stimuli ( ). We selected the seed regions for the default mode, affective touch, and self-/other-networks as follows. The posterior cingulate cortex (PCC), mPFC, and left/right lateral parietal cortex (lLPC, rLPC) were used as the seed regions for the DMN, because these regions are recognized as central hubs within the network ( ). For the affective touch network, we used the right posterior insular cortex (Ig2) as a seed region based on a previous meta-analysis study ( ).   reported a higher activation of Ig2 in response to affective touch compared with discriminative touch. Using this seed region of Ig2, they observed an affective touch network composed of bilateral clusters, including posterior and anterior insular cortex, postcentral primary, and secondary somatosensory regions. For the self- and other-networks, we used the pregenual anterior cingulate cortex (pACC) and posterior cingulate cortex/precuneus (PCC/PC) regions as seed ROIs, because these two seed regions have been reliably shown to be involved in conceptual self- and conceptual other-processing, respectively ( ). The self-network consisted of the pACC and anterior insular cortex, whereas the other-network consisted of the PCC/PC and angular gyrus/temporoparietal junction ( ). \n\nFinally, using the functional connectivity estimates, we further investigated the potential association of condition-specific connectivity changes with affective state changes while watching ASMR stimuli. Our hypothesis was that the changes in functional connectivity during ASMR would be closely associated with the changes in pleasant/unpleasant emotion and arousal states during ASMR. We assessed the affective outcomes of watching ASMR video clips using the Multi-Affect Indicator ( ;  ) and then performed a correlation analysis between the functional connectivity strengths and individual scores for affective state induced by ASMR. \n\n\n## Materials and Methods \n  \n### Participants and Experimental Protocol \n  \nTwenty-eight healthy subjects (13 females, 15 males; mean age: 26.39 \u00b1 3.77 years) participated in this study. No subjects had any history of neurological disorders. The study was approved by the Institutional Review Board (IRB) of Korea Basic Science Institute, and the experiment was performed with the understanding and written consent of each participant, according to IRB guidelines. \n\nThe experiment consisted of two sessions. In the first session, which served as a control experiment, participants underwent a 5-min resting-state fMRI scan. During this scan, participants were instructed to stare at a fixation point in the center of the screen and remain awake. The scan duration of 5 min was based on previous studies showing that estimates of resting-state functional connectivity stabilized with this acquisition time ( ). We also determined the specific instructions for resting-state condition (eyes closed, eyes open, or eyes fixated on a cross), based on  . It was found that reliability in the default mode, attention, and auditory networks was the highest when subjects kept their eyes fixated on a cross. \n\nIn the second session, participants underwent ASMR task in the MRI scanner. During the scan, participants were instructed to view ASMR-eliciting video for 5 min. This video was trimmed to a length of 5 min from the full-length version of the YouTube video, which comprised repetitive and slow movements with a scratching sound (i.e., scratching of a sand table). The web address is as follows:  . While standards for ASMR videos have not yet been extensively examined, several studies ( ;  ) have established the common stimuli that elicit an intense ASMR experience, including whispering, scratching sound, and slow/repetitive movements. Therefore, we selected the content of the video clips based on these criteria. The length of ASMR video clips was set to be consistent with that of the resting-state condition because the scan length has been known to affect the reliability of fMRI connectivity estimates ( ). \n\nAfter completing fMRI experiments, outside the scanner, participants responded to questionnaires for assessing the changes in affective states while watching ASMR video clips (see the Behavior Data Analysis section for more details). Overall, this study consisted of three phases: the first session for resting-state experiment in the MRI scanner (5 min), the second session for ASMR experiment in the MRI scanner (5 min), and behavioral data collection outside the scanner. \n\n\n### MRI Acquisition \n  \nAll images were acquired using a 3T Philips Achieva scanner (Philips Medical Systems, Best, The Netherlands). Structural images were acquired using a three-dimensional T1-weighted sequence [repetition time (TR) = 6.6 ms; echo time (TE) = 3.1 ms; flip angle = 9\u00b0; voxel size = 1.0 \u00d7 1.0 \u00d7 1.2 mm ; field of view (FOV) = 240 mm; 170 slices]. Blood oxygenation level dependent (BOLD) images were obtained using a T2 -weighted gradient echo-planar imaging (EPI) sequence (TR = 2000 ms; TE = 35 ms; flip angle = 79\u00b0; voxel size = 3.0 \u00d7 3.0 \u00d7 3.0 mm , FOV = 195 mm, 34 interleaved slices without slice gap). \n\n\n### Data Processing \n  \nThe functional connectivity toolbox (CONN toolbox,  ) with the statistical parametric mapping software package (SPM12,  ) was used for pre-processing of the functional and structural images, and functional connectivity analysis. \n\nThe effects of head movement between scans were corrected by realigning all scans to the first image using a six-parameter affine spatial transformation; the geometric distortion was corrected by the unwarp function. The ensuing realignment parameters were saved for modeling residual head motion effects in the BOLD time series. To further mitigate motion-related BOLD effects, including spikes, we used artifact detection tools (ART,  ) interoperable with CONN toolbox. Specifically, outlying volumes in BOLD time series (scan \u201cscrubbing\u201d) were identified based on normalized global mean intensity values (>Z = 5) and motion parameters (>1 mm translational movement in the x, y, or z planes or >0.02 rotation in yaw, pitch, or roll). The matrices of outliers and realignment parameters were then entered as first-level covariates (i.e., nuisance variables). To compensate for slice-acquisition delays, the signal in each slice was realigned temporally to a reference middle slice using sinc interpolation. The structural image was co-registered with functional images and segmented into gray matter (GM), white matter (WM), and cerebrospinal fluid (CSF). All images were spatially normalized to the Montreal Neurological Institute (MNI) space. Spatial smoothing with a 6 mm full-width at half-maximum (FWHM) Gaussian kernel was applied to the normalized images. \n\nSystemic physiological confounds arising from cardiac and respiration have been known to cause spurious correlation structures throughout the brain ( ;  ;  ). We therefore reduced systemic physiological noise using the anatomical component-based noise correction method (aCompCor) ( ). The method has also been shown to be effective in the suppression of motion-related artifacts ( ). Assuming that the physiological noise contribution is globally distributed, and neuronal activity-related signals are low in the WM and CSF, the signals within the WM and CSF were used as sources that primarily reflect physiological noise. The top three components obtained from each of the WM and CSF using principal component analysis were included as the nuisance regressors in the first-level analysis. In addition, to remove spurious task-induced co-activation effects, we constructed a condition-specific regressor and included it as additional temporal confounding factors by convolving a canonical hemodynamic response function with a condition (either ASMR or resting-state) spanning the entire scanner acquisition length ( ;  ). Prior to the first-level connectivity analysis, these temporal confounding factors (consisting of subject movement, cardiac/respiration, and spurious parameters related to task effects) were regressed out from BOLD time series at each voxel. The resulting residual time series were then band-pass filtered in the range of 0.01\u20130.1 Hz to constrain the low-frequency BOLD fluctuations presumed to be related to spontaneous neural activity ( ;  ). \n\nFirst-level functional connectivity maps were generated by computing Pearson\u2019s correlation coefficients between average BOLD time series calculated across all the voxels of a given seed region and the time series of all other voxels in the brain ( ;  ). The resulting correlation coefficients were converted to   Z  -scores using Fisher transformation ( ) to improve the normality assumptions of the subsequent second-level general linear model (GLM) analysis. Functional connectivity considered in our analysis was associated with (a) the DMN ( ), (b) affective touch network ( ), and (c) the self-/other-networks ( ;  ). As seeds of the DMN, we used the PCC centered at MNI coordinates [1, \u221261, 38], mPFC (MNI: [1 55 \u22123]), and l/rLPC (lLPC, MNI: [\u221255 \u221212 29], rLPC, MNI: [56 \u221210 29]). The seed regions of interest (ROIs) were defined using a standardized CONN toolbox atlas (networks.nii) that was originally derived from group-level independent component analysis (ICA) of the human connectome project dataset ( ;  ;  ). For an affective touch network, we used the Ig2 as a seed ROI that comprised all voxels within a sphere of 6 mm radius, centered on the MNI coordinates [42, \u221214, 8]. Finally, for the self- and other-networks, we used the pACC and PCC/PC regions as seed ROIs (spheres of 6 mm radius, centered on MNI coordinates: [\u22122, 38, 16] and [2, \u221261, 26]). \n\nFollowing the computation for the first-level functional connectivity maps, the resulting voxel-specific   Z  -scores between a seed area and every other voxel for each subject were entered into a second-level GLM analysis. Specifically, we performed a one-sample   t  -test at the second level to test the statistical significance of each functional connectivity map in a group of subjects that was generated during resting-state or ASMR conditions (ASMR). We then tested our hypothesis that functional connectivity related to mentalizing and self-referential processing within the default mode, affective touch, and self-/other-networks would be greater during an ASMR condition than the resting-state, using a two-tailed paired sample   t  -test with a contrast \u201cASMR > resting-state\u201d at the second-level. This analysis enabled us to compare the functional connectivity patterns between two conditions, including a resting-state and an ASMR condition, and assess their statistical significance in a sample. For false positive control in the whole-brain seed-to-voxel connectivity analysis, we applied a cluster-forming threshold using a height threshold of uncorrected   p  -value < 0.001 and a cluster-extent threshold of false discovery rate (FDR)-corrected   p  -value < 0.05 ( ;  ). We used a semi-automated search for finding local maxima (peaks) and their MNI coordinates within the cluster-corrected thresholded map, to identify regions within the significant functional connectivity maps. Their anatomical labels were determined using xjView toolbox ( ), and the Brodmann area labels were identified using the Brodmann atlas, which is included in the MRIcron software ( ). Functional connectivity maps were overlaid on a cortical surface atlas using the CONN toolbox ( ). \n\n\n### Behavioral Data Analysis \n  \nTo investigate the potential association of functional connectivity estimates with the psychological changes of ASMR, we measured the affective outcomes of watching ASMR video clips using the Multi-Affect Indicator ( ;  ). This multi-affect indicator has been designed to specify different kinds of feelings in terms of two dimensions, including the conventional negative-to-positive continuum (from unpleasant to pleasant state) and low-to-high mental activation (arousal) that defines one\u2019s state of readiness for action or energy expenditure ( ). Particular feelings were then categorized into four affective states: low-activation positive (LAP, which corresponds to comfort and calmness), high-activation positive (HAP, related to enthusiasm and excitement), low-activation negative (LAN, related to depression and sadness), and high-activation negative states (HAN, related to anxiety and stress). In this study, we used 12 items to measure these affective states ( ;  ): \u201ccalm,\u201d \u201crelaxed,\u201d and \u201cat ease\u201d for LAP; \u201centhusiastic,\u201d \u201cjoyful,\u201d and \u201cexcited\u201d for HAP; \u201cdepressed,\u201d \u201cdejected,\u201d and \u201chopeless\u201d for LAN; and \u201canxious,\u201d \u201cnervous,\u201d and \u201ctense\u201d for HAN. After completing the fMRI experiments, the participants were asked to rate each item in the range of 1 (much less) to 7 (much more) by responding to the question: How did you feel while watching ASMR video clip during the MRI scan, compared to before you watched the video? \n\nWe then performed two-tailed paired samples   t  -tests to compare the means of two affective states that were selected from LAP, HAP, LAN, and HAN, and determined whether there was a significant difference between the two states that can be observed from ASMR stimuli. In addition, we performed a correlation analysis to investigate the associations of these affective state changes with ASMR condition-specific functional connectivity changes. Specifically, for each brain network, we identified clusters that had a significantly higher functional connectivity from a seed region for ASMR condition than the resting-state condition (a height threshold of uncorrected   p  -value < 0.001 and a cluster-extent threshold of FDR-corrected   p  -value < 0.05). Then, we extracted the functional connectivity values (z-score) of peak coordinates (i.e., the local maxima of the cluster) for all subjects, and calculated Pearson\u2019s correlation coefficients between these functional connectivity strengths and individual scores for each affective state. We decided that the computed correlation value is significantly different from zero if the   p  -value is less than 0.05. \n\n\n\n## Results \n  \n### Functional Connectivity \n  \n shows the group-level functional connectivity of the   t  -statistic in the default mode network generated during either ASMR or resting-state conditions. Statistical significance of clusters and their peak coordinates for ASMR and resting-state conditions are summarized in  ,  , respectively. While the global maxima of the functional connectivity was located in the seed cluster, in both conditions of resting-state and ASMR, the significant hubs (local maxima of the functional connectivity within the cluster) were reliably positioned in the PCC, mPFC, lLPC, rLPC, and superior/middle/inferior temporal gyri, and superior/inferior frontal gyri. For seed regions of the PCC and rLPC, the negative functional connectivity was observed in the insular cortex. \n  \nGroup-level functional connectivity of the   t  -statistic in the default mode network during resting-state, and in response to ASMR effects. Functional connectivity strengths in terms of   t  -statistics were thresholded at a significance level of false discovery rate (FDR)-corrected   p   < 0.05, and overlaid on a cortical surface atlas. Functional connectivity of the posterior cingulate cortex (PCC) seed region in response to ASMR   (A)  , and in resting-state   (B)  . Functional connectivity of the medial prefrontal cortex (mPFC) seed region in response to ASMR   (C)  , and in resting-state   (D)  . Functional connectivity of the left lateral parietal cortex (lLPC) seed region in response to ASMR   (E)  , and in resting-state   (F)  . Functional connectivity of the right lateral parietal cortex (rLPC) seed region in response to ASMR   (G)  , and in resting-state   (H)  . \n    \nStatistical significance of the group-level functional connectivity generated during ASMR condition. \n      \nStatistical significance of the group-level functional connectivity generated during resting-state condition. \n    \n shows the group-level functional connectivity of the   t  -statistic in the affective touch, self-, and other-networks generated during either ASMR or resting-state conditions. For the affective touch network with Ig2 seed region, the significant clusters were estimated in the insular cortex and postcentral gyrus in both conditions of resting-state and ASMR. In the self-network with the pACC seed region, we found the positive functional connectivity of the anterior cingulate cortex. In other-network with the PCC/PC seed region, the positive functional connectivity was observed in the angular gyrus, precuneus, and frontal regions extending orbitofrontal and medial prefrontal cortices. \n  \nGroup-level functional connectivity of the   t  -statistic in the other networks during resting-state, and in response to ASMR effects. Functional connectivity strengths in terms of   t  -statistics were thresholded at a significance level of false discovery rate (FDR)-corrected   p   < 0.05, and overlaid on a cortical surface atlas. Functional connectivity of the right posterior insular cortex seed (Ig2) region in response to ASMR   (A)  , and in resting-state   (B)  . Functional connectivity of the pregenual anterior cingulate cortex (pACC) seed region in response to ASMR   (C)  , and in resting-state   (D)  . Functional connectivity of the posterior cingulate cortex/precuneus (PCC/PC) seed regions in response to ASMR   (E)  , and in resting state   (F)  . \n  \n shows the group-level functional connectivity of the t-statistic obtained by the \u201cASMR > resting-state\u201d contrast.   summarizes statistical significance of clusters functionally connected to the seed regions of the PCC, l/rLPC, pACC, and Ig2, and their peak coordinates. There were no significant clusters in the DMN with the mPFC seed region and the other-network with the PCC/PC seed region. In the DMN with the PCC seed region, 5 clusters having positive functional connectivity were significantly detected in peaks in the cuneus, superior/middle temporal gyri, and lingual gyrus. In addition, 6 clusters having negative functional connectivity were significantly detected in peaks in the superior/middle frontal gyri, middle occipital lobe, precuneus, and visual area. In the DMN with the lLPC seed region, 2 positive and 1 negative clusters were observed in peaks in the superior temporal gyrus and visual area (calcarine sulcus), and precuneus, respectively. In the DMN with the rLPC seed region, 2 positive clusters were generated in peaks in the cuneus and lingual gyrus. In the self-network with the pACC seed region, a positive cluster was detected in peaks in the middle frontal lobe. In the affective touch network with the the Ig2 seed region, one cluster having positive functional connectivity was observed in peaks in the cuneus. \n  \nGroup-level functional connectivity of the   t  -statistic obtained by the \u201cASMR > resting-state\u201d contrast. The default mode networks with seed regions of   (A)   the posterior cingulate cortex (PCC),   (B)   left lateral parietal cortex (lLPC), and   (C)   right lateral parietal cortex (rLPC).   (D)   The self-network with the pregenual anterior cingulate cortex (pACC) seed region.   (E)   Affective touch network with the posterior insular cortex (Ig2) seed region. There were no significant clusters in the default mode network with the mPFC seed region and the other-network with the PCC/PC seed region. \n    \nStatistical significance of the group-level functional connectivity obtained by the \u201cASMR > resting-state\u201d contrast. \n    \nThe beta-values of the group-level functional connectivity for ASMR, resting-state, and ASMR > resting-state contrast are provided in  . \n\n\n### Behavioral Data \n  \nThere was a significant overall main effect on the affective response while watching ASMR video clips. As shown in  , participants had the most increase in low-activation positive state during the ASMR condition among four affective states that we have considered: LAP (group mean \u00b1 standard deviation: 3.94 \u00b1 1.46), HAP (1.51 \u00b1 0.63), LAN (1.45 \u00b1 0.64), and HAN (1.38 \u00b1 0.78). Statistical significance of the comparison between two selected states are as follows: LAP > HAP [beta = 2.429,   t   = 8.349,   p   = 5.86 \u00d7 10 , df = 27, 95% confidence interval of the mean = (1.832\u20133.025); LAP > LAN (beta = 2.488,   t   = 8.471,   p   = 4.39 \u00d7 10 , df = 27, 95% confidence interval of the mean = (1.885\u20133.091); LAP > HAN (beta = 2.560,   t   = 7.638,   p   = 3.25 \u00d7 10 , df = 27, 95% confidence interval of the mean = (1.872\u20133.247)].   summarizes the statistical significance of affective states in response to ASMR. \n  \nSummary of the results showing changes in affect state after viewing ASMR, relative to before watching ASMR. Bar graphs represent group mean scores for affective state assessed using the Multi-Affect Indicator ( ). All variables range from 1 to 7. For self-reported changes in affect, 1 = much less; 7 = much more. The participants had the most increase in low-activation positive state during the ASMR condition among four affective states: low-activation positive state (group mean \u00b1 standard deviation: 3.94 \u00b1 1.46), high-activation positive state (1.51 \u00b1 0.63), low-activation negative state (1.45 \u00b1 0.64), and high-activation negative state (1.38 \u00b1 0.78). Statistical significance was determined by a   p  -value of less than 0.05. \n    \nMean and standard deviation of behavioral score among emotional states. \n    \nCorrelation coefficients between each of the four affective states and ASMR condition-specific connectivity changes are summarized in  . In the DMN with the PCC seed region, significantly negative correlation was estimated between HAN and clusters with peaks in the lingual gyrus. Associations of HAP with clusters of the cuneus and lingual gyrus were also negatively correlated. In the affective touch and self-/other-networks, there were no significant correlation between the affective state scores and the ASMR-condition specific connectivity changes. \n  \nStatistical results of correlation coefficients between each of the four affective states and ASMR condition-specific connectivity changes. \n    \n\n\n## Discussion \n  \nIn this study, we sought to test whether changes in functional connectivity within specific networks, including the DMN, affective touch network, and self-/other-networks occurred during ASMR. As a result, relative to connectivity in the resting-state, significantly altered connectivity of seed regions during viewing of ASMR-eliciting stimulus was found in the main hub composing each network. Furthermore, we confirmed that the strength of connectivity in involved in visual information processing was negatively correlated with the behavior score, including the HAN, and HAP states. We now discuss the implications of these results in more detail. \n\n### Default Mode Network (ASMR > REST) \n  \nOur results showed that in the DMN, functional connectivity between the PCC seed region and the superior/middle temporal gyri, cuneus, and lingual gyrus were significantly increased during ASMR condition, compared to the resting-state. Previous functional imaging studies ( ;  ) have found that the PCC and superior temporal gyrus (STG) are involved in the \u201cmentalizing,\u201d also known as \u201ctheory of mind\u201d that is an ability to make inferences about other people\u2019s mental states [i.e., an understanding that the behaviors of others is determined by their desires, attitude, and beliefs ( )]. Specifically,   revealed that the superior temporal region was activated while watching silent or computer-presented animations, and this process was related to the attribution of mental states.   reported significantly increased cerebral blood flow in the PCC during the condition necessitating the attribution of mental task. Therefore, the increased functional connectivity between the STG and PCC during ASMR condition can be associated with the increased covariance of the STG and the PCC activities compared to the resting-state, which may be interpreted as activation of mentalizing process to infer others\u2019 mental and emotional states by observing objects and perceiving intended actions and using ourselves to simulate their experience to understand them ( ;  ;  ;  ;  ). \n\nWe also found the reduced connectivity between the dorsolateral prefrontal cortex (dlPFC) and the PCC during ASMR condition, compared with the resting-state.   reported that the dlPFC was involved in inhibition processing such as voluntary suppression of a negative emotion (sadness) while the participants suppressed their emotional reaction to the sad stimuli. For the PCC, this region has been known to be a part of network for emotion evaluation ( ), including an automatic perception for the emotion salience of stimulus ( ). Thus, compared to the resting state, the decreased functional connectivity between the dlPFC and PCC during ASMR condition can be interpreted as the decrease in voluntary suppression of negative emotion. This process may occur due to the nature of ASMR triggers that often lead to response of psychologically pleasant effects ( ). \n\nWith the DMN of the bilateral LPC seed regions, we found that the functional connectivity between the l/rLPC seeds and the visual areas of the cuneus and calcarine sulcus was significantly higher during the ASMR condition than during the resting-state. The cuneus is involved in visual information processing that interacts with the primary visual cortex ( ) and is known to integrate somatosensory information with other sensory stimuli ( ). In addition, the LPC is involved in receiving a visual input from the occipital regions, which belong to the dorsal stream of visual processing ( ). In terms of the visual stimuli, in our experiment, ASMR-eliciting video clips were much richer in visual information than the instruction for resting-state condition (with eyes fixated on a cross). Therefore, greater functional connectivity of the cuneus and calcarine sulcus within the DMN may reflect the increased visual input and processing from ASMR-eliciting stimuli through functional connectivity, compared to the resting-state condition. \n\n\n### Affective Touch and Self-Networks (ASMR > REST) \n  \nThis study showed significant connectivity differences not only in the DMN but also in other network areas, including affective touch network, and self-network. In terms of the affective touch network, we found a greater connectivity between the Ig2 and the cuneus of the occipital region during the ASMR condition than the resting-state. The cuneus is a part of the visual areas and engages in processing of visual input ( ) and the insular cortex integrates information from multiple modalities, including visual and auditory sensory modalities ( ). Thus, the increased connection between Ig2 and cuneus indicates the higher visuoauditory influence of ASMR stimulus. \n\nIn terms of the self-network involved in the reflection of one\u2019s own experiences against other stimuli ( ), we found an increased connectivity between the pACC and the mPFC during ASMR condition, compared to resting-state.   revealed that the mPFC and dorsal anterior cingulate cortex were activated in the self-referencing processing state rather than the other-relevant processing, and   showed that these regions were particularly involved in self-referential processing in emotion domain. In addition,   reported that cortical midline structures including the mPFC and pACC mediate self-referential processing in psychological or physical domain such as autobiographical, emotional, and motor stimuli. Therefore, the increased connectivity between the pACC and the mPFC during ASMR may reflect the self-referential processing triggered by ASMR stimulus. \n\n\n### Correlation Between Connectivity and Affective State \n  \nAlthough the major focus of this study is the connectivity on which the effects of ASMR are neural underpinnings, a correlation analysis was performed to investigate how these changed connections relate to the feelings felt during ASMR. As a result, in the PCC region, significantly negative correlation was estimated between clusters with peaks in the lingual gyrus and HAN. For rLPC seed region, connectivities in clusters of the lingual gyrus and cuneus were also negatively correlated in HAP. The PCC receives visual information from visual systems ( ) and the LPC also accepts visual input through dorsal stream ( ). The ASMR stimulus contains audio-visual stimuli that lead to a positive emotional response to calmness and a tingling sensation that emerges from a positive emotion ( ). Thus, these results imply that visual information processing in response to high arousal states can be weakened by ASMR-eliciting stimuli. \n\nAs a limitation of this finding, we did not explicitly measure the affective outcomes of resting state using the behavioral questionnaire [e.g., the Multi-Affect Indicator ( ;  )]. As described in the Behavioral Data Analysis section, the participants were instructed to indicate how they felt while watching the ASMR video clip during the MRI scan, compared to before they watched the video. Therefore, individual behavioral scores that we measured may reflect relative affective states of ASMR condition to resting state. However, a control acquisition of the behavioral questionnaire after the resting state session would be required to compare the affective state changes between resting-state and ASMR conditions more explicitly. Thus, caution should be exercized when interpreting the correlation coefficient between functional connectivity estimates and behavioral scores used in this study. \n\nIn conclusion, using fMRI functional connectivity estimates, we explored the ASMR-condition specific connectivity changes in the DMN, self-/other-networks, and the affective touch network. Compared with the resting-state functional connectivity, we found that several connections within the selected networks were significantly altered while watching ASMR video. In particular, the connections between the PCC and the superior temporal gyrus, between the pACC and the mPFC, and between the Ig2 and the cuneus were significantly greater during ASMR condition than resting state. These results suggest that ASMR process can be associated with ongoing interaction between regional activity that are involved in the integration of visual and auditory information followed by the mentalizing and self-referential processing. In terms of the relationship between connectivity and affective state changes, we found that ASMR-induced affective states (i.e., high activation negative and high activation positive state) were significantly negatively correlated with functional connectivity involved in visual information processing. These results imply that high arousal states can be attenuated in the process of perception of ASMR-eliciting stimuli. Our findings have implications for neurophysiological mechanisms of an ASMR effects in relation to functional connectivity changes. \n\n\n\n## Data Availability Statement \n  \nThe fMRI data that support the findings of this study are available from the corresponding author on request. \n\n\n## Ethics Statement \n  \nThe studies involving human participants were reviewed and approved by the Institutional Review Board of Korea Basic Science Institute. The patients/participants provided their written informed consent to participate in this study. \n\n\n## Author Contributions \n  \nSL designed the study. SL and JK conducted the experiment and performed the fMRI data acquisition. SL and ST performed the data analysis, discussed the study idea, analysis, and results, and wrote the manuscript. All authors reviewed the manuscript. \n\n\n## Conflict of Interest \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n## ID: T1\n### Label: TABLE 1\nConnectivity (ASMR)\tBrodmann area\tMNI (x,y,z)\tSize\tPeak-T\tPeak-beta\tSize p-FDR\nPCC seed\t\t\t\t\t\t\nPrecuneus\tBA 7\t(\u22122, \u221264, 40)\t25801.0\t30.715\t0.977\t0.0\nMedial frontal gyrus\tBA 10\t(4, 50, \u22126)\t12173.0\t11.445\t0.342\t0.0\nAngular gyrus\tBA 39\t(54, \u221262, 34)\t6167.0\t14.407\t0.436\t0.0\nInsular cortex\tBA 48\t(\u221236, 4, 2)\t1195.0\t\u22128.276\t\u22120.170\t0.0\nCuneus\tBA 18\t(\u221226, \u2212100, \u22128)\t631.0\t\u22127.666\t\u22120.169\t0.0\nSupramarginal gyrus\tBA 1\t(64, \u221224, 48)\t355.0\t\u22125.303\t\u22120.204\t0.0\nCuneus\tBA 17\t(20, \u2212102, \u22124)\t221.0\t\u22125.441\t\u22120.144\t0.0\nSuperior frontal gyrus\tBA 8\t(22, 4, 54)\t151.0\t\u22125.831\t\u22120.135\t4e-05\nmPFC seed\t\t\t\t\t\t\nMedial frontal gyrus\tBA 10\t(2, 60, \u22122)\t22584.0\t29.669\t1.241\t0.0\nPosterior cingulate cortex\tBA 23\t(6, \u221250, 22)\t6927.0\t14.525\t0.562\t0.0\nAngular gyrus\tBA 39\t(\u221250, \u221266, 32)\t2558.0\t11.710\t0.487\t0.0\nPostcentral gyrus\tBA 40\t(54, \u221232, 40)\t1832.0\t\u22126.744\t\u22120.229\t0.0\nSuperior temporal gyrus\tBA 21\t(60, \u221258, 20)\t1715.0\t10.946\t0.397\t0.0\nInferior temporal gyrus\tBA 20\t(54, \u22124, \u221236)\t1659.0\t8.214\t0.256\t0.0\nInferior frontal gyrus\tBA 45\t(\u221244, 38, 16)\t251.0\t\u22125.211\t\u22120.241\t0.0\nSuperior temporal gyrus\tBA 38\t(36, 20, \u221236)\t146.0\t6.139\t0.163\t6e-05\nParahippocampal gyrus\tBA 30\t(26, \u221232, \u221216)\t144.0\t5.305\t0.132\t6e-05\nInferior frontal gyrus\tBA 45\t(46, 38, 4)\t109.0\t\u22125.598\t\u22120.212\t0.00046\nlLPC seed\t\t\t\t\t\t\nSuperior fontal gyrus\tBA 8\t(24, 32, 48)\t16420.0\t14.658\t0.390\t0.0\nAngular gyrus\tBA 39\t(\u221244, \u221272, 32)\t15617.0\t25.964\t1.003\t0.0\nAngular gyrus\tBA 39\t(46, \u221270, 36)\t5690.0\t18.819\t0.645\t0.0\nFusiform gyrus\tBA 37\t(36, \u221234, \u221220)\t408.0\t7.241\t0.186\t0.0\nrLPC seed\t\t\t\t\t\t\nMiddle frontal gyrus\tBA 8\t(26, 30, 52)\t17027.0\t14.827\t0.480\t0.0\nSuperior temporal gyrus\tBA 39\t(52, \u221260, 26)\t7214.0\t24.514\t0.901\t0.0\nCuneus\tBA 18\t(2, \u221270, 30)\t7204.0\t17.547\t0.501\t0.0\nMiddle temporal gyrus\tBA 39\t(\u221244, \u221268, 26)\t4980.0\t20.052\t0.566\t0.0\nMiddle temporal gyrus\tBA 20\t(\u221254, \u22128, \u221222)\t2654.0\t9.443\t0.267\t0.0\nInsular cortex\tBA 13\t(42, 6, \u22124)\t694.0\t\u22127.820\t\u22120.210\t0.0\nFusiform gyrus\tBA 37\t(\u221230, \u221236, \u221216)\t358.0\t7.388\t0.271\t0.0\nParahippocampal gyrus\tBA 36\t(30, \u221220, \u221228)\t316.0\t5.600\t0.147\t0.0\nInsular cortex\tBA 48\t(\u221236, 14, 8)\t197.0\t\u22126.373\t\u22120.135\t0.0\npACC seed\t\t\t\t\t\t\nAnterior cingulate cortex\tBA 32\t(\u22122, 38, 16)\t25640.0\t46.025\t2.517\t0.0\nInferior temporal gyrus\tBA 20\t(\u221260, \u221256, \u221216)\t2289.0\t\u22128.354\t0.160\t0.0\nInferior parietal lobule\tBA 48\t(\u221244, \u221234, 32)\t2285.0\t\u22122.731\t\u22120.079\t0.0\nPrecuneus\tBA 7\t(8, \u221260, 70)\t2062.0\t\u22129.274\t\u22120.176\t0.0\nMiddle occipital gyrus\tBA 37\t(50, \u221264, \u221210)\t1555.0\t\u22126.903\t\u22120.132\t0.0\nInferior parietal cortex\tBA 18\t(58, \u221250, 50)\t365.0\t6.027\t0.150\t0.0\nPCC/PC seed\t\t\t\t\t\t\nMiddle frontal gyrus\tBA 8\t(26, 40, 44)\t12514.0\t12.037\t0.453\t0.0\nPrecuneus\tBA 23\t(2, \u221262, 26)\t8240.0\t51.265\t2.433\t0.0\nAngular gyrus\tBA 39\t(\u221244, \u221262, 26)\t2753.0\t12.495\t0.521\t0.0\nMiddle temporal gyrus\tBA 21\t(\u221266, \u221228, \u22128)\t2310.0\t8.849\t0.229\t0.0\nAngular gyrus\tBA 39\t(54, \u221262, 34)\t2107.0\t13.294\t0.493\t0.0\nInferior temporal gyrus\tBA 20\t(56, \u22124, \u221238)\t1751.0\t11.132\t0.212\t0.0\nInsular cortex\tBA 48\t(48, 12, 4)\t1197.0\t\u22127.101\t\u22120.226\t0.0\nSupramarginal gyrus\tBA 2\t(54, \u221234, 38)\t1075.0\t\u22127.354\t\u22120.264\t0.0\nInsular cortex\tBA 48\t(\u221236, 2, \u22124)\t905.0\t\u22127.141\t\u22120.165\t0.0\nMiddle frontal gyrus\tBA 46\t(\u221240, 54, 8)\t837.0\t\u22128.354\t\u22120.215\t0.0\nInferior frontal gyrus\tBA 45\t(44, 40, 2)\t712.0\t\u22126.300\t\u22120.239\t0.0\nMiddle occipital gyrus\tBA 18\t(\u221230, \u221290, 8)\t486.0\t\u22127.160\t\u22120.167\t0.0\nFusiform gyrus\tBA 37\t(\u221230, \u221236, \u221216)\t342.0\t7.493\t0.204\t0.0\nParahippocampal gyrus\tBA 35\t(26, \u221222, \u221224)\t229.0\t9.158\t0.199\t0.0\nSuperior temporal gyrus\tBA 38\t(40, 20, \u221234)\t172.0\t5.631\t0.157\t6e-05\nMiddle occipital gyrus\tBA 37\t(\u221250, \u221262, \u221210)\t124.0\t\u22126.009\t\u22120.159\t0.0001\nIg2 seed\t\t\t\t\t\t\nInsular cortex\tBA 13\t(42, \u221214, \u22128)\t9980.0\t63.964\t0.669\t0.0\nPostcentral gyrus\tBA 40\t(\u221258, \u221226, 16)\t9729.0\t16.404\t0.298\t0.0\nAnterior cingulate cortex\tBA 24\t(4, 22, 24)\t6178.0\t11.215\t0.209\t0.0\nCuneus\tBA 18\t(\u221212, \u221272, 6)\t5566.0\t10.453\t0.163\t0.0\nMiddle frontal gyrus\tBA 46\t(\u221232, 44, 22)\t329.0\t7.780\t0.154\t0.0\nMiddle frontal gyrus\tBA 9\t(38, 26, 54)\t184.0\t\u22125.517\t\u22120.085\t0.0\n### Caption\nStatistical significance of the group-level functional connectivity generated during ASMR condition.\n### Footer\nWe report clusters having significant connections from the seed region, cluster size, and the peak-voxel location in each cluster.\n\n\n## ID: T2\n### Label: TABLE 2\nConnectivity (Resting state)\tBrodmann area\tMNI (x,y,z)\tSize\tPeak-T\tPeak-beta\tSize p-FDR\nPCC seed\t\t\t\t\t\t\nPrecuneus\tBA 7\t(\u22122, \u221264, 40)\t22585.0\t33.057\t0.930\t0.0\nMedial frontal gyrus\tBA 11\t(8, 54, \u221212)\t8607.0\t11.036\t0.303\t0.0\nMiddle frontal gyrus\tBA 9\t(\u221228, 42, 42)\t2296.0\t9.627\t0.263\t0.0\nInsular cortex\tBA 22\t(50, 2, \u22122)\t1748.0\t\u22127.633\t\u22120.161\t0.0\nMiddle temporal gyrus\tBA 21\t(52, 0, \u221226)\t613.0\t7.965\t0.195\t0.0\nMiddle temporal gyrus\tBA 21\t(\u221262 0 \u221226)\t311.0\t6.144\t0.133\t0.0\nmPFC seed\t\t\t\t\t\t\nMedial orbital gyrus\tBA 11\t(0, 50, \u221210)\t23406.0\t27.766\t1.122\t0.0\nPosterior cingulate cortex\tBA 23\t(\u221210, \u221254, 22)\t6945.0\t16.959\t0.422\t0.0\nSupramarginal gyrus\tBA 40\t(44, \u221234, 38)\t4216.0\t\u22129.262\t\u22120.150\t0.0\nInferior parietal lobe\tBA 40\t(\u221238, \u221242, 44)\t4023.0\t\u22128.222\t\u22120.270\t0.0\nAngular gyrus\tBA 39\t(\u221246, \u221264, 30)\t2171.0\t13.206\t0.383\t0.0\nAngular gyrus\tBA 39\t(52, \u221268, 34)\t1983.0\t12.751\t0.433\t0.0\nInferior temporal gyrus\tBA 37\t(\u221258, \u221260, \u22128)\t877.0\t\u22127.902\t\u22120.191\t0.0\nFusiform gyrus\tBA 37\t(54, \u221250, \u221224)\t812.0\t\u22129.106\t\u22120.167\t0.0\nParahippocampal gyrus\tBA 30\t(24, \u221220, \u221224)\t571.0\t7.417\t0.230\t0.0\nInferior frontal gyrus\tBA 44\t(\u221248, 8, 20)\t422.0\t\u22125.921\t\u22120.175\t0.0\nMiddle occipital gyrus\tBA 18\t(34, \u221292, 10)\t384.0\t9.068\t0.194\t0.0\nlLPC seed\t\t\t\t\t\t\nSuperior frontal gyrus\tBA 8\t(\u221230, 24, 58)\t27546.0\t14.534\t0.440\t0.0\nAngular gyrus\tBA 19\t(\u221240, \u221274, 38)\t12347.0\t28.357\t0.992\t0.0\nMiddle temporal gyrus\tBA 39\t(40, \u221266, 28)\t4118.0\t18.926\t0.446\t0.0\nMiddle temporal gyrus\tBA 20\t(\u221260, \u221244, \u221214)\t1331.0\t12.042\t0.366\t0.0\nSuperior temporal gyrus\tBA 38\t(\u221252, 2, \u22124)\t788.0\t\u22126.582\t\u22120.190\t0.0\nParahippocampal gyrus\tBA 36\t(26, \u221228, \u221220)\t615.0\t8.237\t0.154\t0.0\nFusiform gyrus\tBA 37\t(\u221228, \u221238, \u221218)\t551.0\t11.315\t0.353\t0.0\nMiddle cingulate cortex\tBA 32\t(\u22128, 16, 36)\t355.0\t\u22125.982\t\u22120.151\t0.0\nSupramarginal gyrus\tBA 40\t(\u221252, \u221226, 14)\t180.0\t\u22125.442\t\u22120.158\t0.0\nCuneus\tBA 18\t(22, \u221288, 8)\t161.0\t\u22125.987\t\u22120.166\t1e-05\nrLPC seed\t\t\t\t\t\t\nMiddle frontal gyrus\tBA 8\t(28, 32, 52)\t17537.0\t17.430\t0.542\t0.0\nSuperior temporal gyrus\tBA 39\t(48, \u221258, 22)\t10591.0\t25.784\t0.839\t0.0\nMiddle temporal gyrus\tBA 39\t(\u221242, \u221264, 24)\t4687.0\t21.402\t0.546\t0.0\nMiddle temporal gyrus\tBA 20\t(\u221260, \u221244, \u221214)\t2905.0\t10.013\t0.275\t0.0\nMiddle temporal gyrus\tBA 21\t(52, \u22124, \u221226)\t2185.0\t9.641\t0.289\t0.0\nInsular cortex\tBA 13\t(40, 4, \u22122)\t1521.0\t\u22126.337\t\u22120.207\t0.0\nParahippocampal gyrus\tBA 30\t(26, \u221220, \u221224)\t653.0\t7.891\t0.215\t0.0\nFusiform gyrus\tBA 37\t(\u221228, \u221238, \u221216)\t652.0\t8.397\t0.235\t0.0\nMiddle cingulate cortex\tBA 24\t(2, 16, 40)\t342.0\t\u22126.416\t\u22120.188\t0.0\nCuneus\tBA 19\t(22, \u221282, 18)\t193.0\t\u22125.855\t\u22120.159\t0.0\nLingual gyrus\tBA 18\t(\u221210, \u221264, \u22126)\t160.0\t\u22125.583\t\u22120.132\t2e-05\npACC seed\t\t\t\t\t\t\nAnterior cingulate cortex\tBA 32\t(\u22122, 38, 16)\t24791.0\t53.786\t2.502\t0.0\nInferior parietal cortex\tBA 7\t(34, \u221250, 58)\t1299.0\t\u22127.197\t\u22120.170\t0.0\nFusiform gyrus\tBA 20\t(54, \u221236, \u221226)\t368.0\t\u22129.512\t\u22120.128\t0.0\nParacentral lobule\tBA 4\t(\u221214, \u221238, 64)\t143.0\t\u22124.862\t\u22120.105\t5e-05\nPCC/PC seed\t\t\t\t\t\t\nSuperior frontal gyrus\tBA 10\t(\u22124, 64, \u22126)\t11827.0\t14.727\t0.388\t0.0\nPrecuneus\tBA 23\t(2, \u221262, 26)\t7292.0\t49.964\t2.393\t0.0\nInsular cortex\tBA 48\t(34, 16, 6)\t3232.0\t\u221213.322\t\u22120.252\t0.0\nMiddle temporal gyrus\tBA 38\t(\u221242, 14, \u221232)\t2957.0\t8.952\t0.193\t0.0\nMiddle temporal gyrus\tBA 39\t(\u221248, \u221266, 28)\t2802.0\t13.988\t0.515\t0.0\nSupramarginal gyrus\tBA 2\t(66, \u221224, 28)\t2555.0\t\u221211.081\t\u22120.281\t0.0\nSuperior temporal gyrus\tBA 39\t(56, \u221260, 28)\t2461.0\t15.897\t0.506\t0.0\nMiddle temporal gyrus\tBA 21\t(54, \u22122, \u221226)\t2302.0\t9.784\t0.345\t0.0\nMiddle cingulate cortex\tBA 32\t(6, 14, 42)\t996.0\t\u22128.940\t\u22120.169\t0.0\nMiddle frontal gyrus\tBA 46\t(\u221232, 46, 28)\t790.0\t\u22127.645\t\u22120.208\t0.0\nParahippocampal gyrus\tBA 36\t(28, \u221216, \u221230)\t743.0\t8.167\t0.155\t0.0\nPrecuneus\tBA 7\t(\u221212, \u221258, 60)\t388.0\t\u22125.490\t\u22120.142\t0.0\nIg2 seed\t\t\t\t\t\t\nInsular cortex\tBA 13\t(42, \u221212, \u22128)\t13955.0\t59.166\t1.709\t0.0\nMiddle cingulate cortex\tBA 31\t(6, \u221252, 32)\t6103.0\t\u22126.661\t\u22120.146\t0.0\nParahippocampal gyrus\tBA 30\t(\u221220, \u221242, \u22128)\t464.0\t5.728\t0.108\t0.0\nCuneus\tBA 18\t(16, \u221272, 8)\t157.0\t6.563\t0.129\t3e-05\nMiddle frontal gyrus\tBA 10\t(4, 68, 18)\t121.0\t\u22126.164\t\u22120.081\t5e-05\n### Caption\nStatistical significance of the group-level functional connectivity generated during resting-state condition.\n### Footer\nWe report clusters having significant connections from the seed region, cluster size, and the peak-voxel location in each cluster.\n\n\n## ID: T3\n### Label: TABLE 3\nConnectivity (ASMR > REST)\tBrodmann area\tMNI (x,y,z)\tSize\tPeak-t\tPeak-beta\tPeak p-unc\tSize p-FDR\nPCC seed\t\t\t\t\t\t\t\nCuneus\tBA 18\t(8, \u221274, 22)\t1451.0\t8.799\t0.283\t0.0\t0.0\nSuperior frontal gyrus\tBA 6\t(24, 4, 56)\t176.0\t\u22125.498\t\u22120.159\t0.0\t1e-05\nVisual area\tBA 18\t(10, \u221290, \u22126)\t173.0\t\u22126.020\t\u22120.207\t0.0\t1e-05\nLingual gyrus\tBA 18\t(\u221218, \u221270, 2)\t59.0\t4.290\t0.176\t0.00021\t0.01692\nPrecuneus\tBA 7\t(6, \u221266, 48)\t49.0\t\u22124.552\t\u22120.171\t0.0001\t0.02626\nSuperior temporal gyrus\tBA 48\t(54, 0, 0)\t49.0\t4.840\t0.178\t4e-05\t0.02626\nSuperior temporal gyrus\tBA 22\t(\u221254, \u22122, \u22128)\t42.0\t5.822\t0.158\t0.0\t0.0421\nPrecuneus\tBA 7\t(\u22126, \u221264, 66)\t37.0\t\u22124.331\t\u22120.219\t0.00018\t0.04281\nMiddle frontal gyrus\tBA 8\t(\u221224, 16, 58)\t37.0\t\u22124.434\t\u22120.177\t0.00014\t0.04281\nMiddle occipital lobe\tBA 39\t(40, \u221278, 24)\t37.0\t\u22124.187\t\u22120.200\t0.00027\t0.04281\nMiddle temporal gyrus\tBA 21\t(\u221262, \u221220, \u22126)\t37.0\t5.742\t0.140\t0.0\t0.04281\nlLPC seed\t\t\t\t\t\t\t\nVisual area\tBA 17\t(\u22126, \u221278, 16)\t526.0\t5.702\t0.186\t0.0\t0.0\nSuperior temporal gyrus\tBA 22\t(\u221256, \u221232, 10)\t266.0\t5.599\t0.168\t0.0\t0.0\nPrecuneus\tBA 7\t(\u22126, \u221266, 50)\t118.0\t\u22125.131\t\u22120.176\t2e-05\t0.00296\nrLPC seed\t\t\t\t\t\t\t\nCuneus\tBA 18\t(8, \u221276, 22)\t1014.0\t5.812\t0.211\t0.0\t0.0\nLingual gyrus\tBA 18\t(\u221214, \u221264, \u22126)\t113.0\t5.501\t0.187\t0.0\t2e-05\npACC seed\t\t\t\t\t\t\t\nMiddle frontal lobe\tBA 9\t(\u221250, 18, 44)\t53.0\t4.426\t0.183\t0.00014\t0.03391\nIg2 seed\t\t\t\t\t\t\t\nCuneus\tBA 17\t(\u221210, \u221268, 6)\t301.0\t5.565\t0.143\t0.0\t0.0\n### Caption\nStatistical significance of the group-level functional connectivity obtained by the \u201cASMR > resting-state\u201d contrast.\n### Footer\nWe report clusters having significant connections from the seed region, the peak-voxel location in each cluster, and the corresponding t-, beta-, and p-values.\n\n\n## ID: T4\n### Label: TABLE 4\nItem\tAverage score\tAverage score.1\tStandard deviation\tStandard deviation.1\tStandard deviation.2\nNervous\t1.464\t\t0.865\t\t\nAnxious\t1.321\t\t0.847\t\t\nTense\t1.357\t\t0.934\t\t\nHAN\t1.381\t\t0.775\t\t\nDepressed\t1.214\t\t0.619\t\t\nDejected\t2.107\t\t1.496\t\t\nHopeless\t1.036\t\t0.186\t\t\nLAN\t1.452\t\t0.644\t\t\nEnthusiastic\t1.536\t\t0.906\t\t\nJoyful\t1.786\t\t1.013\t\t\nExcited\t1.214\t\t0.674\t\t\nHAP\t1.512\t\t0.627\t\t\nCalm\t3.964\t\t1.742\t\t\nRelaxed\t4.071\t\t1.731\t\t\nAt ease\t3.786\t\t1.820\t\t\nLAP\t3.940\t\t1.456\t\t\n\t\t\t\t\t\nPaired t-test\tp\tt\tbeta\t(95% CI)\tdf\n\t\t\t\t\t\nLAP-HAP\t0.00000\t8.349\t2.429\t(1.832\u20133.025)\t27\nLAP-LAN\t0.00000\t8.471\t2.488\t(1.885\u20133.091)\t27\nLAP-HAN\t0.00000\t7.638\t2.560\t(1.872\u20133.247)\t27\nHAP-LAN\t0.6858\t0.409\t0.060\t(-0.239\u20130.358)\t27\nHAP-HAN\t0.4957\t0.691\t0.131\t(-0.258\u20130.520)\t27\nLAN-HAN\t0.6078\t0.519\t0.071\t(-0.211\u20130.354)\t27\n### Caption\nMean and standard deviation of behavioral score among emotional states.\n### Footer\nWe report t-test results for comparing affective states during ASMR. HAN, High-activation negative state; LAN, Low-activation negative state; HAP, High-activation positive state; LAP, Low-activation positive state; df, Degrees of freedom.\n\n\n## ID: T5\n### Label: TABLE 5\nConnectivity-behavioral correlation\tMNI (x,y,z)\tr\tp\nPCC seed\t\t\t\nHAN-Lingual gyrus *\t(\u221218, \u221270, 2)\t\u22120.411\t0.03\nrLPC seed\t\t\t\nHAP\u2212Cuneus **\t(8, \u221276, 22)\t\u22120.5085\t0.006\nHAP\u2212Lingual gyrus**\t(\u221214, \u221264, \u22126)\t\u22120.497\t0.007\n### Caption\nStatistical results of correlation coefficients between each of the four affective states and ASMR condition-specific connectivity changes.\n### Footer\n**p\u2013value < 0.01, *p\u2013value < 0.05. PCC, Posterior cingulate cortex; rLPC, Right lateral parietal cortex. HAN, High-activation negative state; HAP, High-activation positive state.\n", "metadata": {"pmcid": 7481390, "text_md5": "2bea9fff9d7c3734e5b783a1e9d6c024", "field_positions": {"authors": [0, 45], "journal": [46, 66], "publication_year": [68, 72], "title": [83, 214], "keywords": [228, 385], "abstract": [398, 2131], "body": [2140, 38114], "tables": [38127, 49943]}, "batch": 2, "pmid": 33192358, "doi": "10.3389/fnbeh.2020.00154", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7481390", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7481390"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7481390\">7481390</a>", "list_title": "PMC7481390  Effects of Autonomous Sensory Meridian Response on the Functional Connectivity as Measured by Functional Magnetic Resonance Imaging"}
{"text": "Luo, Yangmei and Huang, Xiting and Yang, Zhen and Li, Baolin and Liu, Jie and Wei, Dongtao\nPLoS One, 2014\n\n# Title\n\nRegional Homogeneity of Intrinsic Brain Activity in Happy and Unhappy Individuals\n\n# Keywords\n\n\n\n# Abstract\n \n## Background \n  \nWhy are some people happier than others? This question has intrigued many researchers. However, limited work has addressed this question within a neuroscientific framework. \n\n\n## Methods \n  \nThe present study investigated the neural correlates of trait happiness using the resting-state functional magnetic resonance imaging (rs-fMRI) approach. Specifically, regional homogeneity (ReHo) was examined on two groups of young adults: happy and unhappy individuals (N\u200a=\u200a25 per group). \n\n\n## Results \n  \nDecreased ReHo in unhappy relative to happy individuals was observed within prefrontal cortex, medial temporal lobe, superior temporal lobe, and retrosplenial cortex. In contrast, increased ReHo in unhappy relative to happy individuals was observed within the dorsolateral prefrontal cortex, middle cingulate gyrus, putamen, and thalamus. In addition, the ReHo within the left thalamus was negatively correlated with Chinese Happiness Inventory (CHI) score within the happy group. \n\n\n## Limitations \n  \nAs an exploratory study, we examined how general trait happiness is reflected in the regional homogeneity of intrinsic brain activity in a relatively small sample. Examining other types of happiness in a larger sample using a multitude of intrinsic brain activity indices are warranted for future work. \n\n\n## Conclusions \n  \nThe local synchronization of BOLD signal is altered in unhappy individuals. The regions implicated in this alteration partly overlapped with previously identified default mode network, emotional circuitry, and rewarding system, suggesting that these systems may be involved in happiness. \n\n \n\n# Body\n \n## Introduction \n  \nAlthough happiness is almost everyone's pursuit, the capacity to be happy varies widely across people. Why are some people happier than others? A large amount of correlational research addressed this question by examining the associations between happiness and a diverse range of factors, such as wealth, marriage, and life events  . Rather than focusing on the objective determinants of happiness, the construal theory focused on explaining the individual differences in happiness with hedonically related subjective psychological processes such as self-evaluation, self-reflection, self-regulation, social comparison, and person perception  ,  . This theory suggests that our alternative perspectives (either positive or negative) and our constructions of reality have different hedonic consequences and, as such, are associated with different levels of enduring happiness  . Within this framework, a wealth of behavioral studies have shown that happy and unhappy individuals have their own temperaments in hedonically related cognitive and motivational processes. Specifically, happy individuals, unlike their unhappy peers, appear to spend less time on self-reflection, are less sensitive to negative achievement feedback  , experience positive emotion most of the time  , have superior self-regulation abilities to maintain positive affective information in working memory  , and have rich and more satisfying social relationships  . \n\nTo date, limited work has investigated happiness within a neuroscientific framework  . Only a handful of studies have directly addressed the neural bases of trait happiness, which characterizes individuals' characteristic level of happiness during a particular period of time  . One resting-state electroencephalography (EEG) study revealed that individuals with greater activation in the left rather than the right superior prefrontal cortex were happier  . More recently, a structural magnetic resonance imaging (MRI) study demonstrated that eudaimonic happiness, which focuses on meaning and self-realization, was positively associated with gray matter volume in the right insular cortex  . Furthermore, a task-based functional MRI study focusing on emotional processes found that happier individuals showed greater amygdala responses to positive stimuli  . Thus, no resting-state fMRI research has been conducted to examine how trait happiness is reflected in the human brain. \n\nResting-state fMRI research has been blooming during the last couple of decades  \u2013  since the seminal work by Biswal et al (1995)  . Not limited by tasks, this approach has been demonstrated as a powerful tool that can reliably characterize intrinsic brain activity  \u2013 . In the present study, we used regional homogeneity (ReHo)  , a widely used resting-state fMRI measure, to examine whether the local synchronization of spontaneous brain activities was associated with trait happiness. We were particularly interested in this measure for four reasons: (1) as a data-driven method, ReHo dose not require a priori hypothesis and is suitable for exploratory analysis; (2) the test-retest reliability of ReHo is well established. With an optimized acquisition and preprocessing pipeline, ReHo has been demonstrated as a highly reliable measure to map the regional activity of the human functional connectome  ; (3) ReHo is associated with a variety of phenotypic variables, including relatively stable traits such as intelligence   and personality  , suggesting that ReHo is able to capture the trait properties reflected in the intrinsic brain activity; and (4) ReHo has also been shown sensitivity to various neuropsychiatric disorders related to mood/emotional changes, such as depression  ,   and social anxiety disorders  . \n\nIn the current study, we focused on obtaining preliminary knowledge on the neural signature of happiness by examining whether happy and unhappy individuals differed in ReHo. Building on the evidence that happy and unhappy individuals differed in self-evaluation, self-reflection, self-regulation, and person perception  \u2013 , we predict that the two groups will differ in ReHo within regions implicated in these functions. \n\n\n## Materials and Methods \n  \n### Ethics statement \n  \nThis study was approved by the Ethics Committee of the Southwest University. Written informed consent was obtained from all participants and they were informed that they can quit at any time during the experiment. \n\n\n### Participants \n  \nA total of 422 undergraduate students were sampled at the Southwest University in China and assessed with the Subjective Happiness Scale (SHS)   and the Beck depression inventory (BDI)  . Seventy-eight participants were excluded from the current study due to mild to moderate depression (BDI scores >14)   and another 2 participants were excluded due to physical illness. The remaining 342 healthy participants were ranked according to the SHS scores. Given that 25 to 27 percent is most powerful in the extreme groups design  , the upper and the lower 27% were selected as the potential happy and unhappy group. The middle 46% were discarded from the current study. We started with a relatively large sample to anticipate a high dropping rate of the scan. As we expected, a large number of participants in the selected two groups withdrew from the study due to either being unwilling or unavailable to participate the scan. We finally acquired imaging data on 51 participants (see   for participants' number change at each step. happy group: N\u200a=\u200a26, SHS\u200a=\u200a6.50\u00b10.29; unhappy group: N\u200a=\u200a25, SHS\u200a=\u200a3.96\u00b10.45). \n   Participants flow chart.    \nThe four-item SHS has been frequently used to assess overall dispositional happiness and is appropriate for different ages, occupations and cultural groups  . SHS has demonstrated good internal consistency (Cronbach's \u03b1\u200a=\u200a0.86) and high validity with Chinese Happiness Inventory (CHI, full version)   (  r  \u200a=\u200a0.604,   p  <0.001). \n\n\n### Data acquisition \n  \nThe experiment was performed on a 3 Tesla Siemens Tim Trio system (Siemens, Erlangen, Germany). Functional images were acquired using a single-shot, gradient-recalled echo planar imaging sequence (TR\u200a=\u200a2000 ms, TE\u200a=\u200a30 ms, flip angle\u200a=\u200a90\u00b0, 32 axial slices, FOV\u200a=\u200a192 mm\u00d7192 mm, acquisition matrix\u200a=\u200a64\u00d764, slice thickness \u200a=\u200a3 mm, with 1 mm gap, voxel size \u200a=\u200a3 mm\u00d73 mm\u00d74 mm). For each participant, a total of 8 minutes of resting data were acquired. Participants were instructed to simply rest with their eyes closed, not to think of anything in particular, and not to fall asleep. To minimize head motion, participants' heads were restricted with foam cushions. For spatial normalization and localization, high-resolution T1-weighted anatomical images were also acquired in sagittal orientation using a 3D magnetization prepared rapid gradient-echo (MPRAGE) sequence (176 slices, TR\u200a=\u200a1900 ms, TE\u200a=\u200a2.53 ms, flip angle \u200a=\u200a9\u00b0, resolution \u200a=\u200a256\u00d7256, and voxel size \u200a=\u200a1 mm\u00d71 mm\u00d71 mm) on each participant. \n\nFollowing the scan, participants' affective states were assessed with the Positive and Negative Affect Schedule (PANAS)  . To further confirm the effectiveness of grouping using SHS, participants were assessed with CHI within one week after the scan. One participant in each group failed to complete the CHI, leaving 24 participants with valid CHI data in each group. \n\n\n### Data preprocessing \n  \nData were preprocessed using DPARSF (Data Processing Assistant and Resting-State FMRI, version 2.2)   with the following steps: (1) removing the first ten volumes to account for the T1 equilibrium effect, leaving 230 volumes for final analysis; (2) slice timing correction; (3) motion correction by realigning images to the first volume then to the mean functional image; (4) segmenting T1 images into gray matter (GM), white matter (WM) and cerebrospinal fluid (CSF); (5) regressing out 27 nuisance covariates (including signals from WM, CSF, global signal, and Friston 24 motion parameters) to reduce the potential effects of physiological processes and motion. The Friston 24-parameter model (i.e., 6 head motion parameters, 6 head motion parameters one time point before, and the 12 corresponding squared items)   was used to regress out head motion effects based on recent work showing that higher-order models were more effective in removing head motion effects  ,  . The linear trends were also removed; (6) spatially normalizing the functional images to the Montreal Neurological Institute (MNI) space using the standard EPI template in SPM8 and resampling the images at a resolution of 3 mm\u00d73 mm\u00d73 mm; and (7) temporally band-pass filtering (0.01<f<0.08 Hz). \n\nTo further rule out the residual effect of motion on ReHo, volume-level mean framewise displacement (FD) was computed  . Participants with excessive motion (outside of the 3 inter-quartile range) relative to their group were excluded as outliers. One participant from the happy group was identified as an outlier and eliminated from the analyses. The final two groups did not differ in mean FD (  t   \u200a=\u200a0.50,   p  \u200a=\u200a0.42; happy: 0.13\u00b10.06 mm; unhappy: 0.14\u00b10.06 mm). \n\n\n### Individual-level analysis \n  \nFor each individual, a ReHo map was generated using REST (Resting state fMRI data analysis toolkit, version 1.8)  . Specifically, the Kendall's coefficient of concordance (KCC) of each voxel was calculated with its nearest neighbors (26 voxels) in a voxel-wise analysis. The formula for calculating the KCC value has been expounded in a previous study  . To reduce the influence of individual variations in the KCC value, standardization of ReHo maps were done by dividing the KCC of a given voxel by the averaged KCC of the whole brain. Then, the standardized ReHo maps were smoothed with a Gaussian kernel of 4 mm full-width at half-maximum to reduce noise. \n\n\n### Group-level analysis \n  \nOne-sample t-tests were first performed within each group to detect where the standardized KCC values were larger than the global mean KCC. The results were false discovery rate (FDR) corrected at   p  <0.05  . \n\nTo examine the group differences in ReHo, voxel-wised two-sample t-tests were performed on ReHo maps using the statistical program in the REST toolkit. Mean FD and gender were included as nuisance covariates to remove the residual effect of motion and gender effect at the group level. Following previous studies  ,  , the t-map was masked by a grey matter map, which was obtained by segmenting the mean normalized high resolution T1-weighted images of all the participants to include only the areas falling in grey matter. Multiple comparisons were corrected using Monte Carlo simulation (The AlphaSim program in REST software). The Parameters were: single voxel   p  \u200a=\u200a0.01, combined height threshold   p  <0.05 and a cluster size >486 mm , 5000 simulations, FWHM \u200a=\u200a4 mm, cluster connection radius r\u200a=\u200a5 mm). \n\n\n### Brain-behavior relationships \n  \nTo explore whether ReHo correlates with the level of happiness, Pearson's correlations between the mean ReHo extracted from regions showing significant group differences and the subjective happiness scores (SHS and CHI) were computed for happy and unhappy group, respectively. \n\n\n\n## Results \n  \n### Demographical and neuropsychological results \n  \nThe demographical and neuropsychological results were presented in  . The happy and unhappy group did not differ in age and gender (  p  s>0.20) and as expected, significantly differed in subjective happiness measured with SHS and CHI (  p  <0.001). \n   The Sample Characteristics.        \n\n### Group analysis in ReHo \n  \nThe mean ReHo maps for the happy and unhappy group are shown in   (one-sample t-test;   p  <0.05, FDR corrected). The default-mode network (DMN), mainly including the medial prefrontal cortex (MPFC), posterior cingulate cortex (PCC), and bilateral parietal lobel, has higher regional homogeneity than other brain regions ( ). This pattern is similar in the two groups and is consistent with previous studies  ,  ,  . \n   Mean ReHo map for each group.  \nThe t statistical maps for the Happy (top panel) and the Unhappy (bottom panel) group are presented (one-sample t-test,   p  <0.05, FDR corrected). Locations of the axial (Z) slices are given according to MNI space. L: left; R: right. \n  \nThe two-sample t-tests results indicated that several regions were implicated in the significant group differences in ReHo (  and  ). Specifically, compared with the happy individuals, the unhappy individuals exhibited significantly decreased ReHo in the bilateral MPFC, the right ventrolateral prefrontal cortex (VLPFC), the right superior temporal gyrus (STG), the left hippocampus (HP), the right parahippocampal gyrus (PHG), and the left posterior cingulate cortex/retrosplenial cortex (PCC/RSP). In contrast, increased ReHo was observed within the left dorsolateral prefrontal cortex (DLPFC), the right superior frontal gyrus (SFG), the right middle cingulate gyrus (MCG), the right putamen (PT), and the left thalamus (TH). \n   Brain regions exhibiting significant group effect and their mean ReHo scores.  \n Panel A   presents brain regions exhibiting significant group effect (two sample t-tests, thresholded at   p  <0.05, AlphaSim corrected). Statistical maps (lateral, medial and anterior views) were projected onto the PALS (population-average, landmark, and surface-based) atlas using CARET software  . The magnitude and direction of the t scores are represented by either warm (happy > unhappy) or cool (unhappy > happy) coloring. R.H. represents right hemisphere and L.H. represents left hemisphere.   Panel B   presents the mean ReHo scores for the Happy (red bars) and Unhappy (blue bars) group within the regions showing significant group effect. Error bars correspond to the standard error of mean. *:   p  <0.05, **:   p  <0.01, and ***:   p  <0.001. Abbreviations: MPFC_B\u200a=\u200a bilateral medial prefrontal cortex; VLPFC_R \u200a=\u200a right ventrolateral prefrontal cortex; RSP_L \u200a=\u200a left retrosplenial cortex; STG_R \u200a=\u200a right superior temporal gyrus; PHG_R \u200a=\u200a right Parahippocampa Gyrus; HP_L \u200a=\u200a left hippocampus; SFG_R \u200a=\u200a right superior frontal gyrus; DLPFC_L \u200a=\u200a left dorsolateral prefrontal cortex; MCG_R \u200a=\u200a right middle cingulate gyrus; PT_R \u200a=\u200a right Putamen; TH_L \u200a=\u200a left Thalamus. \n     Brain regions exhibiting significant group differences in ReHo.        \n\n### Brain-behavior correlations \n  \nFor the happy group, there was a significant negative correlation between the CHI and the mean ReHo within the left TH ( ,   r  \u200a=\u200a\u22120.43,   p  \u200a=\u200a0.04, uncorrected). No other correlations were significant (  p  s>0.05). \n   The mean ReHo within the left Thalamus (TH_L) is negatively correlated with the Chinese Happiness Inventory (CHI).    \n\n\n## Discussion \n  \nThe present study used resting-state fMRI approach to examine whether local functional homogeneity was modulated by happiness. Significant group differences in ReHo were observed within distributed brain regions over prefrontal cortex, temporal lobe, limbic system and certain subcortical regions, suggesting multiple brain regions were involved in trait happiness. In addition, the ReHo within left thalamus was correlated with CHI in happy group, suggesting that ReHo could be useful for indexing the extent of happiness. Recently, extensive studies have reported altered ReHo in clinical populations with emotional disorders, such as depression  ,   and social anxiety disorders  . The novelty of the current study is that we observed alterations of ReHo in healthy individuals who experience more negative affect. \n\nReHo measures the local synchronization of a given voxel with its nearest neighbors based on the assumption that if a brain region is responsible for a specific function, the voxels within this region were more temporally homogeneous when involved in that function  . The ReHo results during a unilateral finger movement is partly consistent with electrophysiologic studies   and resting state ReHo is of functional relevance and can predict the behavioral performance of a stop signal task  . These results suggest that altered ReHo might reflect changes in the temporal feature of intrinsic neuronal activity. \n\nCompared to happy individuals, unhappy individuals exhibited decreased ReHo within MPFC, VLPFC, medial temporal lobe (MTL), STG, and PCC/RSP cortex. These regions largely overlap the DMN, suggesting the involvement of DMN in happiness. This is supported by the reports that ReHo was altered within the DMN in depression  ,   and bipolar depression disorder  . DMN activity during rest is associated with mind-wandering or stimulus-independent thoughts   and a higher frequency of mind-wandering has been shown to be related to less happiness  . However, recent work demonstrated that it may not be mind-wandering per se that is responsible for psychological distress, but rather the general tendency to be less aware and attentive to the present-moment  . \n\nHappy and unhappy individuals have their own characteristic temperaments. Individuals with lower level of happiness spent more time ruminating on negative feelings, thoughts and shortcomings  ,  ,  , have less satisfying social function  , and envision future with less details  . These characteristics may be explained by the abnormalities in the DMN, which is involved in personal significance evaluation, self-relevant affective decision-makings, present mental states consideration, inference of other individuals' mental states, and envision future events  . The involvement of DMN in happiness also supports the construal theory which suggests self-reflection, self-evaluation, social comparison and personal perception are psychological processes that influence our constructions of reality and have hedonic consequences  . \n\nConverging evidence from lesion, neuroimaging and electrophysiological data supports the view that the prefrontal cortex (PFC) is a key component of the circuitry that implements both positive and negative affect  . In our study, we found that several important subdivisions of PFC are involved in trait happiness, such as MPFC and DLPFC. MPFC played an important role in hedonic evaluation of pleasure valence  . Compared to healthy participants, decreased ReHo was observed in depression  ,   and social anxiety disorder  . Furthermore, after a 6-week duloxetine therapy, ReHo in MPFC in patients with major depressive disorder and panic disorder were significantly increased after the treatment  . Consistent with these studies, we also found decreased ReHo within MPFC for individuals who have lower level of happiness. \n\nIn contrast, higher ReHo was found within left DLPFC for unhappy individuals. One methodological limitation of the ReHo approach is that its biological significance is still unclear, thus it is difficult to interpret the exact meaning of the opposite effects observed within MPFC and DLPFC  . However, our findings support the view that these two regions played different functional roles in emotion  . One main role of DLPFC is executive control  ,  . Happy individuals, relative to unhappy individuals, experienced more positive moods  , this is possibly due to happy people having greater cognitive control abilities to regulate negative emotional experience   and maintain and update positive information in working memory  . Evidence from clinical populations further supports the role of DLPFC in emotional regulation. For example, patients with left DLPFC damage have an increasing likelihood of depressive symptoms   which is associated with deficits in positive affect   In late-life subthreshold depression   and major depressive disorder   patients, abnormal resting-state ReHo and functional connectivity were also reported within this region. \n\nBesides the DLPFC, the right MCG, right putamen, and left thalamus also exhibited increased ReHo in unhappy individuals. Furthermore, the ReHo score within the left thalamus is negatively correlated with CHI scores in happy group. Previous personality neuroimaging studies demonstrated that the volume of MCG was correlated with neuroticism  . Neuroticism is characterized by anxiety, guilt, and emotional instability. Compared with other personality traits, neuroticism is the strongest predictor of happiness  . Thus, the increased regional coherence in unhappy individuals within MCG may suggest that unhappy individuals are less emotionally stable and more reactive to stress, compared with their happy peers. \n\nBoth the striatum  \u2013  and the thalamus  ,   played a critical role in reward processing. Specifically, the putamen is not only involved in processing reward outcome, but also engaged in anticipating a reward  ,   and the thalamus is suggested to be one of the core areas regulating reward processing  . Reward is important for driving incentive-based learning, approaching reward object, and inducing positive emotions  . Dysfunction in reward processing may lead to mood disorders  . Previous studies have reported increased ReHo in right PT in patients with social anxiety disorder  ,  , and greater functional connectivity between TH and subgenual cingulate in patients with depression  . These results support our finding that these two regions were implicated in happiness. \n\nAlthough the current results provided novel information on our understanding of happiness, several limitations need to be considered. First of all, general trait happiness instead of a specific type of happiness was assessed in the current study. As happiness can be divided into hedonic (pleasure attainment and pain avoidance) and eudaimonic components (meaning and self-realization)  , refined studies to elucidate the neural underpinning of different types of happiness are needed. Secondly, although we started with a large initial sample, the final sample size is relatively small, which may decrease the statistical power to detect the correlations between ReHo and happiness. Limited power also prevented us from investigating the interaction between happiness and gender on ReHo. As this is still an unexplored question and previous behavioral and neuropsychological studies have reported inconsistent results, it would be of merit to tackle this question in our future study. Finally, recent work showed that ReHo is correlated with neurovascular variables and the contribution of ReHo to task activation can be counted by neurovascular factors  . Thus, alterations in ReHo might not purely reflect changes in neuronal activity but instead it might reflect changes in neurovascular coupling, or both. Future work is needed to investigate the physiological significance of ReHo before we can more accurately interpret the direction of the results (e.g. increased or decreased ReHo in certain regions for one group compared with another group). \n\n\n## Conclusions \n  \nIn summary, we used a ReHo approach to investigate the differences in intrinsic brain activities between happy and unhappy individuals. We found that the local synchronization of intrinsic brain activities was altered in unhappy individuals within prefrontal cortex, temporal lobe, limbic system, and subcortical regions. These regions overlapped with the previously identified DMN, which suggests that DMN plays an important role in subjective happiness and is in support of the construal theory. Our findings also provide further evidence to support that core components of the emotional and rewarding network are involved in happiness. \n\n \n\n# Table(s)\n## ID: pone-0085181-t001\n### Label: Table 1\nUnnamed: 0\tHappy group (N\u200a=\u200a25)\tUnhappy group (N\u200a=\u200a25)\tUnnamed: 3\nAge (mean, SD)\t20.16(1.34)\t20.36(1.38)\tt(48)\u200a=\u200a\u22120.52, p\u200a=\u200a0.606\nGender (male/female)\t6/19\t8/17\tx2 (1)\u200a=\u200a0.40, p\u200a=\u200a0.754\nSHS (mean, SD)\t6.51(0.29)\t3.96(0.45)\tt(48)\u200a=\u200a23.55, p<0.001\nPA (mean, SD)\t33.96(3.9)\t29.84(5.21)\tt(48)\u200a=\u200a2.38, p\u200a=\u200a0.021\nNA (mean, SD)\t18.00(3.74)\t20.80(5.21)\tt(48)\u200a=\u200a\u22122.23, p\u200a=\u200a0.031\nCHI (mean, SD)\t2.621(0.33)(N\u200a=\u200a24)\t2.21(0.30)(N\u200a=\u200a24)\tt(46)\u200a=\u200a4.42, p<0.001\n### Caption\nThe Sample Characteristics.\n### Footer\nNote: SHS\u200a=\u200a Subjective Happiness Scale; PA\u200a=\u200a Positive Affect (subscale of Positive and Negative Affect Schedule); NA\u200a=\u200a Negative Affect (subscale of Positive and Negative Affect Schedule); CHI\u200a=\u200a Chinese Happiness Inventory.\n\n\n## ID: pone-0085181-t002\n### Label: Table 2\nAnatomical region\tSide\tBAs\tMNI\tMNI\tMNI\tVoxel Size (voxels)\tPeak T-value\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tUnnamed: 2_level_1\tx\ty\tz\tUnnamed: 6_level_1\tUnnamed: 7_level_1\nHappy > Unhappy\tHappy > Unhappy\tHappy > Unhappy\tHappy > Unhappy\tHappy > Unhappy\tHappy > Unhappy\tHappy > Unhappy\tHappy > Unhappy\nMedial Prefrontal Cortex\tB\t10\t\u22126\t72\t6\t39\t3.39\nVentrolateral Prefrontal Cortex\tR\t45\t48\t42\t\u22123\t20\t4.33\nPosterior Cingulate Cortex/Retrosplenial Cortex\tL\t18\t\u22129\t\u221257\t3\t19\t3.25\nSuperior Temporal Gyrus\tR\t22\t51\t\u221257\t12\t22\t3.55\nParahippocampa Gyrus\tR\t\t18\t\u221212\t\u221218\t25\t3.86\nHippocampus\tL\t\t\u221215\t\u22129\t\u221212\t18\t3.52\nUnhappy > Happy\tUnhappy > Happy\tUnhappy > Happy\tUnhappy > Happy\tUnhappy > Happy\tUnhappy > Happy\tUnhappy > Happy\tUnhappy > Happy\nSuperior Frontal Gyrus\tR\t9\t21\t36\t48\t23\t\u22123.53\nDorsolateral Prefrontal Cortex\tL\t46\t\u221230\t51\t24\t45\t\u22124.47\nMiddle Cingulate Gyrus\tR\t6\t15\t0\t51\t120\t\u22125.77\nPutamen\tR\t\t27\t9\t\u22126\t23\t\u22123.4\nThalamus\tL\t\t\u22126\t\u221221\t15\t41\t\u22124.27\n### Caption\nBrain regions exhibiting significant group differences in ReHo.\n### Footer\nNote: Side refers to the hemisphere side (B: bilateral; R: right; and L: left). The Brodmann areas (BAs), the coordinates of peak t-value in Montreal Neurological Institute (MNI) space, the volume in voxels, and the peak t-value are specified for each region showing group differences in regional homogeneity (ReHo).\n", "metadata": {"pmcid": 3893192, "text_md5": "68c5038c5c4357a0bc3615a250aba31f", "field_positions": {"authors": [0, 90], "journal": [91, 99], "publication_year": [101, 105], "title": [116, 197], "keywords": [211, 211], "abstract": [224, 1862], "body": [1871, 25371], "tables": [25384, 27527]}, "batch": 2, "pmid": 24454814, "doi": "10.1371/journal.pone.0085181", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3893192", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3893192"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3893192\">3893192</a>", "list_title": "PMC3893192  Regional Homogeneity of Intrinsic Brain Activity in Happy and Unhappy Individuals"}
{"text": "Deng, Demao and Liao, Hai and Duan, Gaoxiong and Liu, Yanfei and He, Qianchao and Liu, Huimei and Tang, Lijun and Pang, Yong and Tao, Jien\nFront Hum Neurosci, 2016\n\n# Title\n\nModulation of the Default Mode Network in First-Episode, Drug-Na\u00efve Major Depressive Disorder via Acupuncture at Baihui (GV20) Acupoint\n\n# Keywords\n\nacupuncture\nBaihui\nfMRI\nfunctional connectivity\nmajor depressive disorder\n\n\n# Abstract\n \n Background  : Previous neuroimaging studies have revealed that acupuncture modulates the default mode network (DMN) in healthy subjects and patients with certain disorder. However, few studies have been performed to investigate whether or not acupuncture might modulate the DMN in patients with major depressive disorder (MDD). Thereby, the aim of the present study was to assess alterations of the DMN induced by acupuncture stimulation in patients with first-episode, drug-na\u00efve MDD. \n\n Materials and Methods  : Twenty nine patients with first-episode, drug-na\u00efve MDD and 29 healthy subjects were enrolled in this study. All the healthy subjects underwent 6-min resting-state functional magnetic resonance imaging (R-fMRI) scan. While patients underwent acupuncture stimulation for 20-min electro-acupuncture stimulation (EAS) at Baihui acupoint (GV20) and two 6-min R-fMRI scans before and after EAS. Based on the precuneus/posterior cingulate cortex (PC/PCC) as the seed region, functional connectivity (FC) method was adopted to examine abnormal DMN in patients by comparing with healthy subjects and to evaluate the influence of EAS on intrinsic connectivity within the DMN in patients with MDD. \n\n Results  : Compared to healthy subjects, MDD patients had abnormal DMN. Moreover, results showed that EAS at GV20 induced increased FC between the PC/PCC and bilateral anterior cingulate cortex (ACC), and decreased FC between the PC/PCC and left middle prefrontal cortex, left angualr gyrus and bilateral hippocampus/parahippocampus (HIPP/paraHIPP) in patients with MDD, which were the main brain regions showing significant differences between the patients and healthy subjects. \n\n Conclusion  : Our findings provide imaging evidence to support that GV20-related acupuncture stimulation may modulate the DMN in patients with first-episode, drug-na\u00efve MDD. This study may partly interpret the neural mechanisms of acupuncture at GV20 which is used to treat patients with MDD in clinical. \n \n\n# Body\n \n## Introduction \n  \nAs a debilitating psychiatric disorder, major depressive disorder (MDD) is characterized by depressed mood, anhedonia, irritability, difficulties in concentration, and abnormalities in appetite and sleep (Nestler et al.,  ). MDD has a negative effect on the quality life of patients and leads to a huge economic burden for patient\u2019s family (Collins et al.,  ). MDD will become the second cause of burden of disease by 2030 (Mathers and Loncar,  ). Recent large-scale epidemiological surveys in China have shown that the prevalence of MDD patients is high to 6.1%, which causes many social problems (Phillips et al.,  ). Thus, it is necessary to pay more attention to understanding the pathophysiological mechanisms of MDD and finding effectively therapeutic approaches. \n\nAs one of the most commonly recognized resting-state networks, the default mode network (DMN) comprises the brain areas mainly including the middle prefrontal cortex, anterior cingulate cortex (ACC), posterior cingulate cortex (PCC), precuneus (PC), angular gyrus and inferior parietal cortex (IPC; Raichle et al.,  ; Greicius et al.,  ). The DMN plays an important role in self-referential activities, such as evaluating characteristics of external and internal cues, planning the future, and remembering the past (Raichle and Snyder,  ; Buckner et al.,  ). Recently, several studies have revealed dysfunctional DMN in MDD patients, and altered functional connectivity (FC) between brain regions were mainly located in the middle prefrontal cortex, angular gyrus, ACC and hippocampus (HIPP; Anand et al.,  ; Tahmasian et al.,  ; Jacobs et al.,  ; Khalsa et al.,  ; Chen et al.,  ; Sankar et al.,  ). The aforementioned studies indicated that the DMN was one of the most mature network matched with functional magnetic resonance imaging (fMRI) for studying mechanisms of MDD (Guo et al.,  ; Chen et al.,  ) and suggested that abnormal DMN was associated with MDD. \n\nAs one complementary and alternative therapy method, acupuncture may improve microcirculation, balance organ function, and adjust mental activities. Acupuncture thereby has been increasingly and widely accepted by western countries (Lee et al.,  ). Neuroimaging technologies have been used to investigating neural mechanisms of acupuncture, and it has been found that acupuncture stimulation may modulate the DMN in healthy subjects and patients with certain psychiatric disorders, such as stroke, migraine and Alzheimer\u2019s disease (AD; Dhond et al.,  ; Fang et al.,  ; Hui et al.,  ; Liu et al.,  ; Wang et al.,  ; Zhang et al.,  ). \n\nAccording to traditional Chinese medicine theory, Baihui acupoint (GV20) is located at the highest place of the head, and GV20 is a commonly acupoint used to relief of dizziness, headache and anxiety by acupuncture stimulation, which attributes to the effect of acupuncture at GV20 on modulating vascular, endocrine, immune and/or nervous systems (Satoh,  ). GV20 was indentified to be involved in the treatment of MDD (Sun et al.,  ; Li et al.,  ). This raised the questions: whether or not the DMN could be modulated by acupuncture stimulation at GV20 in MDD patients. If so, how acupuncture stimulation modulated intrinsic connectivity in the DMN. To our knowledge, limited neuroimaging studies focused on relationships between the acupuncture stimulation at GV20 and the DMN in MDD patients. \n\nIn the present study, we tried to investigate whether or not acupuncture stimulation at GV20 could modulate the DMN in patients with first-episode, drug-na\u00efve MDD using FC method. FC is known to describe relationships between the neuronal activation patterns of anatomically separated brain regions, showing the level of functional communication among regions (Van Den Heuvel and Pol,  ). FC is typically used in most resting-state fMRI studies and is suitable for exploring the DMN (Greicius et al.,  ; Liu et al.,  ; Van Den Heuvel and Pol,  ; Sripada et al.,  ; Lehmann et al.,  ). Here, we hypothesized that the abnormal DMN in patients might be modulated by acupuncture, which might attribute to the characteristic of GV20. \n\n\n## Materials and Methods \n  \n### Ethics Statement \n  \nAll participants were informed about the whole experiment procedure and signed an informed consent. The current study was permitted by the Medicine Ethics Committee of First Affiliated Hospital, Guangxi University of Chinese Medicine, Guangxi, China. All research procedures of the current study were conducted in accordance with the Declaration of Helsinki. \n\n\n### Subjects \n  \nThirty patients with first-episode, drug-na\u00efve MDD (21 females and 9 males) were recruited from out-patients or in-patients at Department of Internal Neurology, First Affiliated Hospital, Guangxi University of Chinese Medicine, Guangxi, China. All the patients were individually diagnosed by two trained psychiatrists using the structured clinical interview of the diagnostic and statistical manual of mental disorders-fourth criteria (DSM-IV; First MB et al.,  ). And the inclusion criterion for patients were: (1) being first-episode, drug-na\u00efve; (2) the ages between 18 and 45 years; (3) being right-handed; and (4) having episode experience of MDD with the score of at least 18 on 17-items Hamilton Depression Rating Scale (HDRS-17; Guo et al.,  ). The exclusion criterion for patients were: (1) having other disorders by DSM-IV criteria, such as schizoaffective disorder, schizophrenia, organic mental disorder , delusional mental disorder, psychotic features coordinated or uncoordinated with mood or bipolar disorder; (2) having history of head injury or neurological disorder and degenerative diseases, such as movement disorder and Parkinson\u2019s disease; (3) having acutely suicidal or homicidal tendency; (4) having any MRI contraindications; (5) having acupuncture contraindications; and (6) being non-responders in acupuncture needling. \n\nTwenty nine healthy subjects (14 females and 15 males; mean age: 26.76 \u00b1 1.72 years) were recruited in this study. All the healthy subjects were free of depression or other psychiatric or neurological illness, and had no history of head injury and alcohol or drugs abuse. Healthy subjects did not have any family history related to neurological or psychiatric illness in their first-degree relatives. \n\nIn addition, it was required that all of the subjects were no smokers, current pregnancy or breast feeding. Meanwhile, each subject completed an identical assessment protocol, which including the HDRS-17, self-rating depression scale (SDS) and self rating anxiety scale (SAS; Guo et al.,  ). \n\n\n### Experiment Paradigm \n  \nEach healthy subject underwent only a 6-min resting-state scan. While each patient underwent two 6-min resting-state scans before and after the acupuncture stimulation for 20-min electro-acupuncture stimulation (EAS) at GV20. In detail, this study focused on GV20, which was a point on the Governor Vessel and located on the vertex of the head (Satoh,  ; Figure  ). The non-repeated event-related (NRER) paradigm was applied in the study (Qin et al.,  ; Liu et al.,  ). Twenty minutes (20-min) EAS at GV20 was operated by the same professional acupuncturist (1 Hz, 2 mA, continuous-wave, HuaTuo-brand, SDZ-V-type, Shanghai, China; Figure  ). EAS was performed by inserting the sterile stainless steel disposable needle (0.30 mm in diameter and 25 mm in length; Huatuo-brand, Suzhou, Jiangsu, China) into GV 20 at the depth of needling arranging from 1.0 cm to 1.5 cm. Another electrode was attached to the acupuncture needle which was shallowly inserted point 1.0 cm nearby GV20. During scanning, each patient was instructed to keep eyes closed, not to think about anything and to stay awake. At the end of scanning, each patient was required to recall acupuncture sensations as following: aching, soreness, numbness, fullness, sharp or dull pain, pressure, heaviness, warmth, coolness, tingling, itching, and any others. The intensity of each sensation was measured by using a 100-point visual analog scale (VAS; 0 = no sensation, 10\u201330 = mild, 40\u201360 = moderate, 70\u201380 = strong, 90 = severe and 100 = unbearable sensation), which was similarly determined by Hui et al. ( ,  ). \n  \n (A)   Location of Baihui acupoint (GV20);   (B)   Experimental paradigm. \n  \n\n### MRI Data Acquisition \n  \nImages were acquired using a 3.0 Tesla Siemens Magnetom Verio MRI System (Siemens Medical, Erlangen, Germany) at the Department of Radiology, First Affiliated Hospital, Guangxi University of Chinese Medicine, Nanning, Guangxi, China. To reduce head movement, each subject\u2019s head was fixed by foam pads in a standard 8-channel birdcage head coil. Functional images were acquired with a single-shot gradient\u2013recalled echo planar imaging (EPI) sequence with the parameters: repetition time (TR)/echo time (TE) = 2000/30 ms, Flip angle = 90\u00b0, field of view (FOV) = 240 mm\u00d7240 mm, matrix size = 64 \u00d7 64, slice thickness = 1 mm and slices = 31. High resolution T1-weighted images were then collected with a volumetric three-dimensional spoiled gradient recall sequence with the parameters: TR/TE = 1900/2.22ms, FOV = 250 mm\u00d7250 mm, matrix size: 250 \u00d7 250, flip angle = 9\u00b0, slice thickness = 1 mm and 176 slices). \n\n\n### Image Preprocessing \n  \nStatistical parametric mapping software (SPM8)  and REST toolbox (REST 1.7)  were used to analyze functional images. The first 10 functional volumes were removed for stabilization of the initial signal. Then the remaining volumes were corrected by slice timing and then realigned to correct for head motion. Data with maximum displacement in any directions of larger than 2 mm or head rotation of larger than 2\u00b0 were excluded from further analysis. The datasets were further spatially normalized to the Montreal Neurological Institute (MNI) template and resampled to 3 \u00d7 3 \u00d7 3 mm  isotropic voxels. The normalized data were smoothed with a 4-mm full width at half maximum (FWHM) Gaussian kernel. Nuisance covariates were regressed out from our data, including the six head motion parameters, white matter signal and cerebrospinal fluid (CSF) signal. As global signal regression may cause a negative shift in the distribution of correlations (Murphy et al.,  ; Saad et al.,  ,  ), global signal was not regressed in our study. The data were then detrended and bandpass filtered from 0.01 to 0.08 Hz to reduce the effect of low-frequency drifts and high-frequency noise. \n\n\n### Functional Connectivity Analysis \n  \nTo identify the DMN, the seed region was selected in the PC/PCC (Sheline et al.,  ). The mean blood-oxygen-level dependent (BOLD) time course was extracted from a 6 mm sphere in the selected PC/PCC (MNI coordinates: \u22129, \u221260, 25) of each subject on different conditions, including one resting-state condition in healthy subjects and two resting-state conditions before and after EAS in patients. Pearson correlation coefficients were estimated between the mean time course of the seed region and the time course of all the other voxels within the whole brain based on different subjects and conditions, separately. Pearson correlation coefficients were then normalized to   z  -scores with Fisher\u2019s   r  -to-  z   transformation to acquire the entire brain   z  -score map of each subject on each condition. \n\n\n### Statistical Analysis \n  \nDemographic and clinical data were compared by using two-sample   t  -test and Chi-square test. The threshold level in all statistical analysis for significance criterion was determined at   p   < 0.05. Main acupuncture sensations were described with each sensation intensity and frequency in patients. \n\nTo explore the DMN, one sample   t  -test was firstly used for FC maps from healthy subjects, patients and patients after EAS, respectively. Two sample   t  -test was then applied to examine different patterns of the DMN between patients and healthy subjects. Paired   t  -test was used to examine the modulated patterns of the DMN in patients before and after EAS. The contrast map was thresholded at a voxel-level threshold of 0.005 with a cluster-level threshold of 0.05 (false discovery rate (FDR) corrected). The age, gender, weight, SAS and SDS were deemed as covariates of no interest. \n\n\n\n## Results \n  \n### Demographic and Clinical Results \n  \nIn our study, one patient was excluded from further data analysis because of incomplete EAS at GV20 during the experiment. There were no significant differences in terms of age, gender and weight between the patients and healthy subjects. Patients had higher scores in HDRS-17, SDS and SAS compared to healthy subjects (Table  ). \n  \n Demographic and clinical characteristics for the study  . \n  \n Abbreviations: SDS, self rating depression Scale; SAS, self rating anxiety scale; HDRS, hamilton depression rating scale; HSs, healthy subjects; DPs, major depressive disorder patients. Except for gender, all values are mean \u00b1 standard deviation (SD).  The p-value was obtained by Chi-square.  The p-value was obtained by two sample t-test  . \n  \n\n### Acupuncture Sensations Results \n  \nThe prevalence of   Deqi   sensations reported by patients was expressed as frequency and intensity (Figure  ). The current results showed that main   Deqi   sensations included fullness, dull pain, numbness, soreness, tingling and heaviness. \n  \n Results of acupuncture sensations in patients with major depressive disorder (MDD).   The soreness, numbness, fullness and dull pain were primary   Deqi   sensations.   (A)   The frequency of acupuncture sensations in patients with MDD.   (B)   The intensity of acupuncture sensations in patients with MDD. \n  \n\n### Imaging Results \n  \nThe patterns of the DMN in both healthy subjects and patients are shown in Figure  . The DMN mainly consisted of the middle prefrontal cortex, ACC, medial temporal cortex (MTC), bilateral angular gyrus. Compared to healthy subjects, patients had significantly statistical increased FC between the PC/PCC and the right middle prefrontal cortex and bilateral angular gyrus, and decreased FC between the PC/PCC and bilateral ACC (Figure   and Table  ). When it came to acupuncture stimulation, EAS-related results showed decreased FC in the left middle prefrontal cortex, left angular gyrus and bilateral HIPP/paraHIPP with the PC/PCC, and increased FC in the bilateral ACC with the PC/PCC in patients (Figure   and Table  ). \n  \n The default mode network (DMN). (A)   The DMN in healthy subjects;   (B)   the DMN in patients with first-episode, drug-na\u00efve MDD;   (C)   the DMN in patients with first-episode, drug-na\u00efve MDD after electro-acupuncture stimulation (EAS) at Baihui (GV20). \n    \n Distinct brain regions. (A)   Differences of the DMN between patients and healthy subjects;   (B)   differences of the DMN in patients before and after EAS at Baihui (GV20). \n    \n Main localization of default mode network (DMN) maps by comparing patients with healthy subjects and comparing electro-acupuncture stimulation (EAS) with resting state in patients  . \n  \n Abbreviation: Hem, hemisphere; BA, Brodmann area; Vol, voxels; ACC, anterior cingulate cortex; HIPP/paraHIPP, hippocampus/parahippocampus; EAS, electro-acupuncture stimulation  . \n  \n\n\n## Discussion \n  \nIn line with the NRER-fMRI design paradigm, we investigated modulatory effect of EAS at GV20 on the intrinsic connectivity within the DMN in patients with first-episode drug-na\u00efve MDD. We found: (1) compared to healthy subjects, patients had abnormal patterns of the DMN including the right middle prefrontal cortex, bilateral angular gyrus and ACC with the PC/PCC; (2) EAS at GV20 modulated the DMN in patients, related to the left middle prefrontal cortex, left angular gyrus, bilateral HIPP/paraHIPP and ACC. Our findings provided further imaging evidence to support the neural mechanisms of GV20 on modulating abnormal DMN in MDD patients. \n\n### Abnormal DMN in Patients \n  \nCompared to healthy subjects, MDD patients had abnormally increased/decreased FC regions associated with the middle prefrontal cortex, angular gyrus and ACC in this study. Previous studies had found altered DMN in patient with depression (Greicius et al.,  ; Bluhm et al.,  ; Sheline et al.,  ; Zhou et al.,  ). Our findings were similar to the results from these previous studies. Prefrontal cortex is involved in integration of cognitive, emotional behaviors by uniting emotional biasing signals or markers into decision making processing (Gusnard et al.,  ; Simpson et al.,  ). As one important part of IPC, angular gyrus plays a critical role in biological substrates of language, thought, attention and spatial working memory (Niznikiewicz et al.,  ), and is also enrolled in many diverse different tasks, such as the perception of emotions and interpretation of sensory information (M\u00fcller et al.,  ; Passingham et al.,  ; Ruschel et al.,  ). Recently, dysregulation of the IPC was found in depression and schizophrenia (M\u00fcller et al.,  ). Angular gyrus exhibited a more abnormal FC in depression patients (Guo et al.,  ), and the parietal cortex systems showed hyperconnectivity with regions of the DMN in MDD patients (Kaiser et al.,  ). Thereby, increased FC of the prefrontal cortex and angular gyrus in our study might suggest that MDD patients could have dysfunctions of cognitive and emotional system. Meanwhile, our results showed significantly decreased FC in the ACC with the PC/PCC in patients. ACC is known to be one of the most important regions related to cognition, emotion and memory (Davis et al.,  ; Greicius et al.,  ; Lavin et al.,  ). Decreased connectivity of ACC with limbic regions was also found in patients with depression (Anand et al.,  ). Thereby, we further speculate that decreased FC in the ACC is likely involved in the pathological mechanisms of MDD. \n\n\n### Modulation on the DMN in Patients after EAS \n  \nAfter 20-min EAS, the DMN patterns in patients were modulated. Results showed that the significantly decreased FC between the PC/PCC and the left middle prefrontal cortex, left angular gyrus and bilateral HIPP/paraHIPP in MDD patients after EAS at GV20. The present findings were similar to the ones from several previous studies, which reported that acupuncture stimulation induced signal attenuation in the middle prefrontal cortex, HIPP/paraHIPP and IPC (Wu et al.,  ; Yoo et al.,  ; Hui et al.,  ). HIPP/paraHIPP is implicated in cognitive-behavioral functions and emotional memory (LaBar and Cabeza,  ; Savitz and Drevets,  ). Impaired function of the HIPP/paraHIPP was found in MDD patients (Hamilton and Gotlib,  ). On the other hand, positive artificial intervention improved status for MDD patients due to excellent performance of angular gyrus (Shen et al.,  ). Therefore, the decreased FC between the PC/PCC and middle prefrontal cortex, angular gyrus and HIPP/paraHIPP in our study might indicate the positive effect of GV20-related acupuncture on eliminating formatted negative emotion and mediating memory related to depression. Our findings also showed that there were significantly increased FC in the ACC with the PC/PCC in patients after EAS. It had been reported that increased FC was found in ACC within the DMN in depression patients after artificial intervention, such as task stimulation and antidepressant treatment (Anand et al.,  ; Greicius et al.,  ; Zeng et al.,  ). Our findings could present that there might exist positive intervention effects on the ACC of MDD patients, which were attributed to acupuncture at GV20. \n\nThere were some limitations of our study: (1) Our study aimed to investigate whether or not GV20-related acupuncture stimulation might modulate the DMN in MDD patients, but not to investigate the specificity of acupoint (GV20). So, there was not a sham acupoint as a control in our experiment paradigm. However, the acupuncture associated with both GV20 and sham acupoint was our another research target in the future; (2) There were not different gender distributions of the two groups. Although gender, as a nuisance covariate, was regressed out from our data, gender factor could still not fully eliminate. Gender differences should be investigated and the present findings should be retested in larger samples in the future; and (3) The present results showed a preliminary research about the immediate effect of EAS on the DMN in patients with MDD. Further studies were still needed to confirm whether or not there were the possibilities of improving treatment effect in patients by a long-term EAS at GV20. \n\n\n\n## Conclusion \n  \nWe used fMRI and FC method to investigate the modulation mechanisms of GV20-related EAS to the DMN in MDD patients. Results showed EAS induced altered FC in the DMN, including the middle prefrontal cortex, angular gyrus, ACC and HIPP/paraHIPP which were the main regions showing abnormalities between patients and healthy subjects. Our findings might provide imaging evidence to support that EAS at GV20 has intervention effect on the DMN in patients with first-episode, drug-na\u00efve MDD. \n\n\n## Author Contributions \n  \nDD made substantial contributions to the overall conception of the work, designed the experiment, revised and handled the manuscript, accurately answered all the questions from the reviewers, ensured the integrity of the work, and approved the final version to be published. HL made important contribution to the literature review, interpreted data for the work, drafted the manuscript, revised some critical structure and intellectual content, advised on the integrity of the work, and approved the final version to be published. GD made important contribution to the design of MR scan protocols, carried out MRI operation, MRI data acquisition and storage, and approved the final version to be published. YL conducted the data processing and analysis for the functional MRI data, interpreted the conceptions of data processing, wrote the procedure of data processing, and approved the final version to be published. QH executed the diagnosis of patients, recruited subjects for this study, interpreted intellectual content in depression, was accountable for some aspects of the work in ensuring that questions related to the accuracy of the work were appropriately resolved, and approved the final version to be published. YP provided the acupuncture theory, made substantial contributions to the overall design and guideline of acupuncture experiment, interpreted intellectual content in acupuncture, and approved the final version to be published. HL was responsible for acupuncture operations, advised on the improvement of acupuncture protocols, provided important intellectual content in acupuncture, and approved the final version to be published. LT and JT conducted the assessment of acupuncture sensations, gave some important advice for the accuracy interpretation or description of conceptions related to acupuncture theory, and approved the final version to be published. \n\n\n## Conflict of Interest Statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nVariable\tHSs (n = 29)\tDPs (n = 29)\tp value\nGender (male/female)\t15/14\t9/20\t0.182a\nAge (years)\t26.76 \u00b1 1.72\t28.69 \u00b1 6.69\t0.138b\nWeight (kg)\t59.55 \u00b1 12.95\t55.10 \u00b1 10.50\t0.157b\nSDS\t42.17 \u00b1 7.74\t62.72 \u00b1 9.81\t<0.001b\nSAS\t43.00 \u00b1 7.59\t62.14 \u00b1 8.79\t<0.001b\nHDRS-17\t4.48 \u00b1 3.22\t21.31 \u00b1 2.58\t<0.001b\n### Caption\nDemographic and clinical characteristics for the study.\n### Footer\nAbbreviations: SDS, self rating depression Scale; SAS, self rating anxiety scale; HDRS, hamilton depression rating scale; HSs, healthy subjects; DPs, major depressive disorder patients. Except for gender, all values are mean \u00b1 standard deviation (SD). aThe p-value was obtained by Chi-square. bThe p-value was obtained by two sample t-test.\n\n\n## ID: T2\n### Label: Table 2\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tUnnamed: 2_level_0\tMNI\tMNI\tMNI\tUnnamed: 6_level_0\tUnnamed: 7_level_0\nRegions\tHem\tBA\tX\tY\tZ\tT-Value\tVol\nPatients vs. healthy subjects\t\t\t\t\t\t\t\nMiddle prefrontal cortex\tR\t8\t24\t18\t54\t3.97\t62.0\nAngular gyrus\tL\t3/79\t\u221236\t\u221263\t45\t3.76\t39.0\n\tR\t39/7\t42\t\u221269\t48\t4.18\t44.0\nACC\tL\t24/32\t\u22126\t36\t12\t\u22123.66\t65.0\n\tR\t24/32\t6\t42\t6\t\u22123.98\t59.0\nEAS vs. resting in patients\t\t\t\t\t\t\t\nMiddle prefrontal cortex\tL\t8\t\u221221\t18\t51\t\u22123.96\t57.0\nAngular gyrus\tL\t39/7\t\u221239\t\u221260\t48\t\u22124.78\t92.0\nACC\tL\t24/32\t\u22126\t36\t12\t3.75\t39.0\n\tR\t24/32\t6\t33\t21\t4.1\t46.0\nHIPP/paraHIPP\tL\t36\t\u221227\t\u221218\t\u221218\t\u22123.96\t38.0\n\tR\t36\t27\t\u221215\t\u221218\t\u22123.82\t33.0\n### Caption\nMain localization of default mode network (DMN) maps by comparing patients with healthy subjects and comparing electro-acupuncture stimulation (EAS) with resting state in patients.\n### Footer\nAbbreviation: Hem, hemisphere; BA, Brodmann area; Vol, voxels; ACC, anterior cingulate cortex; HIPP/paraHIPP, hippocampus/parahippocampus; EAS, electro-acupuncture stimulation.\n", "metadata": {"pmcid": 4869560, "text_md5": "767aa10592fd17ca17d1a09497c0a3f8", "field_positions": {"authors": [0, 138], "journal": [139, 157], "publication_year": [159, 163], "title": [174, 309], "keywords": [323, 397], "abstract": [410, 2408], "body": [2417, 25552], "tables": [25565, 27325]}, "batch": 2, "pmid": 27242492, "doi": "10.3389/fnhum.2016.00230", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4869560", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4869560"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4869560\">4869560</a>", "list_title": "PMC4869560  Modulation of the Default Mode Network in First-Episode, Drug-Na\u00efve Major Depressive Disorder via Acupuncture at Baihui (GV20) Acupoint"}
{"text": "Taruffi, Liila and Skouras, Stavros and Pehrs, Corinna and Koelsch, Stefan\nCogn Affect Behav Neurosci, 2021\n\n# Title\n\nTrait Empathy Shapes Neural Responses Toward Sad Music\n\n# Keywords\n\nTrait empathy\nSad music\nSocial neuroscience\nMusic & emotion\nfMRI\n\n\n# Abstract\n \nIndividuals with a predisposition to empathize engage with sad music in a compelling way, experiencing overall more pleasurable emotions. However, the neural mechanisms underlying these music-related experiences in empathic individuals are unknown. The present study tested whether dispositional empathy modulates neural responses to sad compared with happy music. Twenty-four participants underwent fMRI while listening to 4-min blocks of music evoking sadness or happiness. Using voxel-wise regression, we found a positive correlation between trait empathy (with scores assessed by the Interpersonal Reactivity Index) and eigenvector centrality values in the ventromedial prefrontal cortex (vmPFC), including the medial orbitofrontal cortex (mOFC). We then performed a functional connectivity (FC) analysis to detect network nodes showing stronger FC with the vmPFC/mOFC during the presentation of sad versus happy music. By doing so, we identified a \u201cmusic-empathy\u201d network (vmPFC/mOFC, dorsomedial prefrontal cortex, primary visual cortex, bilateral claustrum and putamen, and cerebellum) that is spontaneously recruited while listening to sad music and includes brain regions that support the coding of compassion, mentalizing, and visual mental imagery. Importantly, our findings extend the current understanding of empathic behaviors to the musical domain and pinpoint sad music as an effective stimulus to be employed in social neuroscience research. \n \n\n# Body\n \n## Introduction \n  \nEmpathy is one of the most remarkable human abilities that allows, for instance, to understand what it feels like to experience someone else\u2019s joy or sadness and that ultimately promotes meaningful social interaction. Empathic behaviors are diverse and include resonating affectively with others\u2019 emotions (  affective empathy   or   experience sharing  ) and comprehending others\u2019 mental and affective states (  cognitive empathy   or   mentalizing  ) (Zaki & Ochsner,  ). While sharing another person\u2019s positive emotion is doubtlessly pleasant, shared negative affective experiences can be challenging and may lead to   empathic distress  , a maladaptive empathic response that is associated with burnout in individuals who are routinely exposed to the suffering of others, such as physicians, nurses, and therapists (McCray et al.,  ).   Compassion   represents an alternative empathic reaction to sharing a negative emotion. In contrast to empathic distress, compassion is characterized by positive feelings of warmth and care as well as strong prosocial motivation and approach components (Singer & Klimecki,  ). Research on the neural underpinnings of affective empathy has predominantly focused on empathy for physical pain, revealing that the medial/anterior cingulate cortex and the anterior insula are consistently activated during first-hand experience of pain as well as while observing another person in pain (Jackson et al.,  ; Lamm et al.,  ; Singer et al.,  ; for a meta-analysis see Lamm et al.,  ). Although the neuroimaging literature on compassion is limited compared with the one on empathy for pain, a number of studies have underlined the role of nonoverlapping brain structures, such as the medial orbitofrontal cortex (mOFC), putamen, pallidum, and ventral tegmental area, extending the dissociation between empathic distress and compassion from the psychological to the neural level (Klimecki et al.,  ; Klimecki et al.,  ). With regard to cognitive empathy, the dorsomedial prefrontal cortex (dmPFC), the superior temporal sulcus/temporoparietal junction, the posterior cingulate cortex, and the temporal poles are reliably engaged when participants are asked to make judgments about targets\u2019 beliefs, thoughts, intentions, and emotions (Denny et al.,  ; Mitchell,  ; Pehrs et al.,  ; Preckel et al.,  ; Van Overwalle & Baetens,  ). \n\nAlthough social neuroscientists have traditionally investigated empathy as an interpersonal phenomenon directed to human beings (e.g., Lamm et al.,  ), empathic responses also extend to aesthetic contexts (i.e., imagined affective experiences, beliefs, or intentions of inanimate characters of the artwork or of the artist) and, in fact, empathy is considered to be a constitutive element of the aesthetic experience in cinema (D\u2019Aloia,  ), figurative art (Freedberg & Gallese,  ), literature (Johnson et al.,  ), and music (Levinson,  ). As argued by the philosophers Robert Vischer ( ) and Theodor Lipps ( ), appreciation of art draws crucially on the beholders\u2019 ability to resonate with the piece of art, thereby underlining the importance of individual characteristics and suggesting that highly empathic individuals may have more intense and pleasurable aesthetic experiences. These philosophical accounts of \u201caesthetic\u201d empathy have stressed its affective component rather than the cognitive one. However, mentalizing processes also are at play in aesthetic contexts, such as music listening. Similar to other art forms, music is the product of\u2014and therefore is expressive of\u2014human feelings, but also beliefs, and intentions. By conveying meaning and signaling inferred intentions, music can act as social agent (or virtual surrogate for social interaction; Sch\u00e4fer & Eerola,  ), even in the absence of any perceptual information indicating the presence of a human agent (Livingstone & Thompson,  ). In line with this perspective, a previous fMRI study, comparing man-made music versus music that participants believed to have been generated by a computer, demonstrated that the former recruits brain areas involved in the attribution of mental states or mentalizing, such as the dmPFC (Steinbeis & Koelsch,  ). These empirical findings add to the theoretical accounts of music as a stimulus with social significance and call for a more systematic investigation of the neural correlates of empathy-related processes (both affective and cognitive) in musical contexts (Clarke et al.,  ). In particular, sad-sounding music (henceforth referred to as \u201csad music\u201d) may act as a powerful and sophisticated \u201csocial\u201d stimulus to map the empathic brain, being capable to evoke multifaceted, yet mostly pleasurable, intense affective experiences despite sadness being a negative emotion (Eerola et al.,  ; Sachs et al.,  ). \n\nOn the behavioral level, music-and-emotion studies have provided mounting evidence, yet merely correlational in nature and limited by the use of convenience samples, of a close relationship between empathy disposition and enjoyment as well as sensitivity to sad music. Specifically, individuals who score high on self-report questionnaires of empathy, the most widely used scale being the Interpersonal Reactivity Index (IRI; Davis,  ), experience more intense emotions, a feeling of \u201cbeing moved\u201d, and enjoyment while listening to sad music compared with individuals who score low (Eerola et al.,  ; Garrido & Schubert,  ; Kawakami & Katahira,  ; Taruffi & Koelsch,  ; Vuoskoski & Eerola,  ; Vuoskoski et al.,  ). The association between trait empathy and sad music draws not only on emotional but also cognitive aspects of empathy, as indicated by the positive correlation between the empathy subscale   fantasy   of the IRI (which assesses the tendency to transpose one\u2019s self imaginatively into the feelings and actions of fictitious characters in books, movies, and plays; Davis,  ) and the liking as well as the intensity of sad music (Taruffi & Koelsch,  ; Vuoskoski et al.,  ). These findings suggest that sad music may trigger empathic listeners to fantasize about mental images related to the unfolding of the music. Interestingly, this is in line with recent evidence that sad (compared with happy) music is associated with higher levels of mind-wandering in the form of visual mental images and the engagement of the default mode network (Taruffi, Pehrs, et al.,  ), which overlaps to a great extent with the abovementioned core regions involved in mentalizing (e.g., Mars et al.,  ). Only one previous fMRI study investigated the neural substrates underlying the relationship between trait empathy and music, providing evidence that individual variance in trait empathy is reflected in differential recruitment of core empathy networks during music listening (Wallmark et al.,  ). Specifically, IRI subscales were found to correlate with activity in regions associated with both emotional (sensorimotor regions, insular, and cingulate cortex) and cognitive empathy (prefrontal cortex and temporoparietal junction) during passive listening tasks. However, this study featured only simple musical tones and 16-s music excerpts varying in familiarity (familiar and unfamiliar) and preference (liking or disliking), but not in emotional tone (e.g., sad or happy). Therefore, it remains to be tested yet whether empathic participants are particularly sensitive to sad music, showing specific empathy-related brain activity patterns. \n\nThe present study sought to investigate whether empathic abilities relate to variation in brain network connectivity in response to sad (vs. happy) music. Participants were scanned while listening to 4-min blocks of sad and happy music and subsequently completed the IRI (Davis,  ). Functional data were analyzed using Eigenvector Centrality Mapping (ECM; Lohmann et al.,  ) and Functional Connectivity (FC), similar to a previous study that investigated \u201csmall-world\u201d networks underlying music-evoked joy (Koelsch & Skouras,  ). ECM is a mathematical method that has been described in detail previously (Lohmann et al.,  ). For interpretational purposes, ECM derives a measure of Eigenvector Centrality (EC) for each voxel within a brain volume, based on timeseries data from each and every other voxel within the same brain volume. Through an iterative self-referential procedure, ECM considers the patterns of interconnectivity across all voxels. The derived EC values correspond to the level of influence that each voxel exerts over the entire brain volume activation pattern. Note that EC values do not only take the number of connections of a voxel into account, but also the importance of connected voxels. For instance, Google's PageRank algorithm was based on EC, such that web domains were not only ranked higher when more other pages linked to them, but also when those linking pages themselves were pages to which more other pages linked. Thus, ECM can reveal influential, or important, hubs of neural networks in the human brain. In this study, first a second-level regression analysis was performed voxel-wise, with IRI scores as the predictor and EC values from the contrasts between emotion conditions as the outcome variable. Then, the cluster identified by this analysis was used as seed region in a subsequent FC analysis that was performed to identify a network of brain regions underlying empathic individuals\u2019 responses evoked by sad compared with happy music. We expected to observe the engagement of brain regions that are involved in compassion and positive affect, in particular the mOFC (Klimecki et al.,  ; Klimecki et al.,  ). This hypothesis was motivated by the fact that empathic individuals show an enhanced enjoyment of sad music, suggesting that they exhibit patterns of empathic reactions to negatively valenced stimuli that are more aligned with compassion rather than emotional distress. In addition, given the association between cognitive aspects of dispositional empathy and the liking of sad music (Taruffi & Koelsch,  ; Vuoskoski et al.,  ), we anticipated the engagement of mentalizing brain regions, specifically the dmPFC, because of its role in social inferences of traits and scripts about other people (Van Overwalle,  ). Moreover, the recruitment of the dmPFC has previously been observed in music studies exploring: (  i  ) neural associations with trait empathy (Wallmark et al.,  ); (  ii  ) internally oriented cognitive experiences, such as mind-wandering in response to sad music (Taruffi, Pehrs, et al.,  ); and (  iii  ) attribution of mental states (Steinbeis & Koelsch,  ). We finally expected that trait empathy would be associated with activity in the visual cortex, given that previous findings suggested enhanced visual mental imagery processes during listening to sad music (Taruffi, Pehrs, et al.,  ). \n\n\n## Methods \n  \n### Participants \n  \nTwenty-four (12 females) right-handed, native German speakers with no history of neurological problems participated in this study (mean age = 25.3, age range 21-34). Participants were screened for depressive symptoms, alexithymia (alexithymia is associated with difficulties in perception of sadness conveyed by music; Taruffi, Allen, et al.,  ), and sensitivity to music reward, using the Quick Inventory of Depressive Symptomatology (QIDS-SR; Rush et al.,  ), the Toronto Alexithymia Scale (TAS-20; Bagby et al.,  ), and the Barcelona Music Reward Questionnaire (BMRQ; Mas-Herrero et al.,  ), respectively. All participants scored below 6 on the QIDS-SR and 52 on the TAS-20; thus, none of the participants were depressive or alexithymic. With regard to the BMRQ, all participants scored between 40 and 60 on the two factors of   emotion evocation   and   mood regulation  , indicating an average sensitivity to reward derived from music-evoked emotional experiences. None of the participants were professional musicians. 58.3% of the participants were nonmusicians, 29.2% amateur musicians, and 12.5% semiprofessional musicians. Participants\u2019 favorite musical genres fell into the following categories: 25.7% rock, 20% electronic, 15.7% pop, 15.7% classical and soundtrack, 12.8% jazz, 5.7% reggae, and 4.4 % other. All participants provided informed consent in a manner approved by the Ethics Committee of the Freie Universit\u00e4t Berlin, and the experiment was performed in accordance with ethical standards outlined by the Declaration of Helsinki. Participants either received course credit or 10\u20ac/h for participation. \n\n\n### Music stimuli \n  \nThe stimulus set consisted of four pairs of sad-happy excerpts of instrumental film soundtracks, capable of evoking sad and happy emotions, respectively. Each sad-happy pair had the same tempo (measured in beats per minute, BPM) and featured an acoustically identical beat track, leading to the same perceived tempo and similar vestibular responses for sad and happy music (for more information about the stimulus preparation see Taruffi, Pehrs, et al.,  ). There were four \u201cshort\u201d (35\u201337\u2009s) and four \u201clong\u201d (1.18\u20131.30\u2009min) excerpts, counterbalanced across conditions. All excerpts were edited to have 1.5-s fade in/out ramps and were RMS (root mean square) normalized to have the same loudness. Stimuli of the same emotion category were concatenated into blocks of 4-min duration (no stimulus was repeated) to ensure optimal data for the application of ECM analysis, which typically requires relatively long trial periods but has the advantage that only one trial per condition is sufficient per subject (Lohmann et al.,  ). \n\n\n### Self-report measure of trait empathy \n  \nIndividual differences in trait empathy were measured through the validated German version (Paulus,  ) of the IRI (Davis,  ). The IRI is one of the most commonly used self-report questionnaires of dispositional empathy, which builds on a multidimensional conceptualization of empathy, including cognitive and affective aspects, and has been consistently used in previous studies that examined the relationship between sad music and trait empathy (e.g., Vuoskoski et al.,  ). Global empathy scores showed a   M   of 15.4 and a   SD   of 1.37 (corresponding   M   of German population norms = 14.49, and   SD   = 3.17; Paulus,  ). \n\n\n### Procedure \n  \nBecause familiarity can strongly affect music-evoked emotions and their neural correlates\u00a0(Pereira et al.,  ), approximately two weeks before the scanning session the participants were tested on their familiarity with the music stimuli to ensure that they were unfamiliar with the selected music excerpts. Participants listened to short excerpts (15 s) of the stimuli and indicated their familiarity with each excerpt on a scale ranging from 1 (\u201cI have never heard this piece before\u201d) to 5 (\u201cI know this piece\u201d). Participants were not included in the fMRI session if they were familiar with any of the music pieces. A paired   t  -test showed that there was no significant difference in familiarity between the happy [1.62 \u00b1 0.57 (  M   \u00b1   SD  )] and the sad pieces (1.57 \u00b1 0.63),   P   > 0.05. \n\nIn the scanning session, participants listened to the 4-min sad and happy music blocks presented in a pseudo-randomized order. Stimuli were presented via MRI-compatible headphones (under which participants wore earplugs) at a comfortable volume level and participants were instructed to close their eyes and relax during the music listening. Each music block was followed by: (  i  ) a 2-s signal tone indicating participants to open their eyes; (  ii  ) a 16-s evaluation period during which participants were asked to indicate their overall emotional state during the 4-min music period using a response pad they held in their right hands; and (  iii  ) a 10-s silence period to avoid emotional crossover between different blocks of stimuli. \n\nFor the emotion evaluation in response to the music, participants were instructed to focus on their emotional experience (i.e.,   felt emotions  ) rather than the emotional tone that the music was intended to convey (i.e.,   perceived emotion  ). We decided to assess only   felt emotions  , because the link between trait empathy and sad music has been reported mainly on experiential rather than perceptual level (e.g., Vuoskoski, & Eerola,  ). Furthermore, no clear findings are available to substantiate the claim that behavioral differences between felt and perceived emotions correspond to separate underlying neural correlates (e.g., Koelsch,  ). Participants rated their felt emotions on four 6-point scales representing valence (\u201cHow unpleasant/pleasant did you feel during the music listening?\u201d), arousal (\u201cHow calm/aroused did you feel during the music listening?\u201d), sadness (\u201cHow sad did you feel during the music listening?\u201d), and happiness (\u201cHow happy did you feel during the music listening?\u201d). The answer scales ranged from 1 (\u201cvery unpleasant\u201d, \u201cvery calm\u201d, \u201cnot at all\u201d) to 6 (\u201cvery pleasant\u201d, \u201cvery aroused\u201d, \u201cvery much so\u201d). \n\nThe total length of the fMRI session was approximately 27 min and, besides the two experimental conditions, included also listening to two blocks of dissonant and neutral music as well as a resting state scanning session with no music (these scans were acquired to fulfill other research purposes). All 24 participants completed the IRI after the scanning session. \n\n\n### fMRI data acquisition and data analysis \n  \nMRI data were acquired on a 3T Siemens Magnetom Trio MRI scanner, at the Dahlem Institute for Neuroimaging of Emotion. Before functional scanning, a high-resolution (1\u2009\u00d7\u20091\u2009\u00d7\u20091 mm) T1-weighted anatomical reference image was obtained from each participant using a rapid acquisition gradient echo (MP-RAGE) sequence. Functional data were acquired using a continuous echo planar imaging (EPI) sequence (37 slices interleaved; slice thickness = 3 mm; interslice gap = 0.6 mm; TE = 30 ms; TR = 2,250 ms; flip angle = 70\u00b0; matrix = 64x64; FOV = 192 x 192 mm). To minimize susceptibility artifacts in areas, such as the orbitofrontal cortex and the temporal lobes, the acquisition window was tilted at an angle of 30\u00b0 to the intercommissural (AC-PC) plane (Deichmann et al.,  ; Weiskopf et al.,  ), similar to previous studies (Koelsch et al.,  ; Koelsch & Skouras,  ). \n\nFunctional images were preprocessed and analyzed using LIPSIA 2.1 (Lohmann et al.,  ). Each participant\u2019s anatomical T1 data were used to derive nonlinear transformation matrices between the participant\u2019s native space and MNI-space. Data were corrected for slicetime acquisition, realigned and normalized, by applying the derived transformation matrices, into MNI-space-registered images with isotropic voxels of 3 mm . A high-pass filter with a cutoff frequency of 1/90 Hz was used to remove low-frequency drifts in the fMRI time-series, and a spatial smoothing was performed using a Gaussian kernel of 6 mm full-width at half-maximum. The mean signal value per scanned volume was computed and regressed out of each participant's data. To control for motion artifacts, the movement parameters of each participant also were regressed out of the respective fMRI time-series. \n\nWhole-brain EC maps were computed separately for each participant during each 4-min experimental condition. Global empathy scores were used as the regressor of interest, with age and gender as covariates of no interest (as in Koelsch et al.,  ), in a second-level design matrix comparing EC between the two experimental conditions using voxel-wise paired sample   t  -tests. Regression was used, because empathy scores were normally distributed, as confirmed by a Kolmogorov-Smirnov test, D(24) = 0.16,   P   > 0.05. Results of this multiple regression analysis were corrected for multiple comparisons using cluster-size and cluster-value thresholds obtained by Monte Carlo simulations with a significance level of   P   < 0.05 (Lohmann et al.,  ). \n\nFC analysis was conducted using as seed region the cluster identified by the above-described voxel-wise regression analysis between EC and empathy scores. The average time-course of activity within the seed region was extracted and regressed against activity in the rest of the brain, separately for the sad and happy music conditions. FC maps were first computed separately for each participant and later normalized across the whole sample. Then, FC maps were compared between the two experimental conditions using paired sample   t  -tests corrected for multiple comparisons (using cluster-size and cluster-value thresholds obtained by Monte Carlo simulations with a significance level of   P   < 0.05; Lohmann et al.,  ). \n\n\n\n## Results \n  \n### Behavioral results \n  \nPaired   t  -tests showed that valence ratings did not significantly differ between sad (4.29 \u00b1 1.46) and happy music (5.21 \u00b1 0.88),   P   = 0.013 (Bonferroni-adjusted alpha level of .012), suggesting that sad music also was associated to some extent with pleasurable emotional experiences. Similarly, arousal ratings did not significantly differ between sad (3.21 \u00b1 1.18) and happy music (3.75 \u00b1 0.9),   P   = 0.04 (Bonferroni-adjusted alpha level of 0.012), in accordance with the use of music stimuli controlled for tempo characteristics. Furthermore, sadness ratings were significantly higher during sad (4.54 \u00b1 0.83) compared with happy music (1.5 \u00b1 0.83),   t  (23) = 10.90,   P   < 0.001. Inversely, happiness ratings were significantly higher during happy (5.42 \u00b1 0.72) compared with sad music (2.71 \u00b1 1.27),   t  (23) = 8.74,   P   < 0.001. \n\n\n### fMRI results \n  \nSignificant positive correlations between EC and the total empathy scores were observed in a cluster of voxels located in the vmPFC, including (but not restricted to) the mOFC (Fig.  ; Table  ), suggesting that the vmPFC is more crucial to emotional processes in people with high empathy scores. This EC cluster exhibited significantly stronger functional connectivity during sad than during happy music with the dmPFC, primary visual cortex (V ), bilateral claustrum (CL), putamen (PT), and cerebellum (CB) (Fig.  ; Table  ). The V  exhibited the strongest connectivity and was by far the largest target region identified (Table  ). Conversely, no region was found to show significantly stronger functional connectivity with the vmPFC/mOFC during happy compared with sad music.   \nResults of the correlation analysis between eigenvector centrality maps and empathy scores. Positive correlations (shown in red-yellow colors) were found in a cluster located in the ventromedial prefrontal cortex, including inferiorly part of the orbitofrontal cortex. Results were controlled for age and gender, and corrected for multiple comparisons (  P   < 0.05). Coordinates refer to MNI space. \n    \nResults of empathy correlation and functional connectivity analyses for the contrast   sad > happy  , corrected for multiple comparisons (  P   < 0.05) \n  \nOutermost right column shows the maximal   z  -value within a cluster (with the mean   z  -value of all voxels within a cluster in parentheses). Percentage in parentheses indicates the anatomical probability according to the SPM Anatomy Toolbox (Eickhoff et al.,  ). CB = cerebellum; CL = claustrum; dmPFC = dorsomedial prefrontal cortex; mOFC = medial orbitofrontal cortex; PT = putamen; V  = primary visual cortex; vmPFC = ventromedial prefrontal cortex. \n    \nResults of the comparison of functional connectivity maps between the sad and happy condition (  sad > happy  ). The cluster located in the ventromedial prefrontal cortex (vmPFC) extending to the medial orbitofrontal cortex showed stronger functional connectivity with the dorsomedial prefrontal cortex (dmPFC), primary visual cortex (V ), bilateral claustrum (CL)/putamen, and cerebellum (CB). Results were corrected for multiple comparisons (  P   < 0.05). Coordinates refer to MNI space. \n  \n\n\n\n## Discussion \n  \nThis study explored how dispositional empathy modulates neural responses to sad (compared with happy) music. Previous behavioral investigations highlighted that the experience underlying listening to sad music is highly modulated by trait empathy, which leads to variability in emotional valence. Using ECM in combination with FC, we demonstrate that individual differences in trait empathy are associated with higher centrality within a distributed network of brain areas encompassing vmPFC/mOFC, dmPFC, V , CL/PT, and CB, which are engaged while listening to sad (vs. happy) music. The vmPFC/mOFC acts as a \u201ccomputational hub\u201d and the remaining brain areas as functionally connected nodes. \n\nIn accordance with our hypothesis, the ECM results revealed that empathy scores correlated with centrality values in the mOFC (part of a larger cluster covering the vmPFC). The mOFC has been recently indicated as core hub of the compassion network (Singer & Klimecki,  ). Specifically, activations of the mOFC have been reported in meditation-na\u00efve participants who, after following a short-term compassion training, were exposed to short film excerpts depicting human suffering (Klimecki et al.,  ). Furthermore, patients with damage in the vmPFC exhibit impaired empathy, poor decision making, and a deterioration of \u201cmoral character,\u201d because they are unable to generate the feelings that guide adaptive decision making in healthy individuals (Anderson et al.,  ; Bechara et al.,  ; Shamay-Tsoory,  ). Similarly, activations of the vmPFC have been previously related to affective empathy (Hynes et al.,  ; Mobbs et al.,  ; Saxe,  ; V\u00f6llm et al.,  ), in particular to empathy for positive emotions (Morelli et al.,  ). In light of these previous findings, the observed data suggest that listeners with a predisposition to empathize took a compassionate, rather than distressed, stance toward sad music. This is in line with (  i  ) the observed high centrality in two bilateral clusters encompassing the PT (Table  ), another core region of the compassion network (Klimecki et al.,  ), and (  ii  ) the fact that we did not observe activity in regions typically involved in empathy for pain (Jackson et al.,  ; Lamm et al.,  ; Singer et al.,  ). Notably, our finding ties in well with the music-and-emotion literature revealing that enjoyment of sad music is positively correlated with trait empathy (Garrido & Schubert,  ; Kawakami & Katahira,  ; Taruffi & Koelsch,  ; Vuoskoski, et al.,  ). It is important to mention that, in this study, the observed centrality of the vmPFC/mOFC was not a result of familiarity effects with sad music (as in Wallmark et al.,  ). Sad and happy stimuli were in fact controlled for familiarity and participants were equally unfamiliar to both emotion conditions (see   Methods  ). \n\nWe obtained also evidence for the involvement of the dmPFC, which exhibited functional connectivity with the vmPFC/mOFC during sad compared with happy music. The dmPFC plays a pivotal role in mentalizing (e.g.,\u00a0Amodio & Frith,  ), and specifically in the attribution of enduring traits and qualities about others (Van Overwalle,  ). Interestingly, activity in the dmPFC predicts altruistic behavior (Moll et al.,  ; Waytz et al.,  ), consistent with the view that prosocial tendencies rely on the capacity to understand the minds of others. In line with our result, a previous music study found that trait empathy correlates with activity in the mPFC during listening to familiar versus unfamiliar music (Wallmark et al.,  ). Therefore, the observed functional connection between the vmPFC/mOFC and dmPFC may suggest that empathic participants engaged with mentalizing-related computations, such as, e.g., fantasizing about other people or fictional characters to undergo imagined events. Levinson ( ) has previously argued that experiencing music as a narrative is one compelling way through which listeners empathize with the music (another common music-empathy mechanism is   emotional contagion  , where the listener internally mirrors the perceived emotional expression of music by means of physiological feedback of muscular and autonomic activity; Juslin & V\u00e4stfj\u00e4ll,  ; Lundqvist et al.,  ). This mechanism of cognitive empathy in music is similar to what readers do with a novel's fictional character (Tamir et al.,  ), but with the difference that listeners can imagine their own narrative unfolding on the basis of the musical events. Notably, simulation of other people\u2019s minds during reading is crucially supported by the default mode network and in particular by the dmPFC, which responds preferentially to passage with social and abstract content (Tamir et al.,  ). \n\nThe observed functional connection between vmPFC and V  during sad compared with happy music is in line with our hypothesis, suggesting an association between visual mental imagery processes and listening to sad music, although the causal direction of this relationship requires further investigation. Neuroimaging literature has provided clear evidence of a large overlap between visual perception and visual imagery. Specifically, the early visual cortex (V ) supports the construction of visual mental images (Kosslyn & Thompson,  ). This parallel between cognitive resources involved in imagery and perception also largely applies to the other sensory modalities (Kosslyn et al.,  ). Music very often stimulates internal images in the listener (K\u00fcssner & Eerola,  ), consisting of pictorial representations (natural landscape, colors), embodied image-schemata (picturing a melodic movement as an ascending or descending image), or complex visual narratives (similar to a movie) (Taruffi & K\u00fcssner,  ). Sad music has been found to trigger enhanced mind-wandering in the form of visual mental imagery with emotion- and nature-related content (Taruffi, Pehrs, et al.,  ). Moreover, previous fMRI studies of music and emotion reported the engagement of the primary and secondary visual cortices during music listening (Koelsch & Skouras,  ; Trost et al.,  ; Wallmark et al.,  ). In these experiments\u2014as in the current one\u2014participants underwent scanning with their eyes closed. Therefore, the present data support our hypothesis that individuals who are prone to empathize exhibit enhanced activity of V  and that this pattern is more pronounced during listening to sad compared with happy instrumental film music. Importantly, of the observed functionally connected structures, V  exhibited the highest centrality values and was by far the largest region, suggesting that visual mental imagery might be a central mechanism underlying empathic individuals\u2019 responses to sad music. Furthermore, these findings lead to the intriguing hypothesis to be tested by future research that experiencing vivid visual mental imagery may facilitate empathic participants to transpose themselves into the feelings and thoughts of their imagined characters or events during the music. \n\nOf particular interest is the functional connection between the vmPFC and bilateral CL during sad compared with happy music. The CL\u2014whose function has remained rather obscure to date\u2014is a thin, irregular sheet of gray matter that lies below the general region of the insular cortex and above the PT (Crick & Koch,  ). The CL has extensive reciprocal connections to almost all cortical areas and also to a number of subcortical areas, including lateral amygdala, caudate, PT, and globus pallidus (Fernandez-Miranda et al.,  ; LeVay & Sherk,  ; Park et al.,  ). Due to these widespread connections, Crick and Koch ( ) proposed that the CL synchronizes and binds separate multisensory information, including perceptual, cognitive, motor and emotional content, to form a unitary, single object, thus serving as a consciousness center for the brain. This proposal is consistent with a number of neuroimaging studies showing the involvement of the CL in tasks in which integration of multimodal information is required (Banati et al.,  ; Baugh et al.,  ). Changes in claustral activity in neuroimaging studies of music and emotion are rather uncommon; however, this may be due to the small size of the CL and its proximity to the insula (i.e., instead more commonly engaged during music listening; see, for example, Caria et al.,  ), which make it challenging to discriminate between claustral and insular activity. The functional connectivity between vmPFC and CL observed in the present study is consistent with anatomical bidirectional projections from the CL to the PFC (Park et al.,  ; Tann\u00e9-Gari\u00e9py et al.,  ) and suggests a role of the CL in the integration of the different affective, perceptual, and cognitive processes underlying listening to sad music. Regarding the functional connection between vmPFC and CB, changes in cerebellar activity have been previously linked to dispositional empathy (Jackson et al.,  ; Moriguchi et al.,  ; Singer et al.,  ). In particular in the study by Singer et al. ( ), individuals scoring higher on empathy (as measured by the empathic concern subscale of the IRI and the Balanced Emotional Empathy Scale from Mehrabian & Epstein,  ) showed higher pain-related activity in ACC, left AI, and also lateral right cerebellum. Another possible interpretation could be related to rhythmic entrainment. The cerebellum is involved in the neural tracking of rhythm (e.g.,\u00a0Nozaradan et al.,  ), and trait empathy is positively associated with (sensorimotor) rhythmic entrainment abilities (e.g.,\u00a0Bamford & Davidson,  ). \n\nIn the broad context, our findings extend the current understanding of empathic behaviors to the musical, and in general aesthetic, domain. In line with the previous account of compassion as a social emotion characterized by a concern for another person\u2019s suffering, which is accompanied by positive feelings and a motivation to help (Singer & Klimecki,  ), our study shows that trait empathy is correlated with centrality values within brain regions (mOFC and PT) that are crucially involved in the generation of compassionate feelings also in response to music\u2014an abstract stimulus that does not contain any explicit reference to a human agent. In addition, in our study empathic participants exhibited enhanced centrality values in brain regions that typically underlie social cognition (dmFPC) and mental imagery (V ). Overall, these centrality patterns were specific for sad music, suggesting that this type of music may constitute an effective social signal that triggers specific empathy-related processes in individuals who are already prone to empathy. Although we did not find any significant result for the contrast happy versus sad, our findings do not exclude the possibility that the observed patterns of centrality during sad music also may be at play during happy music. People may find it easier to engage with happy rather than sad music, given that the latter represents a more complex emotion with positive and negative nuances, which could be more readily available to empathic individuals who are prone to transfer themselves into others\u2019 emotions and perspectives; such difference may consequently lead to a range of more sophisticated or enhanced neural responses to sad music in high-empathy participants (e.g., integrating complex affective and cognitive processes), as suggested by the present study. \n\nFurthermore, our findings underscore the importance of considering individual differences when investigating the neural mechanisms underlying musical experiences. This is particularly relevant for the case of sad music, where individual characteristics play a key role. A piece of sad music can be associated with feelings of sorrow or be experienced as pleasurable by someone else. Therefore, future neuroimaging research should foster experimental paradigms that take into account the variance brought about by individual differences in emotional responses to music. Although previous accounts of music-empathy focused predominantly on emotional contagion (e.g.,\u00a0Davies,  ; Juslin & V\u00e4stfj\u00e4ll,  ; Lundqvist et al.,  ), our study points to more sophisticated forms of empathy, involving compassion, mentalizing, and fantasy processes. Clearly, this could be due to the particular music genre of the stimuli employed in this study\u2014film soundtrack\u2014and a question arises about the extent to which the current results can be generalized to other music\u00a0genres. Film music is in fact particularly effective in facilitating listeners to conjure up visual images and to evoke intense emotions as well as vivid daydreams. Therefore, this issue should be addressed by future research employing stimuli from other music genres. \n\nIn future studies, it would be important to show how in empathic individuals the observed neural activity pattern maps onto behavioral responses to sad music. Our data along with evidence collected by previous studies (Eerola et al.,  ; Garrido & Schubert,  ; Kawakami & Katahira,  ; Taruffi & Koelsch,  ; Vuoskoski & Eerola,  ; Vuoskoski et al.,  ) suggest that empathic individuals experience more complex emotional responses toward sad music, including both positive and negative facets. However, this needs to be validated by using a more thorough behavioral assessment in the scanner. Nevertheless, our study still provides an intriguing step forward in the scholarship concerning empathy and sad music by showing that a unique network of brain regions related to individual differences in trait empathy is significantly more active for sad music than for happy music. Finally, although we estimated our target sample on previous research that successfully identified neural correlates of emotional personality using music (Koelsch et al.,  ), we underline here the necessity for future research to increase sample size. Because our sample is relatively small in the context of individual differences research, it could be possible that more potential results have been missed. \n\n\n## Conclusions \n  \nThis study identified a distributed brain network associated with individual differences in trait empathy and spontaneously recruited during listening to sad music. This \u201cmusic-empathy\u201d network comprises brain regions subserving coding of compassion, mentalizing, and visual mental imagery. In addition, a novel site of activation was found in the CL, showing its involvement in a music listening task. Our study contributes to the increasingly sophisticated understanding of the empathic brain, mapping neural dynamics to specific individual characteristics. In this sense, our results are promising because they suggest that the variation in brain-network connectivity provides a valid marker of empathic abilities. Moreover, the fact that music acts as a social stimulus\u2014by triggering empathic individuals to undergo enhanced emotional and cognitive experiences\u2014opens novel possibilities, involving the use of music tasks, for social neurosciences and, in general, speaks about the importance of empathy in aesthetic contexts (an issue that has been discussed by philosophers but mostly overlooked by neuroscientists). \n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table 1.\nAnatomical location\tMNI coordinates\tCluster size (mm3)\tz-value: max (mean)\nEmpathy correlation\tEmpathy correlation\tEmpathy correlation\tEmpathy correlation\nvmPFC/mOFC\t-3 36 -14\t1,053\t3.28 (2.75)\nFC (seed region: vmPFC/mOFC)\tFC (seed region: vmPFC/mOFC)\tFC (seed region: vmPFC/mOFC)\tFC (seed region: vmPFC/mOFC)\ndmPFC\t9 48 37\t972\t3.09 (2.78)\nL. CL/PT\t-24 12 10\t5,238\t3.77 (2.93)\nR. CL/PT\t27 -6 10\t1,404\t3.35 (2.79)\nCB (lobule V, 70%)\t-3 -60 -5\t1,026\t3.46 (2.84)\nCalcarine sulcus (V1, 90%)\t-6 -90 1\t15,255\t4.47 (3.11)\n### Caption\nResults of empathy correlation and functional connectivity analyses for the contrast sad > happy, corrected for multiple comparisons (P < 0.05)\n### Footer\nOutermost right column shows the maximal z-value within a cluster (with the mean z-value of all voxels within a cluster in parentheses). Percentage in parentheses indicates the anatomical probability according to the SPM Anatomy Toolbox (Eickhoff et al., 2005). CB = cerebellum; CL = claustrum; dmPFC = dorsomedial prefrontal cortex; mOFC = medial orbitofrontal cortex; PT = putamen; V1 = primary visual cortex; vmPFC = ventromedial prefrontal cortex.\n", "metadata": {"pmcid": 7994216, "text_md5": "e285ca64a1db56fcbfe605016637de66", "field_positions": {"authors": [0, 74], "journal": [75, 101], "publication_year": [103, 107], "title": [118, 172], "keywords": [186, 251], "abstract": [264, 1727], "body": [1736, 40630], "tables": [40643, 41808]}, "batch": 2, "pmid": 33474716, "doi": "10.3758/s13415-020-00861-x", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7994216", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7994216"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7994216\">7994216</a>", "list_title": "PMC7994216  Trait Empathy Shapes Neural Responses Toward Sad Music"}
{"text": "Riem, Madelon M. E. and Van Ijzendoorn, Marinus H. and Parsons, Christine E. and Young, Katherine S. and De Carli, Pietro and Kringelbach, Morten L. and Bakermans-Kranenburg, Marian J.\nCogn Affect Behav Neurosci, 2017\n\n# Title\n\nExperimental manipulation of infant temperament affects amygdala functional connectivity\n\n# Keywords\n\nAmygdala\nfMRI\nFunctional connectivity\nInfant temperament\nReward\n\n\n# Abstract\n \nIn this functional magnetic resonance imaging (fMRI) study we examined neural processing of infant faces associated with a happy or a sad temperament in nulliparous women. We experimentally manipulated adult perception of infant temperament in a probabilistic learning task. In this task, participants learned about an infant's temperament through repeated pairing of the infant face with positive or negative facial expressions and vocalizations. At the end of the task, participants were able to differentiate between \u201cmostly sad\u201d infants who cried often and \u201cmostly happy\u201d infants who laughed often. Afterwards, brain responses to neutral faces of infants with a happy or a sad temperament were measured with fMRI and compared to brain responses to neutral infants with no temperament association. Our findings show that a brief experimental manipulation of temperament can change brain responses to infant signals. We found increased amygdala connectivity with frontal regions and the visual cortex, including the occipital fusiform gyrus, during the perception of infants with a happy temperament. In addition, amygdala connectivity was positively related to the post-manipulation ratings of infant temperament, indicating that amygdala connectivity is involved in the encoding of the rewarding value of an infant with a happy temperament. \n \n\n# Body\n \n## Introduction \n  \nWhile all infants cry, they differ from each other in how frequently and intensely they cry. Infants with a temperament characterized by negative emotionality cry more often and tend to react to stressors with a high degree of emotionality, including anger, irritability, fear, or sadness (Rothbart, Ahadi, & Hershey,  ). Research has shown that infant temperament influences the way parents respond to their infant. For example, irritable or demanding children may elicit feelings of irritation in parents and withdrawal of contact (Putnam, Samson, & Rothbart,  ). In a meta-analysis, Paulussen-Hoogeboom, Stams, Hermanns, and Peetsma ( ) showed that negative emotionality is associated with insensitive parenting in families with low socioeconomic status. This can in turn lead to later problems with a child\u2019s emotional functioning (Paulussen-Hoogeboom, Stams, Hermanns, Peetsma, & Van Den Wittenboer,  ). However, previous studies examining the relation between infant temperament and caregiver perception and behavior are correlational and parent measures of infant temperament may be influenced by parental negative mood (Youngstrom, Izard, & Ackerman,  ). In natural environments, it is not possible to experimentally manipulate infant temperament to examine its influence on parenting. Here we examine the effects of computerized manipulation of infant temperamental features on adults\u2019 neural processing of infant faces as assessed with functional magnetic resonance imaging (fMRI). \n\nNeuroimaging studies may provide more insight into the perception of infant signals and point to a role of the amygdala (for reviews see Rilling,  ; Swain et al.,  ), a brain region involved in the processing of arousal, threat, or fear, and the detection of emotionally significant stimuli (LeDoux,  ). Several previous studies found amygdala reactivity to the sound of a crying infant, possibly indicating that the amygdala is involved in the detection of threat cues that signal that the infant is in danger (Riem et al.,  ; Seifritz et al.,  ). Amygdala reactivity has also been found in response to infant laughter (Riem et al.,  b; Sander, Brechmann, & Scheich,  ; Seifritz et al.,  ). Thus, the amygdala seems to play a role in the detection of both happy, rewarding infant signals and expressions of infant distress. It is, however, unknown whether the amygdala is also involved in the representation and encoding of infant temperament \n\nIn addition to amygdala activity,   connectivity   between the amygdala and other brain regions involved in emotional processing also plays a role in the perception of infant signals (Atzil, Hendler, & Feldman,  ). The amygdala is suggested to be a functional connectivity hub because of its widespread connections to other brain regions involved in emotional processing (Pessoa,  ; Pessoa & Adolphs,  ). For example, the amygdala has strong reciprocal connections to the visual cortex and these connectivities facilitate the perceptual tuning in the visual sensory cortex based on stimulus evaluation and significance. Visual cortex responses to emotionally salient stimuli depend on inputs received from the amygdale, and this process serves the upregulation of processing emotionally significant stimuli (Pessoa,  ,  ; Pessoa & Adolphs,  ; Vuilleumier & Pourtois,  ), such as positive or negative infant signals. In addition, amygdala connectivity with frontal regions, such as the orbitofrontal cortex and the medial prefrontal cortex, is important for encoding the rewarding value and associative information about the motivational significance of stimuli (Murray,  ; Schoenbaum, Chiba, & Gallagher,  ). In a previous study, we found increased amygdala connectivity with frontal reward areas during exposure to infant laughter after administration of the hormone oxytocin (Riem et al., 2012b). Thus, amygdala connectivity seems to be involved in the encoding of the rewarding value of infant signals and may also be involved in the representation of a happy infant temperament. \n\nIn the current study, we examine neural activity and connectivity in response to infants with experimentally manipulated temperament using a paradigm called the Baby Social Reward Task (BSRT) (Bhandari et al.,  ; Parsons et al.,  ). The BSRT is a probabilistic learning task where child temperament is derived from learning the facial and vocal features indicative of a more or less happy or sad baby. The BSRT consists of three parts: The first phase is a baseline measure of perceived temperament and cuteness. In addition, participants indicate their motivation to see the infant faces by key pressing to control the length of time the faces are onscreen. The second phase is training where, over a series of trials, participants learn to differentiate more often sad and more often happy infants by observing the infants\u2019 facial expressions and vocalizations. After the training phase, participants evaluate the infants again in terms of temperament, cuteness, and motivation to see the infant. The BSRT has been used to show that the perception of infant temperament and cuteness is not based on physical facial features alone, but is modifiable through experience (Bhandari et al.,  ; Parsons et al.,  ). \n\nHere, we use the BSRT to compare brain activity during the perception of neutral faces of infants with happy or sad temperaments to the activity during the perception of neutral infant faces without temperamental cues. This experimental procedure is a unique window to study variations in brain activity triggered by infants with different temperaments under controlled experimental conditions. We expect that the amygdala is involved in the encoding of infant temperament and shows elevated reactivity to infants with a sad temperament, even in the absence of salient emotional expressions of the infant. In addition, we expect that amygdala connectivity is related to ratings of infant temperament and involved in explaining individual differences in the perception of infants with different temperaments. \n\n\n## Method \n  \n### Participants \n  \nParticipants were 54 female undergraduate students from the Department of Child and Family Studies, Leiden University. Participants were screened for MRI contraindications, childhood experiences, psychiatric or neurological disorders, hearing problems, pregnancy, alcohol and drug abuse, and did not have children of their own. See Riem et al. ( ) for the recruitment and selection of participants. More than 95% of the participants were born in The Netherlands. Two participants were excluded due to excessive head movement and two participants were excluded because fMRI scanning could not be completed due to technical or health problems during the session. Three participants were excluded from the analysis because they did not learn to discriminate between the sad and happy infants and their mean accuracy scores were two standard deviations below the mean on the final part of the learning phase of the BSRT. This resulted in a total sample size of 47 participants for the current study. The mean age of the participants was 19.62 (SD = 2.12). Written informed consent was obtained from all participants. Permission for this study was obtained from the Institute\u2019s Ethics Committee and from the Leiden University Medical Centre Ethics Committee. \n\n\n### Procedure \n  \nParticipants were invited for a lab session at the Leiden University Medical Center. They first signed the consent form and were screened for MRI contraindications. Afterwards, the Baby Social Reward Task (BSRT) was administered. The BSRT was used to manipulate and measure participants\u2019 perception of the temperament of six babies (see Parsons et al.,  , for a detailed explanation of the paradigm). The task consisted of three different phases: baseline measures of participants\u2019 responses to the infant faces, the experimental manipulation of infant temperament, and post-manipulation measures of participants\u2019 responses to the infant faces. \n\nThe first phase consisted of two tasks: the Rating task and the Wanting task (Parsons et al.,  ). In both tasks each baby\u2019s face is presented on the middle of the screen with a neutral expression. In the Rating task the participant is asked to evaluate the babies on three different dimensions (\u201ccuteness,\u201d and two temperament dimensions \u201cdifficultness\u201d and \u201ceasiness\u201d) pressing the \u201cup\u201d or \u201cdown\u201d arrow on the keyboard to change the level of a vertical visual analogue scale (VAS). Similar to Parsons et al. ( ), the ratings of difficultness and easiness were then combined (the difficultness values were reversed) to produce a global measure of temperamental easiness of the baby. Stimuli were presented in random order for 5 s and each participant rated each face once. The Wanting task is a measure of motivation to see each baby\u2019s face. The participants are asked to press the \u201cup\u201d or \u201cdown\u201d arrow to change the time they want to see the baby. A vertical VAS with a descending level represented the passing of time and the participant\u2019s key pressing changed the speed of the descending level (pressing the \u201cup\u201d arrow decreased the speed of the descending level, extending the amount of time the face was onscreen, while pressing the \u201cdown\u201d arrow increased its speed, reducing the amount of time the face was onscreen). Data regarding the baseline ratings of the baby faces are presented in the Appendix. \n\nThe second part of the BSRT consisted of the manipulation of the temperament: in each trial the participants were presented with one of three pairs of baby faces and they were asked to identify, by trial and error, the happy baby or the sad baby of the pair. Participants selected one of the two babies and received feedback, in the form of a change of facial expression and an equivalent vocalization (either \u201chappy\u201d or \u201csad\u201d). By means of repeated trials, participants could infer how often the baby cried or laughed and decide which one was the happier or the sadder of the two. Similar to Parsons et al. ( ), participants were instructed that \u201cIn each pair of faces, there is one happy and one sad baby. Like in real life the happy baby will not always be happy and the sad baby will not always be sad. In each set your task is to find the happier baby, the one who smiles most often, and continue to always select this baby even if this baby may sometimes appear sad.\u201d The three pairs of babies varied in the probability of each infant of being happy or sad. In the easy pair, the easy-to-learn   happy   infant laughed in 80% of trials and cried in the remaining 20% of trials. The easy-to-learn   sad   infant laughed in 20% of trials and cried in the other 80% of trials. In the difficult-to-learn pair the difficult-to-learn   happy   infant laughed 60% of the time while the difficult-to-learn   sad   infant laughed 40% of the time. As a variation to the BSRT task used in previous works (Parsons et al.,  ), we adapted the procedure to the fMRI requirements by eliminating a third pair (with 70% of probability for the \u201chappy baby\u201d to be happy) and instead introduced a \u201cneutral pair\u201d where no feedback was given. Participants were informed about this neutral pair and were told that they would not receive feedback about one pair of infants. See Table   for an explanation of the labels that are used for each infant in the current study. Participants received feedback just for the selected baby, but they could infer that the infant not selected would show the opposite emotion on each trial. In each trial, neutral faces were presented onscreen until participants made a response. After participants made a response, visual feedback was presented immediately for 1.5 s accompanied by a 1.5-s vocalization. There was a 500-ms gap between the end of the feedback and the beginning of the next trial during which a red fixation cross was presented in the center of the screen.   \nLabels and explanations for the 80%, 60%, 40%, and 20% happy babies and the neutral babies \n  \n\nThe training consisted of two blocks of 60 trials each, so that each pair was presented 40 times in total (20 times per block). In one of the two blocks the participant was asked to select the happy baby, and in the other to select the sad baby. The order of the trials was randomized within session and the order of the blocks was randomized between participants. The identity of the babies (happy, sad, or neutral) was randomized between participants. \n\nAfter the training phase participants were ready to start the fMRI procedure. Participants were asked to change clothes and were given instructions about the fMRI paradigm (see fMRI paradigm and data acquisition). The third phase of the BSRT, consisting of the post-manipulation evaluation of the babies, was administered after the fMRI paradigm. During this phase participants were asked to perform the Rating and Wanting tasks again. Participants rated the cuteness, easiness, and difficultness of the babies and indicated through button-press how long they wanted to see the babies. See the Appendix for data regarding the post-manipulation ratings of the baby faces. Comparisons of the pre- and post-manipulation ratings and wanting data showed that the manipulation of temperament was effective. The pre-manipulation measurements did not show significant differences in perceived temperament between the infants (see supporting information in the Supplemental Material). The BSRT was programmed and performed using Presentation software (Version 14.4 Neurobehavioral Systems, Inc.,  ). \n\n\n### Stimuli \n  \nAll infant faces images and vocalizations were the same as those used in Parsons et al. ( ) and Bhandari et al. ( ). The pictures represented smiling, crying, and neutral faces for each of the six babies (aged 3\u201312 months) of the set. In order to reduce any confounding effects of stimulus gender, we had an independent sample of adult females (n = 40) rate faces from a larger set of 13 (Kringelbach et al.,  ) as \u201cmale,\u201d \u201cfemale,\u201d or \u201ccannot tell.\u201d These ratings were then used to select six faces such that there were two faces clearly perceived as female, two as male, and two with ambiguous ratings (Parsons et al.,  ). Images were in grayscale and equal in size (300\u00d7300 pixels) and luminosity. Vocalizations were six laughing babies and six crying babies, as unambiguously evaluated by adults (Young et al., 2012), and sampled from the larger Oxford Vocal (OxVoc) Sounds Database, which is a validated set of non-acted affective sounds from human infants, adults, and domestic animals (Parsons et al.  ). The vocalisations were 1.5 s long, free from background noise, and matched for the characteristics of the sounds. Vocalizations were presented to the participants through headphones. The infant vocalizations and emotional expressions were only used during the training phase of the BSRT. During the fMRI task, only neutral facial expressions were presented to participants. \n\n\n### fMRI paradigm and data acquisition \n  \nInside the MRI scanner, participants were presented with the six infant faces   with neutral facial expressions  , one at a time. Each neutral infant face was presented in the center of the screen and accompanied by the words \u201csad\u201d and \u201chappy.\u201d Participants were asked to indicate if the infant was happy or sad by using button presses with the right hand, based on what they had learned during the training phase of the BSRT. Infant faces were presented 20 times for a maximum of 2.6 s, in random order, resulting in a total of 120 infant presentations. The task was self-paced, meaning that the task continued to the next trial after a button press. Interstimulus intervals were jittered and calculated using Optseq ( ). The mean number of errors during the fMRI paradigm was calculated, excluding the trials with the neutral infants because there was no correct answer for these infants. The percentage of incorrect trials was 26.3% (M = 21.04, SD = 17.58). Because of the low number of incorrect trials within each condition, it was not possible to reliably examine brain activation during correct versus incorrect trials during the fMRI task. The fMRI paradigm was programmed and administered using E-Prime software (version 2.0). \n\n\n### fMRI data acquisition and analysis \n  \nScanning was performed with a standard whole-head coil on a 3-T Philips Achieva TX MRI system (Philips Medical Systems, Best, The Netherlands) in the Leiden University Medical Center. For fMRI, a total of 298 T2*-weighted whole-brain echoplanar images were acquired (repetition time = 2.2 s; echo time = 30 ms, flip angle = 80\u00b0, 38 transverse slices, voxel size 2.75 \u00d7 2.75 \u00d7 2.75 mm (+10% interslice gap)). Following the fMRI scan, a T1-weighted anatomic scan was acquired (flip angle = 8\u00b0, 140 slices, voxel size .875 \u00d7 .875 \u00d7 1.2 mm). \n\nThe following pre-statistics processing was applied: motion correction (MCFLIRT, Jenkinson et al.,  ), non-brain removal (Smith,  ), spatial smoothing using a Gaussian kernel of full-width-at-half-maximum 8.0 mm, and highpass temporal filtering (highpass filter cutoff = 90.0 s). Functional scans were registered to the high-resolution EPI-images (high-resolution functional scans), which were registered to the T1-weighted images, which were registered to standard space (Jenkinson et al.,  ). \n\nData analysis was carried out using FEAT (FMRI Expert Analysis Tool) version 6.00, part of FSL (Smith et al.,  ). In native space, functional activity was examined using general linear model analysis. Each infant (easy-to-learn   happy  , difficult-to-learn   happy  , easy-to-learn   sad  , difficult-to-learn   sad  , neutral 1, neutral 2) was modeled separately as a square-wave function. Each predictor was then convolved with a double gamma hemodynamic response function and its temporal derivative was added to the model, giving six regressors. To examine brain regions involved in the perception of infants with different temperaments, we contrasted the easy-to-learn   happy  , the difficult-to-learn   happy  , the easy-to-learn   sad  , and the difficult-to-learn   sad   infant with one of the neutral infants (easy-to-learn   happy   > neutral, difficult-to-learn   happy   > neutral, easy-to-learn   sad   > neutral, difficult-to-learn sad > neutral). \n\nIn addition, we examined psychophysiological interactions (PPI), that is, condition-dependent changes in the covariation of the response between a seed region and other brain regions (Friston et al.,  ). We used the left and right amygdala as seed regions. We extracted the mean time series for each participant from the left and the right amygdala, defined using the Harvard\u2013Oxford subcortical atlas. These time series were then used as a physiological regressor in the model. We applied two separate models: one to analyze left amygdala connectivity, and one to study right amygdala connectivity. Contrasts for the easy-to-learn   sad  , easy-to-learn   happy  , difficult-to-learn   sad  , difficult-to-learn   happy   infant, and the neutral infant (all conditions versus baseline) were created. These regressors were convolved with a double gamma hemodynamic response function and their temporal derivatives were added to the model. The easy-to-learn   sad  , easy-to-learn   happy  , and the neutral infant contrasts were used as psychological regressors. Finally, the interaction between the psychological regressors and the time series from the left or right amygdala were modeled. We assessed the positive and negative contrast of the interaction in order to examine condition-dependent changes in functional connectivity. \n\nAll first-level contrast images and the corresponding variance images were transformed to standard space and submitted to second level mixed-effects group whole brain analyses. The group mean was tested using one-sample t-tests on these contrasts and the reverse contrasts (neutral > easy-to-learn   happy  , neutral > difficult-to-learn   happy  , neutral > easy-to-learn   sad  , neutral > difficult-to-learn   sad  ). For PPI analysis, we tested the group means using one-sample t-tests on the positive and negative contrasts of the psycho-physiological interaction. We only examined functional connectivity during the easy-to-learn happy and sad infants because behavioral and functional activation results indicated that the easy-to-learn happy and sad infants were more emotionally salient compared to the difficult-to-learn happy and sad infants. We included the number of errors of the last ten trials of the training phase of the BSRT as a confound regressor in the functional activity analysis and PPI analysis. The statistical images were thresholded using clusters determined by   Z   > 2.3 and a cluster corrected significance threshold of   p   < .05. Moreover, because of concerns about Type 1 errors (Eklund, Nichols, & Knuttson,  ), analyses were repeated with a strict threshold of   Z   > 3.0 and   p   < .05. Results from the analyses with the Z > 3.0 contrast are presented in the Supplemental Material. \n\nA whole brain analysis was conducted to examine brain activity during the perception of infants with different temperaments. In addition, a region of interest (ROI) analysis was conducted to examine functional activity in the bilateral amygdala, anatomically defined using the Harvard\u2013Oxford subcortical atlas ( ). \n\nMean Z-values were calculated (using Featquery) for brain regions that were significantly connected to the amygdala, the bilateral occipital fusiform gyrus and the left middle frontal gyrus (anatomically defined using the Harvard\u2013Oxford cortical atlas), in order to examine the relation between amygdala connectivity and the post manipulation ratings of the infants. \n\n\n\n## Results \n  \n### Behavioral analyses \n  \nWe examined the relation between the number of errors that were made in the fMRI paradigm and the temperament ratings of the infants after the manipulation. The number of errors was negatively related to the mean post-manipulation rating of the happy infants (easiness and difficultness rating (reversed) combined) (  r   = \u2212.40,   p   < .01) and the difference between the pre and post-manipulation rating of the happy infants (  r   = \u2212.34,   p   < .05), but not to the pre-manipulation rating (  r   = \u2212.09,   p   = .53). Individuals who made fewer errors during the fMRI paradigm rated the happy infants as more positive afterwards, indicating that individuals were accurate during fMRI when the temperament manipulation was effective. The number of errors was not significantly related to the mean post-manipulation rating of the sad infants (easiness, and difficultness rating (reversed) combined) (  r   = .19,   p   = .20). \n\n\n### Functional brain activation \n  \nA whole brain analysis was conducted to examine brain activity during the perception of neutral infant faces associated with a happy, sad, or neutral temperament. We assessed the contrasts (i) easy-to-learn   happy   infant versus neutral infant, (ii) difficult-to-learn   happy   infant versus neutral infant, (iv) easy-to-learn   sad   infant versus neutral infant (v) difficult-to-learn   sad   infant versus neutral infant, and the reverse contrasts. The contrast difficult-to-learn   happy   infant versus neutral infant showed significant activity in the cuneal cortex, but no significant activity was found during the perception of the easy-to-learn   happy   infant, the easy-to-learn   sad   infant, the difficult-to-learn   happy   infant, and the difficult-to-learn   sad   infant compared to neutral infants. However, the reverse contrasts, comparing activity during neutral infants with easy-to-learn   sad   or easy-to-learn   happy   infants, revealed significant activity in several brain regions (see Table   and Figs.\u00a0  and  ). We found significant activity during the perception of the neutral infant compared to the easy-to-learn   happy   infant in the middle frontal gyrus, orbitofrontal cortex, the frontal pole, the angular gyrus, the putamen, the anterior cingulate cortex, precuneus, the middle and superior temporal gyrus, the insula and the paracingulate gyrus. In addition, during the perception of the neutral infant compared to the easy-to-learn   sad   infant, significantly more activity was found in the postcentral gyrus, the precuneus, the frontal pole, the orbitofrontal cortex, the anterior cingulate cortex, the paracingulate gyrus, the thalamus, the nucleus accumbens, and the putamen (see Table   and Figs.\u00a0  and  ). The ROI analysis with the amygdala showed significant amygdala activity during the perception of the easy-to-learn   happy   infant compared to the neutral infant. No significant amygdala activity was found during the perception of the easy-to-learn or difficult-to-learn   sad   infant or difficult-to-learn   happy   infant compared to the neutral infant.   \nMNI coordinates, cluster size, and Z-max values for significantly activated clusters revealed by the whole brain analysis and ROI analysis with the amygdala  \n    \nSignificant activity during the perception of the neutral infant compared to the easy-to-learn   happy   and   sad   infant and difficult-to-learn   happy   infant compared to the easy-to-learn   happy   infant. Facial expressions of the infants were neutral.   ACC   anterior cingulate cortex,   PCG   paracingulate gyrus,   THA   thalamus,   MTG   middle temporal gyrus,   PostCG   postcentral gyrus,   PRE   precuneus,   PCC   posterior cingulate cortex,   PUT   putamen,   FP   frontal pole,   OFC   orbitofrontal cortex,   INS   insula,   SMG   supramarginal gyrus,   STG   superior temporal gyrus. The right side of the brain corresponds with the left hemisphere and vice versa. Statistical images were thresholded with clusters determined by   Z   > 2.3 and a cluster-corrected significance threshold of   p   < 0.05 \n    \nMean and SE Z values of anterior cingulate cortex activity during presentation of the easy-to-learn   happy   infant and neutral infant and precuneus activity during the easy-to-learn   sad   infant and neutral infant \n  \n\nIn additional analyses, we assessed the contrasts easy-to-learn   happy   infant versus difficult-to-learn   happy   infant and easy-to-learn   sad   infant versus difficult-to-learn   sad   infant. There was significantly more activity in the supramarginal gyrus, postcentral gyrus, middle and superior temporal gyrus, insula, and putamen during the perception of the difficult-to-learn   happy   infant compared to the easy-to-learn   happy   infant (see Fig.\u00a0 ). The pattern of activation partially overlapped with brain activity resulting from the neutral infant compared to the easy-to-learn   happy   infant. The contrast easy-to-learn   sad   infant versus difficult-to-learn   sad   infant did not reveal significant activity. \n\n\n### Functional connectivity \n  \nWe performed PPI analyses to examine amygdala connectivity during the perception of infants with different temperaments. When participants were presented with the easy-to-learn   happy   infant (vs. baseline), there was significant connectivity between the right amygdala and the bilateral occipital fusiform gyrus (OFG), the lateral occipital cortex, the occipital pole, the postcentral gyrus, inferior temporal gyrus, and the lingual gyrus and between the left amygdala and the left middle frontal gyrus (MFG), the frontal pole, the inferior frontal gyrus, the postcentral gyrus, and the lateral occipital cortex (see Table   and Fig.\u00a0  for the clusters of connectivity and Table S1 for the local maxima in the clusters). In addition, we found significant functional connectivity between the left amygdala and the left superior frontal gyrus during the presentation of the neutral infant (vs. baseline). There was no significant amygdala connectivity during the presentation of the easy-to-learn   sad   infant.   \nOverview of functional amygdala connectivity: MNI coordinates, cluster size, and Z-max values for significant clusters of functional connectivity \n    \nSignificant functional connectivity with the left (red) and right (blue) amygdala during the presentation of the easy-to-learn   happy   infant (with a neutral facial expression).   ITG   inferior temporal gyrus,   PCG   postcentral gyrus,   MFG   middle frontal gyrus,   IFG   inferior frontal gyrus,   LG   lingual gyrus,   LOC   lateral occipital cortex,   OFG   occipital fusiform gyrus,   OP   occipital pole. The right side of the brain corresponds with the left hemisphere and vice versa. Statistical images were thresholded with clusters determined by   Z   > 2.3 and a cluster-corrected significance threshold of   p   < 0.05 \n  \n\nFurthermore, mean Z-values were extracted from the OFG and the MFG in order to examine the relation between amygdala-OFG/MFG connectivity and the post-manipulation ratings of the infants. There was a significant positive correlation between amygdala-OFG connectivity and the post-manipulation temperament rating of the happy infants (  r   = .31,   p   = .03, not significant after Bonferroni correction) (see Fig. S4 for a scatterplot). Individuals with high levels of amygdala-OFG connectivity during the presentation of the easy-to-learn   happy   infant rated the happy infants as more positive than individuals showing low levels of functional connectivity. A contrast Z-value was calculated by subtracting the mean Z-value for the OFG during the presentation of the neutral infant from the mean Z-value for the OFG during the presentation of the easy-to-learn   happy   infant. The correlation between the contrast Z-value (easy-to-learn   happy   infant vs. neutral infant) and the post-manipulation temperament rating of the happy infants was significant (  r   = .30,   p   = .04). There was no significant correlation between amygdala-OFG connectivity and the post-manipulation cuteness ratings of the happy infants (  r   = \u2212.06,   p   = .71) or time wanting to view the happy infants (  r   = \u2212.04,   p   = .81). Neither were there significant correlations between amygdala-MFG connectivity and the post-manipulation ratings of the happy infant (all   p   > .17). \n\n\n\n## Discussion \n  \nThe current fMRI study is the first to experimentally manipulate infant temperament and examine subsequent neural processing of infant faces. We employed a computerized probabilistic learning task that manipulated infant temperamental features, the BSRT, to create a sense of the temperament of previously unfamiliar infants and examined its effects on neural processing. Our study is the first to demonstrate how a simple temperament manipulation can change brain activity to a basic social reward, namely infants with a neutral facial expression. We found that exposure to infants with a happy or sad temperament resulted in decreased activation in a neural network involved in emotion processing compared to infants without temperamental cues. In addition, our results indicate that amygdala connectivity is involved in explaining individual differences in the perception of infant temperament, which is in line with previous studies indicating that the amygdala plays an important role in the perception of infant signals (Barrett et al.,  ; Kim et al.,  ; Riem, Bakermans-Kranenburg, van Ijzendoorn, Out, & Rombouts,  a; Riem et al.,  ). Our study indicates that previous positive or negative experiences with an infant influence how the brain responds to that infant. Infants with a sad or happy temperament elicit different brain activity and connectivity than infants with an unknown temperament, even when the facial expression is neutral and the same for all infants. This effect cannot be accounted for by a familiarity effect, for all infant faces were presented with the same frequencies. \n\nInfant faces without temperamental cues resulted in increased activation in a neural network involved in emotional processing compared to infant faces with a happy or sad temperament. More specifically, neutral infants elicited activation in brain regions involved in empathy, including the insula and anterior cingulate cortex (Lamm, Decety, & Singer,  ), and brain regions involved in theory of mind and mentalizing, including the precuneus and middle and superior temporal gyrus (Carrington & Bailey,  ; Van Overwalle & Baetens,  ). One explanation for this finding is that these neutral infant faces may have been perceived as ambiguous. Although participants had seen the neutral infants as often as the infants with the happy and sad temperament, they did not \u201cknow\u201d the infants in terms of their temperament and emotionality. Categorizing infants without temperamental cues as being happy or sad is more difficult, requires more effort, and may therefore result in more neural activation. Knowing the temperament of an infant seems to be adaptive because it requires fewer neural resources, regardless of whether the infant has a happy or sad temperament. Thus, information about infant temperament may facilitate the interpretation of infant signals and the selection of an appropriate caregiving response. \n\nContrary to our expectations, we did not find increased amygdala activity in response to infants with a sad temperament. This seems to be in contrast to previous studies pointing towards a role in the processing and perception of infant distress (Riem et al.,  ). One explanation for the absence of amygdala activity is that we contrasted amygdala activity during the perception of sad and happy infants with neutral infants. The amygdala also responds to neutral faces (Pessoa,  ), which might explain why the sad versus neutral contrast did not reveal significant amygdala activity. In contrast to previous studies that found amygdala responses to sad infant faces or infant cry sounds, we did not present participants with stimuli with clear threat signals: the facial expression of the infants were neutral in all conditions. The amygdala shows a rapid and automatic response to threat, independent of context, attention, and awareness (Dolan & Vuilleumier,  ). A sad infant temperament is not a direct alarming signal of threat and may therefore not elicit different amygdala activity compared to neutral infant faces. \n\nInterestingly, we found increased amygdala connectivity during the perception of infants with a happy temperament. This is consistent with the suggestion that amygdala connectivity is involved in encoding the rewarding value of stimuli (Murray,  ; Schoenbaum et al.,  ). Moreover, amygdala connectivity during the perception of the happy infants was related to the post-manipulation temperament rating of the happy infants. Individuals with high levels of amygdala-OFG connectivity rated the happy infants as more positive than individuals showing low levels of functional connectivity. The amygdala is functionally and anatomically connected to the regions of the visual cortex, including the fusiform gyrus, and exerts a modulatory influence on visual cortex responses based on the biological and affective relevance of the stimulus. In this way, the amygdala prioritizes the processing of emotional stimuli over others and separates significant from less significant stimuli (Pessoa,  ). The fusiform gyrus is particularly important for face processing and receives amygdala projections that serve enhanced processing of emotional faces (Herrington, Taylor, Grupe, Curby, & Schultz,  ; Vuilleumier, Richardson, Armony, Driver, & Dolan,  ). Our finding that amygdala-occipital fusiform gyrus connectivity is related to the temperament ratings of the happy infants might therefore indicate that the amygdala plays an important role in enhancing the processing of positive emotional infant stimuli and tagging infant stimuli such as infant laughter as emotionally significant, in particular in nulliparous females. Surprisingly, amygdala connectivity during the perception of the sad infant was not related to temperament ratings of the sad infant, possibly because the participants perceived the sad infant as less emotionally salient. Indeed, a comparison of the pre- and post-manipulation ratings of temperament indicated that only the happy infants were perceived as more positive and cute after the training phase of the BSRT. In line with our findings, a previous study indicated that non-parents are particularly sensitive to infant laughter and show less amygdala reactivity to crying than to laughter (Seifritz et al.,  ). In contrast, parents showed more amygdala reactivity to crying than to laughter. Thus, this vocalization-specific pattern of response seems to change after the transition to parenthood, which may be important for the adaptation to the specific demands associated with successful infant care (Seifritz et al.,  ). \n\nOur study has a few limitations. First, functional connectivity using fMRI is a correlational method that does not allow conclusions about (the direction of) any causal relation between the amygdala and other brain regions. The development of new whole-brain computational modelling methods may in the future allow for further investigations of the underlying causal mechanisms (Deco & Kringelbach, 2014; Deco et al.  ). Second, our findings can only be generalized to women without children of their own. Women without children were recruited for participation in order to control for influences of parenting experiences with own infants. The results may be different in parents because amygdala reactivity to infant signals are influenced by parental status (Seifritz et al.,  ). Since infant crying can trigger harsh caregiving responses and even child abuse and neglect (Barr, Trent, & Cross,  ; Reijneveld, Van der Wal, Brugman, Sing, & Verloove-Vanhorick,  ), it is important to examine how infants who cry more often than others are perceived by their parents and how that relates to caregiving behavior. It should be noted that temperament is a complex construct that was simplified to only one dimension ranging from happy to sad in the current study. Other aspects of infant temperament such as activity and inhibition are more difficult to artificially model in an experimental paradigm like the BSRT. However, experimental manipulation is not possible in natural contexts because it would require rather forceful interventions. The advantage of our simplified, one-dimensional manipulation of temperament, however, is the more unequivocal, focused interpretation of a very salient temperamental characteristic. Finally, an untrained neutral condition was used as a baseline condition in this study. Enhanced brain activity during an untrained neutral condition may be related to the lack of training, e.g. not being able to draw on memory or not knowing the right response. However, this is unlikely since we also found enhanced activity during the perception of the difficult-to-learn   happy   infant compared to the easy-to-learn   happy   infant, even though participants were reliably trained to identify both infants as happy and rated both infants as cuter and more positive after the training phase (see Supplemental Material). This indicates that even subtle differences in infant temperament are associated with changes in brain activity. Thus, although the difficult-to-learn   happy   infant and the easy-to-learn   happy   infant were both perceived as happy infants, they elicited differential patterns of brain activity, indicating that previous experiences with an infant influence brain responses to that infant. \n\nIn sum, we examined how computerized manipulation of infant temperamental features affects subsequent neural processing of infant faces as assessed with fMRI. To our knowledge, this is the first demonstration of how temperament manipulation can change brain responses to infant signals. We found that information about infant temperament results in decreased activation of a neural network involved in emotion processing, possibly indicating that infant temperament is a source of contextual information that facilitates the interpretation of infant signals. Our findings point to a role of the amygdala in the perception of infant signals and indicate that amygdala connectivity is involved in the representation of infant temperament. Amygdala connectivity appears to be important for the encoding of the rewarding value of an infant with a happy temperament, which may affect subsequent caregiving responses. \n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table 1\nLabel\tExplanation\tLikelihood of positive expression\nEasy to-learn happy Baby\tThe happy baby in the easy pair\t80%\nEasy-to-learn sad Baby\tThe sad baby in the easy pair\t20%\nDifficult-to-learn happy Baby\tThe happy baby in the difficult pair\t60%\nDifficult to-learn sad Baby\tThe sad baby in the difficult pair\t40%\nNeutral\tNo cues about temperament\t\u2013\n### Caption\nLabels and explanations for the 80%, 60%, 40%, and 20% happy babies and the neutral babies\n### Footer\nNone\n\n\n## ID: Tab2\n### Label: Table 2\nContrast\tBrain region\tN voxels\tZ max\tMNI coordinates Z max\tMNI coordinates Z max\tMNI coordinates Z max\nContrast\tBrain region\tN voxels\tZ max\tx\ty\tz\nNeutral > Easy-to-learn Happy\tL middle frontal gyrus\t7,305\t4.2\t\u221232\t24\t28\nNeutral > Easy-to-learn Happy\tR angular gyrus\t7,296\t4.5\t54\t\u221248\t40\nNeutral > Easy-to-learn Happy\tR putamen\t3,381\t4.08\t32\t\u221216\t0\nNeutral > Easy-to-learn Happy\tL putamen\t1,533\t4.01\t\u221226\t\u221214\t4\nNeutral > Easy-to-learn Happy\tR amygdalaa\t14\t2.61\t18\t\u221214\t\u221212\nDifficult-to-learn Happy > Neutral\tR cuneal cortex\t2,165\t3.5\t8\t\u221280\t34\nDifficult-to-learn Happy > Easy-to-learn Happy\tR putamen\t4,355\t3.74\t26\t\u22126\t8\nNeutral > Easy-to-learn Sad\tR postcentral gyrus\t8,787\t3.87\t52\t\u221228\t56\n\tR frontal pole\t1,980\t4.0\t26\t46\t24\n\tR nucleus accumbens\t1,189\t3.58\t14\t18\t\u22126\n### Caption\nMNI coordinates, cluster size, and Z-max values for significantly activated clusters revealed by the whole brain analysis and ROI analysis with the amygdala a\n### Footer\nNone\n\n\n## ID: Tab3\n### Label: Table 3\nContrast\tDirection\tSeed region\tFunctional connectivity\tN voxels\tZ max\tMNI coordinates Z max\tMNI coordinates Z max\tMNI coordinates Z max\nContrast\tDirection\tSeed region\tFunctional connectivity\tN voxels\tZ max\tx\ty\tz\nEasy-to-learn Happy\t-\tRight amygdala\tLingual gyrus\t8,363\t4.12\t16\t\u221264\t\u221212\nEasy-to-learn Happy\t-\tLeft amygdala\tMiddle frontal gyrus\t1,092\t3.68\t\u221252\t32\t24\nEasy-to-learn Happy\t\t\tLateral occipital cortex\t927\t3.32\t\u221226\t\u221262\t50\nNeutral\t+\tLeft amygdala\tSuperior frontal gyrus\t1,089\t3.32\t\u22128\t0\t72\n### Caption\nOverview of functional amygdala connectivity: MNI coordinates, cluster size, and Z-max values for significant clusters of functional connectivity\n### Footer\nNone\n", "metadata": {"pmcid": 5548834, "text_md5": "fddd188b8926a3bb643e7f6355a55649", "field_positions": {"authors": [0, 184], "journal": [185, 211], "publication_year": [213, 217], "title": [228, 316], "keywords": [330, 394], "abstract": [407, 1756], "body": [1765, 42206], "tables": [42219, 44393]}, "batch": 2, "pmid": 28585020, "doi": "10.3758/s13415-017-0518-8", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548834", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5548834"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5548834\">5548834</a>", "list_title": "PMC5548834  Experimental manipulation of infant temperament affects amygdala functional connectivity"}
{"text": "Javadi, Amir Homayoun and Schmidt, Dirk H.K. and Smolka, Michael N.\nNeuropsychologia, 2014\n\n# Title\n\nDifferential representation of feedback and decision in adolescents and adults\n\n# Keywords\n\nDevelopmental\nUncertainty\nAnterior cingulate cortex (ACC)\nVentral striatum (VS)\nVentromedial prefrontal cortex (vmPFC)\nReward processing\nDecision-making\nProbabilistic reversal learning\n\n\n# Abstract\n \nIt is widely accepted that brain maturation from adolescence to adulthood contributes to substantial behavioural changes. Despite this, however, knowledge of the precise mechanisms is still sparse. We used fMRI to investigate developmental differences between healthy adolescents (age range 14\u201315) and adults (age range 20\u201339) in feedback-related decision making using a probabilistic reversal learning task. Conventionally groups are compared based on continuous values of blood oxygen level dependent (BOLD) percentage signal change. In contrast, we transformed these values into discrete states and used the pattern of these states to compare groups. We focused our analysis on anterior cingulate cortex (ACC), ventral striatum (VS) and ventromedial prefrontal cortex (vmPFC) as their functions have been shown to be critical in feedback related decision making. Discretisation of continuous BOLD values revealed differential patterns of activity as compared to conventional statistical methods. Results showed differential representation of feedback and decision in ACC and vmPFC between adolescents and adults but no difference in VS. We argue that the pattern of activity of ACC, vmPFC and VS in adolescents resulted in several drawbacks in decision making such as redundant and imprecise representation of decision and subsequently poorer performance in terms of the number of system changes (change of contingencies). This method can be effectively used to infer group differences from within-group analysis rather than studying the differences by direct between-group comparisons. \n   Highlights  \n  \nACC activity in adults represented solely the subsequent decision. \n  \nACC activity in adolescents reflected both feedback and decision. \n  \nActivity of vmPFC in adults reflected both feedback and decision. \n  \nActivity of vmPFC in adolescents it represented feedback only. \n  \nVS represented feedback and did not differ between adolescents and adults. \n  \n \n\n# Body\n \n## Introduction \n  \nWhen making decisions, adolescents generally show a propensity towards risk-taking and novelty-seeking due to the greater lure of positive consequences, as well as the considerable influence of social context, resulting in the disregard of disregarding negative consequences ( ). For example, self-report and observational studies have shown that adolescents are involved in the majority of traffic accidents ( ). These individuals also have a higher chance of engaging in criminal behaviour, substance abuse and unsafe sexual activity. Such behaviour has been associated with an \u201cimbalance\u201d in the development of different brain areas in adolescents ( ). \n\nMaturation of the human brain and reorganisation of neuronal structures related to emotional, motivational and cognitive processes are essential for the establishment of behavioural control, cognitive flexibility and efficient brain function. Differences in the pattern of development of reward and control-related circuitry have been proposed to lead to an \u201cimbalance\u201d in the adolescent brain, presumably due to immature frontal lobe suppression of reward sensitivity in mesolimbic regions ( ). Behavioural changes in risk-taking observable during development might be explained by an imbalance between early maturing mesolimbic brain regions, namely the ventral striatum functionally associated with affective information processing, relative to less mature prefrontal areas, critically involved in top-down control ( ). As a result, compared to adults, adolescents place greater value on the potential positive (as opposed to negative) consequences of risk-taking ( ). Nevertheless the literature is inconsistent and therefore it is highly debated whether reward-related striatal brain activity is exaggerated or attenuated in the adolescent brain. Some neuroimaging studies found the striatum to be hypersensitive during reward processing ( ) while others report hyposensitivity on rewards in striatal regions ( ) in adolescents. \n\nAlbeit this inconsistency several studies have shown differences in terms of behavioural performance between adolescents and adults in a large variety of reward-related tasks. For instance adults perform better when choosing between high- and low-risk or during feedback-based learning ( ). Using a deterministic reversal learning task   found that overall performance increases from age 10 to 25. Interestingly, punishment-based learning was best for the youngest age group, whereas reward-based learning was best in young adults. \n\nThese differences in behaviour and brain activity have increasingly attracted attention to developmental studies of the brain and behaviour of adolescents. In this context we aimed to investigate their differences in the context of feedback-related decision making. \n\nWe used a probabilistic reversal learning (PREL) task to investigate how adolescents and adults incorporate feedback (both rewarding and punishing) in their decisions in a dynamic and uncertain environment, where feedback is probabilistic and contingencies change from time to time. PREL has been used previously in many studies investigating feedback-related decision making using behavioural ( ), brain imaging ( ) and computational modelling ( ) approaches. \n\nThree main brain regions that have been implicated with probabilistic reversal learning are anterior cingulate cortex (ACC), ventral striatum (VS) and ventromedial prefrontal cortex (vmPFC). It has been shown that ACC is crucial for the processing of feedback-related decision-making and error management ( ), for a review see ( ). The difference between the expected value and the actual outcome of an action, known as reward prediction error (PE), is encoded in the VS ( ). vmPFC has been found to be critically important in   reversal   learning (for a review see ( ). As such, we focused our analysis on these brain areas. \n\nTo date, direct comparison of groups has provided us with a rich body of knowledge. We, however, were not interested in how adolescent and adult brain activity differed in a given condition, but in a more abstract and functional comparison between groups. Contrary to conventional methods of comparison in which groups are directly compared using between-group tests, we compared groups by converting brain activity into discrete states based on a 2-level randomisation procedure. Blood oxygen level dependent (BOLD) percentage signal changes in different conditions were transformed into states of activity, i.e. continuous percentage signal changes were converted into a few discrete states. This conversion enabled us to remove baseline differences and overcome intrinsic scale differences between adolescents and adults groups.   shows an example of how this conversion was carried out. These states represented different conditions in the brain in terms of feedback and decision for the subsequent trial. The patterns of these states in different brain areas were then compared between adolescents and adults. This method is comparable with drawing conclusions on differences between groups from within-group comparisons. \n\n\n## Methods \n  \n### Participants \n  \nThe data from adolescents were acquired as part of the project \u201cThe adolescent brain\u201d funded by the German Federal Ministry of Education and Research (BMBF). This project aims to investigate structural and functional brain development in the context of environmental and genetic factors. The study has a longitudinal design and seeks to reveal links between functional as well as structural brain development and occurrence of substance use disorders. We present results of the first acquisition wave of adolescent data in a cross-sectional design compared to data of an adult group. \n\n260 adolescents were recruited from local secondary schools (adolescent group). We had to exclude 40 adolescents from the analysis due to acute head movements (movements greater than 3\u00a0mm in any one direction), interruption in scanning, fault in data transfer or missing data. Consequently we analysed data for 220 adolescents (115 male (52.27%), age range 14\u201315, mean age 14.61 years (SD=0.32)). As a control group we recruited 28 adult participants (adult group) by board and Internet announcements (17 male (58.62%), age range 20\u201339, mean age 25.24 years (SD=6.34)). Adolescents were screened with the structured diagnostic interview \u201cdevelopment and well-being assessment\u201d (DAWBA) ( ) according to the fourth edition of the diagnostic and statistical manual (DSM-IV) and adults were screened using the \u201ccomposite international diagnostic interview\u201d (CIDI) ( ). This was done to control for homogeneity among the two groups and to exclude participants with history of psychiatric or neurologic diseases. Adults performed all and exactly the same tasks as adolescents. \n\nAll participants were compensated for taking part in this study. All the participants in the adults group, the adolescents and at least one legal guardian for each adolescent gave their written informed consent to participate in the study after receiving a comprehensive description of the study protocol. The study was carried out in accordance with the Declaration of Helsinki. The study was approved by the local research ethics committee. \n\n\n### Apparatus \n  \nThe stimuli were presented via a head-coil-mounted display system based on LCD technology (NordicNeuroLab AS, Bergen, Norway). Participants responded with a ResponseGrip  (NordicNeuroLab AS, Bergen, Norway). Stimuli were presented using the Presentation  software (v11.1 Neurobehavioral Systems Inc. Albany CA, USA). Behavioural data was analysed using SPSS (v17.0; LEAD Technologies Inc., Charlotte, NC, USA). Imaging data was analysed using MATLAB (v7.5; MathWorks Company, Natick, MA, USA) and SPM5 (Wellcome Trust, London, UK). \n\n\n### Image acquisition \n  \nAll MRI data were acquired at the Neuroimaging Centre at the Technische Universit\u00e4t Dresden, using a 3.0\u00a0T scanner (Magnetom Tim Trio, Siemens, Erlangen, Germany). Series of T -weighted echo-planar images (EPI) with 42 transverse slices tilted approximately 30\u00b0 towards the coronal beyond the anterior to posterior commissure line, with a 3\u00a0mm in-plane resolution and a slice thickness of 2\u00a0mm (1\u00a0mm gap resulting in a voxel size of 3\u00d73\u00d73\u00a0mm ), field-of-view (FoV) of 192\u00d7192\u00a0mm , a flip angle (FA) of 80\u00b0, a repetition time (TR) of 2410\u00a0ms, a bandwidth of 2112\u00a0Hz/pixel, and an echo time (TE) of 25\u00a0ms were acquired. The first 3 volumes were discarded to allow the magnetisation to reach equilibrium. High-resolution three-dimensional anatomical images were acquired using a T -weighted magnetisation-prepared, rapid acquisition gradient echo (MP-RAGE) sequence with a FoV=256\u00d7224\u00a0mm , 176 slices, a voxel size of 1\u00d71\u00d71\u00a0mm , a TR of 1900\u00a0ms, a TE of 2.26\u00a0mm and a FA of 9\u00b0. \n\n\n### Task description \n  \nWe employed a probabilistic reversal learning task similar to that used by  . Please see  (a) for a detailed description of the procedure of a trial. During each trial, participants were presented with two options, which differed in probabilities of monetary outcomes associated with them. One option was associated with a 70% chance of gaining 20 Euro cents (positive feedback (PFB)) and 30% chance of losing 20 Euro cents (negative feedback (NFB)), while the other option was associated with 40% chance of PFB and 60% chance of NFB. The option with a higher mean payoff (70% PFB: 30% NFB) was designated as the   correct   option, while the other option (40% PFB: 60% NFB) was designated as the   wrong   option. Participants were instructed to maximise their gains, that is, to identify and choose the   correct   option at every trial. At the end of each trial, participants were provided with feedback. Additionally on the feedback screen they were presented with the total amount of money they had accumulated over the preceding trials. Prior to the scan, participants were told that in addition to their participation fee (5 Euros), they would also receive their earnings from the in-scanner task. \n\nApart from learning to identify the   correct   option during each session, participants also had to adapt to changes in reward contingencies over time. During the session, should the participant choose the   correct   option consecutively four times, contingencies of the options could reverse. That is, the option that was previously   correct   becomes the   wrong   option, and vice versa for the other option. However, as these reversals in contingencies only occurred at a 25% probability after correct responses to at least last four consecutive trials, participants had to remain vigilant in adapting to these changes to maximise their gains. This reward-punishment schedule has been well established in previous probabilistic reversal learning studies ( ). \n\nThe in-scanner task consisted of 120 trials. Total task duration was 26\u00a0min. Before entering the scanner, participants performed a training session of the task consisting of three phases; see  (b). In the first phase of the training session, system changes (change of contingencies) were implemented, but participants were provided with deterministic feedback \u2013 that is they were always rewarded for correct responses and punished for wrong responses. The phase ended upon three consecutive system changes. In the second phase, there was no system change, but feedback was probabilistic. The phase ended once the participant has selected the   correct   option consecutively ten times. The third phase combined probabilistic feedback with system changes. This phase was identical to the main task in the scanner. Similar to that of the first phase, this phase ended upon three system changes. Once they have completed their training, the participants proceeded with the in-scanner task. \n\n\n### Behavioural data analysis \n  \nThree behavioural performance measures were considered: ratio of correct responses, total accumulated monetary reward and number of system changes. Ratio of correct responses was defined as the ratio of total number of correct responses to total number of trials. On a broad level, the ratio of correct responses reflects how well the participant was able to form associations between the feedback and the options. Number of system changes adds a further dimension as it is dependent on participant\u05f3s understanding of the underlying mechanism of the task, i.e. system changes based on performance. For the purpose of quantifying individual differences in adaptation to a dynamic environment, it is necessary to include both measures to take into account how well they were able to learn the associations and how quickly they were able to adapt to changes. \n\nRatios of behavioural switch after negative and positive feedbacks, i.e. proportion of behavioural switch after NFB and PFB to the total number of feedbacks were also computed. This parameter was subjected to a mixed-factor analysis of variance (ANOVA) with feedback (NFB/PFB) as within-subject factor and group (adolescents/adults) as between subject factor. Data were checked for normal distribution using a Kolmogorov-Smirnov goodness-of-fit test. The Mann\u2013Whitney U-test was used for non-parametric tests. Mean and standard deviation (SD) values are reported for factors with normal distribution and median for factors with non-normal distribution. \n\n\n### Imaging data analysis \n  \nData was preprocessed to correct for slice timing differences and head motion, spatially normalised to a standard EPI template in MNI space and smoothed with a 8\u00a0mm FWHM isotropic Gaussian kernel. Templates were based on the MNI305 stereotaxic space, an approximation of Talairach space ( ). \n\nFor the first level analysis, event-related fMRI data were analysed by constructing \u03b4-functions. We constructed a general linear model (GLM) with five regressors: one at the onset of the stimulus, three at the onset of feedback in the current trial and decision in the subsequent trial (PFB, NFB-Stay and NFB-Switch). We did not split trials with PFB into PFB-Stay and PFB-Switch because participants rarely switched their decision after PFB; finally one regressor for trials with no response at the onset of both stimulus and feedback. All of these regressors were convolved with a canonical hemodynamic response function (HRF). In addition, the six scan-to-scan motion parameters produced during spatial realignment were included to account for residual motion effects. \n\nThree regions-of-interest (ROI) were specified: anterior cingulate cortex (ACC), ventromedial prefrontal cortex (vmPFC) and ventral striatum (VS). For the ACC mask, we first combined Brodmann areas 24 and 32 provided in Wake Forest University (WFU) PickAtlas for SPM ( ). It was then masked by a 24\u00a0mm radius sphere located at MNI space (0, 27, 45) to remove the pregenual and posterior parts of anterior cingulate. For the vmPFC mask, we used an automated anatomical labelling (AAL) atlas provided in the WFU PickAtlas. For the VS, the regions were specified in accordance to probabilistic maps freely available online ( ). Binary images were made using the threshold value of 0.5 for VS. The selected threshold provided the possibility to cover the whole VS. Finally, the rfxplot toolbox for SPM ( ) was then used to extract the mean activity elicited by PFB, NFB-Stay and NFB-Switch of the voxels specified by the ROIs. The masks are shown in  . \n\nBrain imaging data analysis was performed in two steps: (1) the first step used a 2-level randomisation procedure in order to compensate for the imbalance in the number of participants in the groups, non-normal distribution of the data and outliers in the two groups. This procedure was used throughout the imaging data analysis to analyse the main and interaction effects and   post-hoc   tests. (2) In the second step data was categorised into states of activity using the results of the earlier step. This step was used to account for intrinsic differences between adolescents and adults\u05f3 brain activity and base the comparison solely on the significance of differences between the two groups rather their literal magnitudes. \n\nRandomisation procedure, similar to permutation procedure, generates simulated participants based on data acquired from real participants. These generated participants are used to create distributions that are later used for statistical comparison. Participants and distributions are created through   permutation runs  . The first level of randomisation is for generation of simulated participants and the second level of randomisation is for creation of distributions that are subsequently used in statistical test of real data. These randomisation procedures were run on participant and group levels as previously used by  . On the first level, a randomisation procedure using 200,000\u00d7220 permutation runs for the adolescent group and 200,000\u00d728 permutation runs for the adult groups were carried out to generate simulations of participants. In this run, for each simulated participant, three values (for the three conditions of PFB/NFB-Stay/NFB-Switch) were randomly selected (with replacement) from all the values of brain activities, separately for each ROI. Different comparisons were made for the second level of randomisation: main and interaction effects (comparable with main and interaction effects in ANOVA). Subsequently significant and non-significant interactions were subjected to   post-hoc   paired-wise tests with- and with-out groups collapsed, respectively. For this level 500,000 permutation runs were conducted to achieve (i) a distribution of grand difference between adolescents and adults (adolescents vs. adults) in each condition and (ii) distributions of grand differences of mean values over the three conditions (3 comparisons, PFB vs. NFB-Stay, PFB vs. NFB-Switch and NFB-Stay vs. NFB-Switch) for the two groups separately and (iii) the same measures as in (ii) with the two groups pooled together. The second set of distributions are for the case of significant interaction effects and the third set of distributions are for the case of non-significant interaction effects as tested using the first set of distributions. For this level of randomisation, groups of 220 adolescents and groups of 28 adults were randomly selected (with replacement) from the population of simulated participants in each group. These distributions were used to determine the   p  -value of comparison for real data ( ). The distributions of   p  -values for   post-hoc   tests over the three ROIs were corrected for multiple comparisons according to the false discovery rate (FDR) procedure ( ). We computed a   q   threshold that set the expected rate of false discoveries to 0.029. Furthermore, absolute value of Cliff\u05f3s Delta effect size measure (  \u03b4  ) was reported ( ). This measure relies on dominance concept rather than mean as in conventional effect size measures such as Cohen\u05f3s   d   and is more robust under skewed distributed data. \n\nIn order to compare our 2-level randomisation procedure with standard whole-brain voxel-wise SPM analyses we ran 2\u00d72 full-factorial ANOVAs for each ROI with condition (pairs of three conditions of PFB/NFB-Switch/NFB-Stay) and group as independent factors and percentage signal change as dependent factor. Therefore, similar to the 2-level randomisation procedure we ran 9 (3\u00d73) different 2\u00d72 full-factorial ANOVAs. \n\nThe focus of our study was on comparison between adolescents and adults in the pattern of activity of ACC, VS and vmPFC in a probabilistic reversal learning task, i.e. how each group of participants represented feedback and decision in the subsequent trial in these brain areas, rather than comparing brain activities directly between the groups. As such, the BOLD percentage signal change was first converted into   states   of activity, that is, where activity differed significantly between conditions using pair-wise comparisons.   shows an example of this classification. This way, we constructed bi- or tri-state patterns of activity for the three conditions (PFB, NFB-Stay and NFB-Switch) and each brain area. \n\n\n\n## Results \n  \n### Behavioural data \n  \nOur results showed that the ratio of correct responses and total accumulated monetary reward were normally distributed, but number of system changes was not. Independent-sample   t  -test on the ratio of correct responses showed no significant difference between groups (adolescents mean (SD)=0.59 (0.07), adults 0.61 (0.06),   t  (246)=1.03,   p  =0.30). Similarly, no significant difference was found for accumulated monetary reward between groups (adolescents 3.58 (1.56), adults 3.51 (1.34),   t  (246)=0.23,   p  =0.81). However, there was significantly higher number of system changes in adults than adolescents (median adolescents 6, adults 7, non-parametric Mann\u2013Whitney   U  -test   Z  =\u22122.04,   p  =0.04). \n\nA 2\u00d72 mixed-factor ANOVA on ratio of behavioural switch after NFB and PFB revealed significantly higher switching rates in adolescents compared to adults (adolescents=0.28 (0.10), adults 0.23 (0.10), main effect of group:   F  (1, 246)=5.37,   p  =0.02,   \u03b7  =0.03), significantly higher switching rates after NFB (NFB=0.46 (0.24), PFB=0.06 (0.16), main effect of feedback:   F  (1, 246)=677.15,   p  <0.001,   \u03b7  =0.73) but a non-significant 2-way interaction (  F  (1, 246)=0.01,   p  =0.92,   \u03b7  <0.001). \n\n\n### Imaging data \n  \nOur imaging data analysis was focused on the main effects of condition (comparisons of PFB\u2013NFB-Stay, PFB\u2013NFB-Switch, and NFB-Stay\u2013NFB-Switch) and 2-way interaction of group and condition.   summarise these comparisons and   shows the median of BOLD percentage signal change in different groups and conditions. In order to compare our method with standard whole-brain, voxel-wise SPM analyses we ran 2\u00d72 full-factorial ANOVAs on different ROIs with different condition pairs and groups. Results of these analyses are shown in  . Results showed similar significant differences for the main effect of condition. On the contrary results showed no significant interaction effect.   shows box plots of percentage signal change in different conditions. \n\n Activity in ACC  ; PFB elicited a lower BOLD response than NFB (significant main effects of PFB\u2013NFB-Stay and PFB\u2013NFB-Switch). Moreover, there was a stronger BOLD response associated with NFB-Switch than NFB-Stay. The randomisation procedure revealed a significant interaction of group and the condition of PFB\u2013NFB-Stay.   Post-hoc   tests indicated that adolescents showed a significantly higher ACC response to NFB-Stay than PFB, while adults\u05f3 brain activity between NFB-Stay and PFB was similar. \n\n Activity in   VS; VS activity was substantially higher in PFB than NFB conditions and there was no difference in VS activity between NFB-Stay and NFB-switch conditions. Furthermore, VS activity did not differ between adolescents and adults in any of the comparisons (non-significant interactions). \n\n Activity in vmPFC  ; As in the VS, vmPFC activity was much higher in the PFB condition than in NFB conditions. Moreover, this difference was more pronounced in adults than in adolescents (significant interactions). There was a significant interaction of group and condition in all comparisons. Within-group   post-hoc   tests showed a difference only in the comparison of NFB-Stay and NFB-Switch in which adolescents showed a non-significant difference while adults showed a very highly significant difference. It should be mentioned that, the 2-level randomisation procedure led to 3 significant interactions. The second step of analysis, conversion of continuous values into discrete states of activity, however, revealed a difference in only one of the comparisons (NFB-Stay\u2013NFB-Switch). \n\nTo summarise, adolescents and adults differed mainly in ACC activity during the PFB and NFB-Stay conditions and vmPFC activity during the NFB-Stay and NFB-Switch conditions, as marked by \u2018\u2020\u2019 in  . \n\nThe continuous BOLD percentage signal change (shown in  ) was converted into states of activity based on the   p   values of   post-hoc   tests and main effect of condition in the case of significant and non-significant interactions, respectively. The result of this conversion is shown in  . Differences between adolescents and adults are reflected in ACC (comparison of PFB and NFB-Stay) and vmPFC (comparison of NFB-Stay and NFB-Switch). \n\n\n\n## Discussion \n  \nIn this study, we tested adolescents and adults to investigate contributions of ACC, VS and vmPFC in feedback-related decision making using a probabilistic reversal learning task. We aimed to investigate how these brain areas represent various conditions of feedback and resulting decision. Subsequent to a 2-level randomisation procedure (1st step) we transformed continuous values of percentage signal change of BOLD signal into discrete states before performing between-group comparisons for different conditions (2nd step). This method revealed differences between the two groups that were not possible to detect using conventional statistical approaches. \n\nOur behavioural data showed a lower number of system changes and a higher ratio of behavioural switch in adolescents compared to adults, but no difference in the ratio of correct responses. Conversion of the brain imaging data into discrete states of activity revealed a difference in the pattern of activity of ACC and vmPFC between adolescents and adults, but no difference in the pattern of activity of VS in response to feedback and subsequent decision (PFB/NFB-Switch/NFB-Stay). These results imply that ACC activity reflected both feedback and decision in adolescents whereas it represented only decision in adults. vmPFC activity represented feedback in adolescents, whereas it reflected both feedback and decision in adults. VS activity reflected solely feedback for both groups. \n\nThere are several models that explain the decision making network from different perspectives and emphasise different aspects of information processing ( ) (for reviews see ( ;  ;  )).   proposed a model which shows the interaction between ACC, VS and vmPFC in decision making, with regard to feedback (input) and decision (output).   shows a schematic of their model. Based on their model, ACC activity reflects the decision based on the provided feedback. This functional role of ACC is also supported by other researchers ( ). According to this model, activity in VS is directly modulated by feedback that additionally incorporates expectation and serves as prediction error, modulated by ACC activity ( ). The updated expectation levels are represented in the vmPFC ( ) which form the basis of the resultant decision. \n\nACC, VS and vmPFC activity observed in our adult participants are in line with the model proposed by   with ACC representing decision ( ), VS responding to feedback ( ), and vmPFC reflecting both feedback and decision (by receiving a modulatory signal from VS) (for a review see ( )). However, our observations in adolescents are not in line with this model as ACC reflected both feedback and decision and vmPFC represented feedback only. We speculate that these observations could be related to poorer feedback-related decision making and probabilistic reversal learning in adolescents. \n\nIn two-choice decision tasks, be it deciding between a circle and rectangle or stay and switch, two states of ACC activity is sufficient for the representation of the decision, as shown in adults. This is an efficient way of representation, as the separation of the states is clear. This classification in adolescents, however, is done in three states, which induces complications in interpretation of the activity of ACC in terms of behavioural decision (namely   stay   and   switch  ). Having three states of brain activity for two possible options requires finer tuning of threshold of   stay   and   switch   in between PFB and NFB-Stay with NFB-Switch. This also introduces redundant representation of   stay   behavioural decision for PFB and NFB-Stay as both of them lead to   stay  . In other words, it is more accurate (and perhaps easier) for the brain areas responsible to make the final motor action to deal with bi-state representation of decision, as in adults, than tri-state one, as in adolescents. \n\nAnother possible drawback of the brain activity in adolescents arises from the activity of vmPFC in response to feedback and subsequent decision. As shown, the activity of vmPFC in adolescents solely represents for feedback which is redundant and identical to the function of the VS. Therefore, its activity does not contribute to the cycle of decision making and expectation update mechanism, which might be a reason for the imprecise representation of decision in ACC. \n\nOur observations suggest that vmPFC could encode an underlying value signal beyond feedback and decision. Adolescents seem to be hypersensitive to NFB, regardless of whether it is relevant (NFB on wrong responses) or misleading NFBs (NFB on correct responses). Further analysis showed that adolescents were more prone to switching behaviour following misleading NFB. That is, they tended to switch more often than adults after receiving misleading NFB (see  ). We speculate that adults were better able to suppress the effects of misleading NFB and stay with their previous decision, while adolescents were more affected by negative feedback. This could reflect a more efficient top-down control (perhaps driven by ACC) in adults while adolescents lacked this cognitive control ability. \n\nTo further investigate differential involvement of the ACC and vmPFC between groups in different conditions, we ran a 3-way mixed-factor ANOVA with condition (PFB/NFB-Stay/NFB-Switch), ROI (ACC/vmPFC) as within subject factors and group (adults/adolescents) as between subject factor. This test showed a significant interaction of the three factors   F  (2, 492)=3.234,   p  =0.040,   \u03b7  =0.013). We should emphasise that the conclusions based on our proposed method of discretisation stand valid without having a significant interaction in an ANOVA. For instance, the outliers in our sample could be arranged in a way that led to a non-significant interaction as the ANOVA does not account for outliers, which are far away from the distribution. \n\nComparison of our randomisation procedure with standard whole-brain voxel-wise SPM showed similar effects for the main effects. In contrast, this analysis showed no significant interaction. This shows that our approach is not a replication of standard analyses, but reveals effects that are not uncovered by standard analyses. Our novel analysis approach, however, should be validated with conventional analytic approaches in further studies. \n\nBehaviourally, the observations are in line with that of the imaging observations. Adolescents showed a higher rate of behavioural switch and lower number of system changes than adults. Both adolescents and adults had comparable numbers of correct responses. It has to be mentioned that adolescents achieved lower number of system changes. As such, they dealt with a more stable system than adults with significantly higher number of system changes. \n\nTo summarise, our results showed a differential representation of feedback and decision in the ACC and vmPFC in adolescents and adults. We argued that this differential representation results in several drawbacks in decision making for adolescents such as redundant and imprecise representation of feedback and decision leading to a higher ratio of behavioural switch and possibly also higher levels of uncertainty. We speculated that adolescents have difficulty in differentially inhibiting negative feedback, reflecting weaker cognitive control. Furthermore, we showed that the functional role of ACC, VS and vmPFC in adults was in-line with the model proposed by   whereas adolescents\u05f3 brain activity in ACC and vmPFC was not in-line with the model. \n\n \n\n# Table(s)\n## ID: t0005\n### Label: Table 1\nROI\tCondition\tMain effect\tMain effect\tInteraction\tPost-hoctest adolescents\tPost-hoctest adolescents\tPost-hoctest adults\tPost-hoctest adults\nROI\tCondition\tp\t\u03b4\tp\tp\t\u03b4\tp\t\u03b4\nACC\tPFB\u2013NFB-Stay\t<0.001\t0.23\t0.015\t<0.001???\t0.244\t0.210???\t0.125\nACC\tPFB\u2013NFB-Switch\t<0.001\t0.419\t0.057\t\t\t\t\nACC\tNFB-Stay\u2013NFB-Switch\t<0.001\t0.192\t0.491\t\t\t\t\nVS\tPFB\u2013NFB-Stay\t<0.001\t0.337\t0.162\t\t\t\t\nVS\tPFB\u2013NFB-Switch\t<0.001\t0.227\t0.369\t\t\t\t\nVS\tNFB-Stay \u2013 NFB-Switch\t0.208\t0.064\t0.284\t\t\t\t\nvmPFC\tPFB\u2013NFB-Stay\t<0.001\t0.265\t0.041\t<0.001\t0.243\t0.003\t0.455\nvmPFC\tPFB\u2013NFB-Switch\t<0.001\t0.345\t<0.001\t<0.001\t0.309\t<0.001\t0.674\nvmPFC\tNFB-Stay\u2013NFB-Switch\t0.071\t0.086\t0.010\t0.145???\t0.068\t0.027???\t0.275\n### Caption\nSummary of the randomisation procedure comparing the three conditions (PFB/NFB-Stay/NFB-Switch) in adolescents and adults split over the three regions of interest. Main effect refers to main effect of condition with groups pooled together. Interaction refers to 2-way interaction of condition and group. Post-hoc comparisons for different conditions are reported for conditions with significant (p<0.05) 2-way interaction of condition and group. ACC, VS and vmPFC stand for anterior cingulate cortex, ventral striatum and ventromedial prefrontal cortex, respectively.\n### Footer\n\u2020Refers to conditions where adolescents and adults differed significantly.\n\n\n## ID: t0010\n### Label: Table 2\nROI\tCondition\tx\ty\tz\tk\tF\tp\nACC\tPFB\u2013NFB-Stay\t6\t24.0\t42\t275.0\t81.04\t<0.001\nACC\tPFB\u2013NFB-Stay\t\u22123\t9.0\t51\t\t35.0\t<0.001\nACC\tPFB\u2013NFB-Stay\t9\t12.0\t51\t\t27.89\t<0.001\nACC\tPFB\u2013NFB-Switch\t6\t24.0\t39\t422.0\t61.79\t<0.001\nACC\tPFB\u2013NFB-Switch\t\u22129\t24.0\t33\t\t47.62\t<0.001\nACC\tPFB\u2013NFB-Switch\t\u22126\t9.0\t51\t\t36.47\t<0.001\nACC\tNFB-Stay\u2013NFB-Switch\t9\t3.0\t51\t306.0\t27.98\t<0.001\nACC\tNFB-Stay\u2013NFB-Switch\t\u22126\t3.0\t51\t\t26.63\t<0.001\nACC\tNFB-Stay\u2013NFB-Switch\t\u22129\t21.0\t33\t\t24.24\t<0.001\nVS\tPFB\u2013NFB-Stay\t12\t6.0\t\u22129\t97.0\t102.41\t<0.001\nVS\tPFB\u2013NFB-Stay\t\u221212\t3.0\t\u22129\t67.0\t62.08\t<0.001\nVS\tPFB\u2013NFB-Stay\t\u22129\t18.0\t\u221212\t\t20.03\t<0.001\nVS\tPFB\u2013NFB-Switch\t9\t6.0\t\u22129\t31.0\t34.48\t<0.001\nVS\tPFB\u2013NFB-Switch\t\u221212\t3.0\t\u22129\t19.0\t25.96\t<0.001\nVS\tNFB-Stay\u2013NFB-Switch\t\t\t\t\t\tns\nvmPFC\tPFB\u2013NFB-Stay\t0\t54.0\t\u22123\t127.0\t62.79\t<0.001\nvmPFC\tPFB\u2013NFB-Stay\t0\t42.0\t\u22129\t\t59.14\t<0.001\nvmPFC\tPFB\u2013NFB-Stay\t3\t30.0\t\u221212\t\t40.27\t<0.001\nvmPFC\tPFB\u2013NFB-Switch\t\u22126\t36.0\t\u22129\t44.0\t42.02\t<0.001\nvmPFC\tPFB\u2013NFB-Switch\t3\t21.0\t\u221212\t\t21.97\t<0.001\nvmPFC\tNFB-Stay\u2013NFB-Switch\t\t\t\t\t\tns\n### Caption\nThis table summarises the results of the main effect of condition in 2\u00d72 full-factorial ANOVAs with condition (pairs of three conditions of PFB/NFB-Switch/NFB-Stay) and group as independent factors and percentage signal change as dependent factor with F(1, 490). Each coordinate shows the location of peak activity in each specific ROI. Reported p values are uncorrected with k>10. ns stands for non-significant. ACC, VS and vmPFC stand for anterior cingulate cortex, ventral striatum and ventromedial prefrontal cortex, respectively.\n### Footer\nNone\n", "metadata": {"pmcid": 3991323, "text_md5": "3040558f5b58a6318308e55effe8dfc8", "field_positions": {"authors": [0, 67], "journal": [68, 84], "publication_year": [86, 90], "title": [101, 179], "keywords": [193, 378], "abstract": [391, 2361], "body": [2370, 34368], "tables": [34381, 37286]}, "batch": 2, "pmid": 24513024, "doi": "10.1016/j.neuropsychologia.2014.01.021", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3991323", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3991323"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3991323\">3991323</a>", "list_title": "PMC3991323  Differential representation of feedback and decision in adolescents and adults"}
{"text": "Tang, Jinsong and Liao, Yanhui and Deng, Qijian and Liu, Tieqiao and Chen, Xiaogang and Wang, Xuyi and Xiang, Xiaojun and Chen, Hongxian and Hao, Wei\nBehav Brain Funct, 2012\n\n# Title\n\nAltered spontaneous activity in young chronic cigarette smokers revealed by regional homogeneity\n\n# Keywords\n\nChronic cigarette smokers\nRegional homogeneity\nResting-state functional magnetic resonance imaging\n\n\n# Abstract\n \n## Background \n  \nFew studies have been previously published about the resting state brain activity in young chronic smokers, although many previous fMRI studies have shown that the task-related activity pattern is altered in chronic smokers. \n\n\n## Methods \n  \nIn the present study, forty-five healthy smokers (age: 27.9\u2009\u00b1\u20095.6\u2009year) and forty-four healthy non-smoking control subjects (age: 26.3\u2009\u00b1\u20095.8\u2009year) have been imaged with functional magnetic resonance imaging (fMRI) and analyzed with the regional homogeneity (ReHo) approach. \n\n\n## Results \n  \nCompared with healthy controls, decreased ReHo was found in smokers in the right inferior frontal cortex and increased ReHo was found in the left superior parietal lobe (P\u2009<\u20090.01, 35 Voxels,Alphasim corrected). \n\n\n## Conclusions \n  \nOur data suggested that, during resting state, neural function is less synchronized in the right inferior frontal cortex and more synchronized in the left superior parietal lobe in chronic smokers compared to non-smokers. The decreased synchronization in the right inferior frontal cortex may reflect lacking of control over reward-related behavior, and the increased synchronization may reflect smoking urges. \n\n \n\n# Body\n \n## Background \n  \nChina, accounting for 30% of the world's smokers, is the nation with the largest population of smokers [ ]. Chronic smoking in China causes a million deaths a year [ ]. Total worldwide smoking related deaths are projected to rise from 5.4 million in 2005 to 6.4 million in 2030 [ ]. \n\nMany functional magnetic resonance imaging (fMRI) studies have been performed to examine the effects of acute nicotine administration in smokers and non-smokers. A common finding from acute administration of nicotine/smoking is the globally reduced brain activity [ ]. However, only a few studies [ - ] reported alteration of brain function activity during resting state in chronic smokers. The resting-state fMRI is a fundamental method to understand global and regional brain functional activity [ ]. It has more potential applications in clinical studies than task-related fMRI which involves relatively complicated tasks. \n\nRegional homogeneity (ReHo)[ ] provides an approach to investigate local brain functional connectivity. The ReHo method measures local correlations in blood-oxygen-level-dependent (BOLD) time series, using Kendall\u2019s coefficient of concordance (KCC) (Kendall and Gibbons., 1990). KCC is based on time course correlations between a given voxel and its neighbors. Thus, it can be used to measure the correlations between a number of time series of a given voxel and its nearest neighbors in a voxel-wise way. Findings from a recent study with 16 male heavy smokers suggested decreased synchronization in the prefrontal regions, as well as increased synchronization in the insula and the posterior cingulate cortex [ ]. The aim of the present study was to further investigate the ReHo of spontaneous brain dynamics in young chronic smokers with a relatively large sample size. \n\n\n## Materials and methods \n  \n### Subjects \n  \nThe study sample comprised 45 smokers and 44 age-matched healthy volunteers (See Table   for participant demographics and smoking history). All these subjects were recruited from the local community by advertisements. They were initially screened during a semi-structured telephone interview to assess smoking, medical, psychiatric, medication, and substance use history. Smokers who had smoked 10 or more cigarettes per day during the previous year and had no period of smoking abstinence longer than 3\u2009months in the past year, and met DSM-IV criteria for nicotine dependence were eligible for the study. All non-smokers had never smoked a cigarette before the study. More detailed information of subject recruitment procedures have been presented in a previous study [ ].  \n  \nDemographic characteristics of the smokers and non-smokers \n  \n significantly different from control group, p\u2009<\u20090.01. \n\n three participants reported drinking more than once a week among smokers and no non-smoking participants reported drinking more than once a week. \n\n Before MRI acquisition run, participants were asked to rank their craving from 0 (\u201cnot at all\u201d) to 10 (\u201cextreme\u201d). \n  \nParticipants were excluded if they were a minority other than Han Chinese or had a diagnosis of mental retardation, current or past alcohol or drug abuse/dependence, a current or past central nervous system disease or condition, a medical condition or disease with likely significant central nervous system effects, history of head injury with skull fracture or loss of consciousness greater than 10\u2009minutes, a physical problem that would render study measures difficult or impossible, any current or previous psychiatric disorder, a family history of a psychotic disorder, current or previous use of electroconvulsive therapy or psychotropic medications, or a positive pregnancy test. A licensed psychiatrist conducted all clinical interviews. The Second Xiangya Hospital of Central South University Review Board approved all procedures used. The studies were carried out in accordance with the Declaration of Helsinki. Subjects were fully informed about the measurement and MRI scanning in the study. Written informed consent was given by all study participants. \n\n\n### MRI Data acquisition \n  \nResting state functional magnetic resonance (MR) images were acquired using a 3.0-Tesla Siemens scanner (Allegra; Siemens Medical System) at the Magnetic Resonance Center of Hunan Provincial People's Hospital. Foam pads were used to reduce head movements and scanner noise. Participants were required simply to keep still as much as possible, close their eyes and not to think of anything systematically. The resting-state functional images were acquired by using an echo-planar imaging sequence with the following parameters: 36 axial slices, thickness/skip\u2009=\u20093/1\u2009mm, in-plane resolution =64\u2009\u00d7\u200964, repetition time\u2009=\u20093000\u2009ms, echo time\u2009=\u200930\u2009ms, flip angle\u2009=\u200990, field of view\u2009=\u2009220\u2009\u00d7\u2009220\u2009mm, 180 volumes. \n\n\n### Data analysis \n  \nThe first 10 time points of the fMRI data were discarded because of the instability of the initial MRI signal and the adaptation of the subjects to the scanning environment. The remaining 170 images were pre-processed using Statistical Parametric Mapping 5 (SPM5;  ). They were slice-time-corrected, and aligned to the first image of each session for motion correction, spatially normalized to the Montreal Neurological Institute (MNI) EPI template in SPM5, and each voxel was resampled to 3\u2009\u00d7\u20093\u2009\u00d7\u20093\u2009mm . Datasets with more than 1.5\u2009mm maximum translation in x, y, or z, or 1 degree of maximum rotation about three axes were discarded. Linear detrending and temporal bandpass filtering (0.01\u20130.08\u2009Hz) were carried out using REST software[ ] (   ). \n\nIndividual ReHo maps were generated by calculating Kendall's coefficient of concordance (KCC, also called ReHo value) for the time series of a given voxel and those of its nearest neighbors (26 voxels), on a voxel-wise basis. The intracranial voxels were extracted to make a mask. For standardization purposes, each individual ReHo map was divided by its own mean ReHo within the mask. Then, the data were smoothed with a Gaussian filter of 6\u2009mm full width at half-maximum (FWHM) to reduce noise and residual differences in gyral anatomy. All these analyses were carried out using REST software. \n\nTo explore ReHo differences between the groups, a second-level random-effect two-sample t-test was performed on individual normalized ReHo maps in a voxel-by-voxel manner. Age, gender and education level were entered as covariates of no interest. Correction for multiple comparisons was performed using Monte Carlo simulation. A corrected threshold of p\u2009<\u20090.01 (two-tailed) was derived from a combined threshold of p\u2009<\u20090.01 for each voxel and a cluster size of\u2009>\u200935 voxels was determined using the AlphaSim program in AFNI software (Parameters: single voxel p\u2009<\u20090.01, 5000 simulations, FWHM\u2009=\u20096\u2009mm, with gray matter mask,  ). Subsequently, we performed a post-hoc correlation analysis in order to investigate the relationship between ReHo values of the significant clusters and clinical factors. Correlations between ReHo values of the significant clusters and clinical factors including age of starting smoking, duration (months) of smoking, accumulative smoked cigarettes, quantity of cigarette use per day and craving for cigarettes,were calculated by partial correlation analysis controlling for age, gender and education level (two tail, p <0.05). \n\n\n\n## Results \n  \nThe results were present for 45 smokers and 44 non-smokers. The overall sample was characterized typically by middle-upper class socioeconomic status in China. Groups were well matched in age, gender and handedness though there was a difference in educational levels (p\u2009<\u20090.01). Basic characteristics of subjects were detailed in Table  . \n\nIn comparison with non-smokers, chronic smokers displayed significantly decreased ReHo in the right inferior frontal cortex and increased ReHo in the left superior parietal lobe (as shown in Table  . and Figure  .). In post hoc analysis, there were no significant correlations between mean regional ReHo values and clinical characteristics (all p\u2019s\u2009>\u20090.1). \n  \nBrain areas of ReHo changes in smokers in comparison with non-smokers (P\u2009<\u20090.01, 35 Volexs,Alphasim corrected) \n    \n Brain areas of ReHo difference between smokers and non-smokers.   Warm and cool colors indicate smokers-related ReHo increase in left side of the brain and decrease in right side of the brain, respectively. (P\u2009<\u20090.01, 35 Voxels,Alphasim corrected). \n  \n\n## Discussion \n  \nIn this study, we found decreased ReHo in the right inferior frontal cortex and increased ReHo in left superior parietal lobe in chronic smokers during resting state, which suggests that, during resting state, neural function is less synchronized in the right inferior frontal cortex and more synchronized in the left superior parietal lobe in chronic smokers compared to non-smokers. \n\nThis study observed decreased ReHo for chronic smokers in the right inferior frontal cortex. The frontal cortex is involved in compulsive drug-seeking behaviors in drug dependence [ ]. Neuroimaging studies indicated that the frontal cortex has been affected directly by long-term exposure to addictive drugs [ ]. This hypo-function of the frontal region [ ] (e.g. lack of control over reward-related behavior) also existed in nicotine dependent individuals. The right inferior frontal gyrus has been implicated in response inhibition [ ]. Recently, Yu et al. investigated the ReHo values in male heavy smokers for the first time [ ]. In Yu\u2019s study, they found heavy smokers exhibited decreased ReHo in right inferior frontal gyrus, and increased ReHo in the insula and the posterior cingulate cortex [ ]. In our study, we also found decreased ReHo in the right inferior frontal cortex, which is similar to results seen in Yu\u2019s study. However, results are inconsistent in other brain regions. Demographic characteristics of the smokers in our study and Yu\u2019s study, such as the mean age (27.9 VS 41.6) and the mean years of smoking (10.2 VS 21.1), may partly explain the inconsistent results. In addition, a large body of evidence has shown that the prefrontal cortex plays a critical role in cognitive function [ , ] and that chronic cigarette smoking is associated with neurocognitive (such as executive skills, learning and memory, processing speed, and working memory) deficits [ , ]. Therefore, it was not unexpected that ReHo decreased in the inferior frontal cortex in chronic smoking individuals. \n\nThe Parietal lobe is a crucial region of planning and executing tool use movements [ ]. In a recent Meta-analysis, the parietal lobe was found to be related to the reward-circuit [ ], which suggests that the parietal cortex can be involved in addiction behavior. A previous task-related fMRI study have found abnormal parietal cortex activations in amphetamine dependent individuals [ ]. In the current study, we detected increased ReHo in the left superior parietal lobe in smokers compared with non-smokers. ReHo provided information about the connectivity at the local level [ ]. Increased ReHo may reflect increased local synchronization in neighboring voxels might be associated with high regional metabolism. In the present study, the enhanced synchronization in local regional resting-state blood oxygen level dependent BOLD activity detected in chronic smokers in the parietal cortex may reflect atypical smoking urges. \n\nSome limitations are worth mentioning. Education levels were not well matched in the two groups. However, education level was set as a covariate of no interest in the group analysis. In addition, we didn\u2019t evaluate sex effects on outcome measures since only a few female subjects (n\u2009=\u20098) were in this study. \n\nIn summary, the present study found decreased ReHo in the right inferior frontal cortex and increased ReHo in the left superior parietal lobe in the chronic smoking group compared to the non-smoking group during the resting state. These results may better our understanding of the neurobiological consequences of chronic smoking. \n\n\n## Competing interests \n  \nThe authors declare that they have no competing interests. \n\n\n## Authors\u2019 contributions \n  \nDesign: JT, YL, WH Data collection: JT, YL, QD, TL, XC, XW, XX, HC Analysis: JT, YL Writing: JT, YL All authors read and approved the final manuscript. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nUnnamed: 0\tSmokers\tnon-smokers\nDemographic variables\t\t\nN\t45\t44\nAge, years, mean\u2009\u00b1\u2009SD\t27.9 (5.6)\t26.3 (5.8)\nRange, years\t19-39\t19-38\nSex (female/male)\t8/37 (17.8%)\t10/34 (22.7%)\nSubjects\u2019 education, years, mean\u2009\u00b1\u2009SD\t13.1\u2009\u00b1\u20093.0 a\t15.0\u2009\u00b1\u20092.6\nHandedness, right/left (n)\t43/2\t43/1\nMarried\t19 (42.2%)\t15 (34.1%)\nDrinker/never-drinker b\t31/14\t18/26\nAge at start of smoking, mean\u2009\u00b1\u2009SD\t18.0\u2009\u00b1\u20094.3\t\u2015\nSmoking initiation age range (years)\t11-30\t\u2015\nYears smoking, mean\u2009\u00b1\u2009SD\t10.2\u2009\u00b1\u20095.8\t\u2015\nRange, years\t1.5-21\t\u2015\nCigarettes per day\t20.3\u2009\u00b1\u20097.6\t\nRange, cigarettes per day\t10-40\t\u2015\nSmoking cravings c\t6.41\u2009\u00b1\u20091.7\t\u2015\nRange, scores\t3-10\t\u2015\n### Caption\nDemographic characteristics of the smokers and non-smokers\n### Footer\na significantly different from control group, p\u2009<\u20090.01.b three participants reported drinking more than once a week among smokers and no non-smoking participants reported drinking more than once a week.c Before MRI acquisition run, participants were asked to rank their craving from 0 (\u201cnot at all\u201d) to 10 (\u201cextreme\u201d).\n\n\n## ID: T2\n### Label: Table 2\nBrodmann area\tBrain region\tMNI coordinates\tMNI coordinates\tMNI coordinates\tT\tCluster size\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tX\tY\tZ\tUnnamed: 5_level_1\tUnnamed: 6_level_1\n46\tReHo decreased in right Inferior frontal gyrus\t48\t39\t9\t3.88\t57\n7\tReHo increased in left Superior parietal gyrus\t\u221224\t\u221269\t54\t4.07\t53\n### Caption\nBrain areas of ReHo changes in smokers in comparison with non-smokers (P\u2009<\u20090.01, 35 Volexs,Alphasim corrected)\n### Footer\nNone\n", "metadata": {"pmcid": 3511796, "text_md5": "df06478c1c9ebce2b21e15e7c5d08423", "field_positions": {"authors": [0, 149], "journal": [150, 167], "publication_year": [169, 173], "title": [184, 280], "keywords": [294, 393], "abstract": [406, 1608], "body": [1617, 13918], "tables": [13931, 15449]}, "batch": 2, "pmid": 22913365, "doi": "10.1186/1744-9081-8-44", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3511796", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3511796"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3511796\">3511796</a>", "list_title": "PMC3511796  Altered spontaneous activity in young chronic cigarette smokers revealed by regional homogeneity"}
{"text": "Schaefer, Michael and Heinze, Hans-Jochen and Rotte, Michael\nPLoS One, 2012\n\n# Title\n\nClose to You: Embodied Simulation for Peripersonal Space in Primary Somatosensory Cortex\n\n# Keywords\n\n\n\n# Abstract\n \n## Background \n  \nAn increasing body of evidence has demonstrated that in contrast to the classic understanding the primary somatosensory cortex (SI) reflects merely seen touch (in the absence of any real touch on the own body). Based on these results it has been discussed that SI may play a role in understanding touch seen on other bodies. In order to further examine this understanding of observed touch, the current study aimed to test if mirror-like responses in SI are affected by the perspective of the seen touch. Thus, we presented touch on a hand and close to the hand either in first-person-perspective or in third-person-perspective. \n\n\n## Principal Findings \n  \nResults of functional magnetic resonance imaging (fMRI) revealed stronger vicarious brain responses in SI/BA2 for touch seen in first-person-perspective. Surprisingly, the third-person viewpoint revealed activation in SI both when subjects viewed a hand being stimulated as well as when the space close to the hand was being touched. \n\n\n## Conclusions/Significance \n  \nBased on these results we conclude that vicarious somatosensory responses in SI/BA2 are affected by the viewpoint of the seen hand. Furthermore, we argue that mirror-like responses in SI do not only reflect seen touch, but also the peripersonal space surrounding this body (in third-person-perspective). We discuss these findings with recent studies on mirror responses for action observation in peripersonal space. \n\n \n\n# Body\n \n## Introduction \n  \nIn social situations, recognition and understanding of actions of the conspecific are extremely important for appropriate behaviour. According to Prinz   this understanding is accomplished by an internal simulation of the actions we are observing. The neurobiological foundation of this process may be so-called mirror neurons, which discharge when a particular action is performed and also when one observes the same action performed by others  . However, in order to assess social situations the recognition and understanding of touch events is also essential. Touch is the first sense to develop and from infancy it is important to acquire information and to manipulate the environment  . Recent studies have demonstrated that viewing touch involves the observers' somatosensory cortices, which has been explained by an internal simulation process similar to action observation  ,  . For example, Keysers et al.   showed that observing someone else's legs being touched with a stick resulted in neural activity in the secondary somatosensory cortex (SII). Furthermore, an fMRI study by Blakemore et al.   revealed that observation of touch to a face or a neck was associated with activity in SI, SII, superior temporal sulcus (STS), and premotor cortex. The premotor cortex and the STS are also parts of the mirror system for action observation  . In monkeys, the premotor cortex has been shown to contain neurons that respond both to the execution and the observation of action  . Based on these results the authors suggest an analogous mirror system for observation of touch  . Similar results for SI, SII, and premotor cortex have been reported by Ebisch et al.  ,  . An increasing body of evidence supports these findings  \u2013 . Thus, SI and SII may not only be involved in the actual perception of experienced touch but might also provide a somatic dimension to our perception of other people's experiences  ,  ,  . However, the way the somatosensory cortices may contribute to this kind of social perception still remains to be cleared. \n\nThe current study tries to further examine the role of somatosensory brain regions for social perception. A first aim of the present study was to test if mirror-like responses in SI and other brain regions are affected by different viewpoints of the observed touch. Our previous study   has demonstrated that SI reflects differences regarding first- (1PP) and second-person-perspective (2PP) when observing touch  . Viewing touch in 2PP showed a hand with fingers pointing to the observer, while touch seen in 1PP depicted the hand with fingers pointing away from the observing participant. Observing touch from both viewpoints elicited vicarious somatosensory activation. Furthermore, touch seen in 2PP was associated with stronger activation in SI/BA2. While our previous study   presented video clips with a hand always either in 1PP or 2PP, we here argue that there is also another perspective, which we did not examine in the former work. Thus, the present study aimed to further test the factor perspective by showing a hand in 3PP. What is the 3PP? In 3PP the participant is no longer directly involved in the interaction. To a far more extent (compared with 2PP and 1PP) the participant here is an out-sided observer, who is looking on a touched hand that is not anymore potentially related to his or her bodily self. Viewing a hand in 2PP as in our previous paper (with finger pointing to the observer) may include a stimulation character to the observer. For example, we often see a hand with fingers pointing to us when somebody wants to receive something. In other situations a hand in 2PP may fulfil the function to point to the observer (with the whole hand). Furthermore, we often see a hand with fingers pointing to us when somebody wants to say hello to us, inviting us to shake hands with him. In all these examples a hand in 2PP has a demanding character to the observer. In contrast, when seeing a hand in 3PP the observer is more independent. Therefore, a hand in 2PP marks a different social situation compared with seeing a hand in 3PP, in which the observer is looking on a touched hand that is not anymore potentially related to his or her bodily self. Thus, viewing touch in 3PP is different from observations in 1PP- or 2PP. We hypothesized that vicarious activity in SI may reflect the difference between observation of touch in 1PP and 3PP, thus providing further support for higher cognitive processing in somatosensory cortices. \n\nA second aim of the present study was to test if events occurring close to the body are similarly \u201cmirrored\". Thus, we wanted to test if the observations of events in the peripersonal space similarly result in vicarious activation of (somatosensory) brain regions. Peripersonal space refers to the space surrounding our bodies within the reach of our limbs. In contrast, extrapersonal space refers to space beyond the reach of our limbs  . According Graziano et al.   a neural circuit including at least premotor area 6, the putamen, and parts of parietal cortices (ventral intraparietal area (VIP), medial intraparietal area (MIP), and area 7b of the parietal lobe) is dedicated to code peripersonal space  \u2013 . A recent study   revealed that mirror neurons in the monkey's premotor cortex differentially encode peri- and extrapersonal space when observing actions. Based on these results we hypothesized a similar involvement of vicarious somatosensory brain areas when viewing movements close to a body. Since mirror-like responses during the observation of touch have been related to the understanding of touch and to social perception  , we argue that events seen in the peripersonal space close to a body might also be important to recognize and understand social situations. \n\nIn order to test our hypotheses we employed an fMRI paradigm to present video clips depicting a hand that received non-painful touch with a paintbrush or video clips showing the paintbrush touching the space close to the hand. The experimental design was based on the paradigms of Keysers et al.   and Schaefer et al.  . In 1PP the hand was shown in a position congruent to the participant's body (similar to our previous study  ). The 3PP presented the same stimulation but here the hand was shown in an anatomical impossible way relative to the participant's body and pointed towards a second hand (see  ). The second hand was added in order to support a 3PP viewpoint situation. We hypothesized a different involvement of SI depending on the viewpoint of observation. \n   Conditions and types of stimuli used in the first experiment.  \nThe two pictures on the left depict the conditions touch hand and movements in peripersonal space, respectively, in 1PP. The two pictures on the right show touch hand and movements in peripersonal space, respectively, in 3PP. \n  \n\n## Methods \n  \n### Participants \n  \nTwelve subjects (six females) with a mean age of 26 years (range 23\u201339 years) participated in the first experiment, 14 in the second (seven females, mean age 23 years, range 24\u201330 years). The participants gave informed written consent to the study, which adhered to the Declaration of Helsinki and was approved by the human subjects committee of the Otto-von-Guericke University Magdeburg. \n\nAll subjects were right-handed as assessed by the Edinburgh Handedness Inventory  . \n\n\n### Procedure for the first study \n  \nThe design of the first experiment consisted out of two factors. The first factor was viewing perspective (1PP vs. 3PP). The second factor was space (touch observation in personal space (\u200a=\u200aPS) vs. in peripersonal space (\u200a=\u200aPPS)). Furthermore, there was an additional block with actual touch (\u200a=\u200areal touch). \n\nFor 1PP, subjects watched video clips in which a right hand was presented in an anatomically congruent position (finger pointing away from participants body). For 3PP the depicted (stimulated) right hand was pointing to the right and faced a second (left) hand. Both of those hands were positioned orthogonal to the subject's own hand. Furthermore, the hands were depicted in an anatomical impossible way relative to the participant's body (see  ). For the factor space, half of the video clips showed a hand being touched on the index finger repeatedly by a paintbrush (i.e., the PS condition) and the other half the paintbrush did not touch the hand but the space close to the hand (i.e., the PPS condition). The same visual stimuli and motion frequency (1 per second) were applied in all video clips across viewing perspective and observed action. In PPS condition the paintbrush made identical motions as in the touch hand condition except that in the former, the brush stroked on the side of the index finger (distance about 1\u20132 cm). In all conditions, a right hand was stimulated. The motion of the paintbrush was vertical in about 90 percent of all trials and horizontal in about 10 percent. Subjects were required to press a key to report the number of vertical strokes at the end of each video clip. This was to ensure that subjects were attentively observing the video presentation (similar to  ,  ). \n\nIn addition to the above-mentioned four conditions, each subject also received a stimulation block in which the hands were repeatedly touched by a paintbrush during the fMRI scan. This run was applied after the touch observation conditions at the end of the experiment. In this block the left and the right hand were (alternating) touched by a paintbrush. The manner and frequency of the brushing were identical to that shown in the videos. Instead of video clips the participants here viewed a fixation cross. The touch of the hand was not viewable. We applied this block in order to localize the somatosensory cortices in each individual. \n\nThe experiment consisted out of three runs. Each run included all conditions. Conditions were presented in a randomized order. Video clips lasted for 18 sec and were followed by a resting period of 15 sec (+\u22123 sec), in which a fixation cross was shown (baseline condition). The experiment lasted for about 45 min. \n\n\n### Procedure for the second study \n  \nThe second experiment was identical to the first experiment, except that we added three further conditions and removed the conditions of 1PP. In a first condition subjects viewed movies with a paintbrush moving (similar to the PS and PPS conditions), but without depicting any body parts (movement only condition). In a second condition the participants observed the hands of the 3PP condition, but without any movements or touch towards those hands (hands only condition). Thus, they viewed hands simply resting on a table. The task for the movement only condition was identical to the first experiment. For the hands only condition we asked subjects to judge if one of the presented hands was a female hand and to press a key after the video has ended. \n\nFurthermore, we aimed to test if only observation of movements or events close to the body (peripersonal space) elicit vicarious somatosensory responses or if events far away from the body (extrapersonal space) also result in mirror-like responses in somatosensory cortices. Thus, we applied a third condition that showed paintbrush movements far from the actor's hand (about 20 cm), testing for vicarious somatosensory responses for events occurring in the extrapersonal space (EPS). Taken together, the second experiment included the conditions PS, PPS, EPS, movement only, and hands only (always in 3PP). The order of the conditions was randomized. Presentation procedure was analogue to the first experiment. \n\n\n### FMRI data acquisition and analysis: First study \n  \nThe functional imaging for the first study was conducted by using a 1.5 T scanner (General Electrics Signa LX, USA) to conduct functional imaging (gradient echo T2-weighted echo-planar images; TR\u200a=\u200a2 sec, TE\u200a=\u200a35 ms, flip angle\u200a=\u200a80 degrees, FOV\u200a=\u200a20 mm). For each subject, data were acquired in three scan runs. In each session, 392 volumes were acquired including 4 \u2018dummy\u2019 volumes, which were acquired at the start of each session and subsequently discarded to allow for T1 equilibration effects. Functional volumes consisted of 23 slices. Each volume comprised 5 mm slices (1 mm gap, in plane voxel size 3.125\u00d73.125 mm). For anatomical reference a high-resolution T1-weighted structural image was collected (3D-SPGR, TR\u200a=\u200a24 ms, TE\u200a=\u200a8 ms). \n\nVisual images were back-projected to a screen at the end of the scanner bed close to the subject's feet. Subjects viewed the images through a mirror mounted on the birdcage of the receiving coil. Foam cushions were placed tightly around the side of the subject's head to minimize head motion. \n\nThe fMRI data was analyzed using the Statistical Parametric Mapping Software (SPM5, Wellcome Department of Imaging Neuroscience, University College London, London, UK). The images were realigned to correct for head movements using sinc interpolation and subsequently normalized into a standard anatomical space (MNI, Montreal Neurological Institute template) resulting in isotropic 3 mm voxels. Data were then smoothed with a Gaussian kernel of 6 mm full-width half maximum. \n\nStatistical parametric maps were calculated using multiple regressions with the hemodynamic response function modeled in SPM5. Data analyses were performed at two levels. We examined data on the individual subject level by using a fixed effects model (all three runs concatenated for each subject). Then, the resulting parameter estimates for each regressor at each voxel were entered into a second-level analysis with the random effects model. We calculated an ANOVA for repeated measurements with the factors perspective (1PP vs. 3PP) and space (PS vs. PPS). Subsequently, statistical contrasts (t tests) were performed to examine cortical activation associated with PS vs. PPS conditions in 1PP and 3PP. Furthermore, we calculated contrasts between 1PP and 3PP for PS and PPS conditions. To examine common activations during real tactile stimulation and observation of touch events, the contrasts were inclusively masked by the contrast (p<0.05) of real touch relative to baseline. The resulting images were thresholded at p<0.05 family-wise error (FWE) corrected for multiple comparisons over the whole brain. Anatomical interpretation of the functional imaging results was performed by using the SPM anatomy toolbox  . \n\n\n### FMRI data acquisition and analysis: Second study \n  \nData acquisition for the second study was done on a 3 T scanner (Siemens MAGNETOM Trio, Germany) (gradient echo T2-weighted echo-planar images; TR\u200a=\u200a2 sec, TE\u200a=\u200a35 ms, flip angle\u200a=\u200a80 degrees, FOV\u200a=\u200a224 mm). For each subject, data were acquired in four runs. In each session, 392 volumes were acquired. Functional volumes consisted of 32 slices. Each volume comprised 3.5 mm slices (no gap, in plane voxel size 3.5\u00d73.5 mm). For anatomical reference a high-resolution T1-weighted structural image was collected (MPRAGE, TR\u200a=\u200a1650 ms, TE\u200a=\u200a5 ms). Subjects viewed the images through a mirror mounted on the birdcage of the receiving coil. Foam cushions were placed tightly around the side of the subject's head to minimize head motion. \n\nData preprocessing was analogue to the first study. Statistical parametric maps were calculated using multiple regressions with the hemodynamic response function modeled in SPM5. Similar to the first study, data analyses were performed at two levels. First, we examined data on the individual subject level by using a fixed effects model (all three runs concatenated for each subject). Second, the resulting parameter estimates for each regressor at each voxel were then entered into a second-level analysis with the random effects model. We calculated an ANOVA for repeated measurements with the factor condition (PS; PPS; EPS, hands only, movement only). Subsequently, statistical contrasts (t tests) were performed to examine cortical activation associated with PS relative to PPS, PS relative to EPS, and PPS relative to EPS. Furthermore, we compared the condition PPS relative to hands only and movement only conditions. The post-hoc tests were reported masked and not masked with real touch condition. \n\nThe resulting images were thresholded at p<0.05 family-wise error (FWE) corrected for multiple comparisons over the whole brain. In addition, we report regions of interest that survived a small volume correction (SVC) of p<0.05 (FWE corrected) for which we had an a priori hypothesis  ,  . Thus, a SVC was applied to activations within a sphere of 5 mm radius in the postcentral gyrus (SI) and 5 mm radius in the parietal operculum (SII). Anatomical interpretation of the functional imaging results was performed by using the SPM anatomy toolbox  . \n\n\n\n## Results \n  \n### First study \n  \n#### Results for real touch stimulation \n  \nFMRI data revealed that the real touch stimulation of the participant's' right (respectively, left) hand (real touch vs. baseline) activated a number of somatosensory regions including contralateral SI, bilateral parietal operculum (SII/parietal ventral area), the precentral gyrus (BA4/BA6), the insula, the lateral temporo-occipatal cortex, the superior parietal/intraparietal cortex, and the thalamus (p<0.05, FWE corrected). \n\n\n#### Main effect for space \n  \nResults of an ANOVA including the two within subjects factors perspective (1PP, 3PP) and space (PS, PPS) revealed a significant main effect for space, including left SI, bilateral insula, bilateral precentral gyrus (BA6), L SII, and cerebellum (at p<0.05, FWE corrected; masked with real touch). \n\n\n#### Main effect for perspective \n  \nFurthermore, the ANOVA revealed a significant main effect for perspective, involving bilateral premotor cortex (BA6), bilateral insula, left temporal pole, and cerebellum (at p<0.05, FWE corrected; masked with real touch). \n\n\n#### Interaction effect of space and perspective \n  \nThe ANOVA revealed a significant interaction between the factors space and perspective. The effect included bilateral SI, bilateral insula, bilateral SII, right inferior parietal lobe, bilateral premotor cortex (BA6), bilateral precentral gyrus, and cerebellum (at p<0.05, FWE corrected; masked with real touch). \n\n\n#### Main effect for space (unmasked) \n  \nFurthermore, we calculated an analogue ANOVA without somatosensory mask. The resulting main effect for space revealed additional activation in medial prefrontal cortex (at p<0.05, FWE corrected). \n\n\n#### Main effect for perspective (unmasked) \n  \nThe main effect for perspective not restricted to somatosensory brain regions revealed no additional areas (at p<0.05, FWE corrected). \n\n\n#### Interaction effect space and perspective (unmasked) \n  \nThe interaction for space and perspective revealed no additional areas (at p<0.05, FWE corrected). \n\n\n#### Post-hoc t-test: Results for space in 1PP (PS>PPS) \n  \nIn order to further examine the significant interaction between space and perspective, we used post-hoc t-tests. These analyses were limited to voxels showing the correct significant effect. \n\nSignificant overlap for real touch and observed touch in 1PP (PS>PPS, masked with real touch condition>baseline) was found in the left postcentral gyrus (SI/BA2), SII, and anterior insula (at p<0.05, FWE corrected, see   and  ). The contrast PPS relative to PS failed to show any significant activation. When not being masked (whole brain) results for observation of touch did not reveal any additional activations (at p<0.05, FWE corrected). \n   Results of experiment 1.  \nStatistical maps showing overlapping activation (p<0.05, FWE corrected) for visual conditions (PS/PPS) and real touch. A: Brain activation in left SI for touch hand relative to movements in peripersonal space video clips in 1PP. B: The analogue contrast in 3PP shows no significant overlap. In contrast, the test movements in peripersonal space relative to touch hand revealed significant bilateral activation in SI. \n     Results of random effects analysis (p<0.05, FWE corrected, L\u200a=\u200aleft hemisphere, R\u200a=\u200aright hemisphere, masked with real touch>baseline).      \n\n#### Post-hoc t-test: Results for space in 3PP (PS>PPS) \n  \nThe overlap for tactile stimulation and observed touch in 3PP (PS>PPS, masked with real touch>baseline) revealed no significant activations (at p<0.05, FWE corrected). When not being masked, the results still failed to show any significant voxels. In contrast, observation of movements in peripersonal space (PPS) relative to PS events showed significant effects in bilateral SI, left SII, and mid insula (masked with real touch>baseline; p<0.05, FWE corrected; see   and  ). When not being masked results for observation of movements in peripersonal space relative to touch hand observation (whole brain) revealed additional brain activation in premotor cortex (MNI coordinates: 28, \u221212, 64, z\u200a=\u200a5.86, 33 voxels, p<0.05, FWE corrected). \n\n displays activation relative to baseline for each of the four experimental conditions (masked with real touch>baseline; p<0.05, FWE corrected). For 3PP both of the contrasts (PS and PPS relative to baseline) revealed strong bilateral somatosensory responses in SI. In contrast, for 1PP brain responses to PPS relative to baseline yielded only minor activations in left SI.   shows the results of these comparisons expressed as percentage signal change of BOLD responses in left SI. For 3PP PPS events revealed even higher activations than PS events. For the activation in right SI (3PP only) the parameter estimates were similar. \n   Brain responses in SI while subjects observe touch to a hand and movements close to a hand (\u200a=\u200aPS and PPS) relative to baseline.  \nA: Results for 1PP revealed activation in left SI for PS events. For PPS events results yielded only minor activation in SI. B: Results for 3PP depict activations in bilateral SI both for PS and PPS conditions. C: Contrast of parameter estimates for activations in left SI (MNI coordinates: \u221238 \u221240 52) during PS and PPS conditions relative to baseline. The left two bars show the results for 1PP, the right two bars depict results for 3PP. In the latter, PS as well as PPS events were associated with strong activation in SI, whereas the observation of PPS events revealed even higher activation than the PS condition. The data of the right SI (3PP only) were similar. All results were at p<0.05, FWE corrected, and masked with real touch relative to baseline in order to reveal common activations with somatosensory areas. \n  \n\n#### Post-hoc t-test: Results for perspective for PS (1PP>3PP) \n  \nFurther analysis of the fMRI data contrasted observation of a touched hand in 1PP with 3PP (masked with real touch>baseline; p<0.05, FWE corrected). Results revealed significant activation in left SI (BA2), premotor cortex and SMA (BA 6), SII, and mid insula (see   and  ). Unmasked data revealed no further significant activation (at p<0.05, FEW corrected). The analogue contrast between 3PP and 1PP did not reveal any significant activation (masked or unmasked, at p<0.05, FWE corrected). \n   Statistical maps for the contrast 1PP (PS - baseline) relative to 3PP (PS - baseline).  \nResults show brain activation in SI for 1PP (at p<0.05, FWE corrected, masked with real touch>baseline). The contrast 3PP (PS - baseline) relative to 1PP (PS - baseline) failed to show any significant voxels (at p<0.05, FWE corrected). \n     Results of random effects analysis for 1PP (1PP-baseline) relative to 3PP (3PP baseline) (p<0.05, FWE corrected, L\u200a=\u200aleft hemisphere, R\u200a=\u200aright hemisphere, masked with real touch>baseline).      \n\n#### Post-hoc t-test: Results for perspective for PPS (1PP>3PP) \n  \nWe further tested for active brain regions when comparing the different perspectives for the PPS condition. The contrast PPS in 1PP relative to PPS in 3PP failed to show any significant activation (masked or unmasked with real touch, at p<0.05, FWE corrected). The contrast PPS in 3PP relative to PPS in 1PP revealed a broad network of significant brain activations including postcentral gyri, premotor areas, left SII, and left mid insula (masked with real touch, at p<0.05, FWE corrected). The unmasked contrast showed no further brain activations (at p<0.05, FWE corrected). \n\n\n\n### Second study \n  \n#### Main effect of condition \n  \nTo examine why observation of PPS events in 3PP were associated with somatosensory activation we conducted the second experiment. Here we applied additional conditions, in which the participants viewed the hand and a moving paintbrush far from the viewed hand (EPS), a moving paintbrush alone or hands simply resting on a table (in 3PP) without any stimulation or movements. \n\nAn ANOVA including the factor condition (PS, PPS, EPS, hands only, movement only) revealed a significant main effect, demonstrating activation in left SI, bilateral premotor cortex, left SII, left mid insula and bilateral inferior parietal cortex (masked with real touch>baseline; p<0.05, FWE corrected). The unmasked results revealed additional activation in premotor areas and occipital brain regions (at p<0.05, FWE corrected). \n\n\n#### Post-hoc t-test PS>PPS \n  \nSubsequent post-hoc t-tests included only voxels showing activation in the main effect of the ANOVA. The contrast PS relative to PPS demonstrated activation of left SI and SII (masked with real touch, at p<0.05, FWE corrected). Unmasked results involved additional activation in occipital areas (at p<0.05, FWE corrected). The opposite contrast PPS relative to PS revealed no significant brain areas (masked or unmasked, at p<0.05, FWE corrected). \n\nContrast of parameter estimates for activations in SI (relative to baseline) revealed activations both for PS and PPS (see  ). Thus, presenting video clips showing a touched hand (PS) as well as video clips depicting movements in the space close to the hand (PPS) resulted in activation of SI. Hence, the results replicated the outcome of the first study with regard to an engagement of SI both for PS and PPS. \n   Results of experiment 2.  \nA: Conditions of the experiment. See text for further details. B: Results revealed activation in SI both for touch hand (PS) and movements in peripersonal space (PPS) conditions. The conditions EPS, hands only and movement only failed to show significant activation of somatosensory brain areas (at p<0.05, FWE corrected, masked with real touch>baseline in order to reveal common activations with real touch). C: Contrast of parameter estimates for activations in left SI (based on ANOVA main effect, see text) demonstrates activation both for PS and PPS conditions, thus replicating the results of the first study. D: Statistical maps for the contrast PS>EPS and PPS>EPS revealed brain activation in left SI (FWE corrected, masked with real touch>baseline). E: Statistical maps for the contrast PPS>hands only show brain activation in left SI and left premotor cortex (FWE corrected, unmasked results). \n  \n\n#### Post-hoc t-tests PS>EPS \n  \nWe further compared brain responses for PS relative to EPS. Results revealed activation of left SI and SII. No other brain area showed significant activation (masked with real touch, at p<0.05, FWE corrected). Unmasked results demonstrated additional activation in occipital brain regions. The opposite contrast (EPS relative to PS) revealed activation only in occipital brain regions (unmasked, at p<0.05, FWE corrected). Furthermore, the contrast EPS relative to baseline revealed no significant activation in somatosensory brain regions (masked with real touch, at p>0.05, FWE corrected). \n\n\n#### Post-hoc t-test PPS>EPS \n  \nThe comparison between PPS and EPS revealed significant activations in left SI and left SII (masked with real touch, at p<0.05, FWE corrected). Unmasked results showed no additional activations. The contrast EPS relative to PPS failed to show significant voxels (unmasked or masked, at p<0.05, FWE corrected). \n\n\n#### Post-hoc t-tests PPS relative to movement only and hands only \n  \nComparisons between PPS relative to movement only engaged left SI and SII (masked with real touch, p<0.05, FWE corrected). Unmasked results showed additional activation in left premotor cortex and occipital cortex (at p<0.05, FWE corrected). Comparison to hands only showed similar results. The contrasts movement only and hands only relative to PPS failed to show any significant activation (masked or unmasked, at p<0.05 FWE corrected). \n\n\n#### Post-hoc t-tests movement only>rest and hands only>rest \n  \nThe contrast movement only relative to rest revealed activation in right inferior parietal cortex (masked with real touch, at p<0.05, FWE corrected). Unmasked results showed additional activation in occipital brain areas (at p<0.05, FWE corrected). \n\nThe comparison hands only relative to rest failed to show significant activations (masked with real touch, at p<0.05, FWE corrected). Unmasked results showed significant activation in occipital areas (at p<0.05, FWE corrected). Thus, neither the hands nor the moving paintbrush alone elicited activation in SI or SII. \n\n\n#### Effects of task performance on brain response in SI \n  \nIn order to examine possible interactions of the BOLD response in SI with task accuracy we computed correlations between the BOLD responses in SI (for both experiments) with accuracy of task performance. Results failed to show significant correlations (all p>0.10). \n\n\n\n\n## Discussion \n  \nThe current study examined the role of somatosensory brain regions when observing touch to a hand (PS) and movements close to the hand (PPS), either in 1PP or in 3PP. When viewing a hand being touched in 1PP the observer's left sensory cortex (SI, SII/insula) showed activation relative to baseline and relative to observation of touch close to the hand, thus confirming previous studies (e.g.,  ). In contrast, when seeing a hand being touched in 3PP, observation of both, touch to a hand and touch close to the hand, revealed activation of bilateral SI (relative to baseline) and SII/insula. Thus, even viewing touch close to the hand yielded vicarious somatosensory activation. Furthermore, activity in SI/BA2, SII and insula for the touch hand condition was stronger in 1PP compared with 3PP (relative to baseline). \n\nThe results for 1PP are in line with recent studies demonstrating activity in SI and SII merely by viewing touch in the absence of any direct stimulation (e.g.,  \u2013 ). Analysis of parameter estimates demonstrated that observing touch to a hand relative to baseline was associated with an increase in SI, while viewing touch close to the hand showed only minor activation in SI, as expected (analogue to   and  ). If we compare the engagement of SI for touch hand observations in 1PP with 3PP, the results show that seeing touch in 1PP elicited stronger activation in SI/BA2 than in 3PP (relative to baseline). Thus, the results provide support for our hypothesis that the viewpoint (or the cognitive distance) of observed touch matters, thereby drawing the attention to higher cognitive processing in somatosensory cortices. \n\nSurprisingly, observing touch in 3PP engaged the sensory cortices in a different pattern. Here the contrast PS relative to PPS revealed no significant voxels, but movements in peripersonal space relative to touch hand demonstrated an involvement of bilateral SI, SII and insula. Further analyses demonstrated that relative to baseline both conditions (touch hand and movements in peripersonal space) elicited activation in SI. These findings were replicated by the second experiment. Why were both events (touch hand and movements in peripersonal space) in 3PP associated with SI activity? Observation of touch close to the hand is different from a resting condition. There may be three reasons why SI was activated by movements in peripersonal space. First, the stroking of the paintbrush might have activated the putative mirror neuron system for observed actions, which is known to involve SI (e.g.,  \u2013 ). Although only the moving paintbrush (without the holding hand) was viewable, a recent study revealed that even the movements of robotic arms may activate the mirror system  . Second, the mere depiction of a hand might have elicited somatosensory activation. It has been demonstrated that seeing a non-stimulated body part may alter somatosensory processing in SI (e.g.,  ). Third, a combination of both factors may explain the results. In order to disentangle the roles of motion and body part depiction we conducted the second experiment. The results demonstrated that neither the moving paintbrush nor the depiction of the hands alone elicited neural responses in the somatosensory cortices (even at an uncorrected level of p<0.001). Since we did not find any effects of task performance, it seems unlikely that attention or task effects may explain this lack of activation. We conclude that only a combination of both, moving paintbrush and picture of a hand, seems to be sufficient to evoke somatosensory activation in the observer. Touching the space close to a hand may have been perceived as \u201ctouch\" of the peripersonal space. Several studies have demonstrated that not only touching the body but also invading the space close to the body affects sensorimotor processing (e.g.,  ). In animals, this peripersonal space seems to be related to defensive behavior and important for the construction of a margin of safety around the body  . In the present study the observation of a \u201ctouched\" peripersonal space seemed to be simulated in the observer's somatosensory cortex. This interpretation is supported by the lack of vicarious somatosensory responses when seeing the moving paintbrush far from the hand (EPS condition). Thus, only events in peripersonal space, not in extrapersonal space, were associated with mirror-like responses in somatosensory brain regions. \n\nThe results were supported by a recent study about the visual perspective on cortical body representation  . The authors reported a suppression of activation in SI for viewing body parts from an allocentric perspective, but no change for the egocentric perspective. Our results similarly revealed differential responses in SI depending on the viewpoint, although we did not find a suppression of activation in SI. \n\nFurthermore, our results are supported by a recent animal study. Caggiano et al.   showed that mirror neurons in the monkey's premotor cortex differentially encode peri- and extrapersonal space. The results of the present study extend these findings in two important ways. First, our results demonstrate that mirror-like responses   in SI   (and SII/insula) reflect the peripersonal space of a seen body part. Second, our study shows that vicarious somatosensory responses are especially sensitive to touch seen in the peripersonal space of an   alien body  . In other words, mirror-like responses in SI do not only seem to reflect the peripersonal space of the own body (as shown by Caggiano et al.   for mirror neurons in the premotor cortex), but also that of an alien body (seen in 3PP). This points to an enhanced complex processing of mirror-like responses in somatosensory brain areas, perceiving not only the perspective of observed touch but also the peripersonal space of an alien body. \n\nIn addition, observation of movements close to the hand (PPS) revealed an involvement of the premotor cortex. This activation was not vicarious, because it was only seen when not masking the results with the results of the real touch condition. Nevertheless, in the context of our study this is important because of three reasons. First, the premotor cortex has been reported to be a key structure for mirror responses in action observation (e.g.,  ). Second, in paradigms on touch observation an involvement of the premotor cortex has also been demonstrated  ,  ,  . Thus, our results may point to a role for the mirror system when observing events in the peripersonal space. Third, the premotor cortex has been shown to be an important brain region for the representation of the peripersonal space  \u2013 . Since the premotor cortex in our study was engaged only when viewing events in the peripersonal space (and not in the personal space condition), the results suggest that in this condition the peripersonal space was vicariously activated. \n\nIt seems remarkable that events in the peripersonal space were \u201cmirrored\" in SI when they were shown in 3PP, but only to a small extent when they were seen in 1PP. Thus, if touch in the peripersonal space is perceived to happen to somebody else, the somatosensory cortices seem to be more affected than when it seems to happen in the peripersonal space around our own body. One explanation for this effect of perspective may be that events we are used to see very often (touch of the space close to our hands) have only limited salience to the somatosensory mirror system. In contrast, when the same events happen in the peripersonal space of somebody else, this may be potentially more important to understand the situation. In an animal study Graziano et al.   reported that tactile neurons in the precentral gyrus do not respond to the touch of the familiar primate chair, to which the monkey was habituated. Graziano et al.   called this the clothing effect. Thus, events that are very close to our body and we are highly used to may not be represented by a putative mirror system. In contrast, Caggiano et al.   examined the peripersonal space of monkeys by either placing the stimuli in the reach of the monkey's hand (peripersonal space) or by locating them out of reach (extrapersonal space). In our study (as well as in  ) the events happened much closer to the body. Thus, the difference of the perspective for the movements in peripersonal space events revealed in our study may be caused by a possible clothing effect in 1PP. \n\nHowever, other explanations should also be taken into account. In a recent study Ebisch et al.   demonstrated SI activation associated with the perceived intentionality of the observed touch. The correlation with intentionality was even valid when the touch was caused by a moving branch (instead of a hand). Based on these results the authors suggested a human tendency to resonate with an (assumed) intentional touching agent, here reflected by vicarious somatosensory responses in SI. A similar explanation might also apply for the engagement of SI for seen touch and seen events in the peripersonal space in our study. Although the actor of the paintbrush was not visible, vicarious SI activation may be related to the intentional agent of the moving paintbrush. A recent study demonstrated that even the observation of movements of a robotic arm activated the mirror network  . Thus, the crucial factor for mirror-like responses in SI may not be touch, but the observation (or assumption) of an intentional agent (in contrast to SII). However, in our study not only SI but also SII revealed strong vicarious activation for seen events in peripersonal space. Hence, our data do not support a functional dissociation between SI and SII for events in the peripersonal space (or for seen touch in the personal space). In addition, Ebisch et al. found a correlation with intentionality only for the left SI, while we found bilateral involvement of SI. Future studies seem to be necessary to further disentangle the role of intentionality for vicarious responses in SI. \n\nAnother explanation for somatosensory engagement when seeing events in the peripersonal space of the subject may be that SI activation has been shown to be linked with the simulation or anticipation of sensory experiences. Carlsson et al.   have demonstrated that the expectancy of sensory experiences elicited activity in SI, without actually being touched. Thus, intentional movements inside the peripersonal space as in our study may be followed by sensory activations. This might also explain the activation of premotor brain regions in our study when seeing movement events in extrapersonal space. However, this explanation seems unlikely. If the expectancy of sensory experiences had caused the somatosensory responses in PPS, both 3PP and 1PP would have been affected. \n\nThe results of the present study suggest a role for perspective when viewing body parts receiving touch. Our previous study similarly pointed to a role for perspective when seeing touch  . However, the previous study found different involvement of SI when viewing touch events in 1PP- and 2PP (demonstrating a role for BA2 in particular for 2PP), whereas the current results point to a different involvement of SI for 1PP and 3PP for movements in peripersonal space. Thus, the role of the perspective might be more complex than previously thought. Future studies are needed to further support our hypothesis that the different involvement of vicarious somatosensory responses is based on different social situations marked by the viewpoint of the observer. \n\nTwo further studies addressed the issue of a varying viewpoint. Keysers et al.   manipulated the difficulty of integration of the observed touch into the body schema of the observer and varied the perspective of the seen touch (1PP vs. 2PP). Results revealed activation in SII irrespective of the perspective of the touched body part. However, this was tested only for SII with a region of interest approach. Another recent study similarly varied the viewpoint of seen touch. Bolognini et al.   presented touch and no-touch stimuli in ego- an allocentric perspectives to patients and healthy subjects in a neuropsychological paradigm. The authors found that viewing touch differently affected visual perception depending on which sensory modality is damaged. This result was independent of the perspective of the seen touch. However, the authors did not use functional imaging, making a comparison to our results difficult. Furthermore, Bolognini et al.   presented fingers touching other fingers of the hand as touch stimuli, whereas the current (and also  ) used a paintbrush to show touch stimuli. This difference may also account for the lack of effect of perspective on vicarious somatosensory responses in the Bolognini et al. study. \n\nTaken together, the results demonstrate that vicarious somatosensory responses are affected by perspective as well as by events in the peripersonal space of the perceived body part. The results support the view that mirror-like responses in somatosensory cortices may provide important contributions to the perception and understanding of other people's sensations and experiences. \n\n \n\n# Table(s)\n## ID: pone-0042308-t001\n### Label: Table 1\nUnnamed: 0\tcontrast\tbrain region\tMNI location (x, y, z)\tpeak z-value\tclustersize (in voxels)\n1PP\tPS>PPS\tL SI (BA2)\t\u221250 \u221232 48\t6.17\t163\n\t\tL insula\t\u221236 20 \u22128\t6.49\t32\n\t\tL SII/insula\t\u221234 8 0\t6.36\t26\n\t\tR inf. parietal lobe\t58 \u221248 46\t5.53\t47\n\t\tcerebellum\t6 \u221246 \u221234\t6.36\t28\n\tPPS>PS\t-\t-\t-\t-\n3PP\tPS>PPS\t-\t-\t-\t-\n\tPPS>PS\tL SI (BA2)\t\u221238 \u221240 52\t4.77\t97\n\t\tR SI (BA1/BA2)\t42 \u221242 62\t5.67\t24\n\t\tL SII/insula\t\u221236 2 \u22122\t4.26\t15\n\t\tL insula\t\u221236 20 \u22124\t4.18\t9\n\t\tR inf. parietal lobe\t62 \u221242 46\t5.03\t45\n\t\tcerebellum\t\u22122 \u221248 \u221234\t4.64\t28\n### Caption\nResults of random effects analysis (p<0.05, FWE corrected, L\u200a=\u200aleft hemisphere, R\u200a=\u200aright hemisphere, masked with real touch>baseline).\n### Footer\nNone\n\n\n## ID: pone-0042308-t002\n### Label: Table 2\ncontrast\tbrain region\tpeak MNI location (x, y, z)\tpeak z-value\tclustersize (in voxels)\n1PP - baseline >3PP-baseline\tL SI (BA2)\t\u221230 \u221242 54\t4.82\t116\n\tL prem. cortex/SMA (BA6)\t\u221210 \u221212 58\t4.45\t67\n\tR prem. cortex/SMA (BA6)\t2 \u221214 54\t4.94\t36\n\tL precentral gyrus (BA6)\t\u221226 \u221212 68\t5.01\t37\n\tL insula\t\u221240 \u22122 \u221210\t4.52\t95\n\tR insula/SII\t42 \u22122 \u22126\t4.63\t21\n\tL temporal pole\t\u221234 14 \u221226\t4.73\t14\n\tcerebellum\t8 \u221252 \u221231\t5.99\t212\n3PP - baseline >1PP-baseline\t-\t-\t-\t-\n### Caption\nResults of random effects analysis for 1PP (1PP-baseline) relative to 3PP (3PP baseline) (p<0.05, FWE corrected, L\u200a=\u200aleft hemisphere, R\u200a=\u200aright hemisphere, masked with real touch>baseline).\n### Footer\nNone\n", "metadata": {"pmcid": 3422286, "text_md5": "c82e7de56fa50ac2618e8fbe49c8a0e8", "field_positions": {"authors": [0, 60], "journal": [61, 69], "publication_year": [71, 75], "title": [86, 174], "keywords": [188, 188], "abstract": [201, 1667], "body": [1676, 44296], "tables": [44309, 45732]}, "batch": 2, "pmid": 22912698, "doi": "10.1371/journal.pone.0042308", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422286", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3422286"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422286\">3422286</a>", "list_title": "PMC3422286  Close to You: Embodied Simulation for Peripersonal Space in Primary Somatosensory Cortex"}
{"text": "Szczypi\u0144ski, Jan and Ali\u0144ska, Anna and Walig\u00f3ra, Marek and Kopera, Maciej and Krasowska, Aleksandra and Michalska, Aneta and Suszek, Hubert and Jakubczyk, Andrzej and Wypych, Marek and Wojnar, Marcin and Marchewka, Artur\nSci Rep, 2020\n\n# Title\n\nFamiliarity with children improves the ability to recognize children\u2019s mental states: an fMRI study using the Reading the Mind in the Eyes Task and the Nencki Children Eyes Test\n\n# Keywords\n\nCognitive neuroscience\nEmotion\nSocial neuroscience\nNeuroscience\n\n\n# Abstract\n \nTheory of mind plays a fundamental role in human social interactions. People generally better understand the mental states of members of their own race, a predisposition called the own-race bias, which can be significantly reduced by experience. It is unknown whether the ability to understand mental states can be similarly influenced by own-age bias, whether this bias can be reduced by experience and, finally, what the neuronal correlates of this processes are. We evaluate whether adults working with children (WC) have an advantage over adults not working with children (NWC) in understanding the mental states of youngsters. Participants performed fMRI tasks with Adult Mind (AM) and Child Mind (CM) conditions based on the Reading the Mind in the Eyes test and a newly developed Nencki Children Eyes test. WC had better accuracy in the CM condition than NWC. In NWC, own-age bias was associated with higher activation in the posterior superior temporal sulcus (pSTS) in AM than in CM. This effect was not observed in the WC group, which showed higher activation in the pSTS and inferior frontal gyri in CM than in AM. Therefore, activation in these regions is required for the improvement in recognition of children\u2019s mental states caused by experience. \n \n\n# Body\n \n## Introduction \n  \nHumans are social beings, and therefore, the ability to understand the mental states of others is crucial to everyday life and to adequately function in modern society, especially regarding social interactions. This ability is called theory of mind (TOM) or mentalizing. TOM allows us to accurately understand and predict the goals, beliefs, desires and emotions (together described as mental states) of others . TOM can be divided into the socio-perceptual component, referring to decoding or detecting other\u2019s mental states based on perceptual information (e.g. a photograph of the eye region) and the socio-cognitive component allowing to infer about others\u2019 intentions or beliefs based on their behaviour and one\u2019s knowledge about the world . Another distinction described in the literature divides TOM into affective and cognitive TOM . Affective TOM refers to an ability to infer about feelings of others, while cognitive TOM allows inferring about beliefs. \n\nSeveral studies showed the own-race bias in socio-perceptual component of TOM \u2014a tendency to better recognize mental states of members of the same race. At the same time, the own-race bias could also be observed in less complex processes, such as face recognition (correctly recalling and matching known vs unknown faces) . A similar phenomenon, called the own-age bias, causes the attention to focus on faces of people the same age  and better remember those . Interestingly, due to experience, ward nurses  and teachers  can become better at remembering the faces of children than control groups can. However, it is currently unknown whether own-age bias affects the ability to understand mental states and, if so, whether this bias can be reduced by experience with other age groups. \n\nAn experimental task widely used to measure socio-perceptual component of TOM is the Reading the Mind in the Eyes Task (RMET) . There is also a debate on whether RMET engages affective, cognitive or both of these TOM components . RMET consists of pictures of the eye region of Caucasian adults paired with adjectives describing mental states (such as playful, amused, and interested). The task requires the processing of the part of the face and gaze direction to choose the correct adjective. RMET was designed specifically to study autism spectrum disorder, however, it was also successfully used in studies of the general population and was later adapted to use in functional magnetic resonance imaging (fMRI). In fMRI studies, the RMET task (Adult Mind condition, AM) is contrasted with a sex recognition task (Adult Sex condition, AS) to obtain brain activations related solely to mindreading. This comparison evokes strong activation in the inferior frontal gyrus (IFG) and posterior superior temporal sulcus (pSTS) . The IFG has been linked to the human mirror neuron system and observing the actions of others . Facial expressions are also an action type , and the activity of the IFG in the AM condition may reflect facial mimicry and the simulation of others\u2019 facial expressions and mental states . Among other functions, the pSTS is involved in decoding social stimuli such as faces and eye gaze . Specifically, this region shows higher activation to socially relevant stimuli than socially irrelevant stimuli . It was also proposed that it serves a more general function of the temporal integration of information flow during TOM processing . \n\nUsing the original and the East Asian RMET, Adams et al.  showed that white American and Japanese individuals were better at understanding mental states of people of their own race group. When directly comparing AM to AS within a race to the same contrasts in other races, in the case of both groups, increased activation in the pSTS was observed. Interestingly, lower activation in the pSTS in the AM condition for other races was related to the behavioural effect of own-race bias (better accuracy in the own-race AM condition than in the other-race AM condition). Thus, the activity of the pSTS is sensitive to ethnic group membership and corresponds to the behavioural effect of own-race bias. Nevertheless, the own-group advantage can be reduced by experiencing other cultures. For example, in a group of East Asian residents of Canada, performance in the Caucasian RMET was positively associated with the amount of time the participants had lived in Canada, their experience interacting with Caucasians and a shift from their own cultural values towards Canadian values . Similarly, Anatolian Dutch and Moroccan Dutch people were equally good at understanding the mental states of their own ethnic group as they were those of Caucasians . These results indicate the occurrence of the own-race bias in TOM processes and that experience with other cultures can reduce this bias and improve the understanding of mental states of people from other cultural groups. \n\n\n## Current study \n  \nCurrent evidence shows that people who work with children are better at recognizing children\u2019s faces than control groups . This effect can be explained as perceptual expertise acquired by daily contact with children or increased motivation to attend to children faces . Remembering faces was shown to be a predictor of TOM abilities, measured by understanding mental states from the eye region, voice and videos . Therefore, adults who work with children could potentially become experts in understanding the mental states of children. This idea is supported by the fact that people who live in multi-ethnic societies can improve their ability to understand the mental states of people of other ethnic groups . \n\nThis study aimed to investigate whether a similar effect of experience occurs in adults who work with children. To address this issue, we recruited young childless adults who had a history of working with children or who were working with children at the time of the study (WC) and a second group of childless adults who had no history of working with children (NWC). To measure participants\u2019 ability to understand the mental states of children, we designed the Nencki Children Eyes Test (NCET), which is a test analogous to the RMET but comprises photos of children. We hypothesized that the RMET and NCET would evoke activation in brain areas engaged in mental state processing, specifically the pSTS and IFG, in all participants. We hypothesized that WC would perform better than NWC in the NCET due to their experience working with children. Because decreased pSTS activity seen when trying to understand other-race mental states was related to own-race bias in previous work , we hypothesized that NWC would show a similar decrease in pSTS activity when performing the NCET, which would represent own-age bias in TOM processing, in contrast, we hypothesized that WC would be characterized by increased activation in the pSTS during the NCET, representing a reduction in the own-age bias. \n\n\n## Methods \n  \n### Participants \n  \nThirty-eight healthy, childless adults (age M\u2009=\u200924.08; SD\u2009=\u20093.33) took part in the study: 19 (10 females) who were working with children at the time of the study or who had worked with them in the past for more than half a year and 19 (10 females) who had never worked with children or who had worked with them for less than half a year. The weekly number of hours the WC group spent working with children ranged from 3.5 to 37.5 (M\u2009=\u200914.31; SD\u2009=\u200911.53). The professions of the participants were varied and included school and preschool teachers, sports instructors, babysitters, children\u2019s physiotherapists, and camp counsellors. All participants were of Caucasian ethnicity. Participants were recruited via advertisements in various groups on Facebook. They were mostly students of Warsaw Universities, and all were native Polish speakers. \n\nSubjects signed an informed consent form and were told about the possibility of resigning from further participation at any point of the study. Financial gratification in the amount of 100 PLN (approximately 20\u201325 EUR) was provided to each subject. The Committee for Research Ethics of the University of Warsaw approved the experimental protocol of the study. The experiment was conducted in compliance with the American Psychological Association\u2019s (APA) Ethical Principles of Psychologists and Code of Conduct ( ). \n\n\n### Experimental tasks \n  \n#### Reading the Mind in the Eyes Task (RMET) \n  \nThe revised version of the   RMET   was designed to measure the ability of the participant to attribute complex mental states (feelings/thoughts/intentions) to others. It consists of 36 photos of the eye region of adults, where each photo is paired with 4 adjectives describing mental states. A participant is asked to choose one term that matches the internal state of the person in the photo. The original task has been previously adapted to the requirements of fMRI studies by limiting the number of displayed adjectives to two instead of four . The sex recognition task was used as a control condition, in which a participant was asked to specify the sex of the person in the photo. For the Polish version of the   RMET,   adjectives were translated from English to Polish by one translator and then back-translated by another translator. \n\n\n#### Nencki Children Eyes Test (NCET) \n  \nDue to the lack of a tool analogous to the   RMET   comprising photos of the eye region of children, we created the   NCET   with 36 photos of the eye region of boys (18) and girls (18) of Caucasian ethnicity. Photos were taken from  , all under the license of noncommercial use with modifications allowed (CC BY-NC 2.0). They were cropped to the eye region, and the colour was changed to black and white. Then, the luminosity and contrast were adjusted using Photo Pos Pro software ( ) for each image to improve the consistency between the photos . \n\nFirst, 20 participants (10 females) assessed the sex of the child in the photo, and only photos with 70% accuracy or higher were used in the next step. This step was performed to create a control condition for the fMRI procedure, similar to the control condition for the   RMET   fMRI adaptation . Next, two independent judges ascribed four terms (one correct, three false) describing the mental state expressed by the child in the photo. Afterwards, a new cohort of subjects (n\u2009=\u200920, 10 females) had to choose the most accurate term describing every image. The photo with the adjectives was included only when one term was chosen by at least 50% of the participants (further treated as the correct one), and each of the three others had no more than 25% answers. The procedure was similar to that described by Baron-Cohen et al.  and was repeated until the number of photos in the test did not reach 36. For the purpose of   NCET   fMRI adaptation, we used two adjectives\u2014the one that was the most frequently selected (treated as the correct answer) and the one that was the least frequently chosen in the validation process. Detailed information about the luminance, contrast, and entropy of the stimuli used in   NCET   are presented in Supplementary Table  . All images used in the NCET are freely available to the scientific community for non-commercial use ( ). \n\n\n\n### Control tests \n  \nHere, we employed various tests to control for possible differences in the studied groups . We gathered measures of the ability to reason about beliefs, basic emotion recognition, vocabulary knowledge and empathy. Additional information regarding the correlations between the control tests and the NCET and the RMET is provided in Supplementary Table S2. \n\n#### PENN ER-40 \n  \nThe   PENN ER-40   task  was used to assess the ability to recognize basic emotions. This task is performed on a computer and comprises 40 photos of faces, each of which is displayed with five terms, four describing basic emotions\u2014\u201chappy\u201d, \u201csad\u201d, \u201cangry\u201d, \u201cfear\u201d\u2014and the fifth describing a neutral expression\u2014\u201cneutral\u201d. The participant has to choose which emotion is expressed by the person in the image and then assess how certain they are of their answer on a scale between 0 and 100. The overall score is the sum of the right answers (maximum 40). \n\n\n#### Hinting task \n  \nThe   Hinting Task   is a false-belief type of test that was used to measure   TOM  . During this task , a participant is presented with ten stories picturing interactions between two persons. Each story ends with a statement stated by one (X) of the two characters, and a question is posed: \u201cWhat does X truly want to say?\u201d. The participant provides an answer for which 0, 1 or 2 points can be given, according to the solution key. If the answer is rated with 0 points, a hint is presented to the participant, who can provide an additional answer. After being provided with a hint, a participant can obtain only 0 points or 1 point. Participants\u2019 answers are written down, and the points earned and the number of hints given are summed. \n\n\n#### Comprehension of words test standard version (TRS-S) \n  \n TRS-S   consists of 32 items and is a test of synonyms, i.e., a person has to choose a synonym of a given word from five possible answers, and the maximum score that can be obtained in the test is 32. This test measures vocabulary knowledge and is highly correlated with fluid intelligence and other tests of vocabulary knowledge . \n\n\n#### Interpersonal reactivity index (IRI) \n  \n IRI   is a multidimensional questionnaire designed by Davis  for measuring four different aspects of empathy: Empathic Concern, Personal Distress, Perspective Taking and Fantasy. However, in the Polish adaptation, the Fantasy subscale was excluded due to a weak theoretical background . The Empathic Concern subscale measures feelings of concern and sympathy for others, the Personal Distress subscale measures negative emotions experienced in tense social settings, and the Perspective Taking subscale measures the ability to take another\u2019s perspective (  put oneself in another\u2019s shoes  ). Empathic Concern and Personal Distress are correlated with tools used to measure emotional empathy , while Perspective Taking is correlated with tests used to measure cognitive empathy . The Polish version of the IRI consists of 28 statements (11 for Empathic Concern, 8 for Personal Distress and 9 for Perspective Taking). A participant is asked to mark how he/she agrees with each statement on a 1\u20135 Likert-type scale ranging from \u201cCompletely disagree\u201d to \u201cAbsolutely agree\u201d. \n\n\n\n### Procedure \n  \n#### Behavioural measures \n  \nPrior to the fMRI procedure, demographic data were gathered, and behavioural tests described above were administered to subjects in a paper form. The Hinting Task was read aloud by the investigator, and the participant\u2019s answers were written down. Subsequently, the PENN task was completed on a computer. This part of the procedure took approximately 45\u00a0min. \n\n\n#### fMRI procedure \n  \nThe experimental procedure was based on a previous adaptation of the   RMET   adapted for fMRI settings . Participants were presented with 4 types of blocks: Adult Mind (AM,  RMET   fMRI adaptation), Child Mind (CM;   NCET   fMRI adaptation), Adult Sex (AS) and Child Sex (CS) (two control conditions). Each block was preceded by a cue indicating the type of block\u2014an \u201cEmotion\u201d cue informed the participant that the next block would be one of the Mind conditions, and the \u201cSex\u201d cue informed participants that it would be one of the Sex conditions. Blocks lasted for 22.25\u00a0s and consisted of 4 photos (presented for 5\u00a0s each) separated by fixation crosses (0.75\u00a0s). Blocks were separated by interblock intervals of 7, 10 or 12\u00a0s. The whole procedure took approximately 18\u00a0min and was divided into two sessions, with each session containing 18 blocks. Blocks were presented in a pseudorandomized order. Since the same pictures were presented in the Mind and the corresponding control condition, half of the participants were presented with the session in an inverse order. The experimental procedure was implemented using Presentation (ver. 20.1; Neurobehavioural Systems, Inc., Albany, CA, USA). For an overview of the procedure, see Fig.\u00a0 .   \nThe fMRI experimental procedure was an adaptation of the RMET and NCET tasks. It consisted of four types of blocks: Adult Mind (AM; RMET adaptation), Child Mind (CM; NCET adaptation), Adult Sex (AS) and Child Sex (CS) (two control conditions). Each block consisted of a cue (Emotion/Sex), 4 photos of children or adults (depending on the task condition) and 4 fixation crosses. In each block, participants were asked to choose one of two possible terms that matched the internal state of the person in the photo (AM and CM conditions) or the sex of the person in the photo (AS and CS conditions). Blocks were presented in a pseudorandomized order and were separated with intervals. The task was divided into two sessions, and each session consisted of 18 blocks.   RMET   Reading the Mind in the Eyes Test,   NCET   Nencki Children Eyes Test,   IBI   interblock interval. \n  \n\n\n\n### Behavioural analysis \n  \nFor the between-groups comparison of demographic data, questionnaire measures and the PENN task, we used either Student\u2019s t-test or the Mann\u2013Whitney U-test, depending on the distribution of the data, using R software. For the between-groups comparison of the level of education, we used the chi-squared test. Accuracy data were used to examine differences in performance between groups and task conditions. Based on participants\u2019 performance, trials were classified as correct or incorrect (incorrect hits or misses). The aligned rank transformation was applied to accuracy data prior to ANOVA, which is the proper method for the factorial analysis of nonparametric data and accuracy data . We performed ANOVA with group (2 levels: WC/NWC) as a between-subjects factor and condition (4 levels: AM/CM/AS/CS) as a within-subjects factor. To verify our behavioural hypothesis, we planned to directly compare WC and NWC in CM conditions using a one-sided Wilcoxon-Mann\u2013Whitney U test. Additionally, we directly compared WC and NWC in other experimental conditions (AM, AS, CS) using a two-sided Wilcoxon\u2013Mann\u2013Whitney U test to ensure that there were no other differences between groups. As these tests were planned a priori, we did not correct for multiple comparisons . Reaction time data were transformed using the Freeman\u2013Tukey method . Subsequently, ANOVA with group (2 levels: WC/NWC) as the between-subjects factor and condition (four levels: AM/CM/AS/CS) as the within-subjects factor was conducted. Reaction time data were examined to ensure that experimental conditions were more demanding than control conditions. The remaining post hoc tests were corrected using Hochberg\u2019s correction for multiple comparisons . Additionally, in the WC group, we run Pearson\u2019s correlation between the number of years participants have worked with children (  Number of Years  ), weekly hours spent in work (  Weekly Hours  ) and behavioural and neuronal measures in the CM condition. All statistical analyses described in this paragraph were performed in R software , with use of   emmeans   and   nlme   packages. \n\n\n### MRI data acquisition \n  \nMagnetic resonance imaging data were acquired using a 3\u00a0T Siemens MAGNETOM Trio system (Siemens Medical Solutions) equipped with a 12-channel head coil. Within a single scanning session, the following images were acquired: structural localizer image, first series of functional EPI images (TR: 2,500\u00a0ms, TE: 28\u00a0ms, flip angle: 80\u00b0, voxel size: 3\u2009\u00d7\u20093\u2009\u00d7\u20093\u00a0mm, field of view: 216\u00a0mm, measurements: 240), second series of functional EPI images (same parameters), structural T1-weighted image (TR: 2,530\u00a0ms, TE: 3.32\u00a0ms, flip angle: 7\u00b0, voxel size: 1\u2009\u00d7\u20091\u2009\u00d7\u20091\u00a0mm, field of view: 256\u00a0mm), and field map (TR: 400\u00a0ms, TE: 6.81\u00a0ms, flip angle: 60\u00b0, voxel size: 3.5\u2009\u00d7\u20093.5\u2009\u00d7\u20093.5\u00a0mm, field of view: 216\u00a0mm). \n\n\n### fMRI data preprocessing \n  \nDICOM series were converted to NIfTI using   Horos (Osirix) Bids Output Extension   ( ), which is based on the dcm2niix converter ( ). Data preprocessing and analysis were performed with Statistical Parametric Mapping (SPM12,  ). Standard preprocessing steps were used , including correction for distortions related to magnetic field inhomogeneity, correction for motion by realignment to the first acquired image; coregistration of the anatomical image to the mean functional image; segmentation of the coregistered structural image with the default tissue probability maps; normalization to the MNI space; and smoothing with 6\u00a0mm FWHM Gaussian Kernel. The ARtifact Detection Tools (ART,  ) software package was used to identify sources of artefacts in functional images, with a translation threshold of 2\u00a0mm and a rotation threshold of 0.02 radians. \n\n\n### fMRI data analysiss \n  \nGeneral linear modelling was used to model blood-oxygen-level dependent (BOLD) signal data for each subject at the first-level analysis. Each block was modelled with the onset of the presentation of the first photo in a given block and a duration of 22.25\u00a0s. Cues that preceded blocks were modelled with corresponding onsets and durations of 0.75\u00a0s. These predictors were convolved with a double gamma \u201ccanonical\u201d haemodynamic response function, and a high-pass filter cut-off of 128\u00a0s was applied. Next, individual t-contrast maps were computed for each of the experimental (AM and CM) and control (AS and CS) conditions. \n\nInitially, we conducted full factorial analysis for all participants, with age (Adult/Child) and task (Mind/Sex) as factors. The positive effect of task (Mind\u2009>\u2009Sex;   p  \u2009<\u20090.05, FWE corrected) was used as an explicit mask in further analysis . Then, a flexible factorial design with condition (AM/CM) as the within-subjects factor and group (WC/NWC) as the between-subjects factor was performed. The interaction effect was included in the design and tested with F contrast. A voxel-wise height threshold of   p  \u2009<\u20090.001 (uncorrected) combined with a cluster-level extent threshold of   p  \u2009<\u20090.05 (FWE corrected) was applied. For post hoc analysis, we extracted mean contrast estimate values that were extracted using MarsBar ( ) from ROIs defined by the clusters with significant activation obtained in the interaction F contrast. The extracted values were compared using the emmeans package in R  and were corrected using Hochberg\u2019s method . All brain areas reported in the study are labelled according to the automated anatomical labelling (AAL2)  atlas applied in bspmview ( ). Additionally, we used the Neurosynth ( ) website to evaluate whether the coordinates for significant activations in the flexible factorial design corresponded to functional maps reported in the literature. \n\n\n\n## Results \n  \n### Behavioural results \n  \n#### Control tests \n  \nWe did not observe any between-groups differences in any of the control measures. The results are summarized in Table  .   \nGroup comparisons of behavioural and self-reported measures. \n  \n WC   working with children,   NWC   not working witch children. \n  \n\n\n#### RMET and NCET \n  \nAn analysis of accuracy revealed a significant effect of condition (F(3,108)\u2009=\u200969.18,   p  \u2009<\u20090.001, \u03b72\u2009=\u20090.54) but no effect of group (F(1,36)\u2009=\u20090.94,   p  \u2009=\u20090.34, \u03b72\u2009=\u20090.01). There was a trend towards a significant effect of the interaction between group and condition (F(3,108)\u2009=\u20092.65,   p  \u2009=\u20090.052, \u03b72\u2009=\u20090.04). Post hoc tests showed that AM was more difficult than AS (T\u2009=\u2009\u2212\u200914.18,   p  \u2009<\u20090.001), AM was more difficult than CM (T\u2009=\u2009\u2212\u20094.9,   p  \u2009<\u20090.001), and AS was less difficult than CS (T\u2009=\u20097.5,   p  \u2009<\u20090.001). There was also a trend showing that CM was more difficult than CS (T\u2009=\u2009\u2212\u20091.8,   p  \u2009=\u20090.075). Post hoc tests of the interaction effect showed that WC scored higher than NWC in CM (U\u2009=\u2009255,   p  \u2009=\u20090.028, r effect size\u2009=\u20090.18), whereas there were no significant differences between groups in AM (U\u2009=\u2009187.5,   p  \u2009=\u20090.85), AS (U\u2009=\u2009137,   p  \u2009=\u20090.13) or CS (U\u2009=\u2009210,   p  \u2009=\u20090.4) conditions (Fig.\u00a0 a).   \nBehavioural results of RMET and NCET. (  a  ) Accuracy in different task conditions for the two groups. Significant post hoc tests of the main effect of condition are marked in grey. A significant post hoc test of the interaction between group and condition is marked in black. (  b  ) The mean reaction times in different task conditions for the two groups. Error bars represent SEs. Significant post hoc tests of the main effect of condition are marked in grey. Groups:   WC   working with children,   NWC   not working with children; Conditions:   AM   adult mind,   CM   child mind,   AS   adult sex,   CS   child sex; #  p  \u2009<\u20090.1; *  p  \u2009<\u20090.05; **  p  \u2009<\u20090.001. \n  \n\nAn analysis of response times revealed a significant effect of condition (F(3,108)\u2009=\u2009433.7,   p  \u2009<\u20090.001, \u03b72\u2009=\u20090.57) but no significant effect of group (F(1,36)\u2009=\u20091.02,   p  \u2009=\u20090.32, \u03b72\u2009=\u20090.03) or an interaction between group and condition (F(3,108)\u2009=\u20090.55,   p  \u2009=\u20090.65, \u03b72\u2009=\u20090.001). Post hoc tests showed that reaction time was higher in AM than in AS (T\u2009=\u200927.9,   p  \u2009<\u20090.001), in CM than in CS (T\u2009=\u200913.3,   p  \u2009<\u20090.001) and in AS than in CS (T\u2009=\u2009\u2212\u200913.9,   p  \u2009<\u20090.001) conditions. There was no difference in response times between AM and CM conditions (T\u2009=\u20090.71,   p  \u2009=\u20090.47; Fig.\u00a0 b). \n\n\n\n### fMRI results \n  \nWhole brain analysis for all participants revealed that the attribution of mental states to others (AM and CM\u2009>\u2009AS and CS) activated a broad network consisting of activation surrounding the bilateral STS and superior temporal gyrus (STG), bilateral inferior frontal gyri (IFG), bilateral middle temporal gyrus (MTG), right temporal pole (TP) and left middle frontal gyrus (MFG) (Fig.\u00a0 a). A more thorough description of the clusters and peaks obtained in the analysis is presented in Table  . The F contrast of the interaction between group and condition (WC\u2009\u2212\u2009NWC)\u2009*\u2009(CM\u2009\u2212\u2009AM) resulted in significant clusters of voxels in the bilateral IFG and right pSTS (Table  ; Fig.\u00a0 b). The results from F contrast interaction were then explored using post hoc tests on the estimated mean values of contrasts extracted from left IFG, right IFG and right pSTS.   \n(  a  ) Whole-brain statistical parametric maps representing brain activation during the attribution of the mental states of others (MIND\u2009>\u2009SEX); corrected for multiple comparisons (FWE;   p  \u2009<\u20090.05). (  b  ) Whole-brain statistical parametric maps representing the F contrast interaction between group and condition (WC\u2009>\u2009NWC)\u2009*\u2009(CM\u2009>\u2009AM) with a voxel-wise height threshold of   p  \u2009<\u20090.001 (uncorrected) combined with a cluster-level extent threshold of   p  \u2009<\u20090.05 (corrected for multiple comparisons using the FWE. Analysis was limited to volumes from a. Groups:   WC   working with children,   NWC   not working with children, Conditions:   AM   adult mind,   CM   child mind,   MIND   AM and CM,   SEX   AS and CS. \n    \nPeak level activations related to understanding the minds of others compared to sex recognition. \n  \nThe table shows all the local maxima separated by more than 8\u00a0mm. Regions were automatically labelled using automatic anatomical labelling. x, y, and z of the Montreal Neurological Institute (MNI) coordinates in the left\u2013right, anterior\u2013posterior, and inferior-superior dimensions, respectively. \n    \nPeak level activations related to understanding the minds of others compared to sex recognition. \n  \nA voxel-wise height threshold of   p  \u2009<\u20090.001 (uncorrected) combined with a cluster-level extent threshold of   p  \u2009<\u20090.05 (corrected for multiple comparisons using the FWE rate) was applied. Activations surviving a peak-level FWE-corrected threshold of   p  \u2009<\u20090.05 are marked with bold text. The table shows all the local maxima separated by more than 8\u00a0mm. Regions were automatically labelled using automatic anatomical labelling. x, y, and z of the Montreal Neurological Institute (MNI) coordinates in the left\u2013right, anterior\u2013posterior, and inferior\u2013superior dimensions, respectively. \n  \n\n#### Left IFG \n  \nPost hoc comparison revealed that in the CM condition, the WC group had stronger activation than the NWC group (t\u2009=\u20094.13;   p  \u2009<\u20090.001) and that the WC group had stronger activation in the CM condition than the AM condition (t\u2009=\u20094.59;   p  \u2009<\u20090.001) (Fig.\u00a0 ).   \nThe mean contrast estimates for the two experimental conditions for the two groups; Error bars represent SEs. Significant post hoc tests of the interaction between group and condition are marked with black brackets and symbols. Hochberg\u2019s correction for multiple comparisons was applied. Groups:   WC   working with children,   NWC   not working with children; Conditions:   AM   adult mind,   CM   child mind; Regions:   lIFG   left inferior frontal gyrus,   rIFG   right inferior frontal gyrus,   pSTS   right posterior superior temporal sulcus. *  p  \u2009<\u20090.05; **  p  \u2009<\u20090.001. \n  \n\n\n#### Right IFG \n  \nPost hoc comparisons revealed that the WC group had stronger activation in the CM condition than the AM condition (t\u2009=\u20094.26;   p  \u2009<\u20090.001; Fig.\u00a0 ). \n\n\n#### Right pSTS \n  \nPost hoc comparisons revealed that the WC group had stronger activation in the CM condition than the AM condition (t\u2009=\u20092.53;   p  \u2009=\u20090.048). The opposite pattern was observed in the NWC group, which had stronger activation in AM condition than the CM condition (t\u2009=\u20093.01;   p  \u2009=\u20090.019) (Fig.\u00a0 ). \n\n\n\n### Correlations between time spend with children, behavioural and neuronal measures \n  \nWe found that reaction times in CM were negatively correlated with   Number of Years   (r\u2009=\u2009\u2212\u20090.53;   p  \u2009=\u20090.024). There were no other significant correlations (Table  .)   \nPearson\u2019s R correlations between measures of time spend with children, behavioural and neuronal measures in CM condition, in WC group. \n  \nCM\u2014Child mind; WC\u2014working with children; Number of years\u2014number of years participants have been working with children; Weekly hours\u2014weekly hours spend in work. *  p  \u2009<\u20090.05. \n  \n\n\n\n## Discussion \n  \nThe phenomena of being able to better remember the faces of members of our own age and own race groups have been well documented . These phenomena are described as own-age bias and own-race bias, respectively. Currently, there is also evidence for own-race bias in understanding mental states in the RMET. This bias can be reduced by gaining experience with other ethnic groups. However, it is unclear whether a similar effect of experience occurs in adults who work with children, reducing own-age bias. Clarifying this topic can improve our understanding of how experience affects TOM and underlying neuronal processes. \n\nTo answer this question, we recruited two groups of adults who were either working with or not working with children and asked them to perform the NCET (CM condition) and RMET (AM condition) tasks in an fMRI setting. We showed that the WC group scored better in the CM than NWC, while there were no between-group differences in the AM condition. When comparing MIND (AM and CM) to SEX (AS and CS) conditions, we observed substantial activation in the bilateral IFG, temporal poles and STS, regions that had previously been reported in studies using the RMET. Additionally, we found an effect of the interaction ((NWC\u2013WC)\u2009*\u2009(CM\u2013AM)) in the bilateral IFG and right pSTS. Specifically, in the left IFG, in the CM condition, the WC group had stronger activation than NWC, and the WC group had stronger activation in the CM condition than in the AM condition. A similar difference between the CM and AM conditions was observed for the WC group, in the right IFG and right pSTS. Additionally, in the right pSTS, NWC were characterized by stronger activation during the AM condition than the CM condition. \n\n### Behavioural differences \n  \nWe found that the WC group performed better than the NWC group in the CM condition, as we hypothesized. At the same time, there were no differences between groups in other experimental conditions. This result is in line with previous studies on an increased ability to remember children\u2019s faces in adults who work with children. A similar improvement was observed in people who live outside their culture of origin. Anatolian Dutch and Moroccan Dutch individuals did not differ in their performance of their own-culture RMET and the Caucasian RMET, while Caucasian Dutch individuals performed worse on the other cultures\u2019 RMETs . The authors of this study suggested that bicultural individuals need to adjust to the Dutch (majority) culture in situations such as work or school, while during interactions with their relatives, they still need to act according to their primary culture. Another study that provided evidence for experience-based improvement in TOM abilities involved Asians living in Canada . Although these subjects performed worse in the Caucasian RMET than in the East Asian RMET, their accuracy in the Caucasian RMET increased as a function of the time they had lived in Canada, their experience interacting with Caucasians, how positive their view on Canadian values was, and how much their identification with their primary culture had decreased. \n\nWe did not find behavioural effects of own-age bias. For all participants, the AM condition was harder than CM. This might have been caused by the fact that children\u2019s facial expressions are more straightforward than the facial expressions of adults. Basic emotions such as sadness, anger and happiness were more easily recognized if they were expressed by children than adults . However, disgust was the only basic emotion that was better recognized if presented by adults. Additionally, in our study, children\u2019s facial expressions might have been easier to correctly match with a given adjective, thus resulting in a lack of behavioural effects related to the own-age bias. \n\nAnother explanation of such results would be the difference between valence and/or intensity of the stimuli in NCET and RMET. Unfortunately, following the procedure of Baron-Cohen et al.  we did not collect the valence and arousal ratings of the stimuli, thus we cannot conclude about the possible impact of these factors. Since we did not observe an effect of the own-age bias, it is more appropriate to ascribe the increased ability to recognize children mental states, observed in the WC group, as caused by familiarity or experience with children. This is further strengthened by the fact that the number of years the participants in the WC group had worked with children was inversely related to the reaction time in the CM condition. Familiarity was described as a potential cause of a reduction of the own-age bias in face recognition in adults who work with children . It was also shown to improve various cognitive skills , in particular recognition of face stimuli . \n\n\n### Differences in pSTS activity \n  \nIn the NWC group, pSTS was activated more in the AM condition than CM. The opposite was observed in the WC group, in which the pSTS was more active in the CM condition than the AM condition. The pattern of activation in the NWC group resembles results reported in studies of own-race bias in the RMET . All participants in this study were characterized by lower activity for other races than for the own-race RMET. This lower pSTS activation to the other-race RMET was also associated with the effect of own-race bias (better performance in the own-race RMET). However, based on the neuronal activation in the NWC group we cannot conclude the occurrence of own-age bias as all participants performed better in the CM condition. The pSTS is a core region in the network responsible for social information processing, serving as a hub communicating with many other regions . This region receives input from sensory regions and is sensitive to social information. The pSTS was shown to be activated specifically when socially relevant stimuli were contrasted with irrelevant stimuli . Information about social cues is sent to the IFG and the inferior parietal lobule (IPL), which are responsible for understanding others\u2019 actions and emotions  by referring them to our own. Next, the signal is sent back to the pSTS where it can be transferred further for more advanced TOM processing, such as belief attribution, based on prior information. The increased activation of the pSTS when understanding the mental states of children might reflect the increased importance of such interactions in the WC group. The increased importance of these interactions was previously proposed as being responsible for the ability of teachers to better remember children\u2019s faces  and for better performance in RMETs of other cultures . The other explanation would simply be a better ability to process sensory information derived from the eye region, in other words, sensory expertise caused by familiarity. The pSTS is also engaged in face-selective processing and activates stronger to familiar vs unfamiliar faces . In a recent study, the pSTS was found to be related to person-selective processing, irrespectively of modality . Therefore the increased activation of pSTS during recognizing the mental states of children in the WC group might reflect an increased familiarity with children. Last, this effect might have been caused by increased activity in the mirror neuron system, corresponding to increased empathy with children. This explanation is highly plausible, as we also observed between- and within-groups differences in the bilateral IFG. \n\n\n### Differences in IFG activity and the mirror neuron system \n  \nFor the WC group, the activation in the bilateral IFG was higher in the CM condition than in the AM condition, similar to what we observed in the pSTS. Additionally, the WC group was characterized by increased activity in the left IFG compared to NWC in the CM condition. \n\nIFG and IPL are parts of the Human Mirror Neuron System (MNS), a group of neurons activated by motor performance as well as observing movements performed by others . MNS was also linked to action understanding, imitation , understanding intentions  and also emotions of others, thanks to facial mimicry . According to the simulation theory, MNS is also the basis for TOM and allows the observer to simulate a mental state that corresponds to the state of the observed person . The activation of the IFG is typically reported in studies using RMET-type tasks , and it is crucial to correctly perform the RMET. Patients with brain lesions in the IFG have been shown to have decreased accuracy in the RMET . Transcranial magnetic stimulation of the IFG was shown to increase reaction times during the RMET and disrupt EEG rhythms related to mirror neurons activity . The RMET requires emotional and semantic processing. Similarly, IFG function is believed to be related to facial mimicry  and storing semantic representations of others\u2019 mental states . However, increased activity in the IFG of those in the WC group when understanding the mental states of children is unlikely to be related to differences in purely semantic processing, as both groups did not differ in their vocabulary knowledge, and the TRS-S score was not related to AM or CM accuracy. Moreover, the AM condition also required the semantic processing of similar adjectives, but no differences in the activation of the IFG during the AM condition were observed. It is more plausible that the WC group expressed increased facial mimicry and had better ability to simulate children\u2019s mental states when viewing children\u2019s photographs, which resulted in a more accurate choice of descriptions of mental states in the CM condition. Interestingly, increased activation of left IFG was also observed in a group of older adults while they performed RMET (comprised mostly of photographs of young adults) in fMRI . Elderly subjects did not differ from young adults, in accuracy, thus the increased engagement of IFG might have been needed to better understand the mental states of members of different age-group, similar to what was observed in the WC group in our study. \n\nAn increase in the activation of brain regions related to mirroring and theory of mind has been previously reported by different groups of experts in specific fields . For example, when watching archery videos, a group of expert archers showed stronger activation in the IPL, pSTS and inferior prefrontal cortex than a non-archer control group. This increased activation was interpreted as an increased number of representations in the human mirror neuron system. Similarly, in our study, the WC group could have shown an increase in the number of representations of children\u2019s facial expressions and/or mental states. Increased activity in bilateral IFG in the WC group supports the role of MNS in the ability to decode the mental states. \n\n\n### Study implications \n  \nOur study is the first to focus on specific expertise in understanding mental states, so these results need to be treated with caution and further explored. Further studies could determine whether this effect could be generalized to other age-groups like adolescents or the elderly. Nevertheless, training-induced neuroplasticity changes in regions related to TOM processing have already been reported in the literature . Our results have implications for childhood education. It shows the potential of personal experience in improving the ability to understand the mental states of children. One may ask to what extent such personal experience in the form of a practical internship (or even having own children) can influence the ability to understand the mental states of children compared to formal pedagogical education. Additionally, our study may shed light on the contact hypothesis which is the idea that interpersonal contact can improve intergroup relations and can effectively reduce prejudice between various social groups (Allport, 1954). Although this hypothesis found support in hundreds of studies (Pettigrew and Tropp, 2006), the psychological processes involved in this improvement are still debated in the literature. One may speculate that one such mediating mechanism is TOM. The prolonged intergroup contact may facilitate the ability to understand mental states of other groups\u2019 members which in turn helps to take the perspective of those members and to empathize with them. \n\n\n### Study limitations and future directions \n  \nWe used experimental tasks that measure mental state decoding and can engage both affective and cognitive TOM. Substantial step forward would be to investigate whether familiarity with children affects mental state reasoning and use tasks which target affective and cognitive components specifically. Additionally, we do not know whether increased contact with children is the reason for better accuracy in CM, in the WC group or whether people who are better at thinking about the minds of children are more likely to work with them. Currently, we know that a similar effect of experience on the accuracy of out-group RMET performance is observed in people who live in multicultural societies outside their culture of origin. Future studies should explore the underlying neuronal mechanism of these behavioural results and compare them to the results obtained in our study. Another substantial step forward would be to investigate whether own-age, as well as other in-group biases, affect affective and cognitive TOM using experimental tasks targeting those processes more specifically. Lastly, since behavioural and neuronal differences in RMET, were observed between children, adolescent and adults  investigating those groups with NCET might expand our understanding of TOM development. \n\n\n\n## Conclusions \n  \nIn summary, we showed that familiarity with children improved the ability to understand the mental states of children in the WC group. In line with the behavioural results, we observed increased activation in the right pSTS and bilateral IFG during the attribution of mental states to children. This was not observed in the NWC group, in which the pSTS was more active during recognizing mental states of adults. Therefore, the engagement of these regions is required to improve the mindreading from the eye region. These differences in the brain\u2019s activity provide novel information about how experience with out-groups can shape behaviour and neuronal processing related to TOM. \n\n\n## Supplementary information \n  \n\n\n\n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table 1\nUnnamed: 0_level_0\tGroup\tGroup\tp value\nUnnamed: 0_level_1\tWC\tNWC\tp value\nUnnamed: 0_level_2\tMean (SD)\tMean (SD)\tp value\nT-test\tT-test\tT-test\tT-test\nYears of education\t15.9 (3.5)\t15.9 (2.26)\t0.938\nAge\t24.6 (3.3)\t23.2 (2.5)\t0.132\nTRS-S\t23.7 (4.25)\t23.7 (4.1)\t1\nEmpathic concern (IRI)\t36.0 (3.99)\t34.7 (3.68)\t0.244\nPersonal distress (IRI)\t24.0 (4.28)\t25.1 (5.85)\t0.616\nPerspective taking (IRI)\t31.9 (3.38)\t31.3 (1.73)\t0.674\n### Caption\nGroup comparisons of behavioural and self-reported measures.\n### Footer\nWC working with children, NWC not working witch children.\n\n\n## ID: Tab2\n### Label: Table 2\nContrast\tRegion label\tHemisphere\tCluster extent\tt-value\tMNI coordinates\tMNI coordinates\tMNI coordinates\tp FWE\nContrast\tRegion label\tHemisphere\tCluster extent\tt-value\tx\ty\tz\tp FWE\nAM and CM\u2009>\u2009AS and CS\tInferior frontal gyrus, pars orbitalis\tL\t7,951\t15.731\t\u2212\u200948\t14\t22\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tMiddle temporal gyrus\tL\t\t14.424\t\u2212\u200958\t\u2212\u200948\t6\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tSuperior temporal gyrus\tL\t\t14.419\t\u2212\u200954\t\u2212\u20096\t\u2212\u200910\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tMiddle temporal gyrus\tR\t2,451\t13.264\t52\t\u2212\u200934\t2\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tMiddle temporal gyrus\tR\t\t10.896\t54\t\u2212\u20092\t\u2212\u200916\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tTemporal pole: superior temporal gyrus\tR\t\t10.15\t48\t16\t\u2212\u200924\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tSupplementary motor area\tL/R\t686\t10.819\t\u2212\u20094\t10\t54\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tInferior frontal gyrus, pars triangularis\tR\t632\t10.279\t52\t32\t0\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tInferior frontal gyrus, pars triangularis\tR\t\t8.889\t46\t18\t24\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tCerebellum\tR\t901\t8.949\t18\t\u2212\u200968\t\u2212\u200926\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tCerebellum crus\tR\t\t7.401\t40\t\u2212\u200966\t\u2212\u200926\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tCerebellum\tL\t\t5.527\t\u2212\u20098\t\u2212\u200976\t\u2212\u200918\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tInferior occipital gyrus\tR\t142\t6.669\t\u2212\u200922\t\u2212\u200998\t\u2212\u20098\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tSuperior frontal gyrus, medial\tL\t44\t6.525\t\u2212\u200910\t54\t28\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tPrecentral gyrus\tR\t14\t6.27\t56\t2\t44\t<\u20090.001\nAM and CM\u2009>\u2009AS and CS\tSuperior temporal gyrus\tR\t13\t6.075\t66\t\u2212\u200938\t22\t0.001\nAM and CM\u2009>\u2009AS and CS\tCalcarine fissure and surrounding cortex\tL\t74\t5.987\t\u2212\u200914\t\u2212\u200972\t10\t0.001\nAM and CM\u2009>\u2009AS and CS\tCerebellum crus\tL\t10\t5.964\t\u2212\u200916\t\u2212\u200972\t\u2212\u200928\t0.001\nAM and CM\u2009>\u2009AS and CS\tVermis\tR\t42\t5.84\t0\t\u2212\u200952\t\u2212\u200934\t0.002\nAM and CM\u2009>\u2009AS and CS\tThalamus\tL\t34\t5.832\t\u2212\u20098\t\u2212\u200916\t8\t0.002\nAM and CM\u2009>\u2009AS and CS\tLenticular nucleus, Putamen\tR\t31\t5.54\t20\t14\t2\t0.006\nAM and CM\u2009>\u2009AS and CS\tMiddle frontal gyrus\tR\t13\t5.522\t46\t2\t56\t0.006\nAM and CM\u2009>\u2009AS and CS\tPrecentral gyrus\tR\t25\t5.208\t40\t\u2212\u20094\t46\t0.020\n### Caption\nPeak level activations related to understanding the minds of others compared to sex recognition.\n### Footer\nThe table shows all the local maxima separated by more than 8\u00a0mm. Regions were automatically labelled using automatic anatomical labelling. x, y, and z of the Montreal Neurological Institute (MNI) coordinates in the left\u2013right, anterior\u2013posterior, and inferior-superior dimensions, respectively.\n\n\n## ID: Tab3\n### Label: Table 3\nContrast\tAssociations neurosynth\tRegion label (AAL2)\tHemisphere\tCluster extent\tF-value\tMNI coordinates\tMNI coordinates\tMNI coordinates\tp FWE\nContrast\tAssociations neurosynth\tRegion label (AAL2)\tHemisphere\tCluster extent\tF-value\tx\ty\tz\tp FWE\n(WC\u2009\u2212\u2009NWC)\u2009*\u2009(CM\u2009\u2212\u2009AM)\tInferior frontal gyrus\tInferior frontal gyrus, pars triangularis\tL\t81\t34.215\t\u2212\u200942\t40\t4\t0.009\n(WC\u2009\u2212\u2009NWC)\u2009*\u2009(CM\u2009\u2212\u2009AM)\tVentrolateral prefrontal\tInferior frontal gyrus, pars triangularis\tR\t50\t20.56\t50\t34\t\u2212\u20092\t0.24\n(WC\u2009\u2212\u2009NWC)\u2009*\u2009(CM\u2009\u2212\u2009AM)\tPosterior superior temporal sulcus\tSuperior temporal gyrus\tR\t55\t18.45\t54\t\u2212\u200934\t8\t0.387\n### Caption\nPeak level activations related to understanding the minds of others compared to sex recognition.\n### Footer\nA voxel-wise height threshold of p\u2009<\u20090.001 (uncorrected) combined with a cluster-level extent threshold of p\u2009<\u20090.05 (corrected for multiple comparisons using the FWE rate) was applied. Activations surviving a peak-level FWE-corrected threshold of p\u2009<\u20090.05 are marked with bold text. The table shows all the local maxima separated by more than 8\u00a0mm. Regions were automatically labelled using automatic anatomical labelling. x, y, and z of the Montreal Neurological Institute (MNI) coordinates in the left\u2013right, anterior\u2013posterior, and inferior\u2013superior dimensions, respectively.\n\n\n## ID: Tab4\n### Label: Table 4\nUnnamed: 0\tCM reaction times\tCM accuracy\tCM L IFG\tCM R IFG\tCM pSTS\nNumber of years (n\u2009=\u200918)\t\u2212\u20090.53*\t0.21\t\u2212\u20090.13\t\u2212\u20090.25\t\u2212\u20090.40\nWeekly hours (n\u2009=\u200916)\t0.18\t0.05\t0.32\t\u2212\u20090.07\t\u2212\u20090.16\n### Caption\nPearson\u2019s R correlations between measures of time spend with children, behavioural and neuronal measures in CM condition, in WC group.\n### Footer\nCM\u2014Child mind; WC\u2014working with children; Number of years\u2014number of years participants have been working with children; Weekly hours\u2014weekly hours spend in work. *p\u2009<\u20090.05.\n", "metadata": {"pmcid": 7395771, "text_md5": "19b55bca0c8cc163a7256c729ef432ac", "field_positions": {"authors": [0, 220], "journal": [221, 228], "publication_year": [230, 234], "title": [245, 422], "keywords": [436, 500], "abstract": [513, 1779], "body": [1788, 46097], "tables": [46110, 50920]}, "batch": 2, "pmid": 32737383, "doi": "10.1038/s41598-020-69938-4", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7395771", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7395771"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7395771\">7395771</a>", "list_title": "PMC7395771  Familiarity with children improves the ability to recognize children\u2019s mental states: an fMRI study using the Reading the Mind in the Eyes Task and the Nencki Children Eyes Test"}
{"text": "Drolet, Matthis and Schubotz, Ricarda I. and Fischer, Julia\nFront Hum Neurosci, 2014\n\n# Title\n\nRecognizing the authenticity of emotional expressions: F0 contour matters when you need to know\n\n# Keywords\n\nemotion\nspeech\nprosody\ntheory of mind\ncontext\nauthenticity\n\n\n# Abstract\n \nAuthenticity of vocal emotion expression affects emotion recognition and brain activity in the so-called Theory of Mind (ToM) network, which is implied in the ability to explain and predict behavior by attributing mental states to other individuals. Exploiting the variability of the fundamental frequency (F0 contour), which varies more (higher contour) in play-acted expressions than authentic ones, we examined whether contour biases explicit categorization toward a particular authenticity or emotion category. Moreover, we tested whether contour modulates blood-oxygen-level dependent (BOLD) response in the ToM network and explored the role of task as a top-down modulator. The effects of contour on BOLD signal were analyzed by contrasting high and low contour stimuli within two previous fMRI studies that implemented emotion and authenticity rating tasks. Participants preferentially categorized higher contour stimuli as play-acted and lower contour stimuli as sad. Higher contour was found to up-regulate activation task-independently in the primary auditory cortex. Stimulus contour and task were found to interact in a network including medial prefrontal cortex, with an increase in BOLD signal for low-contour stimuli during explicit perception of authenticity and an increase for high-contour stimuli during explicit perception of emotion. Contour-induced BOLD effects appear to be purely stimulus-driven in early auditory and intonation perception, while being strongly task-dependent in regions involved in higher cognition. \n \n\n# Body\n \n## INTRODUCTION \n  \nEmotions play a fundamental role in human social behavior. Within an evolutionary framework, emotions are considered to be evolved, adaptive mechanisms that facilitate an organism\u2019s coping with important events ( ;  ). Although the dispute about the nature of emotions is far from settled, there is a growing consensus that emotion should be viewed as a multi-component entity ( ;  ;  ). The three major components of emotion are neurophysiological response patterns, subjective feelings, and the motor patterns of expressions of emotions. \n\nEmotions can be expressed through body language ( ), the face ( ;  ), or the voice ( ;  ). A key question in understanding emotions and their expression is whether emotions constitute graded or discrete entities ( ;  ). The discrete model initially gained support from research into facial emotion expressions ( ;  ;  ). Researchers that primarily investigated emotion expression in the voice, however, lean toward a graded model in which emotions and their expressions vary along continuous dimensions, including valence and arousal; some models also include potency ( ). This concurs with the fact that vocal expressions of emotion vary along continuous dimensions, such as pitch and intensity ( ). These multidimensional models have also been applied to the perception of vocal expressions of emotion ( ;  ), implying that the patterns revealed in emotion perception map onto the expression of emotions. Thus, studying the perception of emotion expressions can help us understand the nature of emotions themselves. \n\nNeuroscientific studies have provided evidence for the different theoretical accounts of emotions.   argued that the discovery of brain circuits and regions such as the amygdala that are associated with specific emotional responses and perception of facial emotional expressions supports a discrete model of emotion.   and  , however, found that the amygdala was not necessary for the perception of vocal emotion expression. Instead, the superior and middle temporal regions are involved in the perception of intonation or prosody ( ;  ;  ). This activation extends further into the temporal cortex than just the primary auditory cortex, also known as the transverse temporal gyrus (TTG), which is the region where cortical auditory processing begins ( ;  ). While these regions can be differentially activated by various expressions of emotion ( ), the evidence for clearly distinct regions for perceiving expressions of different emotions is still debated. \n\nAnother core issue is the link between emotion and cognition at the level of the experience, expressions, and perception of emotion.   observed that activity in the inferior frontal cortex was enhanced during explicit recognition of emotional prosody as compared to just listening to emotional prosody (see also  ). This led to a model in which the superior temporal and inferior frontal cortices are involved in basic acoustic and task-dependent processing, respectively ( ). Additionally, the orbitofrontal (OFC) and anterior cingulate cortices (ACC) may be central to making evaluative decisions based on the emotions associated with available choices ( ) during the perception of emotional prosody ( ). Such evaluation is included in models of emotion as so-called   cognitive appraisal  , often including information from different modalities and/or previous experiences. As such, the perception of emotion can be modified by context through cognitive appraisal of the situation and environment in which that expression is produced or perceived ( ;  ;  ). These findings indicate that the perception of emotional expressions parallels the multi-component dimensional nature implied in their production ( ;  ). \n\nA particularly relevant contextual modulator of emotion perception is recognition of speaker intention ( ,  ). The ability to perceive another\u2019s intention is commonly called Theory of Mind (ToM;  ), defined as the implicit or explicit attribution of mental states (e.g., desires, beliefs, and intentions) to others and self ( ;  ). ToM has been studied extensively, including its evolutionary roots ( ), its development ( ;  ), and its every-day use in humans ( ;  ). Importantly, ToM has been shown to both interact with emotion perception and be influenced by it ( ;  ). For example,   showed that active regulation of emotional distractors is required in cognitive tasks such as ToM. The influence of ToM on emotion recognition, however, has not been studied extensively. \n\nOur previous work ( ) showed that emotional authenticity affects emotion perception. Recordings of speech produced by professional actors after instruction to express a specific emotion (hereafter play-acted) were compared to speech produced without external instruction (hereafter authentic). While authenticity affected the recognition of categories of emotion, there were no significant effects of arousal or valence dimensions, likely due to the subtle differences inherent to short vocal expressions. Explicit rating of authenticity did induce blood-oxygen-level dependent (BOLD) response modulation in the ToM network (medial prefrontal, retrosplenial and temporoparietal cortices) more so than did emotion categorization, while authentic stimuli additionally up-regulated activation in an important component of the ToM network, the medial prefrontal cortex (mPFC). A subsequent study required only an emotion categorization task ( ), while subjects were told via cues whether a recording was authentic or play-acted. In that study, instead of authentic stimuli up-regulating mPFC, play-acted stimuli up-regulated temporoparietal junction (TPJ), early auditory processing in TTG, and early sentence perception in middle temporal gyrus (MTG) and superior temporal gyrus (STG). Cueing influenced brain activation in ACC when there was a conflict between cue and authenticity of stimulus, but did not affect brain activation found in the previous study or emotion recognition. Taken together, our previous results indicate an interaction between bottom-up and top-down influences. While activation in early auditory cortices appears to be stimulus-dependent, BOLD signal in frontal regions appeared to increase for authentic stimuli during recognition of authenticity and for play-acted stimuli during recognition of emotion. \n\nHowever, some important questions remain. Emotion is known to affect vocal expressions ( ;  ), but the acoustic properties that led to the aforementioned bottom-up effects of authenticity remain unclear.   examined the acoustic correlates of authenticity and found that contour (i.e., variability of the fundamental frequency or F0 contour) was significantly greater for play-acted recordings than for authentic. The variability in fundamental frequency is measured across the entire span of the vocal expression (see   Figure   ). So someone hearing an expression with   higher   variability may consider it more likely to be   play-acted  , while one with   lower   variability would be more likely to be   authentic  . The perception of such acoustical differences is paralleled by stimulus-induced activation in the brain.   showed that several acoustic parameters, including contour, correlated positively with activation in right STG, while a recent review by   found that superior temporal and lateral frontal areas are activated by phonological processing. \n  \n F0 contour (top) and spectrogram (bottom) of two complementary example recordings.   Examples are of the same text (\u201c\u2026 Pr\u00e4senz ist und so, was hier los ist\u2026\u201d translated: \u201c\u2026presence is and such, what is going on here\u2026\u201d) from the original authentic and play-acted versions. \n  \nAgainst this backdrop, we wished to determine whether F0 contour affects behavior and BOLD response when listening to emotional prosody and whether it is the acoustic variable that is responsible for the authenticity effects seen in the previous studies ( ,  ). Three main questions were addressed: (1) whether F0 contour influences the recognition of authenticity, (2) whether it influences early auditory and intonation processing and the ToM network during explicit categorization of emotions, and (3) whether it up-regulates TPJ and mPFC activity dependent on whether participants are rating emotional category or authenticity. These questions were tested on both previously published datasets ( ,  ). While the 2012 study included both the authenticity and emotion tasks, it became clear during the analysis that perception of emotional content required more power to be analyzed in detail. By combining the two studies it was possible to analyze the effects specific to the emotion task in the 2013 study (due to more emotion task trials), while contrasting task effects in the 2012 study. The studies included two different groups of participants and differences in the control tasks, but were otherwise setup identically. Based on the two previous studies, we predicted low contour stimuli would be rated as sad or authentic and high contour stimuli as anger or play-acted. \n\nWith regard to functional magnetic resonance imaging (fMRI), three hypotheses were tested. First, the effect of contour was analyzed parametrically to determine what, if any, region responded to the entire measurable span of contour. Based on differing contour between play-acted and authentic stimuli ( ) and up-regulation in the primary auditory cortex by play-acted stimuli ( ), we expected stimuli with higher contour to induce higher activation in primary auditory cortex, STG and superior temporal sulcus. \n\nSecond, BOLD effects of extremely high and low contour values were identified in order to directly compare recordings that, based on contour, have a high probability of being either authentic or play-acted. Based on our previous studies, as well as   and  , we predicted that the BOLD response in STG, MTG, TPJ, mPFC and lateral frontal areas would increase with increasing contour. \n\nThird, regions of interest (ROI) within the ToM network were examined in the previous contrast to determine whether task requirements modulate the effect contour has on the BOLD response. These ROIs were extracted from the two tasks in   to determine the interaction of bottom-up contour effects and top-down task effects. Based on previous results we expected authentic stimuli to up-regulate BOLD during authenticity tasks, and play-acted stimuli to do so during emotion tasks. \n\n\n## MATERIALS AND METHODS \n  \n### STIMULUS SELECTION \n  \nOriginal recordings (mono wave format; sample rate of 44.1 kHz) were selected from German radio interviews of individuals talking in an emotional fashion (anger, fear, joy, sadness) about a highly charged ongoing or recollected event (e.g., the death of a child, winning a lottery, threatened by a current danger). Emotion was ascertained through verbal content and recording summaries. Staged and scripted settings were excluded. Of 80 speech segments, 35 were made outdoors but were of good quality with minimal background noise. To ensure inference-free verbal content, text-only transcripts were rated by na\u00efve subjects. Recordings with emotion recognized better than chance were replaced to ensure neutral semantic content. The original set consisted of 80 recordings by 78 speakers (half male, half female; mean 1.75s \u00b1 1.00 SD; range 0.36\u20134.06 s). \n\nPlay-acted stimuli were performed by actors from Germany (42 actors each replicated a maximum of three recordings of equivalent emotional content), who were told to express each text in their own way, using the transcripts, summaries, and emotion (stimulus segments were not indicated and actors never heard the originals). Recording environment was varied while minimizing background noise, with 30 of 80 made outdoors (mean 1.76s \u00b1 1.02 SD; range 0.38\u20134.84 s). Average amplitudes of all stimuli were equalized with Avisoft SASLab Pro Recorder 4.40 (Berlin, Germany). The final stimulus set consisted of 20 samples of joy and sadness, 22 samples of anger and 18 samples of fear, both for authentic and play-acted sets. \n\n\n### PARTICIPANTS \n  \n#### Study 1 \n  \n24 female participants (mean 24 years old; range 20\u201330 years; right-handed; German mother-tongue), without a history of neurological or psychological complications (including the use of psychiatric medication), were selected and contacted using the Cologne Max-Planck Institute (MPI) database for fMRI experiments. Participants were informed about the potential risks of magnetic resonance imaging and screened by a physician. They gave informed consent before participating and were paid afterward. The experimental standards were approved by the local ethics committee and data were handled pseudonymously. \n\n\n#### Study 2 \n  \nSelection criteria were identical to Experiment 1, with 18 female participants selected (20\u201330 years, mean 24 years, right-handed, German mother-tongue). \n\n\n\n### TRIAL AND STIMULUS PRESENTATION \n  \n#### Study 1 \n  \nThe program NBS Presentation (Neurobehavioral Systems, Inc., Albany, CA, USA) controlled the trial structure, timing, and order of each experimental run. Each run (one per participant) included 178 trials, of which 72 were used for an emotion rating task and 72 for an authenticity rating task. In addition, two control tasks were included: 16 word detection trials, in which participants had to count occurrences of the word \u201cund\u201d (\u201cand\u201d), and 18 empty trials with pink-noise playback. For emotion ratings four responses were possible: anger, sadness, happiness, fear (presented in German as: \u201cWut,\u201d \u201cTrauer,\u201d \u201cFreude,\u201d \u201cAngst\u201d), while for authenticity ratings responses were authentic (\u201cecht\u201d) and play-acted (\u201ctheater\u201d; described to participants beforehand as \u201cgespielt,\u201d i.e., play-acted). To minimize eye movement the maximal line-of-sight angle for visual information was kept under 5\u00b0. Trial type and stimulus type pseudo-randomizations were performed using conan (UNIX shell script: MPI for Neurology in Leipzig, Germany) to reduce any systematic effects that could have otherwise occurred with simple randomization. Each participant was shown a button sequence on-screen (800 \u00d7 600 pixel video goggles: NordicNeuroLab, Bergen, Norway) complementary to the response box layout (10 cm \u00d7 15 cm \u00d7 5 cm gray plastic box with a row of four black plastic buttons). For both emotion rating and word detection all buttons were assigned a possible response. For authenticity rating only the two left-most buttons were used. \n\n\n#### Study 2 \n  \nSoftware, hardware, and trial and stimulus randomization were identical to Experiment 1, but only the emotion rating task was applied (144 trials). One third (  n   = 48) were not cued (no authenticity information was provided), one third were cued as authentic, and one third were cued as play-acted. Cueing was congruent half the time and was presented above the response options as authentic or play-acted (\u201cecht\u201d or \u201cspiel\u201d respectively). The remaining 30 trials were used to implement two independent control tasks: 18 empty trials with pink-noise playback and 16 age task trials in which participants had to determine the age of the speaker (20, 30, 40, or 50). \n\n\n\n### EXPERIMENTAL PROCEDURE \n  \n#### Study 1 \n  \nParticipants were fitted with headphones for audio playbacks (NNL: NordicNeuro-Lab, Bergen, Norway) after they were placed in a supine position on the fMRI table. Imaging was performed with a 3T Siemens MAGNETOM TrioTim (Cologne, Germany) system equipped with a standard birdcage head coil. Participants were placed with their four fingers (excluding thumb) positioned on the response buttons of the response box. Form-fitting cushions were utilized to prevent head, arm, and hand movements. Twenty-two axial slices (210 mm field of view; 64 \u00d7 64 pixel matrix; 4 mm thickness; 1 mm spacing; in-plane resolution of 3 mm\u00d7 3 mm) parallel to the bicommissural line (AC\u2013PC) and covering the whole brain were acquired using a single-shot gradient echo planar imaging (EPI) sequence (2000 ms repetition time; 30 ms echo time; 90\u00b0 flip angle; 1.8 kHz acquisition bandwidth) sensitive to BOLD contrast. In addition to functional imaging, 22 anatomical T1-weighted modified driven equilibrium fourier transform (MDEFT) images ( ;  ) were acquired. In a separate session, high-resolution whole-brain images were acquired from each participant to improve the localization of activation foci using a T1-weighted 3D-segmented MDEFT sequence covering the whole brain. Functional data were mapped onto this 3D average using the 2D anatomical images made immediately following the experiment. Including a visual and auditory test prior to the experiment, one experimental run lasted approximately 45 min. \n\n\n#### Study 2 \n  \nThe general procedure was identical to experiment 1. Twenty-four axial slices were acquired using a single-shot gradient EPI sequence sensitive to BOLD contrast. \n\n\n\n### BEHAVIORAL STATISTICS \n  \nIn order to determine whether contour has an effect on participant responses, the responses to both emotion and authenticity tasks from study 1 were examined as to whether labeled recordings differed significantly in contour values (correct and incorrect trials were analyzed together as this had no effect in previous analyses). The generalized linear model was implemented (R Statistical Package v2.15;  ) to determine the best model fit for response rates with the glmer function from the lme4 package using restricted maximum likelihood estimation with binomial error structure and logit link function ( ). The basic model examined the effect contour has on responses with participant included as a random factor [glmer (Response ~ Contour + (1|Subject), family = binomial, REML = FALSE)].   Post hoc   statistics were applied using a likelihood ratio test (LRT) with a Chi-squared distribution (\u03c7 ) to examine the effect on each emotion and were corrected for multiple comparisons. \n\n\n### FUNCTIONAL MRI STATISTICS \n  \nAfter motion correction using Siemens rigid-body registration protocol (M\u00fcnchen, Germany), the functional data were processed using the software package LIPSIA v1.5.0 ( ). This software package is available under the GNU General Public License ( ). To correct for temporal offset between the slices acquired in one image a cubic-spline interpolation was employed. Low-frequency signal changes and baseline drifts were removed using a temporal high-pass filter set for each scanned participant dependent on the pseudo-randomized design (filter frequency range: 1/75\u201385 Hz). Spatial smoothing was performed with a Gaussian filter of 5.65 mm full width at half maximum (FWHM) (sigma = 2.4). To align the functional data slices with a 3D stereotactic coordinate reference system, a rigid linear registration with 6\u00b0 of freedom (three rotational, three translational) was applied. The rotational and translational parameters were acquired on the basis of the MDEFT slices to achieve an optimal match between these slices and the individual 3D reference dataset. The MDEFT volume dataset with 160 slices and 1-mm slice thickness was standardized to the Talairach stereotactic space ( ). The rotational and translational parameters were subsequently transformed by linear scaling to a standard size. The resulting parameters were then used to transform the functional slices using trilinear interpolation, so that the resulting functional slices were aligned with the stereotactic coordinate system, thus generating output data with a spatial resolution of 3 mm\u00d7 3 mm\u00d7 3 mm (27 mm \u00d7 27 mm \u00d7 27 mm). \n\nTwo design matrices were applied. In the first, contour (variation in fundamental frequency; measured as standard deviation) was modeled parametrically to examine its correlation with brain activation. The design matrix contained all authentic and play-acted stimulus trials in each of the first two event types respectively, with an amplitude vector of one. The second and third event types each also contained all authentic and play-acted stimulus trials with an amplitude vector corresponding to the specific stimulus\u2019s contour value. The last event type in the design matrix, null-events, was assigned an amplitude value of one. This analysis was performed for the data from  ; with authenticity and emotion task) and  ; only with emotion task). \n\nIn order to further substantiate the parametric analysis, an additional step was taken. Using a second design, stimuli with extreme values of contour were contrasted directly. To do so, trials were preselected based on their respective recording\u2019s contour value and grouped as high or low contour trials within the design matrix. Since we know authenticity correlates with contour ( ), a simple block selection of upper and lower contour stimuli would lead to selections with unequal numbers of, and unbalanced mean contour values for, authentic and play-acted stimulus categories. Therefore, individual stimuli were excluded from each group to ensure equal numbers of authentic and play-acted stimuli (15 of each) and equivalent average contour values (  Table   ). Exclusions were performed pseudo-randomly, such that stimuli that were not included affected the group-average contour values but did not affect any other parameter. Stimulus emotion was included as a regressor of no interest. High and low contour trial groups were contrasted for emotion task trials in both studies and authenticity task trials in study 1 (trials outside the low and high contour groups were included as a single regressor of no interest). Subsequently, a conjunction of the two contrasts from study 1 was used to examine regions activated in both tasks, while an exclusive disjunction was applied to uncover regions more highly activated in one task but not in the other. \n  \nMean values of high and low stimulus groups by contour (standard deviation of F0). \n    \nStatistical evaluation was based on a least-squares estimation using the general linear model (GLM) for serially auto-correlated observations ( ;  ). Both designs were generated with a delta function, convolved with the hemodynamic response function (gamma function). Each trial in the design matrix was identified by its onset time and stimulus length, while speaker repetition was included to prevent this from influencing the statistical analysis. Brain activations were analyzed time-locked to recording onset and the analyzed epoch was set individually for each trial to the duration of the respective stimulus. The model equation, including the observation data, design matrix, and error term, was convolved with a Gaussian kernel of dispersion 5.65 s FWHM to account for temporal autocorrelation ( ). In the following, contrast images (i.e., beta value estimates of the raw-score differences between specified conditions) were generated for each participant. As all individual functional datasets were aligned to the same stereotactic reference space, the single-subject contrast images were entered into a supplementary second-level analysis on the basis of Bayesian statistics ( ). \n\nBayesian statistics provide an alternative to frequentist significance tests. Instead of testing the estimated probability of detecting activation with the null hypothesis of no activation being true (i.e.,   P  -values), the Bayesian approach directly infers the probability that a contrast between two conditions is greater than 0. When applied to second-level analyses, the probability that a contrast is larger than 0 is calculated based on the parameter estimations for the individual participants on the first level (i.e., the beta-values of the GLM). In the approach by  , posterior probability maps for the effects of interest are calculated on the basis of the resulting least-squares estimates of parameters for the GLM. The output of the Bayesian second-level analysis is a map integrating the reliability of activation differences between categories and the probability that the contrast is larger than 0 (percentage value between 0 and 100). Bayesian statistics consider only voxels for which signal was measured in all participants. A threshold of 99.5% and minimum cluster size of 100 voxels was applied to the probability maps and listed activation maxima. Bayesian inferences are not susceptible to problems of multiple comparisons thanks to direct computation of the probabilities. \n\nFinally, the ROI analysis was performed on the high versus low contour contrast to determine the influence of contour relative to task instruction. ROIs were selected from the high versus low contour contrast from study 2 ( ), which was possible due to the higher power from the number of emotion tasks, to avoid statistical issues with so-called \u201cdouble-dipping\u201d ( ). GLM beta values (measure of BOLD response) within these ROIs were extracted separately for the two tasks in study 1 ( ). ROIs were selected from peak activations in mPFC bilaterally (  x,y,z   of Talairach space: 1,44,22; -2,47,24), and left TPJ (-53,-52,32). Activation was then extracted from these ROIs for the two tasks in the first study. The generalized least-squares model was implemented (R Statistical Package v2.15;  ) to determine the best model fit for recognition rates with the gls function from the nlme package using restricted maximum likelihood estimation and compound symmetry for paired data ( ). The model examined the effects contour and task have on BOLD response (GLM beta values) with participant included as correlation factor: [gls(BOLD ~ Contour * Task, correlation = corCompSymm (form = ~1|Subject), data = D)]. Results are indicated using the interaction effect degrees of freedom,   t  -value,   p  -value, and Spearman\u2019s rank correlation coefficient (rho). \n\n\n\n## RESULTS \n  \n Figures    and     show the mean \u00b1 standard deviation of contour values for each response type for the emotion and authenticity tasks respectively. Examining the behavioral effects of contour indicated that contour values for \u201cauthentic\u201d responses were significantly lower than for \u201cplay-acted\u201d responses [\u03c7 (1) = 88.3,   p   < 0.001;   Figure   ;   Table   ]. In addition, contour values for \u201csad\u201d responses were significantly different from \u201canger\u201d [\u03c7 (1) = 768.0,   p   < 0.001], \u201cfear\u201d [\u03c7 (1) = 1037.9,   p   < 0.001], and \u201cjoy\u201d [\u03c7 (1) = 1089.6,   p   < 0.001], with stimuli labeled as \u201csad\u201d being significantly lower in contour than the other emotions (  Figure   ;   Table   ). \n  \n Mean contour (measured as standard deviation of fundamental frequency) and standard deviation for behavioral responses to rating stimuli as authentic or play-acted  . \n    \n Mean contour (measured as standard deviation of fundamental frequency) and standard deviation for behavioral responses to rating stimuli by emotion category  . \n    \nMean values of high and low stimulus groups by F0 contour (SD). \n    \nThe parametric analysis of brain activation with contour value was performed on the data for both studies. The parametric analysis of the first study was performed both across and split by task type, however, neither of these contrasts indicated any significant activation. Within the second study (which implemented only the emotion task), this analysis did produce significant activation in TTG (-47,-16,6) and inferior frontal sulcus (IFS: -41,-1,39; -38,23,24) (  Figure   ). \n  \n Brain activation correlates of emotion experimental task of study 2 ( )  . Group-averaged (  n   = 18) statistical maps of significantly activated areas for parametric effect of contour (higher contour in blue, lower contour in red). Posterior probability maps with a threshold of 99.5% and 100 voxel minimum size. Activation was mapped onto the best average fit subject 3D anatomical map. Left: anterior coronal section through middle temporal lobe. Right: left view sagittal section through temporal lobe. IFS, inferior frontal sulcus; TTG, transverse temporal gyrus. \n  \nDue to reduced contour effects for the emotion task in study 1, whole-brain contour-induced activations during authenticity and emotion trials could only be compared between studies 1 and 2 (not within study 1). Both a conjunction and an exclusive disjunction were performed on these two contrasts. The conjunction (regions similarly modulated in both tasks) revealed activation in the precentral (PrG) and postcentral gyri (PoG) on the left, the dorsal anterior cingulate cortex bilaterally (dACC) extending into the left pre-supplementary motor area (pre-SMA), the left TTG, the left inferior occipital gyrus (IOG), and the lateral hemispheres of the cerebellum. The disjunction (regions differently modulated between tasks) revealed activation in the dorsomedial prefrontal cortex bilaterally (dmPFC) extending into anterior cingulate cortex (ACC) bilaterally, the left middle frontal cortex (MFG), the left inferior parietal lobule (IPL), the right inferior parietal sulcus (IPS), and left MTG (  Table   ;   Figure   ). \n  \n Conjunction (top) and disjunction (bottom) of brain activation correlates of contour in authenticity task trials of study 1 and emotion task trials of study 2.   Top: regions marked red up-regulated by low contour in both tasks, regions marked blue up-regulated by high contour in both tasks. Bottom: interaction of contour extremes and task type (regions up-regulated by one end of the contour range in one task and by the other end of the contour range in the other task). Shown are group-averaged statistical maps (study 1:   n   = 24; study 2:   n   = 18). Posterior probability maps with a threshold of 99.5% and 100 voxel minimum size. Activation was mapped onto the best average fit subject 3D anatomical map. Top: left view sagittal section. Bottom: left view sagittal section through midline. PoG, postcentral gyrus; dACC, dorsal anterior cingulate cortex; TTG, transverse temporal gyrus; IOG, inferior occipital gyrus; IPS, inferior parietal sulcus; IPL, inferior parietal lobule; MTG, middle temporal gyrus; MFG, middle frontal gyrus. \n    \nCoordinates of conjunction and disjunction of brain activation correlates of contour in authenticity task trials of study 1 and emotion task trials of study 2. \n    \nFinally, the ROI analysis performed on the data from the first study, split by task, using coordinates extracted from the second study, showed a clear interaction effect of task and contour. While high contour up-regulated TTG and STG activation independent of task, bilateral activation in mPFC appeared to increase for low contour during the authenticity task and high contour during the emotion task. Of these tendencies, the activation in right mPFC reached significance, such that the interaction of contour and task was significant [  t  (84) = 3.26,   p   < 0.01, \u03c1 = 0.604;   Figure   ]. \n  \n Mean and 95% confidence interval of BOLD signal measure (GLM beta value) by task type and trial stimulus fundamental frequency contour value.   Measures from three regions of interest selected from study 2 and extracted within study 1. (*  p   < 0.05). \n  \n\n## DISCUSSION \n  \nIndependent of the task, high contour stimuli (which are more likely to be play-acted than authentic) induced BOLD modulation in the left primary auditory cortex or TTG. Within the cortex, initial modulation of activation by auditory stimulation occurs in TTG ( ;  ). Therefore, contour has a strong effect on activation even at a very early stage in perception and can be considered the source of the authenticity effects seen in the primary auditory cortex ( ). Notably, stimuli with high variability of F0 frequencies (i.e., high contour) stimulated a larger portion of the TTG than stimuli with low variability. This is due to the fact that frequencies are mapped tonotopically in TTG ( ;  ), such that segments within the TTG are sensitive to different sound frequencies. The activation of a greater area within the cortex leads to a greater BOLD response. Interestingly, participant behavior was affected by this sensitivity to F0 contour, as seen in the correlation between responses to explicit categorization tasks and contour (  Figure   ). While the range of contour values in these correlations was quite large and their corresponding effects are subtle, \u201cauthentic\u201d and \u201csad\u201d responses were nevertheless associated with lower contour values than \u201cplay-acted\u201d or other emotions, respectively. \n\nWhile activation in TTG was left-lateralized, any conclusions on the role of such lateralization would be speculative. There is much research indicating a right-lateralization for emotion perception in speech ( ;  ), but there is also evidence to the contrary ( ;  ). Clearly, hemispheric differences are an active area of research and several non-hypothesis driven reverse inferences could be valid in this context. More important to this study, fMRI BOLD analyses can exaggerate the influence of laterality differences. While Bayes statistics are not influenced by differences in   p  -values, comparing activation patterns between brain regions would represent a non-statistical comparison of probabilities. Therefore, these effects will not be discussed in detail here. \n\nLow variability of F0 frequencies induced a very different pattern of activation. Task-independent activation (conjunction) by low contour stimuli (which are more likely to be authentic than play-acted) included dorsal ACC, extending into pre-SMA. Activation in ACC was seen in previous work ( ,  ). The novel finding presented here is that this ACC activation was associated specifically with low contour stimuli. ACC activation has been attributed to overall task difficulty ( ). As suggested by  , and further corroborated by  , activation in medial SMA and dorsal ACC is modulated relative to difficulty distinguishing stimuli themselves while the task is simple (response conflict), as opposed to complex tasks and difficult rules related to task completion (decision conflict). The high and low contour stimuli in the current study were more likely to be play-acted and authentic respectively, but the emotion categories were not equally distinct at either extremes of the contour range: the difference between the lowest contour values of authentic and play-acted stimuli was only 1.31 Hz, while the difference between the highest values was 22.96 Hz (data from  ), such that the authentic versus play-acted distinction was much clearer between high contour stimuli. The increased ambiguity in distinguishing authentic and play-acted between low contour stimuli likely induced the increased BOLD response in ACC. \n\nThe disjunction, on the other hand, showed that medial BA 9 (bilaterally extending into anterior ACC) was differentially activated between the tasks. Activation increased for low contour values during the authenticity task, while they did so for high contour values during the emotion task. Activation in mPFC and TPJ was previously seen in study 1 ( ) as part of the ToM network ( ), suggesting that contour is the source of the previously seen authenticity effects in mPFC ( ). In that study we hypothesized that mPFC may generally be activated for rating authenticity as part of the ToM network. The current results more specifically indicate that during explicit rating of authenticity the ambiguous low contour stimuli induced activation in mPFC. This was additionally corroborated via the direct comparison of values from emotion and authenticity tasks using ROIs from study 2 within study 1 (focusing specifically on TPJ and mBA9). Within these previous coordinates, right mPFC activation was significantly different for low contour stimuli. While mPFC was recruited in the case of a ToM-relevant task such as the rating of stimulus authenticity, this activation was up-regulated specifically for ambiguous stimuli that were more difficult to perceive and may have therefore required more resources to distinguish. This differentiation also reemphasizes the importance of contour in perception of authenticity since stimuli with ambiguous contour did not induce activation during the emotion task. \n\nThe remaining sites of the network uncovered by the disjunction were part of the top-down attention control network. For example,   found that the superior frontal gyrus (SFG), parietal, and occipital gyri increased activation during top-down shifting of attention, potentially due to increased working memory load. The novel result shown in the disjunction was that, while this task-related attention occurred toward low contour stimuli during authenticity rating, the emotion task actually recruited more resources for high contour stimuli. While the latter may have been due to the bottom-up stimulation of TTG by high contour stimuli, the perception of play-acting may also have been perceived as a form of pretense, inducing increased activation to ensure that the correct emotion was perceived relative to the context at hand ( ;  ). The involvement of the perception of pretense in the use of acted behavior in similar research should be examined further considering the importance of such stimuli in emotion research. In fact,   found that reading invented versus real stories activated regions including the dACC and TPJ, indicating that this network is particularly important in differentiating between sources of the information. \n\nThe fact that not only phylogenetically older structures, such as the primary cortices, but also higher association cortices (e.g., TPJ) and frontal sites (e.g., PFC) are engaged during decoding of expressed emotions, points to a complex interplay of automatic and cognitively reflected components. The findings presented here concur with theoretical approaches that include the cognitive evaluation of the surrounding event in emotion perception ( ;  ;  ;  ). \n\nThe current results and previous findings ( ,  ) also point to an intriguing functional difference between TPJ and mPFC. TPJ was recruited for explicit rating of authenticity or when a stimulus was labeled as either authentic or play-acted, but this activation did not interact with bottom-up stimulus perception ( ,  ). mPFC, however, was up-regulated by low contour (authentic) stimuli when explicitly rating stimulus authenticity. While confirming the previous hypothesis that mPFC activation by stimulus categories is dependent on task ( ), it is now clear that this interaction is specific to the feature of greatest importance to that task: As stimuli became more ambiguous due to less distinct F0 contour, the mPFC required more resources to rate their authenticity. While the TPJ was activated by both task requirements and stimulus features, no interaction occurred, leaving bottom-up/top-down integration to the mPFC. \n\nFinally, considering the question of how emotions are to be defined, the results presented here support the view that the perception of emotions is a multi-component phenomenon. While it is known that acoustic features indicate emotional content, we have provided evidence that prosodically encoded authenticity can interact with emotional information. The integration of these features represents a novel complex interaction that can be observed both behaviorally ( ) and in BOLD responses related to the implicit and explicit perception of these acoustic features. As the effect can occur independent of the awareness of authenticity ( ), and therefore cannot be easily dissociated from emotion perception itself, we suggest that this process is one of the many integral components of emotion perception. \n\n\n## Conflict of Interest Statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nUnnamed: 0\tUnnamed: 1\tAuthentic (Hz)\tPlay-acted (Hz)\tStatistics\nStudy 1\tLow contour\t7.03 \u00b1 3.14\t8.53 + 3.00\tt = 2.07, p > 0.2\n\tHigh contour\t48.44 \u00b1 13.83\t56.93 + 22.39\tt = 2.04, p > 0.1\nStudy 2\tLow contour\t6.78 \u00b1 3.00\t8.27 + 2.99\tt = 2.06, p > 0.2\n\tHigh contour\t48.89 \u00b1 15.24\t56.36 + 20.75\tt = 2.05, p > 0.1\n### Caption\nMean values of high and low stimulus groups by contour (standard deviation of F0).\n### Footer\n \nMean contour (measured as standard deviation of fundamental frequency) and standard deviation of the selected high and low value recordings for each authenticity category and study. Statistics represent t-tests of the differences between the contour values by authenticity as applied to BOLD contrasts.\n\n\n## ID: T2\n### Label: Table 2\nUnnamed: 0\tUnnamed: 1\tRT (s)\tEmotion\tAuthenticity\nStudy 1\tHigh contour\t3.30 \u00b1 0.59\t0.46 \u00b1 0.25\t0.61 \u00b1 0.29\n\tLow contour\t3.12 \u00b1 0.92\t0.40 \u00b1 0.31\t0.70 \u00b1 0.23\n\tStatistic\tt = 0.91; p > 0.1\tt = 0.93; p > 0.1\tt = -1.18; p > 0.1\nStudy 2\tHigh contour\t3.09 \u00b1 0.60\t0.41 \u00b1 0.24\t\n\tLow contour\t2.93 \u00b1 0.82\t0.47 \u00b1 0.31\t\n\tStatistic\tt = 0.88; p > 0.1\tt = -0.84; p > 0.1\t\n### Caption\nMean values of high and low stimulus groups by F0 contour (SD).\n### Footer\nReaction time (in seconds) with SD and recognition rate (probability of correct recognition) with SD. Statistics represent t-tests of the differences in reaction times and recognition rates between the pre-selected contour groups.\n\n\n## ID: T3\n### Label: Table 3\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tUnnamed: 2_level_0\tTalairach coordinates\tTalairach coordinates\tTalairach coordinates\nArea\tBA\tHemisphere\tx\ty\tz\nConjunction\t\t\t\t\t\nSMA\t6\tL\t-5.0\t6.0\t48.0\ndACC\t32\tL\t-8.0\t21.0\t36.0\n\t32\tR\t1.0\t21.0\t36.0\nPrG\t6\tL\t-29.0\t-9.0\t54.0\nPoG\t3\tL\t-41.0\t-28.0\t51.0\nTTG\t42\tL\t-53.0\t-15.0\t6.0\nIOG\t19\tL\t-47.0\t-78.0\t0.0\n\t37\tL\t-44.0\t-63.0\t-3.0\nCerebellum\tCrus I\tL\t-41.0\t-54.0\t-21.0\nCerebellum\tV\tR\t13.0\t-51.0\t-12.0\nDisjunction\t\t\t\t\t\nmPFC\t10\tL\t-11.0\t47.0\t12.0\n\t9\tR\t1.0\t41.0\t24.0\nACC\t32\tL\t-5.0\t38.0\t21.0\n\t32\tR\t4.0\t41.0\t3.0\nMFG\t8\tL\t-38.0\t24.0\t45.0\nIPL\t40\tL\t-56.0\t-48.0\t42.0\nIPS\t40\tR\t49.0\t-36.0\t42.0\nMTG\t21\tL\t-65.0\t-24.0\t-9.0\n### Caption\nCoordinates of conjunction and disjunction of brain activation correlates of contour in authenticity task trials of study 1 and emotion task trials of study 2.\n### Footer\nConjunction (regions similarly modulated by contour in either task) and disjunction (interaction: regions differentially modulated in either task) of brain activation correlates of contour in authenticity task trials of study 1 and emotion task trials of study 2 (study 1: n = 24; study 2: n = 18). Anatomical specification, Brodmann area (BA) Talairach coordinates of local maxima (>99.5% Bayesian probability). aMCC, anterior middle cingulate; MFG, middle frontal gyrus; SPL, superior parietal lobule; IPL, inferior parietal lobule; FG, fusiform gyrus; IOG, inferior occipital gyrus; sgACC, subgenual anterior cingulate; mPFC, medial prefrontal; SFG, superior frontal gyrus; STG, superior temporal gyrus; TTG, transverse temporal gyrus; pSTS, posterior superior temporal sulcus; TPJ, temporoparietal junction; pSTS, posterior superior temporal sulcus; TPJ, temporoparietal.\n", "metadata": {"pmcid": 3965851, "text_md5": "be25b817022d1bfd01d53a2a4228e609", "field_positions": {"authors": [0, 59], "journal": [60, 78], "publication_year": [80, 84], "title": [95, 190], "keywords": [204, 263], "abstract": [276, 1822], "body": [1831, 41548], "tables": [41561, 44732]}, "batch": 2, "pmid": 24701202, "doi": "10.3389/fnhum.2014.00144", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3965851", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3965851"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3965851\">3965851</a>", "list_title": "PMC3965851  Recognizing the authenticity of emotional expressions: F0 contour matters when you need to know"}
{"text": "Lopez, Richard B. and Chen, Pin-Hao A. and Huckins, Jeremy F. and Hofmann, Wilhelm and Kelley, William M. and Heatherton, Todd F.\nSoc Cogn Affect Neurosci, 2017\n\n# Title\n\nA balance of activity in brain control and reward systems predicts self-regulatory outcomes\n\n# Keywords\n\nself-control\nreward\nfMRI\ndieting\nindividual differences\n\n\n# Abstract\n \nPrevious neuroimaging work has shown that increased reward-related activity following exposure to food cues is predictive of self-control failure. The balance model suggests that self-regulation failures result from an imbalance in reward and executive control mechanisms. However, an open question is whether the relative balance of activity in brain systems associated with executive control (  vs   reward) supports self-regulatory outcomes when people encounter tempting cues in daily life. Sixty-nine chronic dieters, a population known for frequent lapses in self-control, completed a food cue-reactivity task during an fMRI scanning session, followed by a weeklong sampling of daily eating behaviors via ecological momentary assessment. We related participants\u2019 food cue activity in brain systems associated with executive control and reward to real-world eating patterns. Specifically, a balance score representing the amount of activity in brain regions associated with self-regulatory control, relative to automatic reward-related activity, predicted dieters\u2019 control over their eating behavior during the following week. This balance measure may reflect individual self-control capacity and be useful for examining self-regulation success in other domains and populations. \n \n\n# Body\n \nIn most situations, human beings can successfully exert control over thoughts, impulses and behaviors. People often take this self-control capacity for granted, until it fails and they succumb to temptation. Psychologists have proposed dual-process models of self-control that include dissociable impulsive and inhibitory components (e.g.  ). A recent theory suggests that the neural basis of self-control involves a balance between automatic processes that represent rewarding qualities of stimuli and controlled activity in prefrontal cortex that regulates this bottom-up activity ( ). Human neuroimaging studies have reliably mapped reward and control systems, but often separately, via cue-reactivity paradigms in which participants passively view or evaluate their responses to appetitive cues, such as high-caloric foods or drug cues ( ;  ;  ;  ), and inhibitory control tasks in which participants are instructed to inhibit reactions to stimuli that otherwise would elicit automatic responses ( ;  ;  ;  ). An unanswered question is the extent to which both reward and control systems are simultaneously recruited when people encounter tempting cues that threaten self-control ( ), and whether differential engagement of these systems predisposes people to experience self-control success or failure in real world settings. \n\nNeuroimaging studies assessing reactivity to appetitive food cues have reliably observed activation of reward circuitry, particularly ventral striatum and orbitofrontal cortex (OFC) ( ;  ;  ;  ;  ). Furthermore, increased reward-related activity in these regions is predictive of self-control failure outside of the scanner environment, with higher reward activity associated with greater likelihood to indulge in desires to eat on a daily basis ( ) as well as weight gain over a longer time span ( ). Importantly, these effects were observed in individuals not selected for dieting status and for whom occasional indulgences were unlikely to reflect self-regulatory failure. Restrained eaters, on the other hand, try to maintain ongoing regulatory goals with respect to eating, but this group is prone to self-control lapses and failure (e.g.  ;  ). Additionally, paradigms that have experimentally manipulated restriction of food intake, by randomly assigning participants to dieting or non-dieting (control) conditions, have demonstrated that dieting increases cortisol production ( ) and can backfire by leading to increased consumption ( ). \n\nCommon sense suggests that chronic dieters might be especially likely to show heightened reward-related brain activity in response to food cues. Quite paradoxically, however, in several studies restrained eaters show minimal activity in regions associated with reward processing (i.e. ventral striatum and OFC) during passive viewing of food cues in neutral conditions ( ;  ). Indeed, in many circumstances dieters eat considerably less than do non-dieters. After all, by definition they are limiting intake of food. But, dieters are also notorious for self-control failure over eating in many circumstances. Behaviorally, self-regulation can be disrupted by situational contexts that lead to self-regulation failures. Three prominent causes of dietary failure outside of the laboratory are emotional distress, diet violations, and depletion of self-regulatory resources ( ). Laboratory studies have revealed consistent evidence that chronic dieters overeat when placed in these contexts ( ;   for reviews). \n\nImportantly, each of these contexts has been studied using neuroimaging and each is marked by increased food cue-reactivity in the reward system. That is, this pattern obtains when diets are broken via a milkshake preload ( ); when dieters receive a negative mood induction ( ); and following effortful exertion of self-control (i.e. depletion;  ). Thus, studies using neuroimaging have found increased reward activity for situational contexts where dieters are prone to overeating both inside and outside the lab. One speculation is that absent other demands on self-regulatory resources, dieters can effectively inhibit reward-related responses to food cues. When self-regulatory resources are challenged, however, inhibitory control is reduced and reward responsivity reemerges. In support of this possibility,  ) showed that after completing a depleting attention task, dieters experienced a breakdown of functional connectivity between the inferior frontal gyrus (a region in prefrontal cortex reliably associated with inhibitory control) and OFC when viewing appetizing food cues, as well as increased OFC activity. \n\nThe balance between reward and self-regulation capacity generalizes beyond eating behavior and may be important for understanding more basic principles of self-regulation. For instance, a recent experiment by   demonstrated a depletion effect for an inhibitory control task (i.e. go/no-go). In their study, participants whose self-regulatory resources were taxed committed more errors on no go trials\u2014but only for trials where the no-go stimulus had high-reward value ( ). Taken together, these findings suggest that self-regulatory depletion manipulations may interfere with processes related to top-down inhibitory control, resulting in increased reward-related activity. \n\nIn light of these findings from previous behavioral and neuroimaging work, several key aims motivated the present study. First, we set out to test whether the above neural effects following exertion of self-control would correspond with real world eating behaviors, namely dieters\u2019 constant need to engage in self-control in the face of tempting food cues. To this end, we adapted   design (i.e. a depleting inhibitory control task requiring effortful self-control exertion, followed by passive viewing of appetizing food cues) with the logic that this paradigm might temporarily simulate dieters\u2019 experience of chronic self-regulatory challenges in their daily lives. \n\nSecond, we developed a novel approach to analyzing neural cue reactivity and putative regulatory processes. Previous neuroimaging studies have employed paradigms that standardize intentions to regulate by providing all participants with explicit instructions and/or cues to do so. In these paradigms, a regulatory process of interest (e.g. inhibitory control in  , or cognitive reappraisal in  ) is elicited and measured with an explicit condition or contrast. In this study, we recruited individuals who share the long-term goal of restricting food intake to maintain or lose weight, under the assumption that these chronic dieters, without explicit instruction, routinely regulate their responses to food. Given their need to regulate responses to food cues in daily life, we propose that any food-cue-related activity observed in regions canonically associated with regulation (e.g. lateral prefrontal cortex) might reflect ongoing motivation to regulate food intake. \n\nThird, we wanted to replicate previous studies that have adopted a brain-as-predictor approach (see  ), but in a population that is particularly vulnerable to self-regulation failure\u2014restrained eaters. Focusing on this population allowed us to formally test several psychological models of self-control that converge on the same core idea. That is, to best characterize self-control outcomes, both impulsive \u2018and\u2019 inhibitory processes should be taken into account, such that the relative engagement of one process   vs   the other may be maximally predictive of behavior\u2014as opposed to the strength or engagement of either process alone ( ;  ;  ). The balance model recently proposed by   makes similar predictions, positing that self-control arises from an interplay of both control and reward-related processes, corresponding to brain systems associated with regulation and reward, respectively. Specifically, for reward-related regions, we focused on activity in ventral striatum and OFC, regions that reliably index the reward value of stimuli (e.g.  ). For regions that support regulation, we examined activity in regions of the frontoparietal (FP) network, previously defined in large-sample resting state functional connectivity studies and has been associated with flexibly exerting control on a moment-by-moment basis ( ;  ;  ). \n\nTo test the balance model in chronic dieters, we simultaneously examined activity within both sets of brain regions, computing a brain-derived measure that reflects the relative balance of food cue-reactivity in regions associated with reward and self-regulatory control. We hypothesized that dieters may vary in this balance of activity, such that those dieters with a greater relative engagement of regulatory (  vs   reward) processes would demonstrate greater self-control success in everyday life. We also hypothesized that, following an exertion of self-control, this balance measure would have predictive and ecological validity for capturing real world responses to food temptations. As discussed earlier, this is a prototypical experience among dieters because of the ongoing nature of dieting goals (i.e. any time a dieter faces a tempting food cue, he or she likely has previously exerted self-control to resist desires to eat). To ensure ecological validity of the self-control outcomes we measured, we employed a validated ecological momentary assessment (EMA) protocol in which participants were prompted to report their eating behaviors as they occurred throughout a given day ( ;  ). The short measurement windows of EMA make it advantageous over other forms of self-report, which are prone to memory and mis-estimation biases (e.g. see  ;  ). \n\nTo summarize, we tested the balance model of self-control, by first simulating a challenging context for chronic dieters (i.e. food cue exposure after previous exertion of self-control) and then assessing food-cue brain activity across both control and reward systems. From this activity we developed a novel brain-based measure reflecting relative engagement of control (  vs   reward) systems and used it characterize and predict the circumstances under which diets succeed (or fail) in real life. \n\n## Methods \n  \nSeventy-five females (  M   = 19.38, Range = 18\u201323) from the Dartmouth community participated in the study. All participants were chronic dieters (as assessed by the Restrained Eating Scale;  ;  ) and gave informed consent. Participants first underwent a functional magnetic resonance imaging (fMRI) scan, followed by a weeklong period of smartphone EMA of eating behaviors. In the fMRI session, participants first performed a difficult inhibition task that taxes self-control capacity ( ). This was immediately followed by a previously validated incidental cue-reactivity task that consisted of various image types, including appetizing, high-calorie foods ( ;  ). Participants made perceptual (indoor/outdoor) judgments about the images, which ensured that participants remained alert but naive to the purpose of the study. fMRI data were analyzed using the Statistical Parametric Mapping software package (SPM8; Wellcome Department of Cognitive Neurology) and add-on tools for automating and batching (freely available at  ). \n\nFollowing the fMRI scan, participants completed the smartphone EMA portion of the study, in which they reported different aspects of their eating behaviors, several times a day for 1 week. The EMA protocol closely followed that of our previous work ( ;  ). Specifically, all EMA prompts were pre-programmed and scheduled using the SurveySignal survey platform ( ). Participants were prompted (via SMS message) seven times a day at random intervals, across a 14-h time window that overlapped with participants\u2019 waking hours. Participants received, on average one EMA prompt every two hours. Each prompt included a link to a survey that included questions about whether participants experienced a food desire currently or recently (i.e. \u226420\u2009minutes), the strength of the desire on a seven-point Likert scale, and whether they gave in to the reported desire and already ate, or not (i.e. desire enactment). Additionally, whenever participants reported having a current or recent desire, they categorized desired food in one of eight categories: (i) grains, breads, cereals; (ii) dairy products; (iii) meat; (iv) fish; (v) junk food; (vi) vegetables; (vii) fruits; and (viii) sweets (e.g. candy, chocolate). Energy density of food items is a potentially important factor to consider in eating and health domains, given that higher density foods (e.g. highly processed and/or high in carbohydrates) are more likely to cause weight gain ( ). Our EMA protocol did not have any questions about the energy density of the desired food items. However, as a rough proxy we created a dichotomous variable representing whether participants desired junk foods or sweets (  vs   all other food categories), as junk food and sweets tend to have relatively higher caloric content. \n\n### fMRI procedure and analysis \n  \nfMRI data were collected with a 3-Tesla Philips Intera Achieva scanner (Philips Medical Systems) equipped with a SENSEitivity Encoding head coil. Stimuli were presented using SuperLab 4.0 (Cedrus Corporation) and projected to an Epson ELP-7000 LCD screen positioned at the end of the magnet bore. Participants were able to view the screen via a mirror mounted on the head coil. While in the scanner, subjects completed an event-related cue reactivity task in which they viewed a series of images and were instructed to make perceptual judgments as to whether each image depicted an indoor or outdoor scene. All judgments were made with a corresponding button press on a Lumina LU-400 fMRI response pad. The indoor/outdoor task incorporated images of food, people, animals and nature scenes, so participants were na\u00efve to the purpose of the study. The cue reactivity task employed a rapid, event-related design, with all design parameters and trial timing following those from previous studies that administered the task (e.g.  ). \n\nFor each functional (EPI) run, data were corrected for differences in slice-timing and preprocessed to remove sources of artifact and noise. Functional data were realigned within and across runs to correct for head movement and were unwarped to reduce any residual movement-related image distortions. Functional data were normalized into a standard stereotaxic space (3-mm isotropic voxels) based on the SPM8 EPI template that conforms to the ICBM 152 brain template space (Montreal Neurological Institute; MNI) and approximates the Talairach and Tournoux atlas space. Normalized images were then spatially smoothed (6mm full-width-at-half-maximum) using a Gaussian kernel. Six subjects\u2019 data were excluded from further analysis, due to excessive motion-related artifact (defined as more than two instances of movement >2 mm; final   n   = 69 for all subsequent analyses). For each subject, a general linear model that incorporated task conditions (convolved with a canonical hemodynamic response function) and covariates of non-interest (e.g. six motion parameters from realignment correction, a linear trend to account for drifts in scanner signal) were used to compute t-contrast images (weighted parameter estimates) for the Food > Non-Food Control images comparison at each voxel. \n\nGiven our interest in the balance between top-down control and bottom-up reward processes, we conducted an a priori region-of-interest (ROI) analysis by extracting parameter estimates from sets of FP and reward ROIs, respectively. For FP regions, we used coordinates from eight regions previously defined by resting-state functional connectivity studies ( ;  ; see   and  ). Next, for reward-related activity, we focused on regions robustly associated with reward processing of appetitive cues across neuroimaging studies, namely ventral striatum and OFC (e.g. see   for a meta-analysis). Importantly, dieters have shown food cue-reactivity in both areas ( ). We used coordinates centered on peak activation from   study to define ROIs in left and right ventral striatum (MNI coordinates: \u00b19, 3, \u22126) and left OFC (coordinates: \u221230, 33, \u221218). For all ROIs (see  ), we used 6-mm seeds to extract parameter estimates reflecting food cue specific activity (in both FP and reward regions) for each participant. \n  \nLateral (top left and right) and ventral (bottom) views on an inflated brain surface depicting ROIs in FP (yellow) and reward (green) systems. ROI spheres have been enlarged to 10\u2009mm for better visualization. \n  \n  \nCoordinates of a priori FP and reward ROIs used to create regulation-reward balance scores (all FP ROIs were taken from   and  , and reward ROIs came from  ) \n  \n\n\n### Computation of brain-based balance scores and outcome measure \n  \nTo compute brain-based balance scores, we first standardized values within each region, and then took the aggregate mean activity across ROIs in each set. Consequently, each subject contributed one value reflecting mean activity across FP ROIs and one value reflecting mean activity across reward ROIs, with positive values reflecting relative greater or negative values reflecting lesser activity in s.d. units. Importantly, this permitted a simple difference score (control\u2013reward) to be calculated for each subject that reflected relative overall bias towards inhibition (positive values) or impulsivity (negative values). Last, for our behavioral outcome measures, we logged how often subjects gave in to food desires during the 1-week EMA sampling period (i.e. the proportion of times subjects ate after experiencing a current or recent desire for food), as well as how much food they ate when they did give in to desires to eat, measured on a scale from 1 (\u2018a tiny bit\u2019) to 5 (\u2018much more than a regular portion\u2013I\u2019m stuffed\u2019). \n\n\n\n## Results \n  \nParticipants completed an average of 31.36 EMAs (s.d. = 8.59; range = 8\u201344) during the sampling period. Overall reported frequency of food desires was relatively low, but revealed some variation (  M   = 35.3%, s.d. = 15.7%, range = 5.4\u201371%). When desires were reported, participants gave in to their desire and consumed food 49.6% of the time (s.d. = 22.8%, range = 0\u2013100%). We compared desires and enactment for junk food/sweets   vs   all other food categories. Following this dichotomous coding of desire instances, 37 out of 69 (53.6%) reported having desires for junk food or sweets during the sampling period. Among these participants, enactment rate for junk food/sweets (48.9%) and non-junk food/sweets (51.0%) did not significantly differ,   t  (36) = \u22120.301,   P   = 0.765. Additionally, to test for the possibility that those dieters who reported having desires for junk food/sweets might struggle in controlling their desires for foods more generally, we compared enactment rate for all other food types in the 37 participants who reported craving junk food/sweets, to that in the 32 participants who didn\u2019t report craving junk food/sweets. The enactment rates of these two subgroups (45.2 and 48.9%, respectively) did not significantly differ,   t  (67) = \u22120.625,   P   = 0.534. Since no differences were observed in these comparisons, we focused on overall enactment rate as our main outcome measure in all subsequent analyses. \n\nIn terms of brain activity, food-cue reactivity in either the reward or control networks did not predict giving in to food temptations. That is, neither reward system activity nor FP activity was associated with participants\u2019 enactment of their desires to eat. There were also no significant correlations between activity in any individual reward or FP region and desire enactment (all   P  \u2019s > 0.10). However, and in support of our main hypotheses, a linear model regressing enactment on regulation-reward balance scores did demonstrate a robust relationship,   b  \u2009=\u2009\u22120.132,   r  (67) = \u22120.410,   P   = 0.0005 (95% bootstrapped CI of correlation coefficient with 5000 iterations: \u22120.652, \u22120.215). Specifically, those dieters with higher regulation-reward balance scores successfully resisted their desires to eat more frequently (see  ).  To account for any variance in enactment associated with activity in the brain regions we selected, we ran two multiple regression models predicting enactment, in which we included regulation-reward balance scores as the main regressor of interest, and parameter estimates from either the three reward regions (model 1) or eight FP regions (model 2) as regressors of no interest. In these two models, balance scores remained robustly associated with less frequent enactment (both   P  \u2019s < 0.003) with stable regression coefficients (  b  \u2009=\u2009\u22120.131,   b   = \u22120.144). \n  \nScatter plot of regulation-reward balance scores regressed on percentage of enacted food desires. \n  \nAs a further test of our hypothesis that greater engagement of control   vs   reward systems mitigates enactment, the sample was split into two groups based on positive (i.e. higher control) and negative (i.e. higher reward) balance scores. We then inspected the proportion of desire enactment by group. The group with higher relative engagement of reward regions gave in to desires to eat more often (57.3% of the time) than the group with higher engagement of the FP control system (41.6% of the time), \u03c7 (1) = 8.086,   P   = 0.005. Additionally, there was a significant negative association between balance scores and amount of food eaten throughout the week,   r  (67) = \u22120.256,   P   = 0.033 (95% bootstrapped CI of correlation coefficient with 5000 iterations: \u22120.527, \u22120.025), with those dieters with higher relative FP-  vs  -reward engagement reporting eating smaller portions when they did give in to desires to eat. \n\n\n## Discussion \n  \nHere we show that the balance of dieters\u2019 food cue reactivity between control and reward brain systems is predictive of self-control success and failure. Our findings suggest that when faced with tempting food cues, dieters who recruit FP (control) regions more so than reward regions are more successful in curbing their daily desires to eat. Critically, they provide empirical support for theories that predict that self-control is most likely to occur when regulatory processes that restrain downstream behavior are engaged relative to an impulsive process that, unchecked, would otherwise lead to self-control failure ( ;  ). \n\nIn addition to replicating and extending prior research using the brain-as-predictor approach, which correlates brain activity with real world behavioral outcomes (e.g.  ), this study makes several contributions. First, we administered a self-regulatory challenge task to evoke activity in both reward and control systems, and then used these evoked patterns of brain activity to predict dieters\u2019 daily eating behaviors. Although prior work has demonstrated brain\u2013behavior relationships in the eating domain ( ), the current study linked brain activity to self-regulation success or failure in a population that experiences frequent challenges to control their eating. We were able to operationalize participants\u2019 success or failure as or refraining from or giving in to desires to eat, respectively, since we recruited from a population that is characterized by maintaining the ongoing self-regulatory goal of broadly restricting food intake. \n\nAdditionally, in contrast with prior work that has tended to focus separately on either impulsive or control processes and their behavioral correlates, we took a balance model approach ( ) by examining the neural correlates of these processes in tandem, namely the simultaneous, \u2018relative\u2019 engagement of brain systems associated with control and reward. The current findings make a new contribution to this literature by demonstrating that the balance of activity may serve as a better neural marker for behavior than activity in either system alone. Importantly, this relative balance of activity was measured as dieters passively viewed appetitive food cues, as opposed to activity elicited by overt instructions to regulate responses to the cues. \n\nThe linear relationship observed between balance scores and enactment of food desires promotes speculation that even within the dieting population, there may be: (i) varying levels of (dieting) goal activation following exposure to tempting food cues that may be indicative of one\u2019s underlying intention to regulate; (ii) differential ability or ease when exerting control over food desires; or (iii) some combination of both. Future work can test these hypotheses by designing studies in which these constructs (i.e. intention to regulate and ability/ease when regulating) are explicitly measured and wedded to diet adherence or other outcome measures that index self-control success and failure. Future research might also examine whether the variability in dieters\u2019 recruitment of FP versus reward regions reflects differential priming or activation of dieting goals. The images of food presented during the cue reactivity task may have automatically triggered dieting goals, outside awareness ( ;  ;  ), but maybe more so for some dieters in the sample than others. \n\nAnother contribution of this study was using a network based approach to aggregate activity within independently defined reward and control networks, rather than discrete brain regions.   have recently proposed such an approach, arguing that a systems-based approach may be a fruitful avenue to characterize individual differences in self-control capacity\u2014with the FP network a prime candidate as a control system ( ). We explicitly tested this by using a priori FP ROIs based on resting state functional connectivity studies ( ;  ). It is possible, then, to interpret activity in the FP system as indicative of that system\u2019s functional integrity and ability to be recruited across multiple instances of self-control challenges in daily life. This makes sense, given that resting state functional connectivity is thought to reflect statistical patterns of co-activation across regions that develop over time. This approach may inform subsequent neuroimaging work that applies systems-based methods to both resting-state and event-related paradigms to better understand the brain mechanisms underlying an individual\u2019s self-regulatory capacity. \n\nDespite the promise of our analysis approach and the obtained findings, there are several limitations and caveats that need to be acknowledged. First, although the use of EMA in behavioral research is advantageous compared with other survey assessment formats and schedules (e.g. retrospective self-report), EMA responses can be prone to biases or inaccuracies, including in the eating domain ( ). Additionally, the EMA response rate was somewhat variable, so future studies may implement appropriate incentives to maintain relatively high and consistent response rates. Last, the generalizability of our study\u2019s findings is necessarily constrained, as participants were all female. We recruited only females primarily because women are more likely to restrict food intake than men ( ), and also to avoid potential gender confounds ( ). Even so, gender differences\u2014as well as gender\u2013dieting interactions\u2014in the recruitment of regulatory and reward systems should be directly tested in future work. \n\nIn summary, this study demonstrated that a balance between cue-induced reward and control activity, observed in defined brain networks, predicted dieters\u2019 daily eating behaviors. The design and analysis of the study entailed three features that may be useful in future work. Specifically, fMRI paradigms can incorporate self-regulatory challenge tasks, like the depleting inhibitory control task, to determine how post-challenge brain activation patterns relate to behavioral outcomes of interest. Second, by taking a balance approach to analyzing neuroimaging data, investigators can test and compare models of self-regulation that simultaneously examine multiple processes that guide behavior to make self-control success more (or less) likely. Last, researchers can test whether system-level correlates of self-regulation success (e.g. FP recruitment and/or interactions between FP and reward systems) are amenable to self-regulation training. Indeed, this approach may yield novel, brain-based indices that can be incorporated into targeted clinical interventions. This would be especially promising for those whose repeated self-control failures pose serious risks for health, such as compulsive over-eating or addiction. \n\n \n\n# Table(s)\n## ID: nsx004-T1\n### Label: Table 1.\nRegion type\tMNI coordinates\tMNI coordinates\tMNI coordinates\tMNI coordinates\tLabel\nUnnamed: 0_level_1\tX\tY\tZ\tL/R\tUnnamed: 5_level_1\nFP\t46\t28\t31\tR\tDorsolateral prefrontal cortex\nFP\t\u221244\t27\t33\tL\tDorsolateral prefrontal cortex\nFP\t44\t8\t34\tR\tMiddle frontal gyrus\nFP\t\u221242\t7\t36\tL\tMiddle frontal gyrus\nFP\t54\t\u221244\t43\tR\tInferior parietal lobe\nFP\t\u221253\t\u221250\t39\tL\tInferior parietal lobe\nFP\t32\t\u221259\t41\tR\tInferior parietal sulcus\nFP\t\u221232\t\u221258\t46\tL\tInferior parietal sulcus\nReward\t\u221230\t33\t\u221218\tL\tOFC\nReward\t9\t3\t\u22126\tR\tVentral striatum\nReward\t\u22129\t3\t\u22126\tL\tVentral striatum\n### Caption\nCoordinates of a priori FP and reward ROIs used to create regulation-reward balance scores (all FP ROIs were taken from Dosenbach et al., 2007 and Power et al., 2011, and reward ROIs came from Wagner et al., 2013)\n### Footer\nNone\n", "metadata": {"pmcid": 5460048, "text_md5": "f974d6e66717919723a6c403e460f956", "field_positions": {"authors": [0, 129], "journal": [130, 154], "publication_year": [156, 160], "title": [171, 262], "keywords": [276, 332], "abstract": [345, 1633], "body": [1642, 30145], "tables": [30158, 30975]}, "batch": 2, "pmid": 28158874, "doi": "10.1093/scan/nsx004", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5460048", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5460048"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5460048\">5460048</a>", "list_title": "PMC5460048  A balance of activity in brain control and reward systems predicts self-regulatory outcomes"}
{"text": "Song, Inuk and Neal, Joshua and Lee, Tae-Ho\nBrain Sci, 2021\n\n# Title\n\nAge-Related Intrinsic Functional Connectivity Changes of Locus Coeruleus from Childhood to Older Adults\n\n# Keywords\n\nlocus coeruleus\ndistractibility\nneurodevelopment\nfunctional connectivity\n\n\n# Abstract\n \nThe locus coeruleus is critical for selective information processing by modulating the brain\u2019s connectivity configuration. Increasingly, studies have suggested that LC controls sensory inputs at the sensory gating stage. Furthermore, accumulating evidence has shown that young children and older adults are more prone to distraction and filter out irrelevant information less efficiently, possibly due to the unoptimized LC connectivity. However, the LC connectivity pattern across the life span is not fully examined yet, hampering our ability to understand the relationship between LC development and the distractibility. In this study, we examined the intrinsic network connectivity of the LC using a public fMRI dataset with wide-range age samples. Based on LC-seed functional connectivity maps, we examined the age-related variation in the LC connectivity with a quadratic model. The analyses revealed two connectivity patterns explicitly. The sensory-related brain regions showed a positive quadratic age effect (u-shape), and the frontal regions for the cognitive control showed a negative quadratic age effect (inverted u-shape). Our results imply that such age-related distractibility is possibly due to the impaired sensory gating by the LC and the insufficient top-down controls by the frontal regions. We discuss the underlying neural mechanisms and limitations of our study. \n \n\n# Body\n \n## 1. Introduction \n  \nThe locus coeruleus (LC) is a small nucleus located deep in the brainstem and a major source of norepinephrine. The LC releases norepinephrine to almost the entire brain throughout its efferent projections according to both the phasic and tonic firing of LC neurons, thereby the LC is one of the primary brain regions critical for selective information processing by changing the brain\u2019s configurations [ , , , , , , , , , ]. Recent studies consistently have suggested that the LC functionally controls sensory inputs at the early sensory gating stage by changing the brain\u2019s connectivity configurations [ , , ]. For instance, the stimulated LC changes its neural communication with the basolateral nucleus of the amygdala [ ] and thalamus [ , ], which receive the majority of sensory information for the further in-depth cognitive process. Similarly, direct chemogenetic stimulation of LC immediately changes neural connectivity configurations, especially for the intrinsic networks that mediate the bottom-up sensory process, including the primary sensory and salience networks [ ]. That is, the LC plays a role in controlling sensory flows in the brain, suggesting that impaired processing selectivity is possibly due to the failure of communication between the LC and sensory regions that introduces the sensory overflows in the brain. \n\nHuman imaging studies also imply that the LC system changes the bottom-up process at the early sensory-perceptual stage to prioritize important information. For example, the induced phasic LC activity by arousing or stressful stimuli at the early sensory-perceptual level increases the initial selective attention processes [ , , ] and attentional control [ , ]. Finally, such initial LC-induced selectivity at the early sensory stage carries over to the late cognitive processing such as memory encoding [ ], memory consolidation [ , ], and decision making [ ]. Thus, the interrupted LC activity has been often examined in individuals with conditions associated with hyperarousal and attentional vigilance such as attention-deficit hyperactivity disorder (ADHD) [ , , ], and posttraumatic stress disorder (PTSD) [ , , ]. \n\nRecent studies also showed that older adults, who are more prone to distraction, exhibit interrupted LC connectivity [ , , , , , , , ]. For instance, older adults showed the hyper-connectivity of the LC with the primary sensory networks compared to younger adults as well as the hypo-functional coupling with the salience network [ ], suggesting that the impaired connectivity between the sensory regions and LC induces sensory overflows in the brain and thus the salience network fails to guide attention appropriately. As a result, there is an unnecessary depletion of limited neural resources in the brain leading the executive frontal systems to not maintain goal-directed processes due to irrelevant stimuli that should be ignored earlier.  \n\nHowever, children\u2019s developmental trajectories of LC connectivity have not been characterized yet. Healthy young children also show behavioral propensity to react to irrelevant information combined with heightened impulsivity [ , , ]. This distractibility in children is possibly due to their less-developed LC function during their early developmental stage, such that structural studies have demonstrated that structural integrity of the LC increases with age gradually and then declines after the peak (i.e., inverted U-shaped curvilinear trend) [ , , ]. Furthermore, studies suggest that brain development occurs first in the primary sensory bottom-up regions from early childhood with a progressively maturing top-down frontal system [ , ]. Thus, the unbalanced brain development in childhood between not-fully-developed LC and matured sensory network regions possibly leads children to fail at moderating sensory overflows in the brain. \n\nConsidering accumulating evidence indicating that the LC plays an essential role in the brain\u2019s processing selectivity, the overarching objectives of the current study are to provide a full description of LC connectivity pattern across the lifespan from early childhood to older adulthood. Given the brain development findings [ , , ] and heightened distractibility in early childhood and older adults [ , , , , ], we hypothesized that children and older adults, compared to younger adults and middle adults, show increased functional connectivity of the LC with the primary sensory regions (i.e., quadratic or u-shape curve), indicating that those two age groups have unnecessarily higher sensory sensitivity intrinsically even without task-induced activity (i.e., resting-state fMRI). We hypothesized the quadratic age effects because the development of structural integrity in the LC follows a curvilinear trend [ ] and behavioral performances also follow the inverted U-shape in general [ ]. To this end, we used cross-sectional samples (age-ranged between 8 and 83 years) and examined intrinsic functional connectivity of the LC associated with age changes based on the resting-state fMRI data. We especially examined the intrinsic network connectivity of the LC based on the resting-state fMRI signal as it reflects general intrinsic neural architecture of brain development at the time of the brain scan, rather than a moment-by-moment task-specific neural response [ , , , , ]. \n\n\n## 2. Materials and Methods \n  \n### 2.1. Data Characteristics \n  \nThe present study was carried out using resting-state fMRI data from the enhanced Nathan Kline Institute (NKI)-Rockland project [ ]. The dataset was initially downloaded through the Mind Research Network\u2019s collaborative informatics and neuroimaging suite (COINS) [ ]. We only included individuals with full-coverage of both T1 and EPI, and without severe motions (framewise displacement,   FD   > 0.5 mm), which resulted in 595 samples (  M   = 39.47 years,   SD   = 20.51, range = 8\u201383, 63.36% females; see  ). In this research, considering the previous studies [ , , , ], we referred to age groups approximately as follows: early childhood (<12), adolescents (12\u201320), younger adults (20\u201340), middle adults (40\u201360), and older adults (>60). All individual data were collected in the same scanning protocol with a 32-channel head-coil for the high-resolution structural image (T1-MPRAGE; TR = 1950 ms; TE = 2.52 ms; FA = 9\u00b0; 1-mm isotropic voxel; FOV = 256 mm) and EPI image (364 volumes; 2-mm isotropic voxel, 64 slices; TR = 1400 ms; TE = 30 ms; FA = 65\u00b0; matrix size = 112 \u00d7 112; FOV = 224 mm). \n\n\n### 2.2. Preprocessing \n  \nPreprocessing was performed using the FMRIB Software Library (FSL) combined with ICA-AROMA [ ] and ANTs [ ], including skull stripping and tissue mask segmentation (CSF/WM/GM) after bias-field correction for structural images, and first 10-volumes cut, motion correction, slice-timing correction, intensity normalization, regressing out CSF/WM with individually segmented masks, ICA-denoising (corrected mean FD = 0.02 mm, range = 0.01\u20130.14 mm;  B) and registration to standard Montreal Neurological Institute (MNI) 2-mm brain template for functional images. To avoid possible signal mixture of LC region with neighboring regions such as periaqueductal gray or ventral tegmental area, we skipped the signal smoothing step.  \n\n\n### 2.3. Whole-Brain Multiple Regression Analysis for Age-Related Changes in LC Connectivity \n  \nWe first extracted the mean time-series of LC activity from the preprocessed image on each individual\u2019s non-smoothed native space using a standard structural LC mask ( A) [ ]. Using this LC time course, a multiple regression analysis was then performed to estimate individual level LC-seed functional connectivity maps (z-transformed). Finally, changes of LC connectivity with age were estimated at the whole-brain level using a multiple regression model. Consistent with our main hypothesis, we examined the age-related variation in the LC connectivity with a quadratic model (i.e.,   age   and   age  ):  \n\nIn the model, we included   gender   in the design matrix as nuisance regressors to attenuate gender effects. The group-level whole-brain connectivity model was tested using non-parametric permutation-based inference (FSL\u2019s randomise tool with 5000 permutations) [ ] with cluster threshold at   Z   = 3.1 (  p   = 0.001) and an   FWE-corrected p   at 0.05. \n\n\n\n## 3. Results \n  \nWhole-brain multiple regression analysis on the LC connectivity revealed significant regions that have quadratic relationships with age. As expected, a significant positive quadratic relationship of age was found for connectivity between the LC and several other regions that are mainly associated with the sensory process (i.e., visual, somatosensory, auditory;  C\u2013E). For example, visual processing regions along the ventral occipitotemporal and dorsal visual pathways including the occipital and temporal fusiform gyrus, parahippocampal gyrus, and precuneus [ ], decrease functional connectivity with the LC gradually from early childhood years to a low around 40\u201345 years old, and then increase according to age ( C). The parietal operculum extended to the central region and the cerebellum also showed the same u-shape curve of age effects on the LC connectivity ( D). These regions are known as the secondary somatosensory cortex involved in tactile and pain sensations [ ]. Finally, we found that regions in the primary auditory network including Heschl\u2019s gyrus extended to the planum temporale [ ] showed the same quadratic age relationship on the LC connectivity ( E). To sum, these results indicated that during their respective development stages, children and older adults have increased sensory interaction with the LC in the brain. \n\nImportantly, we also found that there was a significant age-related negative quadratic effect on the LC connectivity for the frontal regions ( F). The frontal pole extended to the frontal medial cortex, known to be involved in action monitoring and cognitive control (e.g., action selection) [ ], showed lower LC connectivity during the early childhood and older adulthood years than younger and middle adulthood years (i.e., inverted U-shaped curve). In other words, the LC has stronger connectivity with the frontal regions during younger and middle adulthood years compared to both developing children and older adults. All significant regions of LC connectivity associated with ages are displayed in   and  . The group-mean of LC connectivity across ages is in  . \n\n\n## 4. Discussion \n  \nThe goal of the current study was to provide a full description of age-related changes in the intrinsic LC connectivity by adopting cross-sectional fMRI data from early childhood to older adulthood. Specifically, given the findings that children and older adults are prone to distraction [ , , , , , , , , , , , , ], we hypothesized that the LC, a critical region for selective information processing in the brain, showed distinct connectivity patterns with other regions in early childhood and older adulthood compared to younger and middle adults who show more stable attentional ability. As a result, we found that the LC\u2019s connectivity with sensory regions showed a U-shaped curve pattern across ages, indicating that the sensory regions exhibit highly increased intrinsic connectivity with the LC in both early childhood and late older adulthood. The current findings suggest that such age-related distractibility is possibly due to the insufficient sensory gating process by the LC. Most importantly, the current analyses also revealed that the LC connectivity with the frontal regions showed an inverted U-shaped curve pattern. That is, while the sensory network regions are connected to the LC excessively, the frontal network regions have decreased connectivity with the LC, implying that the frontal control regions cannot handle the sensory overflows appropriately. These results are similar to the previous finding in that the LC showed curvilinear connectivity patterns with other cortical regions as a function of age [ ]. However, the previous study\u2019s curvilinear patterns were cubic mostly, and most of them appeared in the frontal lobe rather than throughout the brain. In addition, our results showed two distinctive connectivity change patterns and covered a wider range of ages including early childhood. This is the first full description of how the LC configuration changes from early childhood to older adulthood, informing the LC model of distractibility in both children and older adults. \n\nThe current findings implied that the increased distractibility at both early and late developmental stages is due to not only the LC-related excessive sensory overflows but also the lower LC connectivity in the frontal regions. However, although the observed patterns of LC connectivity for sensory and frontal regions are the same for both children and older adult groups, the underlying neural mechanisms for the attentional deficits regarding the LC connectivity may not be identical given structural differences in the developmental trajectory. At the early developmental stage, the primary brain structures including sensory cortex and subcortical bottom-up network regions mature first while the higher-cognitive prefrontal regions are still in the process of developing [ , ], whereas the LC does not yet fully function [ , , , ]. Thus, it is possible that the LC fails to appropriately prioritize sensory inputs inflow from the fully developed sensory networks, leading to sensory overflows in the children\u2019s brain. That is, the immature LC which cannot control sensory inputs appropriately, and the overflow leads to the unnecessarily increased functional connectivity between LC and sensory regions. In addition, the LC fails to initiate the frontal control region for the flux of sensory inputs in the children\u2019s brain, leading to the decreased functional connectivity. In contrast, given the finding of prominent age-related decline in brain volume as well as functional response of the prefrontal areas compared to other regions [ , ], the increased distractibility in the older adults is more derived from the decreased frontal functionality in controlling sensory inputs. Although the sensory networks also showed cortical thinning with the frontal cortex in older adults [ ], evidence indicates decreased sensory sensitivity in the brain at the early sensory gating stage. For instance, older adults have less activations in the visual and auditory cortex under the passive stimuli presentation [ ] suggesting that older adults have less sensory-perceptual sensitivity in terms of change detection. Therefore, the LC can still handle the reduced primary sensory processing even when the LC is functionally degraded, but the prominently decreased frontal control regions are overwhelmed by even less sensory inputs. It may cause the increased functional connectivity between the LC and the sensory and the decreased connectivity between the LC and the frontal control region. \n\nIn the current study, we mainly examined the LC-centered neural connectivity across age which may possibly serve as the underlying neural mechanism for the attentional distractibility often observed at both early and late developmental stages. However, the suggested LC circuit mechanism sheds light on understanding other late cognitive process and attention-related mental disorders, as the current result showed the intrinsic connectivity pattern of the LC as a function of age, and it can be used as a framework to interpret the LC-involved neural activities. For instance, the attentional process involved in memory encoding. Some studies revealed that the LC is associated with memory encoding [ , ] and older adults with reduced LC structure showed poorer memory encoding [ ]. With regard to these studies, our results imply that the intrinsic LC-parahippocampal gyrus connection is a pivotal neural circuit of memory encoding in aging. As another example, ADHD is regarded as a mental illness characterized by hyperarousal and attentional vigilance [ ]. As described above, it is known that the LC is associated with ADHD. Our results may bring insight into understanding and/or predicting the neural underpinnings of ADHD developmental trajectories given that there have not been many studies involving adults with ADHD [ ]. \n\nHowever, there are some limitations in the current study. We examined intrinsic functional connectivity of the LC using the non-task based intrinsic neural network (i.e., resting-state fMRI) based on the previous behavioral observations of the increased attentional distractibility in the early childhood and older adulthood. Thus, our observation might be suboptimal to link actual attentional ability and LC-associated neural configurations compared to task-based assessments in the laboratory with various attentional tasks, which measure attentional selectivity and control more directly. We conjecture that additional attention-related brain regions and/or networks, such as dorsolateral prefrontal cortex, anterior cingulate cortex [ , ], and frontoparietal network [ , ], can be more involved in cognitive processing and the interactions between the additional regions and the LC can be estimated. Future research is needed to employ task-based assessments to link the attentional ability and LC connectivity changes across ages.  \n\nMoreover, it is important to note that the LC is an exceptionally small structure in the brainstem, and thus it is difficult to locate its location and signal in an individual brain. Although we used the standard LC structure mask and extracted LC time-series (i.e., LC\u2019s neural activity) from non-smoothed EPI image on the native space [ ] combined with the ICA-denoising [ , , ] to increase LC signal fidelity in the connectivity estimation, there are several ways to increase LC signal reliability. First, an additional T1-FSE scan (i.e., structural MRI scanning for norepinephrine neuron) can be used. With a 2\u20133 min duration in a scan, it allows to locate the individual neuromelanin structure such as substantia nigra, ventral tegmental area, and the LC on the native space [ , ]. Recent studies also suggested that T1 structural MRI with magnetization transfer (MT-weighted MRI) can distinguish the LC from its surroundings [ , ]. Unfortunately, the current study is based on public data and thus we could not utilize additional LC structure images given the pre-determined imaging protocols and collections. Secondly, extracting a seed signal without smoothing on the native space can minimize the mixture of signals between nearby regions [ ]. In our analysis, we used the non-smoothed LC time-series as a seed region neural activity. Thirdly, recent studies suggested a comprehensive mask [ ] and a high-confidence meta mask of the LC by aggregating multiple LC masks [ ]. For example, Dahl and colleagues yielded the high confidence mask by aggregating 6 LC masks [ , , , ] and showed that the meta mask captured LC-related hyperintensity accurately. Thus, it would also be beneficial to use the comprehensive or meta mask in the future study. Lastly, the LC is often confounded by physio artifacts such as cardiac pulsation and thus it is helpful to run additional physiological denoising [ ]. Although the ICA-denoising is a promising approach to mitigate physiological influence at the global level, the individual-based physiological denoising process using respiration and cardiac pulse signal can be more focal and direct to the brainstem signal fluctuation correction [ ]. In this instance we could not use individual specific LC masks or physiological noise correction. Therefore, in future work, it would be beneficial to utilize the LC structural scan and physiological data collection. \n\n\n## 5. Conclusions \n  \nWe analyzed the age-related LC connectivity changes with a quadratic model. A positive quadratic relationship of age was found for connectivity between the LC and sensory regions. A negative quadratic relationship was found between LC and frontal regions. Our results suggest that the increased distractibility at both early and late developmental stages is due to not only the LC-related excessive sensory overflow but also the lower LC connectivity with the frontal regions. It is noteworthy that the LC showed two distinctive connectivity change patterns as a function of age. Furthermore, we revealed the children\u2019s LC connectivity configuration that has not been characterized yet. Our findings are the first full description of how the LC connectivity configuration changes across age. \n\n \n\n# Table(s)\n## ID: brainsci-11-01485-t001\n### Label: Table 1\nUnnamed: 0_level_0\tt\tH\tBA\tMNI\tMNI\tMNI\tNote\nUnnamed: 0_level_1\tt\tH\tBA\tx\ty\tz\tNote\nPositive quadratic age effect\t\t\t\t\t\t\t\nParahippocampal gyrus\t4.79\tR\t36\t30\t\u221222\t\u221216\tVisual\nPrecuneus\t4.71\tR\t7\t8\t\u221248\t52\tVisual\nLateral occipital gyrus\t4.37\tR\t19\t46\t\u221266\t18\tVisual\nFusiform gyrus, temporal occipital\t4.52\tR\t37\t40\t\u221248\t\u221222\tVisual\nFusiform gyrus, occipital\t4.16\tL\t19\t\u221228\t\u221278\t\u221212\tVisual\n\t4.07\tR\t37\t34\t\u221270\t\u221216\tVisual\nCerebellum\t4.58\tR\t-\t4\t\u221256\t\u221218\tSomatosensory\n\t4.17\tL\t-\t\u22124\t\u221248\t\u221216\tSomatosensory\nOpercular cortex, central\t4.25\tR\t6\t54\t\u22122\t6\tSomatosensory\nOperculum, parietal\t3.81\tL\t13\t\u221246\t\u221234\t20\tSomatosensory\n\t3.27\tR\t13\t42\t\u221226\t18\tSomatosensory\nHeschl\u2019s Gyrus\t4.54\tR\t41\t38\t\u221224\t12\tAuditory\nPlanum temporale\t3.33\tL\t41\t\u221242\t\u221234\t12\tAuditory\nNegative quadratic age effect\t\t\t\t\t\t\t\nFrontal pole\t3.897\tL\t10\t\u221228\t52\t2\tFrontal\nFrontal medial cortex\t3.16\tL\t11\t\u22124\t40\t\u221218\tFrontal\n### Caption\nSignificant brain regions of quadric age effects (cluster threshold at Z = 3.1 and corrected p-value at 0.05 after 5000 permutation) on the LC seed-based whole-brain connectivity analysis. t = t-value; H = hemisphere; BA = Broadman area; Region labeling is based on Harvard\u2013Oxford atlas.\n### Footer\nNone\n", "metadata": {"pmcid": 8615904, "text_md5": "470c74e3b70b66f266b053b33e500ad8", "field_positions": {"authors": [0, 43], "journal": [44, 53], "publication_year": [55, 59], "title": [70, 173], "keywords": [187, 260], "abstract": [273, 1665], "body": [1674, 22306], "tables": [22319, 23528]}, "batch": 2, "pmid": 34827484, "doi": "10.3390/brainsci11111485", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8615904", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=8615904"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8615904\">8615904</a>", "list_title": "PMC8615904  Age-Related Intrinsic Functional Connectivity Changes of Locus Coeruleus from Childhood to Older Adults"}
{"text": "New, Anneliese B. and Robin, Donald A. and Parkinson, Amy L. and Duffy, Joseph R. and McNeil, Malcom R. and Piguet, Olivier and Hornberger, Michael and Price, Cathy J. and Eickhoff, Simon B. and Ballard, Kirrie J.\nNeuroimage Clin, 2015\n\n# Title\n\nAltered resting-state network connectivity in stroke patients with and without apraxia of speech\n\n# Keywords\n\nApraxia of speech\nNetwork connectivity\nResting-state fMRI\nStroke\n\n\n# Abstract\n \nMotor speech disorders, including apraxia of speech (AOS), account for over 50% of the communication disorders following stroke. Given its prevalence and impact, and the need to understand its neural mechanisms, we used resting state functional MRI to examine functional connectivity within a network of regions previously hypothesized as being associated with AOS (bilateral anterior insula (aINS), inferior frontal gyrus (IFG), and ventral premotor cortex (PM)) in a group of 32 left hemisphere stroke patients and 18 healthy, age-matched controls. Two expert clinicians rated severity of AOS, dysarthria and nonverbal oral apraxia of the patients. Fifteen individuals were categorized as AOS and 17 were AOS-absent. Comparison of connectivity in patients with and without AOS demonstrated that AOS patients had reduced connectivity between bilateral PM, and this reduction correlated with the severity of AOS impairment. In addition, AOS patients had negative connectivity between the left PM and right aINS and this effect decreased with increasing severity of non-verbal oral apraxia. These results highlight left PM involvement in AOS, begin to differentiate its neural mechanisms from those of other motor impairments following stroke, and help inform us of the neural mechanisms driving differences in speech motor planning and programming impairment following stroke. \n   Highlights  \n  \nResting state fMRI connectivity of a speech network in apraxia of speech (AOS) \n  \nAOS patients had reduced bilateral premotor (PM) connectivity relative to severity. \n  \nAOS patients also had reduced left PM\u2013right anterior insula connectivity. \n  \nLeft PM may drive disordered speech motor planning and programming post-stroke. \n  \n \n\n# Body\n \n## Introduction \n  \nApraxia of speech (AOS), first delineated by Darley, Aronson, and Brown (e.g. 1975) as a speech disorder is associated with inefficiencies in the translation of speech sounds (phonemes) into the kinematic parameters associated with speech production ( ). While the diagnosis is made in the absence of fundamental (e.g. weakness or slowness) neuromuscular, cognitive, or linguistic impairments, it rarely occurs as an isolated entity ( ). Apraxia of speech is characterized by changes in speech rate (prolongation of speech sounds/segments and between sound or segment gaps), distorted sounds, consistency in error type, and abnormal prosody (de-stressing of typically stressed syllables and sounds). \n\nDespite its prevalence and deleterious impact on communication ( ), there has been very little functional imaging work in the area. Hence the neural basis of the disorder remains elusive. To date there are few brain imaging studies on AOS, and most reports are case studies ( ). The absence of imaging data limits our understanding of the exact nature and neurobiological mechanisms of AOS. Thus, there is a critical need for further functional imaging studies to identify neural mechanisms of action. Such information may increase diagnostic specificity and lead to mechanistically based treatments, not unlike the aphasia literature (e.g.  ). \n\nIdentification of a single brain region or site of lesion for AOS is a challenge and postulated regions are still debated. Early post-mortem studies of AOS first identified Broca's area (BA44) as a region associated with speech articulation difficulties (e.g.  ;  ). Recently,   provided support for the role of BA44 in the disorder by using the volume of infarct as the key variable. Early lesion overlap studies identified the left anterior insula (aINS) as being associated with AOS ( ). However, in Dronker's study over half of the patients diagnosed with AOS also presented with Broca's aphasia and 40% had dysarthria. More recently, behavioral measures of speech have been included in lesion overlap studies ( ) to examine how the extent of the lesioned region varies with performance. Ogar etal. identified the superior precentral gyrus of the insula as a region where all patients with AOS had lesions. With the introduction of lesion overlap and voxel-based lesion symptom mapping (VBLSM) methods, more precise lesion mapping is now possible. Other studies have argued against a relationship between AOS and the left insula.   performed diffusion and perfusion weighted imaging and found no relationship between AOS and diffusion or perfusion in the left insula in acute patients. Recently,   identified the left premotor area (PM) and motor cortex as the most commonly affected anatomy in patients with pure AOS caused by stroke, AOS with aphasia, and neurodegenerative AOS. It is therefore unclear whether the anterior insula, BA44 or other regions are the primary regions responsible for AOS. \n\nAs noted above, understanding the pathophysiology of AOS can only be accomplished by studying a network of regions and their change following stroke. Hence, it is likely that the pathogenesis of AOS is associated with changes in a network of the debated regions related to AOS, rather than a single region. Therefore, this study sought to delineate functional network anomalies among the bilateral inferior frontal gyrus (IFG; BA44), PM, and aINS in AOS. \n\nThere are various methods for studying network connectivity with fMRI data ( ). To study functional network connectivity in AOS, we used resting state fMRI, an efficient approach to studying brain function in health and disease. Examining functional network connections at rest allows for analysis of relations of brain regions   independent of task performance and compliance,   and thus provides information on more permanent temporal coherence between brain regions ( ). In turn, these stable network interactions are easily applied to clinical settings. \n\nThe use of functional imaging measures to understand AOS is very limited, and although debates exist as to the region(s)of damage associated with AOS, few data are available to test any neurobiological model of the disorder. There are currently no studies examining resting state functional connectivity (RSFC) following stroke in patients with AOS, though several studies have examined the effect of disrupted RSFC networks on limb motor impairment following stroke ( ;  ;  ;  ). Thus, we chose to analyze connectivity of resting state data in an a priori network because it allows for the examination of specific regions rather than a whole brain network, such as the default mode network (DMN; cf.  ). \n\nBecause AOS is considered a disorder of \u201cmotor planning and programming\u201d ( ), it is important to consider current models of speech production. Directions into Velocities of Articulators (DIVA;  ) is a neurocomputational model devoted to identifying the neural regions and networks involved in healthy speech, accounting for the interactions among motor, somatosensory and auditory cortical areas. The premotor regions are commonly associated with the planning and programming of speech (see ( )). Models of motor programing in AOS also suggest a deficit in the preprogramming (INT) stage of   model of speech motor programming ( ). The INT stage of the model is designated for the organization of the structure of individual units of movement and reading them into a short-term memory store, or motor buffer ( ). During the second process in the model the motor programs are sequenced (SEQ) into the correct serial order for output. Compared to AOS-absent control subjects, patients with AOS have a longer INT time with normal SEQ and initiation times ( ). Based on the DIVA model ( ), we can speculate that, in AOS, the INT process is implemented in the PM regions, and thus hypothesize that there would be reduced network connectivity in this seed in patients relative to controls and in patients diagnosed with AOS relative to those with no clinical signs of AOS. Differences between patients with AOS and those without AOS might also be reflected in a correlation analysis of connectivity with diagnostic ratings. \n\n\n## Materials and methods \n  \n### Participants \n  \nThirty-two, right-handed, chronic left-hemisphere stroke patients (27 males, 5 females; age\u00a0=\u00a062\u00a0\u00b1\u00a010\u00a0years; median months post-stroke onset (median MPO)\u00a0=\u00a027; range\u00a0=\u00a01\u2013156\u00a0months; see   for clinical and demographic details) and 18 healthy volunteers (8 males, 10 females; age\u00a0=\u00a063\u00a0\u00b1\u00a09\u00a0years) without any record of neurological or psychiatric disorders were included in the analyses of resting state functional connectivity. Stroke patients were recruited from a larger sample of patients consecutively referred from local speech language pathologists and national and local support networks and were eligible if they had difficulty with speech or language. Healthy controls were recruited through advertising in the Neuroscience Research, Australia registry. Volunteers were tested in the order that they responded to the advertisement, regardless of gender. All participants were eligible if they were between the ages of 18 and 75; right handed, per participant report; native English speakers; had no contraindications for undergoing an MRI [materials that may distort signal, such as pacemaker, or other implant; claustrophobia (1 patient and 1 control)]; had no history of uncorrected hearing, vision, or other sensory impairment; cognitive impairment; premorbid speech, language, or reading impairment; or substance abuse. All subjects gave informed written consent to participate in the study. All procedures were approved by the human ethics committees of the Sydney Southwest Area Health Service and the University of Sydney. \n\n\n### AOS diagnosis and speech measures \n  \nAll patients underwent a battery of speech and language tests to define their communication impairment(s), including: (1)a case history; (2)the Spontaneous Speech, Auditory Verbal Comprehension, Repetition, and Naming and Word Finding subtests from the Western Aphasia Battery\u2014 Revised ( ) to determine aphasia severity andtype; (3)Raven's Progressive Colored Matrices ( ) asscreen for nonverbal cognitive abilities; (4)the Motor Speech Examination ( ), the Apraxia Battery for Adults\u2014 2 ( ) and connected speech samples generated from the Story Retell Procedure ( ) to generate speech samples for expert judgment of presence and severity of AOS, nonverbal apraxia and dysarthria; (5)the Assessment of Intelligibility of Dysarthric Speech ( ); and (6)the Auditory Discrimination of Minimal Pairs subtest of the Psycholinguistic Assessments of Language Processing in Aphasia\u2014 2 ( ) to assess auditory perceptual impairment underlying any speech impairment. \n\nFrom the assessment battery, a 15\u201320\u00a0minute video was generated for each patient, capturing their responses to the speech and oral-nonspeech tasks in the Motor Speech Examination, the Apraxia Battery for Adults\u2014 2, and the Story Retell Procedure. Two expert clinicians, blinded to patients' speech and language test scores, independently viewed each video and judged presence and severity of AOS, dysarthria, nonverbal oral apraxia, and phonologically-based sound errors (i.e.,paraphasias) by selecting from dropdown menus on a web-based survey. Severity was rated on a 7 point Likert-type scale (1\u00a0=\u00a0normal, 2\u00a0=\u00a0minimal, 3\u00a0=\u00a0mild, 4\u00a0=\u00a0mild-moderate, 5\u00a0=\u00a0moderate, 6\u00a0=\u00a0moderate\u2013severe, 7\u00a0=\u00a0severe). Patients were rated in the order they entered the study. For disagreements on the presence/absence of greater than one point on the severity scale a third expert judged the samples and the majority rating was used. All raters had more than 25\u00a0years of clinical experience with AOS. The diagnostic criteria for AOS were articulatory distortions, slow speech rate, prolonged inter-word intervals, syllable segregation, and equal stress across words and syllables ( ). \n\nJD rated all cases and MM, DR, or KB served as second or third rater for 28 speech samples. Agreement for the presence/absence of AOS was 24/28 (86%) and agreement on the severity rating scale for AOS (within 1 point) was also 24/28 (86%). Agreement for the presence/absence of dysarthria was 21/28 (75%; in four of these cases, the disagreement was between 1\u00a0=\u00a0normal and 2\u00a0=\u00a0minimal) and severity rating within one point was 26/28 (93%). Agreement between raters on nonverbal oral apraxia presence was 24/28 (86%) and severity rating within one point was 23/28 (82%). Severity ratings for AOS and those for NVOA were moderately correlated (  r  \u00a0=\u00a0.718). A third rater resolved disagreements over presence/absence. Average severity over the two most closely agreeing raters was entered in analyses, with the exception of severity of phonological paraphasias due to low rater agreement. Due to most disagreements being between ratings of \u201c1\u201d (normal) and \u201c2\u201d (minimal), we conservatively assigned patients with scores of 2.5 or higher on the severity rating scale to the AOS group for connectivity analyses. Fifteen individuals were identified as having AOS (15 males; age\u00a0=\u00a061\u00a0\u00b1\u00a012\u00a0years; lesion volume 102.6\u00a0\u00b1\u00a050.8\u00a0cm ; median MPO\u00a0=\u00a027; range\u00a0=\u00a01\u2013156\u00a0months) and 17 were without AOS (12 males and 5 females; ages 64\u00a0\u00b1\u00a09\u00a0years; lesion volume 89.2\u00a0\u00b1\u00a089.5\u00a0cm ; median MPO\u00a0=\u00a026; range\u00a0=\u00a03\u2013121\u00a0months). \n\n\n### MRI data acquisition \n  \nAll structural and functional fMRI data were acquired on a Philips 3T TX MRI scanner. Ahigh-resolution 1\u00a0mm T1-weighted structural image was collected. Two hundred sixteen resting state EPI images were acquired using blood-oxygen-level-dependent (BOLD) contrast [gradient-echo EPI pulse sequence, TR\u00a0=\u00a02.2\u00a0s, TE\u00a0=\u00a030\u00a0ms, flip angle\u00a0=\u00a090\u00b0, in-plane resolution\u00a0=\u00a03.1\u00a0\u00d7\u00a03.1\u00a0mm , 36 axial slices (3.1\u00a0mm thickness) covering the entire brain]. Immediately before the session, participants were asked to lie still and stay awake with their eyes open. \n\n\n### Data analysis \n  \n#### Structural image analysis and lesion classification \n  \nSPM8 software (Wellcome Trust Centre for Neuroimaging;  ) was used to spatially normalize the structural T1 scan to standard MNI space using the \u201cunified segmentation\u201d algorithm ( ). An additional step was added to optimize the solution for the stroke patients. This step included an extra empirically derived tissue class (\u201clesion\u201d) being added to the segmentation priors to allow the lesion to be represented in a tissue class other than gray/white/CSF ( ). All segmentation output images were then smoothed with an isotropic kernel of 8\u00a0mm at full-width at half maximum. After smoothing, the value of each voxel in the image represented the probability that the tissue belongs to one class and not to one of the others (gray matter, white matter, non-brain, or lesion). \n\nThe additional tissue class image (binary lesion) for each subject was in an additional analysis to determine lesion volumes using the automated lesion identification algorithm (ALI toolbox) implemented in SPM8 ( ). These binary lesion images were also used to create a lesion overlap map (see  ) using the automated lesion overlap map toolbox in SPM. Lesion volumes between AOS and AOS-absent patients were tested with independent samples   t  -test, and not significantly different (  p  \u00a0=\u00a0.612). \n\n\n#### Functional image analysis \n  \nPrior to analysis, we ensured that all stroke patients did not have significantly more head motion than healthy controls. Independent sample   t  -tests of framewise displacement (FD) and root mean squared movement (RMS) were indeed not different between groups ( ). EPI images were first corrected for head movement by applying affine registration using a two-pass procedure in SPM8. A mean EPI image for each subject was created and then spatially normalized to the MNI single subject template using the \u201cunified segmentation\u201d approach ( ). A deformation field was output from this process and then applied to the individual EPI volumes. Output images were then smoothed using a 5-mm FWHM Gaussian kernel. The following instances of variance were then removed from each voxel's time series in order to reduce spurious correlations by confounds such as physiological noise and motion (cf.  ): i)the six motion parameters derived from the image realignment, ii) their first derivative, and iii) mean gray, white matter and CSF signal intensity ( ;  ;  ). Data were then band-pass filtered, preserving frequencies between 0.01 and 0.08\u00a0Hz ( ;  ). \n\n\n\n### ROI selection \n  \nFunctional connectivity was then investigated using a network of cortical regions proposed to have roles in AOS. Coordinates for each of these regions had also been identified from a meta-analysis of previous fMRI studies of overt speech and an effective connectivity analysis of this speech network [see  ( )]. The regions selected were: i)IFG (BA 44), ii) aINS, and iii) PM (BA6). Coordinates of each region from   are displayed in  . We examined both hemispheres in the same model to identify any altered connectivity between the affected and unaffected hemispheres and also any adaptive changes that may have occurred in the unaffected hemisphere. The time course for each of the identified seed regions was then extracted for each subject as the first eigenvariate of the resting-state signal time-series of all gray-matter voxels located within 5\u00a0mm of the respective peak coordinate. In particular, these regions were selected to test the different hypotheses associated with the role of each ROI in the pathogenesis of AOS. \n\n\n### Functional connectivity network analysis \n  \nFor each subject we computed linear (Pearson) correlation coefficients between the extracted time series of each of the seed regions to examine connectivity within the specified network, after controlling for individual differences in head motion (see   for measures of head motion). These voxel-wise correlation coefficients were then transformed into Fisher's   Z   values where each score represents the functional connectivity strength for each connection in each subject. The connectivity was calculated for all seeds to identify regions showing significant coupling with other regions within the identified speech network. Functional network connectivity (cf.  ;  ) was assessed in both of the patient groups. Furthermore, we determined significant differences between patients and controls, and as a final comparison, significant differences in network connectivity between individuals diagnosed with AOS and those patients diagnosed as AOS-absent were identified using independent samples   t  -tests. Results for network connectivity within and between groups were thresholded at FDR-corrected   p  \u00a0<\u00a00.05. \n\nTo assess a possible relationship between functional connectivity and speech and language impairment, Spearman rank-correlation analyses were performed on the individual connectivity strengths between the regions of our network and expert diagnostic rating scale scores in the patient groups. Correlations between diagnostic scale scores and the neural network connectivity were thresholded at FDR-corrected   p  \u00a0<\u00a00.05. \n\n\n\n## Results \n  \n### Characterization of communication impairment in patients with stroke \n  \nAcross all 32 patients, the mean WAB Aphasia Quotient was moderate in severity (M\u00a0=\u00a065.66\u00a0\u00b1\u00a025.12). The patients were divided into two groups, 15 with AOS symptoms and 17 without AOS. Furthermore, of the AOS-absent group, three had mild word-finding aphasia, seven had anomia, one suffered from global aphasia, three from Broca's aphasia, one from transcortical sensory aphasia, one from Wernicke's aphasia, and one from conduction aphasia. Of the AOS group, two suffered from global aphasia, one from transcortical motor aphasia, four from conduction aphasia, four from Broca's aphasia, one from Wernicke's aphasia, and four from anomic aphasia. Two patients (one AOS, one AOS-absent) evidenced below normal nonverbal cognitive performance on Raven's Colored Progressive Matrices (M\u00a0=\u00a026\u00a0\u00b1\u00a06.86). Lastly, patients averaged 87.5% (M\u00a0=\u00a063\u00a0\u00b1\u00a017.17) on the Auditory Discrimination of Minimal Pairs subtest of the Psycholinguistic Assessments of Language Processing in Aphasia\u2014 2. Finally, expert ratings of AOS and NVOA severity were moderately correlated (  r  \u00a0=\u00a0.718). \n\n\n### Lesion overlap data \n  \n displays the results from the lesion overlap map. In the group of 15 patients diagnosed with AOS the regions of highest overlap were the left hemisphere caudate (head), insula and premotor regions (BA6). In the group of 17 patients without AOS symptoms, the highest areas of lesion overlap were the left hemisphere caudate (tail) and postcentral gyrus. Among the current regions of interest, 38% of patients had damage to the left IFG, 59% had damage to the left PM, and 56% had damage to the left aINS. Using post-hoctwo-tailed  t  -tests thresholded at Bonferroni-corrected   p  \u00a0<\u00a0.05, we found that patients categorized as non-verbal oral apraxia had significantly more damage to all ROIs (left IFG(  p  \u00a0=\u00a0.004), left PM (  p  \u00a0<\u00a0.001) and left aINS (  p  \u00a0=\u00a0.002)), compared to those without non-verbal oral apraxia. Using independent samples   t  -test thresholded at Bonferroni-corrected   p  \u00a0<\u00a0.05, percent damage to each 5\u00a0mm left hemisphere ROI was compared between AOS and AOS-absent patients. The groups did not significantly differ in percent damage to the left IFG (  p  \u00a0=\u00a0.064) or left aINS (  p  \u00a0=\u00a0.027). Percent damage to the left PM seed slightly differed between AOS and AOS-absent groups (  p  \u00a0=\u00a0.008). Multiple correlations determined that percent damage to any ROI was not related to connectivity strength in connections that included those damaged seeds. \n\n\n### Resting state connectivity in healthy controls and patients with and without AOS \n  \n displays significant resting state connectivity (  z  -scores) within the identified network in healthy control subjects (a)and all patients (b). The network in healthy controls ( ) showed strongest connectivity among bilateral seeds (left\u2013right IFG:   z  \u00a0=\u00a05.77; left\u2013right PM:   z  \u00a0=\u00a04.73; left\u2013right aINS:   z  \u00a0=\u00a04.28). Inter- and intra-hemispheric connectivities between IFG and aINS were also consistent (right IFG\u2013right aINS:   z  \u00a0=\u00a04.07; left IFG\u2013left aINS:   z  \u00a0=\u00a03.83; left aINS\u2013right IFG:   z  \u00a0=\u00a03.65; left IFG\u2013right aINS:   z  \u00a0=\u00a03.34). The left IFG was also connected to the right PM (  z  \u00a0=\u00a02.94). \n\nThe network in stroke patients was similar among many of the seed regions, but differed qualitatively among certain nodes. The strongest connection in patients was that of the right IFG and right aINS (  z  \u00a0=\u00a06.98). Likewise, each bilateral seed connection was present (left\u2013right aINS:   z  \u00a0=\u00a04.21; left\u2013right PM:   z  \u00a0=\u00a04.02; left\u2013right IFG:   z  \u00a0=\u00a03.26). Intrahemispheric connectivity was also represented among the left IFG and left aINS (  z  \u00a0=\u00a03.81), and the right PM and right aINS (  z  \u00a0=\u00a03.27). Finally, the left aINS was also connected to the right IFG (  z  \u00a0=\u00a03.20). \n\nWhen comparing patients to healthy controls, each seed's bilateral connections were significantly reduced in patients ( ; left\u2013right IFG:   z  \u00a0=\u00a03.33; left\u2013right PM:   z  \u00a0=\u00a02.81; left\u2013right aINS:   z  \u00a0=\u00a02.56). \n\nIn the AOS-absent group ( a), there was coupling between the left aINS and right aINS (  z  \u00a0=\u00a03.64), right IFG (  z  \u00a0=\u00a03.02), and left IFG (  z  \u00a0=\u00a02.57). The right IFG was also connected to the left IFG (  z  \u00a0=\u00a02.37) and the right aINS (  z  \u00a0=\u00a05.01). Finally, the right PM was connected to the right aINS (  z  \u00a0=\u00a02.24) and the left PM (  z  \u00a0=\u00a03.91). \n\nIn the AOS group ( ), the right aINS was positively connected to the right IFG (  z  \u00a0=\u00a04.79) and the left aINS (  z  \u00a0=\u00a02.21), but negatively connected to the left PM (  z  \u00a0=\u00a02.51). Finally, the left IFG was connected to the left aINS (  z  \u00a0=\u00a02.81), and the left PM (  z  \u00a0=\u00a02.07). \n\nGroup differences (AOS versus AOS-absent) reached significance between the left PM and right aINS (positive in AOS-absent and negative in AOS) and between the left and right PM (more positive for AOS-absent; see  ). \n\n\n### Correlation of connectivity with expert clinical diagnosis scores \n  \nIn order to assess whether connectivity within the specified network is associated with expert clinical diagnosis, correlations were performed between expert diagnosis ratings in all patients and connectivity strength of all connections. Results from the correlation analyses ( ) identified a significant negative correlation between connectivity between the left and right hemisphere PM regions, present in all stroke patients, and expert diagnosis rating of AOS (  r  \u00a0=\u00a0\u22120.59) in which patients rated with more severe AOS showed reduced connectivity between the PM regions. A significant negative correlation was also seen between severity ratings for non-verbal oral apraxia and connectivity between the left hemisphere PM and right hemisphere aINS regions (  r  \u00a0=\u00a0\u22120.56). In this case, patients who were rated as more impaired for non-verbal apraxia showed enhanced negative connectivity between the left PM and right aINS. We did not find any significant correlations between connectivity and clinical diagnosis ratings for dysarthria. \n\n\n\n## Discussion \n  \nWe investigated resting state functional connectivity between the PM, IFG and aINS regions in both hemispheres to provide insight into the neurobiological mechanisms of acquired AOS in three groups of subjects. These data add to the sparse neuroimaging information in AOS, provide insight into network connectivity hitherto unavailable for AOS, and provide insights from the brain at rest that are unbiased by task and that likely represent relatively stable brain states. Patients with speech and language problems were grouped based on the presence or absence of AOS. When comparing patient groups with healthy controls we found reductions in connectivity between each bilateral seed region in the patient groups. We found that stroke patients with AOS had reduced functional connectivity between the left and right premotor regions and the left premotor and right aINS regions in comparison to stroke patients without AOS. Importantly, the strength of bilateral PM connectivity was negatively correlated with severity of AOS in this patient group, which is expected and is supported by literature that provides evidence of changes in bilateral BOLD activation in chronic stroke in the motor cortex ( ;  ). Furthermore, we did not find any instances of increased positive connectivity within the network in the AOS patients compared to the AOS-absent patients, though we did find that the left PM\u2013right aINS connectivity was negative in the AOS patient network model. \n\nOur findings of altered PM connectivity in AOS relative to AOS-absent patients may be understood in the context of DIVA. The model ( ;  ) has been recently updated to include a lateralized feedback control map in the right ventral premotor cortex. This region is thought to be involved in transforming error signals into corrective motor commands when incoming sensory feedback does not fall within the range of expected sensory consequences of the speech action. The reduced connectivity between the left and right hemisphere PM regions may be related to disordered preprogramming of speech units. Remapping of functions from the damaged left hemisphere to the right hemisphere PM region could be used in compensation for the interrupted left hemisphere networks. However, an alternative consideration regarding reduced positive left\u2013right PM connectivity is that patients with AOS may be unable to fully compensate using the right PM region for the INT stage. In this case, it is possible that the right aINS may be recruited for compensation. Thisis supported by the negative connectivity seen in AOS patients between the left PM and right aINS. Imaging studies of perturbed speech production in healthy adults have also identified the ventral premotor cortex as having increased activation during the perturbed feedback condition when compared to the unperturbed condition ( ;  ;  ), suggesting involvement of this region in speech error correction. Below, we discuss altered connectivity in stroke patients, followed by altered speech network connectivity specific to AOS. \n\n### Altered speech network connectivity in patients with stroke \n  \nThe comparison of healthy control subjects to stroke subjects is complicated by the fact that the control subjects do not have a lesion in the left hemisphere. Although inter-hemispheric connectivity was significantly reduced across both patient groups following contrast analysis, these lateral connections were also consistently present in both healthy control and patient group models, individually. In addition, the ipsilateral IFG\u2013aINS connection was present in both hemispheres in both patient groups and healthy controls. When looking at individual group models, the healthy controls' connectivity strength is similar in both the left and right hemispheres, but in the patient group, the right hemisphere IFG\u2013aINS connection is similar in strength to healthy controls, yet the left hemisphere IFG\u2013aINS connection appears to be weaker. Functional imaging of unimpaired speech production consistently reports activation of the aINS and IFG regions (e.g.  ). The left IFG (BA44) is associated with the speech sound map component of DIVA ( ) and it has been suggested that the left aINS region might represent involvement in speech motor sequence planning ( ). The seemingly weaker connection strength between the left aINS and left IFG is most likely due to over half of the patient sample having extensive damage to the left aINS, but fewer having damage to the left IFG. This may alter the amount and nature of the BOLD signal as recorded during fMRI. \n\nGroup differences, which were found in bilateral seed connections, represent a reduction in interhemispheric synchronization of the BOLD signal following stroke. If reorganization of function from left to right hemisphere occurred, this would certainly alter the correlation of BOLD signal in time between the two hemispheres, causing the difference in connectivity. In the current study, we are unable to infer causation and directionality and can therefore only hypothesize about the cause of connectivity influences. One resting state study ( ) employed an effective connectivity analysis, structural equation modeling (SEM), to examine changes following an upper limb rehabilitation therapy post-stroke. They found increases in connectivity from the affected hemisphere PM region to the unaffected hemisphere PM region. We can hypothesize that the reduced connectivity we see in stroke compared to healthy controls might be in the direction of the affected to the unaffected hemisphere for the IFG, PM, and aINS regions. Previous inter-hemispheric synchronization is no longer present following stroke, nor have the current patients received rehabilitation; thus, the speech and language functions of these regions degrade, and possibly reorganize to different remote regions in chronic stages. Though interhemispheric motor region resting state connectivity changes are common following stroke, interpretation may still be debatably over-simplified ( ). \n\n\n### Altered connectivity specific to AOS \n  \nWithin the speech network hypothesized to be different in stroke patients with AOS, we found different trends of connectivity between two sets of nodes, both including the left PM. Similar to all stroke patients compared to healthy controls, bilateral PM connectivity was reduced in AOS compared to AOS-absent patients. This is further discussed below in the context of its relation to clinical ratings of AOS severity. \n\nFurthermore, patients with AOS differed from those without AOS because they showed a negative relationship between the left PM and right aINS, e.g. lower activity in the left PM was associated with higher activity in the right aINS. This is in keeping with the possibility that the right aINS may play a role in compensating for left PM damage. These results point to the importance of the left PM region in its role in disordered planning and programming of speech following stroke. The nature of neural activity in these regions is unique to AOS. Furthermore, the effect of the two patients who scored below average on Raven's Colored Progressive Matrices is not presumed to be significant, as one was in the AOS group, and the other in the AOS-absent group. \n\nIn addition, the lesion overlap analysis shows more overlap on the left PM seed in the AOS group. Damage to the left PM cortex, as supported by intrinsic connectivity that also differentiates AOS and AOS-absent stroke patients, may be a unique factor in developing AOS. However, the current data are not capable of providing enough support to posit this argument. The relationship between neuronal death and BOLD signal is only beginning to be studied, particularly in cerebrovascular diseases ( ). \n\n\n### Clinical apraxia severity correlates in the speech network \n  \nPrevious studies examining resting state connectivity following stroke have found correlations in limb motor behavior or motor impairment with resting state connectivity measures ( ;  ;  ). Here we found significant correlations with expert clinical ratings of AOS severity in the two connections that showed reduced connectivity in the AOS patient group. Specifically, we found the connectivity between the left and right PM regions to be negatively correlated with expert diagnosis ratings of AOS severity. The \u201cinverse\u201d connectivity between the left PM and right aINS regions was greater in the AOS patient group compared to the AOS-absent patient group and also negatively correlated with expert ratings of non-verbal orofacial apraxia severity. Insula activation is present in a wide range of cognitive and sensorimotor tasks, but the specific role of the right aINS region in speech is less documented.   previously found that gray matter intensity in the right insula correlated with measures of non-fluency during reading in individuals with progressive aphasia with and without progressive AOS, further emphasizing its involvement in sensory motor loops and cortical integration. The region's documented role in peripheral arousal relating to task difficulty ( ) could also suggest involvement in anticipation of sensory feedback during speech. It is likely that the insula is critical to many aspects of speech and integration of information and, therefore, increased negative connectivity of this region with the left PM in AOS, particularly those with severe non-verbal orofacial apraxia, suggests a compensating role of the right aINS, though perhaps unspecific to motor-speech pathology, following left hemisphere damage. \n\nWe also found a strong correlation between expert ratings of AOS and NVOA severity, consistent with our previous work ( ). Various functional imaging meta-analyses of speech ( ;  ) and non-speech orofacial motor systems ( ) have shown similarity in regions activated in both speech and non-speech motor tasks. These findings suggest that the brain networks subserving speech and non-verbal orofacial motor systems overlap one another. Though there was a high overlap between AOS and non-verbal oral apraxia ratings in most of the AOS patients, other work in pure AOS following stroke supports the role of the left PM in AOS ( ), though further experimental controls are needed to verify these findings. Furthermore, we did not find any significant correlations with connectivity and clinical diagnosis ratings for dysarthria, supporting AOS as a separate clinical entity and the utility of resting state network analysis as a potential clinical tool. \n\n\n### Limitations \n  \nThe most notable limitation to the current study is that of the imbalance in gender, particularly between patients and controls. As healthy controls were recruited for this study, they were not explicitly matched to patients based on gender. In order to quantify the effect of gender in the current study, we ran a post-hoc   t  -test comparison of connectivity across genders, within the control group and the patient group. Though we found no difference in connectivity between males and females in healthy controls (  p  \u00a0=\u00a0.422), or in patients (  p  \u00a0=\u00a0.203), future work should enact gender matching. \n\nAnother caveat of the current methodology is that the relationship between structural and functional connectivity in stroke is unclear. A correlation in activity between two regions does not necessarily reflect either direct or indirect anatomical connections between the correlated regions. It could reflect two complementary systems working in synchrony (positive correlation) or opposition (negative correlation). More specifically, the relationship between neuronal death, particularly in populations such as chronic stroke, and the BOLD signal (nonetheless functional connectivity) is unknown. Future studies are needed to understand this relationship. Even if the differences in connectivity seen here are simply a result of impaired or absent anatomic connections between these regions, the results still inform us of the key connections involved in AOS, the impact of lesion on the function and integrity of the speech network and the key differences in patients with aphasia when AOS is judged as present or absent. \n\nFinally, we would also need to examine groups based on lesion site or disorder (i.e.,non-AOS), while controlling for lesion volume, as the current sample did not provide enough patients with these matching characteristics. It might also be important to look at alternative regions, such as the postcentral gyrus, as it was one of the most common sites of lesion overlap, and in some studies it has been a common site of lesion overlap in persons with \u201cpure\u201d AOS, without concomitant dysarthria or aphasia ( ). The caudate, the other most common site of lesion overlap in our AOS sample, should also be included in future network connectivity studies. \n\n\n\n## Conclusions \n  \nThese results suggest that bilateral PM is critically associated with AOS. Interestingly, we did not see connectivity differences between patient groups related to the IFG, given the postulated involvement in AOS. We show that reduced bilateral PM functional connectivity is related to AOS severity, while left PM\u2013right aINS connectivity is related to non-verbal oral apraxia severity. Apraxia of speech severity was also more strongly related to the percent damage of the PM seed than was non-verbal oral apraxia severity. The decrease in connectivity between these regions in patients with AOS compared to AOS-absent patients may result from differences in the severity of aphasia that exist in both groups. However, the connectivity differences clearly relate to neural mechanisms of reorganization and/or symptom. These connectivity differences related to speech production impairment help inform us of the neural mechanisms driving differences in speech motor planning and programming impairment following stroke. \n\n\n## Funding \n  \nThis work was supported by   project grant 632763 (Principal Investigator: Kirrie J. Ballard, PhD). \n\n \n\n# Table(s)\n## ID: t0005\n### Label: Table\u00a01\nID\tAge\tGender\tMPO\tLesion volume (cm3)\tAOS\tExDx AOS\tExDx Dys\tExDx NVOA\tWAB AQ\tRCPM\tPALPA\nDIS001\t69\tM\t52\t80.7\tN\t1.0\t1.0\t1.0\t86.0\t19.0\t67.0\nDIS002\t48\tM\t17\t149.16\tY\t7.0\t2.0\t7.0\t11.3\t21.0\t72.0\nDIS003\t72\tM\t156\t34.3\tY\t2.5\t3.0\t1.0\t81.3\t26.0\t63.0\nDIS004\t66\tM\t32\t163.0\tY\t3.5\t1.0\t5.5\t83.7\t34.0\t70.0\nDIS005\t56\tF\t44\t66.2\tN\t1.0\t1.5\t1.5\t93.0\t32.0\t72.0\nDIS006\t54\tM\t36\t59.2\tY\t3.5\t1.0\t4.5\t75.1\t31.0\t68.0\nDIS007\t71\tM\t17\t32.4\tN\t1.5\t1.5\t2.0\t73.7\t28.0\t56.0\nDIS008\t58\tM\t10\t27.1\tN\t1.0\t1.0\t1.0\t68.3\t34.0\t66.0\nDIS009\t71\tM\t16\t1.5\tN\t1.0\t2.5\t2.0\t91.6\t32.0\t70.0\nDIS010\t67\tM\t58\t70.4\tN\t1.0\t1.0\t1.5\t86.4\t35.0\t63.0\nDIS011\t77\tM\t81\t140.3\tY\t6.5\t3.5\t5.5\t60.5\t30.0\t70.0\nDIS012\t69\tM\t27\t55.3\tY\t3.0\t2.5\t4.5\t80.8\t34.0\t66.0\nDIS013\t73\tM\t38\t114.3\tN\t2.0\t1.5\t5.0\t11.9\t6.0\t\nDIS014\t48\tM\t13\t62.4\tY\t4.5\t1.5\t4.0\t41.6\t36.0\t\nDIS015\t66\tM\t84\t171.1\tY\t3.0\t1.5\t4.0\t75.3\t32.0\t60.0\nDIS017\t76\tM\t120\t158.6\tY\t6.5\t3.5\t6.0\t39.6\t22.0\t63.0\nDIS018\t66\tM\t21\t21.0\tN\t1.5\t2.0\t2.0\t97.3\t27.0\t71.0\nDIS022\t64\tF\t121\t222.4\tN\t2.0\t1.0\t5.0\t54.5\t29.0\t63.0\nDIS023\t49\tM\t14\t49.5\tN\t1.0\t1.0\t1.0\t72.5\t32.0\t69.0\nDIS024\t59\tM\t69\t132.9\tN\t1.0\t1.0\t1.0\t80.7\t27.0\t66.0\nDIS025\t55\tF\t92\t17.7\tN\t1.0\t1.0\t1.0\t98.7\t35.0\t71.0\nDIS026\t71\tM\t11\t217.4\tN\t1.0\t1.0\t1.0\t66.6\t25.0\t72.0\nDIS027\t73\tM\t26\t298.5\tN\t1.0\t1.0\t4.5\t50.0\t31.0\t72.0\nDIS028\t50\tM\t9\t62.2\tY\t5.0\t4.0\t3.0\t60.2\t\t68.0\nDIS029\t75\tM\t36\t117.2\tY\t6.0\t3.0\t4.5\t17.8\t15.0\t\nDIS030\t61\tM\t3\t1.1\tN\t1.0\t1.0\t1.0\t88.9\t35.0\t67.0\nDIS031\t63\tM\t23\t56.2\tY\t2.5\t1.0\t6.0\t62.8\t30.0\t61.0\nDIS047\t45\tF\t37\t161.5\tN\t1.0\t1.0\t5.5\t36.9\t3.0\t67.0\nDIS048\t40\tM\t13\t143.2\tY\t5.0\t1.0\t6.0\t23.9\t21.0\t66.0\nDIS050\t51\tM\t6\t37.4\tY\t4.0\t3.0\t5.0\t69.5\t34.0\t68.0\nDIS051\t57\tM\t1\t129.8\tY\t4.5\t1.0\t5.5\t64.8\t28.0\t68.0\nDIS052\t74\tF\t5\t1.3\tN\t1.0\t1.0\t2.0\t96.0\t35.0\t68.0\n### Caption\nPatient demographics. MPO\u00a0=\u00a0months post-onset of stroke; AOS\u00a0=\u00a0apraxia of speech; ExDx AOS\u00a0=\u00a0expert severity rating of apraxia of speech; ExDx Dys\u00a0=\u00a0expert severity rating of dysarthria; ExDx NVOA\u00a0=\u00a0expert severity rating of non-verbal orofacial apraxia; WAB AQ\u00a0=\u00a0Western Aphasia Battery\u2014 Revised (Kertesz, 2006) Aphasia Quotient (max score 100); RCPM\u00a0=\u00a0Raven's Colored Progressive Matrices (max score 36); PALPA (Kay, Lesser and Coltheart, 1992)\u00a0=\u00a0Auditory Discrimination subtest of the Psycholinguistic Assessments of Language Processing in Aphasia (max score 72); N/A\u00a0=\u00a0not administered.\n### Footer\nNone\n\n\n## ID: t0010\n### Label: Table\u00a02\nRegion of interest\tMNI coordinate (x, y, z)\nInferior frontal gyrus (BA44) (IFG)\t\u221250 10 5\nInferior frontal gyrus (BA44) (IFG)\t50 10 5\nAnterior insula (aINS)\t\u221232 15 2\nAnterior insula (aINS)\t32 15 2\nVentral premotor cortex (BA6) (PM)\t\u221258 1 23\nVentral premotor cortex (BA6) (PM)\t58 1 23\n### Caption\nNetwork location coordinates in MNI space.\n### Footer\nNone\n\n\n## ID: t0015\n### Label: Table\u00a03\nGroup\tFD mean (SD)\tp (t-test)\tRMS mean (SD)\tp (t-test).1\nControls\t0.33 (0.15)\t0.68\t0.25 (0.13)\t0.97\nPatients\t0.35 (0.15)\t0.68\t0.25 (0.11)\t0.97\n### Caption\nBetween-group matching for head motion.\n### Footer\nNone\n", "metadata": {"pmcid": 4473263, "text_md5": "80f8da662a1a8006bde3e21e03f733b2", "field_positions": {"authors": [0, 213], "journal": [214, 229], "publication_year": [231, 235], "title": [246, 342], "keywords": [356, 421], "abstract": [434, 2167], "body": [2176, 39432], "tables": [39445, 42376]}, "batch": 2, "pmid": 26106568, "doi": "10.1016/j.nicl.2015.03.013", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4473263", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4473263"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4473263\">4473263</a>", "list_title": "PMC4473263  Altered resting-state network connectivity in stroke patients with and without apraxia of speech"}
{"text": "Shen, Yan-Kun and Ge, Qian-Min and Pan, Yi-Cong and Shu, Hui-Ye and Zhang, Li-Juan and Li, Qiu-Yu and Liang, Rong-Bin and Shao, Yi and Yu, Yao\nAging (Albany NY), 2021\n\n# Title\n\nDecreased gray matter volume and increased white matter volume in patients with neovascular age-related macular degeneration: a voxel-based morphometry study\n\n# Keywords\n\nneovascular age-related macular degeneration\nchoroidal neovascularization\nmental disorder\n\n\n# Abstract\n \nObjective: To measure white and gray matter volume (WMV, GMV) in patients with neovascular age-related macular degeneration (nAMD) using voxel-based morphometry (VBM). \n\nMaterial: Eighteen patients (9 men, 9 women) with nAMD and 18 (9 men, 9 women) healthy controls (HCs) aligned were recruited. Functional magnetic resonance imaging (fMRI) and VBM of three-dimensional T1 brain images were analyzed. And we also apply t-tests to look for GMV and WMV differences between groups. Correlation analysis was utilized to probe the connection between observational GMV and WMV values of diverse brain areas and the severity of HADS (hospital anxiety and depression scale). Also, distinctions between nAMD and HCs in GMV can be presented with the help of a ROC (receiver operating characteristic) curve. \n\nResults: Compared with HCs, GMV values were significantly lower in patients with neovascular age-related macular degeneration in the right inferior frontal gyrus, temporal pole of left superior temporal gyrus, left superior temporal gyrus, left middle frontal gyrus, left anterior cingulate and para cingulate gyrus. While WMV was slightly increased in these areas. HADS (hospital anxiety and depression scale) scores portrayed a non-linear correlation with the GMV value of the right inferior frontal gyrus, left middle frontal gyrus, left anterior cingulate and paracingulate gyrus of the nAMD group (r=-0.6629, P=0.0027)(r=-0.9451, P<0.0001)(r=-0.6183, P=0.0062). Moreover, the ROC curve analysis of the mean VBM values for altered brain regions indicated high diagnostic accuracy. \n\nConclusion: These results indicated that patients with nAMD have abnormal GMV and WMV and formed a basis for future research on pathological mechanisms in this disease. Moreover, decreased gray matter volume in particular brain regions might be associated with choroidal neovascularization and abnormal HADS score. It might help to explain the pathological mechanism of anxiety and depression in patients with nAMD. \n \n\n# Body\n \n## INTRODUCTION \n  \nAge-related macular degeneration (AMD) is the third most common potentially blinding eye disease globally, with a significant impact on elderly patients\u2019 quality of life [ ]. Its disease stage may be categorized as early, late indeterminate, late wet active, late dry, or late wet inactive. AMD arises and progresses with age, damaging the central (macular) region of the retina, and features no clear pathogeny [ ]. As a common cause of severe vision loss, nAMD is accompanied by choroidal neovascularization, an important pathological feature of this disease stage. And a lack of timely intervention may lead to visual impairment and even blindness [ ]. \n\nThe diagnosis of nAMD is mainly based on fundus angiography, optical coherence tomography, and confocal laser fundus imaging [ ,  ]. Diversified diagnostic methods and standards being helpful to diagnose nAMD in its different presentations. In addition to medical diagnosis, patients with the following risk factors should be alert to the possible occurrence of nAMD: (1) the elderly; (2) nAMD in the other eye; (3) family history of nAMD; (4) smoking and smoking history; (5) hypertension; (6) obesity or hyperlipidemia; (7) insufficient intake of vitamins, carotenoids. and minerals; (8) high-fat diet; (9) lack of exercise. \n\nWith the characteristics of noninvasive, clear imaging and high soft-tissue resolution ratio, magnetic resonance imaging (MRI) has been increasingly applied in the research fields of ophthalmic diseases [ ], related animal models [ ], and the clinical research of visual injury [ ]. Thus, MRI can be used to detect brain changes in nAMD patients and compare all images in the same stereotactic space [ ]. \n\nVoxel-based morphometry (VBM) is a statistical analysis tool to measure particle size of gray matter [ ]. It can be used to measure and compare the volume as well as gyration between groups. Correlation analysis of clinical scores shows that VBM can be used not only for structural analysis but also for analyzing the impact of structural changes [ ]. It has been used to study the pathology of trigeminal neuralgia, senile dementia, mild cognitive impairment, and motor neuron diseases [ \u2013 ]. In ophthalmology, it has also been used to increase understanding of optic neuritis, retinal detachment, acute eye pain, advanced monocular blindness [ \u2013 ], and nAMD. It offers a powerful method of elucidating the pathological mechanisms of those diseases, and monitoring the course of their progression. \n\n\n## RESULTS \n  \n### Demographics and visual surveys \n  \nNo significant difference in age (P=0.802) or handedness (P>0.99) was found between the nAMD and HC groups. Handedness was analyzed using the chi-squared test. Significant differences were found in the best-corrected right and left visual acuities (P=0.003 and P=0.001 respectively) but not in right or left intraocular pressure (P=0.119 and P=0.134 respectively). Details are shown in  . \n   Demographics and behavioral results of nAMD and HCs groups.    \nNotes: Independent t-tests comparing the age of two groups (P<0.05) represented statistically significant differences). Male/female and Handedness were analyzed using chi-squared test. \n\nAbbreviations: nAMD, neovascular age-related macular degeneration; HCs, healthy controls; N/A, not applicable; VA, visual acuity; R, right; L, left; IOP, intraocular pressure. \n  \n\n### VBM differences \n  \nCompared with HCs, the GMV values were generally lower in patients with nAMD in the left superior temporal gyrus, right inferior frontal gyrus, left middle frontal gyrus, temporal pole of left superior temporal gyrus, and the left anterior cingulate and para cingulate gyrus (P=0.010). While group differences in WMV were not found within regions, the averaged white matter volume (WMV) was slightly higher in the nAMD group. (  [red],   and  ,  ; P<0.01 for multiple comparisons by GRF theory). \n  \n GMV regional decrease in patients with nAMD compared with HCs.   (  A  ,   B  ). Notes: Compared with the HC group, the GMV was reduced in the right inferior frontal gyrus in the patients with nAMD, as well as left superior temporal gyrus temporal pole, left superior temporal gyrus, left middle frontal gyrus, left anterior cingulate and paracingulate gyrus. Abbreviations: nAMD, neovascular age-related macular degeneration; HC, healthy controls; GMV, gray matter volume. \n    \n The mean GMV values between the nAMD and HC group.   Abbreviations: GMV, gray matter volume; nAMD, neovascular age-related macular degeneration; HC, healthy controls. \n     Brain regions with significant differences in grey matter volume between nAMD group and HCs.    \nAbbreviations: nAMD, neovascular age-related macular degeneration; HC, healthy controls. \n     Group GMV differences between nAMD group and HC group.    \nAbbreviations: nAMD, neovascular age-related macular degeneration; HC, healthy controls. \n  \n\n### Correlation analysis \n  \nIn the nAMD group, the GMV values of the right inferior frontal gyrus, left middle frontal gyrus, left anterior cingulate and para cingulate gyrus were each non-linear correlated with HADS scores (r=- 0.6629, P=0.0027; r=-0.9451, P<0.0001; r=-0.6183, =0.0062). The details are shown in  . \n  \n Correlation between the mean GMV and severity of HADS in different brain areas.   Notes: (  A  ) The GMV value of the right inferior frontal gyrus of the nAMD group portrayed a non-linear correlation with the severity of HADS (r=-0.6629, P=0.0027). (  B  ) The GMV value of the left middle frontal gyrus of the nAMD group portrayed a non-linear correlation with the severity of HADS(r=-0.9451, p<0.0001). (  C  ) The GMV value of the left anterior cingulate and paracingulate gyrus of the nAMD group portrayed a non-linear correlation with the severity of HADS(r=-0.6183, p=0.0062). Abbreviations: GMV, gray matter volume; HADS, hospital anxiety and depression scale; nAMD, neovascular age-related macular degeneration. \n  \n\n### ROC curve \n  \nThe areas under the curves (AUCs) for GMV values in these regions were as follows: right inferior frontal gyrus=0.917, left superior temporal gyrus temporal pole=0.722, left middle frontal gyrus=0.933, left anterior cingulate and para cingulate gyrus=0.988. Details are shown in  . \n  \n ROC curve analysis of the mean VBM values for altered brain regions.   Notes: The area under the ROC curve were 0.917 (P<0.0001; 95% CI: 0.823-1.000) for Frontal_Inf_Orb_R, Temporal_Pole_Sup_L 0.988 (P<0.0001; 95% CI: 0.960-1.000), Temporal_Sup_L 0.722 (P=0.033; 95% CI: 0.544-0.900), Frontal_Inf_Orb_R2 0.917 (P<0.0001; 95% CI: 0.824-1.000), Frontal_Mid_L 0.933 (P<0.0001; 95% CI: 0.852-1.000), Cingulum_Ant_L 0.988 (P<0.0001; 95% CI: 0.960-1.000). Abbreviations: AUC, area under the curve; ROC, receiver operating characteristic. \n  \n\n\n## DISCUSSION \n  \nTo our knowledge, this is the first study to use the VBM method to investigate differences in GMV and WMV in nAMD patients. The results indicate that the average value of GMV was lower while the average one of WMV was slightly higher in nAMD patients compared with HCs. Within regions, GMV was significantly lower in the right inferior frontal gyrus, left superior temporal gyrus temporal pole, left superior temporal gyrus, left middle frontal gyrus, left anterior cingulate and para cingulate gyrus. \n\nAs explained earlier (see Introduction), nAMD is a common macular degeneration disease that progresses slowly and it mainly afflicts the elderly. It is characterized by central vision loss, which often leads to map-like atrophy as well as neovascularization. Choroidal neovascularization is the most essential pathological feature of nAMD and a lack of timely intervention may lead to severe complications, such as visual acuity being reduced by three lines in one year and four lines in two years [ ,  ]. Therefore, diagnosis and treatment of the disease need more attention. In past studies, we have used fMRI to assess neural activity in patients with nAMD. While in the present study VBM was used to investigate changes of GMV and WMV in patients with nAMD and to explore the possible underlying pathogenesis. \n\nThe results showed reduced GMV in right inferior frontal gyrus in patients with nAMD. The inferior frontal gyrus is located on the ventral side of the inferior frontal sulcus. It is in front of the anterior central sulcus and on the lateral fissure. It is divided into three accessory gyri (Brodmann area 47/12, Brodmann area 45, Brodmann area 44) [ ] by the anterior ascending branch and the anterior horizontal branch of the lateral fissure. The most widely known functions of the inferior frontal gyrus are speech and language comprehension [ ]. Some results showed that in patients with depression, the resting state amplitude of low frequency fluctuation (ALFF) of the left inferior frontal gyrus was significantly decreased. It was associated with functional abnormalities including emotion, cognition, and memory [ ]. \n\nThe temporal lobe is segmented into superior, middle, and inferior gyri. The superior temporal gyrus is also the vestibular cortex. Therefore, balance disorder and vertigo may arise with temporal lobe lesions. Oculomotor nerve palsy may occur with large lesions of the superior temporal gyrus. With functional magnetic resonance imaging (fMRI), one study showed that patients with left anterior temporal lobectomy behaved activation in the central cover processing structure due to intractable epilepsy. After both right and left lobectomy, the researchers discovered in the right superior temporal sulcus reduced responses to faces together with reduced recognition of facial expression [ ]. In addition, damage to the left posterior superior temporal gyrus has been associated with impairments in phonological processing [ ]. NAMD may damage the left temporal pole, which may lead to impaired recognition of facial expression, language difficulty, and arachnoid cyst [ ]. It can compress brain tissue and cause headache, intractable epilepsy and other corresponding symptoms [ ]. \n\nThe anterior cingulate cortex is situated at the medial frontal lobe of the brain. It can monitor target orientation behavior [ ], conflict and error monitoring [ ,  ], behavioral decision-making and volitional control [ \u2013 ]. And it allocates attentional resources effectively in relevant brain regions according to the current task processing requirements [ ]. Therefore, it is an advanced regulatory structure in the executive functional neural network [ ]. In concordance with this, non-invasive imaging implies that the cingulum bundle is involved in executive control, as well as emotion, pain, and episodic memory. Clinical studies indicate that abnormalities in the cingulum may manifest as numerous conditions, including post-traumatic stress disorder schizophrenia, depression, obsessive-compulsive disorder, mild cognitive impairment, autism spectrum disorder, and Alzheimer\u2019s disease [ ]. Moreover, one study detected significant cortical atrophy in patients with AMD at long-term follow-up, with a decline in mean cortical volume across the whole occipital lobe. And what\u2019s significant is this decline could be explained by cortical thinning of the lesion projection zone [ ]. \n\nResting-state fMRI and fractional ALFF scores were utilized by a former study to explore the neural mechanism of perceived stress in 234 healthy adolescents [ ]. A positive correlation was found between perceived stress grades and the fractional ALFF measures at the left middle frontal gyrus, which remained after adjusting for the influence of positive and negative emotions [ ]. \n\nImportantly, the left middle frontal gyrus can facilitate the connection between perceived stress and depression [ ]. Furthermore, an activation likelihood estimation meta-analysis found a negative correlation between migraine severity and GMV in the left middle frontal gyrus and the bilateral inferior frontal gyri. Consistent with this, GMV reduction in the left middle frontal gyrus is also related to the estimated frequency of headache [ ]. These findings together with the present results suggest that nAMD patients are liable to suffer from mental health disorders and headaches. Clinicians should be aware of this potential link when treating and managing patients with nAMD. Also, Charles Bonnet syndrome (CBS) is generally defined as the occurrence of recurrent complex visual hallucinations. It is a prevalent condition in patients with nAMD. Some researches indicated that the overall prevalence of CBS in patients with nAMD to be 15.8%\u2014around one in six [ ]. While it\u2019s unfortunate that when measured in a population of patients with nAMD, awareness of CBS is limited and it may be difficult for clinicians to link CBS with it. Thus, according to clinical practice, we should understand the fact that CBS is relatively common in patients with nAMD and should consider providing help and relief for them. \n\n### Summary \n  \nAs investigated above, we have discovered that declined GMV values in certain areas in patients with nAMD indicated that they might suffer from mental sickness. Thus, unusual alternation in those areas can be symbolized as valuable clinical indices. However, our article also has some limitations. For example, we only took samples from one hospital and the number of samples was also small, which presented limitations of research scope and sample size. Also, while we have found loss of frontotemporal volume in the nAMD cases studied here which was associated with mildly raised HADS scores, the statistical approach used is suboptimal and liable to false positives. In the future, we will use more scientific methods to solve the problem. \n\n\n\n## MATERIALS AND METHODS \n  \nThis study recruited eighteen (9 men, 9 women) patients with nAMD from the Nanchang University\u2019s First Affiliated Hospital. HADS scores were collected from those patients. They are composed of 14 items, including 7 items of self-rated anxiety scale and 7 items of self-rated depression scale. The inclusion criteria are as follows: (1) age \u2265 55 years old; (2) meeting the diagnostic criteria for nAMD. Patients meeting the following criteria were excluded: (1) history of ocular trauma or surgery; (2) previous treatment for nAMD such as intravitreal injection with anti-VEGF; (3) other retinal vascular diseases; (4) other ocular diseases decreasing the efficacy of injection; (5) history of myocardial infarction, stroke or other systemic diseases that are contraindications for injection. \n\nEighteen age- and education-matched healthy control subjects (9 men, 9 women) were recruited based on the following criteria: (1) no ocular diseases (such as maculopathy, diabetic retinopathy, cataract or glaucoma); (2) corrected monocular visual acuities >1.0 decimal; (3) no indications for fMRI. The patients and their family members were familiarized with the research protocol and signed a declaration of informed consent before each procedure ( ). The study was conducted in accordance with the tenets of the Declaration of Helsinki and was approved by the medical ethics council of the Nanchang University\u2019s First Auxiliary Hospital. \n  \n Example of choroidal neovascularization and macular scar caused by neovascular age-related macular degeneration seen on fundus camera and fluorescence fundus angiography.   Abbreviations: FC, fundus camera; FFA, fluorescence fundus angiography; ICGA, indocyanine green angiography. \n  \n### MRI parameters \n  \nTo perform the MRI scanning, a three-Tesla scanner (Trio; Siemens, Munich, Germany) was utilized to record high-definition cross-sectional weighted T1 images. The whole-brain image was obtained with a rapid-gradient echo sequence in 176 1.0 mm slices with the following parameters: echo time=2.26 ms; replication time=1900 ms; flip angle=9\u00b0; visual field=215\u00d7230 mm; gap=0 mm. The whole scanning process was operated by the same neuroradiologist throughout. \n\n\n### Image processing \n  \nMRIcro software ( ) was used to eliminate fragmentary data. The configurable images were analyzed using statistical parametric mapping (SPM 8) ( ) tools within MATLAB 7.9.0. Software (R2009b; The Mathworks, Inc., Natick, MA, USA). Using (VBM8) ( ), the brain regions can be separated into white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) utilizing the default estimation selections (minimum deflection normalization; 60 mm interception for the calculation of Gaussian evenness of graphic intention; and the original European template for affine conversion of the International Consortium for Brain Mapping [ICBM]). The Diffeomorphic Anatomical Registration Through Exponentiated Lie (Dartel) algebra method in VBM8 was used for the normalization of the Montreal Neurological Institute (MNI) standard space. The Dartel method was used to generalize the GM and WM templates and normalize the GM and WM of each participant with these templates. A 6 mm full-width half-maximum Gaussian was used for smoothing. Standardized, adjusted and flattened graphs were subjected to group-standard analysis. \n\n\n### Statistical analysis \n  \nAfter accounting for age and sex, we conducted a general linear model (GLM) analysis with the SPM8 toolbox to compare GM and WM between patients with nAMD and HCs. Gaussian random field (GRF) theory was used for large-scale comparison rectification (GRF calibrated, minimal z>2.3, voxel standard P<0.01, cluster standard P<0.05). To generate color-coded images, the voxels with statistical significance were superimposed on the fast acquisition gradient echo sequence (3DT1WI) of standardized three-dimensional images. \n\nThe receiver operating characteristic (ROC) curves of each brain region were compared to evaluate the average redistribution value. The objective of correlation analysis was to explore the relationship between the values in different regions (P < 0.05). \n\n\n### Brain behavior \n  \nBased on the VBM results, REST software (version 1.8) was utilized to partition distinct brain regions into multiple regions of interest (ROIs). Within each ROI, the median gray matter volume (GMV) value of all voxels was calculated. In the nAMD group, correlation analyses were used to look for associations between the median GMV values and clinical symptoms. \n\n\n### Clinical behavior \n  \nClinical data including nAMD disease duration (months since the first symptom) and hospital anxiety depression scale (HADS) scores were collected. The SPSS 20.0 software was used to compare data using an independent samples t-test. \n\nIn all analyses, P values less than 0.05 were considered statistically significant. \n\n\n### Ethical statement \n  \nAll research methods were approved by the committee of the medical ethics of the First Affiliated Hospital of Nanchang University and were in accordance with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. All subjects were explained the purpose, method, potential risks and signed an informed consent form. \n\n\n \n\n# Table(s)\n## ID: t1\n### Label: Table 1\nUnnamed: 0\tnAMD\tHC\tt-value\tp-value\nMale/female\t9/9\t9/9\t\t>0.99\nAge(years)\t55.74\u00b15.32\t56.24\u00b15.43\t0.311\t0.802\nHandedness\t18R\t18 R\t\t>0.99\nDuration (M)\t1.16\u00b10.41\t\t\t\nBest-corrected VA-L\t0.10\u00b10.05\t1.05\u00b10.15\t7.344\t0.001\nBest-corrected VA-R\t0.15\u00b10.05\t0.95\u00b10.15\t5.433\t0.003\nIOP-L\t14.59\u00b16.61\t14.26\u00b14.22\t1.657\t0.134\nIOP-R\t13.63\u00b15.27\t13.17\u00b14.26\t1.764\t0.119\n### Caption\nDemographics and behavioral results of nAMD and HCs groups.\n### Footer\nNotes: Independent t-tests comparing the age of two groups (P<0.05) represented statistically significant differences). Male/female and Handedness were analyzed using chi-squared test.Abbreviations: nAMD, neovascular age-related macular degeneration; HCs, healthy controls; N/A, not applicable; VA, visual acuity; R, right; L, left; IOP, intraocular pressure.\n\n\n## ID: t2\n### Label: Table 2\nBrain areas\tMNI coordinates\tMNI coordinates.1\tMNI coordinates.2\tNumber of voxels\tT value\nBrain areas\tX\tY\tZ\t\t\nHC>nAMD\t\t\t\t\t\nright inferior frontal gyrus\t37.5\t18.5\t-21.5\t74.0\t6.7939\nleft superior temporal gyrus temporal pole\t-46.5\t-5.5\t-11.5\t184.0\t7.2464\nleft superior temporal gyrus\t63.5\t-19.5\t-3.5\t209.0\t7.9122\nright inferior frontal gyrus\t43.5\t44.5\t0.5\t233.0\t7.8886\nleft middle frontal gyrus\t-32.5\t54.5\t0.5\t119.0\t6.9893\nleft anterior cingulate and paracingulate gyrus\t-0.5\t38.5\t20.5\t458.0\t9.5194\n### Caption\nBrain regions with significant differences in grey matter volume between nAMD group and HCs.\n### Footer\nAbbreviations: nAMD, neovascular age-related macular degeneration; HC, healthy controls.\n\n\n## ID: t3\n### Label: Table 3\nUnnamed: 0\tnAMD group\tHC group\tt\tP\nGMV\t594.11\u00b151.10\t645.71\u00b151.42\t2.736\t0.010\nWMV\t506.67\u00b158.30\t501.79\u00b146.65\t-0.248\t/\n### Caption\nGroup GMV differences between nAMD group and HC group.\n### Footer\nAbbreviations: nAMD, neovascular age-related macular degeneration; HC, healthy controls.\n", "metadata": {"pmcid": 8544331, "text_md5": "c95acaa95826c93f86eb0454c3be581e", "field_positions": {"authors": [0, 142], "journal": [143, 160], "publication_year": [162, 166], "title": [177, 334], "keywords": [348, 438], "abstract": [451, 2457], "body": [2466, 21484], "tables": [21497, 23358]}, "batch": 2, "pmid": 34623972, "doi": "10.18632/aging.203610", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8544331", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=8544331"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8544331\">8544331</a>", "list_title": "PMC8544331  Decreased gray matter volume and increased white matter volume in patients with neovascular age-related macular degeneration: a voxel-based morphometry study"}
{"text": "Berens, Sam C. and Bird, Chris M.\nHippocampus, 2017\n\n# Title\n\nThe role of the hippocampus in generalizing configural relationships\n\n# Keywords\n\nlearning\nmemory\npattern completion\nfMRI\n\n\n# Abstract\n  ABSTRACT  \nThe hippocampus has been implicated in integrating information across separate events in support of mnemonic generalizations. These generalizations may be underpinned by processes at both encoding (linking similar information across events) and retrieval (\u201con\u2010the\u2010fly\u201d generalization). However, the relative contribution of the hippocampus to encoding\u2010 and retrieval\u2010based generalizations is poorly understood. Using fMRI in humans, we investigated the hippocampal role in gradually learning a set of spatial discriminations and subsequently generalizing them in an acquired equivalence task. We found a highly significant correlation between individuals\u2019 performance on a generalization test and hippocampal activity during the test, providing evidence that hippocampal processes support on\u2010the\u2010fly generalizations at retrieval. Within the same hippocampal region there was also a correlation between activity during the final stage of learning (when all associations had been learnt but no generalization was required) and subsequent generalization performance. We suggest that the hippocampus spontaneously retrieves prior events that share overlapping features with the current event. This process may also support the creation of generalized representations during encoding. These findings are supportive of the view that the hippocampus contributes to both encoding\u2010 and retrieval\u2010based generalization via the same basic mechanism; retrieval of similar events sharing common features. \u00a9 2016 The Authors Hippocampus Published by Wiley Periodicals, Inc. \n \n\n# Body\n \nLearning relationships between features within the environment is central to complex behaviors such as navigation (Cohen and Eichenbaum,  ). However, it is often not sufficient to rely on information that was learnt within a single episode. Frequently, memories acquired across multiple episodes must be integrated to allow the expression of novel behaviors (Bunsey and Eichenbaum,  ). Such \u201cmemory generalizations\u201d are also fundamental to the formation of the context\u2010free memory structures that characterize semantic knowledge (Eichenbaum,  ). \n\nThe hippocampus has long been implicated in supporting memory generalization (Bunsey and Eichenbaum,  ). Broadly speaking, there are two classes of model that attempt to describe the role of the hippocampus in generalization. Encoding\u2010based models propose that when related events are encoded, their representations overlap with each other and therefore contain information that is common to all of the events (Shohamy and Wagner,  ). This results in unitary (or generalized) memory traces where the retrieval of any one detail automatically cues the retrieval of related features. In contrast, retrieval\u2010based models pose that study events are strictly \u201cpattern separated\u201d at encoding. Nonetheless, these models suggest that the hippocampus can engage \u201con\u2010the\u2010fly\u201d generalization where representational overlaps are inferred during retrieval (e.g., Kumaran and McClelland,  ). \n\nPrevious investigations have provided evidence for both encoding\u2010 and retrieval\u2010based accounts of hippocampal generalization (e.g., Shohamy and Wagner,  ; Preston et al.,  ). Indeed, it has been suggested that these models are not mutually exclusive. In particular, the hippocampus may initially form pattern separated representations which gradually become integrated over a period of memory consolidation (Zeithamova et al.,  ). Consolidation is associated with memory traces becoming more dependent on neocortical regions that underlie semantic memory (McClelland et al.,  ). This raises the possibility that generalization may sometimes depend on functions of the neocortex rather than the hippocampus. \n\nTo date, two studies have examined how the hippocampus and neocortex contribute to generalization over the course of both an initial learning phase and a generalization test (Zeithamova and Preston,  ; Zeithamova, et al.,  ). Both have provided good evidence for a mixed encoding/retrieval account. These studies used \u201crelational inference\u201d paradigms where hierarchical or pairwise relationships between stimuli must be inferred from training on a set of \u201cpremise pairs.\u201d This contrasts with simpler forms of generalization where novel discriminations are made on the basis that stimuli belong to particular \u201cequivalence classes.\u201d For example, if particular configurations of stimuli are always rewarded, then they belong to the same superordinate class of rewarded items. It remains unclear whether or not generalizations reliant on equivalence class membership depend on hippocampal and/or neocortical involvement at either study or test. We used fMRI to examine the brain mechanisms involved in gradually learning and subsequently generalizing a set of visual discriminations. In particular, we explored whether hippocampal and/or neocortical activity at encoding, retrieval, or both, was associated with generalizations between equivalence classes. \n\nTwenty\u2010three right\u2010handed students were recruited by way of online advertisement. All gave written informed consent to take part and were compensated for their time. Subjects had either normal or corrected\u2010to\u2010normal vision and reported no history of neurological or psychiatric illness. Of those who participated, eight did not exhibit sufficient levels of learning on the task to be included in the analyses (see below). As such, analyses reported here used data from 15 subjects (7 male) with a mean age of 23.8 years (SD\u2009=\u20094.14). The study was approved by the Brighton and Sussex Medical school's Research Governance and Ethics Committee. \n\nDuring scanning participants learned a set of visual discriminations via trial\u2010and\u2010error (learning phase), and were subsequently tested on their ability to generalize what they had learned (generalization phase). Both learning and generalization occurred within a single scanning session and took place in the context of a first\u2010person virtual reality environment (see Fig.  ). On each trial, a scene was presented depicting two buildings positioned equidistantly from a start location. One building concealed a pile of gold (the \u201creward\u201d). The location of this gold was determined by the configuration of wall textures rendered onto the towers of each building. Participants were required to select the rewarded building (within 3 s). Following a response, video feedback was presented (7 s) before an inter\u2010trial interval (1 s). The stimuli for the task were generated in Unreal Development Kit (Epic Games, 2012) and presented via the Cogent 2000 toolbox in MATLAB (Mathworks). \n  \nUpper: Details of the trained and generalized discriminations. Each capitalised letter refers to a unique wall texture as indicated by the three wall texture samples (left). The two tables list how wall textures were combined and which arrangements were rewarded. Each row within a table corresponds to a unique discrimination and vertical bars (i.e. |) indicate spatial arrangements within each building (\u2018X|Y' indicates \u2018X' to the left of \u2018Y'). The \u2018+' column denotes wall texture combinations that were rewarded while the \u2018\u2212' column denotes wall texture combinations that were unrewarded. Note: The reward was equally likely to be in the left or right building. Lower: Example of a trained discrimination within the virtual\u2010reality reality environment. [Color figure can be viewed at  ] \n  \nThree discriminations were learnt (see Fig.  ). In each discrimination there were two buildings and each building comprised two textures (in other words, each building was a \u201ccompound\u201d stimulus). Participants were required to learn not only which combination of textures was rewarded but also which spatial arrangement of textures was rewarded. For example, when texture A appeared with texture B, the building with A to the left of B was rewarded (A|B). However, when texture A appeared with texture C, the building with C to the left of A was rewarded (C|A). This form of \u201cstructural\u201d configural learning, which includes a spatial or temporal component, is thought to depend on hippocampal learning mechanisms (Sanderson et al.,  ; Aggleton et al.,  ). There were 48 trials per discrimination which were presented in a pseudorandom order. \n\nThe initial learning phase also included a set of non\u2010memory discriminations (location of gold visible at trial onset) and a further set of three discriminations that constituted a transverse patterning contingency (see Moses et al.,  ). However, these trials were not subject to a generalization test after leaning and are therefore not discussed in the current study. \n\nThe generalization phase involved 12 test trials. Here each rewarded wall texture configuration was presented alongside an unrewarded configuration that had only ever been trained in the context of a different discrimination (e.g., A|B+\u2009vs. A|C\u2212, see Fig.  ). As such, these trials involved making novel discriminations between stimuli on the basis of an equivalence class membership (rewarded vs. unrewarded). Encoding\u2010based models of generalization predict that during the initial training phase, participants not only learn specific relationships between texture combinations (A|B+\u2009vs. B|A\u2212), but also the superordinate equivalence classes (A|B+, B|C+, and C|A+\u2009all belong to a rewarded class whereas B|A\u2212, C|B\u2212, and A|C\u2212\u2009all belonging to an unrewarded class). Given this, we would expect brain activity during the initial training phase to be correlated with subsequent generalization performance. In contrast, retrieval\u2010based models predict that generalization depends on recalling trained associations when stimuli are presented in a novel combination. Under this view, we would expect brain activity during the generalization test itself to correlate with generalization performance. Relatively few generalization trials were run to ensure that participants did not develop a well\u2010practiced response to each trial type. \n\nBehavioral outputs from the task were binary sequences indicating correct versus incorrect responses on each trial. Trials were also coded as incorrect when no response was made within 3 s. For each discrimination of the initial learning phase, these binary sequences were then converted into learning curves using a state\u2010space smoothing model developed by Smith et al. ( ). This model indicates a \u201clearning trial\u201d defined as the first trial at which there is a significant level of certainty (  P  \u2009<\u20090.05) that a subject is performing above chance and the discrimination has been learnt. All participants included in the sample reached the learning trial for each discrimination at least five trials before the end of training (mean learning trial\u2009=\u200922.56, S.D.\u2009=\u20098.37). \n\nWe wished to group each trial of the experiment into one of four stages based on how many of the three discriminations had been learnt; from \u201cstage 0\u201d (prior to the learning trial of any discrimination), to \u201cstage 3\u201d (after all three discriminations had been learnt). Across participants, the mean (and S.D.) number of trials within each stage were as follows; Stage 0\u2009=\u200943.33 (23.39), Stage 1\u2009=\u200923.13 (22.75), Stage 2\u2009=\u200921.53 (20.50), Stage 3\u2009=\u200956 (33.79). Importantly, response times did not significantly differ between learning stage;   F  (3,42)\u2009=\u20091.125,   P  \u2009=\u2009.350. As such, it is unlikely that any BOLD effects coincident with learning stage are a result of differential reaction times. Performance on the 12 generalization trials was taken as the proportion of correct responses. Although each subject included in the analysis showed a high degree of learning on each of the directly trained discriminations, generalization performance was highly variable across subjects; mean proportion correct: 0.73, range 0.33\u20130.92. \n\nEncoding\u2010based models of generalization propose that new representations overlap with existing ones, such that the commonalities across different discrimination pairs are also represented. We therefore looked for brain regions where encoding\u2010related BOLD activity increased linearly with the number of discriminations that had been learnt. This pattern of results would be consistent with the notion that the representation of one discrimination automatically triggers the retrieval of overlapping discriminations that have been learnt by that stage. As an additional and stronger test of encoding\u2010based models, we carried out a between\u2010subjects\u2019 analysis to test whether BOLD activity during the final stage of learning (stage 3) correlated with subsequent generalization performance. \n\nThe imaging analyses were performed in SPM8 ( , see Supporting Information for details about the imaging protocols and pre\u2010processing). Following image pre\u2010processing, first\u2010level models of the fMRI data were produced that specified five regressors of interest; four of these modeled the trial onsets within each learning stage (i.e., stages 0\u20133) and an additional regressor modeled the trial onset of each generalization test trial. Nuisance regressors included motion parameters and a vector coding for drift in the MR signal. HRF amplitude estimates relating to each event of interest were then subject to group\u2010level analyses. \n\nAt the group level, we specified a mixed\u2010effects regression model that tested for linear increases in activity across the four learning stages (random intercepts for each subject were also modeled). This revealed four clusters showing the predicted linear increases, each significant after controlling for the family\u2010wise error rate at the cluster\u2010level (whole\u2010brain, map\u2010wide height threshold was   P  \u2009<\u20090.001); see Table   (upper) and Figure  . An unthresholded statistical image for this contrast can be viewed and downloaded at  . The analysis did not reveal any significant linear increases or decreases in hippocampal BOLD activity when either performing a small volume correction within an bilateral hippocampal ROI (Tzourio\u2010Mazoyer et al.,  ) or, averaging across all hippocampal voxels,   t  (14)\u2009=\u2009\u22121.285,   P  \u2009=\u20090.220. \n  \nLeft panel: Cluster in the left inferior temporal gyrus (ITG) exhibiting linear increases in activity as a function of the number of learnt discriminations. Right panel: Bar chart illustrating the ITG effect. Because the plot shows data selected by a whole\u2010brain analysis, the bars are a biased representation of the true effect size in this region. Error bars indicate 95% confidence intervals. [Color figure can be viewed at  ] \n    \nClusters Showing Linear Changes in BOLD Activity Across the Four Learning Stages \n  \nFor the clusters exhibiting activation increases as a function of learning stage, we, we next examined whether BOLD activity during stage 3 (i.e., the final stage of learning) was correlated with subsequent generalization performance (across participants). A significant positive association was detected in the inferior temporal gyrus but not in any other cluster,   r  (13)\u2009=\u20090.666,   P  \u2009=\u20090.028 (Bonferroni adjusted for four comparisons). This suggests that the region may be involved in representing overlapping associative information in a manner that supports mnemonic generalizations as specified by encoding\u2010based models. \n\nRetrieval\u2010based models of generalization propose that generalizations are carried out \u201con\u2010the\u2010fly\u201d (i.e., during novel tests) when problems cannot be solved by reproducing exactly what has been learnt. We therefore carried out a between\u2010subjects\u2019 analysis to identify the brain regions that were activated most by individuals who performed best on the generalization test. To examine this, the HRF amplitude estimates relating to generalization test trials were correlated with generalization performance at the second\u2010level. This revealed one cluster in the right posterior hippocampus showing a positive association (see Fig.  ). This effect was significant after controlling for the family\u2010wise error rate at the peak level within a bilateral hippocampal ROI (Tzourio\u2010Mazoyer et al.,  );   r  (13)\u2009=\u20090.861,   P  \u2009=\u20090.011, peak MNI coordinate\u2009=\u2009[24,\u221230, \u221206]). The unthresholded statistical image for this contrast can be viewed and downloaded at  . A Kolmogorov\u2013Smirnov test verified that the assumption of normally distributed errors had been met,   D  (15)\u2009=\u20090.143,   P  \u2009>\u20090.200. However, it is noteworthy that the performance of one subject was numerically below chance (i.e., <0.5) and that this subject yielded a relatively large regression\u2010residual. As such, we examined whether the hippocampal effect was robust to the removal of this data point. Even after excluding the outlier, the correlation remained significant;   r  (13)\u2009=\u20090.761,   P  \u2009<\u20090.001. No other significant effects were detected. \n  \nCorrelation between generalization performance and right hippocampal activity during the generalization test. [Color figure can be viewed at  ] \n  \nWe next explored whether the hippocampal region identified above showed a BOLD correlation with generalization performance during the final stage of learning (stage 3). A significant positive association was indeed found (  r  \u2009=\u20090.599,   P  \u2009=\u20090.018) suggesting that the region may also play a role in encoding\u2010based generalization. We further examined whether the hippocampal cluster exhibited linear changes in activity coincident with initial learning. Across the three learning stages, there was a marginally significant decrease in BOLD activity;   t  (44)\u2009=\u2009\u22121.98,   P  \u2009=\u20090.054. This latter result neither corroborates or rules out a role for the hippocampus in learning conjunctions between related discriminations, especially given that decreases in hippocampal BOLD may actually reflect successful associative binding (Olsen et al.,  ). \n\nGiven the above, an important possibility is whether the hippocampal generalization effects actually reflect the retrieval of specific reward contingencies rather than a generalization process per se. Indeed, our study was not ideally suited to examine associative generalization since participants could have solved the generalization task by retrieving the value of individual compound stimuli (e.g., A|B is rewarded). This would entail a form of \u201cstimulus\u201d generalization, that is, the extension of a prelearnt response across similar contexts. As such, while we did not detect any significant modulations of hippocampal BOLD over the course learning, it is possible that the hippocampal effects simply reflect better stimulus generalization in participants with the strongest representations of the original contingencies. However, we consider this to be unlikely. Participants\u2019 ability to generalize was uncorrelated with learning rate (as measured by the time to reach stage 3);   r  (13)\u2009=\u20090.19,   P  \u2009=\u20090.498. Furthermore, the hippocampal correlations with generalization at both stage 3 and the generalization test held after controlling for learning rate;   r  (12)\u2009=\u20090.649,   P  \u2009=\u20090.013, and   r  (12)\u2009=\u20090.843,   P  \u2009<\u20090.001 (respectively). Given these findings, we suggest that the hippocampus contributed to generalization performance over and above simply representing the directly trained associations. \n\nThe main focus of this study is on the role of the hippocampus in learning a set of related discriminations and generalizing them on the basis of equivalence class membership. We found no strong evidence for learning\u2010related BOLD changes within the hippocampus that would be consistent with encoding\u2010based models of generalization. However, it remains a possibility that the small number of subjects included in our final sample may have limited our ability to detect such effects. Nonetheless, during the generalization test, one hippocampal region showed a robust correlation between BOLD activity and individuals\u2019 ability to generalize. Importantly, the association between generalization performance and hippocampal BOLD was also present in the learning phase after all discriminations had been learnt. This suggests that representations necessary for accurate generalization may have been present in the hippocampus before there was any requirement to make generalizations. Although post\u2010hoc, this latter finding is partially supportive of an encoding\u2010based mechanism. \n\nTaken together, the results of our study support a role for the hippocampus in both \u201con\u2010the\u2010fly\u201d generalizations that are computed in novel situations and in generalizations during initial learning where the hippocampus activates information from previous events which share features relevant to the current event. Our results are therefore consistent with proposals that the hippocampus contributes to generalization at both encoding and test via the same fundamental mechanism (Zeithamova and Preston,  ; Zeithamova et al.,  ). \n\nThe region of the hippocampus associated with generalization in our study was midway along its length. Several neuroimaging studies have implicated the anterior hippocampus in generalization (Heckers et al.,  ; Shohamy and Wagner,  ; Schlichting et al.,  ). However, it may be that the site of hippocampal involvement in generalization depends on the nature of the information that must be generalized. It has been argued that the longitudinal axis of the hippocampus is characterized by a functional gradient whereby mnemonic representations that are more local to each other in space or time are coded by more posterior hippocampal regions (see, Strange et al.,  ). Moreover, associations between events that are closely related within a narrative structure may be represented by posterior parts of the hippocampus while associations between more distally related events are represented by anterior regions (Collin et al.,  ). It is therefore possible that the precise locus of hippocampal involvement in generalization depends on the nature of the associations that are being generalized. \n\nOutside of the hippocampus, learning\u2010related effects were observed in several regions, including two which are strongly implicated in semantic processing (the left angular gyrus [AG] and left inferior temporal gyrus [ITG]). Unlike the hippocampus, the ITG showed activation increases suggestive of gradually learning generalized memory traces. Interestingly, activity in this region also correlated with generalization performance during the initial learning phase. Damage to the ITG results in a loss of semantic knowledge (e.g., Mummery et al.,  ; Schwartz et al.,  ). Given this, we suggest that the left ITG may be responsible for storing integrated memory traces relevant to subsequent generalization. In contrast, the left AG is believed to play a role in matching the conjunctions of perceptual features to specific memory representations (especially in the light of competition from similar, overlapping representations; see Ansari,  ). \n\nWe also observed learning\u2010related effects in the ventromedial prefrontal cortex (vmPFC). Previous learning and generalization studies have shown that vmPFC activity and its connectivity with the hippocampus correlates with subsequent generalization performance, both during encoding and retrieval (Zeithamova and Preston,  ; Zeithamova et al.,  ). Furthermore, lesions to this region impair the ability to make transitive inferences (Koscik and Tranel,  ). One model suggests that the vmPFC acts to reactivate well\u2010established memories (i.e., schemas) when they are consistent with incoming information and to integrate new information into memory schemas (Van Kesteren et al.,  ). Thus the vmPFC, working in close association with the hippocampus, is able to create integrated knowledge representations that have been abstracted away from individual events that share common elements (see also, Schlichting and Preston,  ). \n\nTo conclude, our findings support the hypothesis that the hippocampus enables generalization, primarily though retrieving stimuli that share overlapping details. This occurs both in novel situations, when there is an explicit requirement to generalize, but is also present during learning, when similar stimuli might be assigned spontaneously to a superordinate equivalence class. \n\n## Supporting information \n  \n \n\n# Table(s)\n## ID: hipo22688-tbl-0001\n### Label: Table 1\nRegion\tPeak MNI [x, y, z]\tPeak t\tCluster size\nL Inferior temporal gyrus\t[\u221248, \u221209, \u221233]\t6.77\t132\nVentromedial prefrontal (L & R)\t[\u221215, +27, \u221209]\t6.57\t162\nL insula and white matter\t[\u221227, \u221257, +09]\t5.87\t187\nL angular gyrus\t[\u221242, \u221272, +45]\t5.78\t109\n### Caption\nClusters Showing Linear Changes in BOLD Activity Across the Four Learning Stages\n### Footer\nNone\n", "metadata": {"pmcid": 5324609, "text_md5": "89706380c9342ee53c6176e18888b7df", "field_positions": {"authors": [0, 33], "journal": [34, 45], "publication_year": [47, 51], "title": [62, 130], "keywords": [144, 184], "abstract": [197, 1771], "body": [1780, 24282], "tables": [24295, 24694]}, "batch": 2, "pmid": 27933668, "doi": "10.1002/hipo.22688", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324609", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5324609"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324609\">5324609</a>", "list_title": "PMC5324609  The role of the hippocampus in generalizing configural relationships"}
{"text": "Limsoontarakul, Sunsern and Campbell, Meghan C. and Black, Kevin J.\nParkinsons Dis, 2011\n\n# Title\n\nA Perfusion MRI Study of Emotional Valence and Arousal in Parkinson's Disease\n\n# Keywords\n\n\n\n# Abstract\n \n Background  . Brain regions subserving emotion have mostly been studied using functional magnetic resonance imaging (fMRI) during emotion provocation procedures in healthy participants. \n  Objective  . To identify neuroanatomical regions associated with spontaneous changes in emotional state over time.   Methods  . Self-rated emotional valence and arousal scores, and regional cerebral blood flow (rCBF) measured by perfusion MRI, were measured 4 or 8 times spanning at least 2 weeks in each of 21 subjects with Parkinson's disease (PD). A random-effects SPM analysis, corrected for multiple comparisons, identified significant clusters of contiguous voxels in which rCBF varied with valence or arousal.   Results  . Emotional valence correlated positively with rCBF in several brain regions, including medial globus pallidus, orbital prefrontal cortex (PFC), and white matter near putamen, thalamus, insula, and medial PFC. Valence correlated negatively with rCBF in striatum, subgenual cingulate cortex, ventrolateral PFC, and precuneus\u2014posterior cingulate cortex (PCC). Arousal correlated positively with rCBF in clusters including claustrum-thalamus-ventral striatum and inferior parietal lobule and correlated negatively in clusters including posterior insula\u2014mediodorsal thalamus and midbrain.   Conclusion  . This study demonstrates that the temporal stability of perfusion MRI allows within-subject investigations of spontaneous fluctuations in mental state, such as mood, over relatively long-time intervals. \n \n\n# Body\n \n## 1. Background \n  \nEven though Parkinson's disease (PD) is a neurodegenerative disease defined by motor features [ ], psychiatric sequelae are common such as depression, anxiety, and apathy [ ,  ]. Previous studies have shown alteration of emotional processing in PD including reduced emotional physiologic response [ ], impaired emotional word recognition [ ], and impaired arousal judgment but normal valence [ ]. The bulk of the evidence suggests that these changes result primarily from the degenerative process in the brain, and are not merely psychological reactions to disability [ ]. Pathologically, Braak and Del Tredici [ ] found that in PD clinical stages 1\u20133 (stage 4-5 pathologically), neurodegeneration could be seen in almost all areas of the brain including prefrontal cortex (PFC) and limbic system. Brain areas affected by PD that are hypothesized to cause emotional dysfunction including raphe nuclei, locus ceruleus, amygdala, mesolimbic, mesocortical, mesothalamic dopaminergic systems, and cingulate cortex [ ]. Furthermore, neuroimaging studies have shown that a decrease in dopamine transporter availability in left putamen was associated with a reduction of ventrolateral prefrontal cortex activity during emotional gesture recognition tasks [ ]. Lack of amygdala activation was observed by visual event-related potentials (ERPs) during facial expression recognition [ ]. Based on these data, emotional processing in PD may differ from that of healthy controls.  \n\nMost fMRI experiments on emotional processing used a variety of validated affective stimuli to elicit changes in mood; stimuli included pictures [ ], sounds [ ], and words [ ]. These studies have identified various brain regions involved in the emotional responses to these stimuli, depending partly upon the type of stimulus [ ,  ]. However, studies designed in this manner may identify brain regions involved in affective perception or naming rather than those that produce internal emotional states. Alternatively, the emotional states transiently induced by these artificial stimuli may be pale shadows of the emotional states people experience in response to spontaneous thoughts, real-life events, idiopathic mood disorders, or the cellular and pharmacological pathology of PD.  \n\nWe studied self-rated emotional valence and arousal in patients with PD on several occasions per subject, without attempting to induce specific emotional states. These patients were participating in a pharmacological perfusion MRI study of an adenosine A2a receptor antagonist and the dopamine precursor levodopa, but emotional ratings were obtained in the same drug and placebo conditions in each subject, allowing us to separate the effects of drug from spontaneous variance in emotional state across participants. The objective was to describe brain areas associated with naturalistic emotional state in PD. We hypothesized that spontaneous variation in self-rated emotional state would be accompanied by statistically significant changes in brain activity, as indexed by regional cerebral blood flow (rCBF) measured with perfusion MRI. \n\n\n## 2. Materials and Methods \n  \nThese data were collected during the course of a Phase IIa clinical and brain imaging study of the investigational adenosine A2a receptor antagonist SYN115, and the primary analyses of those data are reported elsewhere [ ,  ]. The results presented here have not been previously reported except in abstract form [ ]. \n\n### 2.1. Regulatory Approvals, Registrations, and Patient Consents \n  \nThis study was approved by the Washington University Human Research Protection Office. Written documentation of informed consent was obtained in advance from each subject. Levodopa and SYN115 were given under US FDA Investigational New Drug application (IND) number 78,230. \n\n\n### 2.2. Study Participants \n  \nFurther details appear in Black et al. [ ]. Briefly, 21 patients with Parkinson's disease (Hoehn and Yahr stages 1\u20133) on a stable dose of levodopa for 30 days were studied. Exclusion criteria included cognitive impairment indicated either by MMSE score <23 or estimated premorbid IQ <70 [ ,  ], neurological diseases other than PD, self-reported history of psychosis or mania, current depression indicated by Geriatric Depression Scale Short Form [ ] score >7, or current use of a dopamine agonist. All were Caucasian and right-handed, and 13 were male. Mean age was 60.8 years (range 44\u201373 years), mean duration of PD symptoms was 5.3 years (range 0.9\u201310.8 years), mean \u201coff\u201d UPDRS (placebo day, before levodopa) was 22.5 (range 7\u201351), and half had ever experienced dopa-induced dyskinesias. \n\n\n### 2.3. Study Protocol \n  \nParticipants were randomly assigned either (a) to take SYN115 twice daily for a week, wait 1 week (washout period), then take a matching placebo twice daily for a week, or (b) the reverse order. For 14 participants, each dose of active drug contained 60\u2009mg of SYN115, whereas 12 subsequent subjects (5 of whom had participated in the 60\u2009mg placebo study) received 20\u2009mg at each dose. Participants and staff were blind to assignment. \n\nOn the last day of each treatment week, participants abstained from food, caffeine, and antiparkinsonian medication overnight, but took the last dose of SYN115 or placebo at 6\u2009am at home. At the imaging center, they took 200\u2009mg carbidopa, and then underwent a set of clinical and MRI assessments. An intravenous levodopa infusion was then begun, dosed in such a way as to rapidly produce and then maintain a steady plasma concentration [ ], with a target concentration of 600\u2009ng/mL. At least 25 minutes after the levodopa infusion started, all MRI and clinical assessments were repeated while the levodopa infusion continued.  \n\nParticipants rated their emotional state in each of four conditions: (1) before and (2) during levodopa infusion (after carbidopa) while taking oral SYN115, and (3) before and (4) during levodopa infusion while taking placebo pills. In each of these 4 conditions, 8 perfusion MRI (CBF) scans were acquired. In 4 of the 8 scans in each condition, the participant fixated on a crosshair throughout the entire 2.73 minutes of each scan; half of these were white on black and half were black on white. In 2 scans, an 8\u2009Hz reversing circular checkerboard pattern surrounded the fixation crosshair, and in 2 scans the participant performed a 2-back letter working memory task for the entire scan. \n\n\n### 2.4. Visual Analog Scale (VAS) and Scoring of Emotional Valence and Arousal \n  \nThe circumplex model of emotion [ ] describes human emotional states in terms of two independent constructs called valence and arousal (also called valence and \u201cactivation,\u201d a term avoided here due to potential confusion with the homonymous word as used in the neuroimaging literature). The original model suggests but does not specify a numerical coordinate system for valence and arousal scores. For this study they were computed as follows. Participants rated various antipodal pairs of emotional descriptors from the circumplex model using VAS [ ] displayed on a computer. They were instructed to freely self-evaluate their current feelings by clicking on the scale for each pair of emotional descriptors. The VAS ratings were recorded on 100\u2009mm scales with anchor terms chosen from the original item set for 4 categories, that is, (a) negative valence, neutral arousal versus positive valence, neutral arousal (sad-happy, grouchy-cheerful); (b) negative valence, high arousal versus positive valence, low arousal (nervous-calm, distressed-relaxed); (c) negative valence, low arousal versus positive valence, high arousal (sluggish-lively, dull-excited); (d) neutral valence, high arousal versus neutral valence, low arousal (intense-tranquil, aroused-passive). For each VAS, the left item anchor was scored as 0 and the right anchor as 100. Subjects were advised to use the full 100\u2009mm VAS range for each item and to score how they felt \u201cat this moment.\u201d Valence and arousal scores were computed from the VAS-item scores by the following formulae: \n  \nvalence score = [average (a, b, c)/50]\u22121; possible range \u22121 to +1; \n  \narousal score = 1\u2212[average (b, 100\u2212c, d)/50]; possible range \u22121 to +1. \n  \n\n### 2.5. MRI Methods \n  \nAll MRI data were acquired on the Siemens 3T Tim Trio with matrix head coil. ASL images were acquired with the commercial Siemens pulsed arterial spin labeling (pASL) sequence [ ]; the center-to-center slice distance was 7.5\u2009mm. Details of image acquisition and transformation to scaled CBF images in atlas space are given elsewhere [ ]. \n\n\n### 2.6. Statistical Analysis \n  \nOnly those voxels were analyzed, that were represented in every EPI image in every subject. Statistical analysis of the CBF data was done via a two-level, random effects model using SPM8 software ( ). First, a voxelwise general linear model (GLM) was computed for each subject. This first-level GLM followed the method of Henson and Penny [ ] by including factors coding for each of the 16 possible combinations of drug (SYN115 or placebo), levodopa (before versus during infusion), and task (the 4 behavioral conditions described in Study Protocol, above). The GLM also included 3 covariates, representing the pertinent valence and arousal scores and their interaction. This approach partitions the variance from each subject's CBF data at a given voxel into components representing valence, arousal, and their interaction, plus components representing the nuisance variables drug, levodopa, task, and all their interactions. The   \u03b2   (model coefficient) images from each subject for the valence and arousal covariates became the input data for the final, second-level analysis. \n\nThe second-level (across-subjects) analysis was a voxelwise general linear model (GLM) that tested whether, across subjects, the mean   \u03b2   value for valence was significantly greater than zero, after controlling for sex, age, and dose group (60 versus 20\u2009mg SYN115 b.i.d. during the active drug week). A corresponding analysis tested whether mean   \u03b2   was significantly   less   than 0. The same analyses were done for arousal. Multiple-comparisons correction was performed at the cluster level with the false discovery rate (FDR) set at   P   = 0.05. Approximate anatomical locations were provided by the Talairach Daemon client ( ) [ ], with corrections by reference to the study-specific MRI template atlas image. \n\n\n\n## 3. Results \n  \n### 3.1. Valence and Arousal, and Their Association with Subject Characteristics \n  \nThe mean value for each VAS item and for the emotional valence and arousal scores are given in   and depicted on a diagram of the circumplex model of emotion ( ). Across conditions, participants tended to have positive valence, mean 0.375 \u00b1 0.339, and low arousal, mean \u22120.199 \u00b1 0.254 (in other words, they tended to be closer to cheerful and calm than to the opposite). Valence and arousal scores correlated negatively with each other (  r   = \u22120.31,   P   < .01); that is, subjects who were less aroused (more tranquil) tended also to be happier.  \n\n shows associations of valence and arousal with pharmacological status and demographic variables. SYN115 increased valence (  t  (25) = 2.57,   P   = 0.02) and valence decreased from before to on levodopa (  t  (25) = \u22122.26,   P   = 0.03), though the mean change in valence score with either drug was less than 5% of the available range. Demographic variables and PD factors were not significantly associated with emotional valence or arousal ( ). \n\n\n### 3.2. Perfusion MRI Data \n  \n#### 3.2.1. Correlations of rCBF with Valence \n  \nRandom-effects analysis revealed significant positive correlations of rCBF with valence across subjects. We found significant areas in prefrontal-subcortical circuits; that is, bilateral dorsolateral PFC, bilateral anterior cingulate cortices (ACCs), orbital frontal cortex, striatum, and thalamus. Other significant clusters were observed in cortical areas including left and right ventral frontotemporal regions, lateral parietal cortex, insula, right motor, and premotor areas (see   and Figures  \u2013 . \n\nAreas whose rCBF correlated negatively with valence included a part of ACC, bilateral subcallosal cingulate cortex (SCC), along with parts of caudate and putamen, bilateral inferior frontal gyri, bilateral superior parietal lobule (SPL), inferior parietal lobule, precuneus, and PCC (see   and Figures  \u2013 ). \n\n\n#### 3.2.2. Correlations of rCBF with Arousal \n  \nRandom-effects analysis of rCBF-arousal correlations found no voxels whose   t   value exceeded our predetermined voxel-level threshold corresponding to uncorrected   P   = 0.001. However, as an exploratory analysis, relaxing that initial threshold to a value corresponding to uncorrected   P   = 0.005 revealed several clusters that were significant after correction for multiple comparisons (  and Figures  - ). \n\n\n#### 3.2.3. Correlations of rCBF with the Interaction of Valence and Arousal \n  \nA random-effects analysis of the valence \u00d7 arousal interaction found no activated clusters significant at   P   < 0.05 after correction for multiple comparisons. \n\n\n\n\n## 4. Discussion \n  \nThis study found a number of brain regions whose activity increased or decreased with changes in self-rated current mood state. Emotional state ratings, drew on the face validity and experimental history of the circumplex model of emotion [ ], augmented here by a numerical implementation of the valence and arousal constructs. The conservative statistical approach employed for this analysis lends credence to the results and uses general linear modeling to minimize the potential confounds of demographic variation (age and sex) and unrelated experimental manipulations (such as medication status). Additionally, the study design allowed us to study ecologically valid or \u201creal,\u201d that is, spontaneously experienced, internal emotional state, which may more faithfully reflect patients' day-to-day experiences. \n\nOn the other hand, the study has a number of limitations, most of which derive from the fact that correlation of rCBF with current emotional state was not a primary goal of the data collection. Mood ratings were not done within the scanning session itself, but rather within a half hour or so, under broadly similar physiological conditions. This may have added noise to our results, so that we may have failed to detect some true correlations. Second, valence and arousal scores were (inversely) correlated, interpretation of results related to one emotional dimension might also be a result of changes in the other. However, the inclusion in our SPM model of a valence-arousal interaction should help disentangle their relation to rCBF. The correlation also tends to restrict the range of emotional states sampled. For that and perhaps other reasons, the range of emotional states reported by the subjects in our data did not equally sample all quadrants of emotional experience. Specifically, there was a bias of positive over negative valence, and low over high arousal. As a consequence, negative correlations with valence came primarily from data with positive values. Additionally, we cannot comment conclusively on whether regions identified as correlating with self-rated mood in this study are specific to PD, since we did not include healthy control subjects. \n\n### 4.1. Nonimaging Results \n  \nEmotional rating in our participants tended towards positive valence and low arousal ( ,  ). We did not test whether this differed from a control group. However, Drago et al. [ ] show that non-demented PD patients under-rate arousal in others' facial expressions, compared to healthy control subjects, and that their spatial judgments are less affected than controls' by emotional stimuli. Imaging studies have shown decreased activation of emotional regions to emotional faces or gestures [ ]. These findings may correspond to observations that PD patients actually experience lower emotional arousal, along with other manifestations of apathy [ ,  ].  \n\nThe slight improvement in mood with SYN115 is not surprising given that it is an adenosine 2a antagonist (caffeine is a nonspecific adenosine antagonist). The small decrease in valence on levodopa may seem counterintuitive, depression and anxiety commonly attend wearing off of individual levodopa doses in PD [ ]. However, on-levodopa data were always collected a few hours after the off-levodopa data, and if subjects were merely less enthusiastic later in the study day, as one might expect, then valence and arousal would be lower, causing an apparent association with levodopa. \n\nThe lack of correlation of UPDRS with mood ratings may be a Type II error, but is consistent with other data suggesting that, contrary to common expectation, motor impairment is at best a modest predictor of mood state in PD [ ]. \n\n\n### 4.2. Regions Associated with General Emotional Processing \n  \nOur study revealed a number of neural substrates associated with naturalistic emotional state; that is, (a) medial frontal PFC/ACC\u2014subcortical circuit\u2014medial PFC/ACC, basal ganglia, and thalamus; (b) limbic and paralimbic\u2014amygdala, hippocampus and parahippocampal gyrus, thalamus, mamillary body, and PCC, insula, parietal, and lateral PFC; (c) visual system\u2014occipital and temporal cortex. These regions are generally in line with previous studies in healthy controls.  \n\nIn a meta-analysis of functional neuroimaging studies of human emotions by Phan et al. [ ,  ], medial frontal PFC (BA 9, 10) was activated in response to nonspecific emotion. In other words, this region was involved in emotional processing regardless of valence, arousal, or induction method. In the present study, we found some brain regions that contained activations associated with either arousal or valence, such as basal ganglia (BG), thalamus, and parietal lobe. Basal ganglia were correlated with happiness induction in 70% of the studies, and disgust induction in 60% [ ] as well as responded to arousal stimuli evidenced by fMRI and skin conductance response (SCR) [ ]. The thalamus is connected to BG, ACC, medial frontal PFC, orbital PFC, and dorsolateral PFC, forming several frontal-subcortical circuits [ ]. The ACC is also closely interconnected to medial PFC. Lesions in the anterior cingulate\u2014subcortical circuit can produce apathy [ ], and the apathy experienced by PD patients who undergo subthalamic (STN)\u2014deep brain stimulation (DBS) has been attributed to dysfunction of medial PFC [ ,  ]. In addition, the thalamus links other structures in the limbic system, which is responsible for fundamental instinctive behaviors, cognition, and emotion, by receiving input from amygdala, basal forebrain, cerebellum, hippocampus, and septal nuclei, and projecting to prefrontal, cingulate, and parietal cortex [ ]. Therefore, the BG, thalamus, and parietal cortex might be related to general emotion processing as a part of this network. \n\n\n### 4.3. Associations between Valence and rCBF \n  \nWe found regions in limbic and paralimbic structures\u2014amygdala, medial PFC/rostral ACC, lateral PFC, and insula\u2014that were positively correlated with valence; whereas subcallosal and posterior cingulate cortex (SCC and PCC) were negatively correlated with valence. \n\n#### 4.3.1. Positive Correlation with Valence \n  \nAmygdala responses to valence or arousal stimuli have varied. Although amygdala response was related to arousal stimuli [ ], and over 60% of studies reported amygdala activation in response to fear induction [ ,  ], other studies have found activation to happy faces [ ] or have linked amygdala activity to both valence and arousal [ ,  ]. Thus, it may respond to salient characteristics of emotion. However, we found amygdala rCBF positively related only to valence. According to the neuropathological staging of PD (stages 1\u20136) proposed by Braak and colleagues [ ], amygdala dysfunction first appears in presymptomatic stage 3 in a particular region. In addition, dopamine is lost in the amygdala due to degeneration of the ventral tegmental area in PD. In fact, loss of dopaminergic innervation of amygdala and other limbic structures were observed in PD subjects diagnosed with major depression [ ], and dopamine modulates the response of amygdala to fearful stimuli in PD patients with depression [ ].  \n\nThe ACC is known to be involved in a form of attention that serves to regulate both cognitive (dorsal) and emotional (ventral) processings [ ]. Valence perception has been reported to be normal in nondemented and nondepressed PD patients [ ], thus, the activity in medial frontal PFC might reflect activation of circuits involved in valence-related attention or decision making. \n\n\n#### 4.3.2. Negative Correlation with Valence \n  \nSubcallosal cingulate cortex was associated with sadness in about 46% studies [ ], in line with our results. Clinically, patients with more than 3 episodes of untreated MDD had smaller SCC volume than controls [ ,  ], and DBS of SCC may benefit treatment resistant depression [ ]. \n\nPosterior cingulate cortex was also negatively correlated with valence. PCC has been linked to emotional processing and is thought to enhance memory for emotional stimuli [ ]. A study that controlled for nonemotional, memory enhancing stimulus features suggested that this region might mediate interactions of emotional and memory-related processes [ ]. Activity in PCC has also been reported to correlate with severity of anxiety symptoms in major depression and obsessive-compulsive disorder [ ,  ] and was associated with levodopa dose-related mood fluctuations in PD patients [ ]. \n\n\n\n### 4.4. Associations between Arousal and rCBF \n  \nWe adopted a more permissive first-stage threshold to find any regions in which rCBF correlated with emotional arousal. The approach is reasonable, but as this threshold differs from the prespecified methods, the arousal results should be taken with a grain of salt. \n\nThe rCBF in hippocampus and middle temporal gyrus correlated positively with arousal in the present study, consistent with the study of Nielen et al. [ ]. The connection with hippocampus may relate to observations that arousal can modulate memory [ ].  \n\nResults from prior studies were arguable whether occipital lobes actually responded to valence or to arousal. The studies of Mour\u00e3o-Miranda et al. [ ] and Lane et al. [ ] found that visual processing could vary with either valence or arousal, consistent with our findings, in which lingual gyrus was also associated negatively with valence, whereas others found occipital activation only when participants were presented stimuli of negative valence [ ,  ]. The activation of the visual system with emotional valence and arousal may be that both can increase attentional processing. Emotional and attentional processings both involve medial frontal PFC, and a variety of functional neuroimaging studies have suggested that attention modulates activity of extra-striate visual cortex [ ]. Moreover, threat stimuli lead to increased perceptual processing [ ]. Our data might extend prior knowledge that current internal emotion, and not just visually presented emotional stimuli, may enhance visual system activity. \n\n\n\n## 5. Conclusion \n  \nEmotions are usually regarded as brief but intense responses to changes in the environment featuring a number of subcomponents: (a) cognitive appraisal, (b) subjective feeling, (c) physiological response, (d) expression, (e) action tendency, and (f) regulation [ ]. In addition, emotional stimulation can be of an interoceptive or exteroceptive nature. Different methods used to provoke emotional state changes can activate different systems. For example, the recall method activated mostly ACC and insula, whereas amygdala and occipital lobe were activated by visual induction [ ]. \n\nMany neuroimaging studies of emotion in healthy volunteers have used clever methods to transiently stimulate emotional perception or attempt to quickly induce a given emotional state. Some experimental designs were chosen in part due to the limitations of blood oxygen level dependent (BOLD) fMRI, namely, its nonquantitative nature and the marked decline in signal-to-noise ratio of BOLD signal at time intervals greater than a few minutes. \n\nThe use of ASL perfusion fMRI enabled us to study within-subject fluctuations of internal mood states over relatively long periods of time (hours to weeks), a study design that is not possible with BOLD fMRI. Since we studied self-perceived emotional state without intentional provocation of a specific emotion, we could examine the effect of \u201csubjective feeling\u201d while being minimally confounded by other emotional processes. Furthermore, the rated emotion might be as a result of both \u201cinteroceptive\u201d and \u201cexteroceptive\u201d natural stimulation that might result in stronger and more regions emotional stimulation, as compared to only one induction method alone. Despite the limitations of this study, it may demonstrate the potential utility of perfusion fMRI in the study of emotion. \n\n \n\n# Table(s)\n## ID: tab1\n### Label: Table 1\nVisual analog scale\tMean, mm (range)\n(1) Sad-happy\t72.721 (8\u2013100)\n(2) Grouch-cheerful\t77.471 (19\u2013100)\n(3) Nervous-calm\t72.000 (5\u2013100)\n(4) Distressed-relaxed\t74.731 (11\u2013100)\n(5) Sluggish-lively\t55.010 (7\u2013100)\n(6) Dull-excited\t60.529 (23\u201396)\n(7) Intense-tranquil\t67.375 (0\u2013100)\n(8) Aroused-passive\t61.038 (1\u2013100)\nValence score\t0.375 (\u22120.333 to 0.967), SD 0.339\nArousal score\t\u22120.199 (\u22120.673 to 0.423), SD 0.254\n### Caption\nVisual analog scale scores for each emotion item pair.\n### Footer\nNone\n\n\n## ID: tab2\n### Label: Table 2\nUnnamed: 0\tValence\tArousal\tP (valence)\tP (arousal)\tN\u2020\nEffect of SYN115 (mean difference [unitless])\t+0.08\t+0.05\t0.02*\t0.08\t26\nOn levodopa minus pre-levodopa (mean difference [unitless])\t\u22120.06\t\u22120.04\t0.03*\t0.18\t26\nAge (correlation, r)\t0.09\t0.18\t0.70\t0.43\t21\nHoehn and Yahr stage (correlation, r)\t0.22\t\u22120.03\t0.34\t0.89\t21\nUPDRS (correlation, r)\t0.08\t0.08\t0.42\t0.41\t104\nSex (t-test)\t\t\t0.82\t0.92\t\nMale (mean)\t0.33\t\u22120.22\t\t\t13\nFemale (mean)\t0.30\t\u22120.20\t\t\t8\nPD symptoms worse on which side of body? (t-test)\t\t\t0.25\t0.34\t\nRight (mean)\t0.26\t\u22120.17\t\t\t13\nLeft (mean)\t0.43\t\u22120.28\t\t\t7\u2021\n### Caption\n Associations of valence and arousal with pharmacological status and demographic variables.\n### Footer\n*P \u2264 0.05.\u202021 people, 26 experiments (5 people participated twice, once for the 20\u2009mg b.i.d. study, once for the 60\u2009mg b.i.d. study), 4 UPDRS measurements per experiment (26 \u00d7 4 = 104).\u2021One subject was equally affected on left and right and was excluded from this analysis.\n\n\n## ID: tab3a\n### Label: None\nFDR-corrected P value\tNumber of voxelsa\tPeak T value (22\u2009d.f.)\tCoordinates of peak T value\tSide of brain\tAnatomical description of cluster\n<10\u221215\t674\t3.86\t28.5, 21, 18\tRight\tMiddle frontal gyrus (BA 8, 9), precentral gyrus, anterior cingulate (BA 32), insula, putamen, caudate\n0.001\t76\t3.86\t4.5, 57, 18\tBilateral\tMedial and superior frontal gyri (BA 10, 9)\n0.001\t97\t3.86\t\u221258.5, 3, 21\tLeft\tPrecentral gyrus (BA 6)\n0.002\t87\t3.86\t16.5, \u22123, \u22123\tRight\tMedial globus pallidus, ventrolateral thalamus, amygdala, frontal prepiriform cortex ventral to accumbens\n0.002\t82\t3.86\t\u221216.5, 6, \u221218\tLeft\tOlfactory area, parahippocampal gyrus, medial globus pallidus/thalamus border, thalamus, hypothalamus, substantia nigra\n0.053\t36\t3.85\t28.5, 42, \u22129\tRight\tMiddle frontal gyrus (BA 11)\n0.010\t56\t3.84\t\u221246.5, \u221260, 33\tLeft\tAngular gyrus and inferior parietal lobule (BA 39, 40)\n### Caption\n(a) Clusters in the brain in which CBF correlates positively with valence\n### Footer\n\naEach voxel contained 0.027\u2009mL.\n\n\n## ID: tab3b\n### Label: None\nFDR-corrected P value\tNumber of voxels\tPeak T value (22\u2009d.f.)\tCoordinates of peak T value\tSide of brain\tAnatomical description of cluster\n<0.0002\t117\t3.86\t\u221234.5, \u221242, 66\tLeft\tSuperior parietal lobule and precuneus (BA 7), postcentral gyrus (BA 5), posterior cingulate cortex (BA 31)\n<10\u22125\t178\t3.86\t\u221213.5, 12, 3\tBilateral\tSubcallosal gyrus (BA 25), left caudate and putamen\n0.007\t67\t3.86\t4.5, \u221275, 54\tRight\tSuperior parietal lobule and precuneus (BA 7), postcentral gyrus (BA 5)\n0.020\t46\t3.86\t\u221234.5, \u221215, 57\tLeft\tPrecentral gyrus (BA 6), postcentral gyrus (BA 3)\n0.014\t54\t3.86\t43.5, \u221239, 63\tRight\tInferior parietal lobule (BA 40), superior parietal lobule (BA 7), postcentral gyrus (BA 5)\n0.008\t63\t3.85\t43.5, 39, \u22126\tRight\tInferior frontal gyrus (BA 47)\u2014lateral frontal part\n0.020\t46\t3.85\t25.5, \u221263, 6\tRight\tLingual gyrus (BA 18, 19)\n0.036\t39\t3.85\t\u221237.5, 33, \u22126\tLeft\tInferior frontal gyrus (BA 47)\n0.043\t36\t3.83\t25.5, 24, \u22126\tRight\tInferior frontal gyrus (BA 47)\n### Caption\n(b) Clusters in the brain in which CBF correlates negatively with valence\n### Footer\nNote: Only clusters significant after correction for multiple comparisons are shown here.\n\n\n## ID: tab4a\n### Label: None\nFDR-corrected P value\tNumber of voxels\tPeak T value (22\u2009d.f.)\tCoordinates of peak T value\tSide of brain\tAnatomical description of cluster\n0.039\t84\t3.0\t31.5, \u22129, \u22126\tRight\tPutamen, thalamus (ventrolateral), hippocampus\n0.039\t85\t3.0\t\u221234.5, \u221275, 6\tLeft\tMiddle temporal gyrus (BA 39), middle occipital gyrus (BA 19)\n<0.0005\t231\t3.0\t\u221237.5, \u221257, 45\tLeft\tInferior parietal lobule (BA 40), superior occipital gyrus (BA 19)\n0.039\t100\t3.0\t34.5, \u221257, 39\tRight\tInferior parietal lobule (BA 40), superior parietal lobule and precuneus (BA 7)\n### Caption\n(a) Clusters in the brain in which CBF correlates positively with emotional arousal\u2020\n### Footer\nNone\n\n\n## ID: tab4b\n### Label: None\nFDR-corrected P value\tNumber of voxels\tPeak T value (22\u2009d.f.)\tCoordinates of peak T value\tSide of brain\tAnatomical description of cluster\n0.001\t216\t3.0\t\u221234.5, \u221227, 27\tLeft\tStriatum and nearby white matter, thalamus (medial dorsal), insula (BA 13)\n0.015\t110\t3.0\t\u221234.5, \u221260, 57\tLeft\tPrecuneus and superior parietal lobule (BA 7)\n0.005\t139\t3.0\t\u221225.5, \u22126, \u22129\tLeft\tPutamen, claustrum, insula (BA 13), amygdala-striatal transition area, superior temporal gyrus (BA 22, 38), inferior frontal gyrus (BA 47)\u2014ventral frontal part\n<10\u22127\t577\t3.0\t13.5, \u221245, \u22126\tRight\tSuperior and middle occipital gyrus, cuneus (BA 17, 18, 19), posterior cingulate cortex (BA 23), thalamus (medial dorsal), midbrain (central portion and red nucleus)\n0.005\t149\t3.0\t34.5, \u221281, 39\tRight\tSuperior parietal lobule and precuneus (BA 7)\n### Caption\n(b) Clusters in the brain in which CBF correlates negatively with emotional arousal\u2020\n### Footer\n\u2020No voxels passed the predefined voxel-level threshold of P < 0.001. For hypothesis generation, we repeated our analysis using a voxel-level threshold of P < 0.005, and those results are shown here.Note: only clusters significant after correction for multiple comparisons are shown here.\n", "metadata": {"pmcid": 3182403, "text_md5": "6595b807f8d3e14cd498027f37838102", "field_positions": {"authors": [0, 67], "journal": [68, 82], "publication_year": [84, 88], "title": [99, 176], "keywords": [190, 190], "abstract": [203, 1728], "body": [1737, 26804], "tables": [26817, 32422]}, "batch": 2, "pmid": 21969917, "doi": "10.4061/2011/742907", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3182403", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3182403"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3182403\">3182403</a>", "list_title": "PMC3182403  A Perfusion MRI Study of Emotional Valence and Arousal in Parkinson's Disease"}
{"text": "Wang, Zhiqun and Nie, Binbin and Li, Donghong and Zhao, Zhilian and Han, Ying and Song, Haiqing and Xu, Jianyang and Shan, Baoci and Lu, Jie and Li, Kuncheng\nPLoS One, 2012\n\n# Title\n\nEffect of Acupuncture in Mild Cognitive Impairment and Alzheimer Disease: A Functional MRI Study\n\n# Keywords\n\n\n\n# Abstract\n \nWe aim to clarify the mechanisms of acupuncture in treating mild cognitive impairment (MCI) and Alzheimer disease (AD) by using functional magnetic resonance imaging (fMRI). Thirty-six right-handed subjects (8 MCI patients, 14 AD patients, and 14 healthy elders) participated in this study. Clinical and neuropsychological examinations were performed on all the subjects. MRI data acquisition was performed on a SIEMENS verio 3-Tesla scanner. The fMRI study used a single block experimental design. We first acquired the baseline resting state data in the initial 3 minutes; we then acquired the fMRI data during the procession of acupuncture stimulation on the acupoints of Tai chong and Hegu for the following 3 minutes. Last, we acquired fMRI data for another 10 minutes after the needle was withdrawn. The preprocessing and data analysis were performed using the statistical parametric mapping (SPM8) software. Then the two-sample t-tests were performed between each two groups of different states. We found that during the resting state, brain activities in AD and MCI patients were different from those of control subjects. During the acupuncture and the second resting state after acupuncture, when comparing to resting state, there are several regions showing increased or decreased activities in MCI, AD subjects compared to normal subjects. Most of the regions were involved in the temporal lobe and the frontal lobe, which were closely related to the memory and cognition. In conclusion, we investigated the effect of acupuncture in AD and MCI patients by combing fMRI and traditional acupuncture. Our fMRI study confirmed that acupuncture at Tai chong (Liv3) and He gu (LI4) can activate certain cognitive-related regions in AD and MCI patients. \n \n\n# Body\n \n## Introduction \n  \nAlzheimer's disease (AD) is one of the most prevalent forms of dementia worldwide. The neuropathological changes of AD are characterized by amyloid-\u03b2 plaques, neurofibrillary tangles and neuronal loss  . Mild cognitive impairment (MCI) is the most important at-risk state of AD. It has a high probability of degenerating into AD at a rate of 10\u201315% per year  . However, There are no effective therapy for AD and MCI. Acupuncture, a treatment of traditional Chinese medicine (TCM), remains promising as an investigational therapy to treat neurological diseases including chronic pain, drug addiction, stroke as well as dementia  \u2013 . Despite its increasing usage of acupuncture, its underlying mechanisms are poorly understood. \n\nMost recent findings hint that sensitive neuroimaging and network analysis played a special role for understanding the pathophysiological mechanism of MCI and AD. Several resting-state fMRI studies have investigated the neuronal integrity in the brain of the AD or MCI patients by different methods. By using regions of interest (ROI)-based functional connectivity approaches, the researchers found reduced functional integrity related to hippocampus  \u2013 , prefrontal regions   and posterior cingulate cortex (PCC)  ,   in AD or MCI patients. Using independent component analysis (ICA), Greicius and colleagues   showed AD-related reduction of spontaneous brain activity within a default-mode network (DMN) including the PCC and medial prefrontal cortex (MPFC). Sorg et al.   found the DMN regions and executive attention network had markedly reduced brain activity in the MCI patients. \n\nNeuroimaging, in particular functional magnetic resonance imaging (fMRI), is a versatile tool that has been applied to investigate the mechanisms of acupuncture. Accumulating neuroimaging studies in humans have shown that acupuncture can modulate a widely distributed brain network  \u2013 , for example, Feng et al.   sought to investigate the functional correlations throughout the entire brain following acupuncture at acupoint ST36, they found that increased correlations for acupuncture were primarily related with the limbic/paralimbic and subcortical regions, whereas decreased correlations were mainly related with the sensory and frontal cortex. Zhong et al.   investigated modulatory effects of acupuncture at GB40 (Qiuxu) and KI3 (Taixi) on resting-state networks and found that acupuncture at different acupoints could exert different modulatory effects. Zhang et al   found that stimulating PC6 (Neiguan) can change the amplitude of the intrinsic cortical activity of the brain. They concluded that stimulating PC6 may be a candidate method for improving cognitive impairment due to the consistent effect of acupuncture within PCC. \n\nBased on the above knowledge, we can speculate that acupuncture may have a great effect on patients such as AD and MCI through modulating special brain network or brain regional activity. However, most of the acupuncture studies have been performed on healthy subjects, to the best of our knowledge; only two fMRI studies have been published on acupuncture effect in patients with AD and MCI  \u2013 .One previous study found that the temporal lobe, some regions of parietal lobe and cerebellum could be activated by acupuncture in AD patients  . Another recent fMRI study on MCI patients found the enhanced correlations in the memory-related brain regions following acupuncture  . In order to better understanding of the pathophysiology of AD and MCI, we sought to investigate the effect of acupuncture on the brain functional activity throughout the entire brain in AD and MCI patients compared to normal controls. We first identified regions showing abnormal brain activity in AD and MCI patients comparing to controls during the resting state. After that, we tested whether these regions could be modulated in AD and MCI patients in the procession of acupuncture. Finally, we explored whether there were any alterations or specific modulatory patterns after the acupuncture in AD and MCI patients by comparing the poststimulus resting state with the resting state. \n\n\n## Materials and Methods \n  \n### Subjects \n  \nThirty-six right-handed subjects participated in this study after giving written informed consent, including 14 patients with AD, 8 patients with MCI and 14 healthy controls. This study was approved by the Medical Research Ethics Committee of Xuanwu Hospital. The AD and MCI subjects were recruited from patients who had consulted the memory clinic at Xuanwu Hospital for memory complaints. The healthy elderly controls were recruited from the local community. \n\nAll AD patients underwent a complete physical and neurological examination, standard laboratory tests and an extensive battery of neuropsychological assessments. The diagnosis of AD fulfilled the Diagnostic and Statistical Manual of Mental Disorders 4th Edition criteria for dementia (American Psychiatric Association, 1994), and the National Institute of Neurological and Communicative Disorders and Stroke/Alzheimer Disease and Related Disorders Association (NINCDS-ADRDA) criteria for possible or probable AD (McKhann et al., 1984). The subjects were assessed with the Clinical Dementia Rating (CDR) score  , CDR of 1 and 2 was assigned to the AD category. \n\nParticipants with MCI had memory impairment but did not meet the criteria for dementia. The criteria for identification and classification of subjects with MCI   was: a) impaired memory performance on a normalized objective verbal memory test; b) recent history of symptomatic worsening in memory; c) normal or near-normal performance on global cognitive tests (MMSE score>24), as well as on an activities of daily living scale; (d) global rating of 0.5 on the CDR Scale, with a score of at least 0.5 on the memory domain; e) absence of dementia. \n\nHealthy controls met the following criteria: a) no neurological or psychiatric disorders such as stroke, depression and epilepsy; b) no neurological deficiencies such as visual or hearing loss; c) no abnormal findings such as infarction or focal lesion in conventional brain MR imaging; d) no cognitive complaints; e) MMSE score of 28 or higher; f) CDR score of 0. \n\nParticipants with contraindications for MRI such as pacemaker, cardiac defibrillator, implanted material with electric or magnetic system, vascular clips or mechanical heart valve, cochlear implant or claustrophobia were excluded. In addition, patients with a history of stroke, psychiatric diseases, drug abuse, severe hypertension, systematic diseases and intellectual disability were excluded. \n\n\n### Data acquisition \n  \nMRI data acquisition was performed on a SIEMENS verio 3-Tesla scanner (Siemens, Erlangen, Germany). The subjects were instructed to hold still, keep eyes closed and think nothing in particular. fMRI was acquired axially using an echo-planar imaging (EPI) [repetition time (TR)/echo time (TE)/flip angle (FA)/field of view (FOV)\u200a=\u200a2000 ms/40 ms/90\u00b0/24 cm, image matrix\u200a=\u200a64\u00d764, slice number\u200a=\u200a33, thickness\u200a=\u200a3 mm, gap\u200a=\u200a1 mm, bandwidth\u200a=\u200a2232 Hz/pixel]. In addition, 3D T -weighted magnetization-prepared rapid gradient echo (MPRAGE) sagittal images were obtained (TR/TE/inversion time (TI)/FA\u200a=\u200a1900 ms/2.2 ms/900 ms/9\u00b0, image matrix\u200a=\u200a256\u00d7256, slice number\u200a=\u200a176, thickness\u200a=\u200a1 mm). \n\nOur study used a single block experimental design. We first acquired the baseline resting state data in the initial 3 minutes; we then acquired the fMRI data during the procession of acupuncture stimulation for the following 3 minutes. A silver needle of 0.30 mm in diameter and 25 mm long was inserted and twirled at the four acupoints of the human body -Tai chong (Liv3) on the dorsum of the left and right foot; He gu (LI4) on the dorsum of the left and right hand. We acquired fMRI for another 10 minutes after the needle was withdrawn ( ). \n   Experimental paradigm.    \n\n### Data analysis \n  \nfMRI post-processing was performed by a single experienced observer, unaware to whom the scans belonged. The preprocessing and data analysis were performed using the statistical parametric mapping (SPM8) software (Wellcome Department of Imaging Science;  ). The functional datasets of all patients and healthy controls were pre-processed using the following main steps. 1) Slice timing: the differences of slice acquisition times of each individual were corrected using slice timing. 2) Realign: the temporal processed volumes of each subject were realigned to the first volume to remove the head motion, and a mean image was created over the 317 realigned volumes. All participants had less than 3 mm of translation in x, y, or z axis and 1\u00b0 of rotation in each axis. 3) Spatial normalization: the realigned volumes were spatially standardized into the MNI (Montreal Neurological Institute) space by normalizing with the EPI template via their corresponding mean image. Then, all the normalized images were resliced by 3.0\u00d73.0\u00d73.0 mm  voxels. 4) Smooth: the normalized functional series were smoothed with a Gaussian kernel of 8 mm full width at half-maximum (FWHM). \n\nThe first level, for each smoothed individual image, was fixed effects analysis based on the general linear model with a box-car response function as the reference waveform convolved with the canonical hemodynamic response function. There are three experimental conditions comprising resting state (baseline), acupuncture stimulation and the second resting state after withdraw of the acupuncture needle. The contrasts of cerebral areas activation during these three conditions were created. The subject-specific contrast images were then used to perform the second level analysis based on the random effects. The two-sample t-tests were performed (1) between AD and healthy controls of baseline; (2) between MCI and healthy controls of baseline; (3) between acupuncture stimulation and baseline of AD group; (4) between acupuncture stimulation and baseline of MCI group; (5) between the resting state after withdraw of the acupuncture needle and baseline of AD group; (6) between the resting state after withdraw of the acupuncture needle and baseline of MCI group. Brain regions with significant BOLD changes in patients of all the six statistical analysis demonstrated above were yielded based on a voxel-level height threshold of p<0.001 (uncorrected) and a cluster-extent threshold of 5 voxels. \n\n\n\n## Results \n  \n### Demography and neuropsychological test \n  \nDemographic characteristics and neuropsychological scores were shown in  . There were no significant differences among the three groups in gender, age, and years of education, but the neuropsychological test such as Mini-Mental State Examination (MMSE) and Auditory verbal learning test (AVLT) scores were significantly different (  P  <0.01) among the three groups. \n   Characteristics of the AD, MCI patients and Normal controls.        \n\n### Regions showing increased or decreased activities in MCI, AD subjects comparing to normal subjects in resting state \n  \nWhen compared to normal subjects, increased activities in MCI patients were found in regions of the temporal lobe [left middle temporal gyrus(MTG) ], frontal lobe [left superior frontal gyrus(SFG), left middle frontal gyrus (MFG) and bilateral inferior frontal gyrus(IFG) ] and left lentiform nucleus; while decreased activities in MCI patients were found in regions of right cingulate gyrus and left fusiform gyrus(FG). In AD patients, left temporal lobe and left MFG showed decreased activities from that of normal subjects. The details of these regions see   and  ). \n   Regions showing abnormal activities in MCI subjects (a) and AD subjects (b) in resting state.  \nLeft in picture is left in the brain. The color scale represents t values. \n     Regions showing increased or decreased activities in MCI, AD subjects comparing to normal subjects in resting state.      \n\n### Regions showing increased or decreased activities in MCI and AD subjects in the procession of acupuncture comparing to resting state \n  \nWhen compared to resting state, MCI patients showed increased activities in regions of bilateral cerebellum posterior lobe (CPL), temporal lobe [bilateral MTG, bilateral FG, right parahippocampus (PHG), left inferior temporal gyrus(ITG) ], frontal lobe, parietal lobe[bilateral inferior parietal lobule (IPL) and right postcentral gyrus(PoCG) ] and occipital lobe. Additionally, MCI patients showed decreased activities in regions of bilateral CPL, temporal lobe, frontal lobe [(bilateral SFG, right MFG, left precentral gyrus (PrCG)], parietal lobe [(right PoCG, left paracentral lobule (PCL), left superior parietal lobule (SPL)], right lingual gyrus and limbic regions. The details of these regions see   and  \n   Regions showing increased or decreased activities in MCI subjects in the procession of acupuncture comparing to resting state.  \nLeft in picture is left in the brain. The color scale represents t values. \n     Regions showing increased or decreased activities in MCI subjects in the procession of acupuncture comparing to resting state.      \nIn AD patients, the regions of right CPL, bilateral frontal lobe, right inferior parietal lobule (IPL), right middle occipital lobe (MOG) showed increased activities from that of resting state. Additionally, In AD patients, the regions of right superior temporal gyrus (STG), right MTG, bilateral MFG and left brain stem showed decreased activities from that of resting state. The details of these regions see   and  . \n   Regions showing increased or decreased activities in AD subjects in the procession of acupuncture comparing to resting state.  \nLeft in picture is left in the brain. The color scale represents t values. \n     Regions showing increased or decreased activities in AD subjects in the procession of acupuncture comparing to resting state.      \n\n### Regions showing increased or decreased activities in MCI and AD subjects in the second resting state after acupuncture comparing to resting state \n  \nIn MCI patients, the regions of bilateral CPL, temporal lobe (bilateral FG, right MTG and right PHG), frontal lobe, right lentiform nucleus, left extra nuclear and right thalamus showed increased activity in the second resting state after acupuncture comparing to resting state. Additionally, decreased activity were showed in the regions of bilateral CPL, temporal lobe (bilateral MTG, left STG, right ITG and right FG), frontal lobe (left SFG, left IFG, bilateral PrCG, right MFG), parietal lobe (bilateral PoCG, left IPL, bilateral SPL, right angular) and occipital lobe [left superior occipital lobe(SOG), left cuneus]. The details of these regions see   and  . \n   Regions showing increased or decreased activities in MCI subjects after acupuncture comparing to resting state.  \nLeft in picture is left in the brain. The color scale represents t values. \n     Regions showing increased or decreased activities in MCI after acupuncture comparing to resting state.      \nIn AD patients, the regions of right CPL, temporal lobe (left ITG, right MTG), frontal lobe (bilateral SFG, left IFG, right MFG and bilateral PrCG), occipital lobe(right MOG), parietal lobe(bilateral SMG, right SPL) showed increased activity in the second resting state after acupuncture comparing to resting state. Additionally, decreased activity were showed in the regions of left CPL, bilateral PHG, right MFG, left lingual gyrus, right cingulate gyrus, left lentiform nucleus and right midbrain. The details of these regions see   and  . \n   Regions showing increased or decreased activities in AD subjects after acupuncture comparing to resting state.  \nLeft in picture is left in the brain. The color scale represents t values. \n     Regions showing increased or decreased activities in AD subjects after acupuncture comparing to resting state.      \n\n\n## Discussion \n  \nOur study used fMRI to study the regional brain activities in MCI patients, AD patients and control subject under three conditions including resting state, acupuncture and resting state after acupuncture. All subjects underwent acupuncture at four acupoints of Tai chong (Liv3) and He gu (LI4) in left and right side. We found that during the resting state, brain activities in AD and MCI patients were different from those of control subjects. During the acupuncture, AD and MCI patients showed activation in regions consistent with impaired brain function. We also found that for the resting state after acupuncture, there are several regions showing increased or decreased activities in MCI, AD subjects comparing to normal subjects. Most of regions were involved in the temporal lobe and the frontal lobe, which were closely related to the memory and cognition. \n\n### Resting state brain activities in AD and MCI patients \n  \nOur study investigated the resting state activities in AD and MCI patients. Comparing to controls, the frontal lobe (SFG, MFG and IFG), the temporal lobe (MTG) and the lentiform nucleus showed increased activities in MCI patients. The frontal and temporal regions were considered as important components of human default-mode networks  \u2013  and have been shown to exhibit AD- and MCI-related structural and functional abnormalities. These increases in frontal and temporal lobe could be interpreted as compensatory reallocation or recruitment of cognitive resource. This result is compatible to previous studies which showed increased temporal activation in MCI and at-risk subjects relative to healthy controls  \u2013 . In addition, some regions such as cingulate gyrus and fusiform gyrus showed decreased activities in MCI patients comparing to controls, these changes represented the functional disruption of the above regions in the MCI patients. \n\nInterestingly, AD patients showed different patterns of resting state activities from MCI patients. The temporal lobe and left MFG showed decreased activity in AD patients, which appeared to reflect a continuous breakdown of spontaneous brain activity during disease progression, consistent with previous studies  ,  ,  ,  ,  . Hence, the increased frontal lobe and temporal activation has been postulated as compensatory mechanisms in MCI patients. On the other hand, the temporal lobe and left MFG exhibited decreased activities with the progression of the disease in AD patients. \n\n\n### Brain activities in AD and MCI patients in the procession of acupuncture \n  \nIn the current study, in order to demonstrate the value of acupuncture, we only focused on the regions which showed different activity in AD and MCI comparing to normal controls in the resting state. In MCI patients, we mainly explored changes of the left SFG, the left MFG and bilateral IFG, left MTG, the left lentiform nucleus as well as the right cingulate gyrus and left FG. In AD patients, we only focused on the left temporal lobe and left MFG. \n\nDuring acupuncture, a lot of regions including the temporal lobe, the frontal lobe, the occipital lobe and the CPL showed increased activities in MCI patients comparing to the resting state. Most of these regions were related to the cognitive impairment. We noticed that the FG and cingulate gyrus were activated. On the other hand, several regions showed decreased activities in MCI patients, among these regions, we noticed that left SFG and right IFG showed decreased activities in MCI patients. To our knowledge, there were only a few previous studies using fMRI technique to explore the acupuncture effect on MCI patients. In our study we firstly found that acupuncture can modulate the brain activity in MCI patients bilaterally. That is to say, it can activate the regions which showed decreased activity in the resting state in MCI patients. It can also deactivate the regions which showed increased activity in the resting state in MCI patients. \n\nDuring acupuncture, several regions showed increased or decreased activities in AD patients comparing to the resting state. However, the regions of left temporal lobe and left MFG were not be involved. We speculated that these regions probably can't be activated by the current acupoints. Future study is needed to elucidate its mechanism. \n\n\n### Brain activities in AD and MCI patients in the second resting state after acupuncture \n  \nIn order to examine the post-effect of the acupuncture, we also studied brain activities in AD and MCI patients in the resting state after acupuncture. A lot of regions including the temporal lobe, the frontal lobe, the limbic regions and the CPL showed increased activities in MCI patients comparing to the resting state. Most of regions were involved in the temporal lobe and the frontal lobe, which were closely related to the memory and cognition, Except for these above regions, thalamus were also activated in the procession of acupuncture in MCI patients. Zhang et al. showed that thalamus is a vital region that integrates neural activity from widespread neocortical inputs and outputs, and modulate and facilitate communication in all areas of the cerebral cortex  . One of our recent studies showed that disruption between the thalamus and posterior cingulate cortex (PCC) in MCI suggested the cognitive decline  . We noticed that the FG was activated, which showed decreased activity in the resting state. On the other hand, several regions showed decreased activity in MCI patients comparing to the resting state. Among these regions, we noticed left MTG and left IFG presented decreased activity, which showed increased activity in the resting state. This was similar with the brain activities in MCI patients in the procession of acupuncture. \n\nAfter acupuncture, several regions showed increased or decreased activities in AD patients comparing to the resting state. \n\nThe activated regions include the frontal lobe, the occipital lobe, the parietal lobe and the temporal lobe. We noticed the region of left temporal lobe (ITG) was involved, which showed decreased activity in resting state. In addition, we also noticed the region of left temporal lobe (PHG) showed decreased activity after acupuncture. We speculated that the temporal lobe, as is subjected to be impaired in AD patients, was activated to compensate for the cognitive impairment. \n\n\n### Conclusions \n  \nIn conclusion, we investigated the effect of acupuncture in AD and MCI patients by combing fMRI and traditional acupuncture. Our fMRI study confirmed that acupuncture at Tai chong (Liv3) and He gu (LI4) can activate certain cognitive-related regions in AD and MCI patients. \n\n\n \n\n# Table(s)\n## ID: pone-0042730-t001\n### Label: Table 1\nCharacteristics\tAD\tMCI\tNOR\tP value\nN (M/F)\t14(4/10)\t8(3/5)\t14(6/8)\t-\nAge, years\t66.92\u00b18.91\t66.37\u00b110.96\t66.07\u00b15.78\t0.96???\nEducation, years\t10.07\u00b13.38\t10.62\u00b13.54\t11.00\u00b14.52\t0.82???\nMMSE\t15.92\u00b14.32\t25.37\u00b11.30\t28.00\u00b11.41\t<0.01???\nAVLT(immediate)\t11.35\u00b13.95\t14.13\u00b13.52\t26.86\u00b15.24\t<0.01???\nAVLT(delayed)\t2.64\u00b11.59\t4.37\u00b11.59\t11.07\u00b12.76\t<0.01???\nAVLT(recognition)\t3.35\u00b11.55\t7.38\u00b13.11\t12.71\u00b12.09\t<0.01???\nCDR\t1\u20132\t0.5\t0\t-\n### Caption\nCharacteristics of the AD, MCI patients and Normal controls.\n### Footer\nMMSE, Mini-Mental State Examination; Plus-minus values are means \u00b1 S.D. AVLT, Auditory verbal learning test; immediate, immediate recall of learning verbal; delayed; delayed recall of learning verbal; recognition, recognition of learning verbal; CDR, clinical dementia rate.*The P values were obtained by one-way analysis of variance tests.\n\n\n## ID: pone-0042730-t002\n### Label: Table 2\nRegions\tBA\tCluster\tCoordinates (MNI)\tCoordinates (MNI)\tCoordinates (MNI)\tT-score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tSize\tx\ty\tz\tUnnamed: 6_level_1\nMCI vs. NOR\t\t\t\t\t\t\nLt. Middle Temporal Gyrus \u2191\t39\t16.0\t\u221257\t\u221267\t13\t3.94\nRt. Inferior Frontal Gyrus\u2191\t44\t127.0\t60\t5\t16\t5.46\nLt. Middle Frontal Gyrus \u2191\t6\t8.0\t\u221233\t14\t61\t4.05\nLt. Middle Frontal Gyrus \u2191\t10\t19.0\t\u221239\t59\t7\t3.78\nRt. Inferior Frontal Gyrus \u2191\t45\t6.0\t57\t29\t7\t3.64\nLt. Inferior Frontal Gyrus\u2191\t46\t7.0\t\u221248\t47\t4\t3.37\nLt. Superior Frontal Gyrus\u2191\t10\t12.0\t\u221218\t62\t25\t3.30\nLt. Superior Frontal Gyrus\u2191\t6\t16.0\t\u221215\t23\t64\t3.15\nLt. Lentiform Nucleus\u2191\t-\t6.0\t\u221215\t2\t\u22125\t3.28\nRt. Cingulate Gyrus\u2193\t-\t16.0\t12\t\u22124\t28\t\u22123.19\nLt. Fusiform Gyrus\u2193\t20\t6.0\t\u221230\t\u221237\t\u221223\t\u22123.15\nAD vs. NOR\t\t\t\t\t\t\nLt. Temporal Lobe \u2193\t20\t45.0\t\u221242\t\u221219\t\u221217\t\u22124.11\nLt. Middle Frontal Gyrus\u2193\t11\t12.0\t\u221236\t50\t\u221214\t\u22123.19\nAD vs. MCI\t\t\t\t\t\t\nLt. Middle Temporal Lobe\u2193\t21\t22.0\t\u221248\t\u221234\t\u22122\t\u22124.87\nLt. Middle Temporal Lobe\u2193\t21\t8.0\t\u221254\t5\t\u221223\t\u22123.55\nLt. Inferior Parietal lobule\u2193\t40\t54.0\t\u221260\t\u221249\t43\t\u22123.89\nLt. Middle Frontal Gyrus \u2193\t11\t29.0\t\u221230\t35\t\u221214\t\u22123.54\nRt. Precentral gyrus \u2193\t6\t8.0\t63\t\u22121\t31\t\u22123.34\nLt. Frontal Sub Gyral \u2193\t-\t9.0\t\u221212\t20\t\u22128\t\u22123.24\nLt. Superior Frontal Gyrus\u2193\t8\t6.0\t\u221233\t20\t58\t\u22123.08\n### Caption\nRegions showing increased or decreased activities in MCI, AD subjects comparing to normal subjects in resting state.\n### Footer\nNone\n\n\n## ID: pone-0042730-t003\n### Label: Table 3\nRegions\tBA\tCluster\tCoordinates (MNI)\tCoordinates (MNI)\tCoordinates (MNI)\tT-score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tSize\tx\ty\tz\tUnnamed: 6_level_1\nMCI vs. NOR\u2191\t\t\t\t\t\t\nLt. Cerebellum Posterior lobe\u2191\t-\t12.0\t\u221227\t\u221249\t\u221250\t4.77\nLt. Cerebellum Posterior lobe\u2191\t-\t109.0\t\u221236\t\u221270\t\u221241\t4.45\nRt. Cerebellum Posterior lobe\u2191\t-\t231.0\t51\t\u221264\t\u221238\t6.81\nRt. Cerebellum Posterior lobe\u2191\t-\t11.0\t36\t\u221240\t\u221244\t3.78\nLt. Cerebellum Posterior lobe\u2191\t-\t12.0\t\u22129\t\u221291\t\u221226\t4.03\nLt. Cerebellum Posterior lobe\u2191\t-\t6.0\t\u22123\t\u221261\t\u221217\t3.46\nLt. Middle Temporal Gyrus\u2191\t38\t24.0\t\u221248\t11\t\u221241\t4.35\nLt. Fusiform Gyrus\u2191\t19\t92.0\t\u221236\t\u221276\t\u221217\t5.55\nLt. Inferior Temporal Gyrus\u2191\t20\t5.0\t\u221239\t\u221213\t\u221226\t3.60\nRt. Parahippocampa Gyrus\u2191\t34\t53.0\t18\t\u221210\t\u221217\t5.98\nRt. Middle Temporal Gyrus\u2191\t21\t18.0\t60\t8\t\u221220\t4.47\nRt. Fusiform Gyrus\u2191\t19\t20.0\t36\t\u221270\t\u221217\t4.78\nRt. Middle Temporal Gyrus\u2191\t21\t7.0\t63\t\u221231\t\u221214\t3.41\nRt. Fusiform Gyrus\u2191\t19\t10.0\t21\t\u221255\t\u22128\t3.36\nRt. Middle Temporal Gyrus\u2191\t21\t43.0\t66\t\u221216\t\u22125\t4.39\nRt and Lt. Frontal Lobe\u2191\t10\t9324.0\t21\t44\t\u22122\t7.35\nLt. Occipital Lobe\u2191\t17\t25.0\t\u221212\t\u2212106\t4\t4.21\nRt. Occipital Lobe\u2191\t19\t54.0\t45\t\u221285\t4\t5.24\nRt. Occipital Lobe\u2191\t19\t212.0\t27\t\u221297\t22\t6.09\nLt. Inferior Parietal Lobule\u2191\t40\t12.0\t\u221251\t\u221240\t25\t3.85\nRt. Inferior Parietal Lobule\u2191\t40\t10.0\t54\t\u221228\t25\t3.48\nRt. Postcentral Gyrus\u2191\t1\t13.0\t54\t\u221228\t43\t3.85\nRt. Inferior Parietal Lobule\u2191\t40\t26.0\t51\t\u221243\t55\t4.83\nMCI vs. NOR\u2193\t\t\t\t\t\t\nRt. Cerebellum Posterior lobe\u2193\t-\t5.0\t33\t\u221276\t\u221250\t\u22123.91\nLt. Cerebellum Posterior lobe\u2193\t-\t20.0\t\u22123\t\u221270\t\u221250\t\u22124.53\nLt. Cerebellum Anterior lobe\u2193\t-\t5.0\t\u221236\t\u221240\t\u221241\t\u22123.69\nRt. Cerebellum Anterior lobe\u2193\t-\t31.0\t42\t\u221243\t\u221232\t\u22125.19\nRt. Cerebellum Posterior lobe\u2193\t-\t10.0\t24\t\u221273\t\u221217\t\u22124.11\nRt. Temporal lobe\u2193\t42\t7.0\t66\t\u22127\t10\t\u22124.56\nLt. Superior Frontal Gyrus\u2193\t6\t60.0\t\u221224\t\u221210\t73\t\u22125.28\nRt. Middle Frontal Gyrus\t6\t7.0\t27\t5\t70\t\u22124.01\nRt. Superior Frontal Gyrus\u2193\t6\t16.0\t21\t\u221210\t70\t\u22123.64\nLt. Precentral Gyrus\u2193\t6\t5.0\t\u221242\t\u221210\t61\t\u22124.06\nLt. Paracentral Lobule\u2193\t6\t52.0\t\u22123\t\u221228\t52\t\u22125.20\nRt. Postcentral Gyrus \u2193\t3\t222.0\t42\t\u221228\t61\t\u22126.06\nLt. Superior Parietal Lobe\u2193\t5\t66.0\t\u221230\t\u221255\t67\t\u22125.15\nLt. Paracentral Lobule\u2193\t3\t18.0\t\u221215\t\u221228\t76\t\u22124.20\nRt. Lingual Gyrus\u2193\t18\t8.0\t6\t\u221279\t\u221211\t\u22123.88\nRt. Limbic Lobe\u2193\t-\t19.0\t24\t\u221210\t\u221235\t\u22124.16\n### Caption\nRegions showing increased or decreased activities in MCI subjects in the procession of acupuncture comparing to resting state.\n### Footer\nNone\n\n\n## ID: pone-0042730-t004\n### Label: Table 4\nRegions\tBA\tCluster\tCoordinates (MNI)\tCoordinates (MNI)\tCoordinates (MNI)\tT-score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tSize\tx\ty\tz\tUnnamed: 6_level_1\nAD vs. NOR\u2191\t\t\t\t\t\t\nRt. Cerebellum Posterior lobe\u2191\t-\t7.0\t51\t\u221267\t\u221232\t4.14\nLt. Medial Frontal Gyrus\u2191\t11\t18.0\t0\t53\t\u221220\t4.46\nLt. Inferior Frontal Gyrus\u2191\t47\t31.0\t\u221212\t11\t\u221214\t4.78\nRt. Middle Frontal Gyrus\u2191\t47/11\t61.0\t27\t38\t\u22125\t4.89\nRt. Superior Frontal Gyrus\u2191\t10\t12.0\t45\t\u221285\t1\t3.74\nLt. Inferior Frontal Gyrus\u2191\t45\t26.0\t\u221257\t29\t7\t4.31\nRt. Inferior Parietal lobule\u2191\t40\t36.0\t42\t\u221258\t58\t4.37\nRt. Middle Occipital Gyrus\u2191\t19\t12.0\t21\t62\t\u22122\t3.83\nRt. Middle Occipital Gyrus\u2191\t19\t20.0\t33\t\u221291\t25\t4.44\nAD vs. NOR\u2193\t\t\t\t\t\t\nLt. Cerebellum Posterior lobe\u2193\t-\t8.0\t\u221239\t\u221279\t\u221241\t\u22124.69\nLt. Cerebellum Posterior Lobe\u2193\t-\t11.0\t\u221248\t\u221267\t\u221238\t\u22123.59\nRt. Cerebellum Anterior Lobe\u2193\t-\t66.0\t30\t\u221249\t\u221235\t\u22124.10\nRt. Middle Temporal Gyrus\u2193\t21\t10.0\t57\t2\t\u221229\t\u22123.74\nRt. Superior Temporal Gyrus\u2193\t22\t5.0\t42\t\u221258\t13\t\u22123.44\nRt. Middle Frontal Gyrus\u2193\t6\t60.0\t42\t\u22121\t46\t\u22124.07\nLt. Medial Frontal Gyrus\u2193\t6\t23.0\t0\t\u221210\t55\t\u22123.93\nLt. Brainstem\u2193\t-\t5.0\t\u22126\t\u221225\t\u221211\t\u22123.40\n### Caption\nRegions showing increased or decreased activities in AD subjects in the procession of acupuncture comparing to resting state.\n### Footer\nNone\n\n\n## ID: pone-0042730-t005\n### Label: Table 5\nRegions\tBA\tCluster\tCoordinates (MNI)\tCoordinates (MNI)\tCoordinates (MNI)\tT-score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tSize\tx\ty\tz\tUnnamed: 6_level_1\nMCI vs. NOR\u2191\t\t\t\t\t\t\nLt. Cerebellum Posterior Lobe\u2191\t-\t33.0\t\u221236\t\u221267\t\u221241\t4.57\nRt.Cerebellum Posterior Lobe\u2191\t\t17.0\t51\t\u221264\t\u221235\t4.51\nRt. Fusiform Gyrus\u2191\t19\t31.0\t36\t\u221270\t\u221220\t5.49\nRt. Parahippocampa Gyrus\u2191\t28\t32.0\t21\t\u221213\t\u221217\t5.34\nRt. Middle temporal Gyrus\u2191\t21\t28.0\t57\t8\t\u221223\t4.65\nRt. Middle temporal Gyrus\u2191\t21\t33.0\t63\t\u221231\t\u221217\t4.09\nLt. Fusiform\u2191\t19\t7.0\t\u221233\t\u221273\t\u221217\t3.65\nRt. Frontal Lobe\u2191\t9,8,32\t1128.0\t12\t23\t16\t5.54\nLt. Medial Frontal gyrus\u2191\t9\t169.0\t\u221218\t29\t34\t3.95\nLt. Frontal lobe Sub-Gyral\u2191\t-\t27.0\t\u221227\t\u221243\t28\t3.76\nLt. Superior Frontal Gyrus\u2191\t8\t5.0\t\u22129\t26\t49\t3.37\nRt. Lentiform Nucleus\u2191\t-\t17.0\t30\t\u221219\t1\t4.03\nLt. Extra-Nuclear\u2191\t-\t165.0\t\u221218\t20\t10\t4.46\nRt. Thalamus\u2191\t-\t89.0\t6\t\u221222\t7\t4.26\nRt. Right Cerebrum sub lobar\u2191\t-\t15.0\t0\t8\t13\t3.38\nMCI vs. NOR\u2193\t\t\t\t\t\t\nRt.Cerebellum Posterior Lobe\u2193\t-\t7.0\t33\t\u221276\t\u221250\t\u22124.16\nLt. Cerebellum Posterior Lobe\u2193\t\t24.0\t\u22123\t\u221270\t\u221247\t\u22125.06\nLt. Cerebellum Anterior Lobe\u2193\t\t108.0\t\u221242\t\u221252\t\u221229\t\u22126.67\nLt. Cerebellum Posterior Lobe\u2193\t\t6.0\t\u221218\t\u221285\t\u221235\t\u22124.06\nRt.Cerebellum Posterior Lobe\u2193\t\t59.0\t0\t\u221270\t\u221226\t\u22124.69\nLt. Middle Temporal Gyrus\u2193\t39\t39.0\t\u221257\t\u221270\t7\t\u22125.17\nRt. Fusiform Gyrus\u2193\t6\t26.0\t24\t\u221273\t\u221214\t\u22124.32\nRt. Middle Temporal Gyrus\u2193\t21\t73.0\t54\t\u221246\t4\t\u22124.20\nLt. Superior Temporal Gyrus\u2193\t22\t9.0\t\u221257\t\u221210\t7\t\u22123.86\nRt. Inferior Temporal Gyrus\u2193\t37\t8.0\t63\t\u221258\t\u22128\t\u22123.54\nLt. Superior Frontal Gyrus\u2193\t8\t14.0\t\u221215\t59\t\u22128\t\u22125.61\nLt. Frontal lobe\u2193\t9\t10.0\t\u22126\t\u22121\t\u221214\t\u22124.39\nLt. Superior Frontal Gyrus\u2193\t18\t6.0\t18\t\u2212100\t\u221211\t\u22123.69\nLt. Inferior Frontal Gyrus\u2193\t44\t32.0\t\u221254\t8\t28\t\u22124.13\nRt. Precental Gyrus\u2193\t4\t11.0\t66\t\u221213\t31\t\u22123.99\nRt. Precental Gyrus\u2193\t6\t124.0\t39\t\u221225\t61\t\u22124.54\nRt. Middle Frontal Gyrus\u2193\t6\t17.0\t30\t2\t67\t\u22124.04\nLt. Precentral Gyrus \u2193\t6\t6.0\t\u221242\t\u22127\t61\t\u22123.72\nLt. Precentral Gyrus\u2193\t6\t13.0\t\u221236\t\u221219\t67\t\u22124.41\nLt. Superior Frontal Gyrus\u2193\t6\t30.0\t\u221230\t\u22127\t70\t\u22124.03\nRt. Postcentral Gyrus\u2193\t43\t22.0\t66\t\u221210\t13\t\u22124.30\nLt. Postcentral Gyrus\u2193\t40\t257.0\t\u221254\t\u221219\t34\t\u22124.93\nLt. Inferior parietal lobule\u2193\t7\t17.0\t\u221236\t\u221276\t49\t\u22124.11\nRt. Angular\u2193\t7\t9.0\t36\t\u221270\t55\t\u22123.83\nRt. Superior parietal lobule\u2193\t7\t19.0\t30\t\u221255\t52\t\u22123.87\nLt. Superior parietal lobule\u2193\t7\t276.0\t\u221239\t\u221240\t61\t\u22125.73\nRt. Postcentral Gyrus\u2193\t7\t189.0\t24\t\u221255\t70\t\u22126.66\nLt. Occipital superior lobe\u2193\t7\t6.0\t\u221215\t\u221285\t46\t\u22123.62\nLt. Cuneus\u2193\t19\t22.0\t\u221227\t\u221294\t28\t\u22125.82\n### Caption\nRegions showing increased or decreased activities in MCI after acupuncture comparing to resting state.\n### Footer\nNone\n\n\n## ID: pone-0042730-t006\n### Label: Table 6\nRegions\tBA\tCluster\tCoordinates (MNI)\tCoordinates (MNI)\tCoordinates (MNI)\tT-score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tSize\tx\ty\tz\tUnnamed: 6_level_1\nAD vs. NOR\u2191\t\t\t\t\t\t\nRt. Cerebellum Posterior lobe\u2191\t-\t29.0\t48\t\u221267\t\u221229\t4.48\nLt. Inferior Temporal Gyrus\u2191\t20\t7.0\t\u221260\t\u221222\t\u221226\t4.43\nRt. Middle Temporal Gyrus\u2191\t21\t10.0\t\u221266\t\u221243\t\u22125\t3.50\nLt. Inferior Frontal Gyrus\u2191\t47\t7.0\t\u221212\t14\t\u221214\t3.49\nRt. Superior Frontal Gyrus\u2191\t10\t32.0\t21\t62\t1\t5.08\nRt. Middle Frontal Gyrus\u2191\t47\t45.0\t30\t35\t\u22122\t4.47\nLt. Superior Frontal Gyrus\u2191\t8\t52.0\t\u221215\t29\t46\t4.27\nRt. Superior Frontal Gyrus\u2191\t6\t11.0\t3\t32\t61\t3.42\nLt. Precentral Gyrus\u2191\t6\t11.0\t\u22129\t\u221222\t67\t3.34\nRt. Precentral Gyrus\u2191\t6\t30.0\t21\t\u221222\t70\t3.72\nLt. Medial Frontal Gyrus\u2191\t6\t7.0\t\u22123\t\u221216\t76\t3.65\nRt. Middle Occipital Gyrus\u2191\t19\t49.0\t48\t\u221282\t\u22122\t4.71\nLt. Middle Occipital Gyrus\u2191\t19/18\t1365.0\t\u221242\t\u221279\t13\t4.81\nLt. Supramarginal Gyrus\u2191\t40\t5.0\t\u221254\t\u221243\t31\t3.29\nRt. Supramarginal Gyrus\u2191\t40\t23.0\t48\t\u221252\t34\t3.50\nRt. Superior Parietal lobule\t7\t23.0\t39\t\u221261\t61\t4.46\nAD vs. NOR\u2193\t\t\t\t\t\t\nLt. Cerebellum Posterior Lobe\u2193\t-\t7.0\t\u221221\t\u221261\t\u221223\t\u22123.64\nRt. Parahippocampa Gyrus\u2193\t35\t12.0\t21\t\u221210\t\u221214\t\u22123.88\nLt. Parahippocampa Gyrus\u2193\t35-\t5.0\t\u221233\t\u221228\t\u221226\t\u22123.68\nLt. Parahippocampa Gyrus\u2193\t35\t100.0\t\u221215\t\u221225\t\u221214\t\u22124.10\nRt.Middle Friontal Gyrus\u2193\t6\t23.0\t42\t\u22121\t46\t\u22123.58\nLt. Lingual Gyrus\u2193\t18\t41.0\t\u22123\t\u221261\t1\t\u22123.95\nRt.Cingulate Gyrus\u2193\t-\t11.0\t12\t\u22124\t37\t\u22123.40\nRt.Cingulate Gyrus\u2193\t-\t15.0\t6\t\u22121\t49\t\u22123.57\nLt. Lentiform Nucleus\u2193\t-\t36.0\t\u221215\t\u22124\t7\t\u22123.95\nRt. Brainstem\u2193\t-\t5.0\t6\t\u221219\t\u221214\t\u22123.35\n### Caption\nRegions showing increased or decreased activities in AD subjects after acupuncture comparing to resting state.\n### Footer\nNone\n", "metadata": {"pmcid": 3423412, "text_md5": "09662201c4bd1de9a409b3c31d123aad", "field_positions": {"authors": [0, 157], "journal": [158, 166], "publication_year": [168, 172], "title": [183, 279], "keywords": [293, 293], "abstract": [306, 2068], "body": [2077, 24626], "tables": [24639, 34563]}, "batch": 2, "pmid": 22916152, "doi": "10.1371/journal.pone.0042730", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3423412", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3423412"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3423412\">3423412</a>", "list_title": "PMC3423412  Effect of Acupuncture in Mild Cognitive Impairment and Alzheimer Disease: A Functional MRI Study"}
{"text": "Tracy, Derek K and Ho, David K and O'Daly, Owen and Michalopoulou, Panayiota and Lloyd, Lisa C and Dimond, Eleanor and Matsumoto, Kazunori and Shergill, Sukhwinder S\nBMC Neurosci, 2011\n\n# Title\n\nIt's not what you say but the way that you say it: an fMRI study of differential lexical and non-lexical prosodic pitch processing\n\n# Keywords\n\n\n\n# Abstract\n \n## Background \n  \nThis study aims to identify the neural substrate involved in prosodic pitch processing. Functional magnetic resonance imaging was used to test the premise that prosody pitch processing is primarily subserved by the right cortical hemisphere. \n\nTwo experimental paradigms were used, firstly pairs of spoken sentences, where the only variation was a single internal phrase pitch change, and secondly, a matched condition utilizing pitch changes within analogous tone-sequence phrases. This removed the potential confounder of lexical evaluation. fMRI images were obtained using these paradigms. \n\n\n## Results \n  \nActivation was significantly greater within the right frontal and temporal cortices during the tone-sequence stimuli relative to the sentence stimuli. \n\n\n## Conclusion \n  \nThis study showed that pitch changes, stripped of lexical information, are mainly processed by the right cerebral hemisphere, whilst the processing of analogous, matched, lexical pitch change is preferentially left sided. These findings, showing hemispherical differentiation of processing based on stimulus complexity, are in accord with a 'task dependent' hypothesis of pitch processing. \n\n \n\n# Body\n \n## Background \n  \nNon-verbal components of language, included under the collective term prosody, play a central role in human communication [ ]. First defined by Monrad-Krohn in 1947 [ ], prosodic elements of speech can be subdivided into the two broad categories of linguistic and emotional prosody. Linguistic prosody conveys information about semantic meaning, such as pragmatic category - e.g. determining if a sentence is a statement, a question or a command - and syntactic relation - e.g. determining clause boundaries within sentences [ , ]. Emotional prosody is the mechanism by which humans convey attitudes and emotions in speech. There has been debate about how clearly these two categories can be delineated. \n\nInitial behavioural and lesion studies implicated both right [ - ] and left [ - ] hemispheric regions, likely confounded both by the inherent difficulties in comparing lesion studies [ , ] and assessing \"global\" prosodic function without considering specific subcomponents. \n\nPET data first suggested that prosodic content and judgement activated the prefrontal cortex bilaterally [ , ], more so on the left, and hemispheric asymmetry has been demonstrated for most regions of activation [ ]. Subsequent imaging studies have implicated right superior temporal regions [ , - ] - most recent work suggesting particularly within Brodmann's area [ ], with additional, partially bilateral responses within the frontal cortex [ , , - ], the anterior insula [ , , ], amygdalae [ ], and the basal ganglia [ , ]. Emotional speech produces greater cortical activation than that which is prosodically neutral [ , , ]. Electrophysiological work has supported neuroimaging findings that the right temporal cortex displays enhanced event-related potentials to emotional stimuli [ ]. \n\nVariations in results, due in no small part to different experimental paradigms, have failed to definitively clarify whether cerebral regional and hemispheric activation are specific to prosodic subcomponent analysis or the functional demand of the task, known as the   cue dependent   [ , ] and   task dependent   [ , - ] hypotheses respectively. \n\nHowever by far the majority of work has been on emotional prosody, and it's unclear how well such data can be applied to linguistic prosody that, in comparison, has had a paucity of research. Furthermore, work on linguistic or semantic aspects of prosody have typically focused on psychometric measures of language conceptualisation and understanding [ , ] rather than the underlying neurobiology. Most authors have recognized the difficulties of the confounding influences of the lexical content of the stimuli and the problem of the higher level cognitive processes involved in the more global process of emotional prosody [ ]. \n\nThe neuroimaging data that exist for linguistic prosody typically favour hemispheric specialisation [ ], with left fronto-temporal regions subserving 'simpler' short [ ] syntactic and lexical segments of speech [ ], and right hemispheric analogues processing larger suprasegmental elements at a sentence level [ ], most in keeping with the task dependent hypothesis. \n\nIn light of this, this study set out to utilise fMRI to examine a single crucial element of linguistic prosodic comprehension; pitch change. We specifically looked at   internal pitch changes  , or \"emphasis shift\", as our earlier work suggested that these were more sensitive markers of subtle neurological deficits and less confounded by working memory primacy and recency phenomena [ ]. As the name suggests, internal pitch changes occur   within   - as opposed to at the beginning or end of - a sentence. Furthermore, in an effort to try eliminate the major confounder of lexical comprehension, following the work of Patel et al [ ] we introduced an analogous tone-sequence paradigm that contained a delexicalised pitch pattern. By removing the lexical content but keeping the tone sequence otherwise matched this design would also allow testing of the validity of the task dependent hypothesis as the same prosodic element, pitch, was being tested, but at different levels, with the tone sequence involving suprasegmental data analysis. \n\nWe hypothesised that a) there are common cortical regions including bilateral prefrontal and temporal cortices associated with pitch processing in both speech and tone-sequence analogues; b) the more \"pure\" pitch processing associated with tone-sequence analogues would preferentially recruit right sided frontal and temporal cortices while more lexically loaded speech would preferentially recruit left temporal cortex; and c) increasing demands on prosodic comprehension would be associated with enhanced activation in the right frontal and temporal cortex. \n\n\n## Methods \n  \n### Subjects \n  \nTwelve subjects were recruited through advertisements in a city-wide newspaper. Inclusion criteria were: males aged between 18 and 55, right-handedness, English as a first language. Exclusion criteria were: previous psychiatric or neurological illness, hearing or speech impairment and illicit drug use in the previous six months. All subjects provided written informed consent. Mean age was 31 (SD = 9.6). All subjects had completed secondary education; none had any formal training in playing musical instruments. The study had been approved by the local ethics committee. \n\n\n### Stimuli and materials \n  \nA modified version of the tone-sequence and prosody discrimination task previously described by the authors [ ] was used, based on the earlier protocol of Patel et al [ ]. The recorded stimuli consisted of 12 lexically identical sentence pairs, spoken by an adult female native English speaker, and their non-verbal, tone-sequence analogue pairs; and 12 sentence and tone-sequence pairs that differed prosodically in internal pitch pattern on a single word or tone (e.g. \"I like blue ties on gentlemen\" and \"I like   blue   ties on gentlemen\", with the italicized word emphasised). Tone-sequence stimuli were created by digitizing each sentence at 40,000 Hz with subsequent normalization to the same amplitude into a tone sequence which corresponded with the sentence's fundamental frequency in pitch and timing, with one level-pitch tone per syllable; a more detailed description is available in Patel et al [ ]. An alternative method of low-pass filtering of the sentence pairs to remove lexical information was felt to be less satisfactory, as such filtering can leave residual phonological information, and previous studies [ ] had validated this method. \n\n\n### Procedure \n  \nSubjects were trained on the prosodic discrimination task, which consisted of six counterbalanced blocks. Each block was composed of twelve trials comprising four pairs of sentences, four pairs of tone-sequences, and four null trials (a silent period equal in length to four paired stimuli) presented in random order. Each trial consisted of a pair of stimuli separated by a one second interval. The pair of stimuli differed in the pitch of an internal component in 50% of trials. As some sentences were longer than others, the duration of the stimuli varied from 3432-6134 milliseconds, with an average length of 5036 ms. Following a visual cue at the end of each trial, subjects indicated whether the paired stimuli were the same or different by using their right index finger and a button press. There was a variable intertrial interval of between 8.6-11.3 seconds before the onset of the next trial. Such a jittered design results in peristimulus distribution of MRI sampling, thus ensuring that all components of an event-related haemodynamic response are sampled, and avoids that bias of having stimulus presentation and data acquisition time-locked [ ]. The total length of the six counterbalanced blocks was 17 minutes 39 seconds. \n\n\n### fMRI Acquisition \n  \nGradient echo echoplanar imaging (EPI) data were acquired on a neuro-optimised GE Signa 1.5 Tesla system (General Electric, Milwaukee WI, USA) at the Maudsley Hospital, London. A quadrature birdcage headcoil was used for radio frequency transmission and reception. Foam padding was placed around the subject's head in the coil to minimize head movement. One hundred and forty four T2*-weighted whole-brain volumes depicting blood oxygen level-dependent (BOLD) contrast were acquired at each of 24 near-axial non-contiguous planes parallel to the intercommissural (AC-PC) line (slice thickness = 5 mm; gap = 0.5 mm; TR = 2.1 seconds; echo time = 40 milliseconds; flip angle = 90\u00b0; matrix = 64 \u00d7 64). This EPI data set provided complete brain coverage. At the same session, a high-resolution gradient echo image of the whole brain was acquired in the intercommissural plane consisting of 43 slices (slice thickness = 3 mm; gap = 0.3 mm; TR = 3 seconds; flip angle = 90\u00b0; matrix = 128 \u00d7 128). \n\nScanner noise during stimuli presentation was minimised by using a partially silent acquisition [ ] during the stimuli presentation lasting 6.3 seconds while fMRI data (associated with prominent scanner noise) was collected during the following 8.4 seconds. \n\n\n### fMRI Analysis \n  \nThe data were first realigned [ ] to minimise motion related artefacts and smoothed using a Gaussian filter (FWHM 7.2 mm). Responses to the experimental paradigm were then detected by time-series analysis using Gamma variate functions (peak responses at 4 and 8 sec) to model the BOLD response. The analysis was implemented as follows. First, in each experimental condition, trial onsets were modelled as stick-functions which were convolved separately with the 4 and 8 sec Poisson functions to yield two regressors of the expected haemodynamic response to that condition. The weighted sum of these two convolutions that gave the best fit (least-squares) to the time series at each voxel was then computed and a goodness of fit statistic was computed at each voxel, the SSQratio. It has been shown that this permutation method gives very good type I error control with minimal distributional assumptions [ ]. \n\nIn order to extend inference to the group level, the observed and randomized SSQratio maps were transformed into standard space by a two stage process involving first a rigid body transformation of the fMRI data into a high-resolution inversion recovery image of the same subject followed by an affine transformation onto a Talairach template [ ]. In order to increase sensitivity and reduce the multiple comparison problem encountered in fMRI, hypothesis testing was carried out at the cluster level using the method developed by Bullmore et al. [ ], shown to give excellent cluster-wise type I error control in functional fMRI analysis. All analyses were performed with < 1 false positive clusters expected per image, under the null hypothesis. \n\nWe examined regions of activation common to both sentence and tone-sequence prosodic comprehension with conjunction analysis. As the levels of activation in the various experiments will vary, the statistical issue is whether the minimum level of activation in any of the tasks is significantly different from zero. In parametric analysis this is done by testing the minimum t statistic. The statistical analysis program utilized (XBAM) found which task had the smallest median level of activation and tested this median against the null distribution of the activation by estimating the SSQratio for each subject at each voxel for each task [ , ]. Then we compared prosodic comprehension between the tone-sequence and sentence stimuli to clarify the effects of lexical processing. Subsequent analyses compared identical stimuli pairs with differing stimuli pairs (same versus different stimuli pairs). During the pilot phase, volunteers subjectively reported the appraisal of identical stimuli to be more demanding. This was used to examine the effects of postulated increased demand on prosodic assessment. We employed a 2 \u00d7 2 factorial design to examine the interaction of factor condition (tone sequence, sentence) with the variables of pair type (same, different). The SSQ values were extracted from whole clusters, and plotted for regions demonstrating significant interaction effects between tone sequence and sentence processing and task demand assessed by same or differing stimuli pairs. \n\nA confounder in all fMRI studies is the intrinsic scanner noise: this is particularly the case in tasks with an auditory component such as this one. We minimized this by having the scanner at a partially silent acquisition phase [ ] during the presentation of stimuli. It has been shown that handedness and gender may affect the neural structures involved in the processing of language [ ] and prosody [ ], as such we only examined right handed males. \n\nBehavioural data were analyzed using the statistical package SPSS. \n\n\n\n## Results \n  \n### Behavioural data \n  \nThere were no significant differences in response time or accuracy rates between sentence and tone-sequence categories either overall, or when analysed in the subcategories of   same   and   different   tasks, using a two tailed t-test (\u03b1 = 0.05). The subjects were generally highly accurate (0.75 - 0.98 on the tone-sequence task, 0.83 - 1.00 on the sentence task), with four individuals getting 100% accuracy on the sentence task, suggestive of a possible ceiling effect. However, subjects were more accurate during   same   tasks (mean accuracy 0.948) than during   different   tasks (mean accuracy 0.866) overall. \n\n\n### Neuroimaging data \n  \nThe conjunction analysis showed significant activation common to both sentence and tone sequence prosodic processing in the bilateral Inferior Frontal Gyri, Middle (MTG) and Superior Temporal Gyri (STG), in addition to bilateral Inferior Parietal lobule and the right Superior Frontal Gyrus (Figure  ; Table  ). \n  \n Conjuction analysis of regions of cerebral activation common to both the sentence and tone-sequence tasks  . 5 ascending transverse slices, with a sagittal section to the right of the image indicating where these are taken from. Exact cluster coordinates are given in Table 1. \n    \nAreas of activation shown in   Figure 1  . \n  \nHem = hemisphere, BA = Brodmann's Area. \n  \nActivation was significantly greater within the right frontal and temporal cortices during the tone-sequence stimuli relative to the sentence stimuli (Figure  , bottom half; Table  ). Regions of greater activation in the sentence task relative to the tone sequence task (Figure  , top half; Table  ) were predominantly left hemispheric, including the cingulate gyrus, left MTG, STG, inferior parietal lobule as well as the basal ganglia; with additional activation in the right precuneus, right cingulate gyrus and right lingual gyrus. \n  \n ANOVA of regions of task-dependent differential activation  . Ascending transverse slices with the sagittal section to the right indicating where they are taken from. The top half displays regions of relative increased activation during the sentence task; the lower half displays those more active during the tone-sequence task. The exact cluster coordinates are provided in Table 2 and Table 3 respectively. \n    \nAreas of activation shown in   Figure 2, BOTTOM HALF  . \n  \nHem = hemisphere, BA = Brodmann's Area. \n    \nAreas of activation shown in   Figure 2-TOP HALF  . \n  \nHem = hemisphere, BA = Brodmann's Area. \n  \nA statistically significant interaction between   factor   condition (tone sequence, sentence) and stimulus pair   type   (same, different) was evident in the right Inferior and Middle Frontal Gyrus and right STG (Figures  ; Table  ). \n  \n Interaction analysis of cerebral regions that can differentiate task (sentence/tone-sequence) and trial type (same/different)  . Cluster coordinates are provided in Table 4. \n    \nAreas of activation in   Figure 3  . \n  \nHem = hemisphere, BA = Brodmann's Area. \n  \n\n\n## Discussion and Conclusions \n  \nAs hypothesized, there was activation in bilateral MTG and STG common to prosodic pitch processing across both sentence and tone-sequence stimuli. There was more prominent right inferior frontal cortex activation, although left inferior frontal activation was also present (Figure  ; Table  ). This was in accordance with previous imaging data of prosodic comprehension [ , , - ]. There was a large bilateral activation in the Inferior Parietal Lobule, a region associated with storage within the working memory system [ ]. Such a role is in accordance with our data, as differential activation maps fail to show differences in parietal activation between the two tasks, coinciding with a purely working memory role. Left precentral and postcentral gyral and basal ganglia activity were common to both conditions, something which would be anticipated in an experimental paradigm involving a right handed finger press. \n\nComparison between the tone-sequence and sentence stimuli aimed to clarify the relative contribution of cortical regions associated with a purer linguistic prosodic pitch analysis (tone sequence > sentences) and those associated with greater lexical or phonological analysis (sentence > tone sequence), which has been recognised as a major confounder in such studies generally [ , - ]. Stripped of this lexical information, the tone-sequence demonstrated significant activation in the   right   inferior and medial frontal, and right STG compared to the sentence task (Figure  , bottom half; Table  ). Wildgruber et al [ ] suggested that at lower levels of both linguistic and emotional prosody processing, the same right hemispheric network is accessed but that the explicit judgment of linguistic aspects of speech prosody is more associated with left hemispheric language regions and explicit evaluation of emotional prosody is related to bilateral orbitofrontal regions. Our data support this assertion, with evident overlap between the regions preferentially activated by the tone-sequence and those elicited during emotional prosodic tasks. Explicit analysis of linguistic aspects preferentially evoked appraisal by left hemispheric regions, fitting with other work [ , , - ] and this may reflect the processing of this lexical content of the stimuli. \n\nOur third hypothesis was that 'increased demand' would be associated with enhanced activation in the right frontal and temporal cortices. Subjects reported finding tone-sequence trials harder than sentence ones - fitting with Patel's notion of extra 'redundancy' cues in the lexical trials [ , ] - and that   same   pairs were 'more difficult' than   different   ones. Interestingly, behavioural data conflicts with subjective perception, demonstrating that subjects more accurate in   same   tasks: during these subjects needed to hold the entire   same   trial pair in working memory, and examine these for subtle (non-existent) differences; as opposed to   different   pairs where participants could discard the stimuli once   any   pitch difference was noted. As such,   same   and   tone-sequence   may have been proxy markers for cognitive demand rather than 'difficulty' per se, as well as tone-sequence exploring 'purer' pitch processing. \n\nDuring the tone-sequence task there was   relatively   increased right STG and left precuneus activation when paired tone stimuli were the   same  , compared to when different. The interaction analysis (Figures  ; Table  ) looked at the effect of one factor (  stimulus type: sentence or tone sequence  ) on another factor (  trial type: same or different  ). Regions which can differentiate between these factors are all right sided: the STG, Inferior Frontal Gyrus and Middle Frontal Gyrus. Each of these discriminatory regions show increased activation in tone-sequence, as opposed to sentence, tasks, and during   same   compared to   different   stimuli (Figure  ). \n  \n Graphed differential activation in the right inferior frontal gyrus in the interaction analysis of Figure 3 demonstrating activation in the two task types (sentence/tone-sequence) and two trial types (same/different)  . SSQ, a \"sum of squares ratio\" is a statistical indicator of activity, as described in the methods section. \n  \nThe authors' interpretation of our data is that it best fits with the task dependent hypothesis that the left hemisphere is hemispherically specialized for lexical and short syntactic aspects of pitch whilst the right hemisphere is superior at processing suprasegmental pitch. Subjects' reports place tone sequence and   same   trials as being more difficult and the interaction analysis of activation in the right inferior frontal gyrus (Figure  ) shows increasing activation for these: in both instances subjects are processing a larger, full trial, sequence at a suprasegmental level. \n\nIn conclusion, our data support the premise that prosodic pitch perception is subserved by the bifrontal and temporal cortices, specifically the Superior Temporal Gyrus, Inferior Frontal Gyrus and Middle Frontal Gyrus, with the degree of hemispheric involvement dependent upon the task. These areas were activated when both tone-sequence and sentence paradigms were used, thus confounding lexical stimuli were removed, though the former preferentially activated the right hemispheric regions, the latter the left. There was a relative increase in activation in the right frontal and temporal cortices during 'same' stimuli tasks, which was deemed to be more demanding, as subjectively reported by subjects, in terms of prosodic comprehension and this, in our opinion, is due to the need to analyse pitch at a broader 'sentence level'. Our data is in agreement with the assertion [ ] of hemispheric specialisation fitting with the task dependent hypothesis, which would have predicted the lateralization [ ] found in this study. \n\nLanguage prosody processing is complex and consists of multiple components. Current understanding of it involves several competing theories, neither of which has garnered consistent support. The vast majority of the literature focuses on emotional prosody: further work is needed to provide a more coherent and distinctive conceptualization of linguistic prosodic processing. \n\n\n## Authors' contributions \n  \n DKT   participated in the study design, recruited participants, participated in fMRI data collection & analysis, interpreted the results and drafted the manuscript.   DKH   contributed to the drafting of the manuscript.   OOD   recruited participants, participated in fMRI data analysis and contributed to the drafting of the manuscript.   PM   participated in fMRI data collection and interpretation of the results.   KM   participated in the study design and coordination.   LCL   participated in fMRI analysis and contributed to the drafting of the manuscript.   ED   participated in fMRI analysis.   SSS   conceived the study and participated in its design and coordination. All authors read and approved the final manuscript. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nSize\tTalairach Coordinates\tTalairach Coordinates\tTalairach Coordinates\tHem\tBA\tCerebral Region\nUnnamed: 0_level_1\tX\tY\tZ\tUnnamed: 4_level_1\tUnnamed: 5_level_1\tUnnamed: 6_level_1\n62.0\t-43.0\t-33.0\t48.0\tL\t40.0\tInferior Parietal Lobule\n\t\t\t\t\t\t\n60.0\t-54.0\t-22.0\t37.0\tL\t2.0\tPostcentral Gyrus\n\t\t\t\t\t\t\n48.0\t51.0\t7.0\t-7.0\tR\t22.0\tSuperior Temporal Gyrus\n\t\t\t\t\t\t\n43.0\t-54.0\t-15.0\t9.0\tL\t41.0\tMiddle Temporal Gyrus\n\t\t\t\t\t\t\n42.0\t47.0\t-48.0\t26.0\tR\t40.0\tInferior Parietal Lobule\n\t\t\t\t\t\t\n40.0\t-54.0\t0.0\t-2.0\tL\t22.0\tSuperior Temporal Gyrus\n\t\t\t\t\t\t\n32.0\t-32.0\t-26.0\t59.0\tL\t4.0\tPrecentral Gyrus\n\t\t\t\t\t\t\n32.0\t-7.0\t-81.0\t-13.0\tL\t18.0\tLingual Gyrus, Occipital Lobe\n\t\t\t\t\t\t\n30.0\t51.0\t15.0\t-2.0\tR\t47.0\tInferior Frontal Gyrus\n\t\t\t\t\t\t\n12.0\t58.0\t-37.0\t-7.0\tR\t21.0\tMiddle Temporal Gyrus\n\t\t\t\t\t\t\n10.0\t32.0\t15.0\t4.0\tR\t\tClaustrum\n### Caption\nAreas of activation shown in Figure 1.\n### Footer\nHem = hemisphere, BA = Brodmann's Area.\n\n\n## ID: T2\n### Label: Table 2\nSize\tTalairach Coordinates\tTalairach Coordinates\tTalairach Coordinates\tHem\tBA\tCerebral Region\nUnnamed: 0_level_1\tX\tY\tZ\tUnnamed: 4_level_1\tUnnamed: 5_level_1\tUnnamed: 6_level_1\n71.0\t32.0\t30.0\t-13.0\tR\t47.0\tInferior Frontal Gyrus\n\t\t\t\t\t\t\n41.0\t7.0\t19.0\t42.0\tR\t32.0\tCingulate Gyrus, Limbic Lobe\n\t\t\t\t\t\t\n40.0\t11.0\t41.0\t37.0\tR\t7.0\tMedial Frontal Gyrus\n\t\t\t\t\t\t\n29.0\t51.0\t11.0\t-2.0\tR\t22.0\tSuperior Temporal Gyrus\n\t\t\t\t\t\t\n22.0\t36.0\t22.0\t4.0\tR\t13.0\tInsula\n\t\t\t\t\t\t\n17.0\t14.0\t11.0\t53.0\tR\t6.0\tSuperior Frontal Gyrus\n\t\t\t\t\t\t\n10.0\t18.0\t-19.0\t-18.0\tR\t28.0\tParahippocampal Gyrus\n\t\t\t\t\t\t\n9.0\t-7.0\t4.0\t53.0\tL\t6.0\tMedial Frontal Gyrus\n### Caption\nAreas of activation shown in Figure 2, BOTTOM HALF.\n### Footer\nHem = hemisphere, BA = Brodmann's Area.\n\n\n## ID: T3\n### Label: Table 3\nSize\tTalairach Coordinates\tTalairach Coordinates\tTalairach Coordinates\tHem\tBA\tCerebral Region\nUnnamed: 0_level_1\tX\tY\tZ\tUnnamed: 4_level_1\tUnnamed: 5_level_1\tUnnamed: 6_level_1\n97.0\t-14.0\t-48.0\t26.0\tL\t31.0\tCingulate Gyrus, Limbic Lobe\n\t\t\t\t\t\t\n58.0\t7.0\t-63.0\t31.0\tR\t7.0\tPrecuneus\n\t\t\t\t\t\t\n47.0\t-29.0\t-11.0\t9.0\tL\t\tPutamen\n\t\t\t\t\t\t\n44.0\t-54.0\t-19.0\t-7.0\tL\t21.0\tMiddle Temporal Gyrus\n\t\t\t\t\t\t\n32.0\t-47.0\t-26.0\t37.0\tL\t2.0\tPostcentral Gyrus\n\t\t\t\t\t\t\n27.0\t-18.0\t-22.0\t15.0\tL\t\tPosterior Thalamic Nucleus\n\t\t\t\t\t\t\n26.0\t4.0\t-44.0\t37.0\tR\t31.0\tCingulate Gyrus, Limbic Lobe\n\t\t\t\t\t\t\n24.0\t14.0\t-78.0\t4.0\tR\t18.0\tLingual Gyrus, Occipital Lobe\n\t\t\t\t\t\t\n19.0\t-54.0\t-52.0\t9.0\tL\t39.0\tSuperior Temporal Gyrus\n\t\t\t\t\t\t\n18.0\t-29.0\t-4.0\t-13.0\tL\t\tAmygdala\n\t\t\t\t\t\t\n15.0\t-22.0\t-56.0\t42.0\tL\t7.0\tPrecuneus\n\t\t\t\t\t\t\n12.0\t-40.0\t-33.0\t26.0\tL\t40.0\tInferior Parietal Lobule\n### Caption\nAreas of activation shown in Figure 2-TOP HALF.\n### Footer\nHem = hemisphere, BA = Brodmann's Area.\n\n\n## ID: T4\n### Label: Table 4\nSize\tTalairach Coordinates\tTalairach Coordinates\tTalairach Coordinates\tHem\tBA\tCerebral Region\nUnnamed: 0_level_1\tX\tY\tZ\tUnnamed: 4_level_1\tUnnamed: 5_level_1\tUnnamed: 6_level_1\n21.0\t43.0\t7.0\t-13.0\tR\t38.0\tSuperior Temporal Gyrus\n\t\t\t\t\t\t\n11.0\t43.0\t15.0\t-2.0\tR\t47.0\tInferior Frontal Gyrus\n\t\t\t\t\t\t\n9.0\t36.0\t33.0\t20.0\tR\t46.0\tMiddle Frontal Gyrus\n### Caption\nAreas of activation in Figure 3.\n### Footer\nHem = hemisphere, BA = Brodmann's Area.\n", "metadata": {"pmcid": 3258233, "text_md5": "0bcd17e6f7c36c0324863108f4290519", "field_positions": {"authors": [0, 165], "journal": [166, 178], "publication_year": [180, 184], "title": [195, 325], "keywords": [339, 339], "abstract": [352, 1548], "body": [1557, 24438], "tables": [24451, 27546]}, "batch": 2, "pmid": 22185438, "doi": "10.1186/1471-2202-12-128", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3258233", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3258233"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3258233\">3258233</a>", "list_title": "PMC3258233  It's not what you say but the way that you say it: an fMRI study of differential lexical and non-lexical prosodic pitch processing"}
{"text": "Kim, Jaejoong and Jeong, Bumseok\nSoc Cogn Affect Neurosci, 2020\n\n# Title\n\nExpecting social punishment facilitates control over a decision under uncertainty by recruiting medial prefrontal cortex\n\n# Keywords\n\nsocial punishment\nuncertainty\ndecision-making\ncomputational modelling\ndynamic causal modelling\n\n\n# Abstract\n \nIn many decision-making situations, sub-optimal choices are increased by uncertainty. However, when wrong choices could lead to social punishment, such as blame, people might try to improve their performance by minimizing sub-optimal choices, which could be achieved by increasing the subjective cost of errors, thereby globally reducing decision noise or reducing an uncertainty-induced component of decision noise. In this functional magnetic resonance imaging (fMRI) study, 46 participants performed a choice task in which the probability of a correct choice with a given cue and the conditional probability of blame feedback (by making an incorrect choice) changed continuously. By comparing computational models of behaviour, we found that participants optimized their performance by preferentially reducing a component of decision noise associated with uncertainty. Simultaneously, expecting blame significantly deteriorated participants\u2019 mood. Model-based fMRI analyses and dynamic causal modelling indicate that the optimization mechanism based on the expectation of being blamed would be controlled by a neural circuit centred on the right medial prefrontal cortex. These results show novel behavioural and neural mechanisms regarding how humans optimize uncertain decisions under the expectation of being blamed. \n \n\n# Body\n \n## Introduction \n  \nIn our workplace, we make many decisions between options with uncertain values. If we fail to make a good decision, we might face a socially undesirable situation\u2014such as being blamed by a boss. Therefore, although it could be hard to make a good decision because of uncertainty, we may become more deliberate and expend more effort to enhance the probability of optimal choice in this situation. We occasionally encounter this kind of stressful situation that might enhance decision performance at that moment but would make us feel bad. \n\nThe motivation to avoid negative outcomes might enhance task performance through several mechanisms, including increasing attention to the task ( ) and enhancing working memory function ( ). Furthermore, the performance-enhancing effect by punishment has been thought to involve an increase in catecholamine level ( ). However, the behavioural and neural mechanisms that an agent uses to optimize an uncertain decision-making process to avoid a highly probable social punishment such as blame if their decision is wrong and how these kinds of socially stressful situation influences out mood have not been investigated. \n\nA candidate mechanism of behaviour under uncertainty that could be controlled under threat to optimize behaviour is by reducing uncertainty-driven error in their action, and an unnecessary exploration could be a kind of that error. Exploration is the choice of an option that does not have maximum value among all options in the current state ( ;  ), which could be either \u2018directed\u2019 to more uncertain options or \u2018random\u2019 ( ). Gershman and colleagues derived trial-by-trial uncertainties according to a Bayesian model of decision-making, and they showed that humans use both kinds of uncertainty-induced exploration ( ). Especially, they suggested that a total uncertainty induces a decision noise (uncertainty-induced decision noise [UDN]), which subsequently causes a random exploration ( ). Because both exploration strategies help an individual obtain information about the environment, it might also benefit a long-term cumulative reward in some situations ( ). However, if the uncertainties of every option are the same and an agent knows the outcomes of both selected and unselected options, exploration would be unnecessary because it does not maximize information gain or the reward; thus, choosing the option with the maximum value would be an optimal choice. We confined the situation regarding uncertain decisions to this type of situation to simplify our question about optimizing an uncertain decision under threat. In this situation, because uncertainties among options are the same, an uncertainty-directed exploration would not exist. However, an increase in total uncertainty would increase the decision noise, causing an unnecessary random exploration, which is an error in this case that might decrease the accuracy of the choice. Therefore, we hypothesized that controlling the sub-optimal choice (error) driven by UDN might help an agent make a more accurate choice when the wrong choice is likely to result in undesirable blame. Furthermore, we expected that blame in this situation would influence not only behaviour control under uncertainty but also people\u2019s negative mood. \n\nTo test this hypothesis, we designed a task with a choice between two options whose uncertainty changes during the task and both the outcomes of selected and unselected options are fully knowable (Figure  A). Importantly, participants received blame with high or low probabilities when they made a wrong choice, and this conditional probability changed between blocks of trials. Note that, we used blame as an aversive stimulus that motivates one to avoid it which is similar to physical pain but encounters more frequently in our social life. However, our aim was not to compare both kinds of painful stimuli in this study. We predicted that participants would infer how likely they would be blamed by making a wrong choice and would control UDN to make a more accurate choice when blame was highly likely while their mood is negatively influenced. Note that the term \u2018uncertainty\u2019 used in our study indicates an \u2018estimation uncertainty\u2019 or \u2018information uncertainty\u2019 resulting from an insufficient estimation of the value ( ). In our case, uncertainty is derived from an imperfect estimation of the probabilistic association between a cue and a \u2018correct\u2019 outcome ( ). These hypothesis were tested by modelling participants\u2019 behaviour and mood during the task using the novel hierarchal Bayesian reinforcement learning model. In this model, an agent infers both about (i) which option is likely to be correct and how such belief is uncertain and (ii) how it is likely to be blamed if one makes the wrong decision and these two kinds of inferences jointly influences the decision. \n  \n(A) Experimental paradigm. Two Tibetan character cues were presented, and cues were associated with a \u2018correct\u2019 outcome with the probability of   P   and 1\u2212  P   each. This probability   P   changes between blocks of trials. If participants made a wrong choice, a blame composed of an angry face and swear words appeared probabilistically. (B) Probability structure of the task. Left: correct probability (Correct prob) and the conditional probability of blame given wrong choice (Blame prob) were changed between blocks of trials to change the participants\u2019 estimation of uncertainty. Furthermore, there were high-blame blocks (grey-shaded area) and low-blame blocks. Right figure shows an example of belief trajectory regarding p(correct|cue) and p(blame|w) estimated from the CUDN model in one participant. The plot shows the similarity between the estimated belief trajectory and the designed probabilistic schedule. (C) A trajectory of good choice proportion for 20 trials after probability reversal. In both high- and low-blame blocks, good choice proportion kept increasing after the reversal. Furthermore, good choice probability was higher in the high-blame blocks than in the low-blame blocks early after reversals (about 10 trials after reversal). (D) Good choice proportion, accuracy and RT difference between high- and low-blame blocks. We compared the mean good choice proportion (left), accuracy (middle) and RT (right) between high-blame and low-blame blocks using a paired   t  -test. Good choice proportion was compared only in early trials after correct probability reversal. Participants showed increased good choice proportion, accuracy and RT within the high-blame blocks. The face used in this figure is different from the one that was used in the experiment to avoid using real human image in the figure (the face in this figure was generated by FaceGen Modeller ( )). \n  \nIn order to identify a neural mechanism of such behavioural optimization under threat, model-based functional magnetic resonance imaging (fMRI) analyses and dynamic causal modelling (DCM) analysis ( ) were performed. A recent study suggested the medial prefrontal cortex (mPFC) as a candidate region for controlling strategic avoidance behaviour under threat ( ;  ). Furthermore, the mPFC implements slower, more controlled and deliberate decision-making during difficult choices ( ) and drives strategy shifts ( ). Therefore, we hypothesized that the neural circuit involving the mPFC would control the behavioural optimization process under the expectation of being blamed. Especially, we expected that such a neural circuit would also involve the rostrolateral prefrontal cortex (rlPFC), which is related to an uncertainty-driven exploration in the previous literature ( ). \n\n\n## Materials and Methods \n  \n### Participants \n  \nForty-six participants (32 males and 14 females, mean age of 22.61\u2009\u00b1\u20093.61 years) from the Korea Advanced Institute for Science and Technology (KAIST) volunteered for this experiment. Details of participants\u2019 information can be found in the  . \n\n\n### Ethics statement \n  \nAll participants provided written informed consent to participate in the experiment based on sufficient explanation about the study (including blame). The study was approved by the KAIST Institutional Review Board in accordance with the Declaration of Helsinki. \n\n\n### Experimental task \n  \nEvery participant completed 240 trials of a choice task in which the goal was to acquire the \u2018correct\u2019 outcome as many times as possible. In every trial, two Tibetan character cues were presented, and participants were asked to choose one (Figure  A). Cues were probabilistically associated with either a \u2018correct\u2019 outcome or a \u2018wrong\u2019 outcome, and this correct probability was reciprocal such that \n\n\n\nwhich was explicitly conveyed to participants to make the uncertainties about the correct probabilities for both cues to be equal, thus minimizing directed exploration. This probability was changed every 10\u201350 trials between 20/30% and 80/70% to change the participants\u2019 estimation of the uncertainty of association probability between the cue and the correct choice (Figure  B). They failed to make a good choice (designed to have a higher probability of correct) right after probability reversal. However, their good choice probability increased through learning ( ). Independent with this correct probability, participants had to think about whether they might face a socially undesirable situation if they fail to make the right decision in the current trial. Particularly, if they made a wrong choice, they were probabilistically being blamed with an angry face and swear words. We called this type of feedback blame, and we instructed participants to regard this feedback as blame in the context of social situation, such as a blame given by their boss or superior (e.g. \u2018Please try to imagine as vividly as possible that your boss yells at you because you made a wrong choice\u2019). Participants sufficiently practised imagining this situation before starting the experiment (Figure  A). Importantly, we varied the conditional probability of the appearance of the blame feedback when participants made an incorrect choice block by block with a range from 20 to 40 trials. Thus, during some blocks of the task, the conditional probability of blame feedback was very high when the choice was wrong (80% or 90%; we designated these blocks \u2018high-blame\u2019 blocks, grey-shaded area of Figure  B), while in the other blocks, this conditional probability was low (10% or 20%; we designated these blocks \u2018low-blame\u2019 blocks). Additionally, to assess the mood of each trial, participants were instructed to rate their mood on a Likert scale ranging from \u22123 to 3 every eight trials after receiving secondary feedback. A total of 30 ratings were acquired from each participant. We expected that participants would implicitly or explicitly calculate the conditional probability of being blamed by making a wrong choice (we represent this subjective conditional probability of being blamed for a wrong choice of each participant as \u2018p(blame|w)\u2019), and this calculation would influence participants\u2019 decision-making, such as encouraging participants to make more deliberate and careful choices and mood, which was revealed in the results of the post-experimental survey ( ). \n\n\n\n## Behaviour analyses \n  \n### Testing effect of blame expectation on making a better choice under uncertainty \n  \nWe first examined whether people made better choices in the trials that a wrong choice is highly likely to result blame. To define a better choice, we defined a \u2018good choice\u2019 and \u2018accurate choice\u2019. In each block, there was a cue that was designed to have a higher correct probability than other cue and choosing this better cue was defined as a \u2018good\u2019 choice of that block. For example, if a cue1 was designed to have 70% correct probability in one block (thus cue2 has 30% correct probability), that cue is the good choice of that block. An \u2018accurate\u2019 choice was defined as a choice that resulted in actual \u2018Correct\u2019 feedback at each trial. Because \u2018Correct\u2019 feedback was probabilistic given the choice, people might not get \u2018Correct\u2019 feedback even if they made a good choice. We compared a good choice proportion and mean accuracy between the high-blame blocks and low-blame blocks using the paired   t  -tests. Furthermore, because we hypothesized that an effect of blame expectation would depend on uncertainty (decreasing UDN), we also compared the good choice proportion in trials expected to have high uncertainty. Considering that uncertainty is known to be maximized after probability reversal and reduced until the next reversal because of the learning ( ), we only used the first 10 trials after a reversal of the correct probability in this test. Additional behaviour analysis can be found in the  . \n\n\n### Computational modelling of an effect of blame belief on sub-optimal decision \n  \nAfter showing that participants made better decision under uncertainty when a wrong choice is highly likely to result a blame, we designed explicit computational models that can explain the internal process of computing beliefs regarding conditional probability of the blame (p(blame|w)), and this belief subsequently influences participants\u2019 decision. We hypothesized that uncertainty would increase the decision noise that increases a chance of sub-optimal choice and p(blame|w) would decrease this UDN, meaning an interaction effect between p(blame|w) and uncertainty on decision noise. Note that sub-optimal choice here was defined with respect to an internal belief (choosing an option that is believed to have lower correct probability than other options), making it different from a bad choice. A computational model explains this process, which was named as control of uncertainty-induced decision noise (CUDN) model (Figure  A). In this model, the parameter   determined the degree of suppression of UDN as p(blame|w) increases. Therefore, if   is large for some participants, those participants greatly suppress UDN when p(blame|w) is high compared with when p(blame|w) is low and vice versa ( ). We fitted the CUDN model to the participants\u2019 responses and compared this model with 15 other models ( ) with random-effect Bayesian model selection (RFX-BMS) ( ;  ). A summary of the 16 models is provided in  . Other details of the computational modelling can be found in the  . \n\n\n### Model-based fMRI analysis \n  \nWe performed a model-based fMRI analysis based on the CUDN model to investigate the neural substrate of suppression of UDN under p(blame|w). We performed parametric modulation analyses using the trial-by-trial trajectories of model variables of interest for each subject as parametric modulators of a first-level general linear model (GLM) in Statistical Parametric Mapping 12 (SPM12) ( ). Variables of interest at the onset of the cue included trial-by-trial p(blame|w) and uncertainty that influenced decision noise in the CUDN model. Moreover, we included the trial-by-trial subjective value of the sub-optimal option (that is, subjective correct probability (p(correct|cue)) of the sub-optimal option), which induces an error (sub-optimal choice). Blame prediction error (BPE) regressor was also added as a parametric modulator at the onset of secondary feedback. Details of the methods regarding fMRI acquisition, pre-processing and parametric modulation analyses can be found in the  . \n\n\n### DCM \n  \nIn the parametric modulation analysis, we found that the bilateral mPFC was robustly activated by p(blame|w), which is consistent with our hypothesis. We expected that the mPFC would be a region that controls the UDN according to the p(blame|w), and this control process would be implemented by a dynamic change of interaction between the mPFC and the region processing sub-optimal option such as the rlPFC. To test this hypothesis, we first confirmed that their connection varies by the p(blame|w) using the psychophysiological interaction (PPI) ( ) and investigated more detailed dynamics and their relationship with UDN control process using the DCM analysis ( ). Details of the methods regarding PPI and DCM analyses can be found in the  . \n\n\n\n## Results \n  \n### Behaviour analyses \n  \n#### Expectation of being blamed facilitates better performance by deliberation. \n  \nOverall, people successfully followed our sophisticated probabilistic design (68.2% of good choice proportion, significantly better than chance (50%):   t  [45.00]\u2009=\u200915.78,   P  \u2009<\u20090.001), this performance was similar but slightly lower to the performance of ideal Bayesian learner (70.1%,  ). They made more good choice in the high-blame blocks only with a marginal significance (mean good choice proportion\u2009=\u20090.692   vs   0.673,   t  [45]\u2009=\u20091.76,   P  \u2009=\u20090.085, confidence intervals [CIs]: 0.00 to 0.04,   d  \u2009=\u20090.3; two-tailed paired   t  -test; Figure  D, left). However, when compared using only uncertain trials, increment of participants\u2019 good choice proportion was small, but significant in the high-blame blocks (0.652   vs   0.614,   t  [45]\u2009=\u20092.02,   P  \u2009=\u20090.049, CIs: 0.000 to 0.077,   d  \u2009=\u20090.298, paired   t  -test), suggesting that an effect of blame expectation on promoting good choices might depend on the uncertainty level. Participants also choice with 57.3% accuracy (significantly better than chance, [45]\u2009=\u200911.45,   P  \u2009<\u20090.001) and they also more accurate choice in the high-blame blocks compared with the low-blame blocks (mean accuracy\u2009=\u20090.591   vs   0.555,   t  [45]\u2009=\u20094.09,   P  \u2009<\u20090.001, CIs: 0.02 to 0.05,   d  \u2009=\u20090.6; Figure  D, middle). Moreover, the mean response times (RTs) of the high-blame blocks were significantly longer than those of the low-blame blocks (mean RT\u2009=\u2009598 ms   vs   583 ms,   Z  \u2009=\u20093.95,   P  \u2009<\u20090.001, Wilcoxon signed-rank test; Figure  D, right). Based on these results, we expected that participants made better decisions under uncertainty via deliberation when p(blame|w) was high. \n\n\n#### Computational modelling: expecting blame optimizes decision under uncertainty while negatively influences mood. \n  \nThe CUDN model was selected with a protected exceedance probability (PEP) of 0.831 among 16 candidate models, suggesting that participants were able to control the influence of subjective uncertainty on their decision depending on the belief of how they are likely to be blamed if they make an incorrect choice (Figure  C). Furthermore, the degree of suppression on UDN under high p(blame|w), which was parameterized by   had significant positive correlation with both increase in the good choice proportion (Spearman\u2019s  \u2009=\u20090.384,   P  \u2009=\u20090.008, Figure  D) and accuracy (Spearman\u2019s  \u2009=\u20090.306,   P  \u2009=\u20090.016, Figure  E) in high-blame blocks, meaning that participants were able to make better decision under social threat by suppressing UDN. Although p(blame|w) enabled a flexible control of the UDN, this kind of belief significantly decreased the mood of participants ( ). Although \u03bd well explained individual differences of an effect of p(blame|w) on controlling UDN, the group average of the \u03bd was not significantly different from the 0 (  t  \u2009=\u20090.93,   P  \u2009=\u20090.357). Finally, because the computational modelling results can be susceptible to the prior parameter setting, we performed the susceptibility analyses on the prior parameter setting of the \u03bd. In all settings, the PEP of the CUDN model was greater than other models. However, this analysis showed that the PEP of the CUDN model changed according to the prior parameter settings and in some settings it was not sufficiently large enough ( ) (e.g. PEP\u2009=\u20090.531 in setting of prior mean\u2009=\u20090, prior variance\u2009=\u20091,  ), which could be the limitation of our computational modelling. \n  \n(A) Graphic description of the computational model of behavioural optimization under the expectation of being blamed. The CUDN model was composed of the following parts: the perceptual model and response model. The perceptual model is composed of two parallel learning systems\u2014learning p(correct|cue) by the three-level hierarchical Gaussian filter (HGF) model (blue) and learning p(blame|w) by the Rescorla\u2013Wagner (RW) model (red dashed circle). Importantly, in the response model,   represents a choice at trial k, and the  , which is the inverse temperature of the Softmax function, is a function of an estimation uncertainty   and   such that   induces decision noise and   suppresses UDN. In this graphic representation, a deterministic node and relationship are represented as dashed circles and dashed lines, respectively, while solid circles and lines represent a stochastic node and relationship. (B) Parameters of the CUDN model. In the function  , parameter   determines the participants\u2019 degree of UDN, and   determines the participants\u2019 degree of suppression on UDN as p(blame|w) increases. (C) Bayesian model selection results. The results of the RFX-BMS show that the CUDN model fits the participants\u2019 behaviour better than other models (PEP\u2009=\u20090.831). (D) Correlation between   and good choice/accuracy enhancement. The results of correlation analysis showed that the participants with large   showed enhanced good choice proportion (left) and accuracy (right) in high-blame blocks. Note that these significant correlations also existed after removing points with values outside of 2 s.d. (rightmost 2 points) from the mean (all   P  \u2009<\u20090.05). \n  \n\n\n### Model-based fMRI analysis \n  \n#### The bilateral mPFC is recruited by an expectation of blame, and the bilateral rlPFC is involved in processing of sub-optimal option. \n  \nIn the parametric modulation analyses of the p(blame|w), robust activation of a bilateral mPFC cluster extending to the lateral prefrontal cortex (lPFC) and dorsal anterior cingulate cortex (dACC) and the bilateral temporal pole cluster extending to the bilateral amygdala and hippocampus was observed (cluster-level whole brain familywise-error (FWE)-corrected   P  -value\u2009<\u20090.001 in both clusters, cluster-defining threshold [CDT]   P  \u2009=\u20090.001, uncorrected, Figure   and Table  ). Interestingly, in our additional conjunction analyses ( ), there was an overlapping activation within ventromedial prefrontal cortex (vmPFC) between p(blame|w) and subjective value difference between chosen and unchosen options ( )\u2014where an increase of such differences are related to an increase of optimal choice (cluster-level whole brain FWE-corrected   P  \u2009<\u20090.001, CDT   P  \u2009=\u20090.001, uncorrected,  ). Therefore, we suspected that this overlap within vmPFC might support the role of p(blame|w) in decreasing decision noise. Furthermore, both p(blame|w) and the variables related to the cognitive control load (decrease of absolute value difference or RT,  ) activated dACC (cluster-level whole brain FWE-corrected   P  \u2009=\u20090.008, CDT   P  \u2009=\u20090.001, uncorrected,  ) and lPFC (cluster-level whole brain FWE-corrected   P  \u2009=\u20090.005, CDT   P  \u2009=\u20090.001, uncorrected,  ) in the conjunction analyses. Note that both regions are previously known as a part of cognitive control network ( ), and thus, we suspect that this might be related to an increase of deliberation according the level of p(blame|w). Next, a parametric modulator regarding the value (subjective correct probability) of the sub-optimal option co-varied with the blood-oxygen-level-dependentsignal of the bilateral rlPFC (cluster-level whole brain FWE-corrected   P  \u2009<\u20090.001, CDT   P  \u2009=\u20090.001, uncorrected, Figure  A,   and  ), which regions were engaged in uncertainty-driven exploration in a previous study ( ). More detailed results of parametric modulation analysis are provided in the  . \n  \nResults of the parametric modulation analysis by p(blame|w). MPFC, PCC (centre) and hippocampus (left), were activated by p(blame|w) (cluster-level whole brain FWE-corrected   P  -value\u2009<\u20090.001, CDT\u2009=\u20090.001). The blue dashed circle denotes the right mPFC used in the DCM as a region of interest (ROI). \n    \n(A) Modulation of connectivity between the right mPFC and other regions by a blame expectation. The results of the PPI analysis (upper figure) suggested that functional connectivity between the right mPFC and right rlPFC was negatively modulated as p(blame|w) increased (red dashed circle, cluster-level whole brain FWE-corrected   P  -value\u2009=\u20090.039, CDT\u2009=\u20090.05). This rlPFC cluster had large overlap with the rlPFC clusters involved in the processing of the sub-optimal option (lower figure, cluster-level whole brain FWE-corrected   P  -value\u2009<\u20090.001, CDT\u2009=\u20090.001). (B) DCM models explaining dynamics between right mPFC and rlPFC. The winning model showed the bidirectional fixed connections between the right mPFC (blue dashed circle in Figure  ) and rlPFC (red dashed circle in Figure 4A). Both connections were modulated by p(blame|w) and p(blame|w) also acted as a driving input to the mPFC. The fixed connection from the right rlPFC to the mPFC (blue arrow) was related to the degree of UDN. Moreover, p(blame|w) acted as a driving input to the right mPFC, and the effective connectivities from the right mPFC to the rlPFC as well as from the right rlPFC to the mPFC were modulated by p(blame|w) (red dashed line). The modulation of effective connectivity from the right rlPFC to the mPFC was related to the degree of UDN control via p(blame|w). \n    \nRegions activated by p(blame|w) \n  \nAAL, automated anatomical labeling; TP, temporal pole; MTG, middle temporal gyrus; STG, superior temporal gyrus. \n  \n\n#### Blame expectation negatively modulates effective connectivity from the right rlPFC to the right mPFC to suppress the UDN. \n  \nIn the PPI analysis, we found out that functional connectivity between right mPFC and right rlPFC was negatively modulated by p(blame|w) (cluster-level whole brain FWE-corrected   P  \u2009=\u20090.039, CDT   P  \u2009=\u20090.05, Figure  A and  ) and the degree of negative modulation was significantly correlated with   (Spearman\u2019s  \u2009=\u2009\u20140.34,   P  \u2009=\u20090.029). To clarify the specific neural dynamics and to identify how those dynamics account for the control of UDN under blame expectation, we performed DCM analysis between two regions. In the RFX-BMS among 16 DCM models considering all possible interaction patterns between 2 regions, model 7 (Figure  B), which includes a driving input to the right mPFC by p(blame|w), a bidirectional fixed connection between two regions and modulation of both connections by p(blame|w), was selected with a PEP of 0.999. We conducted a robust linear regression analysis using the parameter   as a dependent variable and two effective connectivities, one from the right mPFC to the right rlPFC and another from the right rlPFC to the right mPFC in model 7, as independent variables to identify which direction of modulation by p(blame|w) was related to the suppression of UDN. Only the effective connectivity from the right rlPFC to the right mPFC negatively influenced   ( \u2009=\u2009\u22120.46,   t  [29]\u2009=\u2009 \u22123.09,   P  \u2009=\u20090.004, CIs: \u22120.75 to \u22120.17,   d  \u2009=\u2009\u22120.5), whereas the effective connectivity in the opposite direction did not ( \u2009=\u2009\u22120.2,   t  [29]\u2009=\u2009 \u22121.33,   P  \u2009=\u20090.193, CIs: \u22120.49 to 0.09,   d  \u2009=\u2009\u22120.2). Furthermore, because the modulation from the baseline \u2018fixed\u2019 connectivity was related to the modulation of UDN by p(blame|w), we suspected that the fixed connection from the right rlPFC to the right mPFC might be related to the UDN and the modulation of this connection is related to the control of UDN. To test this hypothesis, we performed a robust linear regression analysis using the parameter \u03b6, which is related to the UDN as the dependent variable and the fixed connection from the right rlPFC to the right mPFC as an independent variable, which showed a positive relationship between two variables (beta\u2009=\u20090.24,   t  [30]\u2009=\u20092.08,   P  \u2009=\u20090.047, CIs: 0.01 to 0.46,   d  \u2009=\u20090.4, Figure  B). In summary, we showed that the UDN is related to the fixed connection from the right rlPFC to the right mPFC and that the modulation of this connection via p(blame|w) is related to UDN suppression. \n\n\n\n\n## Discussion \n  \nUnder the condition that a wrong decision leads to severe blame by another, we must regulate ourselves to make better decisions. In such situation, participants enhanced their ability to make better choices under uncertainty through the suppression of UDN. This means that when one is already confident about the best action, then an expectation of being blamed has little effect\u2014however, when one is unsure, then blame tends to increase optimal choices by reducing random exploration. However, expecting such blame with high probability impaired participants\u2019 mood. Furthermore, fMRI analyses, including DCM analyses, revealed that a neural mechanism underlying this behavioural tendency is related to the suppression of connectivity from the right rlPFC to the mPFC as p(blame|w) increases, where the right rlPFC was engaged in processing the sub-optimal option and the right mPFC was activated by p(blame|w). \n\nOur study improves our understanding of the behavioural and neural mechanisms of optimal decision-making strategies to avoid aversive outcomes expected for incorrect decisions in a social context and how such kind of stressor influences our mood. From a behavioural perspective, when punishment or loss is expected with lower performance, participants enhance their performance by enhancing working memory function ( ) or inhibitory control mechanisms ( ). However, to the best of our knowledge, few studies have proposed the computational mechanisms that are involved in optimizing uncertain decisions under punishment expectations based on explicit computational models of behaviour. In the present study, using the CUDN model, we successfully showed that participants increased good and accurate choices when a conditional probability of blame given a wrong choice was high through the flexible control of UDN. \n\nIn many cases, random exploration might be beneficial for maximizing a long-term expected reward because it helps the individual obtain information about uncertain options ( ;  ). However, in situations such as our task, where there is no more information gain by choosing one option over another, random exploration would become a choice that might decrease the accuracy of the choice. We modelled this effect of expectation of being blamed on uncertainty-driven sub-optimal choices using a CUDN model in which an uncertainty increases decision noise and p(blame|w) controls this UDN; this model explained participants\u2019 behaviours better than other models. An interesting point regarding models where p(blame|w) had a negative value is that p(blame|w) naturally decreased the decision noise, regardless of the amount of uncertainty, which is different from the CUDN model in which only UDN is influenced by p(blame|w). Therefore, another point recognized from the Bayesian model selection results is that p(blame|w) likely controls the decision noise in a manner proportional to a degree of uncertainty but not in an uncertainty-independent manner. Because the decision noise increases with uncertainty, the requirement for the suppression of UDN to make an optimal choice is higher when high uncertainty exists. Furthermore, based on the results of the post-experimental survey, we recognized that participants made more deliberate, effort-driven decisions under threat, resulting in the suppression of (uncertainty-driven) decision noise. Thus, we surmise that the suppression of decision noise might require a mental effort that is costly to exert ( ;  ). Therefore, we speculated that a balance between the cost of deliberation and the need to suppress decision noise to make an optimal choice under uncertainty might increase the efficiency of the suppression of UDN, particularly in a volatile environment in which an uncertainty level continuously changes, such as in our task. \n\nAfter confirming that p(blame|w) controlled the UDN, we revealed that the suppression of UDN enabled the participant to make a better choice by showing a positive correlation between increased good choice proportion and accuracy in the high-blame blocks and the model parameter  . Therefore, our behavioural results suggest that when a wrong choice is likely to result in an aversive outcome under the uncertain decision-making situation used in our task, an agent tries to make a better choice by suppressing UDN to some degree. However, although \u03bd well explained individual differences regarding the effect of p(blame|w) on controlling UDN, it seems that this parameter alone is insufficient to explain this effect. Considering that group average of \u03bd was not significantly different from the 0 despite increased good/accurate choice in high-blame blocks, we speculate that this effect could be implemented by a whole CUDN model including interactions between \u03bd other parameters. For example, because an increase of optimal choice depends on decreasing UDN, an effect of p(blame|w) on controlling UDN would be affected also by the \u03b6. Note that \u03b6 determines the degree of decision noise induced by an uncertainty. This point is a limitation of our study and should be investigated in future studies. Additionally, we also have shown that an inference regarding a conditional probability of the blame significantly impaired participants\u2019 mood. People suffer from abusive supervision are at high risk of affective disorder ( ). We speculate that people who are frequently exposed to abusive supervision similar to our task such that their supervisor forces them to make good decision under uncertainty with social punishment would be more likely to evolve an affective disorder by an accumulation of a daily negative mood induced by an aversive outcome expectation by their wrong decision. \n\nWe then identified the neural mechanism underlying the expectation of blame and the suppression of the UDN by p(blame|w). The regions involved in processing p(blame|w) included the mPFC, hippocampus and posterior cingulate cortex (PCC), which are similar to the regions involved in the \u2018cognitive fear circuitry\u2019 ( ). The suggested role for this circuit was strategic avoidance of a threat ( ), and the authors mentioned that the mPFC is likely involved in selecting defensive response strategies ( ). This region contains \u2018strategy-selective\u2019 cells that protect against threats, as reported in an animal study ( ). Moreover, the mPFC is related to internally driven strategy shifts ( ). Consistent with these studies, subsequent DCM analyses revealed the involvement of the mPFC in the control of UDN. Especially, neural dynamics involving the right mPFC and rlPFC were related to the control of UDN via p(blame|w). Two regions had bilateral fixed connections, and these connections were negatively modulated according to the p(blame|w). Importantly, among these two directional connections, only the connection from the right rlPFC to the right mPFC was relevant to the control of UDN, such that the UDN itself was related to the fixed connection from the right rlPFC to the right mPFC, and the control of the UDN was related to the modulation of this connection via p(blame|w). \n\nBased on these results, we propose a possible neural \u2018gate\u2019 model regarding the control of the UDN based on p(blame|w) that fits with the structure of the CUDN model. In the CUDN model, given a fixed value of the sub-optimal option, (i) uncertainty increased the probability of choosing the sub-optimal option and (ii) p(blame|w) decreased such effect of uncertainty (represented by the decision noise modulation in the model). Similarly, in the DCM analyses, (i) influence of uncertainty on decision temperature (UDN) was related to the strength of fixed connectivity from rlPFC to mPFC and (ii) p(blame|w) decreased the connectivity from rlPFC to mPFC, which was related to a p(blame|w)\u2019s effect on decreasing UDN. (iii) p(blame|w) increased the mPFC activity. From these information, we focused on how p(blame|w) information can modulate the connectivity from rlPFC to mPFC while activating the right mPFC. We suggest that (i) the UDN information is encoded in the fixed connection from the right rlPFC to the mPFC. (ii) If p(blame|w) increases, p(blame|w) information is conveyed to the right mPFC and activates this region. (iii) Using this p(blame|w) information, the mPFC regulates the flow from the right rlPFC to the mPFC to control the UDN. This gate model could explain the concurrent activation of the mPFC and the negative modulation of the connection from the right rlPFC and the mPFC based on p(blame|w). This gate model not only corroborates our behavioural and fMRI analyses but also is consistent with previous studies suggesting that the mPFC controls strategic avoidance behaviour under threat ( ). Furthermore, a previous study suggested that the mPFC controls the slower and deliberate decision-making associated with difficult choices by modifying the decision threshold of the drift-diffusion model via an interaction with the sub-thalamic nucleus ( ). Especially, increasing of decision threshold increases the RT and reduces the choice noise ( ), which is effect similar to that of an effect of p(blame|w). Therefore, it could be possible that a \u2018gate\u2019 in the mPFC controlled by p(blame|w) might correspond to an increase of decision threshold. \n\nOne notable point is that whether our result could be generalizable to non-social punishment such as physical pain. Because we did not perform a similar experiment using a non-social punishment (e.g. physical pain or monetary loss), it is difficult to determine whether this effect is universal to all types of punishment or specific to blame. However, the results of this study allow us to infer the similarity and dissimilarity of the blame with other non-social stimuli. For example, if the expectation of blame is similar to that of loss, we would expect that the p(blame|w) would contribute as a negative value; however, this result was not the case in the behavioural modelling section. Furthermore, previous studies have shown that physical and social pain are similar in both emotional response and saliency as well as share a similar neural representation ( ). Moreover, we observed a similar between updating blame expectation and updating of physical pain expectation, which we discussed in the above section ( ). Therefore, we hypothesize that the effect of expecting blame might be more similar to that of expecting physical pain than to that of expecting a monetary loss. However, this hypothesis is only speculative, and an experiment using non-social stimuli might help us to identify both the similar and different neural and behaviour mechanisms that underlie the optimization of behaviour under social and non-social threats. Finally, one should note that one limitation of our computational modelling was that the result was susceptible to the selection of prior parameters, which could be resulted from the complexity of the CUDN model. \n\nIn conclusion, we identified one strategy for optimizing uncertain decision-making under a threat and the underlying neural mechanism. Because there was no benefit of the sub-optimal choice in our task, the suppression of UDN under the blame expectation helped participants to make better decisions in those situations, and this phenomenon was successfully modelled using the CUDN model. On the other hand, an expectation of being blamed deteriorated participants\u2019 mood. The implementation of this behavioural optimization strategy was related to the suppression of effective connectivity from the right rlPFC to the right mPFC as p(blame|w) increased. These results added one novel neural mechanism of a brain region related to processing threat that actually interacted with other decision-making-related regions to avoid a threatening outcome. \n\nBecause we addressed only one optimization mechanism under particular conditions, where directed exploration is absent or minimal, an extension of our research to determine how directed exploration is influenced in this situation would be interesting. Based on recent findings that people became more \u2018myopic\u2019 under the threat ( ), we speculate that directed exploration would also be reduced by blame expectation and it could explain reduced creativity under the threat. Finally, from the perspective of computational psychiatry, an investigation of the optimization behaviour of our task in patients with psychiatric conditions, such as autism and psychopathologies, would be interesting to quantify their lack of an ability to expect social responses and utilize adaptive behaviours ( ). \n\n\n## Supplementary Material \n  \n \n\n# Table(s)\n## ID: T1\n### Label: Table 1.\nCluster(CDT P\u2009=\u20090.001, uncorrected)\tClusterP-value (whole brain FWE corrected)\tNo. of voxels\tRegion name (AAL)\tMNIcoordinates(x, y, z)\tVoxelZ-value (uncorrected P-value)\nmPFC\t<0.001\t4556\tFrontal_Sup_Medial_L\t\u22128, 62, 28\t6.65(<0.001)\nmPFC\t<0.001\t4556\tFrontal_Sup_Medial_R\t6, 60, 32\t5.27(<0.001)\nRight TP/hippocampus/amygdala\t<0.001\t1156\tTemporal_Pole_Mid_R\t\u22124, \u221246, 35\t5.51(<0.001)\nRight TP/hippocampus/amygdala\t<0.001\t1156\tHippocampus_R\t20, 4, 18\t4.93(<0.001)\nLeft TP/hippocampus/amygdala\t<0.001\t1368\tTemporal_Pole_Sup_L\t\u221244, 16, \u221240\t4.95(<0.001)\nPCC\t<0.001\t407\tCingulate_Mid_L\t\u22124, \u221246, 34\t4.61(<0.001)\nPCC\t<0.001\t407\tCingulate_Post_L\t\u221212, \u221246, 30\t4.50(<0.001)\nRight MTG/STG\t<0.001\t1120\tTemporal_Mid_R\t52, \u221218, \u221210\t5.47(<0.001)\nLeft MTG/STG\t<0.001\t814\tTemporal_Mid_L\t\u221256, \u221228, \u22126\t5.13(<0.001)\nLeft MTG\t0.003\t210\tTemporal_Mid_L\t\u221242, \u221260, 20\t4.05(<0.001)\ndACC/MCC\t0.007\t178\tCingulate_Mid_L\t\u22122, \u221218, 34\t4.35(<0.001)\nCerebellum\t<0.001\t817\tCerebelum_Crus2_R\t24, \u221286, \u221236\t5.31(<0.001)\nCerebellum\t0.009\t166\tCerebelum_Crus1_L\t\u221242, \u221268, \u221224\t4.76(<0.001)\nCerebellum\t0.012\t157\tCerebelum_Crus2_L\t\u221222, \u221286, \u221234\t4.66(<0.001)\n### Caption\nRegions activated by p(blame|w)\n### Footer\nAAL, automated anatomical labeling; TP, temporal pole; MTG, middle temporal gyrus; STG, superior temporal gyrus.\n", "metadata": {"pmcid": 7745153, "text_md5": "958117f59ddf0f4e88126e9fd4e4352d", "field_positions": {"authors": [0, 32], "journal": [33, 57], "publication_year": [59, 63], "title": [74, 194], "keywords": [208, 303], "abstract": [316, 1643], "body": [1652, 42186], "tables": [42199, 43506]}, "batch": 2, "pmid": 33104801, "doi": "10.1093/scan/nsaa145", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7745153", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7745153"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7745153\">7745153</a>", "list_title": "PMC7745153  Expecting social punishment facilitates control over a decision under uncertainty by recruiting medial prefrontal cortex"}
{"text": "Sohoglu, Ediz and Kumar, Sukhbinder and Chait, Maria and Griffiths, Timothy D.\nNeuroimage, 2020\n\n# Title\n\nMultivoxel codes for representing and integrating acoustic features in human cortex\n\n# Keywords\n\nAuditory cortex\nParietal cortex\nfMRI\nMultivariate\nFeature binding\n\n\n# Abstract\n \nUsing fMRI and multivariate pattern analysis, we determined whether spectral and temporal acoustic features are represented by independent or integrated multivoxel codes in human cortex. Listeners heard band-pass noise varying in frequency (spectral) and amplitude-modulation (AM) rate (temporal) features. In the superior temporal plane, changes in multivoxel activity due to frequency were largely invariant with respect to AM rate (and vice versa), consistent with an independent representation. In contrast, in posterior parietal cortex, multivoxel representation was exclusively integrated and tuned to specific conjunctions of frequency and AM features (albeit weakly). Direct between-region comparisons show that whereas independent coding of frequency weakened with increasing levels of the hierarchy, such a progression for AM and integrated coding was less fine-grained and only evident in the higher hierarchical levels from non-core to parietal cortex (with AM coding weakening and integrated coding strengthening). Our findings support the notion that primary auditory cortex can represent spectral and temporal acoustic features in an independent fashion and suggest a role for parietal cortex in feature integration and the structuring of sensory input. \n   Highlights  \n  \nThis study used fMRI and multivariate analysis to examine acoustic feature coding \n  \nIn auditory cortex, frequency and AM rate were represented primarily independently \n  \nIn parietal cortex, multivoxel representation was exclusively integrated \n  \n \n\n# Body\n \n## Introduction \n  \nIn structuring the auditory scene, the brain must carry out two fundamental computations. First, it must derive   independent   representations of component acoustic features so that task-relevant features can be prioritized and task-irrelevant ones ignored. Second, to solve the well-known \u201cbinding problem\u201d, the brain must subsequently   integrate   these separated representations into a coherent whole so that the features of a relevant sound source can be tracked successfully in cluttered scenes. Whether representations of stimulus features are independent or integrated is a longstanding issue in psychology ( ;  ) and neuroscience ( ;  ). Even when not explicitly framed using these terms, many questions concerning sensory systems can be formalized in terms of representational independence versus integration ( ). \n\nIt is widely believed that auditory processing is hierarchically organized and that neural representations are progressively transformed from independent to integrated codes as sensory information ascends the auditory pathway ( ;  ). Thus, while neurons in low-level regions might respond to single stimulus features, higher-level neurons should show more complex tuning properties and respond to conjunctions of features. Precisely where along this continuum human primary auditory cortex (and regions beyond) fit within this conception of the auditory system has been the subject of debate. \n\nBased on presumed similarities with the visual system, early models proposed that representations in primary auditory cortex were primarily independent, instantiated as topographically organized \u201cfeature maps\u201d (see  ). According to such accounts, the integration of features is a computation that should most reliably be observed in non-primary regions. However, animal physiology studies demonstrate highly nonlinear neural responses already at the level of primary auditory cortex, suggestive of an integrated coding scheme ( ;  ;  ;  ;  ;  ;  ;  ;  ). The extent to which this also applies in humans remains unclear. While there are many sources of human imaging evidence that are potentially relevant to this issue, particularly investigations of how low-level acoustic features and higher-level categories are represented in cortical activity ( ;  ;  ;  ;  ;  ;  ;  ;  ;  ;  ), fewer studies have directly tested and quantified the extent of representational independence versus integration in human cortex. \n\nIn the current study, we used fMRI and multivariate pattern analysis to determine the extent to which spectral and temporal acoustic features are represented by independent or integrated multivoxel codes and how those codes are expressed over the human cortical hierarchy. Participants listened to band-pass noise varying across stimuli in frequency (a spectrally-based feature) and amplitude modulation (AM) rate (temporally-based; see  A). We chose to investigate these two acoustic features as they are sufficient alone to characterize much of the information present in biologically important sounds such as speech ( ;  ). An approach based on MANOVA ( ) allowed us to estimate the independent contributions of frequency and AM features to the observed multivoxel patterns, as opposed to nonlinear interactions between the features that are a signature of integrated coding ( ;  ). Moreover, by acquiring whole-brain fMRI, we were able to characterize multivoxel representations across the entire human cortex, in contrast to more localized physiological recordings in animals.   \nA) Spectrograms of the nine stimuli, with the spectrogram frequency axis equally spaced on a scale of Equivalent Rectangular Bandwidth (ERB;  ) and smoothed to obtain a temporal resolution similar to the Equivalent Rectangular Duration ( ). This depiction more accurately captures spectral representation in the ascending auditory system than a spectrogram with a linear frequency axis. Note that the carrier frequencies of the presented stimuli were equally spaced on a logarithmic (rather than ERB) scale. The cyan- and magenta-colored text above each spectrogram indicate the center carrier frequency and AM rate of the bandpass noise, respectively. B) Statistical contrast matrices for testing the two main effects (of Frequency and AM) and Frequency\u00a0\u200b\u00d7\u00a0\u200bAM interaction. These contrasts follow the standard form for the two main effects and interaction under a 3\u00a0\u200b\u00d7\u00a0\u200b3 design ( ). From these three contrasts, we could test for independent and integrated coding (see Methods section for details). C) Multivariate pattern distinctness estimates for each effect of interest, when activity patterns were simulated using an independent representation (left-side graph) or an integrated representation (right-side graph). Each data point represents the pattern distinctness for a single iteration (\u201cparticipant\u201d) of the simulation. Freq, Frequency. D, Pattern distinctness. \n  Fig.\u00a01   \n\n\n## Methods \n  \n### Participants \n  \nTwenty participants (eleven female), aged between 18 and 27 years (mean\u00a0\u200b=\u00a0\u200b23, SD\u00a0\u200b=\u00a0\u200b2.4), were tested after being informed of the study\u2019s procedure, which was approved by the research ethics committee of University College London. All reported normal hearing, normal or corrected-to-normal vision, and had no history of neurological disorders. Our sample size is in line with (or exceeds that of) related studies with   a priori   unknown effect sizes (e.g.  ;  ;  ;  ). While recent methods work recommends larger sample sizes for (univariate) fMRI studies ( ;  ), we note that this recommendation was made in the context of more complex cognitive paradigms each lasting around 10\u00a0\u200bmin. Thus, both cross- and within-participant variability might be expected to be greater than for the simpler sensory paradigm employed here conducted over a longer scanning time of 50\u00a0\u200bmin (for a discussion of the trade-off between sample size and scan duration, see  ). \n\n\n### Stimuli \n  \nThe stimulus consisted of narrow (third of an octave) bandpass noise, amplitude modulated sinusoidally with 80% depth (see  A). Each sound was presented for 1\u00a0\u200bs and varied across trials in center carrier frequency (from hereon, \u201cfrequency\u201d) and amplitude modulation rate (\u201cAM\u201d). Frequency (500, 1300 and 3380\u00a0\u200bHz) and AM (4, 10 and 25\u00a0\u200bHz) were equally spaced on a logarithmic scale. Importantly for the purpose of assessing independent and integrated feature coding (see First-level statistics section below), frequency and AM varied across stimuli in an orthogonal fashion, such that every frequency was paired with every AM (i.e. nine stimuli in total, arranged as a 3\u00a0\u200b\u00d7\u00a0\u200b3 factorial design). The relatively slow AM rates precluded the perception of pitch associated with the temporal modulation. In addition, the carrier center frequencies and bandwidths were chosen to avoid detectable spectral cues from resolved sidebands in the stimulus ( ). Sidebands will be most detectable for sounds with fast AM rates and low carrier frequencies ( ). In the current study, this corresponds to the stimulus with the 500\u00a0\u200bHz carrier frequency and 25\u00a0\u200bHz AM rate. However, the sidebands resulting from this stimulus (500\u00a0\u200b+\u00a0\u200b25\u00a0\u200b=\u00a0\u200b525\u00a0\u200bHz and 500\u201325\u00a0\u200b=\u00a0\u200b475\u00a0\u200bHz) fall inside the auditory filter centered at 500\u00a0\u200bHz with an equivalent rectangular bandwidth (ERB) of 79\u00a0\u200bHz ( ). \n\nStimuli were matched in terms of their RMS amplitude and shaped with 20\u00a0\u200bms raised-cosine onset and offset ramps. Bandpass noise was synthesized independently on each presentation (with a sampling rate of 44,100\u00a0\u200bHz) and delivered diotically through MRI-compatible insert earphones (S14, Sensimetrics Corporation). To compensate for resonances in the frequency response of the earphones, the stimuli were digitally preprocessed using the filters and software provided with the earphones. \n\n\n### Procedure \n  \nStimulus delivery was controlled with Cogent toolbox ( ) in Matlab (MathWorks). Participants were scanned for five runs, each lasting around 10\u00a0\u200bmin consisting of sixteen repetitions of the nine stimuli. For one participant, there was insufficient time to scan for the fifth run because of technical difficulties. Stimuli were grouped into blocks of eighteen sounds within which all nine stimuli appeared twice and in random order. The inter-stimulus interval ranged uniformly between 2000 and 4000\u00a0\u200bms. \n\nParticipants were instructed to listen carefully to the sounds while looking at a central fixation cross and press a button (with their right hand) each time a brief (150\u00a0\u200bms duration) white-noise interruption occurred during sound presentation. These white-noise interruptions were unmodulated in their amplitude profile and occurred on a small percentage (~6%) of stimuli (once every block of eighteen sounds). Group performance was near ceiling, confirming engagement with the task. The average hit rate was .98 (ranging from 0.8 to 1 across participants; SEM\u00a0\u200b=\u00a0\u200b0.014) with no false alarms. \n\nTo estimate the perceived saliency of the sounds, two participants from the main fMRI experiment and four new participants (two female; mean age\u00a0\u200b=\u00a0\u200b29 years, SD\u00a0\u200b=\u00a0\u200b4) completed a short behavioral session similar in procedure to  . These participants listened to all pairwise combinations of the nine sounds (eight pairs for each of the nine sounds; separated by 200\u00a0\u200bms of silence) and were asked to judge on each trial which of the two sounds was more salient. Participants were told that saliency refers to how much a sound would grab their attention. Pairs were presented three times in random order, with the order of the sounds within a pair counterbalanced across trials. \n\nTo estimate perceived loudness, we used the loudness model of  , as implemented in Matlab ( ). As the model output differs slightly for different noise samples of the same stimulus, we generated an entire (single-participant) stimulus set in the same way as was done for the main experiment which we submitted to the model. We computed the time-varying long-term loudness, averaged over the duration of the stimulus and across noise samples for each of the nine stimuli. \n\n\n### Image acquisition \n  \nImaging data were collected on a Siemens 3\u00a0\u200bT Quattro MRI scanner ( ) at the Wellcome Trust Center for Human NeuroImaging, University College London. A total of 175 echo planar imaging (EPI) volumes were acquired per run, using a 32-channel head coil and continuous sequence (TR\u00a0\u200b=\u00a0\u200b3.36\u00a0\u200bs; TE\u00a0\u200b=\u00a0\u200b30\u00a0\u200bms; 48 slices covering the whole brain; 3\u00a0\u200bmm isotropic resolution; matrix size\u00a0\u200b=\u00a0\u200b64\u00a0\u200b\u00d7\u00a0\u200b74; echo spacing\u00a0\u200b=\u00a0\u200b0.5\u00a0\u200bms; orientation\u00a0\u200b=\u00a0\u200btransverse). After the third run, field maps were acquired (short TE\u00a0\u200b=\u00a0\u200b10\u00a0\u200bms; long TE\u00a0\u200b=\u00a0\u200b12.46\u00a0\u200bms). During the functional scans, we also obtained physiological measures of each participant\u2019s breathing and cardiac pulse. Because of technical issues, physiological measures were not available for two participants. The experimental session concluded with the acquisition of a high-resolution (1\u00a0\u200b\u00d7\u00a0\u200b1\u00a0\u200b\u00d7\u00a0\u200b1\u00a0\u200bmm) T1-weighted structural MRI scan. \n\nThe randomized presentation order of the nine stimuli was employed to sensitively detect between-stimulus differences in BOLD signal ( ). However, our experimental design also permitted detection of sound versus implicit baseline as we randomized the ISIs uniformly between 2 and 4\u00a0\u200bs (equivalent to 3\u20135\u00a0\u200bs stimulus onset asynchrony). Although this stimulus timing is fast relative to the duration of the haemodynamic response function (which peaks around 5\u00a0\u200bs), the randomization of ISIs sufficiently enabled the detection of BOLD signal variations relating to sound versus baseline. This is confirmed by inspection of the predicted BOLD timeseries and by the parameter estimates in superior temporal plane regions, which were reliably greater than baseline (shown in  ).   \nWhole-cortex multivariate searchlight analysis. A) Group-level statistical maps for each effect of interest, overlaid onto coronal and axial sections of the group-averaged structural (in MNI space) and thresholded voxelwise at   p  \u00a0\u200b<\u00a0\u200b.005 and clusterwise at   p  \u00a0\u200b<\u00a0\u200b.05 (FWE corrected for multiple comparisons). B) ROI analysis. Each data point shows the pattern distinctness D, averaged over the searchlight map within each ROI and over participants. Error bars represent the standard error of the mean. Asterisk symbols above each data point indicate significantly above-zero pattern distinctness, FDR corrected for multiple comparisons across contrasts, ROIs and hemispheres. \u2217\u2217\u2217  p  \u00a0\u200b<\u00a0\u200b.001, \u2217\u2217  p  \u00a0\u200b<\u00a0\u200b.01, \u2217  p  \u00a0\u200b<\u00a0\u200b.05. \n  Fig.\u00a02   \n\n\n### Image processing \n  \nfMRI analysis was performed in SPM12 ( ). After discarding the first three volumes to allow for magnetic saturation effects, the remaining images were realigned and unwarped to the first volume to correct for movement of participants during scanning. Also at the unwarping stage, the acquired field maps were used to correct for geometric distortions in the EPI due to magnetic field variations. Realigned images were co-registered to the mean functional image and then subjected to multivariate statistical analysis, generating searchlight maps from unsmoothed data in each participant\u2019s native space (see First-level statistics section below). Searchlight maps were subsequently normalized to the Montreal Neurological Institute (MNI) template image using the parameters from the segmentation of the structural image (resampled resolution: 2\u00a0\u200b\u00d7\u00a0\u200b2\u00a0\u200b\u00d7\u00a0\u200b2\u00a0\u200bmm) and smoothed with a Gaussian kernel of 6\u00a0\u200bmm full-width at half-maximum. Where additional univariate analyses are reported, realigned images were spatially normalized and smoothed first before statistical analysis. \n\n\n### First-level statistics \n  \nStatistical analysis was based on the general linear model (GLM) of each participant\u2019s fMRI time series, using a 1/128\u00a0\u200bs highpass filter and AR1 correction for auto-correlation. The design matrix comprised the auditory stimulus events, each modeled as a stick (delta) function and convolved with the canonical haemodynamic response function. Separate columns were specified for each of the nine stimuli, in addition to a column for target sounds (to remove variance associated with the white noise interruptions and the button presses). Additional columns were specified for the six movement parameters and the mean of each run. Cardiac and respiratory phase (including their aliased harmonics) as well as heart rate and respiratory volume were modeled using an in-house Matlab toolbox ( ). This resulted in fourteen physiological regressors in total: six each for cardiac and respiratory phase and one each for heart rate and respiratory volume. \n\nFor statistical inference, we used cross-validated multivariate analysis of variance ( ), as implemented in the cvMANOVA toolbox in Matlab (version 3;  ). For each participant, this method measures the pattern distinctness D, a cross-validated version of one of the standard multivariate statistics: Lawley-Hotelling\u2019s trace. \n\nLawley-Hotelling\u2019s trace (  \u0394  ) quantifies the amount of multivariate variance explainable by an experimental contrast, in units of error variance: where   B   are the parameter contrasts,   X   is the design matrix and   \u2211   is the error covariance matrix. The pattern distinctness D is derived by additionally cross-validating the data using a leave-one-run-out procedure (for further details, see  ). Cross-validation ensures that the expected value of D is zero if two voxel patterns are not statistically different from each other, making D a suitable summary statistic for group-level inference (e.g. with the one-sample   t  -test). Note that because of this cross-validation, D can sometimes be negative if its true value is close to zero in the presence of noise. \n\nIn contrast to classification accuracy from pattern decoders, which is dependent on the particular algorithm used as well as the amount of data and partitioning into training and test sets, D is a clearly interpretable, standardized effect size (for examples of previous applications, see  ;  ,  ;  ). When applied to the simple case of only two stimuli, D is a measure of between-stimulus pattern dissimilarity and is closely related to the (cross-validated) Mahalanobis distance, which has been demonstrated to be a more reliable and accurate metric for characterizing multivoxel patterns than the correlation or Euclidean distance ( ;  ;  ). Like the Mahalanobis distance, D takes into account the spatial structure of the noise (GLM residuals) by normalizing the multivoxel variation for an experimental effect by the noise covariance between voxels. As D is obtained from the GLM, cvMANOVA can also be used to test more complex contrasts such as the main effects and interactions of a factorial design. For the 3\u00a0\u200b\u00d7\u00a0\u200b3 design of the present study, the contrast matrices for the two main effects and interaction take the standard form ( ) and are shown in  B. \n\nWe tested the extent to which frequency and AM features are represented by independent or integrated multivoxel codes by examining three effects of interest. If frequency and AM features are represented in an integrated fashion, then changes in these two features should combine nonlinearly (non-additively) to influence multivoxel activity patterns (see  ;  ). In other words, the effect of frequency should differ depending on AM (and vice versa). Thus, the first effect of interest was the interaction between frequency and AM and quantified the extent of integrated coding. If on the other hand, frequency and AM features are coded independently, then changes in these two features should result in a linear (additive) effect on activity patterns. An independent effect implies that changes in voxel patterns attributable to the frequency feature remain invariant with respect to AM (and vice versa): there is no interaction. Within the cvMANOVA framework, the extent of independence can therefore be quantified by subtracting the interaction from the main effects as follows (see equation 19 in  ): where   D(Freq)  ,   D(AM)   and   D(Interaction)   are the pattern distinctness estimates for the main effects of frequency, AM and the interaction, respectively.   L(Freq)   and   L(AM)   are the number of levels for the frequency and AM factors, respectively (for the current design,   L(Freq)  \u00a0\u200b=\u00a0\u200b  L(AM)  \u00a0\u200b=\u00a0\u200b3).   expressed such contrasts as measures of \u201cpattern stability\u201d but are equivalently considered measures of independent coding ( ). \n\nComputational simulations confirm that the above effects of interest capture the presence of independent and integrated representations, in line with previous modeling work and applications in the visual and motor domains ( ;  ). For each of twenty \u201cparticipants\u201d and nine stimuli, we generated synthetic activity patterns over 123 voxels consisting of the true underlying pattern (normal random vector) and a noise component that was generated independently for each of five \u201cruns\u201d and sixteen repetitions of the nine stimuli. These synthetic data were then submitted to cvMANOVA resulting in a pattern distinctness estimate for each participant and effect of interest. \n\nTwo versions of the simulation were run, differing in the generative model used to produce the voxel patterns. In the first version, frequency and AM features were represented independently. That is, voxel patterns were generated separately for the two features and summed together to obtain voxel patterns (Y) for each of the nine stimuli with carrier center frequency f and AM rate m: where   F   and   T   denote, respectively, the voxel pattern representations for the frequency and AM features and e the noise. \n\nIn the second version, frequency and AM were represented in an integrated fashion by generating a unique pattern for each of the nine stimuli. Thus, in this version of the simulation, the representation of frequency is inseparable from that of AM: Here   FT   denotes the true pattern that was generated uniquely for each stimulus. In both versions, the resulting patterns were scaled to have the same mean and variance. \n\nIn the present version of the simulations, the variance of the noise was set to 10 times that of the true underlying pattern. We could vary this ratio to modulate the overall effect sizes in the simulations and to match those observed in the experimental data. However, our goal here was not to recreate the precise conditions of the experiment. This would require modeling the spatiotemporal correlation of within-subject noise and cross-subject variability, which is outside the scope of the current study. Rather, through the use of a generative model, we wished to provide a more formal definition of independent and integrated coding. In addition, we wished to confirm that   in principle  , our experimental contrasts can indeed capture independent and integrated coding in the specific context of our 3\u00a0\u200b\u00d7\u00a0\u200b3 factorial design. For more detailed simulations that validate the current methods, see   and  . \n\nAs  C shows, when frequency and AM were simulated as independent representations, the pattern distinctness D was significantly greater than zero when testing the independent (but not integrated) coding effects of interest (frequency:   t  (19)\u00a0\u200b=\u00a0\u200b29.2,   p  \u00a0\u200b<\u00a0\u200b.001; AM:   t  (19)\u00a0\u200b=\u00a0\u200b35.1,   p  \u00a0\u200b<\u00a0\u200b.001; Integrated:   t  (19)\u00a0\u200b=\u00a0\u200b\u22120.104,   p  \u00a0\u200b=\u00a0\u200b.541). In contrast, when frequency and AM were represented in an integrated fashion, the reverse was true with a significant effect of integrated (but not independent) coding (frequency:   t  (19)\u00a0\u200b=\u00a0\u200b\u22121.39,   p  \u00a0\u200b=\u00a0\u200b.910; AM:   t  (19)\u00a0\u200b=\u00a0\u200b\u22120.429, p\u00a0\u200b=\u00a0\u200b.664; Integrated:   t  (19)\u00a0\u200b=\u00a0\u200b33.0,   p  \u00a0\u200b<\u00a0\u200b.001). This pattern of results was supported by a repeated measures ANOVA in which we observed a significant two-way interaction between simulation type (independent versus integrated) and effect of interest (frequency/AM/integrated;   F  (2,30)\u00a0\u200b=\u00a0\u200b737.2,   p  \u00a0\u200b<\u00a0\u200b.001). \n\ncvMANOVA was performed as a searchlight analysis ( ) using spheres with a radius of three voxels (~9\u00a0\u200bmm; ~123 voxels of 3\u00a0\u200b\u00d7\u00a0\u200b3\u00a0\u200b\u00d7\u00a0\u200b3\u00a0\u200bmm) and constrained to voxels within the whole-brain mask generated by SPM during model estimation. This whole-brain mask does not explicitly exclude white matter voxels but inspection of the overlap with a probabilistic white matter mask revealed no overlap with high probability (>80%) white matter voxels. Moreover, the noise normalization performed by cvMANOVA should in principle automatically downweight noise from white matter voxels, circumventing the need to explicitly distinguish between gray and white matter. Thus, for each participant and effect of interest, a whole-brain searchlight image was generated in which each voxel expressed the pattern distinctness D over that voxel and the surrounding neighborhood. As recommended by  , to correct for searchlight spheres near the brain mask boundaries containing fewer voxels, the estimate of D at each voxel was adjusted by dividing by the square root of the number of voxels within the searchlight. \n\n\n### Group-level statistics \n  \nFor whole-cortex statistical analysis of the multivariate data, searchlight images were submitted to a group-level one-sample   t  -test under minimal assumptions using the nonparametric permutation test ( ). In this procedure, the sign of the pattern distinctness at each voxel for each subject was randomly flipped. The one-sample   t  -statistic was subsequently computed at each voxel, the image thresholded and the largest cluster size noted. By repeating these steps over a number of iterations (here 5000), we could build a null distribution of cluster sizes against which to compare the observed cluster size at each voxel. Note that because the true pattern distinctness can never be negative, a one-sample   t  -test in this context effectively provides fixed-effect inference ( ). This is similar to   t  -tests on classification accuracies, the true values of which can never be below chance. Whole-cortex statistics for the univariate analysis were also based on the permutation test. Here we used a one-sample   t  -test for comparing sound-evoked activation with the implicit baseline and repeated measures ANOVA with the factors frequency and AM to test between-stimulus differences. When using ANOVA, the null distribution was created by randomly shuffling the nine stimulus labels. We constrained all analyses to voxels within the cortex (as defined by the probabilistic Harvard-Oxford cortical mask thresholded at 25%, distributed with FslView  ). Statistical maps were thresholded voxelwise at   p  \u00a0\u200b<\u00a0\u200b.005 and clusterwise at   p  \u00a0\u200b<\u00a0\u200b.05 (familywise error [FWE] corrected for multiple comparisons). \n\nAdditional region of interest (ROI) analyses were conducted by averaging over the searchlight and univariate contrast images in locations anatomically defined by the J\u00fclich and Harvard-Oxford probabilistic atlases (distributed with FslView) and thresholded at 30%. This ROI analysis was conducted parametrically (i.e. without using the permutation test). The ROIs included primary auditory cortex (area Te1.0 in middle Heschl\u2019s gyrus [HG]) and the non-primary auditory areas Te1.1 (posteromedial HG), Te1.2 (anterolateral HG), planum polare (PP) and planum temporale (PT). We also tested the posterior parietal region revealed in the whole-cortex searchlight analysis, to enable a comparison of effect size with the auditory cortical ROIs and to statistically test for between-region differences. To avoid statistical \u201cdouble-dipping\u201d ( ), we used a leave-one-subject-out procedure ( ) in which the whole-cortex second level   t  -test was repeatedly re-estimated, each time leaving out one participant, and using the resulting left parietal cluster as the ROI for the left out subject (cluster defining threshold   p  \u00a0\u200b<\u00a0\u200b.005 uncorrected). To obtain the homologous cluster in the right hemisphere, each left parietal cluster was left-right flipped using MarsBaR toolbox for SPM ( ). This enabled us to statistically compare effects in parietal cortex with those in the superior temporal plane ROIs (which were distributed in both hemispheres). To reduce computation time, these leave-one-subject-out   t  -tests were also conducted parametrically in SPM. To facilitate interpretation, ROI effect sizes for the multivariate analysis are reported after transforming the adjusted pattern distinctness back into the original estimate (by multiplying by a constant factor of \u221a123 i.e. the typical number of voxels within each searchlight). \n\nClassical multidimensional scaling (MDS) was performed on single-participant dissimilarity matrices in selected ROIs. The resulting MDS solutions were averaged over participants after Procrustes alignment to account for the arbitrary rotation induced by the MDS procedure. Because Procrustes alignment potentially removes some of the true inter-individual differences, the standard error ellipses in  B should be considered a lower-bound estimate of cross-participant variability ( ). To further visualize the dissimilarity relationships, we subjected the dissimilarity matrices to an agglomerative hierarchical clustering procedure (based on complete-linkage) and visualized the results with dendrograms (see  ). Dissimilarity matrices were formed by computing the pattern distinctness of all pairwise comparison contrasts between the nine stimuli and subjected to a group-level one-sample   t  -test. Given that the goal of this analysis was to better visualize effects of interest already identified as significant (i.e. the independent and integrated contrasts in the whole-cortex and ROI analyses), we thresholded these dissimilarity matrices at   p  \u00a0\u200b<\u00a0\u200b.05 uncorrected. \n\n\n\n## Results \n  \n### Cortical distribution of independent and integrated codes \n  \nWe used cross-validated MANOVA ( ) to determine the extent to which cortical activity patterns show evidence for 1) independent coding of frequency, in which the influence of frequency was invariant with respect to AM, 2) independent coding of AM, in which the influence of AM was invariant with frequency or 3) integrated coding, in which the influences of frequency and AM were interdependent. This was achieved by testing whether the pattern distinctness D over a searchlight sphere or ROI was significantly above zero for the independent and integrated effects of interest (see First-level statistics in the Methods section). \n\nUsing a whole-cortex searchlight analysis ( ), we detected large clusters in the superior temporal plane bilaterally (extending into the superior temporal gyrus) that showed significant independent coding of frequency and AM ( A and  ). Within these regions of auditory cortex, there was no evidence for integrated coding after correcting for multiple comparisons over the whole cortex. Instead, significant integrated coding was observed in a cluster outside of classically defined auditory cortex in the left posterior parietal lobe, extending over the inferior and superior portions of the parietal lobule and the intraparietal sulcus.   \nMNI coordinates and anatomical labels for significant multivariate searchlight effects. \n  Table\u00a01   \n\nWe next conducted an ROI analysis in which independent and integrated coding was tested in anatomically defined regions in the superior temporal plane as well as the posterior parietal region identified in the whole-cortex searchlight analysis. We first tested each ROI separately, using false discovery rate (FDR) correction for multiple comparisons across 6 ROIs x 2 hemispheres x 3 effects of interest ( ). As expected from the earlier whole-cortex analysis, significant independent coding of both frequency and AM was observed in all auditory ROIs but not in posterior parietal cortex (shown in  B). The effect size for independent coding of AM (mean D\u00a0\u200b=\u00a0\u200b0.02\u20130.04 over auditory regions) was smaller than for frequency, amounting to no more than 8% of the frequency effect size (mean D\u00a0\u200b=\u00a0\u200b0.5\u20131.0). Also expected was significant integrated coding in the left posterior parietal ROI. However, additional effects of integrated coding were observed in right primary auditory cortex (area Te1.0), right anterolateral auditory area Te1.2 and right PT. The effect size for integrated coding (mean D\u00a0\u200b=\u00a0\u200b0.01\u20130.02 over right Te1.0, Te1.2, PT and left parietal) was considerably smaller than that for independent coding (50% of the AM effect size and no more than 4% of the frequency effect size). \n\nThus, the ROI analysis above suggests that in the superior temporal plane, cortical activation patterns show a mixture of components: a strong independent code and a weak integrated code. In contrast in parietal cortex, only an integrated code is present. In support of this pattern of results, we conducted repeated measures ANOVA with representation type (frequency/AM/integrated), region (primary/nonprimary/parietal) and hemisphere as factors. We observed a significant interaction between representation type and region (  F  (4,76)\u00a0\u200b=\u00a0\u200b154,   p  \u00a0\u200b<\u00a0\u200b.001). No factors involving hemisphere were significant and so in subsequent comparisons, we averaged the data over hemispheres. To further characterize the representation type by region interaction, we separately assessed how the magnitude of independent and integrated coding changed along successive stages of the cortical hierarchy. For independent coding of frequency, there was a significant decrease in pattern distinctness in non-primary versus primary auditory cortex (  t  (19)\u00a0\u200b=\u00a0\u200b\u221212.2,   p  \u00a0\u200b<\u00a0\u200b.001). This was also the case for parietal versus non-primary auditory cortex (  t  (19)\u00a0\u200b=\u00a0\u200b\u221211.8,   p  \u00a0\u200b<\u00a0\u200b.001). The pattern was less clear-cut for independent coding of AM and integrated coding. Like the results for the frequency feature, there was a significant decrease in independent coding of AM in parietal versus non-primary auditory cortex (  t  (19)\u00a0\u200b=\u00a0\u200b\u22127.67,   p  \u00a0\u200b<\u00a0\u200b.001). However, the equivalent comparison for non-primary versus primary auditory cortex was not significant (  t  (19)\u00a0\u200b=\u00a0\u200b\u22121.21,   p  \u00a0\u200b=\u00a0\u200b.120). For integrated coding, there was an increase in parietal versus non-primary auditory cortex (  t  (19)\u00a0\u200b=\u00a0\u200b1.82,   p  \u00a0\u200b<\u00a0\u200b.05). However, there was no significant difference between non-primary and primary auditory regions (  t  (19)\u00a0\u200b=\u00a0\u200b\u22120.797,   p  \u00a0\u200b=\u00a0\u200b.218). In summary, although there was a clear and fine-grained change across hierarchical levels in the strength of frequency coding (primary vs. non-primary auditory cortex, non-primary auditory vs. parietal cortex), such a change for AM and integrated coding was less fine-grained and only evident in the higher hierarchical levels (non-primary vs. parietal cortex). \n\nAdditional univariate analyses were conducted which were focused on the strength of activation. As expected, at the whole-cortex level, sound presentation was associated with increased BOLD responses in the superior temporal plane bilaterally ( A and  ). No significant sound-evoked activations were observed in parietal cortex. Using repeated measures ANOVA (with frequency and AM as factors), we also evaluated between-stimulus differences in activation. Note that the main effects of frequency and AM for this analysis are conceptually different to the independent coding effects of the multivariate analysis. Here the main effect of frequency, for example, simply captures activation differences attributable to this factor rather than quantifying the extent of frequency invariance when AM rate changes. We observed significant effects of frequency and AM in the superior temporal plane bilaterally that survived whole-cortex testing but no significant frequency\u00a0\u200b\u00d7\u00a0\u200bAM interaction ( A and  ). When conducting this analysis in the ROIs (shown in  B), main effects of frequency and AM were present in auditory cortical regions but not in parietal cortex (FDR corrected as before, across 6 ROIs x 2 hemispheres x 3 effects of interest). Consistent with previous work (see  ;  ), follow-up   t  -tests in ROIs showing main effects showed a low carrier frequency preference in areas Te1.0 and Te1.2 bilaterally (all   p  \u2019s\u00a0\u200b<\u00a0\u200b0.001) and a high carrier frequency preference in right Te1.1 (  t  (19)\u00a0\u200b=\u00a0\u200b3.46,   p  \u00a0\u200b<\u00a0\u200b.01). For the main effect of AM, the preference was for slow modulation rates throughout (all   p  \u2019s\u00a0\u200b<\u00a0\u200b0.01; consistent with data from  ). No significant interaction between frequency and AM was observed in any of the ROIs tested (even with an uncorrected threshold).   \nUnivariate analysis. A) Whole-cortex analysis for contrasts of sound versus implicit baseline and main effects of frequency and AM. Images have been thresholded voxelwise at   p  \u00a0\u200b<\u00a0\u200b.005 and clusterwise at   p  \u00a0\u200b<\u00a0\u200b.05 (FWE corrected for multiple comparisons). B) ROI analysis. Data represent the BOLD signal change averaged over the spatial extent of each ROI and across participants. Error bars represent the standard error of the mean. Asterisk symbols indicate a significant main effect of frequency (in cyan) or AM rate (in magenta), FDR corrected for multiple comparisons across contrast, ROI and hemisphere. \u2217\u2217\u2217  p  \u00a0\u200b<\u00a0\u200b.001, \u2217\u2217  p  \u00a0\u200b<\u00a0\u200b.01, \u2217  p  \u00a0\u200b<\u00a0\u200b.05. \n  Fig.\u00a03     \nVisualizations of multivariate pattern distinctness A) Matrices expressing the multivoxel dissimilarity for all pairs of stimuli, averaged over the searchlight map within each ROI and over participants. Warm colors indicate multivoxel patterns that are highly dissimilar while cool colors indicate less dissimilarity. Dissimilarity matrices are shown thresholded based on a group-level one-sample   t  -test (see  ) at   p  \u00a0\u200b<\u00a0\u200b.05 uncorrected. B) Group-averaged MDS solutions after Procrustes alignment across participants (first two dimensions plotted only). Each dot and surrounding ellipse represent the mean and its standard error, respectively. The cyan number beside each data point indicates the carrier center frequency of the bandpass noise while the magenta number indicates the AM rate. C) Dendrograms showing the results of hierarchical clustering. \n  Fig.\u00a04     \nMNI coordinates and anatomical labels for significant univariate effects. \n  Table\u00a02   \n\n\n### Multidimensional scaling and cluster analysis \n  \nHaving established the cortical distribution of independent and integrated codes, we next used classical MDS to further characterize those codes ( ). In three selected ROIs (right Te1.0, right PT and left parietal), we computed the pattern distinctness for all pairs of stimuli and assembled the results into dissimilarity matrices. These ROIs were chosen as together they fully sample the transition from auditory core to non-core to parietal cortex and show a mixture of independent and integrated coding profiles. As shown in  A, we first averaged the matrices over participants and thresholded them based on a group-level one-sample   t  -test (see  ). Given that we were interested in further characterizing independent and integrated effects previously shown as significant, we used an uncorrected   p  \u00a0\u200b<\u00a0\u200b.05 threshold. MDS was performed to project the multivoxel dissimilarity structure onto a simple two-dimensional space ( B). In this visualization, stimuli that are close together are associated with similar multivoxel activation patterns while stimuli that are far from each other are associated with dissimilar patterns. \n\nIn right primary auditory cortex (area Te1.0) and right PT, frequency and AM features were automatically projected by the MDS solution onto separate dimensions, despite the method having no information as to the stimulus features. Frequency was carried by the first MDS dimension (shown as the x-axis in  B) while AM was carried by the second dimension (y-axis). This is consistent with our previous observation of these regions representing frequency and AM in a largely independent manner. \n\nIn contrast to auditory cortex, MDS for the left parietal ROI did not clearly separate frequency and AM features. The MDS solutions instead suggest that activation patterns in this region were modulated by particular conjunctions of carrier frequency and AM rate (e.g. F500AM10 and F3380AM25). This is again consistent with our previous observation that parietal cortex is characterized solely by an integrated code. \n\nVisual inspection of the MDS plots in superior temporal regions suggests that carrier frequency was the main driver of multivoxel pattern dissimilarity. That is, multivoxel patterns were most dissimilar when evoked by different carrier frequencies. Indeed, hierarchical clustering analysis showed that multivoxel dissimilarities clearly clustered according to carrier frequency in right Te1.0 and PT ( C). In contrast in the left parietal ROI, this analysis failed to reveal a clear clustering. These results are consistent with the effect sizes for independent and integrated coding shown previously in  B. \n\n\n### Saliency analysis \n  \nIn the visual domain, parietal cortex has repeatedly been implicated in the processing of bottom-up saliency ( ;  ). We therefore asked to what extent the integrated coding effect observed in posterior parietal cortex could be explained by between-stimulus differences in perceived saliency. In a separate behavioral session, listeners listened to all pairwise combinations of the nine sounds and judged which sound in each pair was more salient. We then estimated the perceived saliency of each sound as the percentage of trials the sound was chosen as more salient (shown in  A as thick black line). Because saliency is related (although not identical) to loudness ( ), we also show for comparison the loudness of the stimuli as predicted by the model of   (shown in  A as thick blue line).   \nSaliency analysis. A) Subjective saliency of the stimuli. The thick black line indicates the group-averaged percentage of trials each stimulus was judged as more salient (than the other stimuli). Light gray lines indicate saliency judgements for individual participants. The thick blue line represents the predicted loudness of the stimuli according to the model of   and normalized to have the same scale as the saliency data (for display purposes only). B) \u201cSaliency distance\u201d matrix expressing the absolute difference in the percentage of observations each sound in a pair was chosen as more salient. C) Whole-cortex multivariate searchlight analysis, showing where the Fisher transformed Spearman correlation between the saliency distance matrix in panel B and the multivoxel dissimilarity structure in each searchlight was significantly above zero across participants (thresholded voxelwise at   p  \u00a0\u200b<\u00a0\u200b.005 and clusterwise at   p  \u00a0\u200b<\u00a0\u200b.05 FWE corrected for multiple comparisons). D) ROI analysis. Each data point shows the Fisher transformed Spearman correlation, averaged over the searchlight map within each ROI and over participants. Error bars represent the standard error of the mean. Brace and asterisk indicates significant   p  \u00a0\u200b<\u00a0\u200b.001\u00a0\u200b  F  -test comparing the strength of Spearman correlation between auditory and parietal regions. \n  Fig.\u00a05   \n\nRepeated measures ANOVA of the saliency judgments, with frequency and AM rate as factors, revealed a significant main effect of frequency (reflecting higher saliency for increasing frequency;   F  (2,10)\u00a0\u200b=\u00a0\u200b31.5,   p  \u00a0\u200b<\u00a0\u200b.001) and a significant main effect of AM rate (reflecting higher saliency for the middle AM rate;   F  (2,10)\u00a0\u200b=\u00a0\u200b6.34,   p  \u00a0\u200b<\u00a0\u200b.025). However, the interaction between frequency and AM rate was not significant (  F  (4,20)\u00a0\u200b=\u00a0\u200b0.808, p\u00a0\u200b=\u00a0\u200b.512). To directly test whether there was positive evidence for the null effect of no interaction, we also conducted repeated measures ANOVA as a Bayesian analysis ( ,  ;  ). We contrasted a model which contained both main effects of frequency and AM and their interaction, with a null model that had the same structure but lacked the interaction (both models were assigned a prior probability of 0.5). This analysis indicated that the null model was 5 times more likely than the alternative model (Bayes Factor\u00a0\u200b=\u00a0\u200b5.31). As the integrated coding effect in parietal cortex is defined by the interaction between frequency and AM, the absence of an interaction in the saliency judgments is therefore inconsistent with a saliency-based account of the integrated coding effect in parietal cortex, or indeed, in any other of the regions in which integrated coding was observed. \n\nAs a further test of a saliency-based account, we used representational similarity analysis (RSA) to relate listeners\u2019 saliency judgments to the observed multivoxel patterns ( ). For each pair of sounds presented in the saliency judgment task, we pooled saliency judgments over trials and participants and computed the absolute difference in the percentage of observations each sound in the pair was chosen as more salient. From this we assembled a distance matrix quantifying the difference in saliency between the two sounds of all presented pairs ( B). This \u201csaliency distance\u201d matrix provides a more detailed characterization of between-stimulus differences in saliency than the summary measure presented in  A, which we could then correlate with the multivoxel dissimilarity matrix observed in each searchlight across the cortex of individual participants. As shown in  C, the (Fisher-transformed) Spearman correlation between the saliency and multivoxel dissimilarity structure was significantly above zero in the superior temporal plane bilaterally but not in parietal cortex (for MNI coordinates, see  ). This pattern was further supported by an ROI analysis ( D) in which the Spearman correlation significantly decreased from superior temporal to parietal cortex (  F  (1,19)\u00a0\u200b=\u00a0\u200b57.8,   p  \u00a0\u200b<\u00a0\u200b.001; effects involving hemisphere were not significant). We further note with interest how this saliency-to-multivoxel correlation peaked in posteromedial auditory area Te1.1, which clearly differs to how the independent and integrated coding effects were expressed over cortical regions (compare  D with  B). Nearly identical results were obtained when using loudness in this ROI analysis (here a loudness distance matrix was formed by computing the absolute differences in loudness between the stimuli). This suggests that saliency/loudness can be reliably dissociated from the independent and integrated coding effects of the earlier analyses. In summary then, this RSA analysis together with the absence of interactive influences of frequency and AM on behavioral saliency judgments suggests that the integrated coding effect we observe cannot be attributed to saliency/loudness. We will return to this point in the Discussion. \n\n\n\n## Discussion \n  \nIn the current study, we manipulated two important acoustic features, frequency and AM rate, and determined the extent to which they are represented by independent versus integrated codes in fMRI multivoxel patterns. We demonstrate that these spectral and temporal dimensions are represented largely independently in the superior temporal plane, with only a weakly integrated component present in right Te1.0, Te1.2 and PT (amounting to no more than 4% of the frequency effect size and 50% of the AM rate effect size). In contrast, in a posterior parietal region not classically considered part of auditory cortex, multivoxel representation is exclusively integrated albeit weakly. \n\n### Independent representations in the superior temporal plane \n  \nOur demonstration of largely independent representations of frequency and AM rate in the superior temporal plane might seem to contrast with evidence from animal physiology that suggest highly nonlinear representations already at the level of primary auditory cortex (e.g.  ;  ;  ). One explanation for why we see independent processing of frequency and AM is the spatial and temporal averaging inherent with fMRI ( ). This spatiotemporal averaging means that transient neural responses at a fine spatial scale will be underrepresented in BOLD signals and sustained responses at a large spatial scale will be overrepresented ( ;  ). Thus, while multivoxel patterns might show independent coding of frequency and AM, this does not exclude the possibility that other components of the neural representational code are nonlinear. \n\nOur findings may also reflect the specific features that were manipulated. Specifically, it has been suggested that frequency and AM rate are fundamental dimensions of sound analysis ( ;  ) and in the auditory cortex are represented as orthogonally-organized topographic maps (\u201ctonotopy\u201d and \u201cperiodotopy\u201d; e.g.  ). The presence of dissociable topographic maps might indicate that frequency and AM are two independent features to which the cortex is tuned. While previous electrophysiological ( ) and fMRI ( ) findings from animals also support the notion of orthogonal topographic maps, in humans the evidence for an AM map is mixed with some studies showing clear topographic organization ( ;  ;  ) but others not ( ;  ;  ;  ). Indeed, our univariate analysis showed regional preferences for slow modulation rates throughout (consistent with  ) rather than a mixture of slow- and fast-tuned regions as would be expected for a topographic map (we acknowledge however that our analysis and imaging parameters were not optimized for characterizing modulation tuning using univariate methods; see below for further discussion). Previous conflicting findings may be attributed to the small size of auditory cortex and high inter-subject variability in anatomy. In the current study we circumvented these challenges by using a multivariate analysis method that abstracts away from the precise configuration of voxels. Importantly, this approach allowed us to directly test and quantify the degree of representational independence without the need to map features onto individual voxels. \n\nDespite being able to robustly detect independent coding of frequency and AM rate in superior temporal regions, we nonetheless found a strong bias for the frequency feature, with the effect size for AM rate amounting to no more than 8% of the frequency effect size. While this result might indicate that superior temporal cortex is more strongly tuned to frequency, it could also reflect that AM rates in our study varied over a restricted range (4\u201325\u00a0\u200bHz) in order to limit spectral confounds ( ). \n\nIndependent representation of frequency and AM features is also suggested by component analysis of human fMRI responses to natural sounds ( ). This work suggests that frequency and AM features are represented as independent components in partly overlapping regions of the superior temporal plane. However, this study did not test for feature interactions between those features, leaving unclear the relative contributions of independent and integrated representations to neural responses. Another study that did test for feature interactions used forward encoding models to predict superior temporal fMRI responses to natural sounds from frequency and spectrotemporal modulations ( ). This work suggests that a model based on conjunctions of these features better predicted fMRI responses than if the features in the model were represented separately. While this result might be taken to be inconsistent with the highly independent code demonstrated here, we note that in our ROI analysis we too observed significant integrated coding in the superior temporal plane. But a consideration of the standardized effect sizes, which the MANOVA approach readily provides ( ), suggests a more nuanced interpretation. That is, while an integrated component may be necessary to fully explain fMRI responses (hence the superiority of an encoding model based on conjunctions of features), the majority of variance can be explained by an independent representation. \n\nThus, our study provides new evidence that frequency and AM are orthogonal dimensions of sound analysis. Such independent representation may support listeners\u2019 ability to selectively process information in frequency versus time. In addition, as noted by  , an independent coding scheme will tend to convey more information than a highly-selective integrated code. This property would be desirable if the role of primary auditory cortex was to relay information to more specialized feature conjunction detectors in higher-level regions. \n\n\n### Integrated representation in posterior parietal cortex \n  \nOur imaging of the entire cortex allowed us to probe beyond classically defined auditory cortex. In this respect, a striking demonstration here is of an exclusively integrated representation of frequency and AM rate in a left posterior parietal region, at the border between the intraparietal sulcus (IPS), inferior parietal lobule and occipital cortex. This finding is notable for two reasons. First, it parallels findings from the visual domain in which parietal cortex (in particular the IPS) shows increased fMRI responses in feature conjunction versus single feature tasks ( ;  ; see also   for a similar finding using multivariate methods), with damage to this region leading to feature binding deficits ( ). Second, BOLD activation in the IPS has been shown to systematically vary in auditory bi-stability ( ) and figure-ground paradigms ( ,  ). Indeed, the peak locations of the posterior parietal effects reported by these latter auditory studies fall inside the cluster reported here. In all these paradigms, perceptual outcomes are critically dependent on the way in which information across multiple features is combined and structured into object-based representations. Thus, the integrated representation for frequency and AM we observe here in parietal cortex is consistent with previous work suggesting a role for the IPS in feature integration and the structuring of sensory input. Further consistent with this, the location of our parietal cluster resides in the posterior portion of parietal cortex, where feature integration can be dissociated from effects of attention switching and task difficulty in anterior parietal regions ( ). However, our study goes beyond previous work in that neural responses evoked by stimulus features were contrasted directly, independently of listeners\u2019 task (cf. feature search and bi-stability paradigms) and in the absence of salient stimulus features that would likely attract attention (cf. figure-ground paradigms). \n\nBecause of previous findings from the visual domain implicating parietal cortex in bottom-up saliency ( ;  ), we also asked a separate group of listeners to rate the subjective saliency of the stimuli. While the sounds clearly differed in their subjective saliency, we found that influences of frequency and AM on the saliency ratings combined independently without evidence for an interaction, an observation inconsistent with a saliency-based account. It should be noted however that a limitation of this analysis is the small sample of participants (N\u00a0\u200b=\u00a0\u200b6) who provided the saliency judgments. In this respect, it is reassuring that when using RSA to relate saliency judgments to the dissimilarity structure of the multivoxel patterns, we found that the effect of saliency was confined to superior temporal plane regions with a peak in posteromedial auditory area Te1.1, which is reminiscent of findings by   who reported correlates of loudness in this region (see   for the close relationship between loudness and saliency). Thus, the results from this saliency analysis suggest that the observed integrated coding effect does not appear to relate to bottom-up saliency. \n\nRelated to the issue of saliency, we also consider the possibility that the integrated coding profile we observe in parietal cortex was in part a consequence of listeners\u2019 task. In our study, listeners performed an attentionally undemanding task that did not require explicit integration of frequency and AM features: detecting the target white-noise interruptions could in principle be based on changes in either the amplitude or spectral profiles alone. Despite this, one might argue that participants nevertheless detected the noise interruptions by attending to changes in both temporal and spectral content, in turn contributing to the integrated coding effect we observe. Indeed, as discussed below, attention has long been proposed to mediate feature integration ( ). However, we think that this is unlikely as an explanation for the current findings. The interaction between frequency and AM rate in parietal cortex resulted from differences in the multivoxel patterns evoked by our stimuli (while the task was fixed throughout). Thus, even if listeners monitored both spectral and temporal content to detect the target interruptions, it is unclear how this would have preferentially biased listeners\u2019 attention towards certain feature conjunctions. This is because the targets were temporally unmodulated and spectrally wide-band and therefore \u201cneutral\u201d with respect to the nine feature conjunctions of the stimuli. \n\nA key assumption in our approach to distinguishing independent and integrated representations is a linear relationship between underlying neural activity and the measured fMRI signal ( ;  ). Our univariate analysis shows that the mean signal amplitude in the posterior parietal region did not differ from the implicit baseline (or interstimulus period). It also did not differ between stimuli, neither in terms of mains effects nor in the interaction between frequency and AM rate. This suggests that our experimental manipulations in this region did not evoke sufficiently large changes in mean signal to saturate the fMRI response and produce nonlinear signal changes that could be misinterpreted as an integrated representation. Nonetheless, it should be noted that our rapid event-related design means that any parietal responses would not have had time to fully return to baseline between sound events. Thus, we cannot completely rule out the possibility that parietal regions were constantly active and operating near saturation. However, further evidence against saturation-driven nonlinearities comes from a recent study formally demonstrating that between-stimulus (and between-action) differences in multivoxel patterns are robust to large changes in mean activity levels ( ). \n\nThe integration of multiple feature representations is critical for building a cohesive perception of the auditory scene. However, even in parietal cortex, the effect size for integrated coding was small in comparison with that observed for independent coding in the superior temporal plane. Why then do we observe only weak integration of frequency and AM rate? As discussed above, frequency and AM may be privileged dimensions of sound analysis that are separable in a way that other dimensions are not. Our results may also be attributed to listeners performing an attentionally undemanding task that did not require explicit integration of frequency and AM features. It has been suggested that while individual features are detected automatically, feature integration is a computationally demanding process requiring focused attention ( ;  ). Thus, the absence of focused attention to feature conjunctions could explain the weak integration we observe. Future work, using manipulations of attention, will be required to test this proposal. \n\n\n### Spatial resolution of current fMRI data and relationship with previous mapping studies \n  \nBecause we wished to measure whole-brain responses, including in regions outside classically defined auditory cortex, we measured BOLD responses with a resolution of 3\u00a0\u200bmm isotropic voxels (the data were additionally smoothed with a 6\u00a0\u200bmm kernel but only after the critical multivariate statistics were computed). While finer-resolution data are commonly obtained in studies investigating how frequency and other acoustic features are mapped to individual voxels (e.g.  ;  ;  ;  ), our focus here is how frequency and AM features are represented in activity patterns over multiple voxels. It is well-established that multivoxel methods can sensitively measure changes in brain responses to acoustic features (even with 3\u00a0\u200bmm resolution data) by pooling weak but consistent signals over voxels and exploiting between-voxel correlations (e.g.  ). \n\nNote also that while significant independent coding of frequency and AM might be consistent with separate underlying neural populations responding to those features, this need not be the case. That is, the same neurons could simply be responding in a linear (additive) fashion to changes in frequency and AM rate. Moreover, the extent of representational independence versus integration does not bear on the issue of whether the underlying neural populations are \u201cdistributed\u201d or \u201csparse\u201d in nature ( ;  ). Thus, the extent of representational independence and integration in multivoxel patterns is a more abstract characterization of cortical processing than the precise spatial configuration of feature-tuned voxels. \n\n\n### Generality of findings \n  \nOne question that arises from the current work is the extent to which our findings generalize to other acoustic features. Our factorial design, combined with synthetic stimuli, allowed us to orthogonalize changes in frequency and AM features in a controlled fashion. This is a statistically powerful method for dissociating contributions of experimental manipulations (here of acoustic features) to observed neural responses ( ). At the same time however, this necessarily constrained the number of features we could investigate. Therefore, our findings should not be taken to mean that all acoustic features are encoded in the same way as the frequency and AM features studied here. \n\nOur factorial design contrasts with studies that have investigated the neural representation of acoustic features using natural sounds and statistical methods that enable many stimulus features to be studied simultaneously ( ;  ;  ;  ;  ;  ;  ;  ;  ). However, the benefits of this more naturalistic approach come with substantial methodological challenges since acoustic features in natural sounds show substantial correlations, making it difficult to dissociate their neural contributions ( ;  ). Thus, we suggest that the approach taken here is complementary to studies using natural sounds. An extension for future work could increase the number of features manipulated factorially, combined with stimulus synthesis techniques to create more naturalistic (yet still controlled) sounds ( ;  ). \n\n\n\n## CRediT authorship contribution statement \n  \n Ediz Sohoglu:   Conceptualization, Methodology, Investigation, Data curation, Formal analysis, Writing - original draft, Writing - review & editing.   Sukhbinder Kumar:   Conceptualization, Methodology, Investigation, Writing - review & editing.   Maria Chait:   Conceptualization, Writing - review & editing.   Timothy D. Griffiths:   Conceptualization, Methodology, Funding acquisition, Writing - review & editing. \n\n \n\n# Table(s)\n## ID: tbl1\n### Label: Table\u00a01\nEffect of Interest\tHemisphere\tRegion Label\tExtent\tt-value\tx\ty\tz\nFrequency\tLeft\tTe1.0\t6056.0\t14.2923\t-44\t-22\t6\n\t\tSuperior Temporal Gyrus\t\t13.1983\t-48\t-26\t-2\n\t\tSuperior Temporal Gyrus\t\t6.2306\t-54\t-44\t12\n\tRight\tRolandic Operculum\t5987.0\t14.0351\t50\t-20\t14\n\t\tSuperior Temporal Gyrus\t\t12.1458\t50\t-22\t0\n\t\tTe1.2\t\t8.3851\t58\t-6\t-4\nAM\tLeft\tSuperior Temporal Gyrus\t2721.0\t7.9246\t-50\t-30\t14\n\t\tSuperior Temporal Gyrus\t\t5.8524\t-42\t-14\t0\n\t\tSuperior Temporal Gyrus\t\t5.1419\t-52\t-36\t6\n\tRight\tSuperior Temporal Gyrus\t2384.0\t7.0587\t62\t-14\t-2\n\t\tSuperior Temporal Gyrus\t\t5.7386\t62\t-28\t8\n\t\tInferior Frontal Gyrus\t\t3.3739\t56\t12\t10\nIntegrated\tLeft\tIntraparietal Sulcus / Inferior Parietal Lobule\t445.0\t4.5942\t-32\t-68\t32\n\t\tSuperior Parietal Lobule\t\t4.3273\t-28\t-72\t50\nSaliency\tLeft\tSuperior Temporal Gyrus\t5446.0\t17.963\t-52\t-30\t8\n\t\tSuperior Temporal Gyrus\t\t8.139\t-50\t-16\t-6\n\t\tSuperior Temporal Gyrus\t\t7.021\t-58\t-10\t0\n\tRight\tSuperior Temporal Gyrus\t5409.0\t14.961\t56\t-24\t8\n\t\tTe1.0\t\t14.005\t52\t-16\t4\n\t\tInsula\t\t13.794\t42\t-14\t0\n### Caption\nMNI coordinates and anatomical labels for significant multivariate searchlight effects.\n### Footer\nNone\n\n\n## ID: tbl2\n### Label: Table\u00a02\nEffect of Interest\tHemisphere\tRegion Label\tExtent\tt-value\tx\ty\tz\nSound\tLeft\tTe1.0\t4264.0\t12.615\t\u221250\t\u221224\t8\nSound\tLeft\tTe1.0\t\t11.616\t\u221244\t\u221218\t6\nSound\tLeft\tTe1.1\t\t11.607\t\u221242\t\u221230\t10\nSound\tLeft\tTe1.0\t\t10.689\t50\t\u221214\t8\nSound\tLeft\tTe1.0\t\t9.493\t48\t\u221210\t0\nSound\tLeft\tTe1.1\t\t9.389\t44\t\u221226\t12\nSound\tLeft\tMedial Frontal\t1841.0\t5.251\t\u22124\t8\t50\nSound\tLeft\tMedial Frontal\t\t4.904\t0\t14\t46\nSound\tLeft\tAnterior Cingulate\t\t4.856\t10\t28\t28\nSound\tRight\tMiddle Frontal Gyrus\t703.0\t4.317\t26\t52\t6\nSound\tRight\tMiddle Frontal Gyrus\t\t4.065\t34\t46\t14\nSound\tRight\tMiddle Frontal Gyrus\t\t3.988\t38\t34\t34\nSound\tLeft\tMiddle Frontal Gyrus\t403.0\t4.145\t\u221232\t40\t22\nSound\tLeft\tMiddle Frontal Gyrus\t\t4.118\t\u221226\t52\t6\nSound\tLeft\tInferior Frontal Gyrus\t\t3.436\t\u221240\t46\t10\nFrequency\tRight\tTe1.1\t606.0\t60.833\t48\t\u221228\t10\nFrequency\tRight\tTe1.1\t\t33.149\t40\t\u221220\t2\nFrequency\tRight\tSuperior Temporal Gyrus\t\t31.023\t46\t\u221212\t\u22126\nFrequency\tLeft\tTe1.0\t666.0\t50.659\t\u221248\t\u221220\t8\nFrequency\tLeft\tTe1.0\t\t36.724\t\u221252\t\u221212\t6\nFrequency\tLeft\tTe1.2\t\t20.665\t\u221258\t\u22126\t2\nFrequency\tRight\tTe1.0\t443.0\t40.95\t52\t\u221214\t6\nFrequency\tRight\tTe1.2\t\t39.995\t54\t\u22126\t2\nAM\tLeft\tSuperior Temporal Gyrus\t1125.0\t32.915\t\u221262\t\u221222\t4\nAM\tLeft\tSuperior Temporal Gyrus\t\t22.847\t\u221266\t\u221230\t12\nAM\tLeft\tSuperior Temporal Gyrus\t\t22.281\t\u221252\t\u221234\t10\nAM\tRight\tSuperior Temporal Gyrus\t877.0\t25.747\t62\t\u221216\t4\nAM\tRight\tSuperior Temporal Gyrus\t\t17.972\t66\t\u221228\t8\nAM\tRight\tTe1.2\t\t15.659\t50\t\u22126\t\u22124\n### Caption\nMNI coordinates and anatomical labels for significant univariate effects.\n### Footer\nNone\n", "metadata": {"pmcid": 7339141, "text_md5": "4397b022bbe45f26c1ebe862f85c3d79", "field_positions": {"authors": [0, 78], "journal": [79, 89], "publication_year": [91, 95], "title": [106, 189], "keywords": [203, 269], "abstract": [282, 1824], "body": [1833, 62749], "tables": [62762, 65391]}, "batch": 2, "pmid": 32081785, "doi": "10.1016/j.neuroimage.2020.116661", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7339141", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7339141"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7339141\">7339141</a>", "list_title": "PMC7339141  Multivoxel codes for representing and integrating acoustic features in human cortex"}
{"text": "Kuehn, Esther and Mueller, Karsten and Turner, Robert and Sch\u00fctz-Bosbach, Simone\nBrain Struct Funct, 2013\n\n# Title\n\nThe functional architecture of S1 during touch observation described with 7\u00a0T fMRI\n\n# Keywords\n\nEmpathy\nPrimary somatosensory cortex\nMirror neuron system\nShared representations\nSuppressive interactions\nReceptive field\n\n\n# Abstract\n \nRecent studies indicate that the primary somatosensory cortex (S1) is active not only when touch is physically perceived but also when it is merely observed to be experienced by another person. This social responsivity of S1 has important implications for our understanding of S1 functioning. However, S1 activity during touch observation has not been characterized in great detail to date. We focused on two features of the S1 functional architecture during touch observation, namely the topographical arrangement of index and middle finger receptive fields (RFs), and their dynamic shrinkage during concurrent activation. Both features have important implications for human behavior. We conducted two fMRI studies at 7\u00a0T, one where touch was physically perceived, and one where touch was observed. In the two experiments, participants either had their index finger and/or middle finger stimulated using paintbrushes, or just observed similar touch events on video. Our data show that observing and physically experiencing touch elicits overlapping activity changes in S1. In addition, observing touch to the index finger or the middle finger alone evoked topographically arranged activation foci in S1. Importantly, when co-activated, the index and middle finger RFs not only shrank during physical touch perception, but also during touch observation. Our data, therefore, indicate a similarity between the functional architecture of S1 during touch observation and physical touch perception with respect to single-digit topography and RF shrinkage. These results may allow the tentative conclusion that even primary somatosensory experiences, such as physical touch perception, can be shared amongst individuals. \n\n## Electronic supplementary material \n  \nThe online version of this article (doi:10.1007/s00429-012-0489-z) contains supplementary material, which is available to authorized users. \n\n \n\n# Body\n \n## Introduction \n  \nIn recent years, the unisensory and private character of many primary sensory brain areas has increasingly been questioned. Traditionally, primary sensory brain areas, such as the primary somatosensory cortex (S1), have been assumed to be unisensory in character, and to only respond to modality-specific input; however, recent research has provided evidence for their multisensory response properties (Kayser  ). The responsivity of primary sensory brain areas to multimodal input has even been called a \u201crevolution in multisensory research\u201d (Driver and Noesselt  ), and S1 seems to be part of it. An increasing amount of evidence shows that S1 activity is not only influenced by direct somatosensory input, but is also modulated by other factors such as attention (Eimer et al.  ; Hsiao et al.  ; Macaluso et al.  ), reward (Pleger et al.  ), spatial processing (Eimer et al.  ), or visual stimulation (Dionne et al.  ; Zhou and Fuster  ). As a consequence, the emerging view in cognitive neuroscience is that S1 can no longer be regarded as a strictly unisensory brain area, but rather as an area whose activity levels can be shaped by multiple environmental inputs. \n\nYet another quantum leap for our understanding of S1 is that recent studies have shown a specific influence of social cues on its functioning. Not only has evidence been provided that viewing the body compared with viewing an object can influence S1 processing during physical touch perception (Cardini et al.  ; Fiorio and Haggard  ; Longo et al.  ), but it has also been shown that viewing touch to a body, without physically perceiving touch at all, can increase S1 activity levels (Blakemore et al.  ; Ebisch et al.  ; Kuehn et al.  ; Schaefer et al.  ,  ). S1 activity changes during touch observation were shown to be stronger when human touch compared with object touch was observed (Blakemore et al.  ), and a specifically   social responsivity   of S1 during touch observation has been assumed (Kuehn et al.  ; Rossetti et al.  ). \n\nImportantly, active voxels in S1 that were triggered by touch observation were shown to overlap with voxels activated during physical touch perception (Blakemore et al.  ; Ebisch et al.  ; Schaefer et al.  ). For example, using functional magnetic resonance imaging (fMRI), Blakemore and colleagues showed that somatotopically specific areas in S1 were activated when touch to another person\u2019s face and neck was observed and that such activity changes overlapped with those areas that were activated during the physical perception of touch to the subject\u2019s own neck and face (Blakemore et al.  ). This is similar to the neuronal \u201cresonance\u201d responses reported for the motor system (Buccino et al.  ; Gazzola and Keysers  ; Mukamel et al.  ), and the emotional system (Corradi-Dell\u2019Acqua et al.  ; Singer et al.  ), where similar areas in the brain were shown to activate during action observation and execution, and emotion observation and perception, respectively. It is assumed that such resonance responses allow a basic understanding of the observed action or emotion, respectively (Bernhardt and Singer  ; Fabbri-Destro and Rizzolatti  ). According to this logic, S1 activity during touch observation should allow a basic understanding of another person\u2019s somatosensory experiences as has recently been proposed (Avenanti et al.  ; Keysers et al.  ). \n\nAn interesting resulting question is how activity changes in S1 during touch observation can be characterized. Which features of the   functional architecture   of S1 are shared between physically perceiving and observing touch, and which only occur in one or the other condition? Based on recent neuroimaging research on the human somatosensory system, two features of the functional architecture of S1 seem to be of specific importance in this respect. On the one hand, the   topographical arrangement   of cortical receptive fields (RFs) in S1 plays an important role in our understanding of somatosensory processing. S1 activity during physical touch perception represents the contralateral side of the human body in a mediolateral sequence (Blankenburg et al.  ; Gardner EK  ; Kaas et al.  ; Krause et al.  ), and has been shown to make an important contribution to the ability to localize tactile stimuli on the skin (Beauchamp et al.  ; Chen et al.  ,  ; Schweizer et al.  ). Changes in the topographical arrangement of single-digit RFs in S1 can, for example, lead to a diminished ability to assign touch to a particular digit (Braun et al.  ; Schweizer et al.  ). \n\nOn the other hand,   suppressive interactions   between coactivated RFs in S1 have often been used to describe the functional architecture of S1. RFs in S1 react within milliseconds to sensory inputs given to surrounding RFs. For instance, the RF of one digit contracts when other digits are stimulated simultaneously and rapidly expands again when the digit is stimulated alone. This shrinking and re-enlarging of S1 RFs, depending on the tactile input given to surrounding RFs, has been demonstrated in studies on cats, mice, and monkeys (Friedman et al.  ; Moore et al.  ; Zarzecki and Wiggin  ), and is posited to reflect a wide-spread cortical mechanism, which results in increased perceived stimulus contrast (Dykes  ; Falkner et al.  ; Jones  ; Moore et al.  ). Suppressive interactions during physical touch perception have also been investigated in multiple human studies (Biermann et al.  ; Braun et al.  ; Gandevia et al.  ; Haavik Taylor and Murphy  ; Hoechstetter et al.  ; Ishibashi et al.  ; Naka et al.  ; Ruben et al.  ; Tanosaki et al.  ; Torquati et al.  ), where the arithmetic sum of S1 signals measured during separate single-digit stimulations of two fingers was compared with the signal change during the stimulation of both fingers at once. In these studies, decreased signal strength during double-digit stimulation, compared with the sum of signals from separate single-digit stimulations, indicated how much the RFs contracted. Also in humans, such RF shrinkages presumably mediated by suppressive interactions, are assumed to positively relate to perceived stimulus contrast (Braun et al.  ; Cardini et al.  ; Puts et al.  ). \n\nGiven that the aim of the present study was to characterize the functional architecture of S1 during touch observation along these two dimensions (topographical arrangement of RFs and suppressive interactions between RFs), the use of standard 3\u00a0Tesla (T) fMRI designs would have limited the scope of this approach. On the one hand, S1 activity during touch observation has been shown to be subtle, often only to survive significance thresholds when small volume corrections are applied to the fMRI data (Blakemore et al.  ; Fitzgibbon et al.  ; Keysers et al.  ; Schaefer et al.  ). This low signal strength clearly limits the possibility to characterize suppressive interactions, because subtle activity differences between different experimental conditions are of primary interest here. On the other hand, the spatial resolution of the functional data in 3 T fMRI studies is often too low to describe fine-grained architectonic characteristics in sufficient detail, for instance when specifying the topography of RFs in S1. In both cases, fMRI at ultra-high field offers a promising approach to circumvent some of these limitations (Chen et al.  ; Kuehn et al.  ; Stringer et al.  ). As has recently been argued in a similar context (Kuehn et al.  ; Stringer et al.  ), 7\u00a0T fMRI can characterize brain activity changes in greater spatial detail, and with far greater sensitivity than is available with standard designs at 3\u00a0T (Bandettini  ; Gati et al.  ; Heidemann et al.  ; Sanchez-Panchuelo et al.  ; Scouten et al.  ). \n\nOne recent study used 7\u00a0T fMRI to characterize S1 activity during touch observation (Kuehn et al.  ). It was found that S1 activity during touch observation was restricted to posterior parts of contralateral S1; anterior parts were spared. This suggests that anterior S1 may still be considered a primary (and private) sensory brain area that is involved in social cognitive processes to a lesser extent, whereas somatosensory processes that are mediated by posterior S1 can be shared between, and are therefore influenced by, social interaction partners. However, that study did not characterize the functional architecture of activity changes in S1; it focused on the main effect of touch observation elicited by observing touch to one part of the hand. In order to characterize the topography of S1 activity during touch observation, one would have to let participants observe touch to different parts of the hands, such as different digits, and see whether distinct and topographically arranged activity changes in S1 were evoked. In addition, in order to characterize whether touch observation leads to similar inhibitory interactions between adjacent RFs, such as during physical touch perception (Gardner and Costanzo  ; DiCarlo et al.  ; DiCarlo and Johnson  ; Friedman et al.  ), one would have to compare the signal strength between conditions where touch to one finger is observed and conditions where touch to two fingers is observed, as is classically done in paradigms on suppressive interactions (Gandevia et al.  ; Ruben et al.  ). \n\nFor such an approach to be successful, it is important to know that single digits are distinctly represented not only in anterior S1, but also in posterior S1 (Duncan and Boynton  ; Stringer et al.  ; Sutherling et al.  ), the area where touch observation elicits higher activity changes (Kuehn et al.  ). More precisely, the RF of the index finger in posterior S1 is more lateral, more anterior, and more inferior than the RF of the middle finger of the same hand (Nelson and Chen  ). A second important prerequisite for this approach is that, in principle, it has to be possible to characterize RF interactions by means of fMRI. Whereas many human studies have used EEG or MEG to characterize suppressive interactions between adjacently activated RFs in S1 (e.g., Biermann et al.  ; Gandevia et al.  ), one study with human participants successfully used fMRI for this purpose (Ruben et al.  ). Importantly, fMRI was able to show that suppressive interactions between adjacently activated RFs in S1 occur not only in anterior but also in posterior parts of S1. \n\nIn the present study, we used fMRI at 7\u00a0T to characterize the functional architecture of S1 during touch observation along two dimensions: topographical arrangement of RFs and suppressive interactions between adjacent RFs. During the scanning session, participants observed video clips where touch was applied either to the index finger alone, the middle finger alone, or both the index and middle finger together using paintbrushes. While observing the videos, participants had to decide which of two subsequently presented paintbrushes offered the rougher stroke. This secondary task was included because the shrinkage of adjacent RFs during their concurrent activation is assumed to relate to more precise stimulus perception (Braun et al.  ; Cardini et al.  ; Puts et al.  ), which we hypothesized could also transfer to the situation of touch observation. In this experiment (hereafter referred to as the observed touch experiment), no physical touch was applied to the participant\u2019s hands or fingers. Based on previous findings (Kuehn et al.  ), we expected that particularly posterior areas of contralateral S1 would show increased activity levels when touch videos were observed. Importantly, we further expected that activity foci during observed touch to the index finger alone and middle finger alone would be partly distinct and somatotopically ordered in accordance with the expected S1 functional topography. We also expected that observing touch to the middle finger and to the index finger together would decrease activity levels in S1 compared with observing touch to the same fingers alone. Such a reduction could likely be explained by suppressive interactions between adjacently activated RFs. \n\nAs a control experiment (hereafter referred to as the physical touch experiment), we performed another 7\u00a0T fMRI experiment where physical tactile stimulation was applied to participants\u2019 index and middle fingers using paintbrushes in the same way as was observed in the observed touch experiment\u2014the index finger alone, the middle finger alone, or both the index and middle fingers together. We expected the same pattern of results for this experiment, i.e., greater activity changes for physical touch perception compared with rest, partly distinct representations of the index and middle finger RFs in posterior S1, and suppressive interactions between index and middle finger RFs. In the conjunction analysis between both experiments, we expected an overlap between activity changes during physical touch perception and touch observation. \n\nIn summary, we intended to produce the first characterization of the functional architecture of S1 during touch observation, and relate the results to the well-described functional architecture of S1 during physical touch perception. Given the novelty of this experimental approach, our results should make an important contribution to understanding the role of S1 in social cognition. \n\n\n## Materials and methods \n  \n### Experimental design \n  \nWe conducted two separate fMRI experiments using a 7\u00a0T MR scanner, where participants either physically perceived tactile stimulation on their finger(s), or merely observed similar events on video. In the physical touch experiment, tactile stimulation was applied to participants\u2019 index and/or middle finger using paintbrushes. In the observed touch experiment, videos were presented to participants showing touch to the corresponding fingers, again applied using paintbrushes. The observed touch experiment was always conducted first to exclude any influence of touch experience in the scanner on touch observation (Gazzola and Keysers  ). Both experiments were separated by 6\u20137\u00a0days (mean: 6.5\u00a0days\u00a0\u00b1\u00a01.1\u00a0days [SD]). \n\n\n### Participants \n  \nSixteen healthy volunteers between 22 and 30\u00a0years (mean age 25.6\u00a0years, 8 females) participated in our study. All were right-handed (mean handedness score on the Edinburgh inventory: 98.1; Oldfield  ), had normal or corrected-to-normal vision and none reported history of neurological, major medical, or psychiatric disorders. They were paid for their attendance and informed consent was obtained from all participants. The study was approved by the local Ethics committee at the University of Leipzig. One participant was excluded from further analyses due to a high number of missed trials (9.4\u00a0%) and a reported failure to stay awake throughout the experiment. The functional and behavioral analyses were therefore conducted with data from 15 participants. \n\n\n### Physical touch experiment \n  \nWhile subjects underwent fMRI scanning, physical tactile stimulation was applied via paintbrushes, either to the participants\u2019 middle finger (MF) or index finger (IF), or simultaneously to both the middle and index fingers (both fingers\u00a0=\u00a0BF) of their right hands. In this way, the RF topography during physical touch perception could be described and later be compared to the RF topography during observation of touch to the corresponding fingers. In addition, added S1 activity changes during single-finger stimulation could later be compared with S1 activity changes during double-finger stimulation, as a measure of suppressive interactions (Gandevia et al.  ; Ruben et al.  ). \n\nIn the scanner, participants had their right hands fixed on a plastic board placed on the abdomen. The two paintbrushes used for tactile stimulation were mounted on two sticks that were connected to the plastic board to hold them at an optimal and fixed angle towards the fingers. To apply tactile stimulation, the two sticks were manually moved back and forth by the experimenter, who sat next to the scanner. Prior to the actual study, the experimenter was given intensive training in applying touch with constant pressure and with as little resultant movement as possible. Stimulation blocks lasted 24\u00a0s, consisted of four upward and four downward strokes (3\u00a0s per stroke), and were always followed by a 24\u00a0s rest period. In each run, the three stimulation blocks (IF, MF, BF) were repeated three times in a randomized sequence. The experiment consisted of four runs. Thus, each stimulation block was repeated 12 times throughout the experiment, which lasted about 30\u00a0min in total. Participants were instructed to close their eyes and to completely relax their hands and fingers throughout the scanning session. Trial order and temporal sequence of stimulation blocks were indicated to the experimenter via earphones. \n\n\n### Observed touch experiment \n  \nDuring touch observation, participants in the scanner observed short video clips (6\u00a0s in duration) showing human right hands being touched by different paintbrushes. While watching the videos, no physical tactile stimulation was applied to the participants\u2019 fingers. In the videos, analogous to the physical touch experiment, either the IF, MF, or BF of the right hand were stroked by one or two paintbrushes, respectively. When only one finger was stroked, the other paintbrush stroked the tabletop next to the hand. We also included a no-touch (control) condition, where both paintbrushes stroked the tabletop, while the hand was still visible. In half of the videos, participants saw their own hand from the first person perspective; in the other half they saw another person\u2019s hand from the third person perspective. In this way, half of the observed touch and no-touch videos were related to the self, whereas the other half were clearly assigned to another person. Overall, this resulted in eight experimental conditions (observed touch IF/observed touch MF/observed touch BF/no-touch\u00a0\u00d7\u00a0self-related/other-related observed touch, see Fig.\u00a0 b). Throughout the experiment, each condition was repeated 12 times.   \nDesign and example trial of the observed touch experiment.   a   Example trial as shown to participants in the scanner. Each trial started with the same question (\u201cWhich paintbrush is rougher?\u201d) followed by two video clips presented in direct succession that belonged to the same experimental condition, but showed two different paintbrush pairs for tactile stimulation; while seeing a question mark on the screen, participants then had to indicate via left-hand button-presses which of the two paintbrush pairs was rougher. Half of the participants responded with their left index finger when they thought the first paintbrush pair was rougher and with their left middle finger when they thought the second was rougher, the other half responded vice versa; the pause between two trials was 6\u00a0s in two-thirds of the trials and 20\u00a0s in one-third of the trials, and this was counterbalanced across conditions.   b   Participants saw either their own hand in the first person perspective or another person\u2019s hand in the third person perspective on video; in the observed touch conditions, touch was applied to either the middle finger (MF), the index finger (IF), or to both fingers (BF) of the right hand; in the no-touch condition, the paintbrush pair stroked the white surface on which the hand was positioned \n  \n\nIn each trial, two brief video clips were presented in direct succession that both belonged to the same experimental condition. In both clips, the paintbrushes shown differed in their roughness levels. After watching both video clips, participants had to indicate via left hand button presses whether they thought that the first or the second video displayed the rougher paintbrushes (see Fig.\u00a0 a for an example trial). A correct response could be given in each trial (see \u201c \u201d for details). This secondary task was conducted to ensure constant attention during the experiment and to estimate how well participants could judge the sensory experience related to paintbrush strokes by sight. \n\n\n### Design \n  \nThe entire experiment took approximately 47\u00a0min in total and consisted of 96 trials. Half of the trials in each experimental condition showed the rougher paintbrushes first, the other half showed the smoother paintbrushes first. Trials were pseudo-randomly presented with the constraint that none of the experimental conditions was repeated more than twice in a row, and in such a way that trials in each condition added up to the same relative time point within the experiment. Prior to scanning, participants were allowed to practice the task in four trials outside the scanner room. The experimenter ensured that they understood the task well, and were familiar with the response mode prior to entering the scanner room. \n\n\n### Stimuli \n  \nThe video clips were recorded several weeks prior to scanning, with the same participants who later took part in the fMRI studies. During the video recordings, participants placed their right hand comfortably on a white table. Their right arm passed through a hole in a paper wall mounted in front of the table, so that they could not see their hand, the paintbrushes, or the experimenter throughout the video recordings. Their right hand was positioned such that their fingers did not touch each other but were also not stretched too far apart, and they were told to completely relax their right hand and fingers for the recording. For tactile stimulation, the experimenter used five different identical-looking paintbrushes [DaVinci paintbrushes, series 5025 (1), 5073 (2), 5036 (3), 5040 (4), and 5076 (5)]. Tactile stimulation was applied for 6\u00a0s, either to the participants\u2019 right MF, IF or BF. In all conditions, two paintbrushes moved in parallel following a fixed temporal sequence that was indicated to the experimenter by an auditory signal (3\u00a0s per stroke, two strokes in total). All videos were recorded at a constant illumination level and with a constant angle and height between the video camera and the hands. During the video session, participants were blind with respect to the purpose of the video recordings, and they were not told how many or which kind of paintbrushes were used for stimulation. \n\nDuring the fMRI experiment, the following paintbrush pairs were compared in the two videos of one trial: (1) versus (4), (2) versus (5), (1) versus (2), and (3) versus (5). Paintbrushes with higher numbers had softer and more flexible brushes and thus a smoother stroke than those with lower numbers. This was tested in a behavioral pre-experiment with an independent group of 9 participants. Roughness levels of all the paintbrush pairs used could be correctly distinguished well above chance (see Online Resource 1 for more information on this experiment). As a criterion to define self/other hand pairs, we matched the self-related and other-related hands for each participant in terms of gender, and chose partners with a similar hand shape index [i.e., ratio of width to length of hand (Longo and Haggard  ); mean hand shape difference between self/other-pairs in our study: 4.4\u00a0%]. Importantly, once a self/other hand pair was identified, the videos that served as the self conditions for one partner always served as the other conditions for the matching partner. In this way, self/other differences in the video clips that could not be explicitly controlled (for example differences in skin color) were counterbalanced across participants. \n\n\n### Imaging acquisition parameters \n  \nFunctional and structural MRI data were acquired using a 7\u00a0T MR scanner (Magnetom 7T, Siemens Healthcare Sector, Erlangen, Germany) with a 24-channel NOVA head coil. Prior to both experiments, high-resolution 3D anatomical T1-weighted scans were acquired. For the observed touch experiment, which was always conducted first, structural data were acquired using the MP2RAGE sequence with the following parameters: TR\u00a0=\u00a05.0\u00a0s, TE\u00a0=\u00a02.45\u00a0ms, TI1/TI2\u00a0=\u00a0900\u00a0ms/2,750\u00a0ms, flip angle\u00a01/flip angle\u00a02\u00a0=\u00a05\u00b0/3\u00b0 with an isotropic voxel resolution of 0.7\u00a0mm (Marques et al.  ). For the physical touch experiment, we used a shorter T1-sequence with a slightly reduced spatial resolution, because the T1-images acquired for each participant during the observed touch experiment could later be used for data analyses; the MP2RAGE sequence here served only to anatomically localize S1 in the subsequently measured functional scans. Acquisition parameters in the physical touch experiment were: TR\u00a0=\u00a04.0\u00a0s, TE\u00a0=\u00a02.36\u00a0ms, TI1/TI2\u00a0=\u00a0900\u00a0ms/2,750\u00a0ms, flip angle\u00a01/flip angle\u00a02\u00a0=\u00a05\u00b0/3\u00b0 with an isotropic voxel resolution of 0.9\u00a0mm. Shimming was performed in both experiments prior to collecting the functional data. In both experiments, T1-weighted scans were subsequently used to select 30 axial slices (interleaved slice acquisition, slice thickness\u00a0=\u00a01.5\u00a0mm, no gap) covering bilateral S1 and adjacent areas (see Fig.\u00a0 ). The hand knob area was used for this purpose. This is easily identified in sagittal T1-images, and reliably indicates the location of the hand area in the primary motor cortex (Yousry et al.  ), and the primary somatosensory cortex (Moore et al.  ; Sastre-Janer et al.  ; White et al.  ). Functional T2*-weighted gradient-echo echo-planar images were then acquired using GRAPPA acceleration (iPAT\u00a0=\u00a03; Griswold et al.  ). A field of view of 192\u00a0\u00d7\u00a0192\u00a0mm  and an imaging matrix of 128\u00a0\u00d7\u00a0128 were used. The functional images had isotropic 1.5\u00a0mm voxels. The other sequence parameters were: TR\u00a0=\u00a01.5\u00a0s, TE\u00a0=\u00a020\u00a0ms, flip angle\u00a0=\u00a090\u00b0. The acquisition parameters of the functional scans were identical for the physical and observed touch experiments.   \nSelected slices for functional imaging of one example subject. Shown is a sagittal slice of the anatomical MP2RAGE scan which was used to select 30 axial slices covering bilateral S1 on the basis of the individual subject\u2019s brain anatomy (i.e., hand knob area) \n  \n\nTo attenuate scanner noise, participants were provided with earplugs and ear-defenders. During the observed touch experiment, the middle and index fingers of participants\u2019 left hands were placed on two buttons of a response box. Visual stimuli were projected onto a plastic screen vertically mounted in front of the participants, which could be looked at via a mirror mounted on the receiver coil. \n\n\n### fMRI preprocessing and localization of S1 activity \n  \nPreprocessing and statistical analyses of the functional imaging data were carried out using SPM8 (Statistic Parametric Mapping, Wellcome Department of Imaging Neuroscience, University College London, London, UK). A slice timing correction was applied to correct for differences in image acquisition time between slices, and realignment was performed to minimize movement artifacts in the time series (Unser et al.  ,  ). Normalization to standard MNI space was done using the unified segmentation approach based on image registration and tissue classification (Ashburner and Friston  ). The high-resolution T1-weighted images of both sessions were used to visually confirm correct registration between the sessions. In addition, the co-registration of each participant within the experiments was visually checked in order to identify possible spatial distortion effects that may occur at higher field strength (none were found, however). Data were filtered with a high-pass filter of 0.01\u00a0Hz to eliminate slow signal drifts. Data were smoothed with a Gaussian kernel of 4\u00a0mm full-width half-maximum (FWHM). \n\nS1 is not a homogenous area, but can be classified into four sub-areas (from rostral to caudal: areas 3a, 3b, 1 and 2). The Anatomy Toolbox implemented in SPM8 (Eickhoff et al.  ,  ,  ; Geyer et al.  ,  ; Grefkes et al.  ) was used to specify in which sub-area activity changes took place for the normalized group-level and single-subject analyses. Single-subject analyses were additionally performed without normalization into stereotactic space in order to describe the site of the suppressive interaction effect as precisely as possible in relation to the cortical anatomy of each individual subject. We used guidelines that linked cytoarchitectonic labeling with anatomical descriptions of subregions (Geyer et al.  ,  ; Grefkes et al.  ; White et al.  ). According to these specifications, areas 3a and 3b (anterior S1) are found in the deep valley of the central sulcus and in the anterior wall of the postcentral gyrus, respectively, whereas areas 1 and 2 (posterior S1) are located at the crown of the postcentral gyrus and at the posterior wall of the postcentral gyrus, respectively. It is important to note that although these specifications are useful, no clear anatomical landmark exists for the exact transition zone between S1 subregions (Geyer et al.  ). However, using a combination of automated and manual labeling, and by including single-subject analyses, the localization of the suppressive interaction effect in S1 in the current study is described in reasonable detail. \n\n\n### fMRI statistical analyses \n  \nA general linear model (GLM) was fitted to the data and   t  -maps were created on the individual subject level. In the observed touch experiment, the observation times of the two video sequences in each trial were modeled as blocks and used to compute contrast images by linear combination of parameter estimates. In the physical touch experiment, the physical tactile stimulation blocks were used for this same purpose. In the observed touch experiment, the questions and the button-press events were included into the model as regressors. We used one-sample   t   tests at the second level to calculate different contrasts for the physical and observed touch experiments. All contrasts on the group level and on the normalized single-subject level were a priori masked with the anatomical S1 mask offered by the Anatomy Toolbox implemented in SPM8. Because the functionally scanned regions were manually selected in each individual subject based on the T1 scans (see Fig.\u00a0 ), thus always covering S1 but covering varying parts of the motor or parietal cortices depending on the individual subject\u2019s brain anatomy, this anatomical masking ensured comparable data analyses for all participants. \n\nFor the group-level calculations, reported voxels of the functional data were considered significant at   p  \u00a0<\u00a00.001 when belonging to a cluster significant at   p  \u00a0<\u00a00.05 (FWE-corrected). In addition, we describe some of the group-level clusters at uncorrected cluster-thresholds (i.e., without FWE-correction) when this provided additional information (for example on the question of whether ipsilateral S1 would show any sub-threshold activity). When these more liberal analyses were used, it is explicitly pointed out in the results section. In addition to group-level analyses, single-subject analyses were also performed in order to describe some of the reported effects in greater detail. For the single-subject analyses, reported voxels were thresholded at   p  \u00a0<\u00a00.001. They are mentioned when belonging to a cluster with a minimum size of five voxels (16.8\u00a0mm ). \n\n#### Topographical arrangement \n  \nFor the physical touch experiment, we calculated the main effect of physical touch perception versus rest (IF touch\u00a0+\u00a0MF touch\u00a0+\u00a0BF touch\u00a0\u2212\u00a03\u00a0\u00d7\u00a0rest), and the specific effects of touch applied only to the IF, MF, and to BF, respectively (e.g., IF touch\u00a0\u2013\u00a0rest). For the observed touch experiment, we calculated the main effect of observing touch to the hand versus observing no touch to the hand, as presented in the videos [(self-related observed touch IF\u00a0+\u00a0self-related observed touch MF\u00a0+\u00a0self-related observed touch BF\u00a0\u2212\u00a03\u00a0\u00d7\u00a0no-touch self)\u00a0+\u00a0(other-related observed touch IF\u00a0+\u00a0other-related observed touch MF\u00a0+\u00a0other-related observed touch BF\u00a0\u2212\u00a03\u00a0\u00d7\u00a0no-touch other)]. This effect was also calculated separately for observing touch to the IF, MF and BF, respectively. To look at whether S1 RFs during observed touch were topographically aligned, we masked the observed touch contrasts with the corresponding physical touch masks (e.g., observed touch IF\u00a0\u2013\u00a0no-touch masked with IF touch\u00a0\u2013\u00a0rest) and non-corresponding physical touch masks (e.g., observed touch IF\u00a0\u2013\u00a0no-touch masked with MF touch\u00a0\u2013\u00a0rest). Physical touch masks contained all voxels significant at   p  \u00a0<\u00a00.001 that belonged to a cluster significant at   p  \u00a0<\u00a00.05 (FWE-corrected). In addition, we estimated whether the topographical arrangement of S1 RFs during observed touch followed the expected pattern (i.e., the RF of the IF was supposed to be more lateral, more anterior, and more inferior than the RF of the MF). \n\n\n#### Suppressive interactions \n  \nTo calculate suppressive interactions between adjacent RFs in S1, we compared the expected activity changes to the actual activity changes during BF physical stimulation or observation, respectively. More precisely, for the physical touch experiment, we calculated the expected activity changes in S1 in the case where signal changes during touch applied to the IF and MF added up linearly. This was calculated as a first-level contrast [i.e., (IF touch\u00a0\u2013\u00a0rest)\u00a0+\u00a0(MF touch\u00a0\u2013\u00a0rest)]. This contrast was then compared with the actual activity changes during BF stimulation (i.e., BF touch\u00a0\u2013\u00a0rest). Also this calculation was performed at the first-level. Note that this is analogous to how suppressive interactions during physical touch were characterized in a previous fMRI study (Ruben et al.  ), as we confirmed in an additional analysis (results not reported). \n\nFor the observed touch experiment, analogous methodology was applied: to measure suppressive interactions during observed touch, we first calculated the expected activity changes in S1 if activity changes during observed touch to the IF and MF added up linearly [i.e., (self-related observed touch MF\u00a0+\u00a0self-related observed touch IF\u00a0\u2212\u00a02\u00a0\u00d7\u00a0no-touch self)\u00a0+\u00a0(other-related observed touch MF\u00a0+\u00a0other-related observed touch IF\u00a0\u2212\u00a02\u00a0\u00d7\u00a0no-touch other)]. To define suppressive interactions during observed touch, this contrast was compared with actual S1 activity changes during observed touch to BF [i.e., (self-related observed touch BF\u00a0\u2212\u00a0no-touch self)\u00a0+\u00a0(other-related observed touch BF\u00a0\u2212\u00a0no-touch other)]. These same analyses were also performed separately for the self- and other-related observed touch conditions. \n\nThe suppressive interaction contrast therefore specified signal decreases in S1 that particularly occur in the BF stimulation and observation conditions, respectively. Signal decreases in these conditions that most likely reflect suppressive interactions are those which occur in voxels that belong to the RF of one of the two single fingers. Other signal drops can be less easily explained by suppressive interactions between adjacently activated RFs. We, therefore, spatially specified the suppressive interaction contrast by only describing significant activity decreases in voxels that that belonged to the RFs either of the IF or of the MF. More precisely, the suppressive interaction contrast for physical touch perception was masked by all voxels that were activated by physical IF stimulation plus those that were activated by physical MF stimulation at   p  \u00a0<\u00a00.001 belonging to a cluster of   p  \u00a0<\u00a00.05 (FWE-corrected; see Ruben et al.   for a similar approach). The suppressive interaction effect for observed touch was analogously masked by all voxels that were activated during observed touch to the IF plus those that were activated during observed touch to the MF. Here, we restricted our search volume to this mask area. Note that this spatial specification was necessary in order to clearly identify signal decreases that were specific to the effect under investigation (i.e., suppressive interactions). \n\nWe also needed a way of quantifying the degree of suppressive interactions, both during physical touch perception and during touch observation. Using contrast estimates, we calculated interaction ratios (IRs), which have frequently been used to specify the relation between expected and real activity changes in S1 (IR\u00a0=\u00a0100\u00a0\u2212\u00a0([BF/(IF\u00a0+\u00a0MF)]\u00a0\u00d7\u00a0100); Biermann et al.  ; Hsieh et al.  ; Ishibashi et al.  ; Ruben et al.  ). We used the masks created for specifying the suppressive interaction contrast for physical touch and observed touch (see previous paragraph) to extract all relevant contrast estimates for each individual subject. The individual IRs could then be used to calculate the mean IR across participants. This allows a much more detailed and spatially specific analysis than taking the contrast estimates as a mean across the whole group of participants. However, this procedure comes with the cost of only allowing the analysis of those participants for whom a mask could be created. More precisely, only those participants who showed significant activity changes at the single-subject level for physically/visually perceiving touch to the MF and IF could be included. As expected, this was the case for all participants with respect to physical touch perception (  N  \u00a0=\u00a015). However, this was not the case for all participants with respect to touch observation. More precisely,   n  \u00a0=\u00a010 participants could be used to calculate the mean IR for observed touch, and   n  \u00a0=\u00a09 participants could be used to calculate the mean IR for self-related observed touch. For other-related observed touch, only   n  \u00a0=\u00a04 participants fulfilled these criteria (i.e.,   n  \u00a0=\u00a011 participants did not show significant activity changes when observing other-related touch to the MF or to the IF at the single-subject level). Thus, the mean IR for other-related observed touch was not calculated. \n\nTo summarize, whereas voxel-wise statistics included all participants (  N  \u00a0=\u00a015), contrast estimates to calculate the IR during observed touch could only be extracted for a subset of participants due to the masking procedure that required significant single-subject results [  n  \u00a0=\u00a010 for main effect of observed touch,   n  \u00a0=\u00a09 for self-related observed touch,   n  \u00a0=\u00a04 for other-related observed touch (not calculated)]. \n\n\n#### Overlapping RFs \n  \nTo find out whether suppressive interactions occurred only in voxels where IF and MF RFs overlapped (and could, thus, theoretically be explained by ceiling effects of the BOLD signal, for example), or also occurred in non-overlapping voxels, we additionally calculated whether suppressive interactions occurred only in \u201coverlapping\u201d, or also in \u201cnon-overlapping\u201d S1 voxels. Overlapping voxels were defined as those voxels in S1 that were active when both touch to the IF and touch to the MF were observed (i.e., observed touch IF\u00a0\u2013\u00a0no-touch \u2229 observed touch MF\u00a0\u2013\u00a0no-touch) or experienced (IF touch\u00a0\u2013\u00a0rest \u2229 MF touch\u00a0\u2013\u00a0rest), whereas non-overlapping voxels were those which did not overlap between the two contrasts. We calculated the percentage (%) of suppressive interaction voxels in either category (i.e., suppressive interaction effect in overlapping and non-overlapping voxels) separately for physical and observed touch. \n\n\n\n### Behavioral analyses \n  \nDuring the observed touch experiment, participants solved a secondary two-alternative forced-choice task in the scanner, in which they had to indicate which of two subsequently presented video clips displayed the rougher paintbrush pair. The two video clips presented in one trial always showed paintbrushes of different roughness levels, such that a correct or incorrect response could be given in each trial. We performed a repeated-measures analysis of variance (ANOVA) to estimate the influence of hand identity (self-related, other-related) and observed event (observed touch, no-touch) on the percentage of correct responses given in this task. We also calculated a one-way ANOVA to estimate the influence of finger touch (MF, IF, BF) on the percentage of correct responses. To investigate whether the individual degrees of suppressive interactions across trials were related to how precisely roughness levels could be estimated by sight, we performed Pearson correlations between individual IRs during touch observation and the percentage of correct responses both for the IRs across conditions and the IRs for the self-conditions. \n\n\n\n## Results \n  \n### Topographical arrangement \n  \nAs expected, physical touch administered to participants\u2019 right fingers activated, as a main effect, a large significant cluster in left (contralateral) S1 that peaked in left posterior S1, and extended to left anterior S1. Touch applied specifically to the right IF, MF, or to BF, respectively, also activated significant focal areas in left S1. The IF and MF RFs partly overlapped, but were also partly distinct. The significant clusters peaked in left posterior S1, but extended to left anterior S1 (see Fig.\u00a0 a; Table\u00a0 ). No significant activity changes were found in right (ipsilateral) S1 for these contrasts. We also looked at sub-threshold activity in ipsilateral S1. Here, we found that when the significance threshold of   p  \u00a0<\u00a00.001 and   k  \u00a0\u2265\u00a05 was not FWE-corrected, one cluster in right (ipsilateral) S1 showed greater activity during physical touch perception compared with rest [  k  \u00a0=\u00a09;   t  \u00a0=\u00a04.05; 53, \u221218, 34 (  x  ,   y  ,   z  )] (see Online Resource 2 for a complete list of sub-threshold activity changes).   \nSuppressive interactions (SI) in contralateral S1 during physical touch perception (  a  ) and touch observation (  b  ).   a   Activity changes of contralateral S1 during physical touch applied to the index finger (IF) and the middle finger (MF); in addition, the suppressive interaction (SI) effect for physical touch is displayed using voxel-wise statistics in the   upper panel   (IF touch\u2013rest\u00a0+\u00a0MF touch\u2013rest\u00a0\u2212\u00a0BF touch\u2013rest), and using contrast estimates in the   lower panel  ; the   bar   labeled \u201cExpected activity\u201d describes the added contrast estimates of physical touch to the IF and MF, whereas the   bar   labeled \u201cActual activity\u201d describes the contrast estimates when both fingers were stimulated together; the   bar graphs   show mean contrast estimates\u00a0\u00b1\u00a0standard deviation (SD) of all (  N  \u00a0=\u00a015) participants.   b   Activity changes of contralateral S1 during observed touch to the IF and MF; in addition, the SI effect for observed touch is displayed using voxel-wise statistics in the   upper panel   (obs. touch IF\u2013no-touch\u00a0+\u00a0obs. touch MF\u2013no-touch\u00a0\u2212\u00a0obs. touch BF\u2013no-touch), and using contrast estimates in the   lower panel  ; the   bar   labeled \u201cExpected activity\u201d describes the added contrast estimates of touch observation to the IF and MF, whereas the   bar   labeled \u201cActual activity\u201d describes the contrast estimates when touch to both fingers together was observed; the   bar graphs   show mean contrast estimates\u00a0\u00b1\u00a0standard deviation (SD) of   n  \u00a0=\u00a010 participants (see \u201c \u201d for details on why not all participants were part of this analysis); functional images are masked with an anatomical mask covering contralateral S1 and are thresholded at   p  \u00a0<\u00a00.0005 (uncorrected) (  a  ) and   p  \u00a0<\u00a00.001 (uncorrected) (  b  ); the data are displayed on a normalized T1-image of an individual subject;   Pre   precentral gyrus,   Post   postcentral gyrus \n    \nS1 activity changes during physical touch perception and touch observation in different experimental conditions \n  \nListed clusters contain voxels thresholded at   p  \u00a0<\u00a00.001 and are cluster-corrected at   p  \u00a0<\u00a00.05 (FWE-corrected); the two contrasts which are marked with a # show clusters that are   not   cluster-corrected, but contain a minimum of five voxels using the same voxel threshold; see Online Resource 2 for a complete list of sub-threshold activity changes for all listed contrasts \n\n obs.   observed,   MF   middle finger,   IF   index finger,   BF   both fingers,   SI   suppressive interactions,   IPC   inferior parietal cortex \n  \n\nFor observed touch, we found that looking at a hand being touched compared with looking at the same hand not being touched significantly increased activity in left (contralateral) posterior S1. Note that participants did not receive any tactile stimulation in either of these observation conditions. No significant activity changes were found for the reverse contrast (no-touch vs. observed touch). In addition, we were interested in whether right (ipsilateral) S1 would show any sub-threshold activity during touch observation. When we omitted the FWE-correction, significant activity changes in ipsilateral S1 were found (  p  \u00a0<\u00a00.001 and   k  \u00a0\u2265\u00a05). This cluster was localized in posterior parts of right S1 (see Online Resource 2 for a list of all sub-threshold activity changes). \n\nObserving touch to specific fingers also activated left (contralateral) S1. Whereas activity changes in left S1 during observed touch to the IF and to BF survived the standard cluster-corrected thresholds, activity change in left S1 during observed touch to the MF was only significant when no cluster-correction was applied (  p  \u00a0<\u00a00.001 and   k  \u00a0\u2265\u00a05). All observed touch clusters peaked in left posterior S1 (see Table\u00a0 ; Fig.\u00a0 ). To verify that activity changes in contralateral S1 in response to touch observation were restricted to posterior S1, and did not occur in anterior S1 (particularly in area 3b), we conducted an ROI analysis focusing on left area 3b. We masked the contrast observed touch\u2013no-touch with the left area 3b mask provided by the Anatomy toolbox implemented in SPM. Here, we found that no significant activity changes survived the standard significance threshold, even when voxels at   p  \u00a0<\u00a00.001 and   k  \u00a0\u2265\u00a05 belonging to uncorrected clusters were taken into account. \n\nWe also looked at whether S1 activity changes during observed touch overlapped with S1 activity changes during physical touch. We masked the contrast observed touch\u2013no-touch with physical touch\u2013rest, and found that significant clusters for touch observation were present in posterior contralateral S1. Similarly, we found that activity changes specific to observing touch to the IF were still significant when masked with the effect of physically experiencing touch to the IF (number of voxels: 124), but not when masked with the effect of physically experiencing touch to the MF (number of voxels: 111). The significant overlap was found in left posterior S1 (see Table\u00a0 ; Fig.\u00a0 ). As explained above, observing touch to the MF evoked activity changes in contralateral S1, significant only when no cluster-correction was applied. We then looked at whether these clusters would be preserved when masked with physical touch to the IF or MF. We found that one cluster remained significant both when masked with physical touch to the MF and when masked with physical touch to the IF (number of voxels MF mask: 25, number of voxels IF mask: 23). This overlap was also found in left posterior S1 (see Table\u00a0 ; Fig.\u00a0 ). To estimate whether the mask would have any significant effect on the number of voxels included in the corresponding and non-corresponding masks, we performed a Chi-square test including the number of voxels significant within the two mask conditions of both contrasts. This test did not reach statistical significance (  p  \u00a0>\u00a00.2). When estimating the percentage of participants who showed overlapping activity changes between physical and observed touch in the different conditions, we found that 75\u00a0% of participants showed shared voxels for observed touch to the IF, 78\u00a0% showed shared voxels for observed touch to the MF, and 92\u00a0% showed shared voxels for observed touch to BF.   \nOverlap between activity changes during physical touch perception and touch observation in contralateral S1. Overlapping voxels between physical touch perception and touch observation are displayed in purple; overlaps are shown separately for the index finger (  upper panel  ) and the middle finger (  lower panel  ); functional images are masked with an anatomical mask covering contralateral S1 and thresholded at   p  \u00a0<\u00a00.001 (uncorrected); functional data are visualized on a normalized T1 image of an individual subject;   Pre   precentral gyrus,   Post   postcentral gyrus \n  \n\nWe additionally looked at the topographic arrangement of activity changes as evoked by observing touch to the IF and the MF, respectively. We found that activity changes in both conditions were partly overlapping, but partly distinct. Importantly, activity changes evoked by observing touch to the IF were more lateral, more anterior, and more inferior than activity changes evoked by observing touch to the MF (see Table\u00a0 ; Fig.\u00a0 ).   \nReceptive field (RF) topography of the index finger (IF) and middle finger (MF) in contralateral S1 during physical touch perception and touch observation. Shown are five axial slices ordered from inferior (  z  \u00a0=\u00a042) to superior (  z  \u00a0=\u00a047) of   N  \u00a0=\u00a015 participants; the borders of the MF RFs are indicated using   blue lines  ; functional images are masked with an anatomical mask covering contralateral S1 and visualized at an individual\u2019s normalized T1 image; to make both conditions better comparable, a slightly more conservative threshold was chosen for physical touch perception [  p  \u00a0<\u00a00.0001 (uncorrected)] than for touch observation [  p  \u00a0<\u00a00.001 (uncorrected)] \n  \n\nOne last analysis was performed due to a concern that activity changes in contralateral S1 during touch observation could be explained by preparatory motor activity for the later button-press responses rather than by touch observation. To counter this argument, we looked at whether left and right primary motor cortex (M1) showed any increased activity changes during touch observation that could indicate preparatory motor activity or motor imaginary during touch observation. There were no significant activity changes neither in left nor in right M1 for the observed touch\u2013no-touch contrast. This was also true when not correcting for multiple comparisons. \n\n\n### Suppressive interactions \n  \nIn order to estimate the degree of suppressive interactions in S1 during physical touch perception, we compared the summed activity changes during physical touch perception to the IF and MF to the activity changes in the BF stimulation condition. We found a significant suppressive interaction effect for physical touch in left (contralateral) S1, which peaked at the border between left area 2 and the left inferior parietal cortex, and extended to left area 2, left BA 1, and left area 3b (see Table\u00a0 ; Fig.\u00a0 a). No significant suppressive interaction effect was found in right (ipsilateral) S1, even when the analysis was performed without correcting for multiple comparisons. At the individual subject level, suppressive interactions for physical touch were significant in all but one of the investigated participants (  n  \u00a0=\u00a014), and could be assigned to left area 1 and left area 2. Only a subset of participants showed additional significant activity changes in left area 3b (  n  \u00a0=\u00a04) and left area 3a (  n  \u00a0=\u00a02) for this contrast. The mean IR for physical touch perception was 37.2\u00a0%, SD\u00a0=\u00a015.9 (Fig.\u00a0 a, see Fig.\u00a0  for single subject data). \n\nWe then calculated the suppressive interaction effect for observed touch, which was similarly calculated by comparing summed activity changes in S1 evoked by observing touch to two single fingers separately to activity changes evoked by observing touch to both fingers together. Here, we found a significant suppressive interaction effect in two clusters that both peaked in left (contralateral) area 2. One cluster also extended to left area 1, the other extended to the left superior parietal lobule (see Table\u00a0 ; Fig.\u00a0 b). No significant suppressive interaction effect was found for right (ipsilateral) S1. At the individual subject level, we found a significant suppressive interaction effect in left S1 for   n  \u00a0=\u00a08 participants (see individual subject data of   n  \u00a0=\u00a05 participants in Fig.\u00a0 ). In all of them, the effect was located in left area 2. In   n  \u00a0=\u00a07 participants, activity changes also extended to left area 1, and in one subject, the activity changes extended to left area 3. Note that most of the other participants also showed suppressive interaction voxels in left S1 during observed touch, but these results are not reported due to the relatively conservative single-subject threshold we defined for our analyses [e.g.,   n  \u00a0=\u00a014 participants showed a suppressive interaction effect when we lower the single-subject threshold to   p  \u00a0<\u00a00.005 (uncorrected)].   \nContralateral S1 activity during physical touch perception and touch observation of   n  \u00a0=\u00a05 individual subjects. The   left side   of the figure shows functional data of physical touch to the index finger (IF), the middle finger (MF), and the suppressive interaction (SI) effect for physical touch; the   right side   of the figure shows functional data of observed touch to the IF, the MF, and the SI effect for observed touch; note that the same axial and coronal slices of the same subjects can here be visually compared; functional data are presented at the individual\u2019s normalized T1-anatomical scans; to make both conditions better comparable, a slightly more conservative threshold was chosen for physical touch perception [  p  \u00a0<\u00a00.001 (uncorrected)] than for touch observation [  p  \u00a0<\u00a00.005 (uncorrected)] \n  \n\nWe also calculated the suppressive interaction effect specifically for self- and other-related observed touch. The suppressive interaction effect for self-related observed touch revealed one significant cluster in left area 2. The suppressive interaction effect for other-related observed touch did not reveal any significant activity changes in S1. At the individual subject level,   n  \u00a0=\u00a08 participants showed a suppressive interaction effect for self-related observed touch, and   n  \u00a0=\u00a04 participants showed a suppressive interaction effect for other-related observed touch. The mean IR for self-related observed touch was 54.93\u00a0%, SD\u00a0=\u00a011.35. The mean IR for observed touch (main effect) was 50.22\u00a0%, SD\u00a0=\u00a09.35. \n\n\n### The role of overlapping RFs \n  \nWe found that the suppressive interaction effect for physical touch occurred in both overlapping and non-overlapping S1 voxels. More precisely, we found part of the cluster of the suppressive interaction effect for physical touch in overlapping voxels [  k  \u00a0=\u00a0113;   t  \u00a0=\u00a07.47; \u221254, \u221226, 39 (  x  ,   y  ,   z  ), localized in left area 2, the left inferior parietal cortex, and left area 1] and part of the cluster in non-overlapping voxels [  k  \u00a0=\u00a07,   t  \u00a0=\u00a04.74, \u221252, \u221221, 38 (  x  ,   y  ,   z  ), localized in left area 2, the left inferior parietal cortex, and left area 3b]. Also at the individual subject level, the suppressive interaction effect for physical touch occurred within both overlapping and non-overlapping S1 voxels in all subjects. As a mean across participants, 79\u00a0% of the suppressive interaction voxels were overlapping voxels, whereas 21\u00a0% were non-overlapping voxels. \n\nThe suppressive interaction effect for observed touch was, on the group level, only observed in non-overlapping S1 voxels [  k  \u00a0=\u00a014;   t  \u00a0=\u00a04.61; \u221256, \u221224, 45 (  x  ,   y  ,   z  ), localized in left area 2]. When looking at the individual subject level, however, the effect was found both in overlapping and non-overlapping S1 voxels in all participants. Across participants, 60\u00a0% of the voxels that showed a suppressive interaction effect were overlapping voxels, and the remaining 40\u00a0% were non-overlapping voxels. For self-related observed touch, again suppressive interactions at the group level were only found in non-overlapping S1 voxels [  k  \u00a0=\u00a014;   t  \u00a0=\u00a04.62; \u221242, \u221240, 62 (  x  ,   y  ,   z  ), localized in left area 2,   k  \u00a0=\u00a09;   t  \u00a0=\u00a04.93; \u221249, \u221236, 57 (  x  ,   y  ,   z  )]. At the single subject level, however, the effect was again found in both overlapping and non-overlapping S1 voxels. Here, 56\u00a0% of the voxels that showed suppressive interactions for self-related observed touch were overlapping voxels, and the remaining 44\u00a0% were non-overlapping voxels. \n\n\n### Behavioral results \n  \nAll participants performed the visual roughness discrimination task (where participants had to distinguish between roughness levels of different paintbrush pairs by sight) with high levels of accuracy [self touch: 93.1\u00a0%\u00a0\u00b1\u00a05.4 (SD), self no-touch: 95.0\u00a0%\u00a0\u00b1\u00a07.6 (SD), other touch: 91.8\u00a0%\u00a0\u00b1\u00a07.4 (SD), other no-touch: 91.7\u00a0%\u00a0\u00b1\u00a07.0 (SD),   N  \u00a0=\u00a015]. The participants maximally missed two trials throughout the entire experiment. The percentage of correct responses in the visual roughness discrimination task was not significantly influenced by hand identity (self, other) or the presence of hand touch (observed touch, no-touch). There was also no significant interaction between these two factors (  p  \u00a0>\u00a00.1). Also, the finger that was touched (IF, MF, BF) did not influence the percentage of correct responses, neither across conditions nor for the self- and other-related conditions separately (  p  \u00a0>\u00a00.05). With respect to how individual IRs related to the degree to which roughness levels could be distinguished by sight, there was a significant correlation between the individual IRs when the self was observed and the accuracy to solve the visual roughness discrimination task when self-related touch to the IF and to BF was observed (  r  \u00a0=\u00a00.78 for IF, and   r  \u00a0=\u00a00.76 for BF self,   p  \u00a0<\u00a00.05, two-tailed, see Online Resource 3). There was no such relation between the individual IRs during observed touch and percentage of accuracy across conditions. Note, however, that the number of subjects whose data were available to calculate this correlation (  n  \u00a0=\u00a09) was very small, such that this positive relation between individual IRs and behavioral performance has to be replicated and verified by future studies using a greater number of participants. \n\n\n\n## Discussion \n  \nThe present study offers the first detailed characterization of the functional architecture of S1 during touch observation. Our data show that posterior parts of contralateral S1 in particular, but not anterior parts, are activated when touch is observed on video. Activity changes in posterior S1 elicited by touch observation also overlap with those elicited by physical touch perception. Importantly, observing touch to the index finger alone or the middle finger alone offers a similar topographical arrangement of RFs in S1 as those elicited by physically perceiving touch to the same fingers. In addition, index and middle finger RFs show the characteristic dynamic shrinkage when activated concurrently not only during physical but also during visual touch perception. Our study, therefore, provides novel evidence indicating that the functional architecture in posterior S1 with respect to RF topography and RF interaction is similar between touch observation and physical touch perception. \n\n### Posterior S1 activity during touch observation \n  \nIn the present study, short video clips were presented to participants, which showed right hands being touched or not being touched by paintbrushes. By comparing observed touch conditions to conditions where no touch was observed, we found significant activity increases in left (contralateral) S1 as a main effect. This effect was not only found at the group level but also in almost all individual participants. Significant activity changes in right (ipsilateral) S1 were only found when the group level statistics were analyzed at uncorrected thresholds. The results of the present study show that observing touch to fingers of a right hand, therefore, clearly evokes activity increases in left posterior S1. \n\nThe finding that touch observation can elicit activity increases in S1 is in accordance with a growing body of evidence suggesting the independence of S1 activity from direct somatosensory input (Chen et al.  ; Yoo et al.  ; Driver and Noesselt  ; Meehan et al.  ; Wood et al.  ). Specifically touch observation has, in a number of fMRI studies, been shown to trigger profound activity increases in S1 (Blakemore et al.  ; Ebisch et al.  ; Kuehn et al.  ; Schaefer et al.  ,  ,  ). A previous study also indicated that in particular posterior rather than anterior contralateral S1 responds to the observation of tactile events (Kuehn et al.  ). This appears to contrast findings reported in an fMRI study by Schaefer et al. ( ). Participants in that study also observed short video sequences where hands were either touched or not touched by paintbrushes. Whereas, in accordance with the present results and those previously reported, touch observation induced activity increases in posterior contralateral S1, the authors also reported responsivity of anterior S1, specifically when participants looked at a hand presented in a first-person viewing perspective. A recent study re-investigating this topic using 7\u00a0T fMRI (Kuehn et al.  ) yielded divergent findings. In that study, anterior S1 did not show significant activity changes, neither as a main effect, nor when first-person and third-person viewing perspectives were directly compared. Kuehn et al. ( ) argued that the lower spatial resolution of the data used by Schaefer et al. ( ), in terms of voxel size and smoothing, may have accounted for the divergent findings. Although an involvement of anterior S1 cannot be excluded, it seems that the major responsivity of S1 during touch observation stems from its posterior parts. This is also in accordance with the recently formulated hypothesis that posterior S1 in particular is open to social influences, for example during action observation (Keysers et al.  ). \n\nThe high connectivity between posterior S1 and visual input areas in the parietal cortex, some of which are known to contain bimodal visuo-tactile neurons (Duhamel et al.  ; Ishida et al.  ; Lewis and Van Essen  ; Maunsell and van Essen  ; Pons and Kaas  ; Rozzi et al.  ) and to show bimodal activation pattern in humans (Sereno and Huang  ), can serve to explain this greater influence of vision on activity changes in the posterior rather than the anterior part of S1. Anterior S1 is more strongly connected to the thalamus than posterior S1 (Kaas  ; Nelson and Kaas  ); therefore, we assume that the thalamus did not strongly contribute to the S1 activity observed in the present study. A dichotomic division of S1 into posterior S1, showing pronounced reactivity to visual input (e.g., during observed touch) and anterior S1, which may still be regarded as a unisensory brain area mainly driven by bottom-up somatosensory input, has been suggested previously (Keysers et al.  ; Kuehn et al.  ), and is supported by our results. \n\nAnother important question is whether the activity changes in posterior S1 found in our study were triggered by touch observation, or resulted from preparatory motor responses or mental imaginary of action. Given the role of area 2 in proprioception (Hsiao and Bensmaia  ), and the involvement of S1 in motor preparation (Kawashima et al.  ), such an explanation cannot a priori be excluded. However, for the present findings, this explanation is highly unlikely. Activity changes in S1 were strongly lateralized to left S1 (contralateral to the observed touch events), whereas right S1 (contralateral to the motor response) showed only sub-threshold activity. In addition, we did not find any activity increases in left or right M1 during touch observation, which would be expected if one assumed an involvement of motor preparation (Kawashima et al.  ) or motor imaginary (Dushanova and Donoghue  ). We are, therefore, confident that the S1 activity reported in the present study is due to touch observation rather than preparatory motor activity or motor imaginary. \n\n\n### Topography of S1 activity during touch observation \n  \nIn order to describe the functional architecture of posterior S1 during touch observation, we first looked at whether S1 activity during observed and physically perceived touch showed a regional overlap. Any overlap would indicate a resonance response (Hogeveen and Obhi  ; Landmann et al.  ; Virji-Babul et al.  ) within S1 between physically perceived and observed touch. Such resonance responses have often been described for the motor system (Buccino et al.  ; Mukamel et al.  ; see Caspers et al.   and Gazzola and Keysers   for an overview), the insula (Corradi-Dell\u2019Acqua et al.  ; Singer et al.  ; see Bernhardt and Singer   and Lamm et al.   for an overview), S2 (Keysers et al.  ), and also for S1 (Blakemore et al.  ; Ebisch et al.  ; Schaefer et al.  ). However, so far, they have not been characterized with such a high sensitivity and high spatial specificity as offered by the design of the present study. Whereas previous studies indicated spatial specificity of S1 activity when touch to different body areas, such as the face and neck, was observed (Blakemore et al.  ), or showed that observing hand touch elicited specific activity increases in the hand area of S1 (Kuehn et al.  ; Schaefer et al.  ), the present study indicates a spatially specific resonance response at the level of the single finger. More precisely, observing touch to the index finger overlapped with activity changes during physically experiencing touching of the index finger, and observing touch to the middle finger overlapped with activity changes during physically experiencing touching of the middle finger. Interestingly, whereas this resonance response seemed relatively specific for the index finger (i.e., S1 responses to observing touch to the index finger significantly overlapped with those to physical touching of the index finger, but did not significantly overlap with those to physical touching of the middle finger), this specificity was not present for observing touch to the middle finger. Here, the same significance level was reached irrespectively of whether the contrast of observing touch to the middle finger was masked with physical touching of the index finger or physical touching of the middle finger. In addition, the responsivity of S1 was generally larger when touching to the index finger was observed compared with when touching to the middle finger was observed. These results indicate that observing touch to the index finger leads to higher and spatially more specific responses in S1 compared to observing touch to the middle finger. These results could be explained by the generally enhanced use of the index finger compared to the middle finger, for example during the so called precision grip (Napier  ). In studies on the motor system, greater experience in a certain motor behavior has been shown to lead to increased responses in the motor system not only during action performance (Karni et al.  ,  ) but also during action observation (Calvo-Merino et al.  ; Cross et al.  ). In addition, a more precise response of the action observation network has also been assumed for participants that have more experience with the observed actions (Cross et al.  ; Diersch et al.  ). One may therefore argue that the results of the present study indicate a similar relation in the somatosensory system. Increased tactile experience of a certain body area, such as the index finger, that has been shown to relate to increased S1 activity (Braun et al.  ; Pleger et al.  ) and better discrimination abilities (Braun et al.  ; Ragert et al.  ; Schweizer et al.  ) during physical touch perception, may also cause a stronger and more precise representation during touch observation. \n\nIt is important to note, however, that the present data do now allow a direct comparison between touch observation and physical touch perception. Whereas in the observed touch videos, different paintbrushes were used for tactile stimulation, and a roughness task had to be solved, in the physical touch experiment, tactile stimulation was applied passively, and the same paintbrushes were used for tactile stimulation. The experimental set-ups therefore differ, and do not allow direct comparison of S1 RFs as evoked by visual and physical touch perception. Future studies should use completely analogue designs with respect to stimulus characteristics and attention requirements in order to compare the overlap between RFs in both conditions more precisely. Only such a design would finally allow conclusions to be drawn about the specificity of the activity overlap between physical touch perception and touch observation. \n\nA second main aspect that characterizes S1 topography during touch observation is the topographical arrangement of the evoked activity changes. Our results show that activity changes in S1 during touch observation to the index finger were partly distinct, and located more lateral, more anterior, and more inferior than activity changes in S1 during touch observation to the middle finger. This topographical alignment of index and middle finger RFs follows exactly the same pattern as has classically been described for physical touch (Nelson and Chen  ), and as has also been found in the present study. This indicates a surprisingly precise representation of observed touch events in S1, and assumes a precision down to the level of the single finger. Should further studies manifest this finding, this would offer another parallel to the action system. Also, observing motor movements of specific body parts has been shown to elicit somatotopically precise representations in the premotor cortex (Buccino et al.  ; Wheaton et al.  ); the present study assumes a similarly spatially specific and precise representation of observed human touch. \n\nTaken together, our results indicate that observing touch to single fingers does not simply activate the hand area in S1, but activates parts in S1 that are topographically precise. The spatial arrangement of S1 activity seems therefore highly similar during physically perceived and observed touch, which leads to the suggestion that not only action events but also tactile events can be shared between the observed person and the observer (Bufalari et al.  ). \n\n\n### Suppressive interactions during touch observation \n  \nIn the present study, the functional architecture in S1 was additionally characterized by looking at suppressive interactions between adjacently activated cortical RFs. Suppressive interactions in S1 have often been characterized by measuring the relative shrinkage of index and middle finger RFs when both are activated simultaneously, compared to when they are activated alone (Gandevia et al.  ; Ruben et al.  ). Using this approach in the present study, we found suppressive interactions mainly in posterior parts of contralateral S1, slightly extending to anterior S1. This confirms previous studies that found greater suppressive interactions during touch perception in posterior contralateral S1 (Friedman et al.  ; Ruben et al.  ; Sur  ; Sripati et al.  ), which may indicate an increasing convergence of somatosensory input from anterior to posterior sites of S1 (Ruben et al.  ). Also the mean interaction ratio found in the present study (38\u00a0%) was similar to that which has been described previously (Biermann et al.  ; Gandevia et al.  ; Ruben et al.  ). These comparable results between the present and previous attempts to characterize suppressive interactions in S1 confirm that the present approach was, in principle, suitable to characterize this phenomenon. \n\nThis is important given that analogue contrasts were used to characterize suppressive interactions during touch observation. This characterization was attempted for the first time in the present study. Here, we looked at whether suppressive interactions in S1 would similarly occur when touch to two fingers, compared to two single fingers separately, was not physically experienced but merely observed. Our data indicate that suppressive interactions in S1 may also occur during touch observation. More precisely, we found that observing touch to two fingers elicited decreased activity levels in S1 compared to observing touch to two single fingers separately, an effect that was specific for the areas in S1 where observed touch to single fingers separately elicited effects. Spatially, the effect was restricted to contralateral posterior S1, which was expected given that touch observation particularly activated posterior parts of contralateral S1. Importantly, suppressive interactions were also found in voxels that did not overlap between index and middle finger RFs, making vascular ceiling or saturation effects an unlikely explanation for the observed effects (Beauchamp et al.  ; Gardner and Costanzo  ). \n\nIt is important to note, however, that while the principle way of characterizing suppressive interactions during visual and physical touch perception in the present study was similar, the results of these two analyses should not be compared directly. During physical touch perception, participants lay in the scanner with their eyes closed, while they actively solved a roughness discrimination task during touch observation. Because previous research has evidenced an influence of attention on suppressive interactions in S1 (Braun et al.  ), the suppressive interaction effect in both conditions is not directly comparable because attentional demands varied between both experiments. Secondly, there was a difference in control conditions. During touch observation, S1 activity changes were compared to a control condition (i.e., where participants saw hands which were not being touched), whereas in the physical touch condition, no such control condition was present (i.e., physical touch perception was compared to a rest condition). Given that merely looking at hands may influence S1 activity (Fiorio and Haggard  ; Longo et al.  ) and the degree of suppressive interactions in S1 (Cardini et al.  ), one should avoid comparing the degree of suppressive interactions between physical and visual touch perception in the present study directly. \n\nThe indicated existence of suppressive interactions in S1 during touch observation can be embedded into the results from recent studies that assign S1 a specific and highly flexible role during touch and action observation (Avenanti et al.  ; Bolognini et al.  ; Bufalari et al.  ; Caspers et al.  ; Keysers et al.  ; Meyer et al.  ). For instance, using multivariate pattern analysis, it has been shown that activity patterns in S1 are separable when haptic exploration of different everyday objects is observed (Meyer et al.  ). Such variable and spatially specific activity changes in S1 could be regarded as an indication of the existence of inhibitory regulatory mechanisms that modulate S1 activity during touch observation. More direct evidence that vision can influence the degree of suppressive interactions in S1 during physical touch perception is offered by studies investigating somatosensory evoked potentials (SEPs) in different viewing conditions. Here, it has been assumed that looking at a body while receiving tactile stimulation increases suppressive interactions in S1 (Cardini et al.  ; Gillmeister et al.  ), which has been related to RF sharpening in this condition (Cardini et al.  ; Haggard et al.  ). Whereas the results of the present study are, therefore, in accordance with previous investigations, they are novel because they target the mechanism of suppressive interactions during touch observation for the first time directly. \n\n\n### The relation between suppressive interactions and behavioral performance \n  \nDuring physical touch perception, suppressive interactions are assumed to positively relate to perceived stimulus contrast (Braun et al.  ; Cardini et al.  ; Puts et al.  ). We therefore hypothesized that, if suppressive interactions during physical and observed touch share a mechanistic basis, such a relation to the ability to discriminate tactile stimulus features should also occur during touch observation. This analysis, however, was hampered by the very small sample size available to calculate this correlation (  n  \u00a0=\u00a09). However, when looking at the correlation, the degree of suppressive interactions during observed touch related positively to performance levels to discriminate roughness levels of paintbrushes by sight. Although this relation clearly needs further exploration in future studies, it indicates a powerful message: the degree of suppressive interactions in S1 during observed touch may determine the precision with which observed tactile events can be decoded by the observer. This is particularly interesting because, so far, signal decreases in S1 during touch observation are mostly assumed to indicate a lower resonance response, and are, thus, interpreted as evidence for lower degrees of inner simulation (Blakemore et al.  ; Ebisch et al.  ; Kuehn et al.  ). Given the results of the present study, this view may be rather one-dimensional. Signal decreases, at least when they can clearly be assigned to the occurrence of suppressive interactions, may indicate a more precise and less noisy, rather than a weaker, stimulus representation. This similarly holds for action observation. A recent study showed that the BOLD response in the action observation network, which is classically assumed to increase during observed actions that are more familiar (Buccino et al.  ; Calvo-Merino et al.  ; Cross et al.  ), does not increase when more familiar actions compared to less familiar actions are observed (Cross et al.  ). Given our framework, one may speculate that the decreases in the BOLD signal indicate a more precise representation of the observed familiar movements. Future studies should, therefore, take decreases of the BOLD signal into account when investigating the role of S1, or other brain areas, in the realm of social cognition. \n\n\n\n## Conclusions \n  \nTaken together, the results from our study provide strong evidence that posterior contralateral S1 is active during touch observation, and that these activity changes overlap with those elicited by physical touch experience. In addition, our results indicate that touch observation to single fingers elicits partly distinct and topographically precise single finger representations in S1, which show similar dynamic interactions as they do during physical touch perception. Although this study only provides a first step to understanding the functional architecture of S1 in a social context, it critically emphasizes the importance of taking fine-grained architectonic details into account when describing the role of S1 in social cognition. \n\n\n## Electronic supplementary material \n  \n\nBelow is the link to the electronic supplementary material.\n \n\n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table\u00a01\nContrast\tArea\tMNI location (x, y, z)\tPeak t value\tNo. of voxels\nPhysical touch\tPhysical touch\tPhysical touch\tPhysical touch\tPhysical touch\nMF touch\u00a0+\u00a0IF touch\u00a0+\u00a0BF touch\u2013rest\tL Area 2\t\u221255 \u221224 40\t8.31\t685\nMF touch\u2013rest\tL Area 2\t\u221255 \u221224 40\t7.33\t185\n\tL Area 2\t\u221244 \u221233 57\t6.78\t215\nIF touch\u2013rest\tL Area 2\t\u221237 \u221239 63\t9.03\t562\nBF touch\u2013rest\tL Area 2\t\u221256 \u221222 42\t9.37\t991\nSI physical touch\tL Area 2/L IPC\t\u221254 \u221226 39\t7.47\t123\nObserved touch\tObserved touch\tObserved touch\tObserved touch\tObserved touch\nObs. touch MF\u00a0+\u00a0obs. touch IF\u00a0+\u00a0obs. touch BF\u00a0\u2212\u00a0no-touch\tL Area 2\t\u221237 \u221244 54\t4.35\t245\nObs. touch MF\u00a0+\u00a0obs. touch IF\u00a0+\u00a0obs. touch BF\u00a0\u2212\u00a0no-touch\tL Area 2\t\u221255 \u221224 44\t4.04\t179\n# Obs. touch MF\u00a0\u2212\u00a0no-touch\tL Area 1\t\u221226 \u221254 66\t5.02\t6\n\tL Area 2\t\u221226 \u221251 57\t5.00\t17\n\tL Area 2\t\u221254 \u221227 45\t3.45\t19\n\tL Area 1\t\u221260 \u221218 36\t3.29\t9\nObs. touch IF\u00a0\u2212\u00a0no-touch\tL Area 2\t\u221258 \u221221 40\t6.05\t139\nObs. touch BF\u00a0\u2212\u00a0no-touch\tL Area 2\t\u221234 \u221244 57\t6.27\t127\n\tL Area 2\t\u221254 \u221224 44\t5.56\t128\nSI observed touch\tL Area 2\t\u221255 \u221226 46\t4.54\t8\n\tL Area 2\t\u221236 \u221236 44\t4.51\t5\nSI observed touch self\tL Area 2\t\u221240 \u221242 62\t4.36\t9\nObserved touch \u2229 Physical touch\tObserved touch \u2229 Physical touch\tObserved touch \u2229 Physical touch\tObserved touch \u2229 Physical touch\tObserved touch \u2229 Physical touch\nObs. touch MF\u00a0+\u00a0obs. touch IF\u00a0+\u00a0obs. touch BF\u00a0\u2212\u00a0no-touch \u2229 MF touch\u00a0+\u00a0IF touch\u00a0+\u00a0BF touch\u2013rest\tL Area 2\t\u221255 \u221224 44\t5.70\t162\n# Obs. touch MF\u2013no-touch \u2229 MF touch\u2013rest\tL Area 2\t\u221254 \u221227 45\t4.45\t15\n# Obs. touch MF\u2013no-touch \u2229 MF touch\u2013rest\tL Area 1\t\u221261 \u221216 33\t4.15\t10\nObs. touch IF\u2013no-touch \u2229 IF touch\u2013rest\tL Area 2\t\u221258 \u221221 40\t6.05\t123\nObs. touch BF\u2013no-touch \u2229 BF touch\u2013rest\tL Area 2\t\u221254 \u221224 44\t5.56\t114\n### Caption\nS1 activity changes during physical touch perception and touch observation in different experimental conditions\n### Footer\nListed clusters contain voxels thresholded at p\u00a0<\u00a00.001 and are cluster-corrected at p\u00a0<\u00a00.05 (FWE-corrected); the two contrasts which are marked with a # show clusters that are not cluster-corrected, but contain a minimum of five voxels using the same voxel threshold; see Online Resource 2 for a complete list of sub-threshold activity changes for all listed contrastsobs. observed, MF middle finger, IF index finger, BF both fingers, SI suppressive interactions, IPC inferior parietal cortex\n", "metadata": {"pmcid": 3889700, "text_md5": "976ca677b15ee6897c32ca86c125a2f4", "field_positions": {"authors": [0, 80], "journal": [81, 99], "publication_year": [101, 105], "title": [116, 198], "keywords": [212, 334], "abstract": [347, 2251], "body": [2260, 80965], "tables": [80978, 83260]}, "batch": 2, "pmid": 23283478, "doi": "10.1007/s00429-012-0489-z", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3889700", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3889700"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3889700\">3889700</a>", "list_title": "PMC3889700  The functional architecture of S1 during touch observation described with 7\u00a0T fMRI"}
{"text": "Brittain, Philip J. and Froudist Walsh, Sean and Nam, Kie-Woo and Giampietro, Vincent and Karolis, Vyacheslav and Murray, Robin M. and Bhattacharyya, Sagnik and Kalpakidou, Anastasia and Nosarti, Chiara\nNeuroimage Clin, 2014\n\n# Title\n\nNeural compensation in adulthood following very preterm birth demonstrated during a visual paired associates learning task\n\n# Keywords\n\nVery preterm birth\nLearning disability\nNeuroplasticity\nfMRI\nVisual paired associates\n\n\n# Abstract\n \nVery preterm birth (VPT; <\u00a033\u00a0weeks of gestation) is associated with an increased risk of learning disability, which contributes to more VPT-born children repeating grades and underachieving in school. Learning problems associated with VPT birth may be caused by pathophysiological alterations in neurodevelopment resulting from perinatal brain insult; however, adaptive neuroplastic processes may subsequently occur in the developing preterm brain which ameliorate, to an extent, the potential sequelae of altered neurophysiology. Here, we used functional magnetic resonance imaging (fMRI) to compare neuronal activation in 24 VPT individuals and 22 controls (CT) in young adulthood during a learning task consisting of the encoding and subsequent recognition of repeated visual paired associates. Structural MRI data were also collected and analysed in order to explore possible structure-function associations. Whilst the two groups did not differ in their learning ability, as demonstrated by their capacity to recognize previously-seen and previously\u2013unseen visual pairs, between-group differences in linear patterns of Blood Oxygenation Level Dependant (BOLD) activity were observed across the four repeated blocks of the task for both the encoding and recognition conditions, suggesting that the way learning takes place differs between the two groups. During encoding, significant between-group differences in patterns of BOLD activity were seen in clusters centred on the cerebellum, the anterior cingulate gyrus, the midbrain/substantia nigra, medial temporal (including parahippocampal) gyrus and inferior and superior frontal gyri. During the recognition condition, significant between-group differences in patterns of BOLD activity were seen in clusters centred on the claustrum and the posterior cerebellum. Structural analysis revealed smaller grey matter volume in right middle temporal gyrus in VPT individuals compared to controls, however volume in this region was not significantly associated with functional activation. These results demonstrate that although cognitive task performance between VPT individuals and controls may be comparable on certain measures, differences in BOLD signal may also be evident, some of which could represent compensatory neural processes following VPT-related brain insult. \n   Highlights  \n  \nWe investigated visual memory ability in young adults who were born very prematurely and a term-born control group \n  \nSimilar performance levels were observed between the groups on a task measuring visual memory capacity \n  \nfMRI analysis revealed that there are significantly different processes occurring between the groups concerning the adaptation of neural resources during learning and recall \n  \nStructural differences were also found, with very-prematurely born adults having smaller grey matter volume in a region relevant to visual processing \n  \nIn the preterm group, some of these different neural responses may represent the results of compensatory neuroplastic processes which aid in overcoming perinatal brain insult \n  \n \n\n# Body\n \n## Introduction \n  \nVery preterm birth (VPT; <\u00a033 completed weeks of gestation) is associated with an increased risk of cognitive disability in childhood and adolescence. Studies have found modest but statistically significant deficits in areas including perceptual\u2013motor skills ( ), language ability ( ;  ;  ), executive functions ( ;  ) verbal and visual memory ( ;  ;  ) and IQ ( ;  ). The cognitive deficits resulting from VPT birth are associated with later academic difficulties ( ;  ) and potentially have a role in the higher incidence of behavioural and psychiatric difficulties seen in these populations in childhood and adulthood ( ;  ). \n\nThe extensive structural brain alterations seen in VPT populations, from infancy through to young adulthood, likely represent an underlying cause of cognitive impairment ( ;  ;  ;  ). However, recent research on the functional sequelae of VPT birth has led to the hypothesis that adaptive neuroplastic processes may allow some VPT born individuals to attain levels of cognitive functioning which are less deficient than might otherwise have been expected given these pathophysiological occurrences ( ;  ;  ;  ;  ;  ). \n\nPostulated compensatory neural pathways can be observed when VPT born individuals and controls complete the same behavioural tasks, whilst their brain activity is measured using functional magnetic resonance imaging (fMRI). Studies investigating Blood Oxygen Level Dependent (BOLD) signal fluctuations during tasks involving language functions, for example, have identified altered patterns of neural interconnectivity between task-specific brain areas (i.e. frontal and temporal cortices) in individuals born VPT compared to controls. During a passive auditory language task, stronger connectivity was observed in VPT-born children between left Wernicke\u2019s area and the right inferior frontal gyrus (the homologue of Broca\u2019s area) and the supramarginal gyri bilaterally ( ); whereas during a semantic association task, VPT-born children demonstrated stronger connectivity between typical language processing and sensorimotor areas, whilst also showing weaker connectivity within areas of the prefrontal cortex ( ). \n\nOther studies have investigated brain structure and function simultaneously, to elucidate how damage to the former could effect the latter.   demonstrated functional differences between VPT born young adults and controls using a verbal paired associates learning task. During the task, pairs of word-stimuli were presented four times (encoding), intercalated with four blocks of cued-recall trials. Equivalent performance on the behavioural measures was seen, but between-group differences in patterns of BOLD activity were apparent in the right anterior cingulate-caudate body during encoding and in the thalamus and hippocampus/parahippocampal gyrus during recall. This study also reported reduced white matter integrity in the VPT group in tracts passing through the thalamic/hippocampal region that was differently activated during recall, suggesting that functional activation is partly accounted for by anatomical differences in regions displaying BOLD signal change. In another study, Gimenez and colleagues ( ), using a declarative \u2018face-name\u2019 memory task, demonstrated significantly greater right hippocampal activation in VPT adolescents than controls, which was associated with a significant decreased volume of the left hippocampus. The authors interpreted this as evidence of a compensatory mechanism in the VPT individuals. Interestingly, in this study, despite the proposed neural compensation, behavioural performance in the VPT group was still poorer than the control group, indicating that such plasticity may not always be fully effective. \n\nOf relevance to this study is a report by Narberhaus et al. ( ), which used the same visuo-perceptual learning task we investigated and described the mean BOLD signal response during four encoding and four recognition blocks of visual stimuli-pairs in VPT-born adults compared to controls. They reported that, despite no significant performance differences between the groups, during encoding VPT subjects showed increased activation compared to controls in the left caudate nucleus, right cuneus and left superior parietal lobule and a mean decreased signal in the right inferior frontal gyrus. During recognition, VPT individuals showed a mean increased BOLD signal response compared to controls in the right cerebellum and in the anterior cingulate gyrus bilaterally. The authors argued that these differential activation patterns represented neural compensation following perinatal brain injury subsequent to very preterm birth. However, as noted by the authors, an important methodological limitation with their analysis concerned the averaging of activations across the four repeated blocks of the task. This had the potential to mask more \u2018pure\u2019 memory effects with repetition effects and retrieval with encoding effects. \n\nTherefore, in this study, we extended the work of Narberhaus et al. ( ) by reanalysing their data to study the adaptation of neural resources during the learning and recall processes. We aimed to investigate whether the way learning of visual paired associates takes place differs between very preterm-born adults and control participants. In order to explore this we determined brain regions, in a sample of VPT young adults and separately in a control group, that demonstrated either increasing or decreasing linear activation patterns over the four repeated blocks of the encoding and recognition phases. We then looked for any patterns of functional adaptation that differed significantly between the groups. \n\nIn normative samples, paired associates learning tasks typically activate a fronto-parieto-occipital network ( ), as well as a hippocampal-diencephalic circuitry and medial temporal lobe structures ( ;  ;  ). \n\nSpecifically, decreased activation in thalamus and superior frontal gyrus has been associated with repeated stimuli presentations in humans ( ). A possible explanation could be that activation during the first learning blocks reflect a direct access to the associations learnt during encoding which exploit areas of the thalamus projecting to the prefrontal cortex ( ) and hippocampus ( ). With practice and successful retrieval of the paired associates, subsequent retrieval may become more automatic and thus may not require access to regions centrally involved in encoding. \n\nWe hypothesized that VPT born young adults would display altered linear patterns of BOLD signal response compared to controls during the processes of encoding and recognition in components of the fronto-parieto-occipital, hippocampal-thalamic and temporal lobe networks, which include areas found to be particularly impacted in VPT cohorts, both at a functional ( ;  ;  ;  ) and a structural level ( ;  ;  ;  ). We further conducted exploratory analyses to investigate whether structural alterations (using a whole-brain analysis approach) in the VPT group would be significantly associated with functional activation ( ;  ). \n\n\n## Materials and methods \n  \n### Participants \n  \nIn 1983\u201384, 147 infants born at less than 33\u00a0weeks gestation and admitted consecutively to the Neonatal Unit at University College London Hospital (UCLH) within 5\u00a0days of birth, survived, were discharged, and were enrolled for long-term follow up. Of this cohort, 78 individuals were born at 28 or less weeks of gestation and 69 were born between 29 and 33\u00a0weeks of gestation. At age 15\u00a0years, 113 (76.9%) of these individuals received a cognitive, behavioural and neurological assessment and 90 (61.2%) had an MRI. At age 20, 94 (83.2%) of the individuals assessed in adolescence agreed to participate in follow-up ( ). For the current fMRI study, 24 young adults of both sexes who were born VPT with no history of cerebral palsy, grade 3/4 intraventricular haemorrhage or periventricular leukomalacia as assessed by neonatal cranial ultrasound, were randomly selected from the cohort described above. These are the same subjects who participated in the study by  , with the addition of three VPT individuals who were previously not analysed due to image corruption issues which were successfully fixed prior to this analysis).Twenty-two controls (CT) were recruited from advertisements in the local press and university and were selected according to age, handedness and gender. Inclusion criteria were full-term birth (37\u201342 completed weeks of gestation); exclusion criteria were birth complications (e.g. low birth weight defined as <\u00a02500\u00a0g, endotracheal mechanical ventilation), prolonged gestation (greater than 42\u00a0weeks), history of psychiatric illness, severe hearing deficits and motor impairment. All participants were English native speakers and right handed. The experiments were undertaken with the understanding and written consent of each subject, with the approval of the appropriate local ethics committee, and in compliance with national legislation and the Code of Ethical Principles for Medical Research Involving Human Subjects of the World Medical Association (Declaration of Helsinki). \n\n\n### Functional MRI task: Visual paired associates \n  \nThe task used here is identical to that used by   and contained the following conditions: encoding, recognition, same/different discrimination and low-level baseline, presented in that order (see  ). During the encoding condition, participants were presented with pairs of coloured abstract pictures on black squares and were required to indicate via a button response (\u2018Yes\u2019/\u2018No\u2019) if the two pictures were associated. Subjects were posed this question in order that they might think about ways in which the two images were linked, which would require close comparison and thus support encoding of the pairs. The same visual pairs were presented in the encoding condition four times but within each block the order of the picture pairs was randomized. In the recognition condition, one picture from each of the pairs presented during encoding was presented either paired with the same (50% of trials) or with a novel picture (50% of trials). Participants were required to indicate if they had seen those pairs of pictures before (\u2018Yes\u2019/\u2018No\u2019). Participants were instructed not to press any button if they did not know what to answer. To reduce the possible confounding effects of differential task performance between the groups on blood oxygen level\u2013dependent signal, in each recognition block of 8 responses each, only activation related to correct responses was modelled. \n\nIn the same/different baseline condition, participants viewed pairs of novel pictures which were clearly identical or dissimilar and were required to indicate whether the pictures were the same (\u2018Yes\u2019/\u2018No\u2019). There was also a low-level baseline condition during which participants were shown two black rectangles, with no pictures inside, of the same dimension as those containing pictures in the preceding conditions and were instructed to press one of the buttons at random. This condition was subtracted from all subsequent analyses. \n\nParticipants were familiarized with the task during an offline training session with two repetitions of the four conditions, each containing 4 stimulus pairs using different pictures to those subsequently presented during the experimental \u201con-line\u201d session. All stimuli were shown in central vision. Responses during each condition were recorded online. There was no rest (fixation) period between the blocks, but an \u2018instruction\u2019 question preceded each encoding (\u201cAre these pictures associated?\u201d), recognition (\u201cHave you seen this pair of pictures before?\u201d), same/different baseline (\u201cDo these pictures look the same?\u201d) and low-level baseline block (\u201cLook at the squares\u201d). Each condition was presented in blocks lasting 40\u00a0s, with 8 presentations of stimulus pairs per block. There were 4 repetitions of each block in the same order (encoding, recognition, same/different baseline, low-level baseline). \n\n\n### MRI data acquisition \n  \nImage acquisition was performed using a 1.5\u00a0T GE Sigma Neurovascular MR system (GE Medical Systems, Milwaukee, WI, USA). A quadrature head coil was used for RF transmission and reception. An inversion recovery EPI data set with 3\u00a0mm thick near-axial slices (inter-slice gap .3\u00a0mm) and an in-plane resolution of 1.5\u00a0mm (TR 3000\u00a0ms, TE 40\u00a0ms, flip angle 90\u00b0) was acquired to facilitate mapping of the functional data into Talairach space. One hundred and forty eight T2*-weighted images were acquired at each of 16 near-axial 7\u00a0mm thick planes (inter-slice gap .7\u00a0mm) parallel to the intercommissural (AC\u2013PC) plane so as to include the whole brain (FOV 24\u00a0\u00d7\u00a024\u00a0cm and matrix 64 ), the first four (dummy) volumes being discarded to allow for T1 equilibration effects. The interstimulus interval (ISI) was 5\u00a0s. This length was chosen to allow for the longer reaction time latencies of very preterm-born individuals and to provide them with a slightly longer than usual interval of rest between trials ( ). The period between the acquisition of clustered image volumes was set at 3.5\u00a0s and the image volume acquisition at 1.5\u00a0s (TE 40\u00a0ms, \ufb02ip angle 90\u00b0). Three-dimensional T -weighted gradient-echo sequences were also collected in order to allow reconstruction in any plane of 124 1.5\u00a0mm slices (TR 35\u00a0ms, TE 5\u00a0ms, flip angle 35\u00b0) to enable the measurement of structural MRI data. \n\n\n### Functional MRI analysis \n  \n#### Individual and group mapping \n  \nThe analysis was hypothesis-driven, and modelled patterns of increase or decrease of activation across the four blocks during encoding, and separately, during recognition. The fMRI data were analysed with the XBAM software (version 4) developed at the Institute of Psychiatry ( ) using a non-parametric permutation-based strategy to minimize assumptions. The non-parametric approach is important to achieve rigorous statistical inference given the difficulty of establishing normality in fMRI data ( ;  ). The images were first corrected for subject motion ( ) and then smoothed using a Gaussian filter (FWHM 8.8\u00a0mm) chosen to improve signal-to-noise ratio over the spatial neighbourhood of each voxel. \n\nResponses to the experimental paradigm were then detected by fitting a linear model in which each component of the design was convolved separately with two gamma variety functions (peak responses at 4 and 8\u00a0s) to allow for variability in the haemodynamic delay. A goodness of fit statistic was computed, consisting of the ratio of the sum of squares of deviations from the mean image intensity due to the model (over the whole time series) to the sum of squares of deviations due to the residuals (SSQ). This addresses the problem inherent in the use of the F statistic that the residual degrees of freedom are often unknown in fMRI time series due to the presence of coloured noise in the signal. The data were permuted by the wavelet-based method described and extensively characterized in Bullmore et al. ( ), which permits the data-driven calculation of the null distribution of SSQ under the assumption of no experimentally-determined response. This distribution can then be used to threshold the activation maps at any desired type I error rate. In addition to the SSQ, the percentage BOLD change was also calculated from the model fit at each voxel. In order to increase sensitivity and reduce the multiple comparison problem, the analysis was extended from voxel to cluster level using a method described in detail in   which has been shown to give excellent cluster-wise type I error control. The observed and randomized SSQ data for each individual were normalized into the standard space ( ) and group maps of activated regions were computed using the group median as described in Brammer et al. ( ). Permutation strategies and median statistics were employed to allow exact computation of   p  -values with minimal assumptions and the minimization of outlier effects. The final cluster maps were thresholded in such a way as to obtain <\u00a00.9 false positive 3D clusters per map. \n\n\n#### Group differences \n  \nThe between-group analysis aimed to find significant interactions between group and linear trend of activation. Comparisons of responses between groups were performed by fitting the data at each intracerebral voxel at which all subjects have non-zero data by linear modelling of the contrast of interest. The model is fitted by minimizing the sum of absolute deviations rather than the sums of squares to reduce outlier effects. The null distribution is computed by permuting data between groups (assuming the null hypothesis of no effect of group membership) and refitting the model at each voxel. Group difference maps at any desired voxel or cluster-wise type I error rate can then be computed by appropriate thresholding of this null distribution. The statistical thresholds were adjusted in such a way as to obtain <\u00a00.9 false positive activated 3D clusters per map. \n\n\n\n### Structural MRI data processing and analysis \n  \nStructural MRI data sets were analysed using voxel-based morphometry (VBM) in Statistical Parametric Mapping SPM8 (Wellcome Department of Cognitive Neurology, Institute of Neurology, London, UK,  /), running on Matlab 7.8 (Math-Works, Natick, USA). The T1-weighted images were affined-registered to an SPM T1 template and segmented into grey and white matter. Then, the affined-registered grey matter images were normalized to a Montreal Neurological Institute (MNI) coordinate space using the unified DARTEL algorithm ( ) with modulation for non-linear components, which compares the absolute amount of tissue corrected for individual brain sizes. All grey matter images were smoothed with a 12\u00a0mm Gaussian kernel and used for statistical analyses. A whole brain statistical comparison evaluating regional grey matter differences between very preterm born individuals and controls was performed at the statistical threshold of   p  \u00a0<\u00a0.05, after family-wise-error (FWE) correction. Grey matter eigenvalues for each study participant were calculated for any clusters where significant between-group differences were noted; SPM\u2019s \u2018volume of interest\u2019 (VOI) data extraction tool was employed. The coordinates locating clusters which significantly differed between the two groups were originally reported in MNI space. The ones we are reporting here were converted to Talairach space using the Non-linear Yale MNI to Talairach Conversion Algorithm ( ) ( ). \n\n#### Structure-function associations \n  \nIn order to explore structure-function associations, we looked for significant correlations (Bonferroni corrected,   p  \u00a0<\u00a00.005) between the structural eigenvalues extracted from areas that significantly differed between the groups and functional SSQ ratios extracted from the regions demonstrating significant linear BOLD response interaction effects. To characterize the change seen across the four blocks of each encoding and recognition interaction, we created a measure of \u2018mean slope change\u2019 for the VPT and CT groups separately using the following formula: \n\n\n\n\n\n### Analysis of Neonatal, socio-demographic and behavioural data \n  \nThese data were explored with independent samples   t  -tests or their appropriate non-parametric equivalent. Online task performance was assessed with a mixed-design ANOVA. \n\n\n\n## Results \n  \n### Neonatal, socio-demographic and behavioural data \n  \n displays neonatal, socio-demographic, and behavioural data for study participants. The VPT group and controls did not differ statistically in terms of gender distribution (\u03c7 \u00a0=\u00a02.1 ,   p  \u00a0>\u00a00.05), age at assessment (  U  \u00a0=\u00a0238.00, N \u00a0=\u00a022, N \u00a0=\u00a024,   p  \u00a0>\u00a00.05, two-tailed), nor in ratings of parental social economic class (\u03c7 (42)\u00a0=\u00a05.57,   p  \u00a0>\u00a00.05). No significant between-group differences were observed in full-scale IQ (  U  \u00a0=\u00a0137.00, N \u00a0=\u00a011, N \u00a0=\u00a024,   p  \u00a0>\u00a00.05, two-tailed), verbal IQ (  U  \u00a0=\u00a0134.00, N \u00a0=\u00a011, N \u00a0=\u00a024,   p  \u00a0>\u00a00.05, two-tailed) or performance IQ (  U  \u00a0=\u00a0146.00, N \u00a0=\u00a011, N \u00a0=\u00a024,   p  \u00a0>\u00a00.05, two-tailed) as assessed by the Wechsler Abbreviated Scale of Intelligence (WASI) ( ). \n\nIn terms of correct response rates for the online behavioural task, a mixed-design ANOVA demonstrated no main effect of group (  F  (44)\u00a0=\u00a00.10,   p  \u00a0>\u00a00.05) but a significant main effect of block (  F  (44)\u00a0=\u00a04.76,   p  \u00a0=\u00a00.003) with no significant group\u00a0\u00d7\u00a0block interaction (  F  (44)\u00a0=\u00a00.74,   p  \u00a0>\u00a00.05). Post-hoc analyses revealed that the mean correct response rates to block 2 (5.76, S.D.\u00a0=\u00a01.57) were higher than to block 1 (4.93, S.D.\u00a0=\u00a01.40;   t  \u00a0=\u00a03.37, df =\u00a045,   p  \u00a0=\u00a00.002) and to block 4 (5.72, S.D.\u00a0=\u00a01.75) higher than to block 1 (  t  \u00a0=\u00a03.40, df =\u00a045,   p  \u00a0=\u00a00.001). These results demonstrate a learning effect, equal across groups, from having the stimulus pairs repeated 4 times. \n\n\n### Functional MRI results \n  \n#### Within group fMRI results \n  \nFor the controls, during encoding, a linear increase in neural activation over the four blocks was seen in a cluster with peak activation in the right brainstem with decreasing activation seen in the left posterior cerebellum and right middle temporal gyrus. During recognition, increasing activation was seen in the left precuneus and left anterior cerebellum with decreasing activation in the left fusiform gyrus (see  ). \n\nFor the VPT-born individuals, during encoding, a linear increase in neural activation over the four blocks was seen in a cluster with peak activation in the left anterior cerebellum with decreasing activation seen in the right thalamus. During recognition, increasing activation was seen in the left anterior cerebellum with decreasing activation in the right posterior cerebellum, left superior frontal gyrus, left precuneus, left posterior cingulate and right anterior cingulate (see  ). \n\n\n#### Between group fMRI results \n  \nA statistically significant interaction between group and patterns of change of activation during encoding was found in eight regions. In four of these, the control participants showed an overall increasing pattern of activation in comparison to the VPT participants who showed a decreasing pattern. These clusters had a peak voxel of local maxima in the left midbrain/substantia nigra, the right parahippocampal gyrus, the left inferior frontal gyrus and the right anterior cingulate. A reverse pattern of activation was seen in the remaining four areas, with the VPT participants showing an overall increasing pattern of activation in comparison to a decreasing pattern in the control group. These clusters had a peak voxel of local maxima in the left posterior cerebellum, the right anterior cerebellum, the right middle temporal gyrus and the right superior frontal gyrus (see   and  ). \n\nA statistically significant interaction between group and patterns of change of activation during recognition was found in just two regions. In one of these, that had a peak voxel of local maxima in the right claustrum, the CT participants showed an overall increasing pattern of activation in comparison to the VPT participants who showed an overall decreasing pattern. A reverse pattern of activation was seen in a cluster with a peak voxel of local maxima in the left posterior cerebellum, with the VPT participants showing an overall increasing pattern of activation in comparison to the CT participants who showed a decreasing pattern (see   and  ). \n\n\n\n### Structural analysis results \n  \nStructural analysis revealed smaller grey matter volume in the right middle temporal gyrus (rMTG) in the VPT group compared to CT participants (  x  \u00a0=\u00a045,   y  \u00a0=\u00a0\u221217,   z  \u00a0=\u00a0\u201330;   p  \u00a0<\u00a00.001). \n\n#### Structure-function associations \n  \nWhen eigenvalues extracted from the significant cluster centred in right middle temporal gyrus were correlated with SSQs extracted from the 10 regions where significant linear interactions were found (encoding and recognition), no significant associations were found, after Bonferroni corrections, for the VPT nor CT groups. \n\n\n\n\n## Discussion \n  \nVery preterm birth has been associated with long-lasting cognitive deficits, which can have profound effects on academic and career achievement, and are likely to be mediated by structural and functional brain alterations following perinatal brain injury. A recent hypothesis predicts that adaptive neuroplasticity in the developing brain may ameliorate the severity of these deficits in some cases via the utilization of compensatory neural pathways ( ;  ;  ;  ;  ;  ). One study, by  , using an fMRI based visual paired associates task, concluded that the differential patterns of neural activation seen in the VPT group, including decreased BOLD response in inferior frontal gyrus accompanied by increased response in caudate nucleus, cuneus and superior parietal lobule, likely represented compensatory neural processes for the adult consequences of perinatal brain injury. However, a methodological limitation of that study concerned the averaging of activations across the four repeated blocks of the experiment, which masked the underlying neurobiology taking place during learning and recall. By expanding the cohort and reanalysing the data via a linear analysis of the BOLD response over the four repeated blocks of the encoding and recognition phases, we could, for the first time, investigate patterns of functional adaptation in relation to visual learning strategies in VPT-born individuals and controls in young adulthood. The results we found with this improved methodology were substantially different from those of  ; our analysis highlighted a number of memory and other domain-general cognitive and attentional regions differentially activated between the CT and VPT groups that were not shown in that study. This suggests that a linear analysis approach is more sensitive for detecting functional alterations during a repeated-block learning paradigm than is the method of using mean activation. \n\nThe VPT and control groups demonstrated a similar improvement in mean accuracy scores across the four recognition blocks of the online behavioural task. This demonstrated that a learning effect took place. The fMRI results demonstrated that it is the way in which this learning effect takes place that is different between the groups. The first piece of evidence for this is seen in the results from the within group analyses ( ). This revealed that both groups demonstrated patterns of BOLD signal change across the four blocks of the task in domain-general cognitive and attentional regions typically activated during tasks involving learning ( ;  ). However, both groups also showed activation in areas previously demonstrated to be specifically involved in memory processing and, crucially, these were largely different between the groups. For example, during encoding, controls demonstrated increasing activation in the right middle frontal gyrus, which has been associated with visual working memory ( ;  ) whereas the VPT group had increasing activation in the left parahippocampal gyrus, which has been associated specifically with non-verbal memory processing ( ). It is this differential activation in memory-related regions, seen here and explored further in the between-subjects analysis, which is suggestive of neuroplastic adaptation in the VPT group. \n\nFor the between-subjects analysis, we were specifically interested in the interaction between group and block. That is to say, we wanted to investigate whether there were any brain regions that would show significantly different patterns of linear BOLD signal change between groups across the four encoding and, separately, across the four recognition blocks. Eight regions ( ) demonstrated such an interaction during the encoding blocks; in four of these there was a pattern of overall progressively increasing activation in the CT participants and decreasing activation in the VPT participants and, in four, the reverse pattern occurred. There were two regions that demonstrated a significant interaction during the recognition blocks; in one of these, activation increased in the CT group and decreased in the VPT group, whilst in the other, the reverse pattern occurred. From these 10 regions, several stand out in relation to our hypothesis of neural adaptation during visual learning in the VPT brain. During the encoding phase, the VPT group had decreasing activation compared to the CT group\u2019s increasing activation in a cluster centred on the right parahippocampal gyrus extending to the hippocampus, key memory-related areas ( ), as well as in the thalamus which has reciprocal connections to the hippocampus and is central to episodic memory processing ( ) and which together represent components of a fronto-subcortical network involved in associative learning ( ). However, the VPT group showed increasing activation compared to the CT group\u2019s decreasing activation in the right superior frontal gyrus, a region known to be involved in various memory functions including episodic and working memory ( ;  ;  ) which typically decreases in activation with repeated stimuli presentations ( ). \n\nIn terms of the structural findings, in a whole brain analysis we found the VPT group to have reduced volume, compared to controls, in a cluster that included most of the right middle temporal gyrus. This result is consistent with the findings of a structural study from our group in a larger sample of VPT participants in mid-adolescence, which included the current study subjects ( ), and reported decreased volume in middle temporal gyri bilaterally. However, despite findings in previous studies which observed significant associations between regional volume alterations and BOLD signal change in similar samples of VPT born individuals completing paired associate learning tasks ( ;  ), in the current investigation, after correcting for multiple comparisons, no significant associations between the volume of the right middle temporal gyrus and fMRI results were observed. This lack of association is difficult to account for. However, it may be that despite our best efforts to create a metric which represented the change in BOLD response across the four time points (see  .), inter-subject variation, in relation to precisely when a structural reduction effects BOLD response, could render correlation between a static time-point (i.e. the eigenvalues representing rMTG volume) and a time-series, ineffective. \n\nIn relation to our principal hypothesis of neural adaptation during visual learning in the VPT brain, we therefore propose that the increased BOLD response of the VPT subjects, in comparison to the controls, in the right superior frontal gyrus, represents compensatory neural adaptation in response to reduced activity in the right parahippocampal gyrus, hippocampus and thalamus. Furthermore, that the increasing BOLD response in the VPT group, compared to controls, in the right middle temporal gyrus, an area which has been associated with visual semantic processing ( ), may represent an attempt at compensatory activity in this structurally altered area. \n\nIt is likely that much of the differential activation we observed was not related to compensatory neural processes but reflects altered neural responses which, were the subjects to undertake a more challenging task, could potentially result in behavioural differences. Closer inspection of our results supports this. Firstly, the between-subjects analysis revealed three clusters (two during encoding and one during recall) where activation in the cerebellum increased for the VPT subjects but decreased for the controls. Emerging evidence places the cerebellum within a network of regions demonstrating reduced activity with practice during task domain-general activity ( ), possibly due to neuronal adaptation to the repeated stimuli ( ;  ). The patterns of decreasing cerebellar activation observed in our control group support this theory, whereas the progressively increasing activation in our VPT group suggests that they may have experienced greater difficulty in completing the task. \n\nA second example of altered neural response in the VPT group can be seen in the activation of cingulate cortex ( ; encoding region 4, recognition region 1). The anterior cingulate receives input from midbrain dopaminergic neurons ( ) which are crucial for motivational salience ( ). Although Narberhaus et al. ( ) showed that in terms of mean activation across the blocks, VPT individuals activate the anterior cingulate and surrounding areas more than controls, our linear analysis revealed that, over time, the control participants increase their activation in this area, whilst in VPT participants it decreases. This possibly reflects a reduction in motivation as the task progresses. A reduction in task interest, albeit at a neural and not behavioural level, would also explain the decreasing activation of the substantia nigra in the VPT participants, as this region is also important in maintaining stimulus engagement ( ). As stressed previously however, if the examples cited above (cerebellum, anterior cingulate, substantia nigra) do reflect altered, or perhaps \u2018sub-optimal\u2019 neural responses in the VPT group, these would likely only become relevant in a task with higher cognitive demands. \n\nThere are two other points from our analysis which merit further consideration. Firstly, most of the between-group differences occurred during the encoding and not the recognition phases of the task. This could suggest that the learning of visual-paired associations represents a more neuroanatomically vulnerable process to VPT-related brain insult than recognition. Secondly, if these results do indeed reflect compensatory neurodevelopment, this has occurred even in the absence of serious perinatal brain injury, for which this cohort of VPT individuals screened negative. \n\nThere are several limitations to the current study. Firstly, we used a relatively small cohort, which restricts the generalizability of our conclusions. Secondly, the lack of more comprehensive offline visuo-spatial memory assessments in this sample leaves us with the probability that more challenging tasks would highlight behavioural deficits in the preterm cohort which would alter the interpretation of the putative adaptive differences from being fully- to only partially-effective. Thirdly, whilst other research has reported differing patterns of neuronal activation between VPT groups and full-term controls whilst performing paired-associates learning tasks, and used the results to support the hypothesis of compensatory neural adaptation ( ;  ;  ;  ), it is difficult to draw meaningful comparisons between our findings and those of the other studies, due to the differing nature of the behavioural tasks and analysis methods used. Specifically, our study is the first to use a linear analysis approach to investigate functional differences occurring during a visual paired associate task. \n\n\n## Conclusions \n  \nIn conclusion, the above results demonstrate that equivalent behavioural performance between VPT subjects and full-term controls can be underlined by significantly different neural processes. An emerging theory in preterm research is that brain insult in the perinatal period can lead to compensatory neurodevelopmental processes resulting in cognitive functioning being less deficient than might otherwise have been expected ( ;  ;  ;  ;  ;  ). Whilst the results from this analysis support that theory, other altered neural processes are still evident which could have consequences where behavioural performance requirements are more demanding. \n\n \n\n# Table(s)\n## ID: t0005\n### Label: Table\u00a01\nUnnamed: 0\tPreterm (n\u00a0=\u00a024)\tControls (n\u00a0=\u00a022)\nGestational age in weeks (mean, SD)\t28.58 (2.08)\t\u2212\nBirth weight in grams (mean, SD)\t1286.88 (391)\t\u2212\nGender (female/male)\t9/15\t13/9\nAge in years at assessment (mean, SD)\t20.09 (0.58)\t20.1 (1.68)\nSocio-economic status??? (percent)\t\t\nI\u2212II\t37.5%\t31.8%\nIII\t54.2%\t31.8%\nIV\u2212V\t8.3%\t36.4%\nWASI full-scale IQ (mean, SD)\t100.50 (11.80)\t103.09 (14.75)\nWASI verbal IQ (mean, SD)\t96.79 (12.09)\t99.45 (13.65)\nWASI performance IQ (mean, SD)\t103.92 (12.04)\t106.36 (15.86)\nCorrect responses [max. 8] (Mean, SD)\t\t\nBlock 1\t4.92 (1.25)\t4.95 (1.59)\nBlock 2\t5.75 (1.39)\t5.77 (1.77)\nBlock 3\t5.67 (1.86)\t5.09 (1.80)\nBlock 4\t5.71 (1.78)\t5.73 (1.75)\n### Caption\nNeonatal, socio-demographic and behavioural data.\n### Footer\naSocio economic status was measured by Her Majesty\u2019s Stationary Office Standard Occupational Classification criteria [Her Majesty\u2019s Stationery Office (HMSO), 1991]. The following SES bands were used: I\u2212II = Managerial and Professional; III\u00a0=\u00a0Intermediate (e.g. small employers and own account workers); IV\u2212V\u00a0=\u00a0Working (e.g. lower supervisory and technical occupations, semi-routine & routine occupations).\n\n\n## ID: t0010\n### Label: Table\u00a02\nCondition/direction\tCerebral region(Brodmann\u2019s area)\tTalairach coordinates\tTalairach coordinates\tTalairach coordinates\tCluster size\tCluster p value\nCondition/direction\tCerebral region(Brodmann\u2019s area)\tX\tY\tZ\tCluster size\tCluster p value\nEncoding/increase\tRight brainstemExtends to precentral gyrus, middle frontal gyrus, superior temporal gyrus, posterior cerebellum, inferior frontal gyrus, anterior cerebellum, middle temporal gyrus, left brain stem\t7\t\u221226\t\u221240\t783\t0.0002\nEncoding/decrease\tLeft posterior cerebellumExtends to precuneus, cuneus, middle temporal gyrus, inferior temporal gyrus\t\u221225\t\u221267\t\u221218\t1096\t0.0002\n\tRight middle temporal gyrus (20)Extends to inferior parietal lobule, postcentral gyrus, temporal lobe, superior temporal gyrus\t47\t\u221233\t\u22127\t118\t0.0065\nRecognition/increase\tLeft precuneus (31)Extends to paracentral lobule, parietal lobe, precuneus, frontal lobe, cingulate gyrus, inferior parietal lobule\t\u221214\t\u221244\t42\t155\t0.0015\n\tLeft anterior cerebellumExtends to brainstem, temporal lobe, limbic lobe, posterior cerebellum, parahippocampal gyrus, temporal lobe, right brainstem\t\u221225\t\u221230\t\u221224\t98\t0.0051\nRecognition/decrease\tLeft fusiform gyrus (37)Extends to superior parietal lobule, posterior cerebellum, middle temporal gyrus, superior temporal gyrus, cuneus\t\u221254\t\u221256\t\u221218\t787\t0.0002\n### Caption\nGroup activations for controls during encoding and recognition of visual paired associates. The coordinates of the cluster maxima (the most activated voxel within the cluster) are detailed.\n### Footer\nNone\n\n\n## ID: t0015\n### Label: Table\u00a03\nCondition/direction\tCerebral region(Brodmann\u2019s area)\tTalairach coordinates\tTalairach coordinates\tTalairach coordinates\tCluster size\tCluster p value\nCondition/direction\tCerebral region(Brodmann\u2019s area)\tX\tY\tZ\tCluster size\tCluster p value\nEncoding/increase\tLeft anterior cerebellumExtends to fusiform gyrus, parahippocampal gyrus, brainstem, posterior cerebellum\t\u221214\t\u221237\t\u221224\t88\t0.0059\nEncoding/decrease\tRight thalamusExtends to inferior parietal lobe, frontal lobe, posterior cingulate gyrus, temporal lobe, brainstem, postcentral gyrus\t25\t\u221226\t15\t188\t0.0031\nRecognition/increase\tLeft anterior cerebellumExtends to brainstem, temporal lobe, limbic lobe, posterior cerebellum, parahippocampal gyrus, temporal lobe, right brainstem\t\u221218\t\u221241\t\u221229\t66\t0.0053\nRecognition/decrease\tRight posterior cerebellumExtends to lingual gyrus, fusiform gyrus, left cuneus, left posterior cerebellum\t36\t\u221263\t\u221240\t185\t0.0021\n\tLeft superior frontal gyrus (9)Extends to middle/medial frontal gyri, anterior cingulate gyrus\t\u221211\t52\t20\t156\t0.0021\n\tLeft precuneus (7)Extends to superior parietal lobule, cuneus\t0\t\u221274\t42\t137\t0.0037\n\tLeft posterior cingulate (30)Extends to cingulate gyrus, thalamus, posterior cingulate, temporal lobe, right posterior cingulate\t\u221218\t\u221248\t9\t106\t0.0045\n\tRight anterior cingulate (32)Extends to cingulate gyrus, frontal lobe, superior frontal gyrus, middle frontal gyrus\t18\t26\t20\t87\t0.0047\n### Caption\nGroup activations for VPT individuals during encoding and recognition of visual paired associates. The coordinates of the cluster maxima (the most activated voxel within the cluster) are detailed.\n### Footer\nNone\n\n\n## ID: t0020\n### Label: Table\u00a04\nCondition\tCerebral region(Brodmann\u2019s area)\tTalairach coordinates\tTalairach coordinates\tTalairach coordinates\tCluster size\tCluster p value\tSignal direction\nCondition\tCerebral region(Brodmann\u2019s area)\tX\tY\tZ\tCluster size\tCluster p value\tSignal direction\nEncoding\t1. Left posterior cerebellumExtends to inferior temporal gyrus, middle occipital gyrus, fusiform gyrus, lingual gyri bilaterally, parahippocampal gyrus, right anterior cerebellum, right inferior occipital gyrus\t\u221225\t\u221263\t\u221218\t285\t0.0001\tVPTs increasing/controls decreasing\n\t2. Right superior frontal gyrus (9)Extends to anterior cingulate gyri bilaterally, medial frontal gyri bilaterally\t4\t48\t31\t99\t0.0015\tVPTs increasing/Controls decreasing\n\t3. Left substantia nigraExtends to thalamus, brainstem bilaterally, insula, parahippocampal gyrus, superior temporal gyrus\t\u22127\t\u221222\t\u221213\t94\t0.0012\tControls increasing/VPTs decreasing\n\t4. Right anterior cingulate (32)Extends to insula, frontal lobe\t18\t26\t20\t64\t0.0022\tControls increasing/VPTs decreasing\n\t5. Right anterior cerebellumExtends to cuneus, lingual gyrus, parahippocampal gyri bilaterally, left anterior cerebellum, left posterior cingulate, left cuneus, left lingual gyrus\t7\t\u221259\t\u22122\t52\t0.0037\tVPTs increasing/Controls decreasing\n\t6. Right parahippocampal gyrus (36)Extends to anterior cerebellum, lentiform nucleus, fusiform gyrus, hippocampus\t32\t\u221226\t\u221224\t50\t0.0058\tControls increasing/VPTs decreasing\n\t7. Right middle temporal gyrus (21)Extends to superior / middle temporal gyri,\t61\t\u221226\t\u221213\t43\t0.0037\tVPTs increasing/Controls decreasing\n\t8. Left inferior frontal gyrus (9)Extends to precentral/postcentral gyri, middle frontal gyrus\t\u221251\t4\t26\t39\t0.0061\tControls increasing/VPTs decreasing\nRecognition\t1Right claustrumExtends to insula, transverse temporal gyrus, inferior/medial frontalgyrus, inferior parietal lobule, cingulate gyrus\t32\t0\t9\t142\t0.0003\tControls increasing/VPTs decreasing\n\t2Left posterior cerebellumExtends to middle / superior temporal gyri, fusiform gyrus, middleoccipital gyrus, lingual gyrus\t\u221225\t\u221259\t\u221218\t125\t0.0005\tVPTs increasing/Controls decreasing\n### Caption\nDifferences in brain activation (as indexed by the median SSQ ratio (sum of squares ratio)) between VPT participants and controls during encoding and recognition of visual paired associates.\n### Footer\nNone\n", "metadata": {"pmcid": 4215530, "text_md5": "493c0ce96465d89d6453020c9572ca56", "field_positions": {"authors": [0, 202], "journal": [203, 218], "publication_year": [220, 224], "title": [235, 357], "keywords": [371, 456], "abstract": [469, 3557], "body": [3566, 39293], "tables": [39306, 46008]}, "batch": 2, "pmid": 25379416, "doi": "10.1016/j.nicl.2014.08.009", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4215530", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4215530"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4215530\">4215530</a>", "list_title": "PMC4215530  Neural compensation in adulthood following very preterm birth demonstrated during a visual paired associates learning task"}
{"text": "Chen, Yin-Hua and Chen, Ying-Chun and Kuo, Wen-Jui and Kan, Kamhon and Yang, C. C. and Yen, Nai-Shing\nSci Rep, 2017\n\n# Title\n\nStrategic Motives Drive Proposers to Offer Fairly in Ultimatum Games: An fMRI Study\n\n# Keywords\n\n\n\n# Abstract\n \nThe hypothesis of strategic motives postulates that offering fairly in the Ultimatum Game (UG) is to avoid rejection and receive money. In this fMRI study, we used a modified UG to elucidate how proposers reached decisions of offering fairly and to what extent they considered offering selfishly with different stakes. We had proposers choose between a fair and a selfish offer with different degrees of selfishness and stake sizes. Proposers were less likely and spent more time choosing the fair offer over a slightly-selfish offer than a very selfish offer independent of stakes. Such choices evoked greater activation in the dorsal anterior cingulate cortices that typically involve in allocation of cognitive control for cost/benefit decision making. Choosing a fair offer in higher stakes evoked greater activation in the anterior cingulate gyrus (ACCg) and the areas that previously have been implicated in reward and theory of mind. Furthermore, choosing a slightly selfish offer over a fair offer evoked greater activation in the anterior cingulate sulcus, ACCg, ventral tegmental area (or substantia nigra) and anterior insular cortex signalling the higher gain and implying higher rejection risk. In conclusion, our findings favoured the hypothesis that proposers offer fairly based on the strategic motives. \n \n\n# Body\n \n## Introduction \n  \nConsider a bargaining environment in which there is a proposer, a recipient and a certain amount of money (i.e. stakes) to be divided between two players. The proposer proposes how to share the sum and the recipient can either accept or reject the proposal. If the recipient accepts the proposal, the money is divided as proposed, whereas both players receive nothing in the case of rejection. This game is known as the ultimatum game (UG) . Although simple, it is important because it has many real-world analogies (such as wage bargaining between a union and the CEO) and helps crystallize more complex bargaining situations. \n\nAccording to the standard economic theory of self-interest, the recipient accepts any offer greater than zero, and the proposer offers the lowest amount possible . However, experimental studies have provided robust evidence that recipients and proposers take actions that are inconsistent with the theoretical prediction. The majority of proposers share equally and offer approximately 40% of the stakes on average, whereas recipients routinely reject offers \u226420% of the stakes . Two hypotheses have been proposed to explain why proposers distribute money in a relatively fair manner . \n\nThe first hypothesis suggests that proposers care about the welfare of others and behave generously out of altruistic motives . Previous studies examined this hypothesis by comparing the proposing behaviours between the UG and the dictator game (DG) , in which the recipient can merely accept the proposal . This hypothesis predicts that proposers would also offer fairly in the DG. However, proposers were found to offer less in the DG (i.e. approximately 23% of the stakes) than that in the UG. \n\nOnly two recent studies have examined the neural correlates of the proposing behaviours between the UG and the DG using functional magnetic resonance imaging (fMRI) . Neither study used the original UG task, in which proposers can freely indicate their offer. Instead, they asked participants to choose one preferred offer among several (i.e. 6:6, 7:5, 8:4, 9:3, 10:2 or 11:1 in splitting 12 cents; see ref.  ) or to choose between a fair offer and a selfish offer with different degrees of selfishness (i.e. \u00a55: \u00a55 vs. \u00a57: \u00a53 or \u00a58: \u00a52; see ref.  ). Weiland   et al  .  reported that fair offers in the UG induce greater activation in the striatum than that of the DG, which is involved in reward expectancy and magnitude, suggesting that UG proposers are mainly driven by egotistic motives that emphasize reward. Zheng and Zhu  reported that the same contrast induces greater activation in the right superior temporal gyrus (STG) and left cingulate gyrus. These two areas have been found to engage in making inferences about other people\u2019s mental state and emotional experiences, respectively , suggesting that fair UG offers may be the results of inferring the recipient\u2019s responses. \n\nStrategic motives are the second main hypothesis, postulating that a fair offer is made to avoid the possibility of rejection and receive a monetary reward . This hypothesis has been used to explain why raising stakes has no marked effect on the proposing behaviour . That is, offering fairly, regardless of the stakes, is the safest solution in which the possibility of rejection is almost zero and proposers will be guaranteed half the stakes. In cases where proposers were explicitly informed that recipients would receive any offer greater than zero, they offered much less (i.e. 25% of the stakes) and even less when the stakes were raised . In other words, proposers made an offer mainly driven after deliberating on the recipient\u2019s answer. \n\nOne important limitation in most previous studies was that only the final proposed offer was observed: participants were asked to divide the money by freely indicating their proposal (e.g. refs  ,  ,  ) or choosing one preferred offer among several offers with different share sizes, such as offering 20%, 30% or 50% of the stakes to the recipient (e.g. refs  ,  ,  ). However, how proposers reached the final decision of \u2018offering fairly\u2019 and to what extent they considered a selfish offer remains poorly understood. To tackle this issue, we followed Zheng and Zhu  by using a modified UG in which proposers had to make a binary choice between a fair offer and a selfish offer. Specifically, we manipulated the share size of the selfish offer systematically to be 10%, 20%, 30% or 40% of the stakes rather than either 20% or 30% of the stakes as tested by Zheng and Zhu . This manipulation gave us the opportunity to approximate the threshold of a selfish offer that proposers might have considered even though they ended up making a fair offer. We also manipulated stake size to investigate whether raising the stake size would have no marked effect in our modified UG as reported for the classical UG (e.g. ref.  ). Importantly, we conducted the experiment using fMRI and measured the time that proposers needed to make a choice. Therefore, we were able to examine the UG proposing behaviour at various levels, including the decisions (fair/selfish offers), reaction times and neural correlates. \n\nIf the proposers were driven primarily by strategic motives in our modified UG, as suggested in the literature (e.g. refs  ,  ,  ), their proposed offer would be altered by the paired selfish offer given the corresponding possibility of rejection and the potential monetary reward. A very selfish offer had a higher possibility of rejection than a fair offer; therefore, proposers might anticipate rejection when choosing between a fair and a very selfish offer and be inclined to choose the fair offer without much hesitation. In contrast, a slightly selfish offer is more amicable and acceptable to recipients than a very selfish offer, even though it also favours the proposers. Therefore, proposers might consider choosing the slightly selfish offer because it is more lucrative than a fair offer but somehow acceptable. Specifically, we expected that proposers would hesitate more and, thus, take longer making a decision when they had to choose between a fair offer and a slightly selfish offer than if they had to choose between a fair offer and a very selfish offer. In the neural level, we expected that proposers would show greater activation in the medial prefrontal cortex (mPFC), which has been reported to be involved in social decision making . Specifically, we expected that the dorsal anterior cingulate cortices (dACC; Brodmann areas [BA] 24 and 32) would be more activated as it has been found to play a central role in decisions about the allocation of cognitive control based on a cost/benefit analysis (review see ref.  ). \n\nWe expected to observe greater activation additionally in the mesolimbic region (i.e. ventral tegmental area [VTA] in the midbrain, ventral striatum [vST] and their reciprocally connected frontal cortex) signalling the greater monetary reward when proposers chose the slightly selfish offer over the fair offer . Such risk-taking behaviour might be reflected from greater activation in the nucleus accumbens (NAcc) of the vST , the insular cortex  and the orbitofrontal cortex  as reported in economic decision-making studies. \n\nIt has been suggested that proposers are more risk averse and more sensitive to the risk of rejection when stakes are higher due to the greater potential monetary gains and losses . Thus, we expected that proposers would take longer to consider the recipient\u2019s answer even though they eventually chose the fair offer in a higher stakes situation. Particularly, we expected to observe greater activation in mesolimbic region signalling with greater potential monetary gains and losses and in regions that previously have been implicated in risk-averse attitudes, such as the right dorsal lateral prefrontal cortex . We expected that the anterior cingulate gyrus (ACCg) would also activate more as it has been found to associate with the value of rewards for others . Moreover, it would be of great interest to examine whether proposers are more likely to spend a shorter amount of time choosing the fair offer over a more selfish offer, particularly when the stakes are higher. \n\nIn fact, the UG proposing behaviour has been rarely studied compared to the responding behaviour. It has been commonly assumed that rejection of selfish offers by recipients reflects negative emotional arousal mediated by the anterior insular cortex (AIC) and ACC . Thus, the findings of the current study will be a great contribution to the existing literature and could help elucidate the neural correlates of the proposing behaviour as revealed by previous behavioural research (e.g. refs  \u2013 ). \n\n\n## Results \n  \nSee Methods for details of participants\u2019 inclusion for the behavioural and imaging data analyses. \n\n### Overall choices with different share and stake sizes: estimated proportion of fair offers \n  \nThe estimated logistic model showed a significant main effect of share size,   \u03c7   (3, 42)\u2009=\u200953.522,   p  \u2009<\u20090.001. Participants were significantly more likely to choose fair offers when the other choice was more selfish (estimated proportion of 0.59\u2009\u00b1\u20090.049, 0.79\u2009\u00b1\u20090.037, 0.90\u2009\u00b1\u20090.024 and 0.92\u2009\u00b1\u20090.019 when the other choice offered 40%, 30%, 20% and 10% of the stakes, respectively). Post-hoc analyses indicated that all pairs of comparisons were significant (odds ratios were 0.106 and 0.280 for the comparisons between 40% and 10% and between 30% and 10%, respectively), except when the other choice offered 20% vs. 10% of the stakes (odds ratio\u2009=\u20090.753). The main effect of stake size,   \u03c7   (1, 42)\u2009=\u20090.302,   p  \u2009=\u20090.583 (odds ratio\u2009=\u20090.718), and the interaction,   \u03c7   (3, 42)\u2009=\u20092.430,   p  \u2009=\u20090.488, were not significant (see Fig.\u00a0 ).   \nEffect of share size and stake size when choosing a fair offer. (  a  ) Estimated proportion of fair offers; (  b  ) average reaction times when proposers chose a fair offer over a selfish offer with different share sizes (i.e., offering 40%, 30%, 20%, and 10% of the stake) in different stakes. Error bars indicate standard errors. *  p  \u2009<\u20090.05; (  c  ) significantly greater activation of a fair offer paired with a slightly selfish offer (i.e., offering 40% or 30%) than a very selfish offer (i.e., offering 20% or 10%), and (  d  ) in high stakes than in low stakes. \n  \n\n\n### Choice of a fair offer over a selfish offer with different share and stake sizes \n  \n#### Behavioural results: response time (RT) of choices for a fair offer over a selfish offer with different share and stake sizes \n  \nSimilarly, the analysis of variance (ANOVA) detected a significant main effect of share size,   F   (1.742, 64.458)\u2009=\u200911.600,   p  \u2009<\u20090.001,   \u03b7  \u2009=\u20090.239. Proposers decreased the RT of choosing a fair offer when the other choice was more selfish (mean times, 1.591\u2009\u00b1\u20090.065, 1.458\u2009\u00b1\u20090.059, 1.399\u2009\u00b1\u20090.051 and 1.371\u2009\u00b1\u20090.047\u2009s when the other choice offered 40%, 30%, 20% and 10% of the stakes, respectively). Post-hoc analyses indicated that all compared pairs were significant, except when the other choice offered 20% vs. 10% of the stakes and when the other choice offered 40% vs. 30% of the stakes. The main effect of stake size was also significant,   F   (1, 37)\u2009=\u20097.923,   p  \u2009<\u20090.01,   \u03b7  \u2009=\u20090.176. Proposers took longer for higher stakes, with mean values of 1.395\u2009\u00b1\u20090.056 and 1.479\u2009\u00b1\u20090.054\u2009s for low and high stake sizes, respectively. No significant interaction was found,   F   (1.893, 70.057)\u2009=\u20090.885,   p  \u2009=\u20090.412,   \u03b7  \u2009=\u20090.023 (see Fig.\u00a0 ). A trend analysis showed that the relationship between RT and share size of the selfish offer could be modelled by a linear trend,   F   (1, 37)\u2009=\u200916.378,   p  \u2009<\u20090.001,   \u03b7  \u2009=\u20090.307.   \nEffect of choice. Significantly greater activation induced when proposers chose a slightly selfish offer over a fair offer. \n  \n\n\n#### Imaging results \n  \nFirst, choice of a fair offer over a slightly selfish offer induced greater activation in the medial frontal gyrus, including the bilateral supplementary motor areas (SMA) and the dACC than choices of a fair offer over a very selfish offer (Table\u00a0  and Fig.\u00a0 ). The reverse contrast did not reveal any significant activation clusters. Second, choosing a fair offer with higher stakes induced greater activation in distributed regions that were more associated with two circuits, such as the mesolimbic system, including the VTA (or the substantia nigra [SN]) in the midbrain and the left pallidum in the vST and the theory of mind (ToM) , including the mPFC, bilateral precuneus and right temporoparietal junction (TPJ). In particular, the activated cluster in the mPFC was mostly in the ACCg. Additional clusters were also observed in bilateral occipital lobes and the left middle frontal gyrus (MFG)/precentral gyrus (Table\u00a0  and Fig.\u00a0 ). The reverse contrast and the interaction effects did not reveal any significant activation clusters.   \nBrain regions showing greater activation in choices of a fair offer over a slightly selfish offer (i.e., offering 40% or 30%) than the same choices over a very selfish offer (i.e., offering 20% or 10%); and in choices of a fair offer in higher stakes thank low stakes (  p  \u2009<\u20090.001 uncorrected with FDR correction at the cluster level; BA, Brodmann\u2019s area). \n  \n\n\n\n### Choosing between a fair and a slightly selfish offer with different stake sizes \n  \n#### Behavioural results \n  \nProportion of fair offers with different stake sizes: Proposers showed similar rates when choosing a fair offer with low and high stake sizes,   t  \u2009=\u2009\u22120.174,   p  \u2009=\u20090.863,   r  \u2009=\u20090.03, with mean rates of 60% and 62% for low and high stake sizes, respectively. \n\nRT of choices for a fair and a slightly selfish offer with different stake sizes: ANOVA detected no significant main effect of choice,   F   (1, 27)\u2009=\u20091.749,   p  \u2009=\u20090.197,   \u03b7  \u2009=\u20090.061, or stake size,   F   (1, 27)\u2009=\u20090.328,   p  \u2009=\u20090.572,   \u03b7  \u2009=\u20090.012, and no significant interaction,   F   (1, 27)\u2009=\u20091.530,   p  \u2009=\u20090.227,   \u03b7  \u2009=\u20090.054, with mean values of 1.592\u2009\u00b1\u20090.079, 1.654\u2009\u00b1\u20090.072, 1.704\u2009\u00b1\u20090.077 and 1.678\u2009\u00b1\u20090.094\u2009s for choosing a fair offer with low stakes, a fair offer with high stakes, a slightly selfish offer with low stakes and a slightly selfish offer with high stakes, respectively. \n\n\n#### Imaging results \n  \nAs shown in Table\u00a0  and Fig.\u00a0 , choosing a slightly selfish offer induced greater activation in the mPFC than choosing a fair offer (mainly in the ACCg and partially in the anterior cingulate sulcus [ACCs]), and regions associated within the mesolimbic system, including the VTA (or the SN) in the midbrain and caudate and pallidum and nucleus accumbens (NAcc) in the vST. The bilateral AIC and ventrolateral prefrontal cortex (VLPFC), including the inferior frontal gyrus and precentral gyrus also displayed greater activation. The other contrasts and the interaction effects did not reveal significant activation clusters.   \nBrain regions showing greater activation in choices of a slightly selfish offer (i.e., offering 40% or 30%) than a fair offer (  p  \u2009<\u20090.001 uncorrected with FDR correction at the cluster level; BA, Brodmann\u2019s area). \n  \n\n\n\n\n## Discussion \n  \nProposers typically make a fair offer in the original UG , and our proposers also showed extremely high rates of choosing the fair offer when the other choice was very selfish in our modified UG. In contrast, when the choice was only slightly selfish, suggesting comparatively lower rejection risk than a very selfish offer, and the higher expected monetary reward than a fair offer, but somehow acceptable, the proposers showed much lower rates of choosing the fair offer. This result was consistent with previous findings . Moreover, our systematic manipulation of the share size of the paired selfish offer allowed us to investigate the rate of choosing a fair offer as share size of the paired selfish offer changes. We found that proposers increased their rates of choosing a fair offer as share size of the paired selfish offer decreased and, more importantly, they showed similar rates when the share sizes were 20% and 10%. Thus, a selfish offer, such as 20%, could be a threshold at which proposers no longer consider the offer, which corresponded perfectly with the threshold that recipients typically reject in the classical UG (e.g. ref.  ). This result suggests that proposers in our modified UG were putting themselves in the shoes of the recipient, and the format of our modified UG retained the essence of the original UG. \n\nFurthermore, the finding that proposers increased RT when choosing a fair offer as a function of share size of the paired selfish offer was new. Moreover, they spent similar time choosing a fair offer when the selfish offer was 40% vs. 30% and 20% vs. 10%. This result further provides justification for the way that we merged the imaging data of 40% and 30% as \u2018slightly selfish offers\u2019 and 20% and 10% as \u2018very selfish offers\u2019. When choosing between the fair and slightly selfish offers than a very selfish offer, proposers\u2019 dACC was more activated. The dACC has been shown to relate to the allocation of cognitive control in making decisions considering the potential gains and losses . Moreover, it has been found to frequently engage in pre-response conflict and decision uncertainty that signals a reduced possibility of obtaining an anticipated reward . Furthermore, it has also been shown to signal a foregone reward for self . We also found greater activation in the rostral cingulate zone (BA 32), which has been shown to have direct and indirect projections and functional connectivity to the SMA and activate more when choosing between competing options in consideration of an anticipated reward associated with each of the options . Similarly, we found greater activation in the SMA, which has been reported to engage in motor control during goal-based action selection processes (i.e. choosing between a fair offer and a selfish offer) . \n\nAn important contribution of this study was that we examined the behavioural and neural responses when proposers made a slightly selfish offer over a fair offer (as in the second subset of data analyses), which has never been reported in the literature. Proposers did not have different decision times when choosing between a fair and a slightly selfish offer or between splitting high and low stakes. The latter result was particularly interesting because proposers took longer for higher stakes when they chose a fair offer (as shown in our first subset of data analyses). The stake effect diminished when proposers chose the slightly selfish offer, suggesting that proposers may have used different considerations when making fair and selfish offers. However, the different sample sizes and data inclusion between the two subsets of data analyses could also make this difference. \n\nChoosing a slightly selfish offer induced greater activation in the mPFC than choosing a fair offer (mostly in the ACCg and partly in the ACCs), implying a greater consideration of the rewards for one self and the other (recipient) (e.g. refs  ,  ,  ,  ,  ). Regions within the mesolimbic system (including the VTA or the SN in the midbrain and the left pallidum in the vST) were also more activated, possibly signalling the potential higher value when choosing the selfish offer (e.g. ref.  ). \n\nMoreover, greater activation was also found in the bilateral AIC. It has been suggested that AIC functions should be inferred with co-activated regions because the AIC is associated with a broad range of functions linked to emotions and homeostatic regulation . The co-activated regions involved in the reward circuit imply representation of reward anticipation by the AIC . Moreover, co-activated regions, such as NAcc in the vST, imply that the activation in the AIC might be related to the representation of risk level for a slightly selfish offer because it was more likely to be rejected than a fair offer . Alternatively, greater activation in the AIC might also associate with negative emotion expression or regulation due to the consideration of choosing a slightly selfish offer over a fair offer. Such an interpretation addresses processing of negative emotion as reported by Sanfey   et al  .  that UG recipients display greater activation in their bilateral AIC for an unfair offer than a fair offer, as a symbol of negative emotion, such as disgust at a disrespectfully selfish offer. Last, the higher activation in the VLPFC might be related to cognitive control and response inhibition because choosing a slightly selfish offer was more rewarding but also riskier than choosing a fair offer . It would be interesting for future studies to use the AIC as a region of interest to investigate the psychological processing of proposers and recipients to better understand their different concerns, such as self-interest and fairness. \n\nIn this study we also examined the effect of stake size, and not surprisingly, we replicated previous findings that stake size did not significantly alter the proposed offer (e.g. ref.  ). Moreover, we provided new evidence that proposers took longer to choose the fair offer when the stakes were higher. It is also possible that proposers took longer when the stakes were higher because higher stakes involve more math skills (e.g. to calculate the percentage of the selfish offer to total stakes). However, after cancelling out the effect of RT in our imaging data with the parametric modulation analysis, proposers still showed greater activation in the brain regions that have been previously shown to associate with reward and ToM . Notably, higher stakes also elicited greater activation in the ACCg, which has been reported to signal rewards delivering to others . Taken together, these imaging results might imply that proposers deliberated over the recipients\u2019 answers to a greater extent when stakes were higher due to the higher potential gains and losses. One limitation of the current study was that stake size may not have been high enough to make a difference on choices. Future studies should test proposing behaviour changes when stake size is extremely high. \n\nIt is worthwhile to compare our results with previous meta-analyses findings of responding behaviour during the UG . Previous studies reported that recipients showed greater activation in the bilateral mid-anterior insula, bilateral anterior midcingulate cortex (aMCC), left anterior SMA and right cerebellum when facing an unfair compared to a fair offer. They also indicated that recipients had greater activities in the SMA, aMCC, right MFG and bilateral lentiform nucleus when rejecting an unfair offer rather than when they accepted an offer. Activation in the mPFC/ACC while proposing a fair offer and rejecting an unfair offer is in line with the view that this region reflects rewards of decisions during social interactions . \n\nThe present study complemented the current literature as there are only two fMRI studies that investigated UG proposing behaviours to any extent . Weiland   et al  .  attempted to investigate UG proposing behaviour but were constrained by the very unbalanced number of choices between fair and selfish offers. The division of fair and selfish offers could also be debated because the offer of 7:5 was considered the fair offer when contrasting fair offers (i.e. offers of 6:6 and 7:5) vs. selfish offers (i.e. offers of 8:4, 9:3, 10:2 and 11:1). Moreover, their UG data were obtained from only 14 participants. Therefore, their results should be interpreted with caution. Furthermore, Zheng and Zhu  did not compare fair and selfish offers. \n\nIn conclusion, in our modified UG, proposers were less likely and spent more time choosing the fair offer over a slightly-selfish offer than a very selfish offer independent of stakes, possibly because a slightly selfish offer was more lucrative than a fair offer but somehow acceptable to the recipient. Such choices induced greater activation in the dACC that typically engage in allocation of cognitive control for cost/benefit decision making. Furthermore, choosing a fair offer in higher stakes evoked greater activation in the ACCg that signal the rewards for the other person and the areas that previously have been implicated in reward and ToM. These results might imply that in higher stakes participants deliberated on recipients\u2019 answers due to higher potential gains and losses. Last, choosing a slightly selfish offer over a fair offer evoked greater activation in the ACCs, ACCg, VTA (or SN), and AIC, tracking rewards for oneself and the other person as well as signalling a higher value and a greater rejection risk In sum, we have provided a comprehensive picture of UG proposing behaviour from various aspects. Our behavioural and imaging findings favoured the hypothesis of strategic motives for fair UG offers, which assumes that a fair offer is made to avoid rejection and receive reward. \n\n\n## Methods \n  \n### Participants \n  \nForty-five participants (27 females and 18 males; mean age\u2009=\u200924.49\u2009\u00b1\u20092.70 years) were recruited. All participants were healthy, right-handed (assessed by the Edinburgh Handedness Inventory; Oldfield 1971, see ref.  ) and without any neurological or psychiatric disorders or contraindications to MRI. They were matched with another 45 participants who acted as recipients to accept or reject their proposals. Prior to the experiment, all participants gave written informed consent to the study. All methods were performed in accordance with the ethical principles of the Declaration of Helsinki and were approved by the institutional review board on Humanities & Social Science Research/IRB-HS at Academia Sinica. \n\n\n### Task, Stimuli and Procedure \n  \nWe explained our modified UG task to the participants before testing, and the participants completed eight practice trials. We informed the participants that another participant would be selected randomly to play the role of recipient and respond to their offers (160 trials in total) in the UG in the other study. Participants did not meet the recipients and did not know who they would be matched with. \n\nWe told participants that two trials would be selected randomly out of all testing trials and that they would receive money based on the matched recipients\u2019 answers to their proposed offer. The average amount of money that they received from the two selected trials was NT$901\u2009\u00b1\u2009NT$452 (range, NT$0\u2009\u2013\u2009NT$1740; exchange rate between NT$ and US$ was approximately 33:1). This amount of money was approximately eight times the minimum wage per hour in Taiwan. Because most of the participants were college students, we assumed that such an amount could be an incentive for them to get as much money as possible. Moreover, they received NT$500 as a participation fee. \n\nParticipants were presented with a fixation cross for 2 or 4\u2009s during each trial, and then a stake with two pairs of choices of a fair offer and a selfish offer. Participants had to choose one pair of choices by pressing the button with their left or right thumb in 4\u2009s; otherwise the trial would be skipped. No feedback was given, so we could observe participants\u2019 original proposing behaviour without being influenced by the immediate answer of the recipient. The jittered inter-trial interval (ITI) was 2, 4, 6, or 8\u2009s (Fig.\u00a0 ). The high stakes ranged from NT$1640 to NT$2360 with an average of NT$2000 and a coefficient of variation (CV) of 0.098. The low stake ranged from NT$164 to NT$236 with an average of NT$200 and the same CV value. The fixed CV of the two stake sizes ensured that the differences among the four levels of the share size were consistent for the two stake sizes. The fair offer was offering 50% of the stake to the recipient, and the selfish offer was offering 40%, 30%, 20% or 10% of the stake. The position (left vs. right) of the fair vs. selfish offer choices was randomised, and the position (left vs. right) of the money assigned to the two players in the offer choice was counterbalanced among participants. Each experimental condition (2 stake sizes\u2009\u00d7\u20094 share sizes) was tested in 20 repetitions, yielding a total of 160 trials divided into four runs. Participants also received a 6\u2009min anatomical scan. The entire experiment took approximately 1\u2009hr. The experimental program was written using MATLAB2008 (MathWorks Inc., Natick, MA, USA) with Psychotoolbox 2.5.4. The choices, RTs, and brain images were recorded.   \nTimeline of an exemplar trial. In each trial, participants had to choose between a fair offer and a very selfish offer (i.e., offering 10% of the stake to the recipient) in a low stake. \n  \n\n\n### Data Acquisition \n  \nMRI images were collected using a 32-channel head coil in a 3T scanner (Skyra, Siemens Medical Solutions, Erlangen, Germany). A T2*-weighted gradient-echo echo planar imaging sequence was used for fMRI scanning, with 3\u2009mm slice thickness, 256\u2009\u00d7\u2009256\u2009mm  field of view, 90\u00b0 flip angle, 34 slices, 2000\u2009ms repetition time (TR), and 30\u2009ms echo time (TE). The anatomical, T1-weighted high-resolution image (1\u2009\u00d7\u20091\u2009\u00d7\u20091\u2009mm ) was acquired using a standard MPRAGE sequence, with a 7\u00b0 flip angle, 2,530\u2009ms TR, 3.3\u2009ms TE and 1,100\u2009ms inversion time (TI). \n\n\n### Data Analysis \n  \nAmong the 45 participants, two (participants 18 and 34) were excluded from the data analysis because they fell asleep in the MRI scanner during the experiment. For imaging analysis, only participants without excessive head movement (i.e. overall motion <3\u2009mm across the runs and <2\u2009mm of motion between adjacent functional volumes) were included. \n\n\n### Overall choices and RTs with different share and stake sizes \n  \nForty-three participants (25 females and 18 males; mean age\u2009=\u200923.67\u2009\u00b1\u20093.00 years) were included in this behavioural data analysis. \n\nWe analysed the UG binary choices using repeated-measures logistic regression implemented with the generalized estimating equations method. We modelled the within-subject effects of share size, stake size and their interaction for the fair offers. We also analysed RTs using repeated-measures ANOVA with share size and stake size as within-subject factors (see Supplementary Information for the RT results). IBM SPSS 20.0 was used for the statistical analysis (IBM Corp., Armonk, NY, USA) with the \u03b1 value set at 0.05. In situations in which sphericity was violated, we employed the Greenhouse-Geisser correction. Bonferroni\u2019s correction was used for post-hoc multiple comparisons. All behavioural data were analysed with the same criteria. \n\nCrucially, as found robustly in the classical UG that the majority of proposers offered fairly (e.g., ref.  ), we examined the choices of a fair offer over a selfish offer with different share sizes and different stake sizes to understand the proposing behaviour in our modified UG in the first subset of data analyses. In addition to the behaviour of offering fairly, we were also interested in the behaviour of offering selfishly. Consistent with the literature , the possibility of making a very selfish offer was very low and that made for very few corresponding images and unreliable imaging results (see Supplementary Information Table\u00a0  for details). Therefore, we selected only the cases in which proposers had to choose between a fair offer and a slightly selfish offer (i.e. offering 40% or 30% of the stake) in different stake sizes for a second subset of data analyses. \n\n\n### Choices of a fair offer over a selfish offer with different share and stake sizes \n  \nOf the 43 participants, five (participants 24, 43, 45, 49 and 59) were not included because they did not have data for certain conditions, resulting in 38 participants included in the RT analysis of fair offers. \n\nWe compared the RTs of choosing a fair offer over a selfish offer with four different share sizes and two stakes in a two-way (4 share sizes\u2009\u00d7\u20092 stake sizes) repeated-measures ANOVA with share size and stake size as within-subject factors. Furthermore, we tested the trend model that best explained the RTs for choosing a fair offer contingent on share size of the paired selfish offer using polynomial contrasts. \n\nFive participants (participants 38, 39, 55, 57 and 60) were excluded from the imaging analyses, given extensive head motion, and another six participants (participants 24, 43, 45, 46, 49 and 59) were excluded because they did not have sufficient trials per condition (n\u2009<\u20095) to gain adequate statistical power (see Supplementary Information Table\u00a0  for details). Consequently, 32 participants (19 females and 13 males; mean age\u2009=\u200923.97\u2009\u00b1\u20093.12 years) were included. The 32 participants showed the same tendency in their behavioural data (both the proportion and RT of fair offers) as the 43 participants. \n\nImaging analysis was performed using the Statistical Parametric Mapping 8 (Wellcome Trust Centre for Neuroimaging, London, UK) software package. The functional images of each participant were corrected for slice timing and head motion and then co-registered to the participant\u2019s segmented grey matter image. Next, the images were normalized to the Montreal Neurological Institute (MNI) standard space and spatially smoothed by convolution using an 8\u2009mm full width at half maximum Gaussian kernel. For simplicity and to ensure sufficient statistical power for the imaging analysis, we merged the options that offered 40% and 30% of the stake as \u2018slightly selfish offers\u2019, and options that offered 20% and 10% of the stake as \u2018very selfish offers\u2019. Consequently, we obtained up to nine different response conditions from the participant\u2019s choice (a fair or a selfish offer) in the four experimental conditions (2 merged share sizes\u2009\u00d7\u20092 stake sizes) plus one error response condition in which participants did not make a choice within 4\u2009s. We modelled the data on each participant with up to nine regressors using the general linear model as the first-level analysis. Next, we specified the onset and duration (0\u2009s) of each response trial and entered the corresponding RT as the parametric modulator with first-order modulation to avoid RT variability correlated with the blood-oxygenation-level-dependent signal . The six parameters of the realignment were also included in the model as regressors of no interest. The parameter estimates for choosing a fair offer by each participant were fed into a two-way (2 merged share sizes\u2009\u00d7\u20092 stake sizes) flexible factorial design with merged share size and stake size as within-subject factors using a random-effects analysis for the second level. The t-contrasts of interest were the differences in merged share sizes and stake sizes and the interaction effects. The threshold of the statistical maps was at a voxel-wise intensity of   p  \u2009<\u20090.001 (uncorrected) with a false discovery rate correction at the cluster level using the whole brain as the volume of interest. The resulting regions of activation were characterized in terms of their peak voxels in the MNI coordinate space. \n\n\n### Choosing between a fair and a slightly selfish offer with different stake sizes \n  \nOf the 43 participants, nine (participants 17, 23, 25, 27, 35, 38, 39, 55 and 60) always chose fair offers and six participants (participants 20, 28, 29, 45, 49 and 59) did not have data under certain conditions (see Supplementary Information Table\u00a0  for details). Therefore, 28 participants (18 females and 10 males; mean age\u2009=\u200923.79\u2009\u00b1\u20093.10 years) were included in this behavioural analysis. \n\nThe rates of choosing a fair offer in the different stake sizes were compared using a paired   t  -test. The RT between choices of a fair and a slightly selfish offer in different stake sizes was compared using a two-way (2 choices\u2009\u00d7\u20092 stake sizes) repeated-measures ANOVA with choice and stake size as within-subject factors. \n\nOf the 28 participants, one (participant 57) had extensive head motion and eight (participants 24, 30, 31, 33, 40, 43, 46 and 56) did not have sufficient images per condition (n\u2009<\u20095) (see Supplementary Information Table\u00a0  for details). In the end, 19 participants (12 females and 7 males; mean age\u2009=\u200924.84\u2009\u00b1\u20093.22 years) were included in the imaging analysis. The 19 participants showed a similar pattern in their behaviours as the 28 participants included in the behavioural analysis. \n\nThe parametric estimates for each participant (i.e. choices of a fair offer and a slightly selfish offer in low and high stakes) obtained in the first-level analysis were entered into a two-way (2 choices\u2009\u00d7\u20092 stake sizes) flexible factorial design with choice and stake size as within-subject factors in a random-effects group-level analysis for the imaging analysis. The t-contrasts of interest were the differences in choices and stake sizes and the interaction effects. The significance levels for behavioural and imaging analyses were identical to those in the first subset of data analyses. \n\n\n\n## Electronic supplementary material \n  \n\n\n\n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table 1\nBrain regions\tPeak MNI x y z\tt-Value\tCluster size\tUnnamed: 4\tUnnamed: 5\nChoices of a fair offer over a slightly selfish offer\u2009>\u2009choices of a fair offer over a very selfish offer\tChoices of a fair offer over a slightly selfish offer\u2009>\u2009choices of a fair offer over a very selfish offer\tChoices of a fair offer over a slightly selfish offer\u2009>\u2009choices of a fair offer over a very selfish offer\tChoices of a fair offer over a slightly selfish offer\u2009>\u2009choices of a fair offer over a very selfish offer\tChoices of a fair offer over a slightly selfish offer\u2009>\u2009choices of a fair offer over a very selfish offer\tChoices of a fair offer over a slightly selfish offer\u2009>\u2009choices of a fair offer over a very selfish offer\nLeft Supplementary motor area (BA 8)\t\u22124\t24\t46\t5.03\t1185\nLeft Medial frontal gyrus (BA 8)\t\u22124\t26\t52\t4.82\t1185\nRight Supplementary motor area (BA 8)\t6\t22\t56\t4.26\t1185\nLeft Anterior cingulate gyrus (BA 32)\t\u221210\t34\t26\t3.88\t1185\nRight Anterior cingulate gyrus (BA 32)\t6\t34\t28\t3.44\t1185\nChoices of a fair offer in high stakes\u2009>\u2009Choices of a fair offer in low stakes\tChoices of a fair offer in high stakes\u2009>\u2009Choices of a fair offer in low stakes\tChoices of a fair offer in high stakes\u2009>\u2009Choices of a fair offer in low stakes\tChoices of a fair offer in high stakes\u2009>\u2009Choices of a fair offer in low stakes\tChoices of a fair offer in high stakes\u2009>\u2009Choices of a fair offer in low stakes\tChoices of a fair offer in high stakes\u2009>\u2009Choices of a fair offer in low stakes\nLeft Calcarine sulcus (BA 17)\t\u221214\t\u221294\t\u22122\t8.67\t1832\nRight Lingual gyrus (BA 17)\t12\t\u221286\t\u22126\t8.18\t1832\nMidbrain\t4\t\u221236\t\u22128\t4.88\t1009\nRight Midcingulate area (BA 23)\t2\t\u221212\t30\t4.27\t1009\nLeft Pallidum\t\u221212\t4\t\u22122\t3.50\t1009\nLeft Precentral gyrus (BA 6)\t\u221234\t0\t52\t4.67\t527\nLeft Middle frontal gyrus (BA 4)\t\u221228\t0\t52\t4.33\t527\nRight Precuneus (BA 31)\t16\t\u221262\t32\t4.57\t1238\nRight Cuneus (BA7)\t16\t\u221268\t38\t4.30\t1238\nRight Temporoparietal junction (BA 7)\t38\t\u221258\t52\t3.88\t469\nRight Temporoparietal junction (BA 40)\t48\t\u221254\t54\t3.75\t469\nLeft Anterior cingulate gyrus (BA 32)\t\u22122\t42\t12\t4.12\t714\nRight Supplementary motor area (BA 8)\t4\t24\t48\t3.88\t714\nRight Anterior cingulate gyrus (BA 9)\t10\t40\t26\t3.83\t714\nRight Medial frontal gyrus (BA 8)\t4\t28\t50\t3.80\t714\n### Caption\nBrain regions showing greater activation in choices of a fair offer over a slightly selfish offer (i.e., offering 40% or 30%) than the same choices over a very selfish offer (i.e., offering 20% or 10%); and in choices of a fair offer in higher stakes thank low stakes (p\u2009<\u20090.001 uncorrected with FDR correction at the cluster level; BA, Brodmann\u2019s area).\n### Footer\nNone\n\n\n## ID: Tab2\n### Label: Table 2\nBrain regions\tPeak MNI\tPeak MNI\tPeak MNI\tt-Value\tCluster size\nBrain regions\tx\ty\tz\tt-Value\tCluster size\nRight Midbrain\t6\t\u221222\t\u22128\t5.6\t404\nLeft Medial frontal gyrus (BA 9)\t\u22128\t44\t18\t5.25\t2794\nLeft Anterior cingulate gyrus (BA 9)\t\u22128\t40\t22\t5.23\t2794\nRight Anterior cingulate gyrus (BA 32)\t14\t40\t16\t5.09\t2794\nLeft Insula\t\u221232\t16\t\u221216\t5.43\t380\nRight Caudate (body)\t12\t10\t\u22126\t4.85\t213\nRight Insula(BA 47)\t26\t16\t\u221216\t4.33\t421\nLeft Inferior frontal gyrus (opercular part; BA 44)\t\u221248\t8\t14\t4.77\t330\nLeft Precentral gyrus (BA 6)\t\u221254\t2\t18\t4.11\t330\nLeft Caudate (head)\t\u221212\t16\t0\t4.76\t186\nLeft Pallidum\t\u221214\t4\t\u22126\t3.45\t186\nRight Inferior Frontal Gyrus (triangular part; BA 45)\t56\t24\t10\t4.43\t505\nRight Precentral gyrus (BA 9)\t36\t4\t30\t3.87\t505\n### Caption\nBrain regions showing greater activation in choices of a slightly selfish offer (i.e., offering 40% or 30%) than a fair offer (p\u2009<\u20090.001 uncorrected with FDR correction at the cluster level; BA, Brodmann\u2019s area).\n### Footer\nNone\n", "metadata": {"pmcid": 5428836, "text_md5": "d32cceb1ea004ef2bfc6ce79786c546b", "field_positions": {"authors": [0, 101], "journal": [102, 109], "publication_year": [111, 115], "title": [126, 209], "keywords": [223, 223], "abstract": [236, 1560], "body": [1569, 38531], "tables": [38544, 42134]}, "batch": 2, "pmid": 28373714, "doi": "10.1038/s41598-017-00608-8", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5428836", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5428836"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5428836\">5428836</a>", "list_title": "PMC5428836  Strategic Motives Drive Proposers to Offer Fairly in Ultimatum Games: An fMRI Study"}
{"text": "Bonnet, Louise and Comte, Alexandre and Tatu, Laurent and Millot, Jean-Louis and Moulin, Thierry and Medeiros de Bustos, Elisabeth\nFront Behav Neurosci, 2015\n\n# Title\n\nThe role of the amygdala in the perception of positive emotions: an \u201cintensity detector\u201d\n\n# Keywords\n\namygdala\nemotion\nIAPS\nfMRI\nelectrodermal response\nemotional intensity\n\n\n# Abstract\n \nThe specific role of the amygdala remains controversial even though the development of functional imaging techniques has established its implication in the emotional process. The aim of this study was to highlight the sensitivity of the amygdala to emotional intensity (arousal). We conducted an analysis of the modulation of amygdala activation according to variation in emotional intensity via an fMRI event-related protocol. Monitoring of electrodermal activity, a marker of psychophysiological emotional perception and a reflection of the activation of the autonomic nervous system, was carried out concurrently. Eighteen subjects (10 men; aged from 22 to 29 years) looked at emotionally positive photographs. We demonstrated that the left and right amygdalae were sensitive to changes in emotional intensity, activating more in response to stimuli with higher intensity. Furthermore, electrodermal responses were more frequent for the most intense stimuli, demonstrating the concomitant activation of the autonomic nervous system. These results highlight the sensitivity of the amygdala to the intensity of positively valenced visual stimuli, and in conjunction with results in the literature on negative emotions, reinforce the role of the amygdala in the perception of intensity. \n \n\n# Body\n \n## Introduction \n  \nOne of the main challenges of neuroscience in the field of emotions is the modeling of anatomical structure and its functional response underlying emotional experience. The two main models of emotion, categorical, and dimensional, are each underpinned by neural and psychophysiological patterns consistent with and validated by numerous studies (Anderson et al.,  ; Dolcos et al.,  ; Lewis et al.,  ; Vytal and Hamann,  ). According to discrete emotion theory, each primary emotion has a constant and specific neural and psychophysiological pattern. The dimensional model involves attractive and repulsive systems. It defines emotions by two parameters: their valence (pleasant to unpleasant or positive to negative) and their intensity, also defined as arousal (calm to excited). \n\nThe amygdala is an anatomical and functional crossroads in the emotional process of which the role has been studied by both the categorical and dimensional models of emotions. Initially, the amygdala was considered to be \u201cthe organ of fear\u201d according to a categorical model (LeDoux,  ). Functional neuroimaging studies (mainly PET) then expanded the role of the amygdala to the recognition of unpleasant negative emotions (Morris et al.,  ; Lane et al.,  ; Paradiso et al.,  ). However, the development in functional imaging techniques has demonstrated that the amygdala may not only be specific to unpleasant stimuli. Indeed, the amygdala showed an activation in response to both pleasant and unpleasant stimuli (Anderson et al.,  ; Murphy et al.,  ; Small et al.,  ; Wager et al.,  ; Zald,  ; Winston et al.,  ; Costafreda et al.,  ; Sergerie et al.,  ; Ball et al.,  ; Costa et al.,  ; Morrison and Salzman,  ; Cunningham and Kirkland,  ). Additionally, a meta-analysis has highlighted the lack of specificity of the amygdala to a specific primary emotion (Sergerie et al.,  ). These results might be a reflection of the failure of the categorical model. \n\nThe dimensional model now seems more appropriate in studying the role of the amygdala in emotion. The challenge was then to decide if the amygdala encodes information about valence or intensity of emotion. First, it has been shown that the amygdala is activated in correlation with the intensity of negative stimuli (Canli et al.,  ; Taylor et al.,  ). Then, studies have expanded the role of the amygdala to the perception of emotional intensity, irrespective of valence, in the chemosensory field, with olfactory and gustatory stimuli and with semantic stimuli (Anderson and Sobel,  ; Anderson et al.,  ; Small et al.,  ; Cunningham et al.,  ; Phan et al.,  ; Lewis et al.,  ; Costa et al.,  ). It is easier to control the variation of intensity regardless of valence in the chemosensory field rather than with visual stimuli, enabling the perception of intensity to be studied without bias related to variations in valence. Winston et al. demonstrated amygdala sensitivity to the intensity of olfactory stimuli with an extreme valence, but not to the intensity of stimuli of average valence (Winston et al.,  ). This suggests that the sensitivity of the amygdala to variations of emotional intensity might be dependent on valence. This explains why some authors have indicated that the amygdala might be a detector of emotional valence (Anders et al.,  ,  ). \n\nIn regard to visual emotional stimulation, the most widely used stimuli are images from the International Affective Picture System (IAPS). Each of these images is provided with a normalized value of valence (  from 1, very pleasant to 9, very unpleasant, with 5, neutral  ) and intensity (  from 1, very calm to 9, very excited  ). Now there is a link between valence and intensity. The more intense images are often the most pleasant or unpleasant. It follows that, in the field of visual emotional stimulation, it is difficult to vary the intensity regardless of the valence, which may cause bias in studies, leading to raising doubt about the sensitivity of the amygdala concerning levels of emotional intensity (Lane et al.,  ; Anders et al.,  ,  ) and about whether the amygdala encodes intensity or valence (Anders et al.,  ). However, it has been shown that increased amygdala activity is associated with greater arousal. This effect has been reported both when pleasant and unpleasant pictures were analyzed together and when just negative stimuli were analyzed (Lane et al.,  ; Garavan et al.,  ; Zald,  ). Moreover, some studies use neutral stimuli as references and base states to compare amygdala activation in response to positive and negative visual emotional stimuli. The amygdala is also activated, although more weakly, in response to \u201cneutral\u201d stimuli (valence around 5), such as faces or photographs (Taylor et al.,  ; Sergerie et al.,  ). So there could be some confusion in these studies between low intensity and neutrality of the valence (i.e., neither pleasant nor unpleasant) which is actually an average valence (valence around 5). To avoid bias it would be preferable to study positive and negative stimuli separately when using visual emotional stimuli from the IAPS. Numerous studies highlighted the role of the amygdala in the perception of the degree of emotional intensity in many other domains (Anderson and Sobel,  ; Anderson et al.,  ; Small et al.,  ; Cunningham et al.,  ; Phan et al.,  ; Costa et al.,  ). Demonstrating the sensitivity of the amygdala to variations in intensity of positively valenced pictures would enhance previous results in the literature in favor of the amygdala encoding intensity of emotions. \n\nThe subject's perception of the two dimensions of valence and intensity in emotional feeling can be evaluated by self-scoring. Furthermore, emotions can be objectively evaluated by monitoring the autonomic nervous system (Lang et al.,  ; Anders et al.,  ; Kreibig,  ). Indeed, during the emotional process, the autonomic nervous system is activated. Electrodermal activity is a psychometric marker, indicating activation of the autonomic nervous system. It has been validated that its variations are correlated with the emotional intensity felt (Dawson et al.,  ). However, when used in fMRI studies, we can question whether the electrodermal reaction is the actual result of the emotional stimulation or a reaction to the noisy and stressful environment of the MRI scan. \n\nThe aim of our study was to demonstrate the role of the amygdala in the perception of the intensity of pleasant emotions when using positively-valenced images without using negative emotional stimuli (unpleasant). In the MRI scanner, we simultaneously recorded electrodermal activity (EDA) in order to indicate the emotional intensity perceived by the subject. In order to control the effect of our stimuli, we replicated our protocol of emotional stimulation outside the scanner 1 month later to evaluate the effect of our stimuli, without the effect of the scanner. Our hypothesis is that increasing the intensity of positive visual emotional stimuli increases amygdala activation. This result should complement knowledge regarding negative as well as positive emotions in other domains (using olfactory, auditory, gustatory or semantic stimuli). We could then consider the fact that the human amygdala encodes the intensity of emotional stimuli whether positive or negative. \n\n\n## Methods \n  \n### Participants \n  \nEighteen healthy participants (10 men, all right handed, mean age 25 years, range 22\u201329) with normal or corrected-to-normal vision, and no history of neurological and psychiatric disorders, participated in this study. Written informed consent, as well as a safety-screening questionnaire to undergo magnetic resonance imaging (MRI), was obtained from each participant. The study received the approval of an Institutional Review Board (CPP   Est II  ). \n\n\n### Stimuli \n  \nStimuli were 75 positively valenced (IAPS ratings >4.6; mean = 5.90 \u00b1 0.49) colored visual stimuli selected from the IAPS (Lang et al.,  ) (see Table   for a full description). We selected three groups of 25 images each, stratified according to their intensity based on the IAPS norms (Lang et al.,  ) (mean intensity ratings \u00b1 SD; low intensity = 2.77 \u00b1 0.17; moderate intensity = 4.53 \u00b1 0.30; and high intensity = 6.35 \u00b1 0.3). We carefully matched these subsets with respect to semantic content, human faces and human figures, animals, and scenes. In addition, we ensured that IAPS valence ratings did not statistically differ between each group (Kruskall-Wallis test,   p   = 0.13). The mean luminance as well as the contrast of images were controlled. Every image was transformed so that the mean luminance of every group was equal. Mean luminance for the group of low intensity (respectively medium intensity, high intensity) was 87.0 (respectively 87.2, 89.5). As there were very little differences with the contrast (mean contrast (\u00b1SD) for the 75 images = 0.115 \u00b1 0.003), no change was made for this parameter. No statistical difference was observed between groups for neither the \u201cluminance\u201d parameter, nor the contrast. From these 75 pictures, we planned to create three new groups of stimuli, according to the intensity ratings made by our subjects in this study. The analyses in this study were based on these three new groups of stimuli. \n  \n Visual stimuli from the International Affective Picture Systems (IAPS)  . \n  \n\n### Experimental procedure \n  \nThis study was composed of two sessions. In the first session, we used functional magnetic resonance brain imaging (fMRI) to examine regional brain activity during a spontaneous emotion reactivity task. Our marker of autonomic activation was EDA, monitored in the scanner. We chose a passive task in order to avoid potential inhibition of amygdala activity by the prefrontal cortex because task instructions involving a form of attentional processing reduce the likelihood of amygdala activation compared to the passive processing of emotional stimuli (Hariri et al.,  ; Keightley et al.,  ; Taylor et al.,  ; Costafreda et al.,  ). Prior to the experimental session, subjects were familiarized with the stimuli by viewing 10 pictures from the IAPS, which were not included in the experiment. Participants were instructed to experience any feelings or thoughts the pictures might elicit in them. In the scanner, subjects saw pictures on a screen, positioned at the head of the scanner, via binoculars positioned on the head coil. Stimuli were applied using an event related design. Each picture was presented for 2 s. Stimulus presentation was jittered in time, with an inter-trial interval varying from 8 to 12 s (mean = 10 s). During the inter-trial interval, a black fixation cross on a white background remained on the screen and was our baseline condition. All stimuli were presented in a randomized order. Inter-trial interval was also randomized in order to maintain the subject's attention. The time interval between two events was chosen to allow the recording of peripheral physiological responses (Breska et al.,  ) as well as to allow blood flow to return to homeostatic levels. The task lasted about 15 min. \n\nIn the second phase, 1 month later, the same participants performed the same paradigm, but outside the scanner. After this second session, all stimuli were presented in a second pass where subjects rated how arousing they had experienced each stimulus on a scale ranging from non-arousing (intensity value of 1) to arousing (intensity value of 9) on a paper-and-pencil version of the self-assessment-manikin (Bradley and Lang,  ). This session allowed us to compare skin conductance responses (SCRs) with visual emotional stimuli inside and outside the MR scanner to evaluate the effect of MRI on SCR. Moreover, it provided us with the personal ratings of emotional intensity felt by our participants for each stimulus. Verbal recordings of experienced intensity after scanning have been shown to reliably represent emotional experiences during scanning (Phan et al.,  ) and avoid biases introduced by monitoring one's own emotion during scanning (Taylor et al.,  ; Phan et al.,  ). \n\n\n### SCR acquisitions and analysis \n  \nSkin conductance was recorded using an MP-150 psychophysiological monitoring system (BioPac Systems, Santa Barbara, CA). We used Ag/AgCl electrodes filled with isotonic NaCl unibase electrolytes attached to the volar surface of the second phalanx of the second and third fingers of the left hand (non-dominant hand) (Fowles et al.,  ). Amplification utilized a constant voltage technique to measure absolute conductance. Electrodermal activity (EDA) was acquired at a sampling rate of 1000 Hz. The skin conductance signal was recorded simultaneously with functional imaging, time-locked to visual stimuli via an analogic system between Biopac and the computer using E-prime. The acquisition of EDA during the second session 1 month later was identical. \n\nThe MP-150 module performed analog-to-digital conversion of the amplified signals and passed data to a computer running Acknowledge 4.2 software (BioPac Systems, Santa Barbara, CA) for analysis of waveforms. \n\nThe SCR data were processed using high-pass filter and smoothing to remove scanner-induced artifacts. The tonic component was then extracted from the phasic component, in order to suppress the effect of the precedent stimulus on the SCR of the next one (Lim et al.,  ). We defined SCR as an increase of more than 0.02 microsiemens of the skin conductance level, occurring between 1 and 6 s after presentation of the stimulus (Dawson et al.,  ). \n\nFor each stimulus we calculated the frequency of SCRs (percentage of SCR among the 18 subjects), the magnitude (mean value computed across all stimulus presentations including those without a measurable response) and the amplitude (mean value computed across only those trials on which a measurable response occurred) of SCRs across all the subjects (Dawson et al.,  ). SCR amplitude measurements were logarithmically transformed. For the SCR magnitude measurements, a one is added to all SCR amplitudes before a logarithmic transformation in order to normalize data. \n\nCorrelations between both sessions (inside and outside the scanner) were calculated for frequencies as well as magnitudes. \n\n\n### Imaging acquisition parameters \n  \nImaging data was collected at Besancon University Hospital using a 3-Tesla (General Electric Healthcare Signa H.D. Milwaukee, WI, USA) MR system with a standard 40 mT/m gradient using blood\u2013oxygen level-dependent (BOLD) fMRI. Foam cushions were used to minimize head movements within the coil. Functional MRI runs were acquired parallel to the anterior-posterior commissural line, covering the entire cerebrum using an echo planar imaging (EPI) sequence: echo time (TE) = 35 ms, flip angle (FA) = 90\u00b0, matrix size = 128 * 128, field of view (FOV) = 256 mm, slice thickness = 4.5 mm, 30 slices and repetition time (TR) = 2500 ms. Before the first run, a high-resolution, T1-weighted, three-dimensional data set encompassing the whole brain was acquired to provide detailed anatomy (G.E. Fast Spoiled Gradient Recalled Echo sequence, matrix size = 256 * 256, FOV = 256 mm , 134 slices, slice thickness = 1 mm, no gap, total scan time = 2 min 56 s). \n\n\n### fMRI analysis \n  \nImage time-series analysis was performed using BrainVoyager QX 2.4 (Brain Innovation, Maastricht, The Netherlands) (Goebel et al.,  ). The time-series were corrected for slice acquisition time, realigned with their corresponding T1 volumes, warped into standard space (Talairach and Tournoux,  ), re-sampled into 3 mm isotropic voxels, motion-corrected using Levenberg-Marquarts's least square fit for six spatial parameters, highpass-filtered for removal of low frequency drifts, corrected voxelwise for linear drifts, and spatially smoothed using a 8-mm full-width at half-maximum Gaussian kernel. The general linear model (GLM) was computed from the 18 z-normalized volume time courses. For all stimuli of interest, i.e., rest and stimulation periods, box-car time courses with a value of one for the stimuli of interest and values of zero for the remaining time points were convolved with a theoretical hemodynamic response function (Boynton et al.,  ) and were entered as predictors into the design matrix of the study. Contrast analyses were based on random effects GLMs of the z-normalized volume time courses. Analyses of the stimulation periods (all groups combined) vs. rest periods as well as contrast analyses between groups were performed from the 18 subjects using a statistical threshold of q(FDR) <0.05 corrected for multiple comparisons. \n\n\n### Statistical analysis \n  \nThe ratings of intensity and valence were normally distributed, according to a Shapiro-Wilk test, but there was no equality of variances across the means of intensity of our three groups (Bartlett test). We performed a Kruskall-Wallis test to search for differences between our three groups using the means of intensity (subjects' ratings) and valence (norms from the IAPS) for each stimulus. When a difference was detected, we performed a Student test to search for differences between each group of stimuli. \n\nSCRs were not normally distributed (Shapiro-Wilk test). We used non-parametric tests. The differences in SCRs across the three groups of stimuli were assessed using a Kruskall-Wallis test and when a difference was found, comparison between groups was made by a Welch test. The differences in SCRs across the two sessions were assessed using a Wilcoxon test. Tests were undertaken for frequency of SCRs, magnitude, and amplitude (microsiemens). \n\n\n\n## Results \n  \n### Ratings of intensity \n  \nRatings made by our subjects were strongly correlated to IAPS norms of intensity (  r   = 0.80;   p   < 0.001) (Figure  ). The ratings made by the subjects were slightly lower than the norms of the IAPS by 0.5 points (  p   < 0.001, paired   t  -test between IAPS ratings and mean ratings from our subjects). We built three groups of 25 visual stimuli according to the mean ratings of intensity performed by subjects: Group 1 (low intensity,   m   = 2.28), Group 2 (moderate intensity,   m   = 4), and Group 3 (high intensity,   m   = 5.8). Mean ratings of intensity were statistically different between each group of stimuli (Kruskall-Wallis   p   < 0.001). There was no significant difference between the mean valence of each group (Kruskall-Wallis,   p   = 0.13) (Figure  ). \n  \n (A)   Distribution of the mean intensity ratings by our subjects for each of the 75 selected IAPS pictures against the IAPS norms of intensity. R, correlation coefficient (Pearson test,   p   < 0.001).   (B)   Distribution of the mean intensity ratings by our subjects for each of the 75 selected IAPS pictures against the IAPS norms of valence. Dashed lines represent the mean valence (  m   = 5.9) and the mean \u00b1 1.96 SD (4.94 and 6.87). Blue (or respectively red/green) points form the low (or respectively medium/high) intensity groups. Points with a black edge represent the means of the sub-groups. Error bars are the standard error of the mean. \n  \nAccording to these three new groups, mean luminance for the group of low intensity (respectively medium intensity, high intensity) was 87.3 (respectively 86.4, 89.9). No statistical difference was observed between groups neither for this parameter, nor for the contrast. \n\n\n### fMRI data \n  \nThe global fMRI analysis comparing the viewing of stimuli and rest state showed activation in the right and left anterior cingulate gyri, right, and left superior medial frontal gyri, right, and left inferior frontal gyri, right, and left posterior orbital gyri, right, and left anterior part of insula, right, and left occipital gyri, right, and left thalami (medial thalamus and pulvinar), right and left colliculi, right, and left amygdalae, right, and left parahippocampal gyri, and the vermis. These areas are known to be involved in the processing of visual emotional information (Sabatinelli et al.,  ). \n\nThe fMRI analysis between the three groups of stimuli (according to subjects' intensity ratings) showed activations in the right and left amygdalae, the right orbital gyrus, the right pulvinar, the right, and left medial thalami, the anterior part of the insula, the right, and left colliculi, and the hypothalamus (see Tables  ,   for a full description). \n  \n Cerebral activations for the 18 healthy subjects for the 3 comparisons between the 3 levels of emotional intensity: Group 1, during viewing of low intensity stimuli; Group 2, during viewing of medium intensity stimuli; Group 3, during viewing of high intensity stimuli  . \n  \n Analyses were based on random effects (RFX) GLMs of the z-normalized volume time courses using a statistical threshold of p < 0.05 corrected for FDR  . \n    \n Cerebral activations for the 18 healthy subjects when testing Group 3 (during viewing of high intensity stimuli) against Group 1 (during viewing of low intensity stimuli)  . \n  \n Analyses were based on random effects (RFX) GLMs of the z-normalized volume time courses using a statistical threshold of p < 0.05 corrected for FDR. Size (voxels), size of the cluster in number of connected voxels of 1 mm ; x, y, z, Talairach coordinates of the maximum peak. BA, Brodmann area  . \n  \nRegarding the main objective of the study, we found a stronger activation of the right and left amygdalae when subjects visualized stimuli of stronger intensity (Group 3) compared to stimuli from the group of lower intensity (Group 1). The left and right amygdalae were activated by viewing emotional stimuli, as demonstrated by the analysis of the differences of cerebral activation between no stimulation (black cross) and the viewing of pictures. However, amygdala activation was stronger when subjects viewed stimuli with strong intensity compared to stimuli with low intensity, with the same valence (neutral or positive). There was no significant difference with corrected statistics in intermediary comparison (between Groups 1 and 2 and between Groups 2 and 3) for the amygdalae. These results are illustrated on Figure   after extracting beta values for each condition in four regions of interest (left and right amygdalae, right pulvinar, and the medial thalami, and hypothalamus complex) defined from the contrast Group 3 minus Group 1. \n  \n Bold curves as well as mean beta weight calculated from 18 subjects by image group in four regions of interest: left and right amygdalae, right pulvinar, and the medial thalami and hypothalamus complex  . Group 1 is the image set with the lowest intensity, and Group 3 the image set with the highest intensity (Group 2 is an intermediate intensity image set). Regions of interest were obtained from the contrast Group 3 minus Group 1 after a statistical threshold of q(FDR) < 0.05 corrected for multiple comparisons. Error bars represent the standard error of the mean (\u00b1 s.e.m.) * indicates a <0.05   p  -value. \n  \n\n### Skin conductance responses (SCRs) \n  \n#### First session, inside the scanner \n  \nDuring the fMRI session, 16 subjects presented SCRs and 2 subjects (2 women) presented no SCRs. The magnitude and frequency of SCRs were greater for the stimuli in Group 3, rated by subjects as the most intense (  p   < 0.005) (Figure  ). There was no difference in amplitude between the three groups of stimuli (  p   = 0.09). \n  \n (A)   Magnitudes and frequencies of the SCRs during viewing of stimuli in the first session inside the scanner. There was a statistical difference between groups of low and moderate intensity compared to the group of high intensity in terms of magnitude and frequency of SCRs.   (B)   Magnitudes and frequencies of the SCR during the viewing of the stimuli outside the scanner, in the second session. There was no statistical difference between the magnitudes of the 3 groups (  p   = 0.28). There was a statistical difference in frequencies of SCRs between groups of low and moderate intensity compared to the group of high intensity. *indicates a <0.005   p  -value. \n  \n\n#### Second session, 1 month later, outside the scanner \n  \nDuring the second phase, 17 subjects presented SCRs and 1 subject showed no SCRs (a woman who did not present any SCRs in the first phase). The frequency of SCRs for Group 3 was significantly higher than those of Groups 1 and 2 (  p   = 0.041) (Figure  ). There was no significant difference in magnitude or amplitude in SCRs in the three groups of stimuli (  p   = 0.27 and   p   = 0.5 respectively). \n\n\n#### Comparison of the session inside the scanner with the session outside the scanner \n  \nFrequency, magnitude, and amplitude of the SCRs were higher during the second pass, outside the MRI scanner, compared to the first pass in the MRI scanner (respectively: frequency = 14 vs. 27%; magnitude = 0.01 vs. 0.04; amplitude = 0.08 vs. 0.12;   p   < 0.0001). \n\nFrequencies of electrodermal responses were significantly correlated between sessions 1 and 2 (  r   = 0.67;   p   = 0.002). Magnitudes of electrodermal responses were also significantly correlated between sessions 1 and 2 (  r   = 0.79;   p   < 0.001). \n\n\n\n\n## Discussion \n  \n### Amygdala and emotional intensity \n  \nWe have shown that the amygdala is sensitive to the emotional intensity of positive stimuli. This result is consistent with studies in primates (Belova et al.,  ) and some studies in humans (Phan et al.,  ,  ; Sabatinelli et al.,  ; Cunningham and Kirkland,  ). However, these studies often showed a bias linked to the use of stimuli varying both in intensity and valence within the same protocol. Indeed, if we consider that the amygdala is sensitive to both the size of intensity and valence, the valence effect may mask an intensity effect if it is stronger or dependent on a higher number of amygdaloid neurons. That is why we chose to use only positive emotional stimuli in this study, to avoid the bias linked to valence. As the valences are not different between our three groups of pictures, our result is not linked to the \u201cvalence\u201d parameter. Studies in macaques have shown that there are different groups of amygdaloid neurons that do not encode the same information. Some amygdaloid neurons were activated depending on the intensity of positive stimuli, some depending on the intensity of negative stimuli and others depending on the intensity of the two types of stimuli. These neurons are involved in mechanisms independent of valence (Belova et al.,  ). Optogenetics in mice has shown that different amygdala nuclei belong to various functional and anatomical circuits (Lalumiere,  ) involved in anxiety, fear-related behavior and regulating reinforcement and reward). Due to the limits of the resolution of functional MRI, it is not possible to accurately discriminate the different amygdaloid nuclei. To clarify the roles and networks to which they belong, further studies using other techniques, such as tractography, are needed (Solano-Castiella et al.,  ). \n\n\n### Amygdala and lateralization \n  \nOur study did not reveal any specific amygdala lateralization. Various models of amygdala lateralization have been proposed, with more recent models showing that amygdala lateralization may be linked to the temporal dynamics of information processing (Wright et al.,  ). Activation of the amygdala found most frequently on the left rather than the right in some studies and meta-analyses (Murphy et al.,  ; Wager et al.,  ; Baas et al.,  ) may be related to a habituation or temporal dynamics effect. The right amygdala is involved in the initial and rapid detection of stimuli, processing data over a shorter duration of time, compared to the left amygdala that may more elaborately evaluate stimuli with a longer latency response (Gl\u00e4scher and Adolphs,  ; Sergerie et al.,  ). This is consistent with the conclusion of several meta-analyses that have shown no amygdala lateralization according to stimuli valence, or sex of the subjects (Murphy et al.,  ; Wager et al.,  ; Baas et al.,  ). Interaction between amygdala laterality and task, stimulus type or novelty may not exist either (Baas et al.,  ). \n\n\n### Other activations associated with emotional intensity in this study \n  \nOur study showed activation of the medial thalamus and the posterior orbital and medial prefrontal cortices, parallel to the increase in the intensity of the stimuli. Concordantly with our study, a coding of emotional intensity by the medial thalamus and the medial prefrontal cortex was demonstrated (Anders et al.,  ). The amygdala is connected to the prefrontal cortex in neocortical circuits that incorporate emotional significance of stimuli and guide complex behavior. The amygdala sends pertinent, filtered sensory information to the prefrontal cortex (directly or via the mediodorsal nucleus of the thalamus) and the latter returns reinforcement or inhibition information to the amygdala after more cognitive processing of information. This is likely to be due to the reciprocal connections between the amygdala and the prefrontal cortex, sources of individual emotional experience specific to humans (Purves et al.,  ; Kim et al.,  ). \n\nWe have demonstrated that the right pulvinar and the left and right colliculi are sensitive to emotional intensity. Data for this circuit are controversial. For some, it may be responsible for the unconscious processing of visual emotional stimuli, while for others, its role, like that of the amygdala, may be to coordinate the neocortical circuits in the treatment of the relevance of visual emotional information (Buchsbaum et al.,  ; Pessoa and Adolphs,  ; Sabatinelli et al.,  ). \n\nActivation of the hypothalamus according to emotional intensity is consistent with amygdala activation. The latter sends projections to the hypothalamus and brainstem, allowing the expression of emotions through the modulation of autonomic and vegetative efferent motor systems. This was highlighted in this study by concomitantly monitoring the EDA, a marker of activation of the sympathetic system of the autonomic nervous system (Dawson et al.,  ). \n\n\n### Validation of stimuli intensity scoring of the IAPS \n  \nScoring the intensity of the IAPS photographs by subjects is similar to that provided by the IAPS. The average scoring of intensity by our subjects is slightly lower to that of the IAPS norms (minus 0.5 points), which is similar to scoring carried out by our neighboring countries (Switzerland, Germany; Bradley and Lang,  ). \n\nThanks to the IAPS norms, we were able to build a set of stimuli sensitive to intensity, devoid of bias relating to valence, and validated in our population of subjects. \n\n\n### Electrodermal activity and emotional intensity felt \n  \nIn both sessions (inside and outside the MRI scanner), frequency of SCRs was greater for more intense stimuli (Group 3). Magnitude was only significantly higher for the more intense stimuli in the first session, in the MRI scanner. In contrast to data from other studies (Dawson et al.,  ) that have demonstrated an increase in the amplitude of SCRs with emotional intensity, we did not demonstrate any significant variation in the amplitude of SCRs according to intensity. Post-processing of the recording and MRI scan pass are not concerned because there is no relationship between the amplitude of SCRs and emotional intensity during the 2 phases (inside and outside the MRI scanner, not requiring post-processing). \n\nWe obtained identical statistical results in both sessions on the relationship between stimuli intensity and amplitude of SCRs (no link during both sessions), and the relationship between stimuli intensity and frequency of SCRs (increased for Group 3 in the 2 sessions). The only difference in result between sessions is magnitude. The magnitude of SCRs is related to stimuli intensity only during the first phase, in the MRI scanner. There is a non-significant tendency during the second phase, outside the MRI scanner. One can draw several hypotheses to explain this difference. It is, first of all, a matter of calculation of magnitude, involving both the concept of response frequency and of amplitude. As amplitude was not sensitive to stimuli intensity in our study, it is likely that it is the frequency that makes variations in magnitude significant. Furthermore, it is also possible that the lack of significance of magnitude in the second session is related to a habituation effect to stimuli. Intra-subject stability of SCRs has been demonstrated 1 year later (Schell et al.,  ) but our second phase took place 1 month after the first. Finally the significance of the relationship between magnitude of SCRs and stimuli intensity in the MRI scanner might be linked to an effect specific to undergoing an MRI. The environment of the MR scanner, noise, lying down, the stress of the examination or its cramped nature could make the subject more stressed and therefore more responsive to more intense stimuli, or less responsive to less intense stimuli. This issue is important because it raises the question of comparability of emotional states inside and outside the MRI scanner. Ambient temperature, a factor known to modify SCRs (Dawson et al.,  ), is not a confounding factor because it was controlled during the two sessions. \n\nThe values of the magnitudes, amplitudes, and frequencies of SCRs that we recorded in the MRI scanner are lower than those recorded outside the MRI scanner (Figure  ). Two factors may be responsible for this difference. First, there could have been a loss of signal due to post-processing of the EDA recording necessary when performing in the MRI. Despite MRI compatibility of the equipment used in this study, the EDA recording was artifacted by the functional MRI sequences and therefore required post-processing by selective removal of high frequencies and smoothing. However, these treatments are known to lose information, both in terms of the frequency of SCRs and in terms of their amplitude. The use of fiber optic cables (Lagopoulos et al.,  ) would avoid these artifacts and thus the loss of data linked to post-processing (Shastri et al.,  ). Undergoing an MRI scan by the subject is another factor that may explain the differences between the two sessions. The MRI might, via the stress that it can cause, block spontaneous emotional reactions. Our study cannot answer these questions. However, it can dispute the authenticity of emotional responses in the MRI scanner. \n\n\n\n## Conclusion \n  \nThese results highlight the sensitivity of the amygdala to variations in the intensity of positive emotions, and in conjunction with results in the literature on negative emotions, show the role of the amygdala in the perception of emotional intensity. \n\nHowever, the role of the amygdala has been identified in other areas, such as the behavior of consciousness, attentional mobilization (Pribram and McGuinness,  ), alertness, as well as the treatment of ambiguity of stimuli (Pessoa and Adolphs,  ). Furthermore, the anatomical location and multiple connections of the amygdala mean that it may be a center for data processing, a role more than that of a simple \u201cdanger detector\u201d (Kim et al.,  ). The amygdala may be an early detector of the relevance of stimuli for the individual (Sander et al.,  ). Its activation in the perception of the intensity of emotional stimuli may be only a facet of its overall role in general sensory perception. \n\nThe study of emotions in healthy subjects will eventually lead to a better understanding of dysfunctions in the pathology of emotions. The amygdala has been studied in several psychiatric pathologies involving emotional disorders such as anxiety disorders and schizophrenia. However, as its roles are multiple, underpinned by its many connections with cortical and subcortical structures, the pathophysiology of the amygdala is not limited to emotional disorders themselves but in fact extends to areas such as memory, attention, decision-making, and cognition. \n\n### Conflict of interest statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nDescription\tIAPS number\tValmn\tAromn\nLizard\t1121\t5, 79\t4, 83\nLeopard\t1310\t4, 6\t6\nGannet\t1450\t6, 37\t2, 83\nJaguar\t1650\t6, 65\t6, 23\nOctopus\t1947\t5, 85\t4, 35\nWoman\t2025\t5, 78\t4, 3\nCheerleaders\t2034\t5, 9\t4, 93\nNeuWoman\t2038\t5, 09\t2, 94\nGirl\t2320\t6, 17\t2, 9\nThreeMen\t2370\t7, 14\t2, 9\nGirl\t2411\t5, 07\t2, 86\nManW/Dog\t2521\t5, 78\t4, 1\nChess\t2580\t5, 71\t2, 79\nBeer\t2600\t5, 84\t4, 16\nDance\t2606\t5, 92\t4, 78\nDancer\t2616\t5, 97\t4, 96\nWoman\t2620\t5, 93\t2, 72\nShadow\t2880\t5, 18\t2, 96\nGold\t3005, 2\t5, 98\t4, 84\nEroticFemale\t4232\t5, 95\t6, 28\nEroticMale\t4490\t6, 27\t6, 06\nEroticMale\t4503\t6\t4, 93\nEroticMale\t4531\t5, 81\t4, 28\nEroticMale\t4538\t5, 91\t4, 65\nEroticCouple\t4604\t5, 98\t6, 09\nEroticCouple\t4651\t6, 32\t6, 34\nEroticCouple\t4669\t5, 97\t6, 11\nEroticCouple\t4692\t5, 87\t6, 39\nEroticCouple\t4693\t6, 16\t6, 57\nEroticCouple\t4697\t6, 22\t6, 62\nFlower\t5000\t7, 08\t2, 67\nFlower\t5020\t6, 32\t2, 63\nFlower\t5030\t6, 51\t2, 74\nBoat\t5390\t5, 59\t2, 88\nCockpit\t5455\t5, 79\t4, 56\nMushroom\t5520\t5, 33\t2, 95\nMushroom\t5530\t5, 38\t2, 87\nHangGlider\t5626\t6, 71\t6, 1\nCave\t5661\t5, 96\t4, 15\nFarmland\t5720\t6, 31\t2, 79\nGrain\t5726\t6, 23\t2, 84\nFlowers\t5731\t5, 39\t2, 74\nLeaves\t5800\t6, 36\t2, 51\nDesert\t5900\t5, 93\t4, 38\nVolcano\t5920\t5, 16\t6, 23\nLightning\t5950\t5, 99\t6, 79\nPicnic Table\t7026\t5, 38\t2, 63\nFork\t7080\t5, 27\t2, 32\nHeadlight\t7095\t5, 99\t4, 21\nFire Hydrant\t7100\t5, 24\t2, 89\nBus\t7140\t5, 5\t2, 92\nTeeth\t7195\t6, 02\t4, 54\nScarves\t7205\t5, 56\t2, 93\nPizza\t7351\t5, 82\t4, 25\nSushi\t7477\t6, 12\t4, 82\nWindow\t7490\t5, 52\t2, 42\nStreet\t7496\t5, 92\t4, 84\nCard Dealer\t7503\t5, 77\t4, 21\nStairs\t7504\t5, 67\t4, 25\nSkyscraper\t7510\t6, 05\t4, 52\nJet\t7620\t5, 78\t4, 92\nSkyscraper\t7640\t5\t6, 03\nCity\t7650\t6, 62\t6, 15\nViolin\t7900\t6, 5\t2, 6\nHiker\t8158\t6, 53\t6, 49\nRock Climber\t8160\t5, 07\t6, 97\nCliffdiver\t8178\t6, 5\t6, 82\nBungee\t8179\t6, 48\t6, 99\nIce Climber\t8191\t6, 07\t6, 19\nVolcano Skier\t8192\t5, 52\t6, 03\nSurfers\t8206\t6, 43\t6, 41\nMotorcycle\t8251\t6, 16\t6, 05\nWingwalker\t8341\t6, 25\t6, 4\nBiking/train\t8475\t4, 85\t6, 52\nWoman\t8620\t6, 04\t4, 6\n### Caption\nVisual stimuli from the International Affective Picture Systems (IAPS).\n### Footer\nNone\n\n\n## ID: T2\n### Label: Table 2\nGroup 3 >Group 1\tGroup 2 > Group 1\tGroup 3 > Group 2\nLeft amygdala\t\u00d7\t\u00d7\nRight amygdala\t\u00d7\t\u00d7\nRight orbital gyrus\t\u00d7\t\u00d7\nRight dorsolateral prefrontal cortex (inferior frontal gyrus)\t\u00d7\tRight dorsolateral prefrontal cortex (inferior frontal gyrus)\nRight medial frontal gyrus\tRight medial frontal gyrus\t\u00d7\nLeft medial frontal gyrus\tLeft medial frontal gyrus\t\u00d7\nRight fusiform gyrus\tRight fusiform gyrus\t\u00d7\nLeft parahippocampal gyrus\t\t\nRight parahippocampal gyrus\t\u00d7\tRight parahippocampal gyrus\nRight temporo-occipital junction\t\u00d7\tRight temporo-occipital junction\nLeft temporo-occipital junction\t\u00d7\tLeft temporo-occipital junction\nLeft parieto-occipital junction\t\u00d7\t\u00d7\nRight posterior cingulate\t\u00d7\t\u00d7\nLeft posterior cingulate\t\u00d7\tLeft posterior cingulate\nLeft anterior insula\t\t\nRight and left colliculi\t\u00d7\t\u00d7\nRight pulvinar\t\u00d7\t\u00d7\nLeft medial thalamus\t\u00d7\tLeft medial thalamus\nRight medial thalamus\t\u00d7\t\u00d7\nRight hypothalamus\t\u00d7\t\u00d7\nVermis\t\u00d7\t\u00d7\n### Caption\nCerebral activations for the 18 healthy subjects for the 3 comparisons between the 3 levels of emotional intensity: Group 1, during viewing of low intensity stimuli; Group 2, during viewing of medium intensity stimuli; Group 3, during viewing of high intensity stimuli.\n### Footer\nAnalyses were based on random effects (RFX) GLMs of the z-normalized volume time courses using a statistical threshold of p < 0.05 corrected for FDR.\n\n\n## ID: T3\n### Label: Table 3\nArea (p < 0.001)\tBA\tx\ty\tz\tPeak (max t-value)\tSize (voxels)\nLeft amygdala\t\t\u221222\t\u22128\t\u22129\t5.134\t777\nRight amygdala\t\t17\t\u22122\t\u221212\t5.13\t750\nVermis\t\t\u22124\t\u221259\t\u221243\t6.081\t923\nRight fusiform gyrus\t20.0\t32\t\u221241\t\u221218\t6.739\t3139\nRight orbital gyrus\t47.0\t29\t13\t\u221218\t7.477\t1898\nRight temporo\u2212occipital junction\t37.0\t38\t\u221259\t9\t6.445\t5821\nLeft temporo\u2212occipital junction\t37.0\t\u221253\t\u221271\t3\t6.943\t3838\nRight parahippocampal gyrus\t28.0\t23\t\u221229\t\u22129\t4.91\t1698\nLeft parahippocampal gyrus\t28.0\t\u221210\t\u221235\t\u22129\t5.923\t1907\nRight colliculus\t\t6\t\u221232\t\u22122\t4.848\t112\nLeft colliculus\t\t\u22125\t\u221235\t\u22127\t5.126\t209\nRight pulvinar\t\t11\t\u221232\t3\t5.291\t1059\nLeft parieto\u2212occipital junction\t19.0\t\u221216\t\u221259\t3\t4.788\t377\nRight posterior cingulate\t23.0\t2\t\u221256\t18\t5.473\t1579\nLeft posterior cingulate\t23.0\t\u22122\t\u221259\t21\t5.007\t534\nLeft medial thalamus\t\t\u22124\t\u221214\t\u22123\t7.386\t1259\nRight medial thalamus\t\t0\t\u221214\t\u22123\t5.956\t556\nRight dorsolateral prefrontal cortex (inferior frontal gyrus)\t9.0\t38\t10\t27\t6.032\t1926\nLeft anterior insula\t\t\u221234\t28\t0\t4.119\t68\nRight hypothalamus\t\t13\t\u22122\t\u221212\t4.755\t158\nLeft medial frontal gyrus\t10.0\t\u22121\t55\t9\t4.766\t979\n### Caption\nCerebral activations for the 18 healthy subjects when testing Group 3 (during viewing of high intensity stimuli) against Group 1 (during viewing of low intensity stimuli).\n### Footer\nAnalyses were based on random effects (RFX) GLMs of the z-normalized volume time courses using a statistical threshold of p < 0.05 corrected for FDR. Size (voxels), size of the cluster in number of connected voxels of 1 mm3; x, y, z, Talairach coordinates of the maximum peak. BA, Brodmann area.\n", "metadata": {"pmcid": 4493392, "text_md5": "d29469715e3d7528d1542932dd7e40d0", "field_positions": {"authors": [0, 130], "journal": [131, 151], "publication_year": [153, 157], "title": [168, 256], "keywords": [270, 340], "abstract": [353, 1644], "body": [1653, 37856], "tables": [37869, 42880]}, "batch": 2, "pmid": 26217205, "doi": "10.3389/fnbeh.2015.00178", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4493392", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4493392"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4493392\">4493392</a>", "list_title": "PMC4493392  The role of the amygdala in the perception of positive emotions: an \u201cintensity detector\u201d"}
{"text": "Wack, David S. and Cox, Jennifer L. and Schirda, Claudiu V. and Magnano, Christopher R. and Sussman, Joan E. and Henderson, Donald and Burkard, Robert F.\nPLoS One, 2012\n\n# Title\n\nFunctional Anatomy of the Masking Level Difference, an fMRI Study\n\n# Keywords\n\n\n\n# Abstract\n \n## Introduction \n  \nMasking level differences (MLDs) are differences in the hearing threshold for the detection of a signal presented in a noise background, where either the phase of the signal or noise is reversed between ears. We use N0/N\u03c0 to denote noise presented in-phase/out-of-phase between ears and S0/S\u03c0 to denote a 500 Hz sine wave signal as in/out-of-phase. Signal detection level for the noise/signal combinations N0S\u03c0 and N\u03c0S0 is typically 10\u201320 dB better than for N0S0. All combinations have the same spectrum, level, and duration of both the signal and the noise. \n\n\n## Methods \n  \nTen participants (5 female), age: 22\u201343, with N0S\u03c0-N0S0 MLDs greater than 10 dB, were imaged using a sparse BOLD fMRI sequence, with a 9 second gap (1 second quiet preceding stimuli). Band-pass (400\u2013600 Hz) noise and an enveloped signal (.25 second tone burst, 50% duty-cycle) were used to create the stimuli. Brain maps of statistically significant regions were formed from a second-level analysis using SPM5. \n\n\n## Results \n  \nThe contrast N\u03c0S0- N0S\u03c0 had significant regions of activation in the right pulvinar, corpus callosum, and insula bilaterally. The left inferior frontal gyrus had significant activation for contrasts N0S\u03c0-N0S0 and N\u03c0S0-N0S0. The contrast N0S0-N0S\u03c0 revealed a region in the right insula, and the contrast N0S0-N\u03c0S0 had a region of significance in the left insula. \n\n\n## Conclusion \n  \nOur results extend the view that the thalamus acts as a gating mechanism to enable dichotic listening, and suggest that MLD processing is accomplished through thalamic communication with the insula, which communicate across the corpus callosum to either enhance or diminish the binaural signal (depending on the MLD condition). The audibility improvement of the signal with both MLD conditions is likely reflected by activation in the left inferior frontal gyrus, a late stage in the what/where model of auditory processing. \n\n \n\n# Body\n \n## Introduction \n  \nThe brain takes advantage of phase differences of binaural auditory stimuli to improve listening ability. An example is that a signal presented within a noise background can have greater than a 10 dB lower (better) detection threshold if it is presented out-of-phase rather than in-phase between ears, when the noise is interaurally in phase. The difference between these signal detection thresholds is known as a masking level difference (MLD). The contrasted stimuli used to determine MLDs can be identical in terms of intensity level, spectrum, and duration, yet the audibility of the signal is very different. The full neural network specific to the processing of binaural MLD stimuli is not well understood, nor has it been extensively investigated using functional imaging. We therefore utilize functional magnetic resonance imaging (fMRI), to localize neural regions involved in MLD processing. \n\nLicklider (1948)  , by altering the phase of speech presented in a noise background, found intelligibility highest with noise in-phase between ears, and the speech 180\u00b0 (\u03c0 radians) out-of-phase between ears. Hirsh (1948)   showed a detection advantage for a tone presented binaurally in background noise if the tone source was 180\u00b0 out-of-phase between the two ears, compared to when both channels of the tone were in-phase. Following Hirsh\u2019s work, psychoacoustic studies were performed to characterize the influence of the frequency of the signal, the bandwidth of the noise, and the phase and level differences between ears in affecting the magnitude of the MLD  \u2013 . In an experiment that increased the masker from 5 to 65 dB SPL (sound pressure level), the MLD increased from 3.5 to roughly 15 dB  . The magnitude of the MLD has been found to decrease as the center frequency of the masker (signal frequency) increased  , and increase with a decrease in the bandwidth of the masker. There is an increase in the magnitude of the MLD with an increase in the duration of the signal up to approximately 500 ms  ,  ,  . Interaural phase and time delay differences of the noise and signal have also been investigated. The best detection (lowest signal threshold level) occurred when either the signal or noise was 180\u00b0 out-of-phase  ,  . \n\nWe denote stimuli presented in-phase between ears with a 0, and \u03c0 (radians) if presented out-of-phase. Both N0S\u03c0 (noise in-phase, signal out-of-phase) and N\u03c0S0 (noise out-of-phase, signal in-phase) have a signal detection advantage compared to N0S0 (noise in-phase, signal in-phase). The MLD is the difference in the participant\u2019s signal intensity threshold between MLD conditions, N0S\u03c0 or N\u03c0S0, and the control condition N0S0. The MLD found with the N0S\u03c0-N0S0 comparison is typically larger (on the order of 2 dB) than N\u03c0S0-N0S0 comparison. Both are typically over 10 dB, and in individual cases can be greater than 20 dB  ,  . \n\nIt is reasonable to expect auditory regions such as the inferior colliculus (IC) and auditory cortex (AC) to play an important role in the neural processing of MLD stimuli, and these regions have been investigated in animals. A series of studies by Jiang et al.  ,   and Palmer et al.   showed differences in neuron firing rates in the IC of the guinea pig related to S0 and S\u03c0, whereas the condition N\u03c0 created little if any response, likely due to the de-synchronization of the stimuli. A study by Guo and Burkard   showed an increased near-field response in the auditory cortex (AC) of the chinchilla for MLD conditions compared to the control condition. \n\nHuman studies using electroencephalogram (EEG) recordings have indicated a cortical rather than brainstem MLD response. For example, Fowler and Mikami   showed that the slow vertex component P2 thresholds for signal detection in both N0S\u03c0 and N0S0 conditions increased linearly with increasing noise level. N0S\u03c0 increased with a smaller (better detection) slope than N0S0, consistent with the findings that the MLD increases for higher overall intensity levels. In a follow up study  , Fowler and Mikami were unable to show an MLD in the middle latency response (MLR); the MLR is thought to arise from midbrain, thalamic and cortical regions of the auditory nervous system  . Wong and Stapells   used an amplitude-modulated signal component to evoke an auditory steady state response (ASSR), and found an MLD for the 7 and 13 Hz modulations rates for N0S\u03c0-N0S0, but not for N\u03c0S0-N0S0. Neither showed a difference at 80 Hz rates. Ishida and Stapells   were unable to find an MLD for the 40-Hz ASSR. These ASSR findings parallel the previous studies, if one accepts the view that ASSR modulation frequencies (>70\u201380) Hz result from superimposed brainstem response, those near 40 Hz reflect superimposed midbrain, thalamic and early cortical responses, and those of very low frequencies (<20 Hz) represent superimposed cortical responses. \n\nAnimal-based studies have investigated specific sites such as the IC and AC, whereas human-based psychoacoustic or evoked potential studies are less localizing. Dichotic listening studies, which use language-based tokens and require a participant to attend to a target in either ear, suggest a high level involvement (that includes the thalamus) may be required for processing the MLD. These studies often find a right ear advantage (REA) in attending to stimuli in the right ear, when competing tokens are presented in the left ear, as opposed to vice versa. Kimura proposed a model explaining REA, which included a right to left hemisphere crossing of auditory (speech) information  . Perceptually, differences in MLD conditions can be quite large, although acoustically the different MLD conditions are very close to each other, and typically only differ in the phase between ears of the noise or signal. Using these stimuli in an imaging study would allow the isolation and focus on the small differences between conditions. \n\nPositron Emission Tomography (PET) and functional Magnetic Resonance Imaging (fMRI) imaging have been used to locate neural regions associated with auditory tasks, by comparing sequential image intensity values in relationship with changes in an auditory condition. In the case of H 0  PET the changes in image intensity values are related to regional cerebral blood flow, in the case of BOLD fMRI the changes are due to changes in the oxygenation of the hemoglobin. Herein, we use the term \u201cactivation\u201d to refer to a neural region which has statistically significant differences in image values for one condition versus another. Dichotic listening using consonant-vowel and musical-instrument stimuli together with the effect of attention was investigated by Hugdahl et al.  \u2013  using  O PET, which measured changes in oxygen utilization. This was followed by fMRI work which typically used dichotic word or syllable stimuli  \u2013 . Budd et al.   used dichotic noise stimuli with varying levels of interaural correlation. Chait et al.   used MEG to study Huggins pitch (a dichotic pitch paradigm) and iterated ripple noise (a diotic pitch paradigm). Hall and Plack  ,   and Barker et al.   used fMRI to study these same stimuli and found activations in the auditory cortex. Puschmann et al.   used tones in noise (N\u03c0S0), Huggins pitch, binaural band pitch and N\u03c0 noise, and also found pitch related activations in the auditory cortex. Ernst et al.   found regions that were mainly sensitive to the signal to noise ratio within and adjacent to lateral Heschl\u2019s gryrus. A follow up study found regions in the auditory cortex related to co-modulation masking release  . \n\nIn the present exploratory investigation, we postulate that listeners will have a regionally different neural activation in response to the MLD-dichotic conditions (e.g., N0S\u03c0) than to the MLD-reference (e.g., N0S0) conditions. Specifically, we will compare a listener\u2019s BOLD level response to each of the MLD dichotic conditions: N\u03c0S0, N0S\u03c0, N0SL (noise in-phase, signal left ear only), and N0SR (noise in-phase, signal right ear only), to the BOLD level response while listening to the MLD reference condition N0S0 (i.e. N\u03c0S0 vs. N0S0, N0S\u03c0 vs. N0S0, etc.). Because the present study is intended to be exploratory, we hypothesize, for the purposes of our analysis, that any brain voxel could show activation differences between MLD conditions. However, based on related MLD animal studies, we expect differences to be in more rostral regions of the central auditory nervous system, including the IC and AC. Furthermore, we conjecture there will be cortical differences in a listener\u2019s BOLD response between the MLD dichotic conditions N\u03c0S0 and N0S\u03c0 based on the commonly observed behavioral and EEG differences observed   between these MLD conditions. \n\n\n## Methods \n  \n### Participants \n  \nThe study protocol was approved by the University at Buffalo, Health Science IRB; all participants gave their informed written consent prior to auditory screening. Participants had to meet the following criteria: be between the ages of 18 and 45 years; be right-handed; have pure tone hearing thresholds of 25 dB HL or better for frequencies 250 Hz - 8000 Hz for each ear; and have a N0S\u03c0 - N0S0 MLD of 10 dB or greater. Participants underwent screening and MLD threshold testing in a sound booth within a week prior to MRI testing. \n\n\n### Auditory Testing \n  \nSignal threshold testing was performed in a sound booth for conditions: N0S0, N0S\u03c0, N\u03c0S0, N0SL, and N0SR. Threshold determination used a forced-choice design with three one-second length noise segments which were separated by.5 seconds and presented at 75 dB SPL. Participants had to determine which segment also included an enveloped 500 Hz tone as the signal. Testing started with a signal level of 85 dB SPL. This signal level stayed the same until the participant was able to correctly identify the signal two times in a row, or was unable to correctly identify the signal once. If the participant was unable to detect the signal, the signal level increased; if the participant was able to detect the signal in two successive trials at the same signal level, the signal level decreased. Seven direction changes were used. Step sizes between level changes were 8, 4, 4, 4, 2, 2, 2 dB. The average of the last two reversals was used as the threshold. MLDs were calculated by subtracting N0S0 threshold from the thresholds found for: N0S\u03c0, N\u03c0S0, N0SL, and N0SR. Participants additionally underwent a forced choice signal lateralization test, and identified randomly presented 1 second segments of N0SL, N0S0, or N0SR, as \"Signal Left\", \" Signal Both\", or \"Signal Right\" for 30 presentations. The tone signal was presented 3 dB above the participant's N0S0 signal threshold. \n\n\n### Stimuli Construction \n  \nConditions were created by summing together noise and signal segments using MATLAB (Natick, MA). The signal was a 500 Hz sine signal, presented in bursts lasting 250 ms with a 25 ms rise and fall time, presented every 500 ms. The noise for the presentations was created by sampling a very long duration of noise (approx. 10 minutes) created and filtered using a 400\u2013600 Hz band-pass, equi-ripple finite impulse response (FIR) filter, with order 1064, having 50 dB attenuation +\u2212 100 Hz, designed with the Filter Design and Analysis Tool in Matlab. The program used calibration values of noise and signal intensity as a program parameter. Calibration measurements were made using a Larson Davis System 824, with acoustic coupler AEC101 IEC 318 (LD-SLM) of individual noise and signal segments. The signal and noise were summed together by randomly choosing a point in the band-passed noise segment, and searching forward for 2 ms (one cycle of the signal) to determine the starting point that would give the highest correlation between the noise and signal. After selecting a starting point, one second each of noise and signal were summed together for the sound booth stimuli, and eight-second segments were summed together for the scanner stimuli. The noise used a.1 second ramp filter at the start and end of each stimulus. \n\n\n### Acoustic Calibration \n  \nMRI-compatible headphones from Resonance Technologies, Inc. (Northridge, CA) were tested and levels calibrated using the LD-SLM. Signal phase between ears was checked using a single cycle sine wave as input to the headphones and was measured through the LD-SLM with an oscilloscope (Tektronix TDS3012). Based on our findings, the stimuli were corrected in software to compensate for reversal of phase (180\u00b0) by the headphones. The scanner headphone acoustic output was evaluated with a Stanford Research System Model SR785, Dynamic Signal Analyzer (DSA), to determine the frequency response to the noise and signal. In response to the 400\u2013600 Hz band-pass noise, resonances in the acoustic system showed a maximum peak in the 600\u2013700 Hz range. For this reason, a shortened version of the MLD testing was also performed with the scanner headphones to ensure that subjects had an MLD response with scanner headphones. The pure tone signal response of the headphones was also measured with the DSA, and didn't reveal any problems. Prior to each scanning session, presentation levels were verified using a Radio Shack model 33\u20132055 sound level meter, which was mounted to a fabricated coupler. Sennheiser 280 Pro headphones were used for the screening, and underwent similar testing and calibration. Correct phase of signal was observed between ears, as was a steep drop off below 400 Hz and above 600 Hz for the noise. \n\n\n### Scanner Room MLD Testing \n  \nMLD threshold testing in the scanner room using scanner headphones followed the same procedure used in the screening (described above), but used only five direction changes, and only two conditions: N0S0 and N0S\u03c0. This testing was used only for assessment of MLD effect size in the scanner environment. Signal level for fMRI presentation was determined separately using longer length segments such that participants could barely identify that the signal was present for the N0S0 condition, but could not identify if the signal was present 2 dB lower. This signal level was fixed for all stimulus conditions. \n\n\n### Scanner Conditions \n  \nScanner conditions were \"NoStim\" (No Stimuli), N0, N\u03c0, S0, S\u03c0, N0S0, N0S\u03c0, N\u03c0S0, N0SL, and N0SR. Each presentation lasted for eight seconds. Presentations followed one second of quiet, which was inserted to prevent an adaptation effect between scanner coil noise and stimuli. The scanner TA (acquisition time) was 3 seconds, resulting in 12 seconds between the start of consecutive conditions. Four sessions were collected for each subject. Each session presented each of the 10 conditions six times. The conditions were presented in randomly-chosen permutations with the provision that neighboring permutation end and start conditions could not be the same. Prior to each session, participants were instructed to \"listen for the signal\". After each session, participants were asked whether they were still comfortable. Each session included three frames prior to the stimuli presentation, which were discarded. \n\n\n### Scanning Parameters \n  \nMR Imaging was performed using a GE 3T Signa Excite HD 12.0 Twin Speed 8-channel scanner (General Electric, GE, Milwaukee, WI) with a maximum slew rate of 150 mT/m/ms and maximum gradient amplitude in each orthogonal plane of 50 mT/m (zoom mode). An 8-channel head coil (In Vivo Corporation, Orlando, FL) was used for all acquisitions. A high-resolution 3D fast spoiled gradient echo (FSPGR) scan was collected at a voxel size of 1\u00d71\u00d71 mm (acquisition matrix of 256\u00d7256, FOV 25.6 cm). 174 locations per slab were acquired, 1 mm thick, ensuring whole brain coverage. Echo/repetition time for the 3D FSPGR scan were TE/TR\u200a=\u200a4.1/9.1 ms, flip angle\u200a=\u200a20, 1 average, and bandwidth 19.23 kHz (150 Hz/px). 2D sparse functional imaging was performed with a TE\u200a=\u200a35 ms. and group delay \u200a=\u200a9 seconds, which provided nine seconds of \u201cquiet\u201d, during which the stimuli was presented, followed by TA\u200a=\u200a3 seconds during which the fMRI planes were actively acquired  ,  . 27 slices 4 mm thick were acquired with no gap, using a 128\u00d7128 acquisition matrix, and FOV\u200a=\u200a24.0 cm, for an in-plane resolution of 1.9 mm\u00d71.9 mm. \n\n\n### Processing \n  \nDicom image files were converted to NIfTI format using dcm2nii (MRIcron;  ). Realignment and co-registration of functional images to the participants T1 weighted image was performed using SPM5 ( ). Segmentation was performed on the participant's T1 image, which provided spatial normalization parameters for transforming the co-registered functional images into the coordinate system of the provided SPM templates. Scans were smoothed using an 8\u00d78\u00d78 mm Gaussian kernel. After using SPM5 to create the general linear model including all conditions for each session, SPMd   was used to identify outlying scans. Next, a first -level SPM analysis was then performed for each subject which included all four sessions, but excluded scans identified by SPMd as having greater than 30 times the median number of outlier voxels, or which had more than 1 mm total motion from the previous scan. The first-level analysis provides separate images showing activation for each individual for each contrast. A second-level analysis was then performed using the contrast images produced for each individual in order to make statistical parametric maps. \n\n\n\n## Results \n  \nFive female and five male participants were recruited. All met the inclusion criteria described above for the study. Male and female participants matched in age within 2 years and ranged in age from 23 to 43 years; the mean female and males ages were 29.2 and 29.8 years, respectively. After each scan session, all participants were alert when spoken with, and reported being comfortable. Each participant completed the full scanning session. \n\n### Auditory Testing Results \n  \nMean threshold values for N0S0, N0S\u03c0, N\u03c0S0, N0SL, and N0SR measured during the auditory testing performed in the sound booth were 68.6, 54.2, 56.4 59.0, and 59.0 dB SPL, respectively. Hence, the mean MLD for N0S\u03c0 \u2013N0S0 and N\u03c0S0\u2013 N0S0 were 14.4 and 12.2 dB, respectively. Mean MLDs for N0SL and N0SR were both 9.6 dB, but participants had up to an 8 dB imbalance between these two conditions. The N0SR-N0S0 MLD for participant 4 was zero. The mean N0S\u03c0 - N0S0 MLD measured using scanner headphones was 11.4 dB, with minimum and maximum values of 4 and 16 dB. Individual MLD thresholds are given in  , a comparison of the MLD thresholds measured in the soundbooth and scanner room is given in  . \n   Thresholds (measured in dB SPL) for detection of 500 Hz sinusoid signal in 75 dB SPL, 400\u2013600 Hz band-pass noise, with all measurements made in the sound booth.         A comparison between MLD condition measurements (in dB SPL) made in the sound booth and scanner room of the thresholds for detection of 500 Hz sinusoid signal in 75 dB SPL, 400\u2013600 Hz band-pass noise.      \nFor the lateralization testing, four participants had a 90% success rate or better, and three participants had a 30% success rate or worse (i.e. less than expected by chance). However, in less than 4% of responses did participants mistake the signal presented to the left as right, or vice versa. Since the signal was presented at 3 dB above the N0S0 threshold, it was on average \u223c13 dB above the thresholds for N0SL and N0SR. Individual lateralization results are provided in  . \n   Individual volunteer\u2019s confusion matrices for identifying whether the signal was presented to the \u201cLeft\u201d, \u201cBoth\u201d, or \u201cRight\u201d ear(s).      \n\n### MRI Results \n  \nIn   we describe all second-level analyses that meet the strict criterion of significance p<.05 correcting for family-wise error (FWE), and regions that meet a weaker \"trending\" criterion of p<.1, FWE, which for comparison was roughly equivalent to p<.00001 uncorrected, for voxel-wise comparisons. \n   Table of SPM activations for study contrasts.        \n\n### MLD: N0S\u03c0 vs. N0S0 \n  \nSecond-level random effects analysis revealed a small region reaching voxel-wise significance in the left inferior frontal gyrus (LIFG) for the contrast N0S\u03c0 - N0S0. The opposite contrast N0S0 - N0S\u03c0 showed a 1608 mm  region of significant activation, located in and around the right insula. \n\n\n### MLD: N\u03c0S0 vs. N0S0 \n  \nSecond-level analysis did not reveal any regions reaching significance using FWE correction for the contrast N\u03c0S0\u2013 N0S0. The maximum occurred within the LIFG, p<.0001, uncorrected, which we include in our   because of its similar location to the N0S\u03c0 \u2013N0S0 activation. Likewise the opposite contrast, N0S0-N\u03c0S0, did not reveal any significant or trending regions. The largest threshold region was located in left insula and planum polare (p\u200a=\u200a.167, FWE, cluster-wise). \n\n\n### N0S\u03c0 vs. N\u03c0S0 \n  \nThe contrast N\u03c0S0 - N0S\u03c0 had a widely-distributed set of regions which reached significance: left insula, right superior frontal gyrus, a region on the right side of the corpus callosum, and the right pulvinar thalami; three of these regions had significance p<.01, FWE, cluster-wise. Additionally, the right insula met our weaker cluster significance threshold of p<.1, FWE. Statistical parametric maps showing the (group) activation in the corpus callosum and pulvinar thalamus are shown in   and  . There were no regions which reached or approached significance for the contrast N0S\u03c0 - N\u03c0S0. \n   Two separate activation regions are seen within the corpus callosum for the group comparison using the 2  level contrast N\u03c0S0 - N0S\u03c0, threshold p<.001, uncorrected for family-wise error (FWE).  \nBecause the activation maps have been smoothed at 8\u00d78\u00d78 mm FWHM, there may appear to be an overlap of the activation with the ventricle seen on the high resolution T1 image, which we did not attempt to mask. The statistics for this cluster is an indication that there exists at least one point of activation within the cluster with true significance (p<.01, FWE, cluster-wise for the larger region,  ). Obviously, the true source of activation would be in the tissue region, as the region of significance would likely be near voxels with the highest t-scores, which are located within the corpus callosum. The large activation seen in the L. insula is also cluster-wise significant (p<.01). All conditions were presented using random permutation ordering to prevent possible cyclic responses or habituation effects being mix with the contrast of conditions. Furthermore, SPMd was used to prevent any possible influence of outliers or motion. \n  \n\n### Lateralization \n  \nSPM results for conditions involving N0SR and N0SL did not exhibit clear patterns. The contrasts N0SL vs. N0S0, N0SR vs. N0S0, and N0SL vs. N0SR had no regions of activation. The most notable results arose from the contrast N0SR \u2013 N0S\u03c0, which showed large activations in and around the left and right caudate nucleus. Individual participant results for contrasts involving N0SL and N0SR vs. N0S0 appeared inconsistent. We believe this might be due to differences in subjects' lateralization ability. To test this belief, an analysis using a participant's overall lateralization success (percentage correct) as a covariate was attempted, as was limiting the analysis to only participants who performed well on the lateralization task. The results of both post-hoc analyses did not reach significance, and likely suffered from limited power. \n\n\n### Other \n  \nWe also present comparisons between three noise-with-signal conditions versus the corresponding noise-only conditions: N0S0 vs. N0, N0S\u03c0 vs. N0, and N\u03c0S0 vs. N\u03c0. We found no activations between N0S0 and N0, in either direction. The opposite contrast, N0-N0S\u03c0, yielded two regions: one in the post-central gyrus that reached significance, and the other in the right STG that approached significance. The contrast N\u03c0S0-N\u03c0 revealed two regions that approached or reached significance: LIFG (similar in location to the contrasts N\u03c0S0-N0S0 and N0S\u03c0 \u2013N0S0), and right pulvinar thalamus. There were no activations for the opposite contrast, N\u03c0 -N\u03c0S0. \n\nWe hypothesized, but did not observe, activation in the primary auditory cortex with the N0S\u03c0 \u2013 N0S0 contrast. In  , we show the number of participants that presented increased activation in the R. STG (SPM T >1.0), as well as the number of participants showing decreased activation (SPM T <1.0). The cross hairs mark a location in the right STG where three participants exhibited an increase, three a decrease, and four had no change for the contrast N0S\u03c0 \u2013 N0S0. For the N0S\u03c0-NoStim contrast, a search of voxels with p<.01 (uncorrected) reveals a cluster of 3012 mm  in the left STG, which is cluster-wise significant, p\u200a=\u200a.035, FWE. There was a cluster located in the right STG, which did not reach significance with peak spm t value \u200a=\u200a5.5 and extent size of 1620 mm . For the contrast N0S0\u2013 NoStim there was a cluster with extent size 1207 mm  and peak spm t\u200a=\u200a5.19 in the left STG, and a cluster with extent size 1187 mm  with peak spm t\u200a=\u200a5.44 in the right STG, however neither cluster was statistically significant accounting for FWE. As a check of the processing, the contrasts S0\u2013 NoStim was examined for all subjects using a height threshold of p\u200a=\u200a.01, uncorrected. All but two subjects had a peak spm t value >3 located in both the left and right STG, with peak spm t\u200a=\u200a11.5. While no regions were significant for the second level analysis, there was a cluster of size 1100 mm  with peak spm t\u200a=\u200a5.8 located in the left STG, and a cluster with extent size 2185 mm  and peak spm t\u200a=\u200a8.12 located in the right STG, using a height threshold of p<.01, uncorrected. Hence for our tested Stim vs NoStim contrasts, we consistently observed clusters of voxels with moderately high spm t values located in the STG, as would be expected in response to auditory stimuli. \n   Activation seen in the right pulvinar thalamus for the group comparison 2  level contrast N\u03c0S0 - N0S\u03c0, threshold p<.001, uncorrected for FWE.       Left image: T1 image showing R STG.  \nMiddle image: subjects with a decrease in activation for N0S\u03c0 \u2013 N0S0. Right image: Image of number of participants with an increase in activation for N0S\u03c0 \u2013 N0S0. \n  \n\n\n## Discussion \n  \nOur study used functional imaging to search nearly the entire brain for neural correlates to the MLD. We did not find support for our hypothesis of activation associated with MLD (comparisons: N\u03c0S0 vs. N0S0, N0S\u03c0 vs. N0S0, N0SL vs. N0S0 and N0SR vs. N0SR) in more rostral regions of the central auditory nervous system, such as the IC and AC, which was based on animal model work  \u2013 . We do not rule out the involvement of these regions, but speculate that the functional anatomical variability of the AC prevented detection using voxel-wise statistics family-wise error corrected across the whole brain. However, our results do indicate clear neural correlates of the MLD in the insula, pulvinar thalamus, and corpus callosum. We interpret this activation pattern as consistent with the Kimura model for REA for speech processing  , and syllable-based dichotic-listening studies  \u2013 ,  \u2013 . \n\nThe main assumptions of Kimura's model are: 1) auditory information is principally processed in the temporal lobe contralateral to the ear of presentation; 2) the left hemisphere is more specialized for language/speech processing than the right (in particular for right-handed participants); 3) there is a decussation of auditory information from the right hemisphere across the corpus callosum to the left hemisphere (which is specialized for the processing of speech stimuli) for further processing; and 4) the ipsilateral pathway can be suppressed by the contralateral pathway  ,  . \n\nAssumption 1 is firmly established in the literature  , but is not addressed by our data, as all of our conditions (except the NoStim condition) are presented to both ears. Assumption 2 is supported by our data, as there was a significant cluster for the contrast N0S\u03c0 -NoStim with extent size 3012 mm  which reached significance within the left STG, whereas a cluster about half the size located in the right STG did not reach significance. The activation in the LIFG for the MLD contrasts: N0S\u03c0 - N0S0, N\u03c0S0\u2013 N0S0, and N\u03c0S0-N\u03c0 also fits with the left lateralization proposed by the \u201cwhat\u201d portion of the \u201cwhat\u201d/\u201cwhere\u201d model  \u2013 , which postulates that the neural processing of information will follow different pathways, depending on whether it is being processed based on recognition or localization. While the Kimura model is for speech, and we used tonal (500 Hz) stimuli, it is not unreasonable to expect a left-hemisphere dominant response, since the stimuli were not continuous but presented in short 250 ms enveloped bursts every half second. The left AC has been shown to respond well to temporal changes  , as would be required in the tracking of formants. We did not find significant regional activation in the right STG, for any of the contrasts using the \u201cNoStim\" condition or any other evidence to argue for right hemisphere dominance. \n\nActivation of the corpus callosum for the contrast (N\u03c0S0\u2013 N0S\u03c0) gives evidence of inter-hemispheric communication (part of assumption 3 of the Kimura model). While less common, corpus callosum activation has been previously observed, including in studies that involved stimulation requiring high inter-hemispheric communication  \u2013 . We were careful to guard against artifacts, and we believe this white matter activation to reflect a true processing path. The two contrasted conditions are similar perceptually compared to the other stimuli, and we did not observe any relative motion of the subjects between conditions. While we employed standard SPM realignment methods, we also eliminated scans that had more than 1 mm total motion from the previous scan. The conditions were presented in an order determined by random permutations, and hence all conditions were balanced in being presented both early and late in the presentation sequence. The contrasts in this study were all \u201cwithin\u201d subject, hence we do not expect an artifact due to spatial normalization differences, such as could be found if comparing between groups. Finally, we used SPMd to eliminate scans that had the possibility of being a transient, which was a cautionary step most others do not take, likely because of the increased difficulty of performing the analysis. \n\nWe note that differences between our MLD conditions N\u03c0S0 and N0S\u03c0 imply an underlying activation difference between at least one of the conditions and the control condition, N0S0. The noise portion of the stimuli has a wider bandwidth and a (generally) higher overall SPL than the sine-wave portion. Accordingly, we speculate that metabolic differences in processing are largely influenced by changes in the noise component of our stimuli. We conjecture that information of the noise signal for N\u03c0S0 crosses the corpus callosum, going from right to left hemisphere. We believe this ipsilateral (double crossing) noise signal may combine with the matching contralateral signal in the left insula, with a net suppression effect. Plausible evidence supporting this belief is seen by the activity decrease in the left insula for N\u03c0S0 compared to N0S0. \n\nIn contrast, we conjecture that the noise portion of N0S\u03c0 is suppressed earlier in the processing chain, perhaps in the right insula or pulvinar thalamus, which would support the reduced activity seen in the corpus callosum (contrast: N\u03c0S0\u2013 N0S\u03c0), and the large decrease in activation (1500 mm ) in the right insula (contrast: N0S0 - N0S\u03c0). Furthermore, we believe that the resulting combination of the noise signal with the ipsilateral auditory signal in the left insula is reduced as a result of the diminished inter-hemispheric transfer. Diagrams of our hypothesized release from masking models for the MLD conditions N\u03c0S0 and N0S\u03c0 are shown in   and  . While dichotic listening is generally believed to involve the transfer of auditory information across the corpus callosum, studies which have examined the effects of surgical sectioning of the corpus callosum indicate that primary auditory pathways are more towards the caudal end than the activation we found  \u2013  This could indicate that the contrast reflects a decrease in activity for the N0S0 condition. This is consistent with previous findings, where one subject   had an improved score for a left ear attention after the anterior sectioning of the corpus callosum. If nothing else, the contrast difference between N\u03c0S0\u2013 N0S\u03c0, shows that all dichotic stimuli are not treated similarly. The surgical studies used dichotic speech pairs (numbers or constant vowels). We suspect that auditory signals cross in the caudal portion of the corpus callosum, but the   differences   between conditions were not great enough to be observed. Again, white matter activation is rare, and the reason we found a difference may only be because we are observing both a slight increase and decrease compared to the control condition N0S0. \n   Diagram showing theorized release from masking processing paths for N\u03c0S0.  \nWhen the noise portion of the stimuli from the left ear arrives in the left hemisphere after crossing the corpus callosum, the subsequent combined noise component after mixing with matching but opposite-phase noise from the right ear is suppressed, because the combining signals lack coincidence. \n     Diagram showing theorized release from masking processing paths for N0S\u03c0.  \nWhen (if) the noise signal from the left ear arrives in the left hemisphere, after crossing the corpus callosum, it has already been greatly suppressed. The site of the original suppression could be at the right pulvinar thalamus or insula of the right hemisphere. \n  \nAssumption 4 of Kimura\u2019s model states that the ipsilateral pathway is suppressed; which has empirical support from the study by Pollmann et al.  , who found that patients with lesions in the posterior part of the corpus callosum showed a nearly 100% REA. Our data is not inconsistent with this, but neither does it support this element of the model. \n\n### Dichotic Listening \n  \nThe thalamus has been proposed as a gating system for speech (and possibly other stimuli) to be sent to more rostral brain regions  ,  , based on dichotic-listening experiments with patients undergoing stereothalamotomy. A dichotic-listening study by Fitch et al.   found that lesions in the posterior thalamus inhibited the processing of auditory stimuli, including attending to stimuli presented to a particular ear. If the pulvinar thalamus is acting as a gating mechanism in our study, we propose that it is triggered when the signal is present in the stimuli. The right pulvinar was observed as part of the large activation pattern for the contrast N\u03c0S0 - N0S\u03c0 (  and  ). The results also revealed activation in the pulvinar thalamus for the contrast N\u03c0S0\u2013 N\u03c0 (p\u200a=\u200a.025, FWE, cluster-wise), which gives another example of its responsiveness to the presence of the signal in background noise. As a final example, if the signal is removed from the contrast of MLD conditions N\u03c0S0-N0S\u03c0 (which had strong activations), the resulting contrast, N\u03c0-N0, has no regions with significant activation. The reverse contrast, N0-N\u03c0, yielded a very different activation pattern, with significant activation found in the left and right angular gyrus, right cingular gyrus, right posterior cingulate, right medial gyrus, and right inferior frontal gyrus. \n\n\n### Lateralization \n  \nOur study's focus was on finding neural correlates associated with the MLDs, and we have reported on the primary focus of the study. In addition to the MLD conditions N0S\u03c0 and N\u03c0S0, we used the MLD conditions N0SL and N0SR. These conditions have an interesting place in the hierarchy of the MLD conditions, since starting from the N0SL or N0SR condition, the addition of the signal in-phase to the opposite ear becomes N0S0, or becomes N0S\u03c0 if the added signal is \u03c0 radians out-of-phase. Based on pilot testing, we believed that participants would be able to distinguish between the signal being presented to the left, right or both ears, amid the noise background. \n\nLateralization testing with MLDs is not normally performed, and has only infrequently been reported in the literature  . The results of the lateralization testing, which was only performed during the screening session (in the soundbooth) were very mixed, with four participants performing very well, and three very poorly (slightly less than expected by chance). Yet, overall, in less than 4% of responses did participants mistake the signal presented to the left as right, or vice versa. The signal was presented at 3 dB above the N0S0 threshold, and was on average \u223c13 dB above the thresholds for N0SL and N0SR. The thresholds for N0SL and N0SR were also mixed. For example, one subject\u2019s MLD for N0SR was 0 dB. By basing the signal level on the N0S0 condition, we effectively made the lateralization harder on those who may have had a more effective strategy for N0S0 signal detection. The remainder of MLD behavioral testing was unremarkable. For example, we observed N0S\u03c0 was roughly 2 dB better than N\u03c0S0  , which was roughly 2.5 dB better than N0SL or N0SR. Based on the lateralization results, we will assume that at least some of the participants were unable to lateralize the location of the signal while in the scanner. The perceptual difference for a signal presented in-phase and out-of-phase diminishes at levels above threshold  , therefore we did not consider a higher signal level. \n\nLack of a strong finding in our hypothesized regions of AC and IC has some support from previous studies. We believe our results to be consistent with a study by Hall and Plack  ,  , which used dichotic stimuli to investigate Huggins pitch, where the perception of pitch was created by linearly changing the phase between ears through 1 cycle of a small band centered around 200 Hz of broadband noise. In their study, Huggins pitch was contrasted against a \u201cjust-noise\u201d condition, whereas we contrasted our MLD conditions against N0S0, which has a detectable pitch due to the presence of the (audible) in-phase 500 Hz stimulus. As both MLD and non-MLD conditions had a detectable tonal stimulus in our study, we expect our \u2018pitch\u2019 vs. control contrast to be smaller than that found by Hall and Plack. In a study using 16 participants, Hall and Plack had comparisons between pitch and noise that did not identify a single pitch center common to all listeners   (pg. 579). However, as an indication of the between-subject anatomical variability of the auditory cortex, they were able to find regions sensitive to pitch stimuli in most subjects, but in slightly varying locations. Hence, our lack of finding any MLD-related activation in the AC is not surprising. In our study we had fewer subjects, and we limited ourselves to FWE statistics corrected for the whole brain as a search region. The advantage of our approach is that we were able to find regions we didn\u2019t originally specify (e.g. pulvinar thalamus); our disadvantage is that our analysis methods are less sensitive than studies that limit their search to the auditory cortex. \n\nThe MLD conditions, when compared to the no stimulus condition (N0S0 - NoStim and N0S\u03c0 - NoStim), only showed one cluster which was significant, which was located in the left STG for contrast N0S\u03c0 \u2013 NoStim. However, for both contrasts, there were clusters in both the left and right STG with peak spm t value greater than 5 and size greater 1100 mm , when using a height threshold of p\u200a=\u200a.01, uncorrected. Examination of individual results for contrast S0\u2013 NoStim showed that there was large variability in responses between individuals ranging from two subjects having only a weak activation in either the left or right STG to one subject that had peak t values greater than 11 (bilaterally). We believe that the weakness of these contrasts is likely the result of anatomical variability. Also, given that our instructions to the subject was to \u201clisten for the signal\u201d, different subjects may have treated the absence of stimuli ambiguously  . We\u2019ll note that we consider our true control condition for the study to be N0S0, and that the \u201cNoStim\u201d condition was intended primarily to test the processing path. We believe that our finding for N0S0\u2013 NoStim in which the signal portion (S0) is barely audible, is similar to that by Hart et al.  , who on a larger data set (12 participants versus our study\u2019s 10 participants, 28 repetitions vs. our study\u2019s 24, and using a presentation level of 90 dB SPL compared to our presentation level of 75 dB SPL), reported no activation for stationary unmodulated (i.e. constant) tones. \n\nOur study compared conditions that were the same in intensity, spectrum, and duration, and we expected neural activation differences because of the perceptual differences. Yet the conditions used in the contrasts with the two largest activation patterns, N\u03c0S0 - N0S\u03c0 and N0 - N\u03c0, are close enough that perceptually they may be hard for some to distinguish, in the same way that some may not recognize stereo speakers or headphones as being wired out of phase. Our rationale for comparing N\u03c0S0 and N0S\u03c0 was based on the findings of Wong and Stapells  , who found an auditory steady state response MLD for modulation frequencies of 7 or 13 Hz for the N0S\u03c0 versus N0S0 comparison, but not for the N\u03c0S0 vs. N0S0 contrast. That we find greater activation for N\u03c0S0 than N0S\u03c0, yet the auditory evoked response MLD was seen only for N0S\u03c0, could be due to the auditory evoked response being sensitive to the signal portion of the stimulus (i.e., phase locked to the envelope of the signal), while the fMRI finding was driven by the noise portion of the stimulus, as we previously argued. \n\n\n### Strengths and Weaknesses \n  \nOur design approach was purposely broad (using 10 conditions) and exploratory in nature. Utilizing fMRI, we were able to search nearly the entire brain for activation patterns in response to MLD conditions. The benefit of our broad approach was that we achieved strong and interesting results outside of our stated study hypothesis, while within our SPM analysis hypotheses. We opted against the use of a button press for monitoring a participant\u2019s attention in order to avoid potential conflicting neural activations; participants were instead instructed to listen for the signal. We believe this approach was sufficient for our set of attentive and well-intentioned participants. The participants, as observed through conversation with the scanners communication system, remained alert throughout the study. SPMd was used as a final guard to identify and eliminate scans which may have been influenced by system transients or brief, unexpected participant behavior or focus. \n\nA sparse MRI sequence allowed the stimuli to be presented during periods of relative quiet, and provided a better environment for listening for the modulated signal in the noise. We included a one second gap of \u2018no stimulus\u2019 between the end of the scanner data collection and the presentation to preserve a clear and consistent onset of the stimulus, and to prevent an auditory adaptation effect  ,   from the scanner noise. Since the band-passed noise component of the stimuli and 500 Hz tone are correlated, we went through the additional step of searching through 2 ms of the noise, to find the noise starting position that gave the maximum correlation, for a consistent presentation strategy  . The N0S0 threshold with the scanner headphones in the scanner room was approximately 2 dB better (lower) than in the sound booth. The lower threshold is likely related to a peak in the noise spectrum above 600 Hz for the scanner headphone, which implies a lower overall noise level near 500 Hz for the scanner vs. sound booth headphones. Also, this indicates that the use of a sound booth isn't critical, likely due to the 75 dB SPL background noise masking much of the environmental background noise. \n\nOur study enrolled 10 participants, and was limited by resources. This allowed sufficient power for our primary hypothesizes and contrasts, as many of our reported regions had p<.01, FWE, cluster-wise. Our analysis of a hypothesized region in auditory cortex showed that some participants had increased activations while some others had decreased activations. We believe this indicates that a moderate increase in the number of participants would not have appreciably improved our findings for our hypotheses. However, while we approached the analysis globally, a regionally-specific analysis of the auditory cortex (which also accounted for anatomical variability of the auditory cortex) may have been able to find significance. While we are satisfied with not using a button press for our main hypothesizes, we recommend that future work, if it focuses on lateralization, include a button press. \n\n\n### Conclusions \n  \nOur findings reveal a network of neural correlates associated with the MLD (that are outside of the previous focus of MLD research) which involves the pulvinar thalamus, the insulae, and a neural process that crosses the corpus callosum. These findings, in particular the involvement of the pulvinar thalamus, fit with the dichotic listening research, and are congruent with the proposed model of Kimura. \n\n\n \n\n# Table(s)\n## ID: pone-0041263-t001\n### Label: Table 1\nParticipant\tGender\tAge\tN0S0 (Ref)\tN0S\u03c0 (MLD)\tN\u03c0S0 (MLD)\tN0SL (MLD)\tN0SR (MLD)\n1\tM\t31\t67.0\t55 (12)\t55 (12)\t57 (10)\t57 (10)\n2\tM\t27\t63.0\t49 (14)\t55 (8)\t59 (4)\t59 (4)\n3\tF\t43\t67.0\t55 (12)\t55 (12)\t57 (10)\t61 (6)\n4\tF\t26\t65.0\t55 (10)\t55 (10)\t59 (6)\t65 (0)\n5\tF\t30\t73.0\t61 (12)\t59 (14)\t59 (14)\t65 (8)\n6\tM\t25\t67.0\t53 (14)\t55 (12)\t59 (8)\t57 (10)\n7\tF\t24\t77.0\t53 (24)\t57 (20)\t59 (18)\t57 (20)\n8\tM\t25\t71.0\t57 (14)\t61 (10)\t61 (10)\t57 (14)\n9\tM\t41\t65.0\t51 (14)\t53 (12)\t59 (6)\t51 (14)\n10\tF\t23\t71.0\t53 (18)\t59 (12)\t61 (10)\t61 (10)\nMean\t\t27\t68.6\t54.2 (14.4)\t56.4 (12.2)\t59.0 (9.6)\t59.0 (9.6)\n### Caption\nThresholds (measured in dB SPL) for detection of 500 Hz sinusoid signal in 75 dB SPL, 400\u2013600 Hz band-pass noise, with all measurements made in the sound booth.\n### Footer\nNone\n\n\n## ID: pone-0041263-t002\n### Label: Table 2\nSubject\tN0S0\tN0S\u03c0\tScannerMLD\tSound Booth MLD\n1.0\t63.0\t55.0\t8.0\t12.0\n2.0\t67.0\t53.0\t14.0\t14.0\n3.0\t63.0\t55.0\t8.0\t12.0\n4.0\t61.0\t57.0\t4.0\t10.0\n5.0\t73.0\t57.0\t16.0\t12.0\n6.0\t65.0\t53.0\t12.0\t14.0\n7.0\t67.0\t51.0\t16.0\t24.0\n8.0\t71.0\t59.0\t12.0\t14.0\n9.0\t65.0\t53.0\t12.0\t14.0\n10.0\t67.0\t55.0\t12.0\t18.0\n\t66.2\t54.8\t11.4\t14.4\n### Caption\nA comparison between MLD condition measurements (in dB SPL) made in the sound booth and scanner room of the thresholds for detection of 500 Hz sinusoid signal in 75 dB SPL, 400\u2013600 Hz band-pass noise.\n### Footer\nNone\n\n\n## ID: pone-0041263-t003\n### Label: Table 3\nParticipant No.\tLateralization % Correct\tResponse\tPresentation\tPresentation\tPresentation\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tUnnamed: 2_level_1\tLeft\tBoth\tRight\n1.0\t90.0%\tLeft\t4\t2\t0\n\t\tBoth\t0\t10\t1\n\t\tRight\t0\t0\t13\n2.0\t23.3%\tLeft\t0\t2\t2\n\t\tBoth\t3\t6\t12\n\t\tRight\t1\t3\t1\n3.0\t93.3%\tLeft\t6\t0\t0\n\t\tBoth\t0\t12\t1\n\t\tRight\t0\t1\t10\n4.0\t26.7%\tLeft\t4\t1\t3\n\t\tBoth\t1\t3\t5\n\t\tRight\t0\t12\t1\n5.0\t40.0%\tLeft\t3\t5\t2\n\t\tBoth\t1\t3\t5\n\t\tRight\t1\t4\t6\n6.0\t63.3%\tLeft\t1\t0\t1\n\t\tBoth\t3\t10\t2\n\t\tRight\t0\t5\t8\n7.0\t76.7%\tLeft\t4\t2\t0\n\t\tBoth\t1\t9\t1\n\t\tRight\t0\t4\t9\n8.0\t30.0%\tLeft\t6\t10\t1\n\t\tBoth\t4\t1\t6\n\t\tRight\t0\t0\t2\n9.0\t93.3%\tLeft\t6\t0\t0\n\t\tBoth\t0\t12\t0\n\t\tRight\t0\t2\t10\n10.0\t90.0%\tLeft\t5\t1\t0\n\t\tBoth\t0\t12\t0\n\t\tRight\t0\t2\t10\n### Caption\nIndividual volunteer\u2019s confusion matrices for identifying whether the signal was presented to the \u201cLeft\u201d, \u201cBoth\u201d, or \u201cRight\u201d ear(s).\n### Footer\nNone\n\n\n## ID: pone-0041263-t004\n### Label: Table 4\nContrast\tMNI Coor.\tLocation Label\tSize\tCluster P, FWE\tVoxel P, FWE\nUnnamed: 0_level_1\tx,y,z mm\tUnnamed: 2_level_1\tmm3\tUnnamed: 4_level_1\tUnnamed: 5_level_1\nN0S\u03c0-N0S0\t\u221252, 30, 10\tLIFG\t170\t0.737\t0.017\nN0S0-N0S\u03c0\t33,\u22127, 20\tR. Insula\t1608\t<0.001\t0.757\nN\u03c0S0-N0S\u03c0\t\u221234, \u22127, 21\tL. Insula\t2919\t<0.001\t0.809\n\t31, \u221222, 21\tR. Insula\t433\t0.091\t1.0\n\t10, 69, 14\tSuperiorFrontal Gyrus\t513\t0.047\t0.676\n\t14, 27, 10\tGenu CorpusCallosum\t566\t0.031\t0.999\n\t10, 13, 16\tCorpus Callosum\t1476\t<0.001\t0.386\n\t26, \u221224, \u22122\tR. Pulvinar Thalami\t2241\t<0.001\t0.201\nN0S\u03c0 \u2013 N0SL\t\u22128, \u221282, \u221215\tDeclive\t101\t0.955\t0.051\nN0SR-N0S\u03c0\t\u221222, \u22123, 23\tLeft Caudate Nucleus\t3618\t<0.001\t0.754\n\t27, 26, 18\tRight caudate Nucleus\t5835\t<0.001\t0.826\n\t18, \u221214, 37\tRight Cingulate Gyrus\t536\t0.027\t0.351\nN0-N0S\u03c0\t50, 11, 14\tPost. Central Gyrus\t551\t0.041\t1.0\n\t63, \u221253, 13\tR. STG\t465\t0.081\t0.836\nN\u03c0S0-N\u03c0\t\u221247, 31, \u22123\tLIFG\t932\t0.056\t0.988\n\t24, \u221232, 9\tR. Pulvinar Thalami\t575\t0.025\t0.999\nN0-N\u03c0\t\u221242, 60, 44\tLeft Angular Gyrus\t627\t0.023\t0.919\n\t51, \u221259, 34\tRight Angular Gyrus\t861\t0.004\t0.982\n\t4, \u221234, 31\tRight Cingular Gyrus\t1012\t0.002\t0.817\n\t10, \u221257, 26\tRight Posterior Cingulate\t456\t0.084\t0.813\n\t7, 43, 25\tRight Medial Frontal Gyrus\t1239\t<0.001\t0.982\n\t54, 24, 8\tRight Inferior Frontal Gyrus\t852\t0.005\t0.955\n### Caption\nTable of SPM activations for study contrasts.\n### Footer\nFor each region of activation; the values from SPM are reported, together with the best representative anatomical label.\n", "metadata": {"pmcid": 3407245, "text_md5": "3c061e00632b803d4d2a73007c87c076", "field_positions": {"authors": [0, 153], "journal": [154, 162], "publication_year": [164, 168], "title": [179, 244], "keywords": [258, 258], "abstract": [271, 2210], "body": [2219, 47602], "tables": [47615, 51333]}, "batch": 2, "pmid": 22848453, "doi": "10.1371/journal.pone.0041263", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3407245", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3407245"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3407245\">3407245</a>", "list_title": "PMC3407245  Functional Anatomy of the Masking Level Difference, an fMRI Study"}
{"text": "Kaufmann, C. and Beucke, J.C. and Preu\u00dfe, F. and Endrass, T. and Schlagenhauf, F. and Heinz, A. and Juckel, G. and Kathmann, N.\nNeuroimage Clin, 2013\n\n# Title\n\nMedial prefrontal brain activation to anticipated reward and loss in obsessive\u2013compulsive disorder\u2606\n\n# Keywords\n\nBrain imaging\nObsessive\u2013compulsive disorder\nReward\nPunishment\nCingulate gyrus\nMedial frontal gyrus\nSuperior frontal gyrus\nFMRI\nMonetary incentive delay task\n\n\n# Abstract\n \nObsessive\u2013compulsive disorder (OCD) is associated with dysfunctional brain activity in several regions which are also involved in the processing of motivational stimuli. Processing of reward and punishment appears to be of special importance to understand clinical symptoms. There is evidence for higher sensitivity to punishment in patients with OCD which raises the question how avoidance of punishment relates to activity within the brain's reward circuitry. We employed the monetary incentive delay task paradigm optimized for modeling the anticipation phase of immediate reward and punishment, in the context of a cross-sectional event-related FMRI study comparing OCD patients and healthy control participants (  n  \u00a0=\u00a019 in each group). While overall behavioral performance was similar in both groups, patients showed increased activation upon anticipated losses in a medial and superior frontal cortex region extending into the cingulate cortex, and decreased activation upon anticipated rewards. No evidence was found for altered activation of dorsal or ventral striatal regions. Patients also showed more delayed responses for anticipated rewards than for anticipated losses whereas the reverse was true in healthy participants. The medial prefrontal cortex has been shown to implement a domain-general process comprising negative affect, pain and cognitive control. This process uses information about punishment to control aversively motivated actions by integrating signals arriving from subcortical regions. Our results support the notion that OCD is associated with altered sensitivity to anticipated rewards and losses in a medial prefrontal region whereas there is no significant aberrant activation in ventral or dorsal striatal brain regions during processing of reinforcement anticipation. \n   Highlights  \n\u25ba OCD associated with bias towards avoidance of aversive stimuli. \u25ba Ventral/dorsal striatal brain activity during reward processing   not   altered in OCD. \u25ba Medial prefrontal brain activity mediates avoidance of aversive stimuli in OCD. \u25ba Medial prefrontal brain activity related to cortical processing of negative affect. \n \n\n# Body\n \n## Introduction \n  \nPatients with obsessive\u2013compulsive disorder (OCD) get stuck on a particular aversive thought or urge and just cannot let go compensatory behaviors like hand washing or controlling. Qualitatively similar thoughts or actions are common in everyday life but are usually terminated in time in non-OCD subjects. Empirically, there is strong evidence from resting state, symptom provocation as well as treatment studies that the disease is associated with dysfunctional brain structures including the basal ganglia, the thalamus, as well as frontal and parietal cortex structures ( ). Activation of these regions is provoked by cues associated with symptoms and appears to reflect processing of negative mood states ( ). Brain regions implicated in OCD are also involved in tasks related to monetary reward and punishment. From a clinical perspective, responses to anticipated reward and punishment may be crucial for obsessive\u2013compulsive behaviors. Compulsive behaviors are purported to reduce distress and anxiety ( ), that is they are experienced as immediate avoidance of punishment. There is also evidence for higher sensitivity to punishment in patients with OCD on the behavioral level ( ). It is therefore a central question of OCD pathopsychology how avoidance of punishment relates to activity within the brain's reward circuitry. \n\nSo far, two studies challenged the reward circuitry in obsessive\u2013compulsive disorder ( ). While   found no group differences,   reported attenuated activity within the dorsal striatum of OCD patients during reward anticipation. Additionally, Jung et al. found decreased activity within the dorsal striatum in OCD upon loss receipt while Figee et al. did not analyze loss receipt (because they restricted their experimental design to stimuli indicating reward). Therefore, heterogeneity of these results may be due to distinct differences in experimental task design. Nevertheless, both studies showed for the first time evidence for altered brain activity in OCD in the context of monetary incentive delay tasks. \n\nDuring the last decade the monetary incentive delay task paradigm ( ) was employed in numerous FMRI studies in health and disease ( ). The experimental paradigm in its original form is optimized for modeling the anticipation phase of immediate reward and punishment. In healthy participants anticipation of rewards and losses was repeatedly found to be associated with BOLD responses in thalamic, striatal and frontal brain structures in healthy subjects ( ). More specifically, mesial prefrontal cortex (MPFC) activity preferentially tracks rewarding outcomes ( ). Activity of a caudate region during anticipation of both reward and punishment was shown to code for expected outcome magnitude whereas ventral striatal activity was associated with expected positive incentive valence ( ). Dopamine release from ventral tegmental area (VTA) neurons projecting to cortical and subcortical regions is increased during reward expectancy ( ), and hence drives activity in the ventral striatum and the MPFC. Further, serotonergic transmission in the forebrain regulates decision making and motivated choices about obtaining reinforcers ( ). \n\nFollowing this line of research the aim of the present study was to elucidate neural correlates for the proposed hypersensitivity to punishment in OCD within the brain's reward circuitry using the monetary incentive delay task focusing on the anticipation phase of incentive processing. According to the literature we hypothesized that hemodynamic activity of the ventral and dorsal striatum, thalamus, cingulate and medial prefrontal cortex would be altered during anticipation of reward and punishment in OCD. Because of indecisive evidence with respect to increased or decreased brain activity in OCD patients relative to healthy controls we refrained from postulating directions of effects. We were additionally interested whether clinically assessed symptom severity and hemodynamic activity would be correlated. \n\n\n## Materials and methods \n  \n### Participants \n  \nPatients (n\u00a0=\u00a019) were consecutively recruited from the OCD outpatient clinic at the Humboldt-Universit\u00e4t zu Berlin. They fulfilled DSM-IV criteria for obsessive\u2013compulsive-disorder (300.3), and were currently or had recently been under treatment with cognitive-behavioral psychotherapy. The Structured Clinical Interview for DSM-IV (SCID; German version:  ) was used by a trained clinical psychologist not involved in the study to confirm clinical axis I diagnoses. Severity of OCD symptoms was evaluated using the Yale-Brown Obsessive Compulsive Scale (Y-BOCS:  ). Patients with past or present psychotic symptoms, or with past or present substance dependence, and with known or self-reported head trauma or neurologic disease were excluded. Ten patients had comorbid diagnoses (affective disorder,   n  \u00a0=\u00a07; phobic disorders,   n  \u00a0=\u00a03; impulse control disorder,   n  \u00a0=\u00a01; personality disorder,   n  \u00a0=\u00a03). Three out of the 19 patients were taking antiobsessional drugs (one clomipramine 10\u00a0mg/d, one venlafaxine 75\u00a0mg/d, and one a combination of clomipramine 75\u00a0mg/d and paroxetine 30\u00a0mg/d). No patient took benzodiazepines within 4\u00a0weeks before the scanning session. \n\nAdditional information with respect to symptom profiles according to the Y-BOCS symptom-checklist for all available OCD patients (  n  \u00a0=\u00a017), which were summarized using a recently described method ( ) is provided as   supplementary material   (Table S1a and b). \n\nParticipants of the control group (  n  \u00a0=\u00a019) were matched to the patients regarding gender, age, handedness, and verbal intelligence ( ). None of them had present signs or a history of psychiatric or neurologic disorder according to a SCID-I-based screening interview. They also reported to not having used psychoactive drugs during the past 3\u00a0months. \n\nAll participants had normal or corrected-to-normal vision. They completed a German vocabulary test (Wortschatztest, WST:  ), the Edinburgh Handedness Inventory (EHI:  ), and the State-Trait Anxiety Inventory (STAI:  ). OCD patients were additionally assessed using the Obsessive\u2013Compulsive Inventory-Revised (OCI-R:  ), and the Beck Depression Inventory (BDI:  ). All participants gave written informed consent according to the institutional guidelines before enrollment. The study was approved by the local ethics committee. \n\n\n### Task \n  \nThe task ( ) was adapted from the monetary incentive delay task (MID) as described by  . There were seven different types of trials: three trial-types with the possibility of winning money on a correct (i.e. timely) button press (reward trials), three trial-types with the possibility to avoid losing money on a correct button press (loss-avoidance trials), and in the remaining trial-type there were no monetary consequences at all (neutral trials). At the beginning of each trial, one of seven different cues was shown to indicate trial type. Participants were asked to press a button as soon as the target stimulus (gray colored square) appeared. Depending on the performance (i.e. timely motor response) participants received feedback about winning or losing money. Each run consisted of 72 trials, i.e. 27 gain, 27 loss, and 18 neutral trials with each trial lasting for 11.6\u00a0s on average (see   for details). Subjects performed the task three times in succession. The first run was a training session while structural MR-sequences were obtained, and the remaining two runs were conducted subsequently. Task difficulty was continuously adapted to come up with a 66% success level in each subject across a task run. This was achieved by using individually tailored reaction times of the training session, and by adapting the response deadline as a result of the averaged reaction times in previous trials and the correctness of the immediately preceding trial during the test runs. Participants effectively received the money they had earned in the game. After the end of the session, they reported whether they had in fact believed in this announcement. From the two task sessions during which FMRI was done, one was selected for final analysis. This selection was made with the aim to match patient and control groups for global performance according to their success level, i.e. total earnings. Selection was carried out blind to FMRI results. The number of sessions selected from first and second runs was comparable in patients and controls (OCD 8/11; controls 9/10). Subsequently, both runs were included in an additional analysis in order to ensure whether FMRI findings remain constant. \n\n\n### FMRI acquisition \n  \nData were acquired on a 1.5\u00a0T MR scanner equipped with a circular-polarized headcoil (Siemens Sonata, Erlangen, Germany) with an T2*-weighted single-shot gradient echo planar imaging sequence: 33 slices, 3\u00a0\u00d7\u00a03\u00a0\u00d7\u00a03.5\u00a0mm resolution, TE\u00a0=\u00a040\u00a0ms, TR\u00a0=\u00a01.87\u00a0s, flip angle\u00a0=\u00a090\u00b0, interleaved acquisition (from bottom to top), 450\u00a0AC-PC oriented images for each run. A vacuum head cushion was used to immobilize the participants' heads and necks in order to reduce movement artifacts. Earplugs were provided to attenuate background noise and additional headphones were used to communicate with subjects. Stimuli were generated using Presentation (Neurobehavioral Systems) and were projected by means of a mirror system attached to the head coil. Anatomical high-resolution T1-weighted scans (spatial resolution 1\u00a0\u00d7\u00a01\u00a0\u00d7\u00a01\u00a0mm, TR\u00a0=\u00a012.24\u00a0ms, TE\u00a0=\u00a03.56\u00a0ms, flip angle\u00a0=\u00a023\u00b0, 256\u00a0\u00d7\u00a0224 matrix) ( ) were acquired during the training session of the MID task. \n\n\n### Statistical analysis \n  \n T   tests for independent samples were computed to compare the samples for age, verbal intelligence, handedness, sum of earnings in the MID task, and STAI-X1 and X2 test scores. Behavioral data were analyzed with repeated measures ANOVAs (reaction times: group (2)\u00a0\u00d7\u00a0cue (7)); proportion of delayed responses: group (2)\u00a0\u00d7\u00a0condition (reward, neutral, loss-avoidance). FMRI data were analyzed with SPM8 ( ). First, the original data files were converted from Dicom to Nifti file format. The first four volumes of each functional time series were discarded in order to avoid non-steady state effects caused by T1 saturation. After slice time correction, all volumes were realigned to the first volume in order to correct for between-scan movements and to remove signals correlated with head motion. Motion correction estimation revealed that no subjects showed more than 2\u00a0mm head movement and more than one degree of rotation during one run. The anatomical data set was coregistered with the mean T2* image, and T1-weighted images were segmented into gray matter, white matter, and cerebrospinal fluid. The gray matter of the coregistered structural image was spatially normalized to the standard template provided by the Montreal Neurological Institute (MNI template) using an automated spatial transformation. The resulting transformation matrix was subsequently applied to the T2* data, and a resampling to a resolution of 3\u00a0\u00d7\u00a03\u00a0\u00d7\u00a03\u00a0mm voxel size was performed. Finally, the normalized images were smoothed with a Gaussian kernel (full width at half maximum) of 8\u00a0mm to create a locally weighted average of the surrounding voxels. FMRI data were then analyzed in the context of the general linear model ( ) by convolving the regressors with a canonical hemodynamic response function as implemented in SPM8. Data analysis was performed by modeling the different cue conditions. Changes in the BOLD response were assessed using linear combinations of the estimated GLM parameters (beta values) and are contained in the individual contrast images for the anticipation of monetary reward versus no consequence, and the anticipation of loss-avoidance versus no consequence, resulting in a   t   statistic for each voxel. To detect differences in BOLD responses, individual contrast images (i.e. the BOLD response differences) of all subjects in each group were included in a second-level random effects analysis with a group (2)\u00a0\u00d7\u00a0condition (2; anticipation of reward versus loss avoidance)\u00a0\u00d7\u00a0amount of consequence (3; low vs. medium vs. high) ANOVA model. All presented results relate to random effects analyses and thus include a group by subject response interaction term. In order to ensure valid statistics on the group level we employed an approach with partitioned error terms as implemented with GLMFlex (extension to SPM8: GLM Flex,  ) and two-sample   T   tests (which are not prone to false between-subjects statistics within SPM). Because between-subjects effects are overestimated within SPM8 for group model statistics, additional interaction terms for between-subjects error and within-factor error are included into second-level model analysis. Statistical significance for the main effects of condition was set to   p  \u00a0<\u00a0.05 (family wise error rate [FWE] whole-brain corrected for multiple measurements) for gain or loss\u00a0>\u00a0neutral;   p  \u00a0<\u00a0.05 (false discovery rate [FDR] whole-brain corrected for multiple measurements) for gain\u00a0>\u00a0loss, and to   p  \u00a0<\u00a0.01 (corrected with a cluster-size based correction for multiple comparisons) for group effects: By using a combination of probability thresholding and cluster thresholding the power of the statistical test is maximized while holding the likelihood of false positives to a minimum. The Alphasim program ( ) as implemented in Resting-State fMRI Data Analysis Toolkit V1.5 ( ) was used to determine the cluster threshold. The program is provided with the number of voxels in the group map, the spatial correlation of voxels, and the voxelwise threshold (in this study,   t  \u00a0>\u00a03.66,   p  \u00a0<\u00a0.001). A series of Monte Carlo simulations (10,000 iterations for our study) was then carried out to determine the frequency of each conforming cluster size produced purely by chance. From this frequency distribution, the cluster size (1701 microliter given our parameters) that occurs <\u00a01% of the time by chance could be selected, to give a threshold of   p  \u00a0<\u00a0.01 (corrected). Transformation from MNI to Talairach coordinates was performed according to  . For the correlation of BOLD contrasts in regions of interest with clinically assessed OCD symptom severity, Y-BOCS ratings were used. \n\n\n\n## Results \n  \n### Total earnings \n  \nMean earnings (\u00b1\u00a0  SD  ) amounted to \u20ac\u00a021.80\u00a0\u00b1\u00a07.80 in the OCD group and \u20ac\u00a022.00\u00a0\u00b1\u00a06.40 in the control group. Success rates were held close to 66% in each subject due to an adaptive procedure (see   section). \n\n\n### Types of responses \n  \nWe classified responses as correct, delayed or omitted. Omitted responses, i.e. no response or a response with a reaction time of more than 1000\u00a0ms, were rare with less than 2% in each group. Delayed responses, i.e. responses after the individually defined deadline but within 1\u00a0s, occurred with an overall rate of 31.6%. For delayed responses, there was no main effect of group,   F  (1,36)\u00a0=\u00a00.514,   p  \u00a0=\u00a00.48, and no main effect of condition (reward, neutral or loss-avoidance),   F  (2,35)\u00a0=\u00a00.11,   p  \u00a0=\u00a00.74, but a significant interaction of condition with group (  F  (2,35)\u00a0=\u00a04.098,   p  \u00a0=\u00a00.05). This interaction reflects that the OCD group showed fewer delayed responses in loss-avoidance trials (26.9%) than in reward trials (33.1%), whereas the opposite was true in the control group (29.6% vs. 25.1%, respectively, see  ). \n\n\n### Response times \n  \nResponse times are depicted in  . Mean response time was similar in the OCD group (222\u00a0ms\u00a0\u00b1\u00a036   SD  ) and the control group (218\u00a0\u00b1\u00a043), the main effect of group being non-significant (  F  (1,36)\u00a0=\u00a0.22,   p  \u00a0=\u00a00.64). There was a significant main effect of cue (  F  (6,31)\u00a0=\u00a022.25,   p  \u00a0\u2264\u00a00.001), but no interaction of cue with group (  F  (6,31)\u00a0=\u00a01.285,   p  \u00a0=\u00a00.293).   Post hoc   tests showed no differences between groups for any cue (all   p  \u00a0>\u00a00.13). \n\n\n### BOLD results \n  \n#### Condition effects \n  \nThe BOLD responses contrasting anticipation of reward or loss-avoidance with anticipation of the neutral condition revealed several active brain regions (Fig. S2 and Table S2) including bilateral cerebellum, (pre-) cuneus, midbrain, thalamus, dorsal striatum, ventral striatum, cingulate cortex, medial frontal cortex, precentral gyrus, insula, and parietal regions. In general, the pattern of activation was similar for both types of anticipated consequences but less pronounced for anticipation of potential loss. Significantly more activation in the reward than in the loss-avoidance condition was found in the striatum (dorsal and ventral) and the medial prefrontal cortex/cingulate gyrus (  p   FDR corrected at 0.05). No region was more activated in the loss-avoidance than in the reward condition at this threshold. In addition, we also found magnitude effects for the different cues (data not shown) similar to those previously reported by  . \n\n\n#### Group effects \n  \nThere was no main effect of group in the hypothesized brain regions of the reward circuitry, i.e. thalamic, dorsal and ventral striatal, cingulate, and medial frontal regions. To illustrate this finding,   shows BOLD contrast estimates for the head of the caudate nucleus and the ventral striatum. For the caudate nucleus, there were cue effects (  F  (6,31)\u00a0=\u00a010.81,   p  \u00a0\u2264\u00a0.01) but no group differences (  F  (1,36)\u00a0=\u00a00.83,   p  \u00a0=\u00a0.42), and also no interactions of group\u00a0\u00d7\u00a0cue (  F  (6,31)\u00a0=\u00a00.71,   p  \u00a0=\u00a0.64); similarly, for the ventral striatum cue effects (  F  (6,31)\u00a0=\u00a05.43,   p  \u00a0\u2264\u00a0.01), but no group differences (  F  (1,36)\u00a0=\u00a00.91,   p  \u00a0=\u00a0.37), and no interactions of group\u00a0\u00d7\u00a0cue (  F  (6,31)\u00a0=\u00a01.04,   p  \u00a0=\u00a0.29) were found. In order to corroborate these null findings we included both runs, disregarding overall behavioral performance. Again we did not find evidence for group differences in dorsal or ventral striatal regions even with a more liberal statistical threshold of   p  \u00a0=\u00a0.005 (uncorrected). \n\nAn interaction of group by condition (reward vs. loss-avoidance) was found in a medial prefrontal/cingulate region (  and  ) indicating differential activation patterns during anticipation of reward versus loss in OCD and control samples. This interaction was also observed at the same statistical threshold in an additional analysis controlling for trait anxiety. Trait anxiety was measured with the STAI-X2, and patients reported higher anxiety levels. We noted no other significant interactions of group with condition even at a more liberal threshold of   p  \u00a0<\u00a0.001, uncorrected. A supplementary analysis of a subgroup of patients without comorbid major depression and their matched healthy controls (  n  \u00a0=\u00a012 vs. 12) revealed similar results (Fig. S3). \n\nBoth runs were included in an additional analysis in order to ensure whether FMRI findings including all patients and controls remain constant. The interaction of group by condition diminished but remained at a more liberal threshold of   p  \u00a0<\u00a0.005, not corrected for multiple measurements (data not shown). \n\n\n#### Correlations of BOLD responses and symptoms \n  \nAfter extracting volumes of the ROIs, which were defined by the clusters showing significant group x condition interaction ( ), individual contrast parameters (gain and loss versus neutral) were computed and correlated with Y-BOCS ratings. Y-BOCS ratings did not correlate significantly with BOLD responses. \n\n\n\n\n## Discussion \n  \n### Behavioral performance \n  \nBoth groups showed comparable behavioral performance. Reaction times varied as a function of monetary value, i.e. decreased with increasing magnitude of the consequence. A two-thirds success level was established using an individual adaptation procedure for response deadlines. This was done because the reward system is best stimulated by rewards which have moderate predictability ( ): The effort a person expends on obtaining an object signaling reward (or avoiding loss), is highest for surprising rewards ( ) and decreases for random or continuously occurring reinforcement. Magnitude of reward expectation is therefore critical for maintaining a functional level of reward-directed behavior, which itself is associated with phasic dopaminergic release ( ). Likewise, in the MID task used in the present experiment anticipation of monetary gains or losses is assumed to motivate subjects to expend efforts in responding as quick as possible ( ). Because overall reaction times were not different between groups OCD is not associated with general slowing of motor responses, nor with any alteration of the global motivational level. \n\n#### Bias towards avoidance of aversive stimuli in OCD \n  \nPatients with OCD showed a relative decrease of delayed responses after loss-indicating cues compared to cues indicative for reward. This suggests that anticipated losses might have higher motivational significance than anticipated rewards. The effect size of the interaction was small which is comprehensible as groups were matched according to their general performance thus reducing possible effects. This finding fits well into clinical symptom descriptions ( ), and was recently described more formally in patients with hoarding symptoms as well as subjects with subclinical obsessive\u2013compulsive states ( ). Cognitive models of obsessive\u2013compulsive psychopathology state that patients overestimate the probability of negative events in unpleasant or threatening situations ( ). Accordingly, patients should be more motivated by loss-avoidance than by direct reward which is supported by our data. It is tempting to speculate that certain dimensions of OCD psychopathology show different sensitivity to reward and punishment. This would be clinically important because therapeutic strategies should then be adapted to such differential reinforcement sensitivity. Obsessive\u2013compulsive symptom dimensions have been shown to be underpinned by partly distinct cortical and subcortical brain activities ( ). Further research is needed to compare larger patient samples with variance in their symptom dimensions ( ) regarding sensitivity to reward and punishment. \n\n\n\n### BOLD results \n  \nBOLD responses for anticipation of potentially motivating consequences revealed activation patterns which were similar to those described in several previous studies ( ). Activations were found in key regions of the reward circuitry including the ventral striatum and the caudate nucleus, demonstrating that the experimental paradigm revealed expected results thus enabling us to test the hypothesis that OCD patients show altered neuronal responses during anticipation of secondary reinforcers. \n\n#### Similar subcortical brain activity during anticipation of reinforcement in OCD \n  \nWe observed no overall increase or decrease of brain activity in basal ganglia structures in OCD patients. Notably, key regions of the reward circuitry as the ventral striatum and the caudate nucleus showed similar activity in both groups during reward and loss anticipation. These results let us conclude that there is no global or trait-like hyper- or hypoactivity of the basal ganglia and connected cortical regions during anticipation of reinforcement. This finding is in agreement with  , who also did not find altered striatal brain activity in OCD patients during anticipation of secondary reinforcers. \n\n\n#### Discrepant findings in the literature \n  \nBut contrary to Jung et al. and our results   observed attenuated BOLD activity of the caudate nucleus during anticipation of reward in patients with OCD. Note, however, that the authors labeled their reported MNI coordinates as nucleus accumbens, although a Talairach based localization ( ) would better indicate a region in the dorsal striatum for these coordinates. \n\nStudies of the human striatal architecture distinguishing the ventral striatum from dorsal caudate also show that the localization of Figee et al.'s results correspond to a caudate brain region ( ). This inconsistency might be of importance in this context because conclusions based on nucleus accumbens or caudate nucleus would differ regarding the involved mesolimbic or nigrostriatal pathways ( ). It was shown that dorsal striatum codes for expected outcome magnitude whereas ventral striatal activity codes more for expected positive incentive valence ( ). \n\nAlso, study and task design differ in several important aspects: Symptom severity was higher in the patient sample of  . In addition, they presented rewarding consequences only but no loss trials. Further, a slow paced version of the task was used with the aim to disentangle anticipation and delivery of reward. Finally, the authors used a reward probability of 50% during rewarding trials to maximize reward uncertainty whereas we employed a reward probability of 66% with lower reward uncertainty. Regarding the differences in symptom severity it cannot be excluded that attenuated hemodynamic activity in OCD during reward anticipation in the dorsal striatum is restricted to patients with severe symptoms. It has been described that so-called punishers induce negative emotional states of anger or fear. Because of the different rewarding scheme used by Figee et al. without any loss trials triggers for negative emotional states were not present ( ). Consequently, participants of our study were in need of differentiating motivational valence of consequences. This might have some impact both on the behavioral and hemoynamic level. \n\nBoth, Figee et al.'s and our study, employed reward probabilities which ensured reward-directed behavior associated with phasic dopaminergic activity ( ). Figee et al. additionally maximized reward uncertainty which was shown to be associated with an increase of tonic dopaminergic activity in ventral midbrain areas until the time of reward delivery ( ). The dopaminergic coding of uncertainty was interpreted to correspond to attention-based learning. Therefore, it might be speculated that the differences between our and Figee et al.'s findings trace back to a nonselective form of attention or arousal designed to aid the learning of predictive stimuli and actions ( ), which was triggered in Figee et al.'s task design and attenuated in patients. Although we found no evidence for decreased BOLD activity in the dorsal or ventral striatum our patients showed more delayed responses for gain stimuli as indicated by the significant group by reinforcement interaction. On the behavioral level, this is in some accordance with Figee et al.'s finding showing significantly slower responses of patients during reward anticipation. \n\nOur results are not in agreement with those of   insofar as they reported reduced activation in the lateral prefrontal cortex and increased activity in the anterior insula of the patient group during loss anticipation. As the authors did not report response times broken down by conditions it is difficult to fully evaluate their findings, because the possibility of differences in the neutral condition between patients and controls cannot be ruled out. Taken together, evidence is not conclusive so far as to whether the ventral and the dorsal striatum show aberrant activations during anticipation of reinforcement. The present study showed no evidence for disease-related activation changes in the striatum during reinforcement learning. \n\n\n#### Medial prefrontal brain activation to anticipated reward and loss \n  \nWe observed a group by condition (anticipation of gain versus loss) interaction localized in a medial frontal/cingulate region. Patients showed less BOLD activity in this region during anticipation of reward and more after loss-indicating cues. Thus, the mentioned region appears to be involved in disorder-related changes of sensitivity for reward and punishment. The medial frontal region partly corresponds to the supplementary motor area (SMA-proper) and the pre-SMA, respectively ( ). The pre-SMA lies rostral to the SMA-proper and is sometimes considered as being part of the anterior cingulate cortex ( ). The SMA is implicated in specific motor events ( ) but has also been shown to mediate the sense of an impending movement without any overt motor event ( ). The pre-SMA is involved in the preparation of actions and has tight connections to dorsolateral prefrontal, anterior cingulate and inferior parietal regions ( ). Thereby, it also underpins cognitive-affective processes. \n\nWe showed previously in a study of cardiovascular arousal and interoceptive awareness that negative feelings correlate with the BOLD response in the dorsal cingulate gyrus extending into the dorsomedial prefrontal cortex in healthy subjects ( ). That region is virtually identical with respect to Talairach coordinates to the region implicated here. Also, other groups described associations of medial frontal and cingulate areas with negative emotions, threat appraisal, response conflict, and detection of unfavorable outcomes, especially in relation to the self ( ). In an extensive review including a quantitative coordinate-based meta-analysis of cingulate cortex findings   report evidence that the anterior midcingulate cortex (aMCC) implements a domain-general process that is integral to negative affect, pain and cognitive control. The aMCC corresponds closely to our observed cluster involved in the regulation of sensitivity for reward and punishment. According to the   adaptive control hypothesis   proposed by   the aMCC uses information about punishment to control aversively motivated actions by integrating signals arriving form subcortical regions (amygdala, striatum) and insula. Accordingly, our results might indicate altered frontostriatothalamic circuitry signaling in OCD patients. \n\n\n#### Different processing of motivating consequences in OCD \n  \nAlthough our patients did not report to consciously focus attention away from reward-indicating to loss-indicating cues, they appear to employ a different processing routine. Evaluation of situations implicating the possibility of gaining or losing a reinforcer appears to be associated with activity in the medial frontal/cingulate brain region. It is tempting to speculate that processing of motivating consequences is different in patients: adopting a pessimistic view, possibly reinforcing events may be perceived as indicating threat because patients with OCD overestimate the probability of loss ( ). Such cognitions might then coactivate brain regions more relevant for threat processing and negative affect. In a sense, there seems to be medial prefrontal involvement for providing additional computing recources, which may partly account for the altered sensitivity for reward. This finding may then represent a top-down mechanism involved in an effort to compensate for inadequate representation of negative feelings, rather than being due to a dysfunctional reward circuitry related bottom-up process. Hence, a different processing scheme of negative feelings could relate to the pessimistic view in patients with OCD concerning the overestimation of the probability of not being rewarded or being able to avoid loss even in overall rewarding situations. \n\nThere was no significant correlation with symptom severity within the patient group. Further empirical corroboration is needed because correlations are not sufficiently robust with relatively small sample sizes as used in our study as well as in most current FMRI studies. \n\n\n\n### Conclusions \n  \nLimitations of this study include the sample size, which does not allow to analyze symptom dimensions with reasonable statistical power. Another limitation is that we analyzed local activations only, without considering connectivity between regions, e.g. of the frontostriatothalamic and limbic circuitry. Therefore, we cannot definitely conclude about possible connectivity alterations during reinforcement learning. Further research should include functional and effective connectivity analyses. Also, studies should systematically vary reward uncertainty and probability, positive and negative incentive valence, and outcome magnitude. \n\nStrengths of the present study are the use of the MID task which is an accepted means to challenge reward circuitry, and the well matched samples including matched behavioral performance. \n\nAltogether, the main findings of this study are   \nincreased delayed reactions after gain-indicating and less delayed reactions after loss-indicating cues in patients with OCD, suggesting a bias towards avoidance of aversive stimuli; \n  \nno significant differences in dorsal and ventral striatal BOLD response during gain or loss anticipation, and \n  \na role of the medial frontal/cingulate region mediating altered sensitivity of patients with OCD for the anticipation of money gains or impending money losses. This alteration might be related to cortical processing of negative affect. \n  \n\n\n \n\n# Table(s)\n## ID: t0005\n### Label: Table\u00a01\nN\u00a0=\u00a019 vs. 19\tOCD (M\u00a0\u00b1\u00a0SD)\tControl\tt (p value)\nSex [female (male)]\t11 (8)\t11 (8)\t\nAge\t34.8 (11.0)\t34.9 (11.8)\t0.03 (.98)\nIntelligence (verbal)\t104 (10)\t107 (12)\t\u2212\u00a01.07 (.29)\nHandedness\t77 (55)\t67 (47)\t0.65 (.52)\nSTAI-X1 (state)\t54 (13)\t49 (6)\t1.61 (.12)\nSTAI-X2 (trait)\t61 (13)\t50 (6)\t3.32 (.002)\nEarnings in \u20ac\t21.80 (7.80)\t22.00 (6.40)\t\u2212\u00a00.07 (.95)\nY-BOCS (range 9\u201339)\t20.7 (7.9)\t\t\nOCI-R (range 9\u201361)\t24 (14)\t\t\nBDI (range 0\u201338)\t17 (11)\t\t\nMedication (N)\t3\t\t\nComorbidity (N)\t10\t\t\n### Caption\nDemographic and psychometric data and total earnings in the MID task of OCD patients and matched healthy controls; comparisons are based on two-sample t tests.\n### Footer\nNone\n\n\n## ID: t0010\n### Label: Table\u00a02\nAnatomical region(Brodmann area)\tHemisphere\tZ value\tx\ty\tz\nSuperior frontal gyrus (6)\tR\t3.6\t9\t3\t63\nSuperior frontal gyrus (6)\tL\t3.45\t\u2212\u00a02\t6\t53\nCingulate gyrus (24)\tR\t3.57\t12\t0\t45\nCingulate gyrus (24)\tR\t3.49\t6\t0\t45\nMedial frontal gyrus (32)\tR\t3.51\t3\t6\t48\n### Caption\nLocation of activated clusters in MNI stereotactic space for the interaction group\u00a0\u00d7\u00a0type of consequence (p\u00a0<\u00a0.01 corrected with a cluster-size based correction for multiple comparisons).\n### Footer\nNone\n", "metadata": {"pmcid": 3777673, "text_md5": "57d5d21cfc5c437d58c890f5e72cbbba", "field_positions": {"authors": [0, 127], "journal": [128, 143], "publication_year": [145, 149], "title": [160, 259], "keywords": [273, 430], "abstract": [443, 2598], "body": [2607, 35453], "tables": [35466, 36666]}, "batch": 2, "pmid": 24179774, "doi": "10.1016/j.nicl.2013.01.005", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777673", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3777673"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777673\">3777673</a>", "list_title": "PMC3777673  Medial prefrontal brain activation to anticipated reward and loss in obsessive\u2013compulsive disorder\u2606"}
{"text": "Kim, Sung-il and Hwang, Suyoung and Lee, Minhye\nPLoS One, 2018\n\n# Title\n\nThe benefits of negative yet informative feedback\n\n# Keywords\n\n\n\n# Abstract\n \nWe investigated whether negative feedback with information could benefit both behavioral and neural responses. Fifteen participants were scanned with functional magnetic resonance imaging (fMRI) while receiving various feedbacks in a novel perceptual task. Behavioral data showed that reaction times of task performance were faster after receiving negative informative feedback compared to negative confirmatory feedback. The fMRI analysis of the interaction contrast between feedback type (informative vs. confirmatory) and valence (negative vs. positive) showed greater activation in the ventrolateral prefrontal cortex (vlPFC) and the ventral striatum in response to negative informative compared to confirmatory feedback. The psychophysiological interactions (PPI) analyses showed that the vlPFC activation was positively correlated with the amygdala and the rostral cingulate zone (RCZ). The ventral striatum activation was negatively correlated with the dorsolateral prefrontal cortex (dlPFC). These results suggest that negative but informative feedback benefits subsequent performance and its primary function is to elicit positive prediction error (instructive signal) and to induce cognitive control to guide subsequent goal-directed behavior. \n \n\n# Body\n \n## Introduction \n  \nFeedback is a direct way to improve learner\u2019s performance by providing relevant and useful information. Feedback facilitates learning and motivation because it helps the learner not only monitor performance but also adjust subsequent behavior [ ]. Most psychological theories of learning and motivation posit that positive feedback generates a positive affect and fosters motivation whereas negative feedback does the opposite [ , ]. \n\nFeedback processing can be viewed from two different perspectives: reinforcement learning (focusing on positive valence of feedback) and cognitive (cybernetic) model of information processing (focusing on negative valence of feedback). According to the reinforcement learning perspective, people are strongly motivated to approach appetitive stimuli (i.e., rewards) and avoid aversive stimuli (i.e., punishment) [ ]. Because positive feedback functions as an appetitive stimulus, it is likely to reinforce the target behavior by increasing the frequency with which this behavior is approached. \n\nHowever, in the cognitive model, feedback serves as information used to reduce discrepancies between a target goal and current state [ ]. In an attempt to learn goal-directed behavior, people need to continuously monitor ongoing performance and adopt appropriate behaviors via feedback. Thus, feedback signals, as long as they hold accurate and valuable information, are processed in the executive cortico-striatal loop to allow for behavioral adjustment. In particular, negative feedback requires executive and cognitive control processes to avoid further errors [ ]. \n\n### Feedback valence \n  \nNeuroimaging studies on feedback processing have established the link between feedback valence and brain activation patterns. For example, positive feedback activates reward-sensitive areas such as the ventral striatum and the medial orbitofrontal cortex (mOFC) [ , ], while negative feedback activates the punishment-related areas of the brain, including the lateral part of the OFC [ , ], the dorsal anterior cingulate cortex (dACC) [ , ], the anterior insular cortex (AIC), and the ventrolateral prefrontal cortex (vlPFC) [ , ]. \n\nHowever, the relationship between feedback valence and behavior is not simple. Particularly in the case of negative feedback, several factors, including types of feedback and individual characteristics, can moderate this relationship. For example, despite the unpleasant nature of negative feedback, people often seek it out and benefit from depending on individual characteristics such as self-esteem and regulatory focus [ , ]. Furthermore, positive feedback can also undermine intrinsic motivation by increasing learner\u2019s self-consciousness to the point of distraction from the task [ ]. \n\nTo understand the role of feedback in learning and motivation, many studies on feedback processing have focused on negative valence of feedback rather than positive one because the former usually informs performance adjustment and regulates behavior [ , ]. Negative feedback processing recruits the cognitive control network, a set of interconnected cortical regions such as the ACC to avoid additional errors [ , ]. A large number of studies have reported that a negative event-related potential (ERP) component, called the error-related or feedback-related negativity (ERN or FRN), occurs following negative feedback that indicates an error or incorrect response [ , , ]. This ERN is mainly modulated by the dACC or the rostral cingulate zone (RCZ), which is known as the central brain region for attention-demanding cognitive control, including action selection and performance monitoring [ \u2013 ]. \n\nIn addition, several studies have demonstrated that the mesencephalic dopamine system, including the midbrain and the ventral striatum, is often activated in response to negative feedback or aversive stimuli [ \u2013 ]. Researchers have interpreted this finding as negative feedback representing unexpected surprising information, leading to an increase in the prediction error [ ]. This hypothesis has been supported by several neuroimaging studies that have demonstrated that activation of the midbrain including nucleus accumbens (NAcc) correlates with the prediction error for negative feedback [ , ]. \n\n\n### Feedback type \n  \nMost functional neuroimaging studies on feedback processing have focused on the differences in neural activity associated with feedback valence rather than feedback type. Although several studies have investigated the effect of types of feedback on brain activation [ ], it is the informative value of feedback that determines learning and performance adjustment. Two different types of feedback can therefore be distinguished depending on the degree of information convey by the feedback: confirmatory (verification) and informative (elaborative or evaluative) feedback [ \u2013 ]. Confirmatory feedback simply indicates whether a response is correct or not. That is, it relays performance accuracy (i.e., success or failure) without any further explanation. In contrast, Informative feedback provides correction about a response by including specific reasons for the success or failure. In particular, negative informative feedback provides useful information in guiding subsequent behavior because it contains specific information about the incorrect performance that needs to be adjusted. Thus, informative feedback serves to correct errors whereas confirmatory feedback serves to confirm a correct response. \n\nBecause the success of a task performance is usually not determined by a single criterion in typical learning situations, learners may not know exactly what aspect of their performance was incorrect based solely on negative confirmatory feedback (i.e., failure). When provided informative feedback, however, learners are able to monitor their performance precisely and modify subsequent behavior [ ]. Through this process, informative feedback not only helps learners engage in more detailed learning, but also it implicitly enhances their achievement motivation and task completion [ , ]. \n\nHowever, previous neuroimaging studies on feedback processing have mainly used confirmatory feedback by only providing the correctness of the response. Bischoff-Grethe et al. [ ] found that the Ventral striatum, the caudate, the putamen, the AIC, and the supplementary motor area (SMA) were sensitive to confirmatory feedback regardless of valence. \u00d6zyurt et al. [ ] also compared confirmatory feedback and no feedback and found that the rostral cingulate zone (RCZ), the vlPFC, and the insula were more strongly activated in response to confirmatory feedback than to no feedback. Although they used the term informative feedback, the feedback provided in these studies was confirmatory because they did not provide any relevant information on the participants\u2019 performance except for indicating their successes or failures. Instead of comparing different types of feedback (confirmatory versus informative feedback), they simply compared feedback versus no feedback. Only a few studies have investigated the neural mechanisms of informative feedback processing. For example, Van den Bos et al. [ ] manipulated the informative value of feedback using a probabilistic learning task. They assumed that negative feedback would contain higher informative value when participants chose the alternative rule (low probability stimuli) than the correct rule (high probability stimuli). Because negative feedback after the choice of the high probability stimuli would not provide any information for subsequent performance adjustment, it has less informative value. They found more activity in the dorsolateral prefrontal cortex (dlPFC) and the dACC (RCZ) in response to negative feedback for the alternative rule than for the correct rule, indicating that it signaled the need for cognitive control and behavior change. \n\nTricomi and colleagues varied the level of informational value by manipulating either the number of possible response options [ ] or the predictability of the feedback reception [ ]. Tricomi and Fiez [ ] varied the amount of information provided by positive and negative feedback by manipulating two versus four response options. When two response options are available, positive and negative feedback provide equal amounts of information. In contrast, when four response options are available, positive feedback provides more information than negative feedback which only eliminates one of four possibilities. They found that the negative feedback in the two-response condition elicited greater signal in the caudate than four-response condition because negative feedback in the two-response condition, relative to the four-response condition, had more informational value. Lempert and Tricomi [ ] also showed that negative feedback increased the caudate activity and no feedback decreased the ventral striatum activity when the receipt of feedback was unpredictable. This suggest that an unpredictable feedback context makes negative feedback more informative than predictable feedback context does. \n\nFurthermore, Woo et al. [ ] demonstrated that informative feedback serves an emotion regulation function. They presented negative feedback consisted of the image of an angry face along with the derogatory statement, \u2018\u2018You are stupid\u201d which induces strong negative emotion. They found that confirmatory negative feedback recruited a neural network associated with negative emotion including amygdala, whereas informative negative feedback activated the dorsolateral prefrontal cortex (dlPFC), a region involved in emotion regulation. \n\nAlthough these previous studies highlighted the importance of informational value of negative feedback, it is not yet known if differential neural mechanisms underlie informative and confirmatory feedback, particularly in conjunction with a negative valence. In the present study, we directly compare informative and confirmatory feedback by varying the degree of information provided on the participants\u2019 performance in a novel perceptual task. The difference between confirmatory and informative feedback depends on the relative amount of useful information in the feedback. The informative feedback provides more specific information which could be used to correct errors whereas confirmatory feedback provides minimal information only as to whether the response was correct or not. While informative feedback serves to correct errors, confirmatory feedback serves to confirm a correct response. Therefore, the greatest difference between confirmatory and informative feedback occurs when the feedback valence is negative. \n\nAssuming that the ventral striatum encodes a reward prediction error signal, there would be no difference in the ventral striatal activation between positive confirmatory and positive informative feedback. Because positive feedback is a reinforcement, we hypothesized that positive feedback would produce positive reward prediction error (better-than-expected) signal regardless of feedback type, which would result in the similar activation of the ventral striatal region. However, in the case of negative feedback, the negative reward prediction error (worse-than-expected) signal would differ depending on the type of feedback. Negative confirmatory feedback would produce negative reward prediction error which would inhibit the ventral striatal activation. In contrast, it is expected that negative informative feedback would produce positive reward prediction error, resulting in greater ventral striatal activation because it contains valuable information for subsequent performance. \n\n\n\n## Method \n  \n### Participants \n  \nSeventeen healthy, right-handed subjects participated in this fMRI experiment. None of the participants had either a history of neurological, psychiatric, or major medical disorders. The number of participants was determined by a priori power analysis with the expected strong effect size for testing difference between two dependent means using G*Power 3.1.9.2 [ ]. They provided informed consent and were paid about $30 for their participation. This study was approved by the Institutional Review Board of Korea University. Two subjects were excluded from the analysis due to excessive head motion (greater than 3 mm). Thus, the final sample consisted of 15 participants (eight males, mean age = 22.21 years, SD = 1.81), which was identical with the minimum required sample size computed from the power analysis. \n\n\n### Experimental stimuli and procedure \n  \nThe experimental design was a 2 (feedback type; informative vs. confirmatory) \u00d7 2 (feedback valence; positive vs. negative) event-related design consisting of 4 runs (see  ). Each run was comprised of 20 trials in which participants performed two consecutive perceptual judgment tasks and received feedback. A total of 80 trials were conducted and the scanning session took approximately 30 minutes in total. Each stimulus consisted of a large number (ranging from 25 to 30) of the letter H and a small number (ranging from 3 to 9) of the letter T, with each individual letter randomly colored red or blue (see  ). Participants were presented with a stimulus of letters on the screen for 1 second and asked to perform the following two tasks consecutively: 1) a color-judgment task, where they judged which color was more numerous, red or blue; and 2) a T-detection task, where they decided whether there were three red Ts present. For the color-judgment task, participants were instructed to click the left button of the mouse if the red letters outnumbered the blue ones or click the right button if the blue letters outnumbered the red ones. For the T-detection task, if participants detected three red Ts they were to click the left button of the mouse; if not, they were to click the right one. Participants had to respond to each task within 2 seconds and the order of the two tasks was counterbalanced. \n   Experimental stimuli and procedure.  \nThe experimental design was a 2 (feedback type; informative vs. confirmatory) \u00d7 2 (feedback valence; positive vs. negative) event consisting of 4 runs of 20 trials each (80 trials in total). Each stimulus consisted of a large number (ranging from 25 to 30) of the letter H and a small number (ranging from 3 to 9) of the letter T which were randomly colored red or blue. Participants were presented with a stimulus of letters on the screen for 1 second and asked to perform the following two tasks consecutively: 1) a color-judgment task where they were to judge which color was more common, red or blue; and 2) a T-detection task in which they were to decide whether there were three red Ts present. After completing these tasks, participants received predetermined feedback that disregarded their actual performance to control for the amount of positive and negative feedback received. To manipulate feedback type, specific information about the criteria they met or not met was presented for informative feedback, whereas simple success or failure information was presented for confirmatory feedback. Fix = fixation; ITI = inter-trial-interval. \n  \nParticipants were told that their response would be considered a success if the response satisfied at least three of the following four criteria: accuracy and speed for both color-judgment and T-detection tasks. To satisfy the speed criteria, participants were required to provide their response within 300 ms. Participants were informed that their response would be considered a failure if they only met one or none of the four criteria. We intentionally in excluded feedback for cases which the responses of the participants satisfied two criteria because they could not be regarded as either successes or failures. \n\nAfter completing the two consecutive tasks, participants received bogus feedback unrelated to their actual performance. Unbeknownst to participants, predetermined feedback was used to control for the number of positive and negative feedback trials received by each individual. Post-experimental interviews with participants revealed that all the participants reported that they perceived the feedback as credible reflecting their actual performance. The type of feedback varied depending on the specific information presented about the performance (see  ). For informative feedback, participants were told which criteria they had met and which they had not. For confirmatory feedback, participants were told whether they had succeeded or failed without any additional information. One of the four different types of feedback (positive informative, positive confirmatory, negative informative, and negative confirmatory feedback) was presented to the participants for 6 s. A random inter-trial interval varying from between 4 to 12 s (mean = 8 s) followed each feedback session. \n\n\n### Imaging procedures \n  \nThe functional imaging was conducted on a 3-tesla scanner (ISOL, Korea). For each subject, we acquired a whole-brain T1-weighted anatomical image (TR = 10 ms; TE = 5.7 ms, flip angle = 10\u00b0, voxel size = 1 \u00d7 1 \u00d7 1 mm ) and gradient echo T2*-weighted echo planar images (EPI) with BOLD contrast (TR = 2000 ms; TE = 35 ms; flip angle = 60\u00b0, sequential ascending order, FOV = 240 mm, 5-mm-thick 22-slice with no gap, 64 \u00d7 64 matrix). \n\n\n### fMRI data analysis \n  \nImage analysis was performed using SPM5 (Wellcome Department of Imaging Neuroscience, Institute of Neurology, London, U.K.). To correct for head motion during scanning, images were realigned to the first image as a reference by using a least squares approach and a six-parameter fixed-body transformation. As a compromise of the 5-mm thickness of imaging option, images were then corrected for differences in the timing of slice acquisition and spatially normalized to a standard T2* template with a resampled voxel size of 2 \u00d7 2 \u00d7 2 mm . Spatial smoothing was applied based on a Gaussian kernel of 8 mm full-width at half-maximum (FWHM). High-pass temporal filtering with a cut-off of 128 s was applied. \n\nThe feedback was categorized into one of four conditions (positive-informative, negative-informative, positive-confirmatory, and negative-confirmatory feedback) and modeled by convolving a delta function at each event onset with a canonical hemodynamic response function (HRF). In addition to the four feedback stimulus onset time regressors, task stimuli onset time, response times of both Color-judgment and T-detection tasks, and six head-motion parameters were included in the model. \n\nWe computed contrast images to enable comparison between positive and negative feedback and for the interaction effect between feedback type and valence at the individual level. The results from the individual analysis were taken to the second-level analyses. In general, results at a threshold of   p   < .001 uncorrected and of more than 10 voxels were considered. We also reported statistical strengths of neural responses found at a significant voxel-wise level of   p   < .05 false discovery rate (FDR) corrected for multiple comparisons. Activations in a priori region of interests (ROIs) which survived in the whole-brain correction were subject to small-volume correction (SVC). ROI masks for SVC were created based on a priori anatomical structures found in previous empirical studies. Masks for the bilateral ventral striatum and vlPFC for the interaction contrast were created based on previous studies adopting similar research designs and paradigms [ , ]. More precisely, the masks for the bilateral ventral striatum were created as 10-mm spheres centered on the coordinates (  x   = -12,   y   = 12,   z   = -8;   x   = 12,   y   = 12,   z   = -8) identified in a Bischoff-Grethe et al.\u2019s empirical study [ ]. The mask for the bilateral vlPFC was also created as a 10-mm sphere centered on the coordinates (  x   = 32,   y   = 24,   z   = 2;   x   = -34,   y   = 22,   z   = 0) reported in a Monchi et al.\u2019s study [ ]. These regions are closely associated with the interaction effects between feedback valence and type. We also conducted ROI analyses by using the MarsBar SPM Toolbox ( ) to infer and visualize the activation patterns of the regions identified in the target interaction contrasts. In order to confirm the independence between whole-brain results and functional ROIs, we utilized the leave-one-subject-out (LOSO) method [ ]. To explore functional connectivity with the ROIs, we also conducted psychophysiological interactions (PPI) analyses for the target interaction contrast, (negative informative\u2013positive informative) > (negative confirmatory\u2013positive confirmatory). MNI coordinates were converted into the standard space of Talairach and Tournoux [ ] when we reported the anatomical locations of significant activation foci. \n\n\n\n## Results \n  \n### Behavioral results \n  \nWe conducted repeated-measure ANOVAs on reaction time and accuracy of color-judgment task and T-detection task, respectively (see   and  ). To examine the effect of prior feedback on subsequent task performance, we analyzed reaction time and accuracy for task trials immediately following the feedback. There were significant interaction effects between feedback type and valence on response time of both tasks (for color task,   F   = 78.92,   p   < .01, \u014b  = .85; for T-task,   F   = 24.66,   p   < .01, \u014b  = .64), but not on task accuracy (for color task,   F   = .00,   p   = .99, \u014b  = .00; for T-task,   F   = .51,   p   = .49, \u014b  = .04). For confirmatory feedback, negative feedback produced a longer reaction time than did positive feedback (for color task,   t   = 11.01,   p   < .01; for T-task,   t   = 7.07,   p   < .01); however, for informative feedback, no difference was found between positive and negative feedback in both tasks. In addition, we found main effects of feedback valence on response time of both tasks (for color task,   F   = 47.07,   p   < .01, \u014b  = .77; for T-task,   F   = 30.61,   p   < .01, \u014b  = .69, respectively) and main effects of feedback type on the color task accuracy (  F   = 5.09,   p   < .05, \u014b  = .27) and on the T-detection task reaction time (  F   = 22.11,   p   < .01, \u014b  = .61). \n  \nInteraction effect of feedback type and valence on response time of (A) color-judgment task and (B) T-detection task. \n     Descriptive statistics for reaction time and accuracy for each task.      \n\n### fMRI results \n  \n#### Whole brain analyses \n  \nWe examined neural differences based on feedback valence and type (see Tables   and  , respectively). In the (positive feedback > negative feedback) contrast, individuals showed increased activation in the ventral striatum, caudate nucleus, cerebellum, anterior cingulate cortex, superior temporal gyrus, and parahippocampal gyrus (  p   < .001 uncorrected, with a minimum cluster size of 10 voxels) when receiving positive feedback compared to receiving negative feedback (see  ). On the contrary, for the (negative feedback > positive feedback) contrast, participants showed greater activation only in the posterior insula when receiving negative feedback than when receiving positive feedback. In regard with the contrast of (informative feedback > confirmatory feedback), participants had greater activations in the ACC, inferior parietal lobule, caudate nucleus, AIC, and cerebellum when receiving informative feedback compared to receiving confirmatory feedback. In contrast, regarding the brain activations in the (confirmatory feedback > informative feedback) contrast, participants showed greater activation in the cerebellum, superior temporal gyrus, and cuneus when receiving confirmatory feedback than when receiving informative feedback. \n   Striatum activations in the (Positive > Negative) contrast.       Feedback valence contrasts.           Feedback type contrasts.        \nTo investigate the interaction effect between feedback type and valence, we created contrasts between negative and positive feedback within each type of feedback for the second-level analysis (see  ). In the contrast of (negative informative feedback\u2013positive informative feedback) > (negative confirmatory feedback\u2013positive confirmatory feedback), brain activations in the left vlPFC and the right ventral striatum reflect the interaction effect between feedback type and valence (  p   < .001 with a minimum cluster size of 10 voxels;   p   < .05 FDR small volume corrected). In the contrast of (negative confirmatory\u2013positive confirmatory) > (negative informative\u2013positive informative), brain activations in the left posterior insular cortex, left calcarine sulcus, and right middle temporal gyrus also reflect the interaction effects between feedback type and valence (  p   < .001 with a minimum cluster size of 10 voxels). \n   Interaction effect of feedback type and valence.        \n\n#### Functional ROI analyses \n  \nWe performed functional ROI analyses on those regions found to be significant in the interaction analysis by using the LOSO method. We found that the brain activation patterns in the ROI varied depending on feedback valence in the case of confirmatory feedback, whereas this was not the case for informative feedback. For confirmatory feedback particularly, positive feedback showed increased activity in the left vlPFC (  F   = 13.38,   p   < .05, \u014b  = .49; see  ) and the right ventral striatum (  F   = 17.21,   p   < .01, \u014b  = .55; see  ), compared to negative feedback. However, the valence of informative feedback did not affect the brain activation patterns in the ROI. In contrast, the left posterior insular cortex showed heightened activation when participants received negative confirmatory feedback (  F   = 4.79,   p   < .05, \u014b  = .26). The left calcarine sulcus showed decreased activation when participants received negative informative feedback, whereas the other types of feedback did not lead to the meaningful changes in the calcarine sulcus activation (  F   = 5.62,   p   < .05, \u014b  = .29). \n  \n(A) Left vlPFC and (B) right ventral striatum activations in the (Negative Informative\u2013Positive Informative) > (Negative Confirmatory\u2013Positive Confirmatory) contrast. \n  \n\n#### PPI analyses \n  \nTo explore the brain connectivity with the ROIs from the (negative informative\u2013positive informative) > (negative confirmatory\u2013positive confirmatory) contrast, we conducted PPI analyses with the left vlPFC and right ventral striatum as the seed regions (see  ). PPI analyses showed that the vlPFC activation was positively correlated with the right amygdala, and the right rostral cingulate zone (RCZ) (  p   < .001 uncorrected,   k   > 10). The ventral striatum activation was negatively correlated with the right dorsolateral prefrontal cortex (dlPFC) (  p   < .001 uncorrected,   k   > 10). \n   Psychophysiological interactions with the vlPFC and ventral striatum activations as the seed ROIs from (Negative Informative\u2013Positive Informative) > (Negative Confirmatory\u2013Positive Confirmatory) contrast.        \n\n\n\n## Discussion \n  \nThe main objective of the present study was to investigate whether negative feedback with information can benefit learning and performance. We compared both behavioral and neural responses to different types and valences of feedback while performing a novel perceptual task. Behavioral data showed that reaction times of task performance were faster after receiving positive confirmatory feedback compared to confirmatory feedback. However, for informative feedback, no significant differences in reaction time were found between negative and positive feedback, indicating that negative informative feedback serves the same function as positive informative feedback. The interaction between feedback valence and type in reaction time suggests that negative feedback containing information about learners\u2019 current performance can benefit subsequent performance, whereas negative confirmatory negative feedback without specific information does not. \n\nThe fMRI interaction contrast between feedback type (informative-confirmatory) and valence (negative-positive) revealed significant activation in the vlPFC and the ventral striatum. ROI analyses revealed that confirmatory feedback elicited lower activation in the vlPFC and the ventral striatum during negative feedback than it did during positive feedback, whereas informative feedback showed the same activation pattern in these regions regardless of valence. \n\nConsistent with the well-established link between the ventral striatum and positive feedback [ ], we found greater ventral striatum activity in response to positive feedback compared to negative feedback. However, there was no difference in the ventral striatum activation between positive and negative informative feedback. Because negative informative feedback contains unexpected but relevant information for subsequent performance, it would be rewarding and produce positive reward prediction error (better-than-expected) signal in the ventral striatum. In contrast, negative confirmatory feedback would produce negative reward prediction error (worse-than-expected) signal. Since the ventral striatum has anticipatory or evaluative function [ ] and plays a critical role in integrating appetitive and aversive predictions [ , ], the current finding may reflect the prediction error signal in the ventral striatum during feedback-based learning [ ]. This is in line with the recent argument that the ventral striatum encodes action outcomes that guide the direction of subsequent ones by integrating cognitive and affective information especially in ambiguous and uncertain situations [ ]. This suggests that the ventral striatum activity increases as long as the feedback provides appropriate instructive signals for learning regardless of the valence of the feedback. \n\nIn addition, the PPI analysis revealed that the ventral striatum activation during negative informative feedback was negatively correlated to the activation of dlPFC. This negative functional connectivity between the ventral striatum and the dlPFC seems to be inconsistent with the previous findings demonstrating dopaminergic modulation over dlPFC [ ]. One possibility is that the dlPFC activation, a region involved in working memory might be decreased when the ventral striatum was relatively more activated due to positive prediction error signal. Negative informative feedback might enhance performance (faster reaction time and higher accuracy) by inhibiting redundant working memory function. \n\nWe also found an interaction effect between feedback type and valence in vlPFC activation. In this study, vlPFC activation was found in response to informative feedback regardless of valence. For confirmatory feedback, however, the vlPFC had relatively lower activation in response to negative feedback than to positive feedback. This is inconsistent with previous findings of greater vlPFC activation following negative feedback compared to positive feedback [ , ]. In the current study negative confirmatory feedback did not provide any specific information that helped the adjustment of subsequent performance. For example, when participants received negative confirmatory feedback, they did not know which criteria they failed to satisfy. In contrast, positive confirmatory feedback indicated whether they had met most of the criteria (3 or 4 criteria). Therefore, in this study, negative confirmatory feedback had less informative value than positive confirmatory feedback. This suggests that the vlPFC is sensitive to the informative value of feedback rather than the valence and that the vlPFC is recruited only when feedback carries significant information for future goal-directed behavior. \n\nAlthough the lateral PFC has been implicated in cognitive control, recent evidence suggests functional dissociation within the subregions of the lateral PFC [ , ]. Monchi et al. [ ] distinguished the role of the vlPFC from that of the dlPFC and vmPFC. They specified that during reversal learning tasks the vlPFC is recruited when planning a response to negative feedback, whereas the vmPFC is activated in response to emotionally salient feedback. They also stated that the dlPFC is involved in the monitoring of information held in working memory, whereas the vlPFC is recruited during the active comparison of stimuli held in working memory. Petrides [ ] argued that the vlPFC is involved in the active maintenance of relevant information, whereas the dlPFC is modulated by more complex higher order information processing. Badre and colleagues found that the left vlPFC was implicated in the top-down control of goal-relevant knowledge [ , ]. \n\nAlthough the RCZ, known as a performance-monitoring region [ ], was not significantly activated in response to negative informative feedback, the subsequent PPI analysis revealed that the vlPFC activation during negative informative feedback was positively correlated to the activation of the RCZ. The indirect involvement of the RCZ indicates that negative informative feedback might enhance top-down cognitive control including performance-monitoring. \n\nInterestingly, the amygdala activation was also found to be positively correlated to the vlPFC activation. This positive amygdala-vlPFC functional connectivity suggests that the vlPFC might involve in the regulation of negative affect elicited by negative informative feedback. This is congruent with current claims that functional coupling between the amygdala and the vlPFC was associated with decreased anxiety [ , ]. Taken together, the PPI results suggest that negative informative feedback enhances both performance monitoring and goal maintenance via emotion regulation such as anxiety-buffering. Although further studies are needed to delineate the precise function of the vlPFC during negative informative feedback processing, we speculate that the main function of the vlPFC might be an active maintenance of task-relevant feedback information. \n\nIn summary, negative feedback is beneficial for improving subsequent performance when it conveys relevant information. The greater activation of the vlPFC and the ventral striatum in response to informative negative feedback in comparison to confirmatory negative feedback suggests that the primary function of negative informative feedback is to elicit positive prediction error (instructive signals) and to induce cognitive control to guide subsequent goal-directed behavior. \n\nOur findings have important implications for instructional and educational practices. Negative feedback could be beneficial for learning and motivation in any learning context as long as it is provided with relevant information for future performance. Furthermore, it would be worthwhile to investigate further how individual characteristics of the learner interact with various types of feedback. The potential limitations of the present study stem from small sample size. Although our sample could have been stronger, it is in the marginally acceptable range to provide valid and reliable knowledge about interactions between feedback type and valence. Another limitation is that we used bogus feedback regardless of participants\u2019 actual performance. Although all the participants believed that the feedback was based on their actual performance, it is necessary to conduct future research using different learning task with real feedback. \n\n\n## Supporting information \n  \n \n\n# Table(s)\n## ID: pone.0205183.t001\n### Label: Table 1\nFeedback type\tFeedback valence\tReaction time\tReaction time\tAccuracy\tAccuracy\nFeedback type\tFeedback valence\tMean\tSD\tMean\tSD\nColor-judgment task\tColor-judgment task\t\t\t\t\nInformative\tPositive\t708.55\t206.18\t51.5\t15.3\n\tNegative\t711.09\t190.66\t52.38\t5.97\nConfirmatory\tPositive\t670.13\t161.17\t46.62\t11.05\n\tNegative\t819.02\t175.65\t47.5\t6.48\nT-detection task\tT-detection task\t\t\t\t\nInformative\tPositive\t447.28\t128.39\t53.01\t9.64\n\tNegative\t475.34\t149.72\t55.44\t14.01\nConfirmatory\tPositive\t476.79\t177.04\t53.38\t13.9\n\tNegative\t604.4\t182.14\t51.07\t11.68\n### Caption\nDescriptive statistics for reaction time and accuracy for each task.\n### Footer\nNone\n\n\n## ID: pone.0205183.t002\n### Label: Table 2\nRegion\tR/L\tBA\tTalairach Coordinate\tTalairach Coordinate\tTalairach Coordinate\tVoxel (k)\tz-value\nRegion\tR/L\tBA\tx\ty\tz\tVoxel (k)\tz-value\nPositive > Negative feedback\t\t\t\t\t\t\t\nVentral striatum\tR\t48.0\t9.0\t3.0\t0.0\t79.0\t4.56\n\tL\t48.0\t-8.0\t0.0\t1.0\t32.0\t3.44\nCerebellum\tR\t\t23.0\t-41.0\t-11.0\t81.0\t4.07\nInferior temporal gyrus\tR\t19.0\t47.0\t-72.0\t-1.0\t43.0\t3.85\nSuperior temporal gyrus\tL\t38.0\t-34.0\t12.0\t-22.0\t194.0\t3.83\nParahippocampal gyrus\tR\t34.0\t11.0\t-8.0\t-13.0\t56.0\t3.76\nAnterior cingulate cortex\tR\t9.0\t3.0\t35.0\t31.0\t54.0\t3.63\n\tR\t40.0\t58.0\t-31.0\t40.0\t18.0\t3.44\nCuneus\tR\t18.0\t12.0\t-98.0\t16.0\t16.0\t3.62\nInferior parietal lobe\tL\t40.0\t-54.0\t-38.0\t41.0\t20.0\t3.57\nCaudate nucleus\tL\t48.0\t-8.0\t19.0\t3.0\t54.0\t3.54\n\tR\t48.0\t13.0\t15.0\t4.0\t22.0\t3.48\nThalamus\tR\t50.0\t1.0\t-15.0\t-1.0\t25.0\t3.51\nMedial globus pallidus\tR\t\t15.0\t-8.0\t1.0\t21.0\t3.46\nInferior frontal gyrus\tR\t46.0\t46.0\t36.0\t8.0\t16.0\t3.44\nMiddle frontal gyrus\tL\t10.0\t-39.0\t38.0\t0.0\t11.0\t3.36\nSupramarginal gyrus\tR\t40.0\t56.0\t-45.0\t35.0\t37.0\t3.35\nPosterior cingulate cortex\tR\t23.0\t8.0\t-50.0\t21.0\t22.0\t3.33\nNegative > Positive feedback\t\t\t\t\t\t\t\nPosterior insula\tL\t13.0\t-43.0\t-17.0\t5.0\t58.0\t3.57\nMedial frontal gyrus\tR\t6.0\t8.0\t-3.0\t59.0\t18.0\t3.47\n\tL\t6.0\t-1.0\t-8.0\t61.0\t15.0\t3.43\n### Caption\nFeedback valence contrasts.\n### Footer\np < .001 uncorrected, extent threshold k > 10.\n\n\n## ID: pone.0205183.t003\n### Label: Table 3\nRegion\tR/L\tBA\tTalairach Coordinate\tTalairach Coordinate\tTalairach Coordinate\tVoxel(k)\tz-value\nRegion\tR/L\tBA\tx\ty\tz\tVoxel(k)\tz-value\nInformative > Confirmatory feedback\tInformative > Confirmatory feedback\t\t\t\t\t\t\nAnterior cingulate cortex???\tR\t6.0\t12.0\t14.0\t46.0\t8540.0\t5.95\nInferior parietal lobule???\tR\t40.0\t55.0\t-29.0\t38.0\t3103.0\t4.78\nSuperior temporal gyrus???\tL\t22.0\t-60.0\t-47.0\t15.0\t28.0\t4.29\nCaudate nucleus???\tL\t48.0\t-7.0\t0.0\t11.0\t222.0\t4.25\nCerebellum???\tL\t\t-27.0\t-70.0\t-12.0\t143.0\t3.65\nAnterior insula???\tL\t13.0\t-33.0\t18.0\t-5.0\t80.0\t3.62\nInferior occipital gyrus???\tL\t19.0\t-43.0\t-74.0\t-5.0\t25.0\t3.44\nMiddle temporal gyrus???\tL\t37.0\t-51.0\t-51.0\t-7.0\t16.0\t3.32\nThalamus???\tR\t50.0\t11.0\t-13.0\t3.0\t13.0\t3.22\nConfirmatory > Informative feedback\tConfirmatory > Informative feedback\t\t\t\t\t\t\nCerebellum\tL\t\t-13.0\t-61.0\t-4.0\t753.0\t4.46\nSuperior temporal gyrus\tR\t22.0\t45.0\t-21.0\t6.0\t188.0\t3.76\nCuneus\tR\t31.0\t2.0\t-66.0\t12.0\t130.0\t3.49\nLingual gyrus\tL\t18.0\t-14.0\t-75.0\t7.0\t15.0\t3.36\nPosterior cingulate cortex\tL\t23.0\t-7.0\t-48.0\t26.0\t20.0\t3.21\n### Caption\nFeedback type contrasts.\n### Footer\n* p < .05 FDR corrected.p < .001 uncorrected, extent threshold k > 10.\n\n\n## ID: pone.0205183.t004\n### Label: Table 4\nRegion\tR/L\tBA\tTalairach Coordinate\tTalairach Coordinate\tTalairach Coordinate\tVoxel(k)\tz-value\nRegion\tR/L\tBA\tx\ty\tz\tVoxel(k)\tz-value\n(NeInfo\u2014PoInfo) > (NeConf\u2014PoConf)\t(NeInfo\u2014PoInfo) > (NeConf\u2014PoConf)\t(NeInfo\u2014PoInfo) > (NeConf\u2014PoConf)\t\t\t\t\t\nVentrolateral prefrontal cortex???\tL\t47\t-31.0\t25.0\t4.0\t25.0\t3.72\nVentral striatum???\tR\t52\t11.0\t6.0\t-9.0\t20.0\t3.61\nHippocampus\tR\t54\t29.0\t-16.0\t-9.0\t17.0\t3.57\n(NeConf\u2014PoConf) > (NeInfo\u2014PoInfo)\t(NeConf\u2014PoConf) > (NeInfo\u2014PoInfo)\t(NeConf\u2014PoConf) > (NeInfo\u2014PoInfo)\t\t\t\t\t\nPosterior insula\tL\t13\t-40.0\t-19.0\t8.0\t167.0\t4.47\nCalcarine sulcus\tL\t17\t-22.0\t-73.0\t14.0\t32.0\t4.02\nFusiform gyrus\tL\t19\t-31.0\t-69.0\t1.0\t13.0\t3.89\nMiddle temporal gyrus\tR\t21\t49.0\t-6.0\t-2.0\t21.0\t3.35\nPrecuneus\tR\t7\t6.0\t-58.0\t53.0\t16.0\t3.43\n### Caption\nInteraction effect of feedback type and valence.\n### Footer\nNote. NeInfo = negative informative feedback; PoInfo = positive informative feedback; NeConf = negative confirmatory feedback; PoConf = positive confirmatory feedback.* p < .05 FDR small volume corrected.p < .001 uncorrected, extent threshold of k > 10.\n\n\n## ID: pone.0205183.t005\n### Label: Table 5\nRegion\tR/L\tBA\tTalairach Coordinate\tTalairach Coordinate\tTalairach Coordinate\tVoxel(k)\tz-value\nRegion\tR/L\tBA\tx\ty\tz\tVoxel(k)\tz-value\nPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\tPositive correlation with the left vlPFC\nAmygdala\tR\t53\t32\t-1\t-13\t65\t3.86\nRostral cingulate zone\tR\t32\t13\t21\t25\t99\t3.68\nDorsolateral prefrontal cortex\tL\t9\t-21\t35\t22\t13\t3.59\n\tR\t10\t27\t41\t17\t16\t3.33\nNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\tNegative correlation with the right ventral striatum\nDorsolateral prefrontal cortex\tR\t9\t28\t45\t37\t129\t4.54\nPosterior cingulate cortex\tL\t23\t-1\t-42\t32\t16\t3.38\n### Caption\nPsychophysiological interactions with the vlPFC and ventral striatum activations as the seed ROIs from (Negative Informative\u2013Positive Informative) > (Negative Confirmatory\u2013Positive Confirmatory) contrast.\n### Footer\np < .001 uncorrected, extent threshold of k > 10.\n", "metadata": {"pmcid": 6195265, "text_md5": "9d6d7b979376f80eff727b597031d671", "field_positions": {"authors": [0, 47], "journal": [48, 56], "publication_year": [58, 62], "title": [73, 122], "keywords": [136, 136], "abstract": [149, 1407], "body": [1416, 36844], "tables": [36857, 42646]}, "batch": 2, "pmid": 30339666, "doi": "10.1371/journal.pone.0205183", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6195265", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6195265"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6195265\">6195265</a>", "list_title": "PMC6195265  The benefits of negative yet informative feedback"}
{"text": "Liu, Hua and Xu, Jian-Yang and Li, Lin and Shan, Bao-Ci and Nie, Bin-Bin and Xue, Jing-quan\nEvid Based Complement Alternat Med, 2013\n\n# Title\n\nfMRI Evidence of Acupoints Specificity in Two Adjacent Acupoints\n\n# Keywords\n\n\n\n# Abstract\n \n Objectives  . Acupoint specificity is the foundation of acupuncture treatment. The aim of this study is to investigate whether the acupoint specificity exists in two adjacent acupoints.   Design and Setting  . Two adjacent real acupoints, LR3 (Taichong) and ST44 (Neiting), and a nearby nonacupoint were selected. Thirty-three health volunteers were divided into three groups in random order, and each group only received acupuncture at one of the three points. While they received acupuncture, fMRI scan was performed.   Results  . The common cerebral activated areas responding to LR3 and ST44 included the contralateral primary somatosensory area (SI) and ipsilateral cerebellum. Acupuncture at LR3 specifically activated contralateral middle occipital gyrus, ipsilateral medial frontal gyrus, superior parietal lobe, middle temporal gyrus, rostral anterior cingulate cortex (rACC), lentiform nucleus, insula, and contralateral thalamus. Stimulation at ST44 selectively activated ipsilateral secondary somatosensory area (SII), contralateral middle frontal gyrus, inferior frontal gyrus, lingual gyrus, lentiform nucleus, and bilateral posterior cingulate cortex (PCC).   Conclusions  . Acupuncture at adjacent acupoints elicits distinct cerebral activation patterns, and those specific patterns might be involved in the mechanism of the specific therapeutic effects of different acupoints. \n \n\n# Body\n \n## 1. Introduction \n  \nAcupuncture, originated in ancient China, has been used as a treatment method in Asia for thousands of years. Nowadays, the therapeutic effect of acupuncture is gradually recognized in the western world. The National Institutes for Health of the United States have recommended acupuncture as an alternative and complementary treatment for many health conditions [ ]. According to the traditional Chinese acupuncture theory as well as clinical practices, performance in specific acupoints can treat specific disorders. However, the exact physiological mechanism of acupuncture therapy is still unclear. \n\nIn the past decades, many studies of acupuncture on experimental animals have shown that acupuncture elicits therapeutic effect through modulating the neuroendocrine system [ ]. Since 1990s, owing to the development of noninvasive brain imaging techniques such as functional MRI (fMRI) and positron emission tomography (PET), people have begun to address acupuncture investigation in human beings using functional imaging methods [ \u2013 ]. Siedentopf et al. reported that acupuncture at vision-related acupoints in the foot activated the visual association cortex with fMRI imaging [ ]. Acupuncture at acupoints with strong analgesic effect, such as LI4 (Hegu), ST36 (Zusanli), and GB36 (Waiqiu), can modulate the hypothalamus and limbic system which are pain-related neuromatrix [ \u2013 ]. These results imply that the modulation effect of acupuncture might be related to the central nervous system. Moreover, acupuncture at specific acupoints could induce cerebral specific activation patterns. Our former work also shows there are specific cerebral patterns responding to different acupoints [ ].  \n\nIn the former studies on the acupoints specificity, the selected acupoints were generally far-between each other on the human body. In the current study, we chose two different and adjacently located acupoints to minimize the effect of general neural stimulation. If similar cerebral responses are derived from two real acupoints, the acupoints specificity needs to be further discussed. Otherwise, if significantly different activated areas are found, the theory of acupoint specificity will be supported.  \n\n\n## 2. Design and Setting \n  \n### 2.1. Subjects \n  \nThis study comprised 33 healthy right-handed volunteers (17 males and 16 females), aged 25.3 \u00b1 2.8 (mean \u00b1 S.D.), without any history of psychiatric, neurological disorders, and substance abuse. All subjects had no acupuncture therapy experience. Each subject had provided informed consent with the adequate understanding of the procedure and purpose of this study. All subjects were free to withdraw from the experiment at any time. The protocol was approved by the local Ethics Committee.  \n\n\n### 2.2. Stimuli \n  \nSince manual acupoint stimulation is classical acupuncture, we adopted this acupuncture mode in this experiment. The silver needle is 0.30\u2009mm in diameter and 25\u2009mm in length. All acupuncture manipulations were performed by the same skilled acupuncturist. Two real acupoints and one nearby nonacupoint were selected in this experiment. The acupoint LR3 (Taichong) is located in the dorsum of the foot, in the depression anterior to the junction of the first and second metatarsals. The acupoint ST44 (Neiting) is located on the dorsum of the foot, proximal to the web margin between the second and third toes. Their nearby nonacupoint is located on the dorsum between the first and second metatarsals, approximately 10\u2009mm anterolateral to LR3 and posteromedial to ST44 ( ). The skilled acupuncturist identified that it was not located in any meridians. \n\nAll volunteers were divided into three groups in random order, and each group only received acupuncture at one of the three points. They were informed that they would receive acupuncture on the foot without being told the nature of the stimulation point. All the acupoints in this experiment were on right foot and anatomically innervated by the L5 spinal nerve. \n\n\n### 2.3. Scanning Procedure \n  \nThe experiments were performed on a 1.5 Tesla whole body scanner (Sonata, Siemens, Germany), with a standard head coil. The images covered whole brain and paralleled to the AC-PC line. Initially, the T -weighted spin-echo images were obtained for anatomical reference. For the fMRI images, we employed a blood oxygenation level-dependent (BOLD) T *-weighted gradient-echo EPI sequence with TR 3000\u2009ms, TE 50\u2009ms, flip angle 90\u00b0, field of view 220\u2009mm \u00d7 220\u2009mm, matrix 64 \u00d7 64, 6\u2009mm slice thickness and 1.2\u2009mm gap. \n\nGiven the fact that the therapeutic effect of acupuncture will last several minutes to several hours, which is called post effect, we adopted a single block design to avoid the influence of unknown duration of post effect [ ,  ]. During scanning, subjects lay supinely on the scanner bed, keeping relaxed and calm. Their eyes were covered with blinders (Aearo Co., USA) and ears were plugged with earplugs (Aearo Co., USA). The lights in the scanning room were dimmed, and there were no sounds except scanner noise. When 62 baseline scans were finished, a sterile silver needle was inserted and twirled for 60 scans. Then the needle was withdrawn. While the scan continued, till total 402 scans were acquired. The needle was twirled manually clockwise and anticlockwise at about 1\u2009Hz frequency with \u201ceven reinforcing and reducing\u201d manipulation. The depth of needle insertion was approximately 15\u2009mm for the real acupoint as well as the nonacupoint. \n\n\n### 2.4. Data Analysis \n  \nThe fMRI data were analyzed with statistical parametric mapping software (SPM2, Welcome Department of Imaging Neuroscience, London, United Kingdom,  ). The first two images of each scan were discarded to avoid the nonequilibrium effects of magnetization, so every subject had 400 volumes. All volume images were automatically realigned to the first image of the time series to correct for head movement between scans. After realignment, the images were normalized and transformed into the Montreal Neurological Institute (MNI) space. Then spatial smoothing was done with a 9\u2009mm \u00d7 9\u2009mm \u00d7 9\u2009mm Gaussian kernel. The smoothed data were processed with two levels. At the first level, each subject's data was, respectively, analyzed using fixed effect analysis based on the general linear model with a box-car reference waveform. The cerebral areas activated during acupuncture at the real acupoint and the nonacupoint relative to baseline were obtained. At the second level, in order to acquire the specific active areas induced by stimulating at the real acupoint compared to the nonacupoint, group analysis was performed using random effects analysis based on the two-sample   t  -test model with the results of first level (height threshold,   P   = 0.01 corrected, spatial extent threshold, 10 voxels). The coordinates in Talairach space were obtained by applying the Mattew Brett correction (mni2tal:  ) to the SPM-MNI coordinates.  \n\n\n\n## 3. Results \n  \nDeqi is a unique sensation of numbness, tingling, fullness, and dull ache that develops at the site of acupuncture and may spread some distance from the acupuncture point during needle manipulation. After scan, subjects were questioned as to the type and intensity of their psychophysical feeling to acupuncture. Based on their answers, all subjects who received stimulation at real acupoint experienced distinct sensation of Deqi. In all subjects who received stimulation at nonacupoint, only one subjects reported sensation of Deqi. \n\nCommon areas activated by manual acupuncture on two real acupoints relative to nearby nonacupoint were illustrated in  , and specific areas activated by stimulation of LR3 or ST44 were showed in  . All results were summarized in  . Acupuncture at LR3 significantly activated contralateral middle occipital gyrus (BA19), bilateral primary somatosensory area (SI), ipsilateral medial frontal gyrus (BA10), superior parietal lobe (BA7), middle temporal gyrus (BA21), rostral anterior cingulate cortex (rACC, BA24), lentiform nucleus, insula, cerebellum, and contralateral thalamus. Alternatively, acupuncture at ST44 selectively activated contralateral primary somatosensory area (SI), ipsilateral secondary somatosensory area (SII), lingual gyrus, lentiform nucleus, contralateral middle frontal gyrus (BA10), inferior frontal gyrus (BA47), bilateral posterior cingulate cortex (PCC, BA29), and cerebellum. \n\n\n## 4. Discussion \n  \nIn the present study, we applied manual acupuncture at two adjacent real acupoints and their nearby nonacupoint, which are all innervated by the same spinal segment, to further explore the acupoint specificity. The result showed that acupuncture at LR3 and ST44 elicited distinct response patterns, though they shared certain activation areas in common.  \n\nThe obvious overlapping activated areas of LR3 and ST44 were contralateral primary somatosensory area (SI) and ipsilateral cerebellum. The activations of these areas have also been reported by some previous studies on the acupuncture at other acupoints [ ,  ,  \u2013 ]. Nakagoshi et al. have acupunctured 6 acupoints, respectively, and summarized that SI might be partly responsible for acupuncture effect [ ]. The same situation happened with cerebellum. Stimulation of acupoints might arouse the modulation effect of cerebellum beyond classical involvement of cerebellum in motor coordination [ ].  \n\nStimulation of LR3 selectively activated the middle occipital gyrus (BA19) which is considered as visual cortex. The study of Siedentopf et al. found that electroacupuncture at eye-related acupoints in the foot activated visual cortex [ ]. Besides middle occipital gyrus (BA19), stimulation of LR3 also activated the medial frontal gyrus (BA10), superior parietal lobe (BA7), thalamus, and the limbic system. These areas were involved in visceral modulation [ ]. It is worth to notice that LR3 were also very effective for visceral pain and body paralysis. The results confirmed the view that therapeutic effects of acupuncture may work through the central nervous system pathway. \n\nAcupuncture at ST44 specifically activated superior frontal gyrus, inferior frontal gyrus and secondary somatosensory area (SII). Frontal areas are known to be related to pain [ ], especially for abirritation of visceral pain. Activation of the SII cortex is thought to be related to the sensory-discriminative aspect of pain processing [ ]. These areas have been reported in previous studies of pain treatment by acupuncture [ ,  ]. In clinical practice, it is often used to cure toothache, sore throat, stomachache, swelling, and pain of dorsum of foot. This finding implied that acupuncture at ST44 may modulate activities of the frontal areas and SII cortex to inhibit pain. \n\nCompared with previous experiment paradigm, our investigation chose two adjacent acupoints and their nearby nonacupoint to explore the acupoint specificity. Since we adopted two adjacent acupoints, the same nonacupoint could be available. The specific activated areas of two acupoints were acquired by contrasting the real acupoints with the same nonacupoint. Therefore, the effect of neural stimulation might be thoroughly eliminated from acupuncture stimulation. Our results might be more credible than previous studies. \n\n\n## 5. Conclusions \n  \nIn this study, results demonstrated that acupuncture at adjacent acupoints could elicit different fMRI activation patterns in the human brain. It is reasonable to suggest that acupuncture at different acupoints may modulate specific cerebral areas. Our results provide supplementary neuroimaging evidence for the existence of acupoint specificity. It is helpful to interpret the underlying mechanism of acupuncture. \n\n \n\n# Table(s)\n## ID: tab1\n### Label: Table 1\nBrain areas\tSide\tLR3 versus nonacupoint\tLR3 versus nonacupoint\tLR3 versus nonacupoint\tLR3 versus nonacupoint\tST44 versus nonacupoint\tST44 versus nonacupoint\tST44 versus nonacupoint\tST44 versus nonacupoint\nBrain areas\tSide\tTalairach (mm)\tTalairach (mm)\tTalairach (mm)\tTalairach (mm)\tTalairach (mm)\tTalairach (mm)\tTalairach (mm)\tTalairach (mm)\nBrain areas\tSide\tX\tY\tZ\tZmax\u2061\tX\tY\tZ\tZmax\u2061\nPrimary somatosensory area\tR\t30\t\u221214\t60\t2.54\t\t\t\t\nPrimary somatosensory area\tL\t\u221238\t\u221214\t60\t2.45\t\u221230\t\u221213\t60\t3.09\nSecondary somatosensory area\tR\t\t\t\t\t59\t\u22129\t21\t3.03\nMiddle frontal gyrus\tR\t14\t65\t10\t3.04\t\t\t\t\nMiddle frontal gyrus\tL\t\t\t\t\t\u22128\t63\t23\t2.71\nInferior frontal gyrus\tL\t\t\t\t\t\u221253\t33\t\u22125\t2.98\nsuperior parietal lobe\tR\t14\t\u221250\t47\t3.16\t\t\t\t\nMiddle temporal gyrus\tR\t61\t\u221216\t\u221214\t2.78\t\t\t\t\nMiddle occipital gyrus\tR\t\t\t\t\t28\t\u221259\t\u22127\t2.68\nMiddle occipital gyrus\tL\t\u221218\t\u221262\t24\t3.09\t\t\t\t\nLingual gyrus\tR\t\t\t\t\t4\t\u221279\t\u22125\t3.26\nACC\tR\t6\t\u221215\t41\t2.81\t\t\t\t\nPCC\tB\t\t\t\t\t0\t\u221248\t15\t3.26\nLentiform nucleus\tR\t28\t\u221218\t\u22121\t3.42\t18\t0\t\u22122\t2.7\nThalamus\tL\t\u221212\t\u221225\t0\t2.6\t\t\t\t\nInsula\tR\t32\t\u221219\t14\t2.65\t\t\t\t\nCerebellum\tR\t42\t\u221256\t\u221238\t2.46\t42\t\u221252\t\u221231\t2.71\nCerebellum\tL\t\u22128\t\u221264\t\u22125\t2.88\t\u221224\t\u221262\t\u221229\t3.55\n### Caption\nActivated regions of brain induced by acupuncture at real acupoint versus nonacupoint.\n### Footer\nAbbreviations: B: bilateral; R: right; L: left; ACC: anterior cingulate cortex; PCC: posterior cingulate cortex.\n", "metadata": {"pmcid": 3676955, "text_md5": "31ec61ae44d8eb0df5f8fc57f5aa9194", "field_positions": {"authors": [0, 91], "journal": [92, 126], "publication_year": [128, 132], "title": [143, 207], "keywords": [221, 221], "abstract": [234, 1633], "body": [1642, 13398], "tables": [13411, 14784]}, "batch": 2, "pmid": 23762172, "doi": "10.1155/2013/932581", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3676955", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3676955"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3676955\">3676955</a>", "list_title": "PMC3676955  fMRI Evidence of Acupoints Specificity in Two Adjacent Acupoints"}
{"text": "Lamm, Claus and Nusbaum, Howard C. and Meltzoff, Andrew N. and Decety, Jean\nPLoS One, 2007\n\n# Title\n\nWhat Are You Feeling? Using Functional Magnetic Resonance Imaging to Assess the Modulation of Sensory and Affective Responses during Empathy for Pain\n\n# Keywords\n\n\n\n# Abstract\n \n## Background \n  \nRecent neuroscientific evidence suggests that empathy for pain activates similar neural representations as the first-hand experience of pain. However, empathy is not an all-or-none phenomenon but it is strongly malleable by interpersonal, intrapersonal and situational factors. This study investigated how two different top-down mechanisms \u2013 attention and cognitive appraisal - affect the perception of pain in others and its neural underpinnings. \n\n\n## Methodology/Principal Findings \n  \nWe performed one behavioral (N\u200a=\u200a23) and two functional magnetic resonance imaging (fMRI) experiments (N\u200a=\u200a18). In the first fMRI experiment, participants watched photographs displaying painful needle injections, and were asked to evaluate either the sensory or the affective consequences of these injections. The role of cognitive appraisal was examined in a second fMRI experiment in which participants watched injections that only appeared to be painful as they were performed on an anesthetized hand. Perceiving pain in others activated the affective-motivational and sensory-discriminative aspects of the pain matrix. Activity in the somatosensory areas was specifically enhanced when participants evaluated the sensory consequences of pain. Perceiving non-painful injections into the anesthetized hand also led to signal increase in large parts of the pain matrix, suggesting an automatic affective response to the putatively harmful stimulus. This automatic response was modulated by areas involved in self/other distinction and valence attribution \u2013 including the temporo-parietal junction and medial orbitofrontal cortex. \n\n\n## Conclusions/Significance \n  \nOur findings elucidate how top-down control mechanisms and automatic bottom-up processes interact to generate and modulate other-oriented responses. They stress the role of cognitive processing in empathy, and shed light on how emotional and bodily awareness enable us to evaluate the sensory and affective states of others. \n\n \n\n# Body\n \n## Introduction \n  \nRecent evidence from functional neuroimaging studies suggests that the perception of pain in others activates similar neural circuits as the first-hand experience of pain - especially in regions processing the affective-motivational dimension of pain, such as the anterior insula and the anterior cingulate cortex  \u2013 . These findings stress the importance of implicit and automatically shared neural representations between self and other for the experience of empathy  ,  . \n\nRecent models of empathy, however, also emphasize the role of top-down processes such as perspective taking and self/other awareness  ,  . These models emphasize that empathy is not an all-or-none phenomenon. Its experience is malleable by a number of factors including personality traits and the type of situation in which social interaction occurs. However, little is known about the neural mechanisms underlying the modulation of empathy. For example, physiological research has shown that evaluating either the sensory or the affective consequences of first-hand pain recruits neural pathways specifically involved in sensory discrimination and affective-motivational processing  . It remains unclear whether this also hold true for the perception of pain in others. We also have only cursory knowledge about how cognitive processes such as deliberate appraisal of the other's situation modulate the empathic reaction to the pain of others. \n\nThe aim of the present study was to investigate how two cognitive mechanisms of top-down control \u2013 attention and appraisal \u2013 affect the psychological and neural correlates of empathic responding. To this end, we performed one behavioral experiment and two subsequent fMRI experiments. The behavioral experiment served for stimulus validation and design optimization, while the fMRI experiments assessed the roles of evaluative focus and cognitive appraisal on brain activity during empathy for pain. More specifically, the first fMRI experiment explored whether focusing on the sensory or the affective consequences of pain in others results in modulation of the hemodynamic signal in areas of the pain matrix processing sensory or affective information. The second fMRI experiment investigated how these responses are modulated by evaluating a putatively harmful situation which is actually not painful. In addition, a number of behavioral and dispositional measures were taken in order to assess the effects of individual differences in empathy and emotion contagion on brain activation during empathizing. \n\nThe question whether focusing on the sensory or affective consequences of another's pain recruits distinct neural networks springs from an ongoing controversy about whether only the affective-motivational or also the somatosensory-discriminative components of pain processing are involved in empathy for pain. Most fMRI studies to date suggest that witnessing another's pain does not recruit areas that are typically involved in coding the sensory aspects of one's own pain - such as the somatosensory cortex (SI/SII and posterior insula) for thermal or mechanical pain (e.g.,  ,  ,  ,  ). In contrast, transcranial magnetic stimulation (TMS)  ,  , electroencephalography  ,   and magnetoencephalographic measurements   suggest a role of sensorimotor representations during the perception of pain in others. One explanation for these discrepancies between fMRI and other measures is the way in which participants observed the targets. For instance, in the TMS studies participants were explicitly instructed to focus on what the depicted person may have felt during the injection of a needle into the hand or the foot \u2013 directing their attention to the sensory aspects of pain, as well as to the affected body part. This interpretation is supported by a positron emission tomography (PET) study showing that focusing on the location of pain on one's own body increased regional cerebral blood flow in the contralateral primary somatosensory cortex and the inferior parietal lobule  . Thus, it seems that directing attention (a top-down influence rather than an automatic reaction) can increase the neural activity in somatosensory-discriminative component of pain processing. Notably, a recent fMRI study also demonstrated that the perception of pain of others can be modulated by attentional and task demands  . \n\nIn the first fMRI experiment of this study, we therefore asked participants to either evaluate the sensory or the affective consequences of non-painful and painful situations (needle injections into different parts of a human hand,  ). We expected that focusing on the sensory consequences of the inflicted pain would recruit somatosensory areas in a more pronounced way, whereas attending to affective aspects should result in stronger activation in areas coding the affective-cognitive dimension of pain (such as the anterior insula and the anterior medial cingulate cortex (aMCC)). Conceptually, this approach also poses the interesting question whether there are different \u2018routes\u2019 (i.e., neural pathways) when perceiving another person in pain, whether these pathways can be selectively activated, and to what extent they are similar to those involved in the first-hand perception of pain. \n   Examples for the stimuli used in the behavioral experiment and in fMRI experiment I.  \nThe upper image shows a needle covered by a black protector cap placed next to the hand (non-painful control stimulus). The lower image shows the (painful) injection of the same needle into the hand. \n  \nIn the second fMRI experiment we explored the fact that emotions are malleable to various forms of cognitive regulation - such as suppression or (re)appraisal of the initial affective response  . Research in developmental psychology shows that one's ability to engage in emotion regulation positively relates to feelings of concern for the other person  ,  . Neuroscientific evidence concerning the modulation of the empathic response by cognitive appraisal and emotion regulation is, however, rather sparse. One study investigated the hemodynamic correlates of empathic feelings triggered by interacting with unfair targets  . The results showed signal reductions in areas coding the affective components of the empathic response and signal increases in reward/punishment-related brain areas. Another study recently demonstrated that the appraisal of others' pain is mediated by brain structures involved in stimulus evaluation and emotion regulation (such as the medial orbitofrontal cortex OFC and the right lateral prefrontal cortex  ). Interestingly, this study neither revealed significant signal changes in sensory areas nor in areas thought to be part of the network supporting affective sharing (anterior insula and aMCC; however, activation in a more rostral part of the cingulate cortex was modulated by appraisal). Therefore it challenges the hypothesis that activation in this network indicates some sort of simulation of the other's actual emotional experience. It also shows that the top-down control exerted by appraisal does not seem to act upon early perceptual computations. \n\nThe current experiment exposed participants to situations that normally would cause pain in both self and other (needle injections into a human hand). In some cases, however, the observer knew that the target's hand had been anesthetized in order to render the injection non-painful for the target ( ). We expected the associated down-regulation of empathy to be accompanied by signal modulations in OFC and medial and lateral prefrontal areas, as well as in brain regions involved in self/other distinction. In addition, we anticipated significantly reduced activation in the affective components of the pain matrix, reflecting the absence of pain in the target. \n   Samples for the stimuli used in fMRI experiment II.  \nThe upper image shows a (non-painful, but unpleasant) tissue biopsy from the numbed hand. The lower image show the (painful) injection of novocaine into the hand. Note the different types of syringes used in the two conditions, indicating their different functions. \n  \n\n## Results \n  \n### Behavioral experiment \n  \nPhotographs depicting needle injections led to higher pain intensity and pain unpleasantness ratings than the photographs in which the needle was covered by the black protector cap (main effect   stimulus   (  painful   vs.   non-painful  ), F(1,22)\u200a=\u200a510.641,   P  <0.001, \u03b7 \u200a=\u200a0.959). In addition, the mean intensity and unpleasantness ratings were significantly different (main effect for   rating  , F(1,22)\u200a=\u200a13.389,   P  \u200a=\u200a0.001, \u03b7 \u200a=\u200a0.378), while no significant interaction term was found (  P  \u200a=\u200a0.413). The following ratings (mean\u00b1S.D.) were obtained: intensity/painful 64.84\u00b119.065; intensity/non-painful: 1.444\u00b12.221; unpleasantness/painful: 69.033\u00b114.225; unpleasantness/non-painful: 9.164\u00b114.304). The Pearson correlation between intensity and unpleasantness ratings was   r  \u200a=\u200a0.769 (  P  <0.001), showing that the two types of rating share about 50% of their variance. When the non-painful stimuli were excluded from this calculation, the correlation remained basically unchanged (r\u200a=\u200a0.797) - indicating that the two stimulus dimensions have similar correlation for both painful and non-painful stimuli. On average, ratings were given within about 2.5 s (average response times for intensity and unpleasantness ratings 2.693 s and 2.767 s, respectively; no significant main effects or interaction for response times,   Ps  >0.153). The mean scores of the eight blocks revealed that ratings did not systematically decrease over the course of the experiment (non-significant main effect of the factor block:   P  \u200a=\u200a0.410, \u03b7 \u200a=\u200a0.04; non-significant interaction block\u00d7rating,   P  \u200a=\u200a0.335, \u03b7 \u200a=\u200a0.049). \n\n\n### Functional MRI experiments \n  \n#### Dispositional measures \n  \nResults for the three questionnaires (Interpersonal Reactivity Index IRI  , Emotional Contagion Scale ECS  , Sensitivity to Pain Questionnaire SPQ  ) and their subscales are documented in  . Data for the IRI are well within published norms (as reported in detail in  ), while the sample mean for the ECS was slightly below the norm average. SPQ sample means are comparable to a study collecting data from 96 normal controls  . Correlation coefficients (Pearson) reveal that the ECS correlates significantly with the IRI Fantasy scale (  r  \u200a=\u200a0.513,   P  \u200a=\u200a0.029), the IRI Empathic Concern scale (  r  \u200a=\u200a0.469,   P  \u200a=\u200a0.049), and the IRI Personal Distress scale (  r  \u200a=\u200a0.545,   P  \u200a=\u200a0.019). The discrimination score (P(A)) of the SPQ was inversely related to the Personal Distress scale (  r  \u200a=\u200a\u22120.504,   P  \u200a=\u200a0.033), and positively correlated with IRI Perspective Taking (  r  \u200a=\u200a0.519,   P  \u200a=\u200a0.027). In addition, P(A) showed a significant correlation with the response bias value   B   of the SPQ (  r  \u200a=\u200a0.648,   P  \u200a=\u200a0.004).   B   also significantly correlated with IRI's Personal Distress subscale (  r  \u200a=\u200a\u22120.605,   P  \u200a=\u200a0.008), and a trend towards significance was observed for ECS (  r  \u200a=\u200a\u22120.454,   P  \u200a=\u200a0.059). \n\n\n#### Pain ratings in the scanner \n  \nSimilar to the behavioral experiment, photographs depicting injections led to significantly higher rating scores than images of the needle with the protector cap (main effect   stimulus  , F(1,17)\u200a=\u200a348.815,   P  <0.001, \u03b7 \u200a=\u200a0.954). This was the case for both intensity and unpleasantness ratings (mean\u00b1S.D. for intensity/painful stimulus: 69.789\u00b114.654; intensity/non-painful stimulus: 3.548\u00b19.68; unpleasantness/painful: 71.237\u00b113.65; unpleasantness/non-painful: 2.054\u00b14.005). Neither the interaction term (  P  \u200a=\u200a0.287) nor the main effect of rating were significant (  P  \u200a=\u200a0.982). No significant change in scores across the two imaging runs was observed, indicating the absence of strong habituation. \n\nIn the second fMRI experiment ( ), injections into a numbed hand were perceived as non-painful, but considerably unpleasant \u2013 while injections into a hand that was not numbed were perceived as both highly painful and unpleasant (main effect numbed vs. non-numbed: F(1,16)\u200a=\u200a404.426,   P  <0.001, \u03b7 \u200a=\u200a0.962; rating/intensity vs. unpleasantness: F(1,16)\u200a=\u200a90.444,   P  <0.001, \u03b7 \u200a=\u200a0.850; significant interaction appraisal\u00d7rating: F(1,16)\u200a=\u200a145.33,   P  <0.001, \u03b7 \u200a=\u200a0.901; significant post-hoc test contrasting injections into non-numbed vs. numbed hands for unpleasantness ratings, F(1,16)\u200a=\u200a90.444,   P  <0.001). Again, scores did not significantly change over the course of the experiment. Note that due to excessive movement during experiment II, one participant had to be excluded from all analyses. \n   Behavioral data from fMRI experiment II.  \nInjections led to high intensity and unpleasantness ratings, while rated pain intensity for the numbed hand stimuli is close to zero. Note also that although the unpleasantness ratings for the numbed hand stimuli are significantly smaller than for the injection stimuli, they are substantially high and significantly different from zero. \n  \n\n\n### fMRI experiment I \u2013 effects of evaluative focus \n  \n#### Perception of Pain vs. NoPain \n  \nIn order to assess the neuro-hemodynamic response to the perception of painful situations, we contrasted activation during painful injections with those where the needle was covered by the black cap (pooled for the two rating conditions, i.e., All_painful>All_Non-painful). This contrast indicated the involvement of large portions of the pain matrix  ,  . Activation clusters were detected in areas coding the affective, the sensory and the motor aspects associated with nociception ( ). Brain areas involved in affective-motivational coding included the dorsal and ventral aMCC, bilateral anterior insula, and right middle insula. Large activation clusters extending from supramarginal gyrus into the postcentral gyrus reflect the involvement of primary and higher-order somatosensory areas (Areas 1 and 2, Area OP4, bilaterally; all areas defined based on cytoarchitectonic probability maps from the Anatomy Toolbox;  ). Bilateral motor activations were observed in cortical, basal ganglia (striatum) and cerebellar motor areas (rostral supplementary motor area and cingulate motor area, dorsal lateral premotor areas, caudate nucleus and putamen). In addition, strong bilateral involvement of the supramarginal gyri and of inferior frontal gyri (ventral premotor cortex, pars opercularis, Area 44) indicated the contribution of areas associated with the anticipation of action consequences. Activations were also found in the thalamus, in right medial frontal gyrus, and in the superior part of the periaqueductal grey. The consistency of the group analysis was confirmed by analyses on the single-subject level \u2013 as the five functional regions of interest (ROIs) described in the   section were clearly activated in the majority of participants.   shows the peak coordinates of these ROIs for each individual participant. \n   Significant clusters from the random effects contrast painful>non-painful (intensity and unpleasantness rating trials pooled) of fMRI experiment I, displayed on a high-resolution structural MRI template in MNI space (used in all figures, displayed in neurological convention; red numbers indicate slice number).  \nThe anatomical labels designate the approximate location (in the rfx average) of the functional ROIs (see text for abbreviations). Threshold   P  \u200a=\u200a0.01 (FDR-corrected),   k  \u200a=\u200a10. \n  \n\n#### Intensity vs. Unpleasantness of pain \n  \nTo investigate whether evaluating the sensory or the affective consequences of painful stimulation leads to differential activation in the pain matrix we assessed the interaction contrasts of our design. The contrast   Intensity (Painful>Non-Painful)>Unpleasantness (Painful>Non-Painful)   yielded several significant clusters in the sensori-motor network identified by the comparison of painful and non-painful stimuli. The strongest activation modulation was obtained in right postcentral gyrus, contralateral to the stimulated target's hand. This indicates an important role of somatosensory processing in differentiating between sensory and affective stimulation consequences. The involvement of areas associated with anticipating action consequences was indexed by activation clusters in inferior parietal cortex/supramarginal gyrus and ventral premotor areas (see  ;  ). Notably, the two types of rating did not modulate activation in the anterior insular cortices. However, activation differed in mid- and posterior insular cortices - i.e., in areas that are specifically involved in the first-hand experience of pain. The increased thalamic activation might be related to a similar mechanism (see  ). In addition, stronger activation was observed in the aMCC at the transition zone from the cingulate gyrus to the superior frontal gyrus. The reverse interaction [  Unpleasantness (Painful>Non-Painful)>Intensity (Painful>Non-Painful)  ] only yielded a significant cluster in visual cortex (right lingual gyrus, MNI 23/\u221282/8). Lowering the threshold to   P  \u200a=\u200a0.005,   k  \u200a=\u200a5, revealed additional clusters in the right cerebellum, and in subcallosal cingulate cortex (see  ). \n   Significant differences resulting from the interaction contrasts Intensity (Painful>Non-painful)>Unpleasantness (Painful>Non-painful) and vice versa.        \n\n#### Relationship between dispositional and behavioral measures and brain activation \n  \nEmotional contagion scores correlated significantly with activation (All_painful>Baseline) in the affective-motivational component of the pain matrix, including bilateral anterior insula and two distinct clusters in aMCC. While insular activation overlapped almost perfectly with the clusters detected by the contrast of painful with non-painful stimuli, activation in aMCC was considerably more rostral. Additional significant correlations were observed in bilateral supramarginal gyri, the precuneus, and various visual areas. \n\nThe correlation between the IRI empathic concern subscale and activation differences between painful and non-painful trials (All_painful>All_non-painful) yielded significant positive correlations in bilateral dorsal premotor cortex, left ventral premotor cortex, left somatosensory cortex, in medial bilateral posterior precuneus and in bilateral fusiform gyrus. No significant clusters were detected in insular or cingulate cortices, even when lowering the threshold to   P  \u200a=\u200a0.005. However, an additional large cluster in the right supra-marginal gyrus was detected at the lower threshold (stereotactic coordinates x/y/z\u200a=\u200a56/\u221237/41). \n\nCorrelation analyses with pain ratings indicated an important role for posterior inferior temporal gyrus and bilateral ventral premotor cortex (Area 45, pars triangularis) in evaluating the amount of pain and its unpleasantness. Pain intensity ratings were additionally associated with activation in contralateral precentral gyrus, and in dorsal posterior cingulate gyrus in a region involved in visuo-spatial attention  . Significant correlations in supramarginal gyrus extending into SII suggest that focusing on the affective consequences selectively recruited this region (see   for a complete list of correlations). \n\n\n\n### fMRI experiment II \u2013 effects of cognitive appraisal \n  \n#### Whole brain analyses \n  \nThe aim of fMRI experiment II was to assess how activity in the pain matrix is modulated by the appraisal of a seemingly painful and aversive, but actually non-painful situation. According to the information given to the participants, the novocaine injections and the subsequent biopsies on the numbed hand differed in one crucial aspect: While the numbing of the target's hand resulted in a complete loss of pain somatosensation, the targets still experienced unpleasantness and discomfort due to the surgical procedure. As indicated above, the behavioral data show a clear effect of this instruction on the pain ratings since putative anesthesia reduced imputed pain. At the neural level, we hypothesized a similar differentiation in neural activity between intensity and unpleasantness ratings. Brain activation in areas of the pain matrix was expected to be different during intensity ratings while unpleasantness ratings should hardly result in activation differences - since both the injections into the numbed and into the non-numbed hand were supposed to be unpleasant for the target. Statistically, this hypothesis was assessed by the interaction terms between the factors rating and stimulus. \n\nThe interaction contrast [Intensity: Numbed hand>Painful Injection)>(Unpleasantness: Numbed Hand>Painful Injection] yielded significant clusters in the precuneus and bilaterally in the temporo-parietal junction (see  ). Interestingly, these effects resulted from a relative difference in deactivation between conditions \u2013 with the target contrast (numbed hand>baseline during intensity trials) being the only condition that showed activation and all the other conditions showing deactivation. Activation differences were also detected in middle and anterior inferior temporal gyrus, in particular in both temporal poles \u2013 a region supposedly involved in linking perceptual information with emotional and visceral responses as well as in mentalizing  . In the frontal lobe, activation differed in medial and in superior frontal gyrus as well as in lateral OFC. There were no significant clusters in occipital primary or secondary visual areas, not even when lowering the threshold to   P  \u200a=\u200a0.05 (uncorrected). The reverse interaction ((Unpleasantness: Numbed hand>Injection)>(Intensity: Numbed hand>Injection)) revealed significant signal modulation in the left anterior insula, the cerebellum, OFC cortex and the basal ganglia. Lowering the threshold to   P  \u200a=\u200a0.005 yielded additional clusters in right anterior insular cortex, and in the inferior parietal cortex/supramarginal gyrus. See   for a complete list of significant activations. \n   Significant clusters in anterior and posterior precuneus (aPRC and pPRC) and in the right temporo-parietal junction (TPJ) revealed by the interaction contrast (Intensity: Numbed>Injection)>(Unpleasant: Numbed>Injection).  \nThreshold   P  \u200a=\u200a0.001 (uncorrected),   k  \u200a=\u200a5. \n     Significant differences resulting from the interaction contrasts Intensity (Numbed>Non-numbed)>Unpleasantness (Numbed>Non-numbed) and vice versa.        \nIn addition, we scrutinized the contrasts Numbed Hand>Painful Injection and Painful Injection>Numbed Hand for those trials in which participants evaluated pain intensity. This analysis was performed to capture differences that might have been missed by the interaction analyses \u2013 whose results also depend upon the assumption of no or negligible differences for the unpleasantness evaluations of injections and numbed hands. This analysis basically confirmed the results of the interaction contrasts - showing that the latter mainly resulted from of a lack of differences for unpleasantness ratings along with different hemodynamic responses during the intensity ratings. However, a few additional clusters were detected (see  ). The contrast Intensity: Numbed>Injection revealed significant clusters in perigenual anterior cingulate cortex (ACC), subcallosal ACC, medial OFC, bilateral superior frontal gyrus, and in the pars orbitalis and triangularis of the right inferior frontal gyrus. Lowering the threshold to   P  \u200a=\u200a0.005 (uncorrected) yielded additional clusters in medial OFC and a small cluster encompassing right pre- and postcentral gyrus (Areas 3 and 4; see   and  ). The reverse contrast (Intensity: Injection>Numbed;  ) indicated additional activation differences in bilateral dorsal and ventral premotor cortex, in bilateral superior parietal lobe and bilateral lateral precuneus, and in several thalamic nuclei. \n   Additional clusters in orbitofrontal cortex (OFC) and subcallosal/perigenual ACC when contrasting the biopsy with the injection condition during pain intensity ratings (numbed>injection; intensity rating trials only).  \nThreshold   P  \u200a=\u200a0.005 (uncorrected),   k  \u200a=\u200a5. \n  \nFurthermore, in order to assess the reproducibility of results across the two fMRI experiments, we compared the results of the contrasts Painful Injection>Baseline (experiment II) and Painful stimuli>Baseline (experiment I; both contrasts pooled for intensity and unpleasantness ratings). This comparison indicated excellent reproducibility of results, with experiment II yielding basically the same findings as experiment I for the painful injections. \n\n\n#### ROI analyses \u2013 effects of cognitive appraisal \n  \nWe specifically assessed activation in six ROIs (three in medial cingulate cortex, bilateral anterior insulae, contralateral primary somatosensory cortex) hypothesized to reflect different kinds of affective information processing during empathy for pain. These analyses tested hypotheses about activation differences in   a priori   and functionally defined areas with higher sensitivity. In addition, they were used to investigate the time-courses of signal changes without assumptions about the shape of the hemodynamic response. Activation of the anterior insula during affective processing in general as well as during the perception of pain in others is well-documented and seems to be related to interoceptive awareness and affective evaluation  . The same applies for MCC activation, with different subregions being related to distinct processes. While activation in ventral posterior MCC (vpMCC) is usually associated with interoceptive awareness and monitoring of bodily responses  , neurons in dorsal anterior MCC (daMCC) seem to be involved in motor processing triggered by the observation of pain  . Finally, activation in rostral anterior MCC (raMCC) seems to reflect evaluation processes related to the aversive consequences of noxious stimulation. \n\nAll ROIs indicated a \u2018typical\u2019 hemodynamic response peaking around five to seven seconds and returning to baseline levels around fifteen to twenty seconds post stimulus. Signal changes were similar for both the biopsies and the injection stimuli. Significant interaction effects (stimulus\u00d7rating), however, were observed in raMCC where higher signals for injection stimuli rated for pain intensity were accompanied by non-differing responses for unpleasantness ratings (F(1,13)\u200a=\u200a5.069,   P  \u200a=\u200a0.042). In addition, there was a trend towards a significant interaction for the right anterior insula (F(1,16)\u200a=\u200a3.45,   P  \u200a=\u200a0.082). All other linear contrasts were non-significant (all   Ps  >0.152). When contrasting only trials rated for pain intensity, the effect for the right insular ROI was significant (F(1,16)\u200a=\u200a6.34,   P  \u200a=\u200a0.023) \u2013 being related to reduced activation during biopsies on the numbed hand evaluated for pain intensity ( ). In addition, there was a trend towards significance in contralateral somatosensory cortex (F(1,16)\u200a=\u200a3.755,   P  \u200a=\u200a0.07), reflecting higher activation during painful injections. The time-course analyses also revealed an interesting signal time-course for the rostral aMCC cluster - which showed a bimodal signal change with a second hemodynamic response about 9 image volumes (TRs) after stimulus onset for the painful injections (in both rating conditions, see  ). A post-hoc comparison of TRs 9 to 11 contrasting non-numbed and numbed trials (pooled for the two rating conditions) revealed a significant difference for this \u2018late response\u2019 (F(1,13)\u200a=\u200a6.96,   P  \u200a=\u200a0.02). \n   Time-courses in the ROIs (anterior insulae, rostral aMCC and contralateral somatosensory cortex/Area 2) analyzed in fMRI experiment II.  \nNote that all areas show a significant hemodynamic response during both the injection and the numbed hand stimuli. Significant differences as determined by linear contrasts are indicated by asterisks (**\u200a=\u200aP<0.05, * P<0.10, see text for details). \n  \n\n#### Relationship between dispositional and behavioral measures and brain activation \n  \n##### Pain ratings \n  \nWe hypothesized that the degree to which a participant showed a better behavioral differentiation between the numbed and non-numbed stimulus conditions when evaluating pain intensity would correlate with stronger signal differences in the pain matrix as well as in regions involved in emotion regulation and evaluation of stimulus valence. We therefore correlated the signal difference between numbed hand and injection trials (numbed>non-numbed, intensity trials only) with the difference in intensity ratings for numbed and non-numbed stimuli. This revealed a number of significant correlations in a network that largely overlapped with the one identified by the interaction contrast and additionally included a number of areas of the pain matrix (see  ). \n\n\n##### Perspective taking \n  \nA similar result was expected when correlating the scores of the IRI perspective taking subscale with the activation differences between numbed and non-numbed stimuli (again, for intensity trials only). This expectation was largely confirmed, as the analysis revealed a very similar network as the correlation analysis computed with the pain rating differences. Results differed, however, with respect to areas involved in self-awareness and mentalizing such as the posterior precuneus, temporo-parietal junction (TPJ) or medial prefrontal/paracingulate cortex, which \u2013 contrary to our expectations - did not correlate with the perspective taking scores ( ). \n\n\n##### Emotion Contagion \n  \nHere we assessed whether emotion contagion scores were inversely related to the activation difference between intensity-rated numbed and non-numbed trials. Our hypothesis was that a higher susceptibility to emotion contagion (and thus a stronger automatic or bottom-up driven reaction to even the non-painful stimuli) would result in lower activation differences in sensorimotor areas and in areas of the pain matrix. This hypothesis was partially confirmed by significant correlations in medial primary/premotor cortex (Areas 4 and 6) and in inferior parietal areas (supramarginal and angular gyri). However, no correlations were observed for insular or cingulate activations. \n\n\n\n\n\n## Discussion \n  \nThe aim of this study was to investigate how top-down control mechanisms modulate the neural underpinnings of empathy for pain. We assessed (1) whether focusing on the sensory or the affective consequences of another's pain distinctly recruits neural pathways involved in sensory-discriminative and affective-motivational processing; and (2) which brain structures subserve the appraisal and down-regulation of empathic responding when witnessing injections into the numbed hand of another person. In addition, we explored the influence of individual differences in empathic concern, emotion contagion and the sensitivity to pain on this modulation. We will first discuss the individual results of each experiment, and then conclude with a general discussion. \n\n### Behavioral experiment and pain ratings \n  \nResults from the behavioral experiment indicate that participants were able to correctly evaluate the sensory and affective consequences of painful needle injections. Further, the absence of systematic changes in ratings across the course of both fMRI experiments demonstrates that behavioral evaluations were not affected by habituation effects. Interestingly, the correlation between intensity and unpleasantness ratings was similar to correlations obtained during the   first-hand   experience of pain e.g.,  ,  . This suggests that ratings of one's own and another's pain might share some common evaluative processes - at least in terms of their behavioral outcomes. \n\n\n### The role of sensory and affective components in empathy for pain \n  \nA growing number of neuroimaging studies reliably documents that witnessing pain in others activates a similar network as the first-hand experience of pain  ,  . Consistent activation in bilateral anterior insula and in dorsal and ventral aspects of aMCC documents the importance of brain areas involved in the affective-motivational coding of pain. In addition our results generate two crucial insights. First, we observed consistent activation in bilateral somatosensory areas, with activation being more pronounced in the right hemisphere \u2013 i.e., contralateral to the stimulated hand. Second, our results demonstrate an important role of ventral premotor and rostral inferior parietal cortex (supramarginal gyrus, inferior parietal lobule, encompassing the intraparietal sulcus; Area hlP2) in the perception of pain in others. These activations can be interpreted within a conceptual framework stressing the importance of serial predictions and event sequencing to anticipate and understand the actions of others (e.g.,  ). Understanding the consequences of the shown actions is clearly required in both fMRI experiments as participants were asked to infer the consequence of the needle injections and to evaluate them in a fine-grained way using a visual analogue scale (VAS). Following the logic of this framework, activation in inferior parietal areas may result from the object-related actions displayed (with the object being the pricked hand in the current case), while ventral premotor activation is related to anticipating the resulting sensory and affective consequences of the displayed action. This is in line with increased functional connectivity of ventral premotor clusters with medial cingulate areas during the rating of pain in others observed in another study  . Note also that activation in ventral premotor cortex positively correlated with the pain intensity ratings ( ). In addition, part of the clusters in inferior parietal cortex might be related to the coding of nocifensive movements, and the visuospatial encoding of noxious threats  ,  . \n\nThe consistent activation of primary somatosensory cortex can be seen in two, not mutually exclusive ways. First, it might reflect the unspecific co-activation of somatosensory representations by neurons in inferior parietal and premotor cortex that are involved in understanding the action's consequences and by means of a feedback loop activate their associated somatosensory representations. Alternatively, somatosensory representations might be involved more specifically by locating the \u2018impact\u2019 point of the aversive object, hence playing a more causal role in coding the action's sensory and aversive consequences. Depending upon where the hand or finger is punctured, this will inform the observer about the resulting pain intensity or unpleasantness. Partial support for this hypothesis comes from studies on the anticipation of touch (e.g.,  ,  ) as well as from the common coding theory which posits that actions are coded in terms of their perceivable effects  . Which one of these hypotheses is correct and therefore which functional role somatosensory representations play in understanding another's emotion should be determined by future studies. Interestingly, a recent event-related potentials (ERPs) study also reports modulation of somatosensory-evoked potentials with pain intensity but not with pain unpleasantness  , supporting our finding that focusing on the consequences of painful stimulation reliably triggers activation in a neural network involved in action understanding and somatosensation. Note also that both the somatosensory ERPs and our hemodynamic responses cannot be explained by the observation of touch alone as stimuli displaying non-painful touch were used as control stimuli in both experimental paradigms. \n\n\n### Correlations between brain activation and dispositional measures \n  \nThe correlation analyses yield interesting clues as to what aspect of empathic responding our experimental design triggers, and to which psychological processes activations in the pain matrix might be related to. Current neurobehavioral models of empathy (e.g.,  ,  ,  ) emphasize the contribution of both automatic and controlled processes to the conscious experience of empathy. The emotion contagion questionnaire assesses an individual's susceptibility to automatically mimic another's behavior \u2013 a mechanism that is also found in phylogenetically older species (e.g.,  ,  ). Conversely, the empathic concern scale measures the more sophisticated aspect of empathy under cognitive control. Hence, the significant correlations in regions involved in affective-motivational as well as in motor processing with emotional contagion suggest that activation in these areas might be related to more bottom-up driven processes, such as motor resonance and affective sharing. To the contrary, the empathic concern scale does not covary with activations in the anterior insula and ACC. Instead, the pattern of significant correlations in prefrontal cortex and OFC probably relates to the more cognitive components of empathy assessed by this scale. Note though that studies which created a more direct social interaction between observer and target (e.g.,  ,  ) also found correlations in affect-related areas. \n\n\n### Effects of focusing on sensory vs. affective consequences of pain \n  \nThere is an ongoing debate about whether perceiving and understanding the pain of others is mediated by somatosensory or by affective representations. While two TMS studies  ,   and a recent ERP study   suggested involvement of sensorimotor processing, most fMRI results support the idea that the empathizers' response relies upon representing the affective rather than the sensory consequences of the other's pain. One explanation for these discrepancies might be the focus of attention in the fMRI   vs.   the other studies. The instruction of the TMS studies made participants explicitly reason about the sensory consequences of the stimulation and directed their attention to the specific body part that was getting punctured. In addition, as the stimuli were short video-clips, participants could predict the location and the time of impact of the needle on the body surface. This reasoning about the spatio-temporal and the sensory consequences of the stimulation might have triggered increased activation in the sensory-motor system. In our experiments, therefore, we asked participants to focus on either the sensory or the affective consequences of painful stimulations. \n\nThe different instructions recruited distinct neural networks. Focusing on pain intensity was associated with increased signal in contralateral somatosensory cortex (S1) and in contralateral premotor cortex. This indicates a stronger contribution of sensorimotor representations to assessing the sensory consequences of pain. A more immediate representation of the target's actual sensory-somaesthetic experiences is also suggested by stronger activations in areas involved in coding the immediate and first-hand sensory consequences of pain - such as the posterior parts of the insula, the thalamus or the hippocampus. The contralateral middle insular cortex has intrinsic connections to the basal ganglia, and a meta-analysis of neuroimaging studies shows that it is most consistently activated during the first-hand experience of pain   \u2013 suggesting a specific role in coding the sensory-motor aspects associated with pain. This part of the insula also shows stronger signal changes when participants imagine pain from a first-person perspective  ,  ,  . In addition, electrical stimulation of the posterior part of the insula evokes painful sensations while stimulation of more anterior parts does not  . Activations in the thalamus and the hippocampus supplement the view that evaluating for pain intensity leads to a more immediate and direct experience of the target's sensory and affective experience. Notably, the hippocampus might reflect memory-related processes activated during both the first-hand and the vicarious perception of pain  ,  . Focusing on the sensory consequences also resulted in stronger activations in the action anticipation network outlined above (inferior parietal cortex and ventral premotor cortex), as well as in two distinct clusters in the anterior cingulate. The more rostral one of these clusters is located in the transition zone between superior frontal and anterior cingulate gyrus. This region responds selectively to increases in stimulus intensity and in subjective pain intensity  . Conversely, the more caudal cluster can be assigned to the cingulate motor area and most likely supports motor preparation and motor mobilization not specific to pain but to stimulus intensity. \n\nFocusing on the unpleasantness of pain did not lead to significant changes in any brain regions, except for small clusters in visual cortex and in subcallosal ACC. The only indicator of increased affective representations is the cluster in subcallosal ACC. Neurons in this area have been associated with processing of negative affect   and this area has many connections to subcortical autonomic centers. Hence, our initial prediction that the perception of pain in others specifically recruits the sensory and the affective parts of the pain pathways only holds for the sensory realm. Activation during intensity ratings suggests higher personal involvement during that condition. Therefore, even though participants were not explicitly instructed to focus on the affective consequences, this higher involvement may lead to an implicit activation of the affective-motivational parts of the pain matrix to an extent that was similar as during the explicit unpleasantness ratings. Alternatively and in line with the findings of experiment II, the presentation of the aversive stimuli along with the requirement to evaluate their painful consequences might by default activate the affective components of the pain matrix - irrespective of the cognitively mediated attentional focus. Note also that although activation in some somatosensory areas was higher during intensity ratings, unpleasantness ratings led to similar activations of somatosensory cortex \u2013 indicating that the classical separation of a \u2018sensory\u2019 and an \u2018affective\u2019 neural pathway may not apply to the evaluation of pain in others. Interestingly, the significant correlation of unpleasantness ratings with activation in secondary somatosensory cortex also suggests a role of somatosensory representations in rating affective stimulation consequences. \n\nTaken together, the results of fMRI experiment I replicate and extend previous findings concerning empathy for pain by showing a stronger involvement of neural structures involved in action anticipation and somatosensation when focusing on the sensory consequences of mechanically induced pain  ,  ,  . The activation pattern suggests that attending to pain intensity leads to higher personal involvement as indicated by stronger activation of brain areas associated with action understanding, noxious threat evaluation and nocifensive reactions. This might result from pain intensity being the more crucial variable from a survival point of view - as it is more important to evaluate the actual injury inflicted than its affective correlates or \u2018side effects\u2019. \n\n\n### The role of appraisal in empathy for pain \n  \nWithin the framework of appraisal theory  , it is the interpretation of an external or internal event that determines its affective consequences and the associated experiences. This theory emphasizes the importance of cognitive processes for emotional responses, posits their malleability and flexibility, and highlights the role of re-appraisal in coping with adverse life events. Accordingly, identical stimuli can result in surprisingly different affective reactions - depending upon stimulus context and the appraisal and coping mechanisms an individual has developed. This also applies for empathic reactions which are a compound of the eliciting stimulus and the interpretation of that stimulus by the empathizer. Recent findings from an fMRI study support such a view  , showing activation modulation in areas involved in affective processing and valence evaluation (insula and orbitofrontal cortex) with different appraisal. \n\nAn important distinction in neural investigations of appraisal and emotion regulation is to determine areas that are the   sources   of regulation as well as their   sites  .   Sources   of regulation are supposed to implement the actual processes allowing for emotion regulation - for example, by means of executive control or by (re)evaluations of the stimulus or event valence. These processes affect (indirectly or directly) the   sites   representing the actual affective state. For example, it has been shown that anxiety reduction is mediated by rostro-lateral prefrontal areas as the sources and medial prefrontal/anterior cingulate areas as the sites of emotion regulation  . \n\nBased upon neuroimaging evidence and neuronal connectivity, we predicted the sources of modulation to be prefrontal areas involved in valence judgments and executive control (medial and lateral OFC, medial prefrontal cortex), dorsal and rostral areas of the MCC (evaluative and motivational processing), as well as areas relevant for self/other distinction and mentalizing \u2013 such as the medial precuneus, the temporo-parietal junction and the temporal poles. Reduced activity, on the other hand, was expected in the network coding affect such as bilateral anterior insula, bilateral amygdalae, as well as the ventro-medial portion of aMCC. In addition, we explored whether top-down control affects neural processing already at an early perceptual stage, which would result in reduced neural activity in areas involved in visual and somatosensory perception. \n\nThe behavioral data showed a clear interaction between the stimulus type and the type of rating that participants had to perform. While perceiving numbed vs. non-numbed hands resulted in clearly different pain intensity ratings, this effect was significantly reduced for unpleasantness ratings because \u2013 in line with the cover story - the biopsies on the numbed hand were evaluated as unpleasant for the target. This dissociation was associated with activation in areas involved in self/other distinction (precuneus and temporo-parietal junction), emotion regulation and valence evaluation (medial and superior frontal gyrus, OFC), and in action anticipation (right ventral premotor cortex). Such activation modulations can be attributed to the   sources   of appraisal processes. We suggest that the signal changes in the precuneus and the temporo-parietal junction reflect the requirement to distinguish one's own prepotent response to the sight of an aversive event from the knowledge about the actual effects for the shown target. Both the precuneus and the temporo-parietal junction have been associated with processes of self/other distinction, self-awareness and agency. The precuneus has widespread connections to a number of cortical and sub-cortical areas, including the posterior and anterior cingulate cortex and areas involved in motor control. This pattern of connectivity along with neuroimaging evidence on resting state metabolism and self-referential actions suggests a dominant role of this structure in self-awareness  \u2013 . The precuneus also has reciprocal connections to a region initially labeled as parieto-temporo-preoccipital cortex   and coined as the TPJ in recent neuroimaging studies. The TPJ is a heteromodal association cortex associated with the processing of phenomenological and cognitive aspects of the self  . A recent meta-analysis documented that the TPJ is not only involved in various high-level cognitive phenomena such as empathy and theory of mind but also in lower-level computations  . The putative basis for these phenomena are neural computations related to updating and reorienting attention due to violations of expectations and the detection of change. Such a mechanism was also required in the current study where the displayed situation does not result in the aversive consequences it would bear under normal circumstances. \n\nThe involvement of medial and lateral areas of the dorsal medial prefrontal cortex, on the other hand, seems to be associated with cognitive and executive control processes. Areas in prefrontal cortex have been repeatedly associated with emotion regulation (  for review). In the current case, neurons in these areas might be involved in exerting control over an affective response that might have been automatically triggered by the sight of a highly aversive situation. The requirement of affective control might be conveyed by neurons in medial and lateral OFC, providing crucial information about the actual emotional valence of the stimuli  . The importance of the OFC in the regulation of empathic responses is also documented by the fMRI results of  ,   mentioned above, which both required regulation of one's own emotional evaluation of an aversive situation. \n\nWhile our results are well in line with our hypotheses concerning the sources of emotion appraisal, a more complex picture emerges for their sites. Top-down control did not affect early perceptual processing. Even lowering thresholds to liberal levels did not reveal any significant clusters in primary or secondary visual cortex. Such an early interference might have been expected though, given the mixed blocked/event-related design which enabled participants to use anticipatory regulation. Interestingly, a previous study of our lab   also did not detect any modulation in visual-perceptive areas during different cognitive appraisals of painful facial expressions. \n\nThe somatosensory cortex is another potential site of activation modulation. Based upon the results of experiment I, we hypothesized that the primary somatosensory cortex is involved in matching the empathizer's bodily sensations with those of the target and that this matching allows a distinction between the painful vs. non-painful response of the anesthetized hand. The trend towards significance provides some evidence for this interpretation, but future studies are required to assess the effect size and the robustness of this finding. In addition, future studies might want to use a separate localizer task in which the first-hand somatosensory representations of touch or pain are localized in each subject. \n\nAs for activation reductions in the affective sharing network, the whole-brain and the ROI analyses suggest that all conditions triggered similar neural responses in the anterior insula and in MCC/ACC. In all ROIs a pronounced and more or less canonical hemodynamic response was observed. Signal time-courses and amplitudes were hardly distinguishable across stimulus conditions. These time-courses suggest that an automatic response was triggered by the presentation of an aversive and putatively noxious stimulus, resulting in the mobilization of withdrawal-related neural response. Note that the anticipation of a potentially painful stimulus alone is sufficient to activate large aspects of the pain matrix  ,  ,  . \n\nWhile all ROIs showed significant signal changes, it should also be noted that amplitudes in the right anterior insula and in rostral aMCC were lower during the perception of biopsies than during the perception of injections. This signal reduction might reflect the cognitively mediated down-regulation of the automatic affective response. The specific modulation of the right insula lends support to the hypothesized higher sensitivity of right as opposed to left anterior insula to various subjective feelings such as anger, coolness, disgust, trustworthiness or sexual arousal ( , for review). The observed lateralization is also in line with the idea that the right anterior insular/opercular cortex plays a specific role in interoceptive awareness and the representation of visceral responses associated with emotional situations . These \u2018gut feelings\u2019 are thought to provide a substrate for subjective feeling states that are accessible to conscious awareness and hence cognitive appraisal  ,  . Such a viewpoint on emotions stresses the importance of embodied processes and their perception, representation, and appraisal by the organism (e.g.,  ,  . \n\nIn addition to the initial amplitude reduction in raMCC, a second signal increase was detected for the actually painful stimuli. This finding might reflect a second evaluation of the triggered pain \u2013 in some sense a closer or second look at the actual aversiveness of the stimulation, which is only required for the injection but not for the trials with the numbed hand. The idea about a second or late cognitive appraisal of the painful consequences receives support from recent electroencephalographic studies demonstrating late responses during the observation of painful situations in others  ,  . Note also that albeit we used a rapid event-related design the occurrence of a second peak during intensity ratings only cannot be explained by subsequent trials as interstimulus intervals and stimulus order were randomized and counterbalanced. However, future studies with interstimulus intervals allowing for a full return of the hemodynamic response to baseline levels are required to unequivocally exclude this potential confound. On a methodological level, the ROI analyses demonstrate the usefulness of fMRI analyses that are free of assumptions about the signal time-course and enabling to track changes deviating from the standard hemodynamic response shape. \n\nFinally, the correlation analyses corroborate and refine the findings of the contrast analyses. The correlation of activation differences between numbed and non-numbed stimuli with the pain ratings basically identified the \u201cclassical\u201d network detected in studies on empathy for pain. The correlation analyses also supports the interpretation that right anterior insula is more sensitive to affective variations, and that precuneus and TPJ play a specific role in distinguishing between the sensory painful and non-painful events. In addition, they indicate that areas in ipsi- and contralateral pre- and postcentral gyrus might play a more important role in this distinction than the contrast analyses alone suggest. \n\n\n### Conclusion \n  \nOur study demonstrates that the perception of pain in others results in the activation of almost the entire pain matrix - including its sensory-discriminative component. Moreover, both the sensory-discriminative and the affective-motivational component is modulated by the context in which pain has occurred, and by the consequences the observer is focusing on. Interestingly, even knowing in advance that the target is not in pain triggers a similar response as when the target actually perceives pain. This is suggestive of an automatic reaction that might not be specific to pain as such but to being exposed to aversive and potentially threatening situations in general. It also casts some doubts on simulation accounts of empathy, which claim that the commonalities in the anterior insula and anterior cingulate cortex indicate the actual emotion sharing between observer and target (see also  ). In the case of the biopsies on the numbed hand, however, no affect has to be shared and yet insular and cingulate cortices are clearly activated. This initial response might be down-regulated by cognitive mechanism of top-down control. It should be acknowledged that the low temporal resolution of hemodynamic responses might not yield precise enough information about when and how this top-down modulation affects neural activities in the pain matrix. To address this methodological limitation, we are now replicating this paradigm using event-related potential measures. In addition, future studies might want to use online interactions between observer and target to increase the ecological validity of the design. Summing up, our findings shed further light on the crucial role of cognitive processing for the experience of empathy. They demonstrate that in order to achieve a full understanding of this complex phenomenon, we need to frame it as a complex interplay between automatic and bottom-up driven and controlled top-down processes that result in a joint but highly malleable and individual experience. \n\n\n\n## Materials and Methods \n  \n### General design \n  \nForty-four healthy individuals were recruited for this study, which consisted of (1) a behavioral experiment and (2) two subsequent fMRI experiments (evaluative focus and appraisal). The goal of the behavioral experiment was to establish and validate the stimuli and procedures used in the fMRI experiments. Individuals who participated in the behavioral study were not involved in the fMRI experiments to avoid learning and habituation effects. A number of behavioral and dispositional measures were also taken from the fMRI participants. \n\n\n### Participants \n  \nTwenty-three right-handed volunteers (19 females, mean\u200a=\u200a27.69 years, S.D.\u200a=\u200a3.5) participated in the behavioral experiment designed for stimulus selection and validation. Eighteen different right-handed healthy volunteers (9 females) aged between 19 and 35 years (mean\u200a=\u200a23.67 years, S.D.\u200a=\u200a3.99) participated in the two fMRI experiments (role of evaluative focus; role of appraisal). All participants gave informed written consent and were paid for their participation. No subject had any history of neurological, psychiatric or major medical disorder. The study was approved by the local Ethics Committee, and conducted in accordance with the Declaration of Helsinki. \n\n\n### Behavioral experiment \n  \nThe purpose of the behavioral experiment was to investigate whether participants are able to assess the sensory and the affective consequences resulting from needle injections into another person's hand. Participants watched photographs showing injections into different parts of the hands off different targets. After each photograph, they rated \u2013 in separate trials - the intensity or the unpleasantness of pain caused by these injections on a VAS scale. Another goal of the behavioral experiment was to identify those situations which triggered the strongest differences between the two types of rating, and to assess potential habituation effects due to the repeated exposure to similar stimuli. \n\n#### Materials \n  \nA series of 123 digital color photographs showing pain inflicted by needle injections into the left hand of three male and three female targets was used ( ). Hands were placed on a blue uniform background to suggest that pictures had been taken in a medical environment. The needle was injected into different parts of hands and fingers (e.g., close to the nail bed or next to one of the joints) to obtain variation in perceived pain intensity and unpleasantness. None of the photographs showed bleeding, but all of them showed compression and displacement of the skin around the punctured area. In addition, 42 photographs depicting neutral non-painful situations were taken. For those stimuli, the needle was covered with a black plastic cap and placed next to one the fingers. The spatial locations of this protected needle were roughly matched with those of the painful stimuli ( ). \n\n\n#### Procedure \n  \nAfter each stimulus, participants had to rate, from their perspective as viewers, pain intensity or unpleasantness using a VAS. For pain intensity ratings, the question \u201cHow much does it hurt?\u201d had to be answered by moving a cursor between the extreme values \u201cno pain\u201d and \u201cworst imaginable pain\u201d. In the case of pain unpleasantness ratings, the question was \u201cHow unpleasant is it?\u201d, and the VAS ranged from \u201cnot unpleasant\u201d to \u201cextremely unpleasant\u201d. The difference between the sensory and the affective consequences of the painful stimulations were explained using standardized written instructions and using a number of practice trials. Stimuli were presented in eight blocks containing 41 randomly interspersed painful or non-painful stimuli each. Breaks could be taken between blocks. Prior to each block, an instruction screen informed participants whether they had to evaluate pain intensity or pain unpleasantness. The Presentation software (Neurobehavioural Systems , Albany, CA, USA) and a laptop with a TFT screen were used for stimulus presentation and response collection. The screen position of the cursor on the VAS was converted to values ranging from 0 to 100. The time to respond was not restricted, and the VAS slider was moved using the left and right arrows on the laptop keyboard. All participants used their right dominant hand to enter responses. \n\n\n\n### Functional MRI experiments \n  \n#### Behavioral data and dispositional measures \n  \nA number of dispositional measures and behavioral data were collected in and outside of the MRI scanner to assess participants' responses to the different stimuli and conditions, as well as to assess the correlation between hemodynamic responses on the one hand and behavioral data and individual differences in empathic concern, personal distress and other variables on the other hand. In the scanner, ratings of the intensity and the unpleasantness of the inflicted pain were collected using the VAS used in the behavioral experiment. Mean VAS values of conditions were analyzed using a 2\u00d72 repeated measures analysis of variance (ANOVA). Behavioral data and dispositional measures (including pre-test data) were analyzed using SPSS 12.0.1 (SPSS Inc., Chicago, IL, USA), and the significance threshold was set to   P  \u200a=\u200a0.05. \n\nThree questionnaires were filled in by the participants: the Interpersonal Reactivity Index  , the Emotional Contagion Scale  , and the Sensitivity to Pain Questionnaire  . The Interpersonal Reactivity Index (IRI) is probably the most widely used self-report measure of dispositional empathy. Its four subscales (Empathic Concern, Perspective Taking, Fantasy Scale and Personal Distress) assess different aspects of interpersonal affective responses. The Emotional Contagion Scale (ECS) assesses the susceptibility to other's emotions from afferent feedback generated by mimicry, using questions such as \u201cI clench my jaws and my shoulders get tight when I see the angry faces on the news\u201d. Such bodily reactions were expected during the viewing and evaluating of photographs showing painful situations. The Sensitivity to Pain Questionnaire (SPQ) assesses the participants' sensitivity to pain by asking them to assess the amount of stimulus-induced pain they would experience in fifteen painful and fifteen non-painful situations. Based on signal detection theory, a discrimination score (P(A)) and a response bias score (B) is calculated. P(A) indicates the extent to which participants are able to differentiate between painful and non-painful situations while the response bias indicates the degree to which the situations are considered as painful. We explored whether these two scores would modulate signal changes in areas of the pain matrix. \n\n\n\n### Experimental design and procedures \n  \nIn the first fMRI experiment (role of evaluative focus) we investigated how attending to the sensory or the affective consequences of painful stimulation affects regional hemodynamic responses. Participants watched photographs of targets undergoing painful and non-painful surgical procedures and rated pain intensity or pain unpleasantness. A subset of the stimuli used in the behavioral experiment was used for fMRI experiment I. In the second fMRI experiment (role of appraisal), different stimuli and targets were used. Participants were told to watch photographs taken at a local hospital, displaying two successive steps of a surgical procedure performed on the hand. One set of photographs showed the numbing of the hand using novocaine while a second set displayed a tissue biopsy performed on the numbed hand. For both experiments, a mixed blocked/event-related presentation mode and a 2\u00d72 factorial design were implemented. \n\n#### Experiment I (role of evaluative focus) \n  \nThe two experimental factors were the stimulus type (  painful vs. non-painful  ) and the evaluative focus (pain   intensity vs.   pain   unpleasantness  ). A total number of 144 event-related trials were presented in two functional imaging runs (36 trials per condition). Each run contained one block in which participants had to rate the intensity or the unpleasantness of pain. The same standardized written instruction as in the behavioral experiment was used to explain the difference between these two aspects of the pain response. Several practice trials were performed before entering the scanner to ensure appropriate understanding of the instructions and experimental procedures. Each block was preceded by an instruction screen followed by the presentation of 36 painful or non-painful situations in a randomized sequence. A trial consisted of the presentation of a painful or non-painful situation (see above, behavioral experiment) for a duration of 1 s, followed by a white fixation cross or a response screen displaying the VAS (which was replaced by a fixation cross upon responding). Actual pain ratings were requested for 10 randomly selected trials out of the 36 trials presented in each condition and block. The time limit to enter a response was set to 5 s. The inter-stimuli interval was jittered (mean\u200a=\u200a3.5 s, minimum/maximum\u200a=\u200a2/5.8 s) to reduce stimulus predictability and to allow efficient event-related signal estimation  . Each stimulus was presented twice \u2013 once during the intensity rating condition and once during the unpleasantness rating condition \u2013 but stimuli were not repeated within the same run. The order of blocks was counterbalanced across participants. The results from the behavioral experiment were used to select optimal stimuli for the fMRI experiment. Out of the 123 available painful stimuli, those showing the strongest difference between intensity and unpleasantness ratings were selected. Additional selection criteria were that stimuli should show high intensity and unpleasantness ratings, and small interindividual variation in ratings. \n\n\n#### Experiment II (role of appraisal) \n  \n120 event-related trials were presented in two functional imaging runs (30 trials per condition). The experimental factors were painful injections   vs.   non-painful injections (  non-numbed vs. numbed  ) and the rating condition (pain   intensity vs.   pain   unpleasantness  ). Stimuli for the non-numbed hand were shot with the same metallic syringe that had been used in the behavioral experiment and fMRI experiment I. For the numbed-hand stimuli, a white plastic syringe (with the same type and size of needle mounted on it as for the painful injections) was used to allow for easier discrimination. Also, the background was green in order to emphasize the difference from experiment I, and targets differed ( ). According to the explicit verbal and written instructions, the painful novocaine injections and the subsequent biopsies on the numbed hand differed in one crucial aspect. While the numbing of the hand resulted in complete elimination of the somatosensation of pain for the target, the targets experienced unpleasantness and discomfort triggered by the surgical procedure (in the same way as dental work on anesthetized teeth might not be painful, but still unpleasant). Each run contained 12 blocks, with each block consisting of either five numbed hand or five injection trials. Before each block, participants were instructed by a screen insert which type of stimuli they would see, and which aspect of the pain response they were supposed to evaluate (intensity   vs.   unpleasantness). A trial consisted of the presentation of an injection or numbed-hand stimulus, for a duration of 1.7 s, followed by a fixation cross or a response screen displaying the VAS. Actual pain ratings were requested in 12 trials randomly selected out of the 30 trials for each condition. The time limit to enter a response was set to 5 s. Between trials, a white fixation cross was presented on black background, and the interstimulus interval was jittered (mean\u200a=\u200a3.5 s, minimum/maximum\u200a=\u200a2.2/5.8 s). The order of blocks was counterbalanced across participants. \n\n\n\n### Function MRI data acquisition and analysis \n  \nMRI data were acquired on a 3 Tesla head-only Siemens Magnetom Allegra System equipped with a standard quadrature head coil. Changes in blood-oxygenation-level-dependent (BOLD) T2*-weighted MR signal were measured using a single-shot echoplanar imaging (EPI) sequence (repetition time TR\u200a=\u200a1810 ms, echo time TE\u200a=\u200a30 ms, flip angle\u200a=\u200a80\u00b0, 30 axial slices/volume with 4.5 mm slice thickness, no gap, in-plane resolution\u200a=\u200a3.28\u00d73.28 mm , 64\u00d764 matrix, FOV 210\u00d7210 mm ). Each run was preceded by several dummy scans ensuring steady state magnetization conditions. A total of 500 EPI volumes was acquired in the two separate runs for experiment I, and 610 volumes were collected in the two runs performed for experiment II. Experiment II was always performed after experiment I. The reason for this was to avoid potential confusion and carry-over effects from the numbed hand stimuli to the non-painful stimuli from experiment I. An ascending interleaved sequence with no temporal gap between consecutive image acquisitions was used for all functional scans. The influence of in-plane susceptibility gradients in orbitofrontal regions was reduced by orienting image slices according to recommendations by  . \n\nStimulus presentation and response collection were performed using the Presentation software (Neurobehavioural Systems , Albany, CA, USA). Visual stimuli were presented using a back-projection system, and a button box consisting of five buttons recorded the responses of subjects (entered using the dominant right hand). \n\nImage processing was carried out using SPM2 (Wellcome Department of Imaging Neuroscience, London, UK), implemented in MATLAB 6.5 (Mathworks Inc., Sherborn, MA, USA). Preprocessing included slice-timing correction (with the reference slice set to the slice containing the superior-inferior center of the insula), correction for head motion (realignment to mean image volume, using the unwarp and realign function of SPM2 to account for susceptibility-movement interactions in orbitofrontal regions), normalization to the EPI template provided in SPM2, and smoothing using a 6 mm FWHM isotropic Gaussian kernel. Event-related responses were assessed by setting up fixed effects general linear models (GLM) for each subject. Regressors of interest modeling the experimental conditions, the instruction display and the evaluation epochs were set up and convolved with the standard canonical hemodynamic response function. Fixed effects models incorporated a high-pass filter with a frequency cut-off at 128 s. Following model estimation, contrasts were calculated for each subject to assess differences between conditions. In addition, signal changes in relationship to the inherently modeled baseline (i.e., fixation) were assessed. The resulting first-level contrast images were entered into second-level random effects analyses to assess differences between conditions with population inference. \n\nActivity differences between the presentation of   physically   distinct stimuli (  painful vs. non-painful   photographs, and photographs   vs.   fixation) were interpreted using a voxel-level threshold of   P  \u200a=\u200a0.01 and a spatial extent threshold of   k  \u200a=\u200a10, corrected for multiple comparisons across the whole volume using the false discovery rate (FDR) approach  . The more subtle differences in signal strength between conditions that differed   psychologically   (e.g.,   intensity   vs.   unpleasantness   ratings,   painful injection   vs.   numbed injection  ) were thresholded using a more liberal threshold of   P  \u200a=\u200a0.001 (uncorrected for multiple comparisons) and an extent criterion of   k  \u200a=\u200a5. The choice of these thresholds was based upon exploratory data analyses and upon effect size considerations derived from similar experiments of our own and other groups  ,  ,  ,  ,  . In addition, the threshold was lowered to   P  \u200a=\u200a0.005 (uncorrected),   k  \u200a=\u200a5, for   a priori   defined regions involved in the perception of pain and in emotion regulation in order to assess whether they showed activation below threshold. Significant clusters were anatomically labeled using structural neuroanatomy information and probabilistic cytoarchitectonic maps provided in the Anatomy Toolbox (version 1.4;   and the Anatomic Automatic Labeling toolbox (AAL;  ). For brain regions not covered by these toolboxes, the brain atlas of   was used. Nomenclature for activations in cingulate cortex is based on a recent review of cingulate anatomy and function  . \n\nFor both fMRI experiments, target analyses evaluated the interactions between the two experimental factors. For   experiment I  , the interaction contrast   Intensity (Pain>No Pain)>Unpleasantness (Pain>No Pain)   assessed which brain areas responded more to evaluating the sensory aspects of the stimulation \u2013 controlling for the generalized response to the non-painful stimuli. The reverse interaction identified clusters indicating stronger activation related to affective evaluations, again controlling for the generalized response to the depiction of the hand and an aversive object. \n\nFor   experiment II  , the same analysis approach was used. Here, the interaction term assessed activation modulations in areas involved in intensity ratings of injections to the numbed and non-numbed hand and contrasted it with the expected absence of such differences for the unpleasantness ratings. In addition, a direct comparison between numbed and painful injections for intensity rating trials only explored additional potential differences not detected by the interaction contrast. \n\nComplementary to the whole-brain analyses, region-of-interest analyses were performed using the MarsBaR toolbox, v0.38 ( ). These analyses compared event-related hemodynamic responses in   a priori   defined functional ROIs. The average signal of all voxels in a certain ROI was extracted per TR in a peristimulus epoch of 15 TRs (i.e., about 27 s). For fMRI experiment II individual ROIs of activations coding the affective-motivational consequences of painful stimulation were defined guided by a meta-analysis of insular and cingulate cortex activation during the perception of pain in self and others  . Two ROIs in left and right anterior insula and three ROIs in cingulate cortex were defined. ROIs in cingulate cortex were located in ventral posterior MCC (vpMCC), in dorsal aMCC (daMCC), and in rostral aMCC (raMCC; see  ). Individual functional ROIs were delineated by determining the conjunction (\u2229) of the activation map (  P  \u200a=\u200a0.05, uncorrected, contrast All_Painful>All_Non-painful from fMRI experiment I, with All referring to activation being pooled across both rating conditions) with a boundary box with dimensions 10\u00d710\u00d710 mm drawn around the peak coordinate. In addition, to scrutinize whether cognitive appraisal modulates somatosensory representations, a combined functional-anatomical ROI from contralateral primary somatosensory activation was determined for each subject. The boundaries of this ROI consisted of the conjunction of supra-threshold activation in contralateral (right) postcentral gyrus with the cytoarchitectonic delineation of Area 2 provided in the Anatomy toolbox. The reason for this different approach was that activation in contralateral somatosensory cortex was less focal than for the other ROIs, showed more variability across subjects, and that a clear-cut cytoarchitectonic and anatomical delineation of this area was available. Area 2 (instead of the other somatosensory areas) was chosen because it was the only area in postcentral gyrus showing significant activation in the random effects grand mean activation map. \n\nStatistical analysis of ROI data consisted of computing planned comparisons on signal peaks (which usually occurred around the third to fourth TR post-stimulus, i.e. about 5\u20137 s post stimulus). The planned comparisons followed the same analysis approach as the whole brain analyses: First, we tested the interaction term (Intensity: numbed vs. not-numbed\u2260Unpleasantness: numbed vs. not-numbed). Then, we directly compared numbed and not-numbed for the intensity trials only. In all cases, violations of the sphericity-assumption for these comparisons were accounted for by using specific error-variances  . \n\nIn order to assess the relationship between behavioral data and brain activation, random effects correlation analyses were performed. Scores of the Empathic Concern scale of the IRI, the ECS, and values P(A) and B of the SPQ were correlated with individual contrast maps. In accordance with other studies assessing brain-behavior relationships, a rather liberal significance threshold of   P  \u200a=\u200a0.001 (uncorrected) and   k\u200a=\u200a  5 was selected for these analyses. \n\n\n\n## Supporting Information \n  \n \n\n# Table(s)\n## ID: pone-0001292-t001\n### Label: Table 1\nUnnamed: 0\tL/R/M\tk\tt\tx\ty\tz\nInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\nPrecuneus\tL\t43\t6.50\t\u221222\t\u221250\t12\nPrecuneus\tR\t235\t5.72\t14\t\u221244\t38\n\u00d7Precuneus\tL\t\t4.24\t\u221210\t\u221252\t38\n\u00d7Precuneus\tM\t\t3.80\t4\t\u221250\t40\nAngular Gyrus\tR\t174\t6.00\t50\t\u221264\t48\nAngular Gyrus\tL\t21\t3.73\t\u221248\t\u221266\t40\nInferior Temporal Gyrus\tL\t8\t4.02\t\u221252\t\u22124\t\u221238\nInferior Temporal Gyrus\tR\t21\t3.89\t58\t\u221222\t\u221228\nMiddle Temporal Gyrus\tR\t186\t4.82\t56\t\u221270\t20\nAngular Gyrus\tR\t\t4.80\t46\t\u221264\t24\n\u00d7Middle Temporal Gyrus\tR\t\t4.37\t38\t\u221254\t18\nInferior Temporal Gyrus/Temporal Pole\tR\t39\t5.02\t48\t0\t\u221242\n\u00d7Inferior Temporal Gyrus/Temporal Pole\tR\t\t4.33\t52\t\u22126\t\u221238\nSuperior Temporal Pole/fronto-insular cortex\t68\t68\t4.61\t30\t8\t\u221224\nMiddle/Superior Temporal Gyrus\tL\t9\t3.88\t\u221266\t\u221244\t8\nCalcarine sulcus\tM\t372\t5.61\t4\t\u221252\t14\nLingual gyrus\tR\t\t4.46\t12\t\u221250\t4\nVentral Precuneus\tM\t\t4.23\t\u22122\t\u221266\t30\nFusiform Gyrus\tL\t5\t3.64*\t\u221232\t\u221266\t\u221210\nSupplementary Motor Area\tM\t8\t3.79\t6\t\u221222\t48\n\u00d7Supplementary Motor Area\tM\t\t3.42*\t10\t20\t68\nPrecentral Gyrus\tR\t10\t3.65*\t24\t\u221224\t76\nRolandic Operculum\tL\t7\t3.15*\t\u221238\t\u221214\t24\nSuperior Frontal Gyrus\tM\t32\t3.74\t4\t26\t64\nSuperior Frontal Gyrus\tR\t5\t3.60*\t20\t64\t8\nMiddle Frontal Gyrus\tR\t19\t3.57*\t40\t20\t54\nInferior Frontal Gyrus\tL\t5\t3.23*\t\u221252\t34\t14\nInferior Frontal/Orbitofrontal Cortex\tR\t11\t3.42*\t48\t32\t\u22128\nInferior Frontal/Orbitofrontal Cortex\tR\t8\t4.20\t32\t36\t\u22128\nInferior Frontal Gyrus/Orbitofrontal Cortex\tL\t13\t4.05\t\u221244\t30\t\u221218\nCerebellum/Lingual Gyrus\tR\t26\t4.03\t12\t\u221244\t\u221210\nCerebellum\tR\t11\t4.06\t22\t\u221224\t\u221228\nParahippocampal area/Amygdala\tR\t17\t3.78\t24\t0\t\u221226\nInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\nInsula\tL\t7\t4.77\t\u221230\t24\t8\nAnterior Insula\tR\t8\t3.40*\t30\t30\t6\nRolandic Operculum/posterior Insula\tR\t7\t3.72\t44\t\u22126\t10\nCerebellum\tR\t8\t4.58\t12\t\u221262\t\u221244\nCerebellum\tM\t10\t3.80\t8\t\u221280\t\u221244\nCerebellum\tR\t25\t4.62\t28\t\u221272\t\u221250\nCaudate/Putamen\tM\t10\t3.94\t\u22128\t4\t\u221210\nOrbitofrontal Cortex\tR\t10\t4.11\t22\t44\t\u221210\nSuperior Frontal Gyrus/Precentral Gyrus\tL\t18\t4.09\t\u221222\t\u221212\t54\nMiddle Occipital Gyrus\tL\t27\t4.01\t\u221240\t\u221290\t\u22124\nSupramarginal Gyrus\tR\t17\t3.36*\t44\t\u221232\t38\nInferior Parietal Cortex\tL\t7\t3.28*\t\u221224\t\u221256\t40\nInferior Parietal Cortex\tR\t9\t3.27*\t30\t\u221246\t44\n### Caption\nSignificant differences resulting from the interaction contrasts Intensity (Painful>Non-painful)>Unpleasantness (Painful>Non-painful) and vice versa.\n### Footer\nNotes: Voxel threshold P\u200a=\u200a0.001 (uncorrected), cluster size threshold k\u200a=\u200a5. * P\u200a=\u200a0.005, k\u200a=\u200a5; stereotactic coordinates and t-values are provided for the local voxel maximum of the respective cluster. x\u200a=\u200asub-peaks of a cluster, L\u200a=\u200aleft hemisphere, R\u200a=\u200aright hemisphere, M\u200a=\u200amedial activation, k\u200a=\u200anumber of activated voxels in cluster; areas (in brackets, e.g. OP4) determined based upon cytoarchitectonic maps provided in the Anatomy Toolbox.\n\n\n## ID: pone-0001292-t002\n### Label: Table 2\nUnnamed: 0\tL/R/M\tk\tx\ty\tz\tt-value\nInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\tInteraction: Intensity>Unpleasantness\nPostcentral gyrus (Area 2)\tR\t24\t26\t\u221244\t48\t6.38\nPostcentral gyrus (Area 3a)\tL\t36\t\u221218\t\u221236\t50\t5.55\nPostcentral Gyrus (Area OP4)\tL\t45\t\u221262\t\u221214\t18\t4.56\n\u00d7Postcentral Gyrus (Area OP4)\tL\t\t\u221260\t\u221222\t28\t4.37\nPrecentral Gyrus (Area 6)\tR\t10\t26\t\u221218\t62\t4.97\nSuperior Temporal Lobe\tL\t12\t\u221242\t\u22128\t\u221212\t4.17\nSuperior Temporal Pole\tL\t16\t\u221240\t4\t\u221220\t4.45\nInferior Temporal Gyrus\tL\t127\t\u221260\t\u221262\t\u22126\t6.34\n\u00d7Inferior Temporal Gyrus\tL\t\t\u221250\t\u221258\t0\t4.86\n\u00d7Inferior Temporal Gyrus\tL\t\t\u221252\t\u221262\t\u221210\t4.12\nSupramarginal Gyrus\tR\t67\t58\t\u221234\t32\t5.13\n\u00d7Supramarginal Gyrus\tR\t\t58\t\u221228\t26\t4.10\n\u00d7Supramarginal Gyrus\tR\t\t54\t\u221236\t24\t3.95\nPrecuneus\tL\t51\t\u221212\t\u221260\t56\t5.65\nPrecuneus (extending into Area 4a)\tM\t14\t4\t\u221240\t52\t5.36\nInferior Occipital Gyrus\tR\t26\t44\t\u221276\t\u22126\t5.10\nFusiform Gyrus\tL\t22\t\u221230\t\u221244\t\u221218\t4.81\nLingual Gyrus/Calcarine Sulcus (Area 17)\tR\t22\t14\t\u221256\t8\t4.72\nCalcarine Sulcus\tL\t11\t\u221218\t\u221256\t10\t4.36\nLingual Gyrus (Area 17)\tR\t21\t24\t\u221250\t\u22124\t4.43\nThalamus\tR\t10\t16\t\u22126\t6\t4.39\nHippocampus\tR\t20\t28\t\u221218\t\u221210\t5.88\nHippocampus\tR\t10\t40\t\u22122\t\u221220\t4.09\nHippocampus\tR\t11\t36\t\u221216\t\u221212\t3.97\nParahippocampal Gyrus\tM\t22\t\u22126\t\u221218\t\u221230\t4.92\n\u00d7Pons\tM\t\t4\t\u221220\t\u221226\t4.76\nCerebellum\tR\t39\t16\t\u221264\t\u221222\t4.95\n\u00d7Cerebellum\tR\t\t24\t\u221274\t\u221220\t4.41\nCerebellum (Vermis)\tL\t10\t\u221212\t\u221256\t\u221250\t5.12\nCerebellum (Crus)\tL\t29\t\u221234\t\u221252\t\u221234\t4.42\nCerebellum\tR\t18\t42\t\u221246\t\u221244\t4.38\nSuperior Frontal Gyrus\tR\t14\t26\t2\t64\t4.81\nInferior Fontral Gyrus/Operculum (Area 44)\tR\t67\t48\t10\t2\t4.59\n\u00d7Inferior Fontral Gyrus/Operculum (Area 44)\tR\t\t52\t8\t10\t4.57\n\u00d7Midinsular Cortex\tR\t\t52\t10\t\u22126\t4.23\nRolandic Operculum (Area 44)\tL\t10\t\u221254\t10\t0\t4.23\nMedial Insular Cortex\tL\t15\t\u221240\t0\t2\t4.14\nAnterior Medial Cingulate Cortex\tM\t68\t0\t24\t36\t5.07\nAnterior Medial Cingulate Cortex\tR\t10\t12\t26\t32\t4.53\nAnterior Medial Cingulate Cortex\tM\t28\t\u22124\t10\t42\t4.47\nInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\tInteraction: Unpleasantness>Intensity\nCalcarine Sulcus\tR\t45\t22\t\u221282\t6\t5.68\nCerebellum\tR\t19\t18\t\u221286\t\u221236\t4.85\nSubcallosal Cingulate Cortex\tM\t18\t\u22126\t20\t\u22124\t4.31\n### Caption\nSignificant differences resulting from the interaction contrasts Intensity (Numbed>Non-numbed)>Unpleasantness (Numbed>Non-numbed) and vice versa.\n### Footer\nNotes: see Table 1 for specifications and abbreviations.\n", "metadata": {"pmcid": 2144768, "text_md5": "a20659f7e7d4e55c397f5af650db6016", "field_positions": {"authors": [0, 75], "journal": [76, 84], "publication_year": [86, 90], "title": [101, 250], "keywords": [264, 264], "abstract": [277, 2280], "body": [2289, 79301], "tables": [79314, 85112]}, "batch": 2, "pmid": 18091986, "doi": "10.1371/journal.pone.0001292", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2144768", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=2144768"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2144768\">2144768</a>", "list_title": "PMC2144768  What Are You Feeling? Using Functional Magnetic Resonance Imaging to Assess the Modulation of Sensory and Affective Responses during Empathy for Pain"}
{"text": "Xu, Xiaomeng and Wang, Jin and Aron, Arthur and Lei, Wei and Westmaas, J. Lee and Weng, Xuchu\nPLoS One, 2012\n\n# Title\n\nIntense Passionate Love Attenuates Cigarette Cue-Reactivity in Nicotine-Deprived Smokers: An fMRI Study\n\n# Keywords\n\n\n\n# Abstract\n \nSelf-expanding experiences like falling in love or engaging in novel, exciting and interesting activities activate the same brain reward mechanism (mesolimbic dopamine pathway) that reinforces drug use and abuse, including tobacco smoking. This suggests the possibility that reward from smoking is substitutable by self-expansion (through competition with the same neural system), potentially aiding cessation efforts. Using a model of self-expansion in the context of romantic love, the present fMRI experiment examined whether, among nicotine-deprived smokers, relationship self-expansion is associated with deactivation of cigarette cue-reactivity regions. Results indicated that among participants who were experiencing moderate levels of craving, cigarette cue-reactivity regions (e.g., cuneus and posterior cingulate cortex) showed significantly less activation during self-expansion conditions compared with control conditions. These results provide evidence that rewards from one domain (self-expansion) can act as a substitute for reward from another domain (nicotine) to attenuate cigarette cue reactivity. \n \n\n# Body\n \n## Introduction \n  \nCigarette smoking is the number one preventable cause of death in the U.S.  . Although medications and behavioral treatments can increase a smoker\u2019s chances of quitting  , cessation rates have nevertheless stalled  , standing at around 37% at 6 months post-quit  . It is therefore important to investigate new approaches that contribute to understanding tobacco dependence and cessation, and that have the potential to inform strategies to enhance cessation rates. \n\nOne approach is that of reward replacement or substitution. Covariation of addiction (or cross-addiction) occurs when common addictive dynamics (e.g., hedonics) substitute for one another  \u2013 . For example, the physiological effects of alcohol and marijuana are similar, and in some populations (e.g., high school students) efforts to prevent alcohol use have been associated with increases in marijuana use  ,  . In addition, rats maintained on a rewarding high-fat diet (vs. low-fat diet) demonstrate decreased cocaine self-administration  . Moreover, chronic food restriction has been shown to increase behavioral sensitivity to drugs of abuse  . This apparent substitutability may explain why obese people (for whom food reward may be particularly salient) are 25% less likely to develop substance abuse problems  . \n\nSocial reward can also be a strong substitute. Recent studies have found that social interactions can be used as substitutes for food in young adults   and that social bonding decreases amphetamine reward (mediated through dopamine) among a monogamous mammalian species, the prairie vole  . Social reward in the context of romantic love may also be useful as a substitute. One study of male alcoholics found that among those who ever experienced a period of abstinence, 32% happened to be in the process of beginning a new romantic relationship  . \n\nRomantic love may act as a strong non-drug reward substitute because it is a very rapid and intense form of \u201cself-expansion.\u201d The self-expansion model proposed by Aron and colleagues   posits that people seek to expand the self to increase their physical, informational, and social resources by engaging in experiences that are novel, exciting and interesting. The process of attaining these resources at a rapid rate (e.g., through forming new relationships, taking part in a new hobby, going on a trip, etc.) generates high levels of aroused positive affect and feelings of reward  \u2013 . Although self-expansion in the context of romantic relationships is typically more rapid and intense during the early stage of the relationship, even among established couples (e.g., those who are married), participating jointly in self-expansion via   exciting   activities (as opposed to pleasant but not particularly exciting activities) is rewarding and significantly increases relationship satisfaction  . \n\nSelf-expansion may also be beneficial during the early stage of smoking cessation because it not only provides reward but has also been shown to mitigate physical pain (through a system different from that of distraction)  , which could reduce the discomfort associated with withdrawal. Self-expansion also operates on a broader level by changing a person\u2019s sense of identity. In the context of close relationships, as people fall in love they begin to include the other in their sense of self  . In non-relationship contexts, as people become immersed in a sport, hobby, etc., which by definition are rewarding, their sense of identity changes to include those aspects. This process by which self-expansion changes one\u2019s sense of identity may also be useful in dealing with addiction, as successful quitters often change their sense of identity from that of a drug user to a healthier self-image  . \n\nEvidence for the possible role of self-expansion as an aid in smoking abstinence and cessation was found in a study in which smokers who had successfully quit reported experiencing significantly more recent self-expanding events (both social forms of self-expansion as well as self-expansion at the individual level) in their lives prior to their quit attempt compared to smokers who tried to quit but ultimately failed  . Even among smokers who attempted to quit but failed, self-expansion experiences were beneficial as there was a significant positive correlation between number of self-expanding events leading up to the quit attempt and how long smokers were able to abstain. \n\nOne potential mechanism through which the reward from substances such as nicotine can be replaced by self-expanding events involves the neurotransmitter dopamine, which is linked to reward and motivation  \u2013 . The brain\u2019s mesolimbic dopaminergic pathway includes the ventral tegmental area (VTA), nucleus accumbens (NAcc), insula, amygdala, medial pre-frontal cortex (mPFC), and dorsal striatum, and plays a key role in addiction  \u2013  including nicotine addiction  \u2013 . Although there are many other factors involved in addiction, past research has shown that the hedonic effects of drugs are proportionally related to the amount of dopamine released in the striatum  . Some research has shown that when dopamine response is blocked, a corresponding decrease in substance use is observed  . As smokers refrain from smoking, craving increases but is attenuated when nicotine is administered  \u2013 . \n\nWe posit that self-expansion also activates the mesolimbic dopaminergic system, and in prior research we have demonstrated this in the context of romantic love (particularly during the early-stage). That is, when viewing an image or the name of a romantic partner in an MRI scanner, compared to the image or name of a familiar acquaintance, activation is significantly elevated in regions that include the VTA, caudate, and putamen  \u2013 . Since nicotine and self-expansion activate the same mesolimbic dopaminergic system, self-expansion may be an appropriate substitute. We were interested in this substitution idea via the mechanism of brain responses during cue exposure. \n\nPast fMRI studies using cigarette cue-reactivity paradigms have found activations in several regions of the brain that include the anterior cingulate cortex (ACC), orbitofrontal cortex (OFC), occipital cortex, parietal cortex, superior frontal cortex (SFC), ventral striatum, thalamus, amygdala, medial frontal gyrus (MFG), posterior cingulate cortex (PCC), cuneus, precuneus, fusiform gyrus, cerebellum and insula  \u2013 . The current research aimed to investigate whether reward from self-expansion could reduce cigarette cue-reactivity. Specifically, nicotine-deprived smokers in the early stages of love were exposed to smoking or neutral cues while simultaneously viewing images of their romantic partner or a familiar acquaintance. We predicted that self-expansion would lead to less cigarette cue-reactivity activations in the brain. We were particularly interested in six of the more common regions from the cigarette craving-cue literature: ACC, PCC, precuneus, SFC, MFG, and insula. \n\n\n## Methods \n  \nThis research was approved by the IRB committees of Stony Brook University and the Chinese Academy of Sciences and all participants provided written informed consent. \n\n### Participants \n  \nParticipants were 18 Chinese smokers who smoked at least eight cigarettes per day, had been smoking at least 6 months, and who reported being in a non-long-distance romantic relationship with a non-smoker for whom they felt intense passionate love. As the rate of daily smoking is high for men in China (48.9%) and extremely low for women (3.25%), we recruited only men for this study  . Participants reported smoking on average 15.78 cigarettes per day (  SD  \u200a=\u200a7.83), and that they had been smoking between 6 months and 10 years (  M  \u200a=\u200a4.42 years;   SD  \u200a=\u200a2.70). Participants were with their partner for an average of 14.22 months (  SD  \u200a=\u200a10.97). \n\nParticipants were recruited from Beijing campuses by flyers and emails to listservs. Students were targeted for recruitment since they report high rates of new relationships and because this population has been used in previous fMRI studies on romantic love, including one in China  . Participants ranged in age from 21\u201333 (  M  \u200a=\u200a25.11,   SD  \u200a=\u200a3.03). Participants were excluded if they reported current attempts to quit smoking or using nicotine replacement products. Participants all met the safety protocol for the MRI, were not taking psychoactive medications, and did not have histories of claustrophobia, head trauma, or severe alcohol/drug use (excepting nicotine). All but one preferred their right hand. \n\n\n### General Procedure \n  \nWe screened participants over the phone and then invited them to the lab where they completed informed consent and we assessed smoking status with a breath CO monitor [  M  \u200a=\u200a14.22 parts per million (ppm),   SD  \u200a=\u200a8.77 ppm]. Participants also completed a 14-item version of the Passionate Love Scale  , where they answered questions on a 1(not true at all) to 9 (definitely true) scale about their partner (e.g., \u201cI have an endless appetite for affection from my partner\u201d and \u201cI would rather be with my partner than anyone else.\u201d) Participants scored an average of 7.75 (SD\u200a=\u200a.82) on each item in the scale, indicative of intense passionate love. \n\nParticipants provided digital photographs of their non-smoker romantic partner and a familiar non-smoker acquaintance (same sex as their partner). Participants were asked to select acquaintances whom they knew for at least as long as their partner and for whom they did not have any romantic feelings or history. Photographs were cropped to show only the head and to ensure similar size. We also asked participants to bring us photographs of a non-smoker close same-sex friend, as we were interested in exploratory analyses with this condition. However, many participants reported after scanning that their close friend was in fact a smoker. Since we wanted to ensure that all face stimuli would not act as a smoking cue, we excluded this condition from our analyses and proceeded with only the partner and familiar acquaintance data. \n\nA separate sample of 7 Chinese volunteers rated all photographs on picture quality on a 1 (extremely bad) to 7 (extremely good) scale. There were no significant differences between partner and acquaintance photographs. Four male volunteers (a subset of the 7) further rated the photographs of the female partners and acquaintances on physical attractiveness on a 1 (absolutely unattractive) to 7 (absolutely attractive) scale. There were no significant differences between partner and acquaintance photographs. \n\nWe asked participants to refrain from smoking and nicotine use overnight for at least 8 hours prior to scanning (which took place within 2 weeks of their initial visit). All participants reported abstaining from smoking and nicotine use (including nicotine replacement products) overnight (for at least 8 hours). The majority (all but 2) reported abstaining for at least 12 hours. Immediately prior to scanning, participants had a mean CO measure of 5.83 ppm (  SD  \u200a=\u200a2.75), which was a statistically significant drop in ppm from baseline (  M  \u200a=\u200a14.22;   SD  \u200a=\u200a8.77)   t  (17) \u200a=\u200a9.00,   p  <.001. The average difference in ppm was 8.39 (  SD  \u200a=\u200a8.13). Participants also completed a brief version of the Questionnaire of Smoking Urges (QSU-brief)  . Participants rated their agreement with 10 statements (e.g., \u201cI have a desire for a cigarette right now\u201d) each on a 0 to 100 rating scale. \n\nAll participants were scanned between 2 pm and 6 pm. Prior to scanning, participants were asked to recall memories of their romantic partner and acquaintance. They were told to think of those memories when they saw the corresponding photographs in the scanner, consistent with past research using this paradigm  ,  ,  . Also following procedures from previous studies, we instructed participants on a count-back task (mentally counting backwards in increments of sevens). Following the scanning session (which took about 1 hour), participants verbally confirmed that they followed all instructions and completed a post-scan QSU-brief. Participants were then debriefed and given payment of 150 RMB (roughly $25 USD). \n\n\n### Scanning Stimuli and Procedure \n  \nParticipants\u2019 data were obtained using a 3T Trio MRI scanner at the Beijing MRI Center for Brain Research. During scanning participants viewed images of people and objects in a 2 (partner vs. acquaintance) \u00d72 [cigarette cue (i.e., cigarette) vs. pen] block design (see  ). Stimuli images were always viewed in pairs of one person and one object side-by-side (left-right order randomized). Person stimuli were always the same photographs of the romantic partner and acquaintance. Object stimuli were always three images: (a) a hand holding a pen (neutral cue), (b) a hand holding a cigarette (cigarette cue) and (c) a person\u2019s hands as they lighted a cigarette (cigarette cue). We had two different cigarette cues so we could investigate if different cues elicited different levels of cue-reactivity and were affected by self-expansion differently. However we did not find any differences in terms of response to the two cigarette cues and therefore we averaged them together during analyses. Our 2\u00d72 design yielded four pairs of distinct stimuli (partner+cig cue, partner+pen, acquaintance+cig cue, acquaintance+pen), and each pair was repeated three times. Stimuli were presented for 30 s after a 2 s-presentation of a fixation point. Participants were instructed to rate their craving levels for a cigarette for 9 s after the stimulus (the 4 buttons on the response box corresponded with \u201cnot at all,\u201d \u201ca little,\u201d \u201csomewhat,\u201d and \u201cextremely\u201d). Due to technical issues during scanning, portions of the rating responses were not recorded for three of our participants. We analyzed the ratings based on the remaining data. Immediately following the ratings, participants completed a count-back task. A random four-digit number appeared on the screen for 26 s and participants mentally counted backwards from that number in increments of 7 s. This count-back task has been used in several other love fMRI studies  ,   to help participants disengage from thoughts about the stimuli and to prevent spillover effects across blocks. \n   Sample block of experimental task and fMRI design.  \nWe used a 2 (partner vs. acquaintance) x2 (cigarette cue vs pen) factor design. Each of the four distinct blocks was repeated three times. \n  \nAll functional scans used a T2* weighted echo planar imaging (EPI) sequence. The imaging parameters were: echo time (TE) \u200a=\u200a30 ms, repetition time (TR) \u200a=\u200a2000 ms, flip angle \u200a=\u200a90\u00b0, field of view (FOV) \u200a=\u200a240 mm, and a matrix of 64\u00d764. The whole brain was imaged in an axial configuration where 30 slices were collected and each slice was 3 mm thick (0 mm gap). The resolution was 3.75\u00d73.75\u00d73 mm. After all functional tasks, high resolution anatomical images were collected by using a T1- weighted, three-dimensional gradient-echo sequence (3D MPRAGE) with 144 slices, slice thickness of 1.33 mm, TR of 2530 ms, TE of 3.37 ms, FA of 7\u00b0, and a matrix of 256\u00d7256, which resulted in a spatial resolution of 1\u00d71.33\u00d71 mm. \n\n\n### Analyses \n  \nWe conducted fMRI analyses on data from 17 participants (1 participant\u2019s data were dropped due to a technical problem; no participants\u2019 data needed to be dropped due to excessive motion, which we defined as >2.0 mm translation in any of the three directions or > than 2.0\u00b0 maximum rotation around any of the axes during the scan). We preprocessed and analyzed the data using AFNI ( ). For each participant, the functional scans were corrected for the slice acquisition timing schedule and head movement, spatially smoothed with a Gaussian kernel of 5 mm FWHM and normalized so that each voxel time series would have a mean of 100. Single-subject whole brain voxel size General Linear Model (GLM) analyses were performed to estimate the individual statistical   t  -maps. There were ten regressors in the GLM in all, with four regressors representing four experimental conditions (partner+cig; partner+pen; acquaintance+cig; acquaintance+pen) and the six head-motion parameters. The regression analysis incorporated correction for the temporal autocorrelation of voxelwise noise (AFNI program 3dREMLfit). \n\nGroup analyses were preformed after converting functional images into Talairach space (re-sampled to a voxel size of 3\u00d73\u00d73 mm ). We compared activations across participants using AFNI program 3dANOVA3 (two-way mixed factor) with condition as the fixed factor and participants as the random factor for each group. A group statistical map was created with four contrasts: partner+cigarette vs. partner+pen (which assesses cigarette cue reactivity in the presence of self-expansion reward); acquaintance+cigarette vs. acquaintance+pen (which assesses cigarette cue reactivity in the absence of self-expansion reward); partner+cigarette vs. acquaintance+cigarette (which assesses the self-expansion effect in the presence of cigarette cues) and partner+pen vs. acquaintance+pen (which assesses the self-expansion effect in the absence of cigarette cues). To correct for multiple comparisons, statistically defined clusters of activation were identified using whole-brain Monte Carlo simulation (AFNI program Alpha Sim) to achieve a corrected cluster threshold of   p  <0.05. \n   Regional activations and deactivations for cigarette-cue contrasts.           Regional activations and deactivations for partner-cue contrasts.        \nFor region of interest (ROI) analyses we were interested primarily in two regions associated with self-expansion reward, namely the caudate and VTA, as well as several regions associated with cigarette cue-reactivity, namely the PCC, ACC, insula, precuneus, MFG, and SFC. The ROIs were defined functionally as spheres with a 6-mm radius (3 mm for the VTA) on the basis of activation clusters from the group analyses. The peak activation coordinates from the cluster of the contrast analysis were selected as the center of each ROI. We built ROIs around coordinates for caudate and VTA from a prior love fMRI study   and cue-reactivity regions from the whole brain analyses in our two groups. We averaged the signal for voxels in each ROI using the AFNI program 3dmaskave. We converted regression coefficients to percent signal change for each ROI for each condition, and used SPSS 17.0 to run repeated measures ANOVAs to compare percent signal change in our contrasts. \n   Whole brain comparisons between conditions.  \nA: partner+pen vs. acquaintance+pen (p<0.01 uncorrected); B: partner+cig vs. partner+pen (IFG) (p<0.05, corrected); C: cue-induced craving: acquaintance+cig vs. acquaintance+pen (p<0.05, corrected); D: partner+cig vs. acquaintance+cig (p<0.05, corrected). \n  \n\n\n## Results \n  \nSelf-reported ratings of cravings did not differ between pen versus cig-cue presentations. As we asked participants to rate their craving every 30 seconds (no prior overnight abstinence study has asked for reporting cravings with this much frequency), and on a scale that only offered 4 options, this rating system may not have been sensitive enough to pick up on variability in subjective craving. Participants differed markedly, however, on self-reported craving levels (QSU-brief scores) immediately prior to entering the scanner, with some participants reporting elevated levels of cravings. To thus address the role of potential ceiling effects on cue-reactivity, we divided participants into two groups. We labeled as our \u201cmoderate craving\u201d group those with QSU-brief scores <400 (800 was the highest score in our sample; n\u200a=\u200a7;   M  \u200a=\u200a308\u00b195). We labeled as our \u201chigh craving\u201d group those with scores >400 (n\u200a=\u200a10;   M  \u200a=\u200a631\u00b1133). Asians are less likely to use the higher anchors on the QSU-Brief scale which leads to overall lower raw QSU-Brief scores compared to Western samples undergoing nicotine abstinence  ,  . There were no significant differences by group in terms of length of romantic relationship, number of cigarettes smoked per day, or number of years as a smoker. Those in the high-craving group were significantly older (  M  \u200a=\u200a26.45 years,   SD  \u200a=\u200a2.95 vs.   M  \u200a=\u200a23 years,   SD  \u200a=\u200a1.7,   p  \u200a=\u200a.013). There was a trend such that the high-craving group showed a greater reduction in carbon monoxide levels from baseline to pre-scan (  M  \u200a=\u200a11.09,   SD  \u200a=\u200a8.98 vs.   M  \u200a=\u200a4.14,   SD  \u200a=\u200a4.30;   p  \u200a=\u200a.076). The high-craving group also seemed to have reached a craving ceiling, such that their pre-scan QSU-brief scores did not differ significantly from their post-scan scores (  p  \u200a=\u200a.761). However, the moderate-craving group had significantly higher post- than pre-scan QSU-brief scores,   t  (6) \u200a=\u200a\u22122.73,   p  \u200a=\u200a.034. \n   Region of Interest (ROI) analysis of the percent signal change of six ROIs for the four experimental conditions (partner+cig, partner+pen, acquaintance+cig, and acquaintance+pen).  \nThe radius for each ROI sphere is 6 mm, VTA was 3 mm. The left line shows the location of each ROI (white circle), the right line shows the corresponding percent signal change for four experimental conditions. The center coordinates (Talarich coordinates)of each ROI sphere are: anterior cingulate cortex(ACC)(-10, 44, 9); posterior cingulate cortex(PCC)(-1,-61,17); middle frontal cortex(MFC)(8,44,14); superior frontal cortex(SFC)(-16,47,26); caudate(-13,11,2) and precuneus(14\u201370 41). The ROI regions ACC, PCC, MFC and SFC are defined from an activation map contrasting acquaintance+cig vs. acquaintance+pen in moderate-craving group; caudate is defined from an activation map of partner+pen vs. acquaintance+pen in moderate-craving group and precuneus is defined from an activation map of partner+cig vs. partner+pen in high-craving group. \n  \n### Whole Brain Analyses \n  \nTo correct for multiple comparisons, Monte Carlo simulation was used to achieve a corrected cluster threshold of   p  <0.05, which yielded corrected clusters reaching contiguous volumes of at least 65 voxels for the high-craving group and 67 voxels for the moderate-craving group, with a voxel-wise threshold of   p  <0.01. These cutoffs yielded large clusters. However, we were also interested in smaller regions associated with cue-reactivity that may still be meaningful (despite not meeting statistical significance via the Monte Carlo simulations), and set a threshold of   p  <0.01 uncorrected for exploring these smaller clusters of voxels (see   &  ). \n\n#### Manipulation checks \n  \nTo verify cigarette cue-reactivity, whole brain analyses compared cigarette cues with neutral cues in acquaintance conditions. In the moderate-craving group, cigarette cue conditions compared to the neutral cue conditions, elicited activations in cue-reactivity regions, specifically the bilateral posterior cingulate, bilateral middle occipital gyrus, right media frontal gyrus, left superior frontal gyrus, left anterior cingulate gyrus, left supramarginal gyrus and left middle temporal gyrus (  p  <0.05 corrected). In the high-craving group, cigarette cues (vs. neutral cues) were associated with deactivation in the bilateral superior parietal gyrus, left precuneus and right supramaginal gyrus. To examine if there was a reward effect of self-expansion independent of smoking-related cues, we compared activations of partner versus acquaintance presentations accompanied by neutral cues. In the moderate-craving group, there were activations in the left putamen, bilateral caudate, bilateral middle frontal gyrus, right inferior parietal lobule and right culmen (  p  <0.01 uncorrected); in the high-craving group, in the left cingulate gyrus and deactivation in the right anterior cingulate (  p  <0.01 uncorrected). \n\n\n#### Cue-reactivity and self-expansion results \n  \nFor the partner+cig cue vs. acquaintance+cig cue contrast, in the moderate-craving group, we found deactivation in the left cuneus (  p  <0.01 uncorrected; see  ), and for the high-craving group deactivation in the left amygdala (  p  <0.01 uncorrected; see  ,  ). As a further test, we compared results between the partner+cig vs. partner+pen contrast and the acquaintance+cig vs. acquaintance+pen contrast. Moderate-craving smokers, when exposed to images of their partner and a cigarette cue (vs. partner and a neutral cue), showed activation in the left posterior cingulate gyrus and left middle temporal gyrus (  p  <0.05 corrected), regions also activated in the acquaintance+cig vs. acquaintance+pen contrast. However, as predicted, there was more activation in these regions in the acquaintance+cig vs. acquaintance+pen contrast compared to the partner+cig vs. partner+pen contrast (see  ;  ). For high-craving smokers, partner+cig vs. partner+pen yielded deactivations in bilateral precuneus, left inferior frontal gyrus and left insula (  p  <0.05 corrected), while acquaintance+cig vs. acquaintance+pen yielded deactivations in bilateral parietal lobule, an area associated with somatosensory function (  p  <0.05 corrected. See  ;  ). \n\n\n\n### ROI Analyses \n  \n#### Manipulation check \n  \nWe found a significant cigarette cue-reactivity effect for our acquaintance conditions (acquaintance+cig vs. acquaintance+pen) in the ACC (center coordinates: \u221210, 44, 9;   p  \u200a=\u200a.001), PCC (center coordinates: \u22121,\u221261, 17;   p  <.001), MFC (center coordinates: 8, 44, 14;   p  \u200a=\u200a.002), and SFC (center coordinates: \u221216, 47, 26;   p  <.001). Similar to our whole-brain analyses, we found these activations more robustly for moderate-craving smokers compared to high-craving smokers (i.e., interaction effects). Specifically, although for both moderate- and high-craving smokers there was significant cigarette cue-reactivity activation in the MFC and SFC during acquaintance conditions, the effect was stronger in the moderate-craving group for activation in the PCC (  p  \u200a=\u200a.010) and marginally stronger in the ACC (  p  \u200a=\u200a.062) (see  ). Across both moderate- and high-craving groups we obtained cigarette vs. neutral cue deactivation in the precuneus (center coordinates 14, -70, 41;   p  \u200a=\u200a.047), but an interaction effect approached significance (  p  \u200a=\u200a.065) indicating less deactivation in moderate-craving smokers compared to high-craving smokers (see  ). \n\nFor the self-expansion reward manipulation check contrast we found significantly more activation in the caudate (center coordinates \u221213, 11, 2) for partner conditions compared to acquaintance conditions,   p  \u200a=\u200a.021, with the partner x craving-group interaction approaching significance,   p  \u200a=\u200a.079. (see  ). \n\n\n#### Cue-reactivity and self-expansion results \n  \nThere was a significant cue x self-expansion interaction in the PCC (  p  \u200a=\u200a.046), such that when moderate-craving smokers viewed cigarette cues alongside images of their partner, there was less activation in the PCC compared with when they viewed cigarette cues alongside images of an acquaintance (see  ). \n\n\n\n\n## Discussion \n  \nThe present experiment used fMRI to examine whether self-expansion through the reward of romantic attraction could decrease brain responses to cigarette cues among nicotine-deprived smokers. A manipulation check confirmed that our smoking cues (compared to neutral cues) yielded significant activation in cue-reactivity regions, notably the anterior and posterior cingulate cortex and prefrontal cortex, during exposure to images of an acquaintance. Moreover, during exposure to images of a romantic partner, results indicated that smoking cues (compared to neutral cues) were associated with deactivation in cue-reactivity regions. This suggests that the reward associated with self-expansion experiences can help attenuate cue reactivity. However, these effects were robust primarily among smokers for whom cravings were not so high that they overwhelmed the effect of self-expansion. For smokers who were experiencing higher levels of cigarette craving prior to scanning, cigarette cues did not elicit more brain response in cue-reactivity regions than control images. Moreover, partner images for these smokers did not elicit more reward-motivated activations than acquaintance images. This indicated that a craving ceiling had been reached such that the effects of cigarette cues and self-expansion were not evident. \n\nWe also obtained an unexpected finding of significantly more deactivation in the precuneus in cigarette-cue conditions compared to control conditions. While the precuneus has been an area associated with cue reactivity, our deactivation results may actually be reflecting a different portion of the precuneus, one that includes the inferior parietal lobule, an area associated with internal representations  . This suggests that participants were focusing less internally during cigarette cue conditions (perhaps attending to the cigarette cue more) compared to control conditions. \n\nEven among moderate-craving smokers (who had not reached a craving ceiling), although partner images still yielded some reward activation (in the caudate), we did not find expected VTA activation. The VTA is an area especially sensitive to intense romantic love reward, whereas the caudate is a region associated with social reward more generally including positive romantic relationships past the initial intense stage  . No other neuroimaging study of love has focused on smokers or investigated participants who had been asked to abstain from any substance, so it is unclear if the lack of significant VTA activations is a finding unique to smokers. It is also possible that while the reward of self-expansion attenuates cigarette cue reactivity (as we found), overnight abstinence and cigarette cue reactivity may also interfere with self-expansion reward associated with the VTA. Future studies, including studies with non- nicotine-deprived smokers, could further explore this potential bidirectional relationship to better understand the threshold at which one effect trumps the other, and various potential moderating and mediating factors. \n\nThere were some limitations to our study and thus the generalizability of our results. First, because we followed the procedures of previous fMRI studies of romantic love  ,  ,  , we used only one image of the partner and one image of the acquaintance and as a consequence also used the same cigarette and pen cues repeatedly. Although past fMRI love studies have found no habituation effects, this is the first study focusing on smokers, and in particular, smokers who have undergone overnight abstinence. It is possible that habituation effects were present for this sample and influenced the results (although this would presumably function primarily to weaken our results). Future studies could use multiple stimuli to ensure that habituation does not occur. Second, we did not find cue-reactivity activations in our sample for several regions that have been implicated in prior literature, particularly in the limbic system. Some potential reasons for this include the design (e.g., possible habituation effects as just noted) as well as the possibility that because smokers abstained overnight, they may have been in withdrawal such that they were exhibiting ceiling effects on limbic responses prior to the cue protocol. \n\nThe current study did not include a distraction control condition, which might be an alternative explanation for our results (however, in the study using a similar paradigm to test effects of self-expansion on pain,  , there was similar pain reduction for both distraction and viewing the beloved, but they operated through different neural systems). In addition, the current study did not have an aversive control condition to specifically test if aversive arousing stimuli would have equally attenuated cue-reactivity. However, brain regions associated with arousing aversive stimuli, for example the amygdala  , did not show activations in our experimental conditions, leading us to conclude that this alternative explanation is unlikely. \n\nFinally, our sample consisted of current smokers who were not in the process of quitting. For purposes of directly applying our results in intervention settings, future studies should investigate our model among smokers who are attempting to quit to test cue-reactivity reduction in a more clinically relevant sample, and to investigate if quit readiness moderates the effect of self-expansion. However, previous fMRI studies on cigarette cue-reactivity have found activations in similar regions for both non-treatment seeking and treatment seeking smokers, suggesting that our model may be appropriate even for those attempting to quit  ,  ,  ,  . Future studies are necessary to directly investigate this. \n\nThe overall results of this research advances our general understanding of reward and cue-reactivity processes in the context of addiction and self-expansion. This research also advances our understanding of self-expansion as a novel approach (one that has never been tested empirically before except by self-report measures) to undermining cigarette cue-reactivity. As an initial study of self-expansion effects, we focused on romantic love because it is one of the most robustly intense and rapid forms of self-expansion and one that is testable in a research situation. However, now that effects have been observed under these strong conditions future research could focus on less intense but widely experienced (and more practical as intervention methods) self-expansion activities/events by including both other social self-expansion experiences (e.g., interactions with friends and family members), as well as self-expansion at the individual level (e.g., engaging in a new sport or hobby or engaging in spiritual experiences). Sport and exercise might be an especially fruitful area as exercise has been shown to help with cigarette craving   and to increase dopamine  . Mindfulness practices may also be especially interesting to investigate as self expansion can be a mediator for mindfulness   and mindfulness has been linked to reductions in smoking  ,   and lower levels of nicotine dependence and withdrawal severity  . Finally, future studies utilizing self-expansion could build upon these results to help create an intervention for smoking cessation and to investigate if a self-expansion model could be applied to other addictions as well. \n\n \n\n# Table(s)\n## ID: pone-0042235-t001\n### Label: Table 1\nUnnamed: 0_level_0\tHigh craving smokers\tHigh craving smokers\tHigh craving smokers\tHigh craving smokers\tHigh craving smokers\tModerate craving smokers\tModerate craving smokers\tModerate craving smokers\tModerate craving smokers\tModerate craving smokers\nUnnamed: 0_level_1\tPeak x\tPeak y\tPeak z\tPeak t-value\tVoxels\tPeak x\tPeak y\tPeak z\tPeak t-value\tVoxels\nPartner-cig vs. Partner-pen\t\t\t\t\t\t\t\t\t\t\nActivations\t\t\t\t\t\t\t\t\t\t\nleft posterior cingulate\t\t\t\t\t\t\u22126\t\u221257\t16.0\t9.14\t118.0\nleft middle temporal gyrus\t\t\t\t\t\t\u221240\t\u221264\t13.0\t5.29\t69.0\nDeactivations\t\t\t\t\t\t\t\t\t\t\nright precuneus\t14\t\u221270\t41.0\t\u22127.04\t461.0\t\t\t\t\t\nleft inferior parietal gyrus\t\u221246\t\u221243\t41.0\t\u22127.70\t342.0\t\t\t\t\t\nleft inferior frontal gyrus\t\u221246\t2\t31.0\t\u221210.56\t171.0\t\t\t\t\t\nleft insula\t\u221243\t\u221237\t20.0\t\u22126.89\t90.0\t\t\t\t\t\nAcquaintance-cig vs. Acquaintance-pen\t\t\t\t\t\t\t\t\t\t\nActivations\t\t\t\t\t\t\t\t\t\t\nbilateral posterior cingulate\t\t\t\t\t\t\u22121\t\u221261\t17.0\t11.19\t556.0\nleft supramarginal gyrus\t\t\t\t\t\t\u221249\t\u221255\t32.0\t8.36\t140.0\nright medial frontal gyrus\t\t\t\t\t\t8\t44\t14.0\t6.64\t81.0\nleft superior frontal gyrus\t\t\t\t\t\t\u221216\t47\t26.0\t6.28\t71.0\nleft anterior cingulate\t\t\t\t\t\t\u221210\t44\t9.0\t4.63\t67.0\nDeactivations\t\t\t\t\t\t\t\t\t\t\nleft superior parietal lobule\t\u221231\t\u221273\t50.0\t\u22125.09\t154.0\t\t\t\t\t\nright superior parietal lobule\t41\t\u221258\t50.0\t\u22124.45\t112.0\t\t\t\t\t\n### Caption\nRegional activations and deactivations for cigarette-cue contrasts.\n### Footer\nWhole brain analyses results for cigarette-cue contrasts. Coordinates are Talairach. We accepted p<0.05 (FWE-corrected) for the single peak voxel in a cluster with a minimum of 65 voxels (high craving group) and 67 voxels (moderate craving group). We also highlight several smaller clusters of interest that did not meet the minimum voxel size set by our Monte Carlo simulations. These smaller clusters were identified using a threshold of p<0.01 uncorrected, and we use an * in this table to indicate these smaller clusters of interest.\n\n\n## ID: pone-0042235-t002\n### Label: Table 2\nUnnamed: 0_level_0\tHigh craving smokers\tHigh craving smokers\tHigh craving smokers\tHigh craving smokers\tHigh craving smokers\tModerate craving smokers\tModerate craving smokers\tModerate craving smokers\tModerate craving smokers\tModerate craving smokers\nUnnamed: 0_level_1\tPeak x\tPeak y\tPeak z\tPeak t-value\tVoxels\tPeak x\tPeak y\tPeak z\tPeak t-value\tVoxels\nPartner-pen vs. Acquaintance-pen\t\t\t\t\t\t\t\t\t\t\nActivations\t\t\t\t\t\t\t\t\t\t\nleft putamen\t\t\t\t\t\t\u221225\t2\t17\t8.23\t23*\nright culmen\t\t\t\t\t\t23\t\u221243\t\u221218\t4.51\t20*\nright inferior parietal lobule\t\t\t\t\t\t41\t\u221234\t41\t9.50\t19*\nright middle frontal gyrus\t\t\t\t\t\t38\t17\t23\t6.17\t15*\nleft caudate head\t\t\t\t\t\t\u221213\t11\t2\t7.25\t12*\nleft middle frontal gyrus\t\t\t\t\t\t\u221225\t\u221210\t41\t7.27\t12*\nright caudate head\t\t\t\t\t\t11\t14\t6\t8.28\t11*\nleft cingulate gyrus\t\u221213\t\u221228\t32\t5.74\t10*\t\t\t\t\t\nDeactivations\t\t\t\t\t\t\t\t\t\t\nright anterior cingulate\t14\t41\t\u22123\t\u22125.44\t10*\t\t\t\t\t\nPartner-cig vs. Acquaintance-cig\t\t\t\t\t\t\t\t\t\t\nActivations\t\t\t\t\t\t\t\t\t\t\nleft middle frontal gyrus\t\t\t\t\t\t\u221240\t31\t26\t6.98\t19*\nwhite matter\t\u221225\t\u221240\t20\t5.83\t84\t\t\t\t\t\nDeactivations\t\t\t\t\t\t\t\t\t\t\nleft cuneus\t\t\t\t\t\t\u22124\t\u221288\t14\t\u22126.39\t48*\nright superior temporal gyrus\t56\t\u221228\t14\t\u22125.28\t75\t\t\t\t\t\nleft amygdala\t\u221214\t2\t\u221212\t\u22127.39\t65\t\t\t\t\t\n### Caption\nRegional activations and deactivations for partner-cue contrasts.\n### Footer\nWhole brain analyses results for partner-cue contrasts. Coordinates are Talairach. We accepted p<0.05 (FWE-corrected) for the single peak voxel in a cluster with a minimum of 65 voxels (high craving group) and 67 voxels (moderate craving group). We also highlight several smaller clusters of interest that did not meet the minimum voxel size set by our Monte Carlo simulations. These smaller clusters were identified using a threshold of p<0.01 uncorrected, and we use an * in this table to indicate these smaller clusters of interest.\n", "metadata": {"pmcid": 3409150, "text_md5": "dc3257ccc6dd0a07a92240482d61f74d", "field_positions": {"authors": [0, 93], "journal": [94, 102], "publication_year": [104, 108], "title": [119, 222], "keywords": [236, 236], "abstract": [249, 1370], "body": [1379, 35803], "tables": [35816, 39538]}, "batch": 2, "pmid": 22860092, "doi": "10.1371/journal.pone.0042235", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3409150", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3409150"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3409150\">3409150</a>", "list_title": "PMC3409150  Intense Passionate Love Attenuates Cigarette Cue-Reactivity in Nicotine-Deprived Smokers: An fMRI Study"}
{"text": "Borst, Jelmer P. and Nijboer, Menno and Taatgen, Niels A. and van Rijn, Hedderik and Anderson, John R.\nPLoS One, 2015\n\n# Title\n\nUsing Data-Driven Model-Brain Mappings to Constrain Formal Models of Cognition\n\n# Keywords\n\n\n\n# Abstract\n \nIn this paper we propose a method to create data-driven mappings from components of cognitive models to brain regions. Cognitive models are notoriously hard to evaluate, especially based on behavioral measures alone. Neuroimaging data can provide additional constraints, but this requires a mapping from model components to brain regions. Although such mappings can be based on the experience of the modeler or on a reading of the literature, a formal method is preferred to prevent researcher-based biases. In this paper we used model-based fMRI analysis to create a data-driven model-brain mapping for five modules of the ACT-R cognitive architecture. We then validated this mapping by applying it to two new datasets with associated models. The new mapping was at least as powerful as an existing mapping that was based on the literature, and indicated where the models were supported by the data and where they have to be improved. We conclude that data-driven model-brain mappings can provide strong constraints on cognitive models, and that model-based fMRI is a suitable way to create such mappings. \n \n\n# Body\n \n## Introduction \n  \nFormal models constitute one of the dominant methodologies in cognitive science: they played a major role in more than half the articles published in the Cognitive Science journal in 2013 (53% of the articles in Cognitive Science volume 37 mentioned \u2018model\u2019, \u2018simulation\u2019, or \u2018computational theory\u2019 in their abstract.). However, the approach is not without its problems, as the quality of models is notoriously hard to evaluate [ \u2013 ]. Although there have been several proposals on how to test cognitive models [ \u2013 ], no consensus has been reached. This is partly due to the wide variety of models; it is for instance unclear if and how approaches suitable for mathematical models could be extended to symbolic process models. \n\nOne important modeling requirement\u2014shared by the different proposals\u2014is that a model should be able to predict data of new experiments, for instance reaction times and accuracy (also referred to as   generalizability   or   applied approach   [ , \u2013 ]). However, even if models are capable of predicting behavioral data, their complexity often exceeds constraints provided by behavioral data. For example,   shows cognitive operations assumed by a model of multitasking behavior, for one trial of the task (which involved 20 responses [ ]). In that model the critical activities where updating a working memory problem state, retrieving information from declarative memory, performing various visual encodings, and outputting the response. Any model that outputs the same responses at the same time would make equivalent behavioral predictions. While not necessarily easy, one could imagine re-arranging the components (note that we use \u2018components\u2019 to refer to concepts of a computational model in this paper) or inserting completely different intervening processes in ways that would leave the output unchanged. \n   Cognitive operations in one trial of a model of multitasking.  \nSuch a trial involved 20 responses [ ]. The four rows indicate four model components; boxes indicate when a component was active. \n  \nTo provide additional constraints for cognitive models, researchers have turned to neuroscience (e.g., [ , \u2013 ]). A prime example of this is the ACT-R cognitive architecture (Adaptive Control of Thought-Rational; [ ]). ACT-R is a general psychological theory, but it also provides a simulation environment in which task models can be developed. It thereby ensures that theoretical ideas have to be formally specified, giving them additional credibility [ ]. It has been used extensively both in basic psychological research as well as in more applied settings (e.g., cognitive tutors [ ]; see   for over 1000 papers that use or discuss ACT-R). After a development based on behavioral and eye-tracking data that extends back to the 1970s, in 2003 a mapping was developed from components of the architecture to brain regions [ \u2013 ]. Since then, models developed in ACT-R automatically predict the fMRI BOLD response in several regions of the brain, and can thus be tested and constrained by fMRI data [ , , ]. This approach has been extremely fruitful (  lists over 60 papers that use or discuss this approach), and was one of the main driving forces behind the latest version of the architecture [ ]. \n\nBefore neuroimaging data can be used to constrain a computational model, one needs a mapping from model components to brain regions. In the case of ACT-R, the initial mapping was based on a reading of the literature [ , ], and adapted slightly based on experience with new tasks. This approach is suboptimal\u2014in the sense that it is subjective\u2014but it was the best option at the time. In this paper we will propose and demonstrate a new, formal method to create such a mapping: model-based fMRI analysis. Model-based fMRI analysis shows the most likely location of model components in the brain by calculating the correlations between activity of certain model-components (or settings of certain model parameters) and observed brain activity [ , , ], and can thus form the basis for a mapping of model components to brain regions. As model-based fMRI is a formal, data-driven method, it is to be preferred over the original, subjective approach for creating model-brain mappings, to prevent researcher-based biases. The goal of the current paper is to show that it performs at least as well as the original method, and that it is therefore a suitable substitution for the original, subjective method. \n\nBecause the results of model-based fMRI are dependent on the quality of the model that is used in the analysis, we will use a recent model-based meta-analysis of five tasks with associated ACT-R models as the basis of our data-driven mapping [ ]. We will subsequently apply both the original literature-based mapping and the new, data-driven mapping to two independent datasets. For each dataset we will use a model from previous research, and either optimize this model to fit the behavioral data of the current task (dataset 1) or use   a priori   predictions based on previously identified model parameters (dataset 2). Next, we will use both models to generate predictions about the patterns we expect to observe in the neural data. We will then compare these predictions to the neural data of the two model-brain mappings. Summarizing, we use two datasets, for each dataset we use a single model to generate neural predictions, and we compare these predictions to data of two different model-brain mappings, the original mapping and the new, data-driven mapping. \n\nThe first dataset consists of a relatively simple algebra task, and should\u2014given our experience of modeling such tasks\u2014result in a good fit of the data. For this dataset we merged two existing models into a new model. The second dataset is a much more challenging multitask for which we made   a priori   predictions using a previously published model. We do not expect to match all details of the data in this case, but we will use it as an example of how the method can direct the development of cognitive models. \n\nIn the remainder of the introduction we will first discuss how ACT-R models can be used to predict fMRI data, and how such data can be used to constrain models. Next, we will describe model-based fMRI analysis, as well as the meta-analysis on which the new mapping will be based. \n\n### Predicting and evaluating ACT-R models with fMRI \n  \n gives an overview of the ACT-R architecture and its current mapping to brain regions ([ , ]; see   for details). ACT-R assumes that cognition emerges from the interplay of several independent components, which are typically referred to as modules. Two modules take care of input, the visual and aural modules, and two modules perform actions, the manual and vocal modules. To perform cognitive operations, ACT-R has four additional modules: declarative memory, procedural memory, the problem state, and the control state. The modules interact through buffers of limited size with the procedural module. The procedural module contains rules that can fire based on the contents of the buffers. For instance, if the visual module has encoded an equation from the screen, a rule can fire that initiates the retrieval of an arithmetic fact from declarative memory. To create an ACT-R   model   one has to write such rules and specify the model\u2019s knowledge (e.g., \u20183 + 4 = 7\u2019) in declarative memory. ACT-R itself can therefore be seen as a theory of the fixed architecture of the mind, while a model is dependent on the task that is simulated, and can be seen as a sub-theory specifying how a particular task is performed. \n   The cognitive architecture ACT-R and its mapping on brain regions.  \nNumbers indicate the z-coordinate of each slice (MNI coordinates). For illustrative purposes only, similar to   in [ ]. \n     Regions-of-interest in the original mapping and in the new data-driven mapping.        \nAs mentioned above, ACT-R models predict the blood-oxygen-level dependent (BOLD) response that is measured with fMRI [ ]. Each module is associated with a small region of the brain, shown in  . The assumption is that this region is active when the corresponding module is active. For instance, when the manual module issues a key-press, the associated area in the motor cortex is assumed to show an increased BOLD response. Note that it is not claimed that these are the only regions that are active in response to the modules. The claim is that these regions are necessarily active when the associated modules are active, and thus provide good indicators of module activity. More formally, we describe the activity of a module as a 0\u20131 demand function. This function is convolved with a hemodynamic response function (HRF), which describes the BOLD response (e.g., [ \u2013 ]). In the current paper we used the HRF of the SPM analysis software [ ], which is the difference of two gamma functions. \n\n illustrates this process (for more details, including example model code in Lisp and convolution code in Matlab, see [ ]). Panel A shows the HRF in response to neural activity at time 0. The HRF increases slowly, and only reaches its peak around 5 seconds after the neural activity.   shows the result of convolving a demand function (gray) with the HRF. The predicted BOLD response depends on the amount and duration of periods of module activity. In essence, for each period of activity an HRF is assumed, which are summed to predict the final response [ ].   shows the results of this process when applied to two modules of a complex model (cf.  ; [ ]). The figure depicts four conditions from left to right, which increase in difficulty. Whereas the manual module predicts a lower BOLD response for the more difficult conditions (because the same amount of key-presses are spaced out over more time), the problem state module predicts a strong increase in activity with task difficulty. These predictions can be compared to fMRI data, and can thus be used to evaluate ACT-R models (we will discuss two examples in this paper). We will refer to this type of analysis as a region-of-interest (ROI) analysis. \n   Convolving module activity with a hemodynamic response function.  \n(a) HRF, (b) convolving short periods of module activity with the HRF, and (c) example of the problem state module and manual module for four conditions of a multitasking experiment [ ]. For illustrative purposes only, similar to   in [ ]. \n  \nIf one has a mapping from model component to brain regions, such an ROI-analysis brings strong constraints to a model: not only does the model have to fit behavioral data, but it also has to match the BOLD response in several brain regions over time. However, the analysis depends on having a correct mapping between model and brain regions, a mapping that is often based on a reading of the literature, and thus inherently subjective. In this paper we propose to use a more objective model-based fMRI analysis to create such a model-brain mapping. \n\n\n### Model-based fMRI \n  \nModel-based fMRI is a recent analysis technique that uses computational models to analyze fMRI data (e.g., [ , , ]). The goal of model-based fMRI is to find the most probable location of model components in the brain. The basic idea is to regress predictions derived from a computational model against brain data, thereby showing which brain regions correlate significantly with the model predictions, and are thus most likely to implement the functionality of the model component. This analysis is very similar to standard fMRI analysis, in which the condition-structure of the experiment is regressed against brain data, indicating which regions correspond significantly to the conditions of the experiment (e.g., Friston et al., 2007). Thus, model-based fMRI analysis can be used to create model-brain mappings in a data-driven manner. \n\nModel-based fMRI can be used in combination with a variety of models, which are typically developed based on behavioral data. In most cases, parameter values of mathematical models have been used as the regressors representing the model. Such models have for instance been used to locate regions involved in reinforcement learning [ \u2013 ], category learning [ ], and decision making [ , ]. In 2011, we have shown that it is also possible to use predictions derived from a symbolic process model as input for model-based fMRI [ ]. Analogous to the ROI-analysis, we took the module activity of an ACT-R model and convolved it with a hemodynamic response function ( ). The resulting predictions were regressed against fMRI data, indicating the locations of the ACT-R modules. Recently, a similar method has been used to map the activity of ACT-R modules on EEG oscillatory power [ ]. \n\nAlthough model-based fMRI is in principle an extremely powerful method to map the functionality of the brain [ ], the results critically depend on the quality and assumptions of the model. To avoid idiosyncrasies of particular tasks and models, Borst and Anderson [ ] applied model-based fMRI to five previously published datasets with associated ACT-R models, and subjected the results to a meta-analysis. As their tasks ranged from paired associates [ , ] and algebra [ ] to information processing and multitasking [ , ], we can be reasonably sure that the results are task-independent. Borst and Anderson determined the location of five ACT-R modules: the aural, visual, and manual modules, as well as declarative memory and the problem state module. We will now briefly review their results, as we will use these results as the basis of our new data-driven model-brain mapping. \n\nAs expected, the aural module was localized in the superior temporal gyrus, an area involved in speech processing [ ]. The visual module correlated most strongly with activity in the left and right occipital gyri, which are involved in spatial-visual attention (e.g., [ ]). ACT-R\u2019s right manual module\u2014all responses were made with the right hand in the tasks that were analyzed\u2014mapped onto the left motor cortex, extending from the premotor cortex into the parietal lobe. Both declarative memory and the problem state module (ACT-R\u2019s working memory, which is comparable to the focus of attention in recent theories, e.g., [ \u2013 ]) correlated significantly with activity around the inferior frontal gyrus and in the anterior cingulate. In addition, the problem state module also correlated with a large region around the intraparietal sulcus (together, these regions form the fronto-parietal network; [ \u2013 ]). To dissociate those two modules further, it was investigated in which regions the declarative memory predictors explained more variance than the problem state predictors, and vice versa [ ]. This resulted in a region in the inferior frontal gyrus for declarative memory, and an exclusive problem state region around the intraparietal sulcus. In the next section we will use these results as the basis for our new model-brain mapping. \n\n\n\n## Method: Creating a New Model-Brain Mapping \n  \nThe regions that have been associated with the modules of the ACT-R architecture vary in size from 60 to 100 voxels. Using the results from Borst and Anderson [ ] we created a set of comparably sized regions. In this section we will explain how we combined those results with anatomical constraints and discriminability considerations to define a set of similarly sized regions. In the next two sections of the paper we will apply the new mapping, as well as the original literature-based model-brain mapping, to two new datasets. We will discuss the methods related to those datasets in their respective sections. \n\nTo create the new mapping, the results of the model-based fMRI meta-analysis were thresholded with   p   < 10  and at least 250 voxels per cluster (following [ ]). For the visual and aural modules, we then took the most significant voxel as a seed, and iteratively selected the most significant voxel bordering the currently selected region, until we reached regions consisting of 100 voxels. For the manual module, we did not use all results from the model-based meta-analysis since some active regions were outside of primary motor areas. Instead, we restricted the definition to voxels in the precentral gyrus (as defined in the AAL atlas [ ]). It is well known that the primary motor cortex is located in this region, which matches the functionality of the manual module. Because only 80 significant voxels remained, this ROI is slightly smaller than the others. \n\nFor the problem state and declarative memory modules we followed the same procedure, except that we took the most significant voxel of the dissociation analysis as a seed as both modules resulted in partially overlapping activation patterns. That is, for the problem state module we used a voxel close to the intraparietal sulcus and for declarative memory a voxel close to the inferior frontal gyrus. These voxels dissociated optimally between problem state and declarative memory contributions to the BOLD signal, and will consequently lead to regions that can be used most successfully to distinguish and constrain these modules. \n\nThe regions that we created in this manner were all left-lateralized because the most significant voxels were located in the left hemisphere. To create right-hemisphere homologues, we mirrored these regions. The resulting ROIs are shown in  , in yellow, and summarized in  . The white squares indicate the original mapping of ACT-R (the original visual ROI is not shown, as it is located outside the displayed slices). For most modules the original and the new mapping overlap in part. However, the new region for the problem state is more anterior than in the original mapping, and the new visual region is in a completely different location than the original ROI (located in the fusiform gyrus;   x   = \u221243,   y   = \u221260,   z   = \u221216). In addition, unlike the original mapping, the new mapping follows brain structures, which might increase the power of the analysis (assuming that brain functions do not cross structural boundaries). The new ROIs can be downloaded from  , both as binary images and as MarsBar ROI definitions for use with the SPM analysis software [ ]. \n   The new mapping of ACT-R modules to brain regions.  \nYellow indicates the new mapping, white the original one (the original visual ROI is not shown because it is located on different slices\u2014its center is \u221243, \u221260, \u221216). Coordinates are the center of mass in the MNI system. \n  \nTo investigate the power of the new mapping, and thereby the suitability of model-based fMRI as a basis for such a mapping, we will apply both the new and the original model-brain mapping to two datasets. For dataset 1 we will develop a model, and fit this model to the behavioral results of the dataset. For dataset 2 we will take a previously published model, and use it to generate   a priori   predictions. Next, we will generate neural predictions from both models, and compare these predictions to the neural data of both the new, data-driven model-brain mapping and the original mapping. \n\n\n## Dataset 1: Algebra \n  \nThe first dataset that we considered concerns relatively simple algebra problems. This dataset was previously used to investigate metacognitive activity in mathematical problem solving, by comparing regular problems to so-called exception problems [ ]. To investigate the new ROIs we will only look at the regular problems, as we have a relatively good understanding of how these are solved. To account for the subjects\u2019 behavior, we combined two previously developed models of this task [ , ]. Given our experience with algebra tasks in general and this task in particular [ , , ], we expected our model to give a good account of the data, and therefore to provide a good test of whether the new ROIs reflect the activity of the model\u2019s resources. \n\n### Design \n  \nIn the experiment subjects were asked to solve \u2018pyramid\u2019 problems. A pyramid problem takes the form of   base   $   height   =   value  , for instance 4 $ 3 = 9. To solve a pyramid, one has to perform repeated addition: 4 $ 3 = 4 + 3 + 2 = 9, where the   base   indicates the starting value and the   height   the number of terms to add (where each term is one less than the previous term). In the experiment, either the   base  ,   height  , or   value   was unknown. Consequently, subjects were asked to solve these three kinds of pyramid problems:\n   \nSolve-for-value: 4 $ 3 =   x  \n  \nSolve-for-height: 5 $   x   = 9 \n  \nSolve-for-base:   x   $ 4 = 26 \n  \nThe   base   of the problems ranged from 4 to 9 and the   height   from 2 to 5, resulting in   values   from 4 $ 2 = 7 to 9 $ 5 = 35. We will analyze the problems based on whether they had a small (4\u20136) or a large (7\u20139) base and whether they had a small (2\u20133) or a large (4\u20135) height. Each subject solved 72 problems in the fMRI scanner, 18 problems per condition. Subjects had 30 seconds per problem to calculate a solution; to enter a response they used a mouse to click on an on-screen numeric keypad, finishing a response by clicking a submit button. After responding subjects immediately advanced to a 5s feedback screen, followed by 12 seconds of repetition detection. Then the next trial started with a fixation screen for 4 seconds, followed by the next pyramid problem. In total, twenty subjects participated in the experiment. Detailed methods are reported in [ ]. \n\n\n### Model \n  \nTo account for results of similar experiments, two slightly different models were developed on the basis of behavioral data [ , ]. We combined these models into a single model, to which we will refer as the behavioral model, to simulate the behavior in the current experiment. The model is available for download on  , under the title of this paper. The model starts by encoding a problem from the screen: it attends the   base  ,   height  , and   value   in turn, and while doing so follows its eye gaze with the mouse cursor [ , ]. Based on which variable is unknown, it proceeds down one of three solution paths. If the   value   is unknown, the model starts an iterative addition sequence, starting with adding the   base   to the   base \u2212 1  , and finishing when it has made as many additions as the   height   indicated. For each addition it retrieves the solution from declarative memory, which takes a certain amount of time (on average 483 ms, estimated from the behavioral data). It then continues to the response phase. If the   height   is unknown, it starts the same iterative addition process, but terminates this process when the result matches the   value  , and reports the number of additions. Finally, if the   base   is unknown, the model follows a guess-and-check procedure (as did the subjects; [ ]). It first guesses a number to fill in as the   base  , and then follows the   base  -procedure to check if this guess leads to the right   value  . If it does the model reports the guessed   base  . If the resulting value is too small, the model reports the guessed   base   + 1, if it is too big it reports the guessed   base   \u2212 1. After determining the response the model looks at the screen to find the right button. It then moves the mouse cursor to this button, clicks the button, reads the entered response, and continues to the next button. After entering the full response in this manner, the model clicks the submit button, and reads the feedback to determine whether it was correct. \n\nThe total time the behavioral model needs to complete a trial is the sum of the encoding steps, the addition steps, and the response steps. The times for encoding and responding are fairly constant for the different trial types, but the number of addition steps\u2014and thus the total time spent on addition\u2014varied considerably (range 1.20\u201329.65 s, m = 5.62 s, sd = 2.86 s). First, larger heights lead to more addition steps and thus to a longer RT. Second, larger bases result in more carries than smaller bases. For instance, compare 4 $ 3 = 4 + 3 + 2 = 9 to 9 $ 3 = 9 + 8 + 7 = 24. In the second case two carries have to be performed, which add additional computations to the model and therefore also result in longer RTs. To fit the response times of the model to the behavioral data, we manually adjusted the activation level of the addition facts (e.g., \u20183 + 4 = 7\u2019) in declarative memory (higher activation levels lead to faster retrievals and vice versa, [ ]). \n\n\n### Analysis \n  \nTo investigate the new ROIs we used correct trials only. Two subjects solved respectively 49% and 76% of the regular trials correctly, where all other subjects scored >85%. We excluded these subjects from the analysis, leaving 18 subjects that solved 93.4% (SE = 0.9%) of the problems correctly on average. In addition, we removed problems with a response time (RT) exceeding 2 standard deviations from the mean per condition and subject (4.2% of the trials). \n\n\n### Behavioral results \n  \n shows the response times, on the left for the data, on the right for the model. Height had a substantial effect on response times, with large heights (orange bars) leading to longer response times than small heights (blue bars). Given that the height determines the number of terms in the addition, this is not surprising. A repeated-measure ANOVA confirmed this effect:   F  (1,17) = 190.9,   p   < .001. In addition to height, base also had a positive effect on RTs, with large bases leading to longer RTs (  F  (1,17) = 20.5,   p   < .001). This effect is explained by the slightly larger numbers that have to be added, more often resulting in carries. Comparing the \u2018cognitive phase\u2019 (dark parts of the bars, before the first number was entered) to the response phase (light parts, first number until submit button) indicates that the effects on RT were almost completely due to the cognitive phase. In addition, the average standard deviations indicate that most of the variability was also contained in the cognitive phase. The model captured all these effects; the biggest discrepancy between model and empirical data is the lower variability in the model\u2019s cognitive phase, especially for the large heights. \n   Response times of the algebra dataset.  \nBlue bars indicate small heights, orange bars large heights; dark parts of the bars indicate the time until the first mouse click, light parts the time between the first click and clicking the submit button. Error bars indicate the average standard deviation. \n  \n\n### Imaging results \n  \nThe top row of   shows the model\u2019s BOLD predictions for four modules: the problem state module (ACT-R\u2019s working memory), declarative memory, the right-manual module, and the visual module. The next two rows show the results in the new, data-driven ROIs and in the original ROIs, respectively. All results are from the ROIs in the left hemisphere, as these typically show the strongest effects.   reports three fit measures of the model predictions to the data: the R , the root-mean-square deviation, and Tucker\u2019s Congruence Coefficient (TCC; [ ]). Although we assume the first two measures to be familiar, TCC might not be. TCC measures the proportionality of the elements in two vectors, that is, it is another way of measuring the similarity of two vectors. The values of TCC range between \u22121 and 1, with \u22121 indicating a complete opposite (with a correlation of \u22121), and 1 indicating identical vectors. In practice, values between .85 and .94 correspond to a fair similarity, and values over .95 indicate that the two vectors are almost identical [ ]. Unlike the R  measure of correspondence, TCC does take into account the slope of the vectors (positive vs. negative), the sign of the vectors, and it can handle horizontal lines. See   for several demonstrations. In addition to the TCC of the aggregate data, we also report the average TCC per participant, and its standard deviation and range. \n   Imaging results of the algebra dataset.  \nThe top row shows model predictions, the middle row the BOLD responses in the new, data-driven ROIs, and the bottom row the BOLD responses in the original ROIs. \n     Fit measures for the new data-driven mapping and the original mapping on the algebra dataset.        \nIn general, both model-brain mappings showed very similar BOLD responses, which, in turn, were similar to the model predictions. The problem state module showed the least good fit, with R -values around .7 and TCC values of .86 and .87. Although the model predicted the order and the difference between conditions correctly, the activity persisted for a longer period of time than assumed by the model. This probably indicates that subjects also used their working memory to interpret the feedback, which was essentially ignored by the model as soon as it had determined that it was correct. With respect to declarative memory, the model predictions might seem less good than for the problem state module, but the fit measures indicate otherwise. The main difference was that the model predicted the   small   $   large   problems to have a significantly lower BOLD response than the   large   $   large   problems, while the two problem types showed an almost identical response in the fMRI data. \n\nFor the right manual module (associated with the left motor cortex), the model predicted a decrease between initial movements and entering the response for the large-height problems. Although there seems to be a similar effect in the data, it is much less pronounced than in the model, indicating that subjects kept moving the mouse around while solving the problems. However, the model correctly predicted the sometimes very small differences between conditions. Finally, for the visual module, the new data-driven ROI performed slightly better than the original ROI, in the sense that the BOLD response in the data-driven ROI was closer to the model prediction. In addition, the signal in the data-driven ROI seems a little smoother (especially scans 0\u20134), which might indicate that the new ROI is less susceptible to noise. \n\n\n### Discussion \n  \nAs expected the model accounted well for the behavioral data, and also matched the fMRI data relatively closely. There were only small differences between the original and the new, data-driven ROIs, indicating that model-based fMRI is a suitable method to create a mapping between model components and brain regions. The regions associated with the visual module showed the greatest difference, which was not surprising given that these were also the furthest apart in the brain. The new visual ROI matched the model predictions a little better than the original ROI, perhaps indicating that the new ROI should be preferred. However, this conclusion is dependent on the model being correct. \n\nWe used a relatively simple task as a first test of the data-driven model-brain mapping, in order to be reasonably sure that our model would give a good account of the data, which gave us some sort of \u2018ground truth\u2019 to compare the data to. However, the comparison normally goes the other way: it is assumed that the ROIs are good indicators of the modules of ACT-R, and they are used to test the model. We will highlight this approach with our second dataset, which was much more challenging and for which we made   a priori   predictions. In addition, the complexity of our second dataset turned out to lead to more differentiating results between the two mappings. \n\n\n\n## Dataset 2: Multitasking \n  \nThe second dataset concerned multitasking. This dataset was previously used to investigate the relationship between single-task and dual-task activation in the brain [ ]. To that end, three different single tasks were used, which were additionally combined to form three different dual-tasks. Based on a behavioral pilot study, a model was developed that matched accuracy and RT data [ ]. This model was used to generate   a priori   fMRI predictions for five ACT-R modules: the aural module, the visual module, the left and right manual modules, the problem state module, and the declarative memory module. Here, we will test how well this model can account for the behavioral and BOLD data of the fMRI study. This will show how these kinds of analyses can be used to indicate problems with a model, and will test how the new data-driven model-brain mapping and the original mapping compare in a more complex task. \n\n### Design \n  \nIn the multitasking experiment subjects were asked to perform three tasks: a visual tracking task, a tone-counting task, and an n-back task. The tasks were performed as single tasks and as dual-tasks, resulting in six different conditions (i.e., A, B, C, AB, AC, and BC). The tasks were identical in the single-task and dual-task conditions, except that two tasks were presented concurrently in the dual-task conditions. In the single-task conditions, all tasks were presented in the center of the screen, while in the dual-task conditions one task was presented on the left half of the screen and one task on the right. \n\nIn the visual tracking task a target dot moved randomly to the left and to the right. The subjects\u2019 goal was to keep a circular cursor centered on this dot by pressing a \u2018left\u2019 and a \u2018right\u2019 key with their right hands. Two vertical lines on each side of the dot indicated the maximum allowed distance between target and cursor. During dual-task conditions, the tracking task was displayed on the right side of the screen. \n\nIn the n-back task a stream of 12 letters was presented on the screen. Each letter was presented for 1000 ms, followed by a 1500 ms blank. For each letter subjects had to indicate whether it was the same or different as the letter two back. They used their left hands for this. During dual-task conditions, the n-back task was presented on the left side of the screen. \n\nFinally, in the tone-counting task, 20 tones were presented over a 30 second period. Tones could be high or low, subjects were instructed to count high tones only (10\u201317 per trial). During this task a fixation cross was presented on the screen; subjects were asked to enter their response at the end of the trial by incrementing a counter. The tone-counting task was presented on the right side of the screen when it was performed in combination with the n-back task; it was presented on the left side of the screen in combination with the tracking task. Subjects used their right hands to respond to the counting task in the single-task condition and in combination with the n-back task; they responded with their left hands in combination with the tracking task. \n\nAll trials lasted 30 seconds, with an additional 10 seconds in the tone-counting conditions to enter a response. 19 subjects participated in the experiment; each subject completed 72 trials, 12 per condition. Detailed methods can be found in [ ]. \n\n\n### Model \n  \nTo account for the behavior on these tasks a model was developed and fit to the data of a behavioral experiment with a similar design [ ]. The model was developed in ACT-R, and incorporates the ideas of threaded cognition theory [ , ] to handle multitasking situations. \n\nTo perform the visual tracking task, the model uses the visual module to perceive the locations of the circular cursor and the target. If the target has moved away from the cursor, the model presses the required key to move the cursor towards the target. It repeats this procedure until the cursor is on top of the target. To count the tones in the counting task, the model uses the aural module to listen to the tones. If a tone is high, it updates a counter in the problem state module, which thus keeps track of the total number of high tones. At the end of a trial this counter is used to enter the total number of high tones. Finally, to perform the n-back task, the model uses the visual module to encode the stimuli. It stores the last letter in the problem state module and the two-back letter in declarative memory based on the observation that the problem state module can only contain a single chunk of information [ ]. When it perceives a new letter, it retrieves the letter two-back from memory and compares them. Based on whether the letters are the same or different, the model gives the required response. \n\nPerforming the single tasks in this way is relatively easy. However, the dual-task situations are more demanding. The modules of the ACT-R architecture operate in parallel, but each module itself proceeds serially [ ]. This results in interference between tasks when they require the same resources at the same time (e.g., [ ]). For example, the tracking task and the n-back task both need the visual module to perceive the stimuli. Given that the visual module can only process one request at a time, these tasks will have to wait for each other, resulting in a decrease in performance on both tasks. Combining tracking and tone counting, on the other hand, does not lead to significant interference for the model, because performance on those tasks is dependent on different modules (aural and problem state for counting; visual and manual for tracking). Finally, combining tone counting and the n-back task will result in the most severe predicted interference. Both tasks require the problem state module to keep track of the count and the letters, respectively. It has been shown that the problem state module can only maintain a single chunk of information, and that it causes considerable interference when required by two tasks concurrently [ , , ]. The idea is that the contents of the problem state module\u2014representing working memory of the first task\u2014are stored in declarative memory when the other task needs to use the problem state. When resuming the first task this information has to be retrieved from declarative memory, which takes time and can go wrong, leading to increased RTs and error rates. \n\nThe model was not fit to the current data-set, we used the parameter settings from [ ], both for the behavioral as well as for the neural predictions. \n\n\n### Behavioral results \n  \n shows the behavioral results: on the left the data, on the right the model predictions. The top left graph shows the mismatch between high tones presented and counted in the tone-counting task. Subjects performed well in all conditions, but made more errors when tone counting was combined with n-back, while tracking only had a minimal impact. The second graph shows the proportion of error time in the tracking task, which is the proportion of time the cursor was outside the vertical lines flanking the target dot. Subjects also performed very well on this task; only the combination with n-back led to a clear decrease in performance. The model predicted these results fairly accurately, although it predicted a much higher tracking error than displayed by the human subjects. In general, doing either of the tasks in combination with n-back led to the largest performance decrements. The model attributed those decrements to competition for the problem state module in the case of tone counting and to competition for the visual module in the case of the tracking task. \n   Behavioral results for the multitasking dataset.  \nLeft four graphs show the data, the right four graphs the model predictions. Error bars indicate standard error. \n  \nThe bottom graphs of   show the results on the n-back task itself, percent error on the left and response time on the right. Interestingly, error rate increased most in combination with tone counting, while the combination with tracking led to the highest RTs. The model matched those effects qualitatively. It explained the increased error rate in combination with tone counting by competition for the problem state module. Because the contents of the problem state have to be swapped out via declarative memory for those tasks, incorrect letters are sometimes retrieved from memory, leading to errors on the n-back task. The increase in RT when n-back was combined with the tracking task was explained by competition for the visual resource: the model had to check the status of the tracking task regularly, resulting in delayed reactions to the n-back task. \n\nAs the purpose of the second dataset is to test the applicability of data-driven model-brain mappings when cognitive models are used to predict data   a priori  , we refrained from optimizing the model to fit the behavioral data as that would refute the notion of a true   a priori   prediction. \n\n\n### Imaging results \n  \n (left and right manual module) and   (problem state, declarative memory, aural, and visual modules) show the fMRI results. The model predictions are shown in the top rows of the figures, the results of the new data-driven ROIs in the middle rows, and the results of the original ROIs in the bottom rows. The colors of the conditions correspond to the colors in  .   reports fit measures. \n   Imaging results of the multitasking dataset for the left and right manual modules.  \nThe top row shows model predictions, the middle row the BOLD responses in the new, data-driven ROIs, and the bottom row the BOLD responses in the original ROIs. \n     Imaging results of the multitasking dataset for the problem state, declarative memory, aural, and visual modules.  \nThe top row shows model predictions, the middle row the BOLD responses in the new, data-driven ROIs, and the bottom row the BOLD responses in the original ROIs. \n     Fit measures for the data-driven and original mappings on the multitasking dataset.        \nFor the right manual module (associated with the left motor cortex;  ), the model predicted high activation levels throughout the trial for all conditions involving tracking. In addition, it predicted a peak at the end of the trial for the tone-counting task (single task and in combination with n-back). These predictions follow from the fact that subjects had to use their right hands for these tasks. Both the data-driven and the original ROIs confirmed this pattern of activity. The data-driven model-brain mapping resulted in a minimally better fit, probably because the conditions that did not use the right hand remained closer to baseline. For the left manual module the model predicted much less activity: only the n-back task required left-handed responses during the trial, and only the tone-counting task in combination with tracking at the end of the trial. Both ROIs confirmed these effects; the data-driven ROI again showed a slightly better fit than the original ROI. The biggest discrepancy between model and data was the lower activity level in the n-back and tone-counting condition than in the other n-back conditions. This decrease might be caused by subjects failing to give all responses in the n-back task when it was combined with tone-counting (1.7% misses vs. 0.9% misses in the other conditions), while the model never missed a response (although it made more mistakes in this condition, see  ). \n\n shows the results for the other modules. The model predicted similar patterns for the problem state and declarative memory modules: activity in all conditions involving n-back and tone-counting, with a major increase in the n-back and tone-counting condition. As explained above, this increase is due to a constant swapping out of the problem state module via declarative memory in the n-back and tone-counting condition. Both ROIs disconfirmed this prediction. Instead, they indicated a decreased use of the problem state module in the n-back and tone-counting condition (perhaps caused by missed n-back stimuli, analogous to the left manual results discussed above). In addition, the tone-counting task seemed not to use the problem state module at all (subjects might have employed subvocal rehearsal strategies instead, see [ ]). Given that neither mapping matched the model predictions, the fit measures can tell us little about which one is preferred. However, visual inspection showed a better separation of the n-back and tone-counting conditions from inactive conditions in the data-driven ROI for the problem state. In addition, the inactive conditions remain closer to zero in the data-driven ROIs. \n\nThe model predicted equal involvement of the aural module (third column in  ) in all tone-counting conditions. The data showed that this was not the case, with the dual-tasks leading to less activity in the aural ROIs\u2014probably linked to less attention for tone counting in these conditions. Again, the data-driven ROI showed to a clearer separation of the conditions, and maintained activity throughout the trial for the n-back and tone-counting condition. Although we do not have access to ground truth, it seems reasonable to assume that subjects kept listening to the tones in this condition given their performance ( ), which is thus better reflected by the data-driven ROI. Finally, the model predicted considerable activity for all tracking conditions in the visual region. For the n-back task much less activity was predicted, and no activity at all for the tone-counting single task. These predictions were confirmed in part by either ROI. The data-driven ROI showed more activity for the tracking condition than for all other conditions, but no activity in response to n-back. The ROI of the original mapping, on the other hand, showed activity for all condition involving n-back, but hardly at all for the tracking conditions (only the tracking single task resulted in some activation). \n\n\n### Discussion \n  \nFor the second dataset we made fMRI predictions based on a pilot dataset [ ]. The model\u2019s behavioral fit to the current dataset was good, especially taken into account that these were   a priori   predictions. However, although the behavioral fit might have led us to believe that the model is on the right track, the fMRI data revealed otherwise. While the model correctly predicted the patterns in the left and right manual regions and showed a rough fit to the data in the aural and visual regions, it predicted the main effects incorrectly in the problem state and declarative memory regions\u2014the core cognitive components of the model. The data seem to indicate that subjects did not use their working memory to perform the tone-counting task, as the model assumed. Furthermore, even in regions where the model fit well to the fMRI data, there were hints in the data on how the model should be improved (e.g., decreased attention to auditory stimuli in the tone-counting dual-tasks). In addition to the module-specific mismatches, there seems to be a general dip in the data in many regions between the start and the end of the trial, which was not captured by the model. One possible explanation is that there was a saturation in the BOLD response that was not captured by our HRF (e.g., [ ]). \n\nOur main interest in the current paper is whether model-based fMRI is a suitable method for creating model-brain mappings. As in the first dataset, the data-driven ROIs performed as well or better than the original ROIs. Conditions for which no activation was predicted remained closer to baseline (the data-driven regions especially showed less deactivation), and conditions were often better separated in the data-driven ROIs (problem state, aural). As in the first dataset, the visual ROIs showed the greatest differences. This dataset seemed to hint at a separate functionality of the two visual ROIs. The new, data-driven ROI reacted exclusively to the visual tracking task, whereas the original ROI responded more strongly to the n-back task. These results seem to indicate that the data-driven ROI is involved in visual-spatial processing, while the original ROI is more involved in detailed processing of the letters in the n-back task. This is in agreement with the literature on regional functions: the data-driven ROI is located in the occipital gyrus, part of the dorsal \u2018where\u2019 stream of visual processing, whereas the original ROI is located in the fusiform gyrus, part of the ventral \u2018what\u2019 stream (e.g., [ , ]). \n\n\n\n## General Discussion \n  \nMore and more researchers turn to neuroscience for constraints on formal models of cognition (e.g., [ \u2013 ]). Our second dataset illustrates why: even though we were able to predict the main patterns in the behavioral data\u2014an important model requirement [ , \u2013 ]\u2014the neuroimaging data showed that several assumptions underlying the model were incorrect. However, before one can use neuroimaging data to constrain cognitive models, a mapping from model components to brain regions is needed. Originally, such a mapping was based on the experience of the researcher or on a reading of the literature, and was thus necessarily subjective. In this paper we proposed a more objective method to create such a mapping: model-based fMRI analysis (e.g., [ , ]). Model-based fMRI is a formal and data-driven method, and is therefore preferred over the original approach\u2014at least if the results are comparable. To test whether model-based fMRI is indeed suitable we used it to create a mapping for five modules of the ACT-R cognitive architecture. We subsequently applied this new mapping, as well as the original, literature-based mapping, to two datasets: a relatively simple algebra task and a more demanding multitasking experiment. For each dataset we developed a model, and used this model to generate fMRI predictions. These predictions were compared to the data of both the original and the new, data-driven mapping. \n\nWe started with the algebra dataset because we have extensive experience with modeling algebra tasks in general and pyramid experiments in particular [ \u2013 ]. We could therefore be reasonably sure that our model of this task would match the data, thereby providing validation of the approach. Indeed, the fit to both the behavioral data and the fMRI data was good. The new data-driven model-brain mapping performed as well as the original mapping on this dataset, indicating that model-based fMRI is a suitable way to create model-brain mappings. As it is a more objective method than the original approach, it is therefore to be preferred, even though the results were not clearly better than the results of the original mapping. \n\nThe drawback of using such a simple task was that demands on the model components were limited and that differences between the two mappings might not have become apparent. We therefore used a much more challenging multitasking dataset as our second test. Instead of fitting data we made   a priori   fMRI predictions for this dataset. We did not expect to match all data in this case; instead, our aim was to provide an example of how fMRI data can be used to inform cognitive models (using the model as a \u2018sacrificial lamb\u2019 [ ]). Indeed, even though the model matched the patterns in the behavioral data and in the perceptual and motor regions of the brain, its predictions for the cognitive components were incorrect. The results indicated which assumptions of the model need to be altered, and additionally showed that behavior alone does not provide sufficient constraints for models of complex cognition. Furthermore, the second dataset resulted in slightly more pronounced differences between the two mappings. In general, the data-driven model-brain mapping yielded a better separation between conditions of the experiment, and showed less activation and less deactivation for conditions that presumably did not involve the associated model components. As a result, it will provide better constraints and guidance for new models developed in the ACT-R architecture. \n\nAlthough we demonstrated model-based fMRI in combination with the ACT-R architecture, it can be used in combination with a variety of cognitive models. The method was originally used in combination with mathematical models, which yield parameter values that typically vary on a trial-by-trial basis. These parameter values can be convolved with an HRF, and subsequently be used as regressors in the analysis. Such models have been used to locate the neural correlates of, for instance, reinforcement learning, category learning, and decision making [ \u2013 ]. In 2011, we have shown that model-based fMRI can also be used in combination with process models that make time-by-time predictions, such as ACT-R [ ]. In fact, the method will work in combination with any formal model, as long as the model predicts activity of model components, either differentiating in temporal profile or in predicted amplitude between conditions (and preferably between trials or at least trial types, [ ]). However, we are not aware of another modeling formalism that has used the results of model-based fMRI to create a mapping between model components and brain regions in order to constrain future models. \n\nWhen using model-based fMRI to develop model-brain mappings, one has to be careful not to apply the method in a circular fashion. That is, one has to use one model (or, preferably, several models) to identify the model-brain mapping, and then use this mapping to confirm or disconfirm   different   models, as we did in the current paper. The same model can never be used to create the mapping and to be tested with the created mapping. \n\nGiven the small differences between the results of the data-driven model-brain mapping and the original mapping, one might wonder whether we need model-based fMRI to create such a mapping. The original mapping was based on the literature on regional functions and on the experience of the ACT-R research group. Even though it was very successful and turned out to be very close to our new data-driven model-brain mapping, it was therefore necessarily subjective. For that reason we argue that model-based fMRI is the preferred method, as it is data-driven and objective (although the models are still dependent on the researchers, a problem we circumvented by using the results of a meta-analysis). The current results can thus be seen as a confirmation of the original mapping. In addition, the new data-driven mapping was slightly more powerful than the original mapping. One reason for this might be that the new mapping follows brain structures, unlike the original mapping (see  ). Assuming that brain functions in general do not cross structural boundaries, this should lead to less noise in the signal. \n\nTaking the results of the two datasets in to account, it seems clear that the new mapping of the problem state, declarative memory, aural, and manual modules is at least as powerful as the original mapping. However, the results of the visual module are less straightforward. In the first dataset the new mapping performed slightly better than the original mapping, under the assumption that the generating model was correct. In the second dataset, however, the new visual ROI exclusively reacted to the tracking task and not to the n-back task\u2014indicating that it is involved in visual-spatial processing and not in processing of detailed stimuli. The original ROI, on the other hand, hardly responded to the tracking task, but more to the n-back task. These results are in agreement with the literature, which suggests that the location of the new ROI (the occipital gyrus) is involved in spatial processing, while the location of the original ROI is involved in reading and processing of detailed stimuli [ , , ]. The functionality of the original ROI seems therefore closer to the functionality of the visual module in ACT-R, which is involved in encoding the details of the visual world. ACT-R currently does not have a module that is used for spatial reasoning. Although the visual-location module might be considered a spatial module, it only processes the location of objects on the screen, and does not perform any kind of spatial reasoning. In the current two datasets it matched worse to both the new and to the original visual ROI than the visual module. The current results imply that a visual-spatial module should be implemented and that its activity should be mapped onto the occipital gyrus. \n\n\n## Supporting Information \n  \n \n\n# Table(s)\n## ID: pone.0119673.t001\n### Label: Table 1\nUnnamed: 0_level_0\tOriginal Mapping\tOriginal Mapping\tData-driven mapping\tData-driven mapping\nModule\tBrain Region\tCoordinates\tName\tCoordinates\nProblem State\tIntraparietal sulcus\t\u221224, \u221267, 44\tIntraparietal sulcus\t\u221238, \u221250, 48\nDeclarative Memory\tInferior frontal sulcus\t\u221243, 24, 25\tInferior frontal sulcus\t\u221246, 16, 26\nManual\tPrecentral gyrus\t\u221242, \u221223, 54\tPrecentral gyrus\t\u221233, \u221218, 57\nAural\tSuperior temporal gyrus\t\u221248, \u221221, 7\tSuperior temporal gyrus\t\u221258, \u221221, 4\nVisual\tFusiform gyrus\t\u221243, \u221260, \u221216\tMiddle occipital gyrus\t\u221230, \u221284, 15\n### Caption\nRegions-of-interest in the original mapping and in the new data-driven mapping.\n### Footer\nNote: Coordinates are for the left hemisphere (MNI).\n\n\n## ID: pone.0119673.t002\n### Label: Table 2\nUnnamed: 0_level_0\tData-driven mapping\tData-driven mapping\tData-driven mapping\tData-driven mapping\tOriginal Mapping\tOriginal Mapping\tOriginal Mapping\tOriginal Mapping\nModule\tTCC\tInd. TCC\tR2\tRMSD\tTCC\tInd. TCC\tR2\tRMSD\nProblem State\t0.86\t.79 (.10; .59\u2013.94)\t0.67\t0.35\t0.87\t.74 (.39; \u2212.81\u2013.92)\t0.7\t0.43\nDeclarative Memory\t0.91\t.70 (.25; \u2212.11\u2013.91)\t0.82\t0.2\t0.91\t.71 (.18; .25 \u2013.90)\t0.84\t0.13\nRight Manual\t0.94\t.71 (.40; \u2212.42\u2013.93)\t0.89\t0.17\t0.93\t.74 (.32; \u2212.32\u2013.91)\t0.87\t0.25\nVisual\t0.96\t.88 (.09; .57 \u2013.94)\t0.93\t0.33\t0.9\t.59 (.44; \u2212.60\u2013.86)\t0.69\t0.17\n### Caption\nFit measures for the new data-driven mapping and the original mapping on the algebra dataset.\n### Footer\nNote: TCC = Tucker\u2019s Congruence Coefficient, Ind. TCC = mean individual TCC (standard deviation, range), RMSD = root-mean-square deviation.\n\n\n## ID: pone.0119673.t003\n### Label: Table 3\nUnnamed: 0_level_0\tData-driven mapping\tData-driven mapping\tData-driven mapping\tData-driven mapping\tOriginal Mapping\tOriginal Mapping\tOriginal Mapping\tOriginal Mapping\nModule\tTCC\tInd. TCC\tR2\tRMSD\tTCC\tInd. TCC\tR2\tRMSD\nProblem State\t0.6\t.48 (.21; .00 \u2013.72)\t0.08\t0.23\t0.5\t.36 (.25; \u2212.08\u2013.67)\t0.01\t0.2\nDeclarative Memory\t0.68\t.48 (.24; \u2212.19\u2013.80)\t0.26\t0.18\t0.63\t.31 (.40; \u2212.56\u2013.78)\t0.21\t0.1\nRight Manual\t0.96\t.87 (.06; .74 \u2013.95)\t0.88\t0.14\t0.96\t.87 (.06; \u2212.74\u2013.96)\t0.86\t0.2\nLeft Manual\t0.8\t.49 (.23; \u2212.02\u2013.83)\t0.49\t0.09\t0.73\t.46 (.23; .01\u2013.84)\t0.47\t0.11\nAural\t0.78\t.52 (.23; .07\u2013.90)\t0.63\t0.09\t0.62\t.36 (.27; \u2212.24\u2013.72)\t0.43\t0.1\nVisual\t0.64\t.42 (.33; \u2212.29\u2013.82)\t0.08\t0.16\t0.54\t.38 (.20; .05 \u2013.65)\t0.03\t0.25\n### Caption\nFit measures for the data-driven and original mappings on the multitasking dataset.\n### Footer\nNote: TCC = Tucker\u2019s Congruence Coefficient, Ind. TCC = mean individual TCC (standard deviation, range), RMSD = root-mean-square deviation.\n", "metadata": {"pmcid": 4352055, "text_md5": "172f17eedd5e4c7e5dbc91786a620d5d", "field_positions": {"authors": [0, 102], "journal": [103, 111], "publication_year": [113, 117], "title": [128, 206], "keywords": [220, 220], "abstract": [233, 1344], "body": [1353, 57319], "tables": [57332, 59902]}, "batch": 2, "pmid": 25747601, "doi": "10.1371/journal.pone.0119673", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4352055", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4352055"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4352055\">4352055</a>", "list_title": "PMC4352055  Using Data-Driven Model-Brain Mappings to Constrain Formal Models of Cognition"}
{"text": "Schaefer, Michael and Cherkasskiy, Lillia and Denke, Claudia and Spies, Claudia and Song, Hyunjin and Malahy, Sean and Heinz, Andreas and Str\u00f6hle, Andreas and Bargh, John A.\nSci Rep, 2018\n\n# Title\n\nIncidental haptic sensations influence judgment of crimes\n\n# Keywords\n\n\n\n# Abstract\n \nExtralegal factors may influence judicial outcomes. Here we investigated the experience of incidental haptic sensations on the harshness of punishment recommendations. Based on recent theories of embodiment, which claim that cognitive representations are structured by metaphorical mappings from sensory experience, we hypothesized that tactile priming with hard objects would cause subjects to recommend harsher sentences (to be \u2018hard on crime\u2019). Furthermore, the theory of embodiment predicts that this effect should be based on sensorimotor brain activation during the judging process. In order to test this we presented participants with scenarios that described various crimes while scanning their brain activity with fMRI. Participants were then asked to rate how severely they would sentence the delinquents. Before the scenarios, the participants were primed by touching either a hard or a soft object. Results revealed tha t hard priming led participants to recommend harder punishments. These results were accompanied by activation of somatosensory brain areas during the judging phase. This outcome is in line with simulation assumptions of the embodiment theory and proposes a central role of the sensorimotor cortices for embodied metaphors. Thus, incidental tactile experiences can influence our abstract cognitions and even how hard we are on criminals. \n \n\n# Body\n \n## Introduction \n  \nWhen people are awaiting sentencing after being convicted of committing a crime, we expect that the judges will be fair to them and not be influenced by any factors beyond those of the crime itself. Regardless if one is facing a judge, a juror, a committee, or his or her boss, we assume that no factors external to the misdeeds themselves should influence this interaction. However, we all know that this is often not the case. Several studies report that \u201cextralegal\u201d factors may have an effect on judicial outcomes . For example, physical attractiveness of defendants has been shown to be advantageous , as is an innocent \u2018baby face\u2019 . Here we suggest that another factor may influence judicial decision-making. We propose that incidental haptic sensations may have an impact on subsequent judgments. \n\nThe supporting theory for this hypothesis is the theory of embodied cognitions, which claims that cognitive representations are structured by metaphorical mappings from sensory experience. In this theory, metaphors are not mere figures of speech, but may actively influence our thoughts and behaviors in an unconscious and often deep way . Numerous studies have found support for this theory. For example, it has been demonstrated that experiencing physical warmth as through holding a cup of hot (versus iced) coffee makes individuals more likely to judge someone as having a \u201cwarm\u201d personality . Additionally, holding something warm activates the same small region of the insula as when the person sends or receives a text from a family member or friend (i.e., social warmth) . Moreover, recent studies have shown that the activation of concepts such as \u2018hardness\u2019 through actual physical experiences may guide analogue psychological concepts. These abstract concepts are based on idioms such as \u201chard-hearted\u201d or \u201chard day\u201d and link \u2018hardness\u2019 with metaphorical meanings of resistance to influence. For example, Ackerman   et al  . asked participants to imagine shopping for a new car, making an offer to the dealer, being rejected, and then being asked to make a second offer. Half of the participants were sitting in a hard wooden chair, the other half in a soft cushioned chair. Those participants sitting in a hard chair made a smaller adjustment to their offer. Thus, they \u2018took a harder line\u2019 in this negotiation . \n\nWhere do these physical-to-psychological priming effects come from? It has been suggested that early experiences with the physical world structure or \u2018scaffold\u2019 our later understanding or representation of more abstract concepts . Hence, abstract concepts such as \u2018hardness\u2019 may be based on, and associatively connected to, representations of sensory and motor experiences . The conceptual metaphor theory holds that mental processes involve simulations of body-related perceptions and actions. Hence, the retrieval of conceptual meaning involves a partial re-enactment of sensory and motor experiences. Conceptual metaphor theory would thus predict that any effects of \u201chard\u201d priming on psychological concepts should involve sensorimotor brain regions being active during the judgment phase and influencing those judgments accordingly. \n\nThe current study had two aims. First, we examined if the activation of the psychological concept of \u2018hardness\u2019 may also affect judgment decisions. Thus, we tested whether incidental \u201chard\u201d priming led people to be \u201chard\u201d on crimes. This hypothesis is based on recent findings that negotiators seated on hard chairs do not compromise as much as do those seated on soft chairs . Second, we evaluated whether the neural underpinnings of this effect are found in the sensorimotor cortices, which would strengthen the hypothesis of the physical-to-psychological link hypothesized by the conceptual metaphor theory. \n\nThe first study report results of a behavioral pre-study that manipulated hard and soft experiences (sitting on a hard vs. sitting on a soft chair) while participants were asked to judge crime scenarios. The second study aimed to explore the neural correlates for this effect by using an fMRI approach. \n\n\n## Study 1 \n  \nWe predicted across two experiments, using 6 different hypothetical criminal scenarios and diverse response formats, that sitting in a hard chair as compared to a soft chair would cause participants to punish hypothetical criminals more harshly because the hard chair should automatically and implicitly (without the participants\u2019 awareness) activate the concept of harshness while the soft chair should activate the concept of leniency. \n\nWe additionally investigated the potential mediational role of changes in emotions or political attitudes produced by the chair hardness manipulation on sentencing behavior. It is possible that any effect of hard (versus soft) chairs on punishment severity might operate by temporarily influencing the participants\u2019 political and social views to be more conservative . It is also possible that the influence of chair hardness on sentencing may operate by making participants in the hard (versus soft) chair condition experience more negative emotions because the hard chair may be uncomfortable or unpleasant to sit in. We wanted to investigate this possibility because negative emotional states have been previously linked to harsh (versus lenient) judgments, including anger  and sadness . \n\n### Experiment 1: Sitting in hard chairs makes people hard on thieves and murderers \n  \nIn Experiment 1, 41 students (mean age\u2009=\u200919 years, 25 females) were randomly assigned to complete a paper and pencil questionnaire at a desk in the laboratory while seated in either a hard wooden chair or a soft cushioned chair. These chairs were identical to those used by Ackerman   et al  . . The questionnaire contained four short hypothetical crime scenarios (adapted from ) which describe 1) a youth who stole a T.V., 2) a bank teller who falsified accounts and stole money, 3) a man who stabbed his unfaithful wife, and 4) a repeat offender who robbed a bank with accomplices and killed a guard. For each scenario, participants were asked to give their judgment as to how many months (if any) the offender should spend in jail and additionally how much money (if any) he or she should be fined for the crime. Next, participants completed the Positive and Negative Affective Schedule (PANAS) , which assesses the extent to which they currently feel each of 20 emotions, on scales from 1(not at all) to 5(extremely); following which they were debriefed and thanked for participating. \n\nTo prepare our data for analysis, we first converted into z-scores participant judgments of how many months the offender should spend in jail and how much money he or she should be fined for the crime. Because combined, these two judgments constitute the full recommended punishment for each described crime, we added together the two z-scores for jail time and fine amount for each scenario to create one composite punishment score from each participant for each scenario. We added the z-scores instead of averaging them because conceptually, the jail time and fine variables are additive components of the overall assigned punishment for each hypothetical criminal rather than redundant measures of the same conceptual variable. \n\nA 4 (criminal scenarios 1\u20134)\u2009\u00d7\u20092 (hard vs. soft chair) repeated measures analysis of variance (ANOVA) on punishment harshness revealed a main effect of the chair hardness manipulation. As predicted, compared with participants in the soft chair condition, participants in the hard chair condition assigned harsher composite punishments across the 4 scenarios (F(1, 39)\u2009=\u20095.03, p\u2009<\u20090.05, see Fig.\u00a0 ) (the pattern of results is the same when recommended jail time and fine are each analyzed separately using a repeated measures ANOVA).   \nRecommended punishment for scenarios involving thieves and murderers is shown as a function of chair condition (study 1, experiment 1). Error bars represent\u2009\u00b1\u20091 SEM. \n  \n\nNext, we assessed whether changes in the valence of experienced emotions mediated the influence of chair hardness on punishment harshness. Following standard scoring procedure, the PANAS score was obtained by subtracting the total negative emotion score from the total positive emotion score to calculate a net positive emotional valence score. Chair hardness had a marginal effect on net positive emotional valence scores, t(36)\u2009=\u20091.91, p\u2009=\u20090.07, but in the opposite of the predicted direction, with participants seated in the hard chair experiencing more positive emotions (M\u2009=\u200914.52, SD\u2009=\u20095.82) than participants seated in the soft chair (M\u2009=\u200910.29, SD\u2009=\u20097.86). There was no influence of emotional valence on composite punishments for any of the 4 scenarios (largest r\u2009=\u20090.25, p\u2009>\u20090.14), so a test of mediation by emotional valence of the effect of chair hardness on punishment was not justified. \n\n\n### Experiment 2: Sitting in hard chairs makes people hard on cheaters \n  \nWe had three goals for Experiment 2: 1) replicate the main effect from Experiment 1 using criminal scenarios involving less severe crimes, 2) replicate the unexpectedly positive (albeit marginal) influence of chair hardness on emotions from Experiment 1 using a different measure of emotional valence, and 3) investigate an additional potential mediator of the relationship between chair hardness and punishment harshness: change in political attitudes. \n\nIn Experiment 2, 44 students and community members (mean age\u2009=\u200922 years, 33 females, 2 unspecified) were randomly assigned to sit in the hard or soft chair as in Experiment 1 while completing a paper-and-pencil questionnaire on a clipboard. Participants were recruited and completed the short (3\u2009minute) study at a busy indoor intersection on a college campus. The questionnaire contained two original hypothetical scenarios about two college students who cheated; one who had failed to cite heavily referenced sources in a final course paper that earned 91/100 points, and another who had copied another student\u2019s answer on a midterm exam on which she earned 94/100 points. For each scenario, participants were asked to give their judgment as to how many points should be deducted as a punishment for cheating on the assignment. Next, participants answered \u201cHow positive do you feel right now?\u201d on a scale from 1 (Not at all) to 7 (Extremely) and \u201cHow negative do you feel right now?\u201d using the same scale. Finally, participants were administered the measure of liberal versus conservative attitudes, in which they indicated how they would describe their political beliefs 1) overall, 2) socially, and 3) economically, using the following scale for each item: 1(Very liberal) to 9 (Very conservative). \n\nTo prepare our data for analysis, we first checked whether the points deducted punishment variable was normally distributed for each scenario using a Kolmogorov-Smirnov test for normality  which showed that the distributions for both scenarios were non-normal (smallest d\u2009=\u20090.24, p\u2009<\u20090.001). Accordingly, we converted points deducted for both scenarios into z-scores to correct for this severe level of non-normality. The two items measuring emotional valence were combined using a procedure analogous to PANAS scoring in which the negativity item was subtracted from the positivity item to create an index of net positive valence. Finally, the three items measuring overall, social, and economic political attitudes were averaged to form a composite index of political attitude (\u03b1\u2009=\u20090.80). A Kolmogorov-Smirnov test for normality revealed that the distribution for the composite political attitude variable was non-normal (d\u2009=\u20090.14, p\u2009<\u20090.05) so we applied the natural log transformation to it (new d\u2009=\u20090.11, p\u2009>\u20090.19.) \n\nAs predicted, a 2 (cheating scenarios 1\u20132)\u2009\u00d7\u20092 (hard vs. soft chair) repeated measures analysis of variance (ANOVA) on punishment harshness (operationalized as amount of points deducted) revealed a main effect of the chair hardness manipulation. Compared with participants in the soft chair condition, participants in the hard chair condition recommended deducting more points across both scenarios (F(1,42)\u2009=\u20094.74, p\u2009<\u20090.05, see Fig.\u00a0 ). Next, we tested whether sitting in a hard chair would, as in Experiment 1, produce the experience of more positive emotions compared to sitting in a soft chair. In Experiment 2, however, chair hardness did not influence emotional valence, t(45)\u2009=\u20090.45, p\u2009>\u20090.60.   \nRecommended punishment for scenarios involving academic cheating is shown as a function of chair condition (study 1, experiment 2). \n  \n\nChair hardness did have the predicted significant effect on political attitudes, t(44)\u2009=\u20092.15, p\u2009<\u20090.05, with participants in the hard chair reporting more conservative attitudes (M\u2009=\u20094.10, SD\u2009=\u20091.53) as compared to participants in the soft chair (M\u2009=\u20093.28, SD\u2009=\u20091.55). There was no influence of political attitudes on points deducted for either of the 2 scenarios (largest r\u2009=\u20090.07, p\u2009>\u20090.64), so a test of mediation by political attitudes of the effect of chair hardness on punishment was not justified. \n\n\n\n## Study 2 \n  \nStudy 2 aimed to examine the neural underpinnings of this \u2018hard on crime\u2019 effect. Since passive tactile stimulation using different chairs (or underlying mattresses) is difficult to manipulate inside an MRI, we changed the paradigm into a within-subjects design with active tactile stimulation. Participants were asked to read scenarios describing a series of different crimes while we scanned their brain activity with fMRI. After each scenario, participants had to rate what sentence they would give the delinquent. Prior to each scenario, the participants were primed with a hard or a soft object. We examined whether hard priming would cause the participants to be \u201chard\u201d on crime and if this effect would be based on activity in the sensorimotor cortices. \n\n\n## Materials and Methods \n  \n### Participants \n  \nSeventeen people (12 females) with a mean age of 24 years (standard deviation +\u22123.58, range 18\u201331) took part in the study. All participants were right-handed native German volunteers with no neurological or psychiatric history. The participants gave written informed consent to the study, which adhered to the Declaration of Helsinki and was approved by the ethical committee of the University of Magdeburg, Germany (ethical committee: 133/12, clinical trials: NCT02517060). \n\n\n### Procedure \n  \nParticipants were told that they would perform two separate experiments in the session: an experiment in order to examine neural correlates of touch experiences and an experiment to investigate neural correlates of judgments processes (cover story). \n\nThe study design included one factor, tactile priming, which was hard, soft, or omitted (no tactile stimulation). Priming was done by using soft (foam material) or hard (wood) objects (comparable weight, seize and shape). At the beginning of the priming phase an experimenter placed the hard or soft object to the participant\u2019s hand in a way that he or she was able to feel the object between his or her thumb and other fingers. The participant did not hold the object in his or her own hand. Hence, the participant was not able to see the objects, freely explore the object, feel the shape or the weight of the object, or swipe on the objects to assess the surfaces. He or she was only allowed (and clearly instructed before) to repetitively press and feel the hardness or softness of the objects by using thumb and residual fingers, while this object was hold by the experimenter. Prior to the beginning of the experiment we made the participant familiar with the task. \n\nWhile horizontally reclined in the scanner the participants received one of the priming stimuli (a hard, a soft, or no object). Participants were allowed to feel the hardness of those stimuli by repetitively touching them for about 15\u2009seconds. After this priming, participants were prompted with a screen describing a crime scenario. These scenarios covered crimes such as burglaries, criminal assaults, murderers, as well as cheating and drug offences. All scenarios were ambivalently valenced in order to prevent straightforward judgments. Thus, the scenarios included both positive (mitigating) and negative components. For example, participants read the following scenario: \u201cA twenty-year-old man drove his friends to a night club. Because he was intoxicated and the atmosphere in the car was distracting, he ran a red light, thereby causing a serious traffic accident. Later on, the young driver apologized for his actions when meeting the injured persons\u201d. The presentation of the scenario lasted for 16\u2009seconds. The subsequent screen asked the participants to give their judgment as to how seriously the protagonist should be punished (\u201cHow seriously should the young man be punished? More seriously: right buttons. Less seriously: left buttons\u201d). Participants used two keys with four buttons for each hand (8-point Likert-scale ranging from 1 to 8) to judge the crimes. Before the experiment, they were told that they could weight their responses from moderate (inner buttons) to extreme (outer buttons). Use of right and left buttons was randomized over the scenarios. Participants had 14\u2009seconds to give their judgment (earlier responding did not automatically start the next trial). Then there was a break of 12\u2009seconds until the next trial started. We used brain activity in a time window around the button press in order to assess comparable parts of the judgment process for all participants. Hence, condition-related activity was measured using an individual \u201cfloating\u201d time window of eight MR images (four images before, one during, and three after the button press, resulting in 16\u2009seconds) covering the time of the point of response . \n\nA total of 60 scenarios was shown to each participant. The order of presentation of the scenarios as well as the kind of priming for the scenarios (hard, soft, or no object) was randomized between and within the subjects. Prior to the beginning of the experiment we made the participants familiar with the task. \n\nVisual images were back-projected to a screen at the end of the scanner bed close to the subject\u2019s feet. Subjects viewed the scenarios through a mirror mounted on the birdcage of the receiving coil. Foam cushions were placed tightly around the sides of the subject\u2019s head to minimize head motion. The experiment consisted out of four runs, each lasting for about 14\u2009minutes. Each run included all conditions. Participants were allowed to take short breaks between the runs. \n\nAfter scanning, the participants were probed for suspicions concerning the experimental hypotheses (\u201cWhat do you think was the purpose of this study?\u201d, \u201cDo you have any ideas about the hypotheses of this study?\u201d). Finally, they were debriefed and thanked for participating. \n\n\n### FMRI Data Acquisition and Analysis \n  \nFunctional scans were acquired by using a 3T scanner (Siemens MAGNETOM Trio, Germany) (gradient echo T2-weighted echo-planar images; TR\u2009=\u20092\u2009sec, TE\u2009=\u200930\u2009ms, flip angle\u2009=\u200980 degrees, FOV\u2009=\u2009192\u2009mm). For each subject, data were acquired in four runs. In each session, 416 volumes were acquired. Functional volumes consisted of 32 slices. Each volume comprised 3.5\u2009mm slices (no gap, in plane voxel size 3.5\u2009\u00d7\u20093.5\u2009mm). For anatomical reference a high-resolution T1-weighted structural image was collected for anatomical reference (MPRAGE, TR\u2009=\u20091900 ms, TE\u2009=\u20092.5\u2009ms). \n\nFMRI data was preprocessed and analyzed using the Statistical Parametric Mapping Software (SPM, Wellcome Department of Imaging Neuroscience, University College London, London, UK). For each subject, the fMRI scans were realigned to correct for inter-scan movement, using sinc interpolation and subsequently normalized into a standard anatomical space (MNI, Montreal Neurological Institute template), resulting in isotropic 3\u2009mm voxels. The scans were then smoothed with a Gaussian kernel of 6\u2009mm full-width half maximum. \n\nWe then computed statistical parametric maps by using multiple regressions with the hemodynamic response function modeled in SPM. Data analyses were performed at two levels. First, we examined data on the individual subject level by using a fixed effects model. Second, the resulting parameter estimates for each regressor at each voxel were entered into a second-level analysis with the random effects model. \n\nTo examine brain responses while participants explored the stimuli, we computed statistical contrasts (t-tests) for hard stimuli relative to no stimulation (fixation cross) and soft stimuli relative to no stimulation. \n\nIn order to investigate brain activity during the judgment process, we examined the time window while the participants gave their recommendations for punishments. We computed an ANOVA for repeated measurements for the priming factor (soft, hard, none). Subsequently, statistical contrasts (t-tests) were performed to examine cortical activation during the judgment depending on the different priming conditions. Behavioral responses (judgment scores) were used to test for possible correlations (Pearson) with the parameter estimates for voxels in the sensorimotor regions of interest (maximum peaks in bilateral primary somatosensory cortex (SI)). \n\nWe report regions that survived correction for multiple comparisons over the whole brain (at p\u2009<\u20090.05, family-wise (FWE) correction). Furthermore, in order to test our hypothesis that the \u201chard on crime\u201d effect is grounded in sensorimotor activations, we report regions of interest that survived a small volume correction (SVC) of p\u2009<\u20090.05 (FWE corrected at the peak level) for which we had an a priori hypothesis. Thus, an SVC was applied to activations within a sphere of 15\u2009mm radius in the left and right SI. The coordinates of these SVCs resulted from the analysis of contrast of hard and soft stimulation relative to no stimulation during the exploration phase (peak activations in SI). \n\nAnatomical interpretation of the functional imaging results was performed using the SPM anatomy tool-box . \n\n\n\n## Results \n  \n### Behavioral results \n  \nNone of the participants reported any suspicions with respect to our experimental hypotheses. In particular, none of the participants guessed the relation between the tactile and the judgment tasks. All of them believed to have participated in two separate experiments. \n\nTwo participants were excluded prior to data analysis; one due to technical reasons (technical problem of behavioral data collection) and the other due to lack of behavioral responses after beginning (response device did not collect behavioral responses after the first minutes of the experiment). \n\nAnalysis of the behavioral results (ANOVA with factor priming: hard, soft, no) revealed a significant effect (F (2,28)\u2009=\u20093.73, p\u2009=\u20090.03). Post hoc t-tests showed that judgments of criminal severity were more serious after hard priming (4.77\u2009\u00b1\u20090.94, mean and standard deviation) compared with soft priming (4.36\u2009\u00b1\u20090.63; t(14)\u2009=\u20092.11, p\u2009=\u20090.02) and compared with no priming (4.39\u2009\u00b1\u20090.56; t(14)\u2009=\u20092.16, p\u2009=\u20090.02). Judgments after soft priming were not different compared with no priming (t(14)\u2009=\u20090.21, p\u2009>\u20090.10) (see Fig.\u00a0 ). Analysis of the reaction times revealed no significant effects.   \nParticipants\u2019 mean recommendation for sentences (+standard errors) after soft, hard, or no priming (scale from 1 to 8, with 8 for very hard sentences). Hard priming resulted in significantly harder punishment recommendations. \n  \n\n\n### FMRI results: Brain responses while exploring the tactile stimuli \n  \nBrain responses when actively exploring the priming stimuli (hard relative to rest and soft relative to rest) showed activation of sensorimotor brain areas (primary and secondary somatosensory cortices, primary motor cortex, premotor cortex) and other areas, p\u2009<\u20090.05, FWE corrected), as expected (see Fig.\u00a0 ).   \nStatistical maps showing brain activation while participants explored the hard and soft primes, respectively (relative to rest, FWE corrected). Areas of significant fMRI signal change are shown as color overlays on the T1-MNI reference brain. \n  \n\nComparing brain activations during hard relative to soft stimulation at the whole brain level revealed activation in bilateral sensorimotor cortex and other brain areas (p\u2009<\u20090.05, FWE corrected at the cluster level) and other brain areas (uncorrected). Brain responses while handling the soft object relative to handling the hard object failed to show any significant activation. \n\n\n### FMRI results: Brain responses while assessing crime scenarios \n  \nWe then examined brain areas of the participants that behaviorally already showed the \u201chard-on-crime\u201d effect in order to investigate the neural underpinnings of this effect. Thus, we examined brain responses while the participants were giving their recommendations of sentences after having read the scenarios. Analysis of brain activations revealed engagement of sensorimotor brain regions (SI, SII, BA6) and inferior frontal gyrus (ANOVA main effect, factor priming; hard, soft, no). Post hoc t-tests demonstrated that brain responses while participants recommended sentences after having explored the hard object compared with being primed with the soft object involved activation in SI (at p\u2009<\u20090.05, FWE corrected, see Table\u00a0  and Fig.\u00a0 ). No other brain areas were activated (even at an uncorrected threshold, see Table\u00a0 ). Brain responses during judging when being primed with the hard object compared with no priming at all showed again activation in SI, but only at an uncorrected threshold (see Table\u00a0 ). Furthermore, premotor cortices, secondary somatosensory cortices, and inferior frontal cortex were engaged (at an uncorrected threshold, see Table\u00a0 ). The contrasts of brain responses during judging for soft priming relative to hard priming and for soft priming relative to no priming failed to show any significant voxels (at p\u2009<\u20090.05, FWE corrected).   \nResults of random effects analysis for brain responses when recommending sentences depending on different priming conditions (p\u2009<\u20090.05, FWE corrected, L\u2009=\u2009left hemisphere, R\u2009=\u2009right hemisphere; in brackets: uncorrected results). See text for further details. \n    \nStatistical maps showing brain activation while participants recommended sentences (whole brain analysis). Hard relative to soft priming revealed brain activation in somatosensory cortex (no other brain areas activated, see Table\u00a0 ). Soft relative to hard priming revealed no significant activation (see Table\u00a0 ). \n  \n\nIn order to further test our hypotheses we then computed correlations of the strength of the neural activation in somatosensory cortices and the behavioral responses of all participants. Thus, we calculated correlations between the strength of the hard on crime effect (behavioral data: judgment scores after hard priming minus judgment scores after soft priming) with signal changes in somatosensory peak areas for the contrast rating after hard priming relative to rating after soft priming. Results revealed a significant correlation of the strength of the \u201chard on crime\u201d effect with signal change in SI (r\u2009=\u20090.57, p\u2009<\u20090.05, Pearson, see Fig.\u00a0 ). For the comparison between judging after hard priming relative to judging after no priming, signal changes in SI were also significant positively linked to the strength of the hard on crime effect (r\u2009=\u20090.48, p\u2009<\u20090.05, Pearson). Thus, the more the participants were affected by the \u2018hard on crime\u2019 effect, the more their somatosensory cortices were engaged in the later judgment phase. Thereby, the data suggests that the observed SI activation is linked to the \u2018hard on crime\u2019 effect. Other areas did not show any significant correlations with the \u2018hard on crime\u2019 effect.   \nBrain activation in somatosensory cortex after hard priming could significantly predict the strengths of the hard on crime effect (peak activations in SI, x\u2009=\u200944, y\u2009=\u2009\u221240, z\u2009=\u200966 and \u2013x\u2009=\u2009\u221224, \u2212y\u2009=\u2009\u221226, z\u2009=\u200950). See text for further details. \n  \n\nIn order to test if even punishment judgments without any priming may correlate with sensorimotor activations, we contrasted brain responses while participants were giving their recommendations of sentences without any priming with activation during baseline. Results revealed neural activations in occipital and posterior parietal lobe, sensorimotor brain regions and frontal lobe. However, given that we here compared brain activation during reading, judging, and pressing a button with a baseline condition, we cannot draw strong conclusions out of this comparison. A correlation between neural responses in sensorimotor cortex and behavioral responses (punishment ratings) revealed no significant correlation. \n\n\n\n## Discussion \n  \nPeople are often judging the behaviors of others in a legal capacity, for example as a judge or member of a jury. While we assume that these processes are fair and consider only legal aspects of the relevant situations, we know that in real life there are numerous situations in which so called extralegal factors are relevant. Here we aimed to experimentally investigate the influence of incidentally and briefly explored hard and soft objects on subsequent judgments of the severity of crimes. Results of a behavioral study demonstrated that sitting in hard chairs make people harder on crime. These results are confirmed by an fMRI study, showing that experiencing \u201chard\u201d vs. \u201csoft\u201d objects before judging the severity of crimes leads to \u201charsher\u201d judgments (compared to soft priming or no priming). Thus, \u201chard\u201d priming makes us harder on crime. In contrast, \u201csoft\u201d (vs. no) priming did not induce any significant effects. FMRI results revealed that this \u201chard on crime\u201d effect was based on the primary somatosensory cortex. \n\n### The psychological concept of hardness \n  \nOur results are in line with other studies, which found evidence that haptic sensations can prime later assessments, attitudes, or behavior. For example, Ackerman   et al  . (2010) reported that negotiators sitting in hard chairs did not compromise as much as did those sitting in soft chairs. Similarly, they also found that participants primed with handling a hard object subsequently judged an employee to be more rigid or strict (in contrast to priming with a soft piece of blanket). Thus, both active as well as passive haptic sensations of hardness affected later social assessment tasks. These physical-to-psychological priming effects are in line with the \u201chardness\u201d metaphor, which associates physical \u201chardness\u201d with terms or metaphors such as \u201chard-hearted\u201d, \u201chard times\u201d, or \u201chard on crime\u201d. Notably, Ackerman   et al  . found an effect on rigidity of the employee, but no general positive (or negative) effects on the ratings. This is in line with the conceptual metaphor theory that claims that metaphors are more than mere abstract linguistic figures. According to Lakoff and Johnson metaphors influence our thoughts, feelings, intentions and behavior in an unconscious but often deep way . Our results support this theory and show that priming the participants with an active experience of a hard object made them harder on crime relative to soft priming or no priming at all. This is demonstrated by behavioral results, showing that the experience of hard objects (sitting in a hard chair) made participants harder on crime, but did not make the participant generally feel more negatively. Hence, \u201chardness\u201d had an effect on judgments of criminal severity, thus documenting an extralegal factor in judgment processes. \n\nInterestingly, we did not find any effects of soft priming vs. no priming on later judgment processes, either for the behavioral data (study 2) nor for the imaging data. One could speculate that softness may not be similarly embodied as hardness. Another possibility is that the negative pole of dimensions has stronger and more easily detectable influence than the positive pole, assuming soft is more positive than hard. For example, in their demonstration of the similarity of physical and social (betrayal in economic game) temperature effects, Kang   et al  . found greater activation of the bilateral insular-opercular cortex caused by cold sensations compared to neutral temperature but no difference in activation levels between the warm and neutral conditions . This is in line with the general finding that \u2018bad is stronger than good\u2019 in their influences on social judgment . It also might be that in our study the soft stimuli were not sufficiently soft to elicit an effect. Further studies are needed in order to replicate this \u2018hard-but-not-soft\u2019 finding. \n\n\n### Neural basis of the \u2018hard on crime\u2019 effect \n  \nOur study also revealed the neural underpinnings of \u201chard on crime\u201d effect. The theory of embodied cognition makes clear assumptions of an interaction between body and mind . Neuroimaging tools provide excellent access in order to test these assumptions. Several studies support the embodiment theory by proving the assumption that motor and in particular somatosensory cortices are crucial neural correlates of embodied cognitions. For example, it has been shown that comprehending textural metaphors activated the somatosensory cortex . Moreover, several studies reported sensorimotor activation during language comprehension in the action domain, thereby suggesting sensorimotor circuits as a cortical basis for language . Furthermore, it has been demonstrated that the moral-purity metaphor  is associated with activations in sensorimotor brain regions . In addition, the roughness metaphor (rough stimuli prime subsequent interactions to become an argument rather than a discussion) activated particularly sensorimotor brain areas . Our results are in line with these reports. The \u201chard on crime\u201d effect was predicted by the activation of the somatosensory cortex: the more the somatosensory cortex was engaged, the stronger the effect. We therefore conclude that these results support the embodiment theory . \n\nThe current experiment focused on punishment judgments depending on different tactile priming stimuli. While we report effects of this priming on punishment judgments, it would be very interesting to test if also other measures were affected by the haptic priming. For example, the priming might had have a general impact on mood or generic positive (or negative) thinking. However, the present study did not include control questions due to time reasons (in order to maximize signal strength in the fMRI). Nevertheless, we think that it is unlikely that the priming might had have a general effect on mood or positive feelings, because the sensorimotor cortex, which we show to be associated with the \u201chard on crime\u201d effect, is not known to be related to feelings such as positive moods. Moreover, results of our pre-study investigated two possible mediators of the influence of hardness on punishment harshness: emotional valence and political attitude. Although we did not find mediation of the effect on punishment by either variable, or consistent results for the influence of hardness on emotional valence, we did find that participants seated in hard chairs consistently reported more conservative (versus liberal) attitudes, compared to participants seated in soft chairs. This finding contributes to a growing body of work suggesting that political attitudes may be more malleable than previously thought (e.g. ). This finding is also in line with previous research documenting the influence of tactile primes on social attitudes . \n\nWe here argued that the retrieval of conceptual meaning involves a partial re-enactment of sensory and motor experiences. Based on this assumption we aimed to demonstrate that tactile priming would in particular enhance this engagement of sensorimotor brain regions. However, according to our theoretical considerations we also assume that even without priming hard punishment judgments should be associated with activations of sensorimotor brain regions . The present study did not find a significant correlation between sensorimotor activation and judgments without any priming. This may be explained by weaker activations in sensorimotor activations when not being primed with hard haptic experiences. Nevertheless, the present experimental design is less suited to examine sensorimotor activation without any tactile priming. Future studies are needed to assess this hypothesis. \n\n\n### The role of neuroscience in research on embodied cognition \n  \nWhy is a neuroscientific approach important for the debate of the theory of embodied cognition? What do we gain by this perspective? Neuroscientific evidence provides us with information on the neural underpinnings of behavioral effects. This seems particularly important within the perspective of embodied cognition. For example, in the traditional understanding knowledge is represented abstractly in an amodal or supramodal conceptual network of formal logic symbols . The theory of embodied cognition challenges this view and claims that cognitive representations that constitute our knowledge are grounded in sensory and motor experiences . Neuroscientific approaches seem to be an excellent tool to test this hypothesis of a sensorimotor grounding. Thus, the present results demonstrate that even highly abstract thinking (punishment judgments related to crimes) is accompanied by activations of somatosensory brain areas. In contrast, the traditional understanding would have hypothesized that abstract cognitions are based on frontal brain areas, regions not known to be related with basic sensorimotor processing and perception. Furthermore, data from brain imaging may also add a new level of data to theoretical considerations that primarily are based on behavioral data. Thereby, neuroimaging data also allow us to link the embodiment theory to other neuroscientific theories. For example, the present results report predominantly activation in primary somatosensory cortices. These brain areas are also described as being related to mirror neurons and empathic personality traits . Those cross-references may help us to further understand how brain and behavior are related. Last, neuroscientific evidence also opens the way to further establish the assumptions of the theory of embodied cognitions. For example, if sensorimotor brain areas are essential for abstract thinking, the temporary blocking of these brain areas (so-called virtual lesions) by using the transcranial magnetic stimulation (TMS) approach should prevent the effects we reported here and also diminish abstract thinking in general. Thus, given that several fMRI approaches stressed the role of sensorimotor brain areas for embodied cognition , TMS could provide complementary results. \n\n\n### Conclusions: Implications \n  \nPrevious research has shown that hypothetical sentencing scenarios can be generalizable to real-world scenarios . Based on the results of Ackerman   et al  . and the present study, we suggest that incidental haptic experiences such as hardness of objects or even furniture (chairs) may influence judgments rendered in actual courtrooms. Future studies should examine the extent of this effect on punishment severity, for example with respect to the duration of the effect (do the effects of sitting in a hard chair immediately disappear upon standing up?). Furthermore, our study consisted of average lay people, not experienced judges and jurists. It remains to explore whether persons who are trained to judge situations according to certain guidelines are also prone to this \u201chard on crime\u201d effect. However, there seem to be numerous real world examples documenting that even very experienced judges are not completely immune to extralegal factors (e.g., the field studies in California courtrooms by Konecni and Ebbesen) , which suggests that even highly trained individuals may be susceptible to such effects. \n\n\n \n\n# Table(s)\n## ID: Tab1\n### Label: Table 1\nContrast\tBrain region\tPeak MNI location (x, y, z)\tPeak z-value\tNumber of voxels\nhard\u2009>\u2009soft priming\tR SI(R SI)(L SI)\t44 \u221240 6660 \u221232 54\u221258 \u221238 52\t3.802.942.88\t321216\nsoft\u2009>\u2009hard priming\t\u2014\t\u2014\t\u2014\t\u2014\nhard\u2009>\u2009no priming\t(L SI)(L BA6)(R BA6)(R SII/Insula)(L SII/Insula)(R inf. frontal gyrus/BA44)(L temporal gyrus)(L middle frontal gyrus/BA45)\t\u221224 \u221226 50\u221232 \u22124 3822 \u221216 5840 \u221212 2\u221228 8 1662 12 6\u221256 \u221210 2\u221224 \u221228 56\t3.503.703.393.463.283.353.343.15\t19812317667\nno\u2009>\u2009hard priming\t\u2014\t\u2014\t\u2014\t\u2014\nsoft\u2009>\u2009no priming\t(L inf. frontal gyrus/BA44)\t\u221240 8 14\t3.33\t10\nno\u2009>\u2009soft priming\t\u2014\t\u2014\t\u2014\t\u2014\n### Caption\nResults of random effects analysis for brain responses when recommending sentences depending on different priming conditions (p\u2009<\u20090.05, FWE corrected, L\u2009=\u2009left hemisphere, R\u2009=\u2009right hemisphere; in brackets: uncorrected results). See text for further details.\n### Footer\nNone\n", "metadata": {"pmcid": 5902547, "text_md5": "b82ba6486194921ffae1820e9ff435bd", "field_positions": {"authors": [0, 173], "journal": [174, 181], "publication_year": [183, 187], "title": [198, 255], "keywords": [269, 269], "abstract": [282, 1655], "body": [1664, 41615], "tables": [41628, 42511]}, "batch": 2, "pmid": 29662068, "doi": "10.1038/s41598-018-23586-x", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5902547", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5902547"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5902547\">5902547</a>", "list_title": "PMC5902547  Incidental haptic sensations influence judgment of crimes"}
{"text": "Martin, Chris B and Douglas, Danielle and Newsome, Rachel N and Man, Louisa LY and Barense, Morgan D\neLife, 2018\n\n# Title\n\nIntegrative and distinctive coding of visual and conceptual object features in the ventral visual stream\n\n# Keywords\n\nsemantic memory\nvisual cognition\nintegration\nfMRI\nperirhinal cortex\nventral visual stream\nHuman\n\n\n# Abstract\n \nA significant body of research in cognitive neuroscience is aimed at understanding how object concepts are represented in the human brain. However, it remains unknown whether and where the visual and abstract conceptual features that define an object concept are integrated. We addressed this issue by comparing the neural pattern similarities among object-evoked fMRI responses with behavior-based models that independently captured the visual and conceptual similarities among these stimuli. Our results revealed evidence for distinctive coding of visual features in lateral occipital cortex, and conceptual features in the temporal pole and parahippocampal cortex. By contrast, we found evidence for integrative coding of visual and conceptual object features in perirhinal cortex. The neuroanatomical specificity of this effect was highlighted by results from a searchlight analysis. Taken together, our findings suggest that perirhinal cortex uniquely supports the representation of fully specified object concepts through the integration of their visual and conceptual features. \n   eLife digest  \nOur ability to interact with the world depends in large part on our understanding of objects. But objects that look similar, such as a hairdryer and a gun, may do different things, while objects that look different, such as tape and glue, may have similar roles. The fact that we can effortlessly distinguish between such objects suggests that the brain combines information about an object\u2019s visual and abstract properties. \n\nNevertheless, brain imaging experiments show that thinking about what an object looks like activates different brain regions to thinking about abstract knowledge. For example, thinking about an object\u2019s appearance activates areas that support vision, whereas thinking about how to use that object activates regions that control movement. So how does the brain combine these different kinds of information? \n\nMartin et al. asked healthy volunteers to answer questions about objects while lying inside a brain scanner. Questions about appearance (such as \u201cis a hairdryer angular?\u201d) activated different regions of the brain to questions about abstract knowledge (\u201cis a hairdryer manmade?\u201d). But both types of question also activated a region of the brain called the perirhinal cortex. When volunteers responded to either type of question, the activity in their perirhinal cortex signaled both the physical appearance of the object as well as its abstract properties, even though both types of information were not necessary for the task. This suggests that information in the perirhinal cortex reflects combinations of multiple features of objects. \n\nThese findings provide insights into a neurodegenerative disorder called semantic dementia. Patients with semantic dementia lose their general knowledge about the world. This leads to difficulties interacting with everyday objects. Patients may try to use a fork to comb their hair, for example. Notably, the perirhinal cortex is a brain region that is usually damaged in semantic dementia. Loss of combined information about the visual and abstract properties of objects may lie at the core of the observed impairments. \n \n\n# Body\n \n## Introduction \n  \nSemantic memory imbues the world with meaning and shapes our understanding of the relationships among object concepts. Many neurocognitive models of semantic memory incorporate the notion that object concepts are represented in a feature-based manner ( ;  ;  ). On this view, our understanding of the concept \u2018hairdryer\u2019 is thought to reflect knowledge of observable perceptual properties (e.g. visual form) and abstract conceptual features (e.g. \u2018  used to style hair  \u2019). Importantly, there is not always a one-to-one correspondence between how something looks and what it is; a hairdryer and a comb are conceptually similar despite being visually distinct, whereas a hairdryer and a gun are conceptually distinct despite being visually similar. Thus, a fully-specified representation of an object concept (i.e. one that can be distinguished from any and all other concepts), requires integration of its perceptual and conceptual features. \n\nNeuroimaging research suggests that object features are coded in the modality-specific cortical regions that supported their processing at the time of acquisition ( ). For example, knowledge about the visual form of an object concept is thought to be coded in occipito-temporal visual processing regions ( ). However, neurocognitive models of semantic memory differ with respect to how distributed feature representations relate to fully\u00a0specified object concepts. On one view, these representations are thought to emerge through interactions among modality-specific cortical areas ( ;  ). Within a competing class of theories, they are thought to reflect the integration of modality-specific features in trans-modal convergence zones ( ;  ;  ), such as the anterior temporal lobes (ATL) ( ;  ;  ). \n\nThe dominant view of the ATL as a semantic hub was initially shaped by neuropsychological investigations in individuals with semantic dementia (SD) ( ). Behaviorally, SD is characterized by the progressive loss of conceptual knowledge across all receptive and expressive modalities ( ;  ). At the level of neuropathology, SD is associated with extensive atrophy of the ATL, with the earliest and most pronounced volume loss in the left temporal pole ( ;  ). Most important from a theoretical perspective, patients with SD tend to confuse conceptually similar objects that are visually distinct (e.g. hairdryer \u2013 comb), but not visually similar objects that are conceptually distinct (e.g., hairdryer \u2013 gun), indicating that the temporal pole expresses conceptual similarity structure ( ; see  ;  , for related neuroimaging evidence). Taken together, these findings suggest that the temporal pole supports multi-modal integration of abstract conceptual, but not perceptual, features. Notably, however, a considerable body of research indicates that the temporal pole may not be the only ATL structure that supports feature-based integration. \n\nThe representational-hierarchical model of object coding emphasizes a role for perirhinal cortex (PRC), located in the medial ATL, in feature integration that is distinct from that of the temporal pole ( ). Namely, within this framework PRC is thought to support the integration of conceptual   and   perceptual features. In line with this view, object representations in PRC have been described in terms of conceptual feature conjunctions in studies of semantic memory ( ;  ;  ;  ;  ), and visual feature conjunctions in studies of visual processing ( ;  ;  ;  ;  ;  ;  ;  ). However, it is difficult to synthesize results from these parallel lines of research, in part, because conceptual and perceptual features tend to vary concomitantly across stimuli ( ). For example, demonstrating that \u2018horse\u2019 and \u2018donkey\u2019 are represented with greater neural pattern similarity in PRC than are \u2018horse\u2019 and \u2018dolphin\u2019 may reflect differences in conceptual or perceptual relatedness. Thus, although the representational-hierarchical account was initially formalized nearly two decades ago ( ), direct evidence of integration across conceptual and perceptual features remains elusive. \n\nIn the current study, we used fMRI to identify where in the brain visual and conceptual object features are stored, and to determine whether and where they are integrated at the level of fully\u00a0specified object representations. To this end, we first generated behavior-based models that captured the visual and conceptual similarities among a set of object concepts, ensuring that these dimensions were not confounded across stimuli ( ). Next, participants were scanned using task contexts that biased attention to either the conceptual or visual features of these well-characterized object concepts ( ). We then used representational similarity analysis (RSA) ( ), implemented using ROI- and searchlight-based approaches, to determine where the brain-based similarity structure among object-evoked multi-voxel activity patterns could be predicted by the similarity structure in the behavior-based visual and conceptual similarity models. \n   Behavior-based RDMs.  \n(  A  ) Visual similarity rating task (top) and corresponding 40 \u00d7 40 behavior-based visual RDM (bottom). (  B  ) Conceptual feature generation task (top), abridged feature matrix depicting the feature frequencies across participants for each concept (middle), and corresponding 40 \u00d7 40 behavior-based conceptual RDM (bottom). The dashed horizontal arrow between behavior-based RDMs denotes a second-level RSA that compared these similarity models with one another. All object concepts are listed in   - Object concepts and targeted pairs. Behavior-based RDMs (together with the word2vec RDM) are contained in   - Behavior-based RDMs and word2vec RDM. \n\n\n\n\n     Brain-based RDMs.  \n(  A  ) Example of object-evoked neural activity patterns obtained across all eight probes in the visual task context (top), mean object-specific activity patterns averaged across repetitions (middle), and corresponding 40 \u00d7 40 brain-based visual task RDM derived from a first-level RSA (bottom). (  B  ) Example of object-evoked neural activity patterns obtained across all eight probes in the conceptual task context (top), mean object-specific activity patterns averaged across repetitions (middle), and corresponding 40 \u00d7 40 brain-based conceptual task RDM derived from a first-level RSA (bottom). \n  \nWe predicted that lateral occipital cortex (LOC), an occipito-temporal region that has been implicated in the processing of visual form ( ;  ;  ), would represent stored visual object features in a visual similarity code. Based on the neurocognitive models of semantic memory reviewed, we predicted that the temporal pole would represent stored conceptual object features in a conceptual similarity code ( ;  ). We also predicted conceptual similarity coding in parahippocampal cortex, which has been linked to the representation of the contextually-based co-occurrence of objects ( ;  ). Critically, objects that are regularly encountered in the same context (e.g. \u2018comb\u2019 and \u2018hairdryer\u2019 in a barbershop) often share many conceptual features (e.g. \u2018  used to style hair  \u2019). Thus, to the extent that shared conceptual features directly shape contextual meaning, object-evoked responses in parahippocampal cortex may express conceptual similarity structure. Returning to the primary objective of the study, we predicted that PRC would uniquely represent the visual and conceptual features that define fully-specified object concepts in an integrated similarity code. \n\n\n## Results \n  \n### Behavior-based similarity models \n  \nUsing a data-driven approach, we first generated behavior-based models that captured the visual and conceptual similarities among 40 targeted object concepts ( ). Notably, our visual similarity model and conceptual similarity model were derived from behavioral judgments provided by two independent groups of participants. For the purpose of constructing the visual similarity model, the first group of participants (N\u00a0=\u00a01185) provided pairwise comparative similarity judgments between object concepts ( ). Specifically, a pair of words was presented on each trial and participants were asked to rate the visual similarity between the object concepts to which they referred using a 5-point Likert scale. Similarity ratings for each pair of object concepts were averaged across participants, normalized, and expressed within a representational dissimilarity matrix (RDM). We refer to this RDM as the   behavior-based visual RDM  . \n\nFor the purpose of constructing the conceptual similarity model, a second group of participants (N\u00a0=\u00a01600) completed an online feature-generation task ( ;  ) ( ). Each participant was asked to generate a list of conceptual features that characterize one object concept (e.g. hairdryer:   \u2018used to style hair\u2019, \u2018found in salons\u2019, \u2018electrically powered\u2019, \u2018blows hot air\u2019  ; comb:   \u2018used to style hair\u2019, \u2018found in salons\u2019, \u2018has teeth\u2019, \u2018made of plastic\u2019  ). Conceptual similarity between all pairs of object concepts was quantified as the cosine angle between the corresponding pairs of feature vectors. With this approach, high cosine similarity between object concepts reflects high conceptual similarity. Cosine similarity values were then expressed within an RDM, which we refer to as the   behavior-based conceptual RDM  . \n\nWe next performed a second-level RSA to quantify the relationship between our behavior-based visual RDM and behavior-based conceptual RDM. This comparison is denoted by the gray arrow between behavior-based RDMs in  . Critically, this analysis revealed that the model RDMs were not significantly correlated with one another (Kendall\u2019s tau-a\u00a0=\u00a00.01, p=0.10), indicating that differences in visual and conceptual features were not confounded across object concepts. In other words, ensuring that these different types of features varied independently across stimuli (e.g. hairdryer \u2013 gun; hairdryer \u2013 comb), rather than concomitantly (e.g. horse \u2013 donkey; horse \u2013 dolphin), allowed us to isolate the separate influence of visual and conceptual features on the representational structure of object concepts in the brain. In this example, a hairdryer and a gun are visually similar but conceptually dissimilar, whereas a hairdryer and a comb are visually dissimilar but conceptually similar. \n\n\n### Comparison of behavior-based RDMs with a corpus-based (word2vec) semantic RDM \n  \nWe next sought to compare our behavior-based RDMs with a corpus-based model of conceptual similarity. To this end, we implemented a word2vec language model, which mapped 3 million words to 300 feature vectors in a high-dimensional space ( ). The model was trained using\u00a0~100 billion words from a Google News dataset. From this model, we calculated the cosine similarity between feature vectors for all pairs of words in our stimulus set. These data were expressed in a 40 \u00d7 40 word2vec RDM (  contains the word2vec RDM). Importantly, the word2vec RDM was significantly correlated with our behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.11, SE\u00a0=\u00a00.0141, p<0.00001), suggesting that both models captured the conceptual similarity structure among the object concepts. However, the word2vec RDM was also significantly correlated with our behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.04, SE\u00a0=\u00a00.0130, p<0.001). This result suggests that, in line with our objectives, the behavior-based conceptual RDM captured semantic similarity selectively defined as conceptual object features, whereas the word2vec RDM may have captured a broader definition of semantic similarity, that\u00a0is, one that includes both visual semantics and abstract conceptual features. Consistent with this view, gun and hairdryer were conceptually unrelated in our behavior-based conceptual RDM (cosine\u00a0=\u00a00), whereas the word2vec RDM suggested modest conceptual similarity (cosine\u00a0=\u00a00.16). Although this difference is likely determined by multiple factors, it is important to note that gun and hairdryer had a relatively high visual similarity index in our behaviour-based visual RDM (normalized mean rating\u00a0=\u00a00.58). These data highlight a theoretically important distinction between our behaviorally\u00a0derived conceptual feature-based statistics and corpus-based estimates of semantic similarity. Specifically, the former allow for distinctions between visual and conceptual object features, whereas corpus-based models may not. \n\n\n### fMRI task and behavioral results \n  \nWe used fMRI to estimate the representational structure of our 40 object concepts from neural activity patterns in an independent group of participants ( ). Given our specific interest in understanding pre-existing representations of object concepts rather than bottom-up perceptual processing, all stimuli were presented as words. This approach ensured that conceptual and visual features were extracted from pre-existing representations of object concepts. That is to say, both conceptual and visual features were arbitrarily related to the physical input (i.e. the orthography of the word). By contrast, when pictures are used as stimuli, visual features are accessible from the pictorial cue, whereas conceptual features require abstraction from the cue. Functional brain data were acquired over eight experimental runs, each of which consisted of two blocks of stimulus presentation. All 40 object concepts were presented sequentially within each block, for a total of 16 repetitions per concept. On each trial, participants were asked to make a \u2018yes/no\u2019 property verification judgment in relation to a block-specific verification probe. Half of the blocks were associated with verification probes that encouraged processing of visual features (e.g. \u2018is the object angular?\u201d), and the other half were associated with verification probes that encouraged processing of conceptual features (e.g. \u2018is the object a tool?\u201d). Each run consisted of one visual feature verification block and one conceptual feature verification block, with order counterbalanced across runs. With this experimental design, we were able to characterize neural responses to object concepts across two task contexts: a visual task context ( ) and a conceptual task context ( ). \n\nBehavioral performance on the scanned property verification task indicated that participants interpreted the object concepts and property verification probes with a high degree of consistency ( ). Specifically, all participants (i.e. 16/16) provided the same yes/no response to the property verification task on 88.4% of all trials. Agreement was highest for the \u2018living\u2019 verification probe (96.8%) and lowest for the \u2018non-tool\u2019 verification probe (73.2%). Moreover, the proportion of trials on which all participants provided the same response did not differ between the visual feature verification task context (mean\u00a0=\u00a087.3% collapsed across all eight visual probes) and the conceptual feature verification task context (mean\u00a0=\u00a089.5% collapsed across all eight conceptual probes) (  z  \u00a0=\u00a00.19, p=0.85). Response latencies were also comparable across the visual feature verification task context (mean\u00a0=\u00a01361 ms, SD\u00a0=\u00a0303) and the conceptual feature verification task context (mean\u00a0=\u00a01376 ms, SD\u00a0=\u00a0315) (  t   (15)=1.00, p=0.33, 95% CI [\u221249.09, 17.71). \n   fMRI feature verification task performance.  \nPercentage of trials on which all participants (i.e. 16/16) provided the same \u2018yes/no\u2019 response for each property verification probe. \n  \n\n### ROI-based RSA: comparison of behavior-based RDMs with brain-based RDMs \n  \nWe next quantified pairwise similarities between object-evoked multi-voxel activity patterns using a first-level RSA ( ). For the purpose of conducting ROI-based RSA, we focused on multi-voxel activity patterns obtained in PRC, the temporal pole, parahippocampal cortex, and LOC. ROIs from a representative participant are presented in  . These ROIs were selected a priori based on empirical evidence linking their respective functional characteristics to visual object processing, conceptual object processing, or both. Our primary focus was on PRC, which has been linked to integrative coding of visual object features and conceptual object features across parallel lines of research ( ;  ;  ;  ;  ;  ;  ;  ;  ;  ). The temporal pole has primarily been linked to processing of conceptual object properties ( ;  ;  ;  ;  ;  ;  ). Parahippocampal cortex has been implicated in the conceptual processing of contextual associations, including representing the co-occurrence of objects, although its functional contributions remain less well defined than the temporal pole ( ;  ;  ). Lastly, LOC, which is a functionally defined region in occipito-temporal cortex, has been revealed to play a critical role in processing visual form ( ;  ;  ). Because we did not have any a priori predictions regarding hemispheric differences, estimates of neural pattern similarities between object concepts were derived from multi-voxel activity collapsed across ROIs in the left and right hemisphere. \n   ROIs in a representative participant.  \nCortical regions examined in the ROI-based RSAs, including lateral occipital cortex (green), parahippocampal cortex (pink), perirhinal cortex (purple), and the temporal pole (cyan). \n  \nObject-specific multi-voxel activity patterns were estimated in each run using general linear models fit to data from the visual and conceptual task contexts, separately. Mean object-specific responses were then calculated for each task context by averaging across runs. Linear correlation distances (Pearson\u2019s r) were calculated between all pairs of object-specific multi-voxel activity patterns within each task context and expressed in participant-specific   brain-based visual task RDMs   and   brain-based conceptual task RDMs  . The brain-based visual task RDMs captured the neural pattern similarities obtained between all object concepts in the visual task context (i.e. while participants made visual feature verification judgments) ( ), and the brain-based conceptual task RDMs captured the neural pattern similarities obtained between all object concepts in the conceptual task context (i.e. while participants made conceptual feature verification judgments) ( ). \n\nWe implemented second-level RSA to compare behavior-based visual and conceptual RDMs with the brain-based visual and conceptual task RDMs (these comparisons are denoted by the solid vertical and diagonal arrows in  ). All RDMs were compared in each ROI using a ranked correlation coefficient (Kendall\u2019s tau-a) as a similarity index ( ). Inferential statistical analyses were performed using a one-sided Wilcoxon signed-rank test, with participants as a random factor. A Bonferroni correction was applied to adjust for multiple comparisons (4 ROIs x 2 behavior-based RDMs x 2 brain-based RDMs\u00a0=\u00a016 comparisons, yielding a critical alpha of. 003). With this approach, we revealed that object concepts are represented in three distinct similarity codes that differed across ROIs: a visual similarity code, a conceptual similarity code, and an integrative code. Results from our ROI-based RSA analyses are shown in   and discussed in turn below. \n   Second-level RSAs.  \nSolid vertical and diagonal arrows reflect second-level RSA in which behavior-based RDMs were compared with brain-based RDMs (ROI-based results in  , searchlight-based results in  ,   and  ). The dashed horizontal arrow between brain-based RDMs reflects second-level RSA in which neural pattern similarities from each task context were directly compared with each other (results in  ). \n     Comparison of behavior-based and brain-based RDMs.  \n S  imilarities between behavior-based and brain-based RDMs are plotted for (  A  ) LOC, (  B  ) parahippocampal cortex, (  C  ) PRC, and (  D  ) the temporal pole. These comparisons are denoted by the solid vertical and diagonal arrows in  . Similarity was quantified as the ranked correlation coefficient (Kendall\u2019s tau-a) between behavior-based RDMs and the brain-based RDMs. Error bars indicate standard error of the mean. ***p<0.001, **p<0.01, *p<0.05 (Bonferroni corrected). Participant-specific Kendall\u2019s tau-a co-efficients are contained in   - Comparison of similarity models and brain-based RDMs. \n\n\n \n   Comparison of word2vec RDM with brain-based RDMs.  \n S  imilarities between the word2vec RDM and brain-based RDMs are plotted for (  A  ) LOC, (  B  ) parahippocampal cortex, (  C  ) PRC, and (  D  ) the temporal pole. Similarity was quantified as the ranked correlation coefficient (Kendall\u2019s tau-a) between behavior-based RDMs and the brain-based RDMs. Error bars indicate standard error of the mean. **p<0.01, *p<0.05 (Bonferroni corrected). Participant-specific Kendall\u2019s tau-a co-efficients are contained in   - Comparison of similarity models and brain-based RDMs. \n  \n \n\n### Lateral occipital cortex represents object concepts in a task-dependent visual similarity code \n  \nConsistent with its well-established role in the processing of visual form, patterns of activity within LOC reflected the visual similarity of the object concepts ( ). Specifically, the brain-based visual task RDMs obtained across participants in LOC were significantly correlated with the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.045, p<0.002), but not the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a0\u22120.006, p=0.72). In other words, activity patterns in LOC expressed a visual similarity structure when participants were asked to make explicit judgments about the visual features that characterized object concepts (e.g. whether an object is angular in form). By contrast, the brain-based conceptual task RDMs obtained across participants in LOC were not significantly correlated with either the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.006, p=0.13) or the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.003, p=0.65). That is to say, activity patterns in LOC expressed neither visual nor conceptual similarity structure when participants made judgments that pertained to conceptual object features (e.g. whether an object is naturally occurring). Considered together, these results suggest that LOC represented perceptual information about object concepts in a task-dependent visual similarity code. Specifically, when task demands biased attention toward visual features, signals in LOC generalized across visually related object concepts even when they are conceptually distinct (e.g. hairdryer \u2013 gun). \n\n\n### Parahippocampal cortex represents object concepts in a task-dependent conceptual similarity code \n  \nPatterns of activity obtained in parahippocampal cortex, which has previously been associated with the processing of semantically-based contextual associations ( ;  ), reflected the conceptual similarity of the object concepts ( ). First, the brain-based visual task RDMs obtained across participants in parahippocampal cortex were not significantly correlated with either the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.005, p=0.26) or the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.009, p=0.26). In other words, activity patterns in parahippocampal cortex expressed neither visual nor conceptual similarity structure when participants made judgments that pertained to conceptual object features (e.g. whether an object is symmetrical). Second, the brain-based conceptual task RDMs obtained across participants in parahippocampal cortex were not significantly related to the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a0\u22120.008, p=0.55), but they were correlated with the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.046, p<0.002). Thus, activity patterns in parahippocampal cortex expressed a conceptual similarity structure when participants were asked to make explicit judgments about the conceptual features that characterized object concepts (e.g. whether an object is a tool). Put another way, conceptual information was represented in parahippocampal cortex in a task-dependent manner that generalized across conceptually related object concepts even when they were visually distinct (e.g. hairdryer \u2013 comb). \n\n\n### The temporal pole represents object concepts in a task-invariant conceptual similarity code \n  \nIn line with theoretical frameworks that have characterized the temporal pole as a semantic hub ( ;  ), patterns of activity within this specific ATL structure reflected the conceptual similarity of the object concepts ( ). Specifically, whereas the brain-based visual task RDMs obtained across participants in the temporal pole were not significantly correlated with the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.006, p=0.25), they were correlated with the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.035, p<0.001). In other words, activity patterns in the temporal pole expressed a conceptual similarity structure when participants were asked to make explicit judgments about the visual features that characterized object concepts (e.g. whether an object is elongated). Similarly, whereas the brain-based conceptual task RDMs obtained across participants in the temporal pole were not significantly correlated with the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.0005, p=0.47), they were correlated with the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.05, p<0.0001). Thus, activity patterns in the temporal pole expressed a conceptual similarity structure when participants were asked to make explicit judgments about   either   the visual or conceptual features that characterized object concepts (e.g. whether an object is dark in color, or whether an object is pleasant). In other words, conceptual information was represented in the temporal pole in a task-invariant manner that generalized across conceptually related object concepts even when they were visually distinct (e.g. hairdryer \u2013 comb). \n\n\n### Perirhinal cortex represents object concepts in a task-invariant similarity code that reflects integration of visual and conceptual features \n  \nResults obtained in PRC support the notion that this structure integrates visual and conceptual object features (6C), as first theorized in the representational-hierarchical model of object representation ( ). Namely, we revealed that the brain-based visual task RDMs obtained across participants in PRC were significantly correlated with both the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.052, p<0.0001), and the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.036, p<0.0003). Similarly, the brain-based conceptual task RDMs obtained across participants were also correlated with both the behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.035, p<0.002), and the behavior-based conceptual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.057, p<0.0001). In other words, activity patterns in PRC expressed both visual and conceptual similarity structure when participants were asked to make explicit judgments about the visual features that characterized object concepts (e.g. whether an object is round) and when participants were asked to make explicit judgments about the conceptual features that characterized object concepts (e.g. whether an object is manufactured). \n\nNumerically, patterns of activity in PRC showed more similarity to the behavior-based visual RDM than to the behavior-based conceptual RDM in the visual task context, and vice versa in the conceptual task context. Therefore, we performed a 2 [behavior-based RDMs] x 2 [brain-based task RDMs] repeated measures ANOVA to formally test for an interaction between behavior-based model and fMRI task context. For this purpose, all Kendall\u2019s tau-a values were transformed to Pearson\u2019s   r   co-efficients (  r  \u00a0=\u00a0sin (\u00bd \u03c0 tau-a),  ), which were then Fisher-z transformed. The task x model interaction neared, but did not reach, significance (F(1,15) = 3.48, p=0.082). \n\nIn sum, these findings indicate that PRC simultaneously expressed both conceptual and visual similarity structure, and did so regardless of whether participants were asked to make targeted assessments of conceptual or visual features. In other words, activity patterns in PRC captured the conceptual similarity between hairdryer and comb, as well as the visual similarity between hairdryer and gun, and did so irrespective of task context. Critically, these results were obtained despite the fact that the brain-based RDMs were orthogonal to one another (i.e. not significantly correlated). Considered together, these results suggest that, of the a priori ROIs considered, PRC represents object concepts at the highest level of specificity through integration of visual and conceptual features. \n\n\n### ROI-based RSA: comparison of corpus-based (word2vec) semantic RDM with brain-based RDMs \n  \nFor the purpose of comparison, we next examined similarities between the word2vec RDM and the brain-based RDMs using the same procedures described in the previous section. Results are presented in  . These analyses revealed significant positive correlations between the word2vec RDM and the brain-based conceptual task RDMs in parahippocampal cortex (Kendall\u2019s tau-a\u00a0=\u00a00.05, p<0.01), PRC (Kendall\u2019s tau-a\u00a0=\u00a00.035, p<0.01), and the temporal pole (Kendall\u2019s tau-a\u00a0=\u00a00.029, p<0.01). The word2vec RDM was also significantly correlated with the brain-based visual task RDMs in PRC (Kendall\u2019s tau-a\u00a0=\u00a00.025, p<0.05) and the temporal pole (Kendall\u2019s tau-a\u00a0=\u00a00.027, p<0.05). Notably, this pattern of results was identical to that obtained using the behavior-based conceptual RDMs in parahippocampal cortex, PRC, and the temporal pole. Interestingly, however, the word2vec RDM was also significantly correlated with the brain-based visual task RDMs in LOC (Kendall\u2019s tau-a\u00a0=\u00a00.028, p<0.05). This result is consistent with the observation that the word2vec RDM was significantly correlated with our behavior-based visual RDM, and further suggests that corpus-based models of semantic memory likely capture similarities between object concepts at the level of abstract conceptual properties and visual semantics. \n\n\n### ROI-based RSA: comparisons of brain-based RDMs within ROIs \n  \nHaving examined the relationships between behavior-based RDMs and brain-based RDMs, we next sought to directly characterize the relationships between brain-based conceptual and visual RDMs within each ROI (these comparisons are denoted by the dashed horizontal arrow in the bottom of  ). These analyses were conducted using the same methodological procedures used to compare behavior-based RDMs with brain-based RDMs in the previous section. A Bonferroni correction was applied to adjust for multiple comparisons (16 brain-based comparisons, yielding a critical alpha of. 003). Using second-level RSAs, we asked whether the brain-based visual task RDMs and brain-based conceptual task RDMs had a common similarity structure within a given ROI. Results are plotted in  . Importantly, we found a significant positive correlation in PRC (Kendall\u2019s tau-a\u00a0=\u00a00.063, p<0.0001), and a trend toward a significant correlation in the temporal pole (Kendall\u2019s tau-a\u00a0=\u00a00.032, p=0.012). Conversely, brain-based visual and conceptual task RDMs were not significantly correlated in either parahippocampal cortex (Kendall\u2019s tau-a\u00a0=\u00a00.008, p=0.12), or LOC (Kendall\u2019s tau-a\u00a0=\u00a0\u22120.008, p=0.92). These results suggest that object concepts were represented similarly within PRC, and to a lesser extent within the temporal pole, regardless of whether they were encountered in a visual or conceptual task context. \n   Comparison of brain-based RDMs.  \n(  A  ) Similarities between brain-based visual task RDMs and brain-based conceptual task RDMs within lateral occipital cortex (LOC), parahippocampal cortex (PHC), perirhinal cortex (PRC), and the temporal pole (TP). These comparisons are denoted by the dashed horizontal arrow in the bottom of  . (  B  ) Similarities between brain-based visual task RDMs across different ROIs. Labels on the x-axis denote the ROIs being compared. (  C  ) Similarities between brain-based conceptual task RDMs across different ROIs. Similarity was quantified as the ranked correlation coefficient (Kendall\u2019s tau-a) between behavior-based RDMs and the brain-based RDMs. Error bars indicate standard error of the mean. ***p<0.001 (Bonferroni corrected),~p\u00a0<\u00a00.05 (uncorrected). Participant-specific Kendall\u2019s tau-a co-efficients are contained in   - Comparison of brain-based RDMs. \n\n\n  \n\n### ROI-based RSA: comparisons of brain-based RDMs across ROIs \n  \nWe next conducted second-level RSAs to quantify representational similarities between the brain-based visual task RDMs obtained across different ROIs. In other words, we asked whether activity in different ROIs (e.g. PRC and LOC) reflected similar representational distinctions across object concepts within the visual task context. Results are plotted in  . Interestingly, these analyses did not reveal any significant results between any of our ROIs (all Kendall\u2019s tau-a\u00a0<0.01, all p>0.07). These findings indicate that PRC and LOC, two regions that expressed a visual similarity code, represented different aspects of the visual object features. \n\nFinally, we quantified the representational similarities between the brain-based conceptual task RDMs obtained across different ROIs. In other words, we asked whether activity in different ROIs (e.g. PRC and the temporal pole) reflected similar representational distinctions across object concepts within the conceptual task context. Results are plotted in  . This set of analyses did not reveal any significant results between any of our ROIs (all Kendall\u2019s tau-a\u00a0<0.016, all p>0.012). These findings indicate that the three regions that expressed a conceptual similarity code (i.e., PRC, parahippocampal cortex, and temporal pole), represented different aspects of the conceptual object features. \n\n\n### ROI-based RSA: comparisons of within-object multi-voxel activity patterns across different task contexts \n  \nThe RSAs reported thus far have quantified relationships among behavior-based and brain-based RDMs that reflected similarities between different object concepts (e.g. between \u2018hairdryer\u2019 and \u2018comb\u2019). We next quantified within-object similarities (e.g. between \u2018hairdryer\u2019 and \u2018hairdryer\u2019) across visual and conceptual task contexts (e.g. \u2018is it living?\u2019 or \u2018is it angular?\u201d) using first-level RSAs. Specifically, we calculated one dissimilarity value (1 \u2013 Pearson\u2019s   r  ) between the mean multi-voxel activity patterns evoked by a given object concept across different task contexts. These 40 within-object dissimilarity values were expressed along the diagonal of an RDM for each ROI in each participant, separately ( ). We next calculated mean within-object dissimilarity by averaging across the diagonal of each RDM for the purpose of performing statistical inference. \n   Comparison of within-object multi-voxel activity patterns across different task contexts.  \n(  A  ) Depiction of first-level RSA procedure for quantifying within-object multi-voxel activity patterns across the visual and conceptual task contexts. (  B  ) Mean similarities between within-object multi-voxel activity patterns across different task contexts within each region of interest. Similarity was quantified as the linear correlation coefficient (Pearson\u2019s   r  ) between object-evoked multi-voxel activity patterns. Lateral occipital cortex (LOC), parahippocampal cortex (PHC), perirhinal cortex (PRC), and the temporal pole (TP). Error bars indicate standard error of the mean. **p<0.01, *p<0.05 (Bonferroni corrected). Participant-specific Pearson\u2019s   r   co-efficients are contained in   - Comparison of within-object similarity across task contexts. \n\n\n  \nResults are presented in  . Within-object similarity did not differ from zero in either LOC (Pearson\u2019s   r  \u00a0=\u00a00.007, p=0.20) or parahippocampal cortex (Pearson\u2019s   r  \u00a0=\u00a0\u22120.008, p=0.87), suggesting that a given object concept was represented differently across the visual and conceptual task contexts in these ROIs. These findings are consistent with the task-dependent nature of the similarity codes we observed in these regions ( ). Conversely, within-object similarity was significantly greater than zero in the temporal pole (Pearson\u2019s   r  \u00a0=\u00a00.34, p<0.05, Bonferroni corrected for four comparisons), indicating that this structure represents a given object concept similarly across different task contexts. This observation is consistent with results from the previous section which revealed that the similarities between object concepts in the temporal pole are preserved across task contexts ( ). These findings reflected the fact that the same conceptual object information (e.g. \u2018  used to style hair  \u2019 and \u2018  found in salons  \u2019) was carried in multi-voxel activity patterns obtained in each task context ( ). Within-object similarity was also significantly greater than zero in PRC (Pearson\u2019s   r  \u00a0=\u00a00.41, p<0.01, Bonferroni corrected for four comparisons), again indicating that a given object concept was represented similarly across different task contexts. This finding dovetails with our result from the previous section which revealed that the similarities between object concepts in PRC were preserved across task contexts ( ). When considered together, we interpret this pattern of results in PRC as further evidence of integrative coding, reflecting the fact that this structure carried the same conceptual (e.g. \u2018  used to style hair  \u2019 and \u2018   found in salons   \u2019) and visual (e.g. visually similar to a gun) object information in both task contexts ( ). \n\n\n### Searchlight-based RSA: comparisons of behavior-based RDMs with brain-based RDMs \n  \n#### Perirhinal cortex is the only cortical region that supports integrative coding of conceptual and visual object features \n  \nWe next implemented a whole-volume searchlight-based RSA to further characterize the neuroanatomical specificity of our ROI-based results. Specifically, we sought to determine whether object representations in PRC expressed visual and conceptual similarity structure within overlapping or distinct populations of voxels. If PRC does indeed support the integrative coding of visual and conceptual object features, then the same set of voxels should express both types of similarity codes. If PRC does not support the integrative coding of visual and conceptual object features, then different subsets of voxels should express these different similarity codes. More generally, data-driven searchlight mapping allowed us to explore whether any other regions of the brain showed evidence for integrative coding of visual and conceptual features in a manner comparable to that observed in PRC. To this end, we performed searchlight RSA using multi-voxel activity patterns restricted to a 100 voxel ROI that was iteratively swept across the entire cortical surface ( ;  ). In each searchlight ROI, the behavior-based RDMs were compared with the brain-based RDMs using a procedure identical to that implemented in our ROI-based RSA. These comparisons are depicted by the solid black vertical and diagonal arrows in  . The obtained similarity values (Pearson\u2019s   r  ) were Fisher-  z   transformed and mapped to the center of each ROI for each participant separately. With this approach, we obtained participant-specific similarity maps for all comparisons, which were then standardized and subjected to a group-level statistical analysis. A threshold-free cluster enhancement (TFCE) method was used to correct for multiple comparisons with a cluster threshold of p<0.05 ( ). \n\nStatistically thresholded group-level similarity maps depicting cortical regions in which behavior- and brain-based RDMs were significantly correlated are presented for the visual task context in  , and for the conceptual task context in  . Corresponding cluster statistics, co-ordinates, and neuroanatomical labels are reported in  . Importantly, results from our whole-volume searchlight mapping analysis showed a high degree of consistency with our ROI-based results. First, we found evidence for visual similarity coding in the visual task context in aspects of right LOC ( ), as well as aspects of early visual cortex, posterior parietal cortex, and areas of medial and lateral ventral temporal cortex ( ). Next, we revealed conceptual similarity coding in the conceptual task context within a cluster of voxels that straddled the border between right parahippocampal cortex and PRC ( ). Although this cluster was only partially situated with parahippocampal cortex, it is interesting to note that its posterior extent did slightly encroach upon anterior aspects of the parahippocampal place area (PPA; functionally defined using a group-level GLM (scenes\u00a0>\u00a0objects);  ), which has previously been linked to the representation of abstract conceptual information ( ;  ;  ). Moreover, we found evidence of conceptual similarity coding in bilateral aspects of the temporal pole in both task contexts (  and  ), an observation that is consistent with results from multiple prior studies that have demonstrated conceptual similarity structure this aspect of the ATL ( ;\u00a0 ; cf  ). Finally, and most importantly, results from the whole-brain searchlight revealed evidence for visual similarity coding and conceptual similarity coding in PRC in both task contexts (  and  ). This result dovetails with findings from previous RSA-based fMRI research that has demonstrated conceptual similarity coding in PRC ( ;  ; cf  ). \n   Visual task context representational similarity searchlight mapping results.  \n(  A  ) Cortical regions in which the brain-based visual task RDMs were significantly correlated with the behavior-based visual RDM. (  B  ) Cortical regions in which the brain-based visual task RDMs were significantly correlated with the behavior-based conceptual RDM. The correlation coefficients (Kendall\u2019s tau-a) obtained between behavior-based RDMs and brain-based RDMs were Fisher-  z   transformed and mapped to the voxel at the centre of each searchlight. Similarity maps were corrected for multiple comparisons using threshold-free cluster enhancement with a corrected statistical threshold of p<0.05 on the cluster level ( ). Outlines are shown for the lateral occipital cortex (green), parahippocampal cortex (pink), perirhinal cortex (purple), and the temporal pole (cyan). \n     Conceptual task context representational similarity searchlight mapping results.  \n(  A  ) Cortical regions in which the brain-based conceptual task RDMs were significantly correlated with the behavior-based visual RDM. (  B  ) Cortical regions in which the brain-based conceptual task RDMs were significantly correlated with the behavior-based conceptual RDM. The correlation coefficients (Kendall\u2019s tau-a) obtained between behavior-based RDMs and brain-based RDMs were Fisher-  z   transformed and mapped to the voxel at the centre of each searchlight. Similarity maps were corrected for multiple comparisons using threshold-free cluster enhancement with a corrected statistical threshold of p<0.05 on the cluster level ( ). Outlines are shown for the lateral occipital cortex (green), parahippocampal cortex (pink), perirhinal cortex (purple), and the temporal pole (cyan). \n     Clusters in which behavior-based RDMs were significantly correlated with brain-based RDMs as revealed using representational similarity searchlight analyses, with corresponding cluster extent, peak   z  -values, and MNI co-ordinates .      \nAlthough suggestive, neither the searchlight- nor the ROI-based RSA results presented thus far necessarily imply integrative coding in PRC. Indeed, it is possible that visual and conceptual object information was carried in spatially distinct sub-regions of this structure. To examine this issue, we first asked whether any voxels showed both visual and conceptual similarity coding in the visual task context (similarity maps in  , respectively) using a voxel overlap analysis ( ). Importantly, we revealed a contiguous cluster of voxels that was unique to left PRC in which both behavior-based RDMs predicted the similarity structure in the brain-based visual task RDMs. This result indicated that a subset of voxels in PRC carried information about visual   and   conceptual object information even when task demands biased attention toward visual object features. We next asked whether any voxels showed both visual and conceptual similarity coding in the conceptual task context (similarity maps in  , respectively) using a second voxel overlap analysis ( ). This analysis also revealed a contiguous cluster of voxels that was unique to left PRC in which both behavior-based RDMs predicted the similarity structure in the brain-based conceptual task RDMs. This finding indicated that a subset of voxels in PRC carried information about visual   and   conceptual object information when task demands biased attention toward conceptual object features. \n   Overlap of searchlight similarity maps.  \n(  A  ) Overlap between similarity maps obtained in the visual task context (i.e. overlapping voxels from  ). (  B  ) Overlap between similarity maps obtained in the conceptual task context (i.e. overlapping voxels from  ). (  C  ) Overlap across brain-behavior similarity maps across both task contexts (i.e. overlapping voxels from  ,  ). Outlines are shown for the lateral occipital cortex (green), parahippocampal cortex (pink), perirhinal cortex (purple), and the temporal pole (cyan). \n  \nIn a final step using a third voxel overlap analysis, we examined whether any voxels showed both visual and conceptual similarity coding in both the visual and conceptual task contexts ( ). This analysis revealed a contiguous cluster of voxels in left PRC in which both behavior-based RDMs predicted the similarity structure captured by both brain-based RDMs. This result indicated that a subset of voxels that were unique to PRC carried information about visual   and   conceptual object information regardless of whether task demands biased attention toward visual   or   conceptual object features. Ultimately, this pattern of results suggests that not only does PRC carry both visual and conceptual object information, but it does so in the same subset of voxels. \n\n\n\n\n## Discussion \n  \nDecades of research has been aimed at understanding how object concepts are represented in the brain ( ;  ;  ;  ;  ), yet the fundamental question of whether and where their visual and conceptual features are integrated remains unanswered. Progress toward this end has been hindered by the fact that these features tend to vary concomitantly across object concepts. Here, we used a data-driven approach to systematically select a set of object concepts in which visual and conceptual features varied independently (e.g. hairdryer \u2013 comb, which are conceptually similar but visually distinct; hairdryer \u2013 gun, which are visually similar but conceptually distinct). Using RSA of fMRI data, we revealed novel evidence of task-dependent visual similarity coding in LOC, task-dependent conceptual similarity coding in parahippocampal cortex, task-invariant coding in the temporal pole, and task-invariant integrative coding in PRC. \n\nSeveral aspects of our data provide novel support for the notion that PRC uniquely represents the visual and conceptual features that define fully\u00a0specified object concepts in an integrated similarity code. First, this was the only region of the brain in which both visual   and   conceptual object coding was revealed. Moreover, these effects were observed regardless of whether fMRI task demands biased attention toward visual   or   conceptual object features. These results are particularly striking given the fact that they were revealed using a behavior-based visual similarity model and a behavior-based conceptual similarity model that were orthogonal to one another. In other words, the degree of similarity between multi-voxel activity patterns obtained while participants made conceptual judgments, such as whether a \u2018hairdryer\u2019 is man-made or a \u2018gun\u2019 is pleasant, was captured by the degree of visual similarity between these object concepts. Likewise, the degree of similarity between multi-voxel activity patterns obtained while participants made visual judgments, such as whether a \u2018hairdryer\u2019 is angular or a \u2018comb\u2019 is elongated, was captured by the degree of conceptual similarity between these object concepts. In both cases, PRC carried information about pre-existing representations of object features that were neither required to perform the immediate task at hand, nor correlated with the features that did in fact have task-relevant diagnostic value. Moreover, we also found that the brain-based visual task RDMs and brain-based conceptual task RDMs were correlated with one another across task contexts in PRC. That is to say, the similarity between \u2018hairdryer\u2019 and \u2018gun\u2019 was comparable regardless of whether task demands biased attention toward visual or conceptual features. Likewise, we also revealed that PRC also represented a given object concept similarly across task contexts, that\u00a0is, \u2018hairdryer\u2019 evoked a pattern of activation that was comparable across task contexts. When considered together, these results suggest that, at the level of PRC, it may not be possible to fully disentangle conceptual and perceptual information. An important but challenging objective for future research will be to determine whether this pattern of results can be replicated at the level of individual neurons. \n\nWhat is the behavioral relevance of fully\u00a0specified object representations in which visual and conceptual features are integrated? It has previously been suggested that such representations allow for discrimination among stimuli with extensive feature overlap, such as exemplars from the same category ( ;  ;  ;  ). In line with this view, individuals with medial ATL lesions that include PRC typically have more pronounced conceptual impairments related to living than non-living things ( ;  ;  ), and more striking perceptual impairments for objects that are visually similar as compared to visually distinct ( ,\u00a0 ;  ). Functional MRI studies in neurologically healthy individuals have also demonstrated increased PRC engagement for living as compared to non-living objects ( ), for known as compared to novel faces ( ;  ), and for faces or conceptually meaningless stimuli with high feature overlap as compared to low feature overlap ( ;  ). In a related manner, fully\u00a0specified object representations in PRC have also been implicated in long-term memory judgments. For example, PRC has been linked to explicit recognition memory judgments when previously studied and novel items are from the same stimulus category ( ;  ;  ), and when subjects make judgments about their lifetime of experience with a given object concept ( ). Common among these task demands is the requirement to discriminate among highly similar stimuli. In such scenarios, a fully\u00a0specified representation that reflects the integration of perceptual and conceptual features necessarily enables more fine-grained distinctions than a purely perceptual or conceptual representation. \n\nThis study also has significant implications for prominent neurocognitive models of semantic memory in which the ATL is characterized as a semantic hub ( ;  ;  ). On this view, the bilateral ATLs are thought to constitute a trans-modal convergence zone that abstracts conceptual information from the co-occurrence of features otherwise represented in a distributed manner across modality-specific cortical nodes. Consistent with this idea, we have shown that a behavior-based conceptual similarity model predicted the similarity structure of neural activity patterns in the temporal pole, irrespective of task context. Specifically, neural activity patterns associated with conceptually similar object concepts that are visually distinct (e.g. hairdryer \u2013 comb) were more comparable than were conceptually dissimilar concepts that are visually similar (e.g. hairdryer \u2013 gun), even when task demands required a critical assessment of visual features. This observation, together with results obtained in PRC, demonstrates a representational distinction between these ATL structures, a conclusion that dovetails with recent evidence indicating that this region is not functionally homogeneous ( ;  ). Ultimately, this outcome suggests that some ATL sub-regions play a prominent role in task-invariant extraction of conceptual object properties (e.g. temporal pole), whereas others appear to make differential contributions to the task-invariant integration of perceptual and conceptual features (e.g. PRC) ( ;  ). \n\nConvergent evidence from studies of functional and structural connectivity in humans, non-human primates, and rodents have revealed that PRC is connected to the temporal pole, parahippocampal cortex, LOC, and nearly all other unimodal and polymodal sensory regions in neocortex ( ;  ;  ;  ;  ;  ;  ). Importantly, our results have linked LOC to the representation of visual object features, and the temporal pole and parahippocampal cortex to the representation of conceptual object features. Thus, PRC has the connectivity properties that make it well suited to be a trans-modal convergence zone capable of integrating object features that are both visual and conceptual in nature. An interesting challenge for future research will be to determine how differentially attending to specific types of object features shapes functional connectivity profiles between these regions. \n\nAlthough speculative, results from the current study suggest that attention may modulate information both within and between the ROIs examined. First, we see visual similarity coding in LOC only when task demands biased attention to visual object features, and conceptual similarity coding in parahippocampal cortex only when task demands biased attention to conceptual object features. Second, we saw a trend toward an interaction between behavior-based models and fMRI task context in PRC, such that visual similarity coding was more pronounced in the visual task context than was conceptual similarity coding, and vice versa. Thus, attending to specific types of features did not merely manifest as univariate gain modulation. Rather, attention appeared to modulated multi-voxel activity patterns. \n\nAnother novel aspect of our findings is that parahippocampal cortex exhibited conceptual similarity coding in the conceptual task context. Interestingly, it has been suggested that this structure broadly contributes to cognition by processing contextual associations, including the co-occurrence of objects within a context ( ;  ). Critically, objects that regularly co-occur in the same context (e.g. \u2018comb\u2019 and \u2018hairdryer\u2019 in a barbershop) often share many conceptual features (e.g. functional properties such as \u2018  used to style hair  \u2019), but do not necessarily share many visual features. Thus, object-evoked responses in parahippocampal cortex may express feature-based conceptual similarity structure because objects with many shared conceptual features bring to mind an associated context, whereas objects that are visually similar but conceptually distinct do not (e.g. hairdryer and gun). We note, however, that the current study was not designed to test-specific hypotheses about the contextual co-occurrence of objects, or how co-occurrence relates to conceptual feature statistics. Ultimately, a mechanistic account of object-based coding in PHC will require further research using a carefully selected stimulus set in which the strength of contextual associations (i.e. co-occurrence) between object concepts is not confounded with conceptual features. \n\nIn summary, this study sheds new light on our understanding of how object concepts are represented in the brain. Specifically, we revealed that PRC represented object concepts in a task-invariant, integrative similarity code that captured the visual and conceptual relatedness among stimuli. Most critically, this result was obtained despite systematically dissociating visual and conceptual features across object concepts. Moreover, the striking neuroanatomical specificity of this result suggests that PRC uniquely supports integration across these fundamentally different types of features. Ultimately, this pattern of results implicates PRC in the representation of fully-specified objects. \n\n\n## Materials and methods \n  \n### Participants \n  \n#### Behavior-based visual similarity rating task and conceptual feature generation task \n  \nA total of 2846 individuals completed online behavioral tasks using Amazon\u2019s Mechanical Turk ( ). Data from 61 participants were discarded due to technical errors, incomplete submissions, or missed catch trials. Of the remaining 2785 participants, 1185 completed the visual similarity rating task (616 males, 569 females; age range\u00a0=\u00a018\u201353; mean age\u00a0=\u00a030.1), and 1600 completed the semantic feature generation task (852 males, 748 females; age range\u00a0=\u00a018\u201358 years; mean age\u00a0=\u00a031.7). These sample sizes are proportionally in line with those reported by  . Individuals who completed the visual similarity rating task were excluded from completing the feature generation task, and vice versa. All participants provided informed consent and were compensated for their time. Both online tasks were approved by the University of Toronto Ethics Review Board. \n\n\n#### Brain-based fMRI task \n  \nA separate group consisting of sixteen right-handed participants took part in the fMRI experiment (10 female; age range\u00a0=\u00a019\u201329 years; mean age\u00a0=\u00a023.1 years). This sample size is in line with extant fMRI studies that have used comparable analytical procedures to test hypotheses pertaining to object representation in the ventral visual stream and ATL ( ;  ;  ;  ;  ;  ; ;  ;  ). Due to technical problems, we were unable to obtain data from one experimental run in two different participants. No participants were removed due to excessive motion using a criterion of 1.5 mm of translational displacement. All participants gave informed consent, reported that they were native English speakers, free of neurological and psychiatric disorders, and had normal or corrected to normal vision. Participants were compensated $50. This study was approved by the Baycrest Hospital Research Ethics Board. \n\n\n\n### Stimuli \n  \nAs a starting point, we chained together a list of 80 object concepts in such a way that adjacent items in the list alternated between being conceptually similar but visually distinct and visually similar but conceptually distinct (e.g. bullet \u2013 gun \u2013 hairdryer \u2013 comb; bullet and gun are conceptually but not visually similar, whereas gun and hairdryer are visually but not conceptually similar, and hairdryer and comb are conceptually but not visually similar, etc.). Our initial stimulus set was established using the authors\u2019 subjective impressions. The visual and conceptual similarities between all pairs of object concepts were then quantified by human observers in the context of a visual similarity rating task and a conceptual feature generation task, respectively. Results from these behavioral tasks were then used to select 40 object concepts used throughout the current study. \n\nParticipants who completed the visual similarity rating task were presented with 40 pairs of words and asked to rate visual similarity between the object concepts to which they referred ( ). Responses were made using a 5-point scale (very dissimilar, somewhat dissimilar, neutral, somewhat similar, very similar). Each participant was also presented with four catch trials on which an object concept was paired with itself. Across participants, 95.7% of catch trials were rated as being very similar. Data were excluded from 28 participants who did not rate all four catch trials as being at least \u2018somewhat similar\u2019. Every pair of object concepts from the initial set of 80 object concepts (3160) was rated by 15 different participants. \n\nWe next quantified conceptual similarities between object concepts based on responses obtained in a conceptual feature generation task ( ), following task instructions previously described by  . Each participant was presented with one object concept and asked to produce a list of up to 15 different types of descriptive features, including functional properties (e.g. what it is used for, where it is used, and when it is used), physical properties (e.g. how it looks, sounds, smells, feels, and tastes), and other facts about it, such as the category to which it belongs or other encyclopedic facts (e.g. where it is from). One example object and its corresponding features from a normative database were presented as an example ( ). Interpretation and organization of written responses were guided by criteria described by  . Features were obtained from 20 different participants for each object concept. Data were excluded from 33 participants who failed to list any features. A total of 4851 unique features were produced across all 80 object concepts and participants. Features listed by fewer than 4 out of 20 participants were considered to be unreliable and discarded for the purpose of all subsequent analyses, leaving 723 unique features. This exclusion criterion is proportionally comparable to that used by  . On average, each of the 80 object concepts was associated with 10.6 features. \n\nWe used a data-driven approach to select a subset of 40 object concepts from the initial 80-item set. These 40 object concepts are reflected in the behavior-based visual and conceptual RDMs, and were used as stimuli in our fMRI experiment. Specifically, we first ensured that each object concept was visually similar, but conceptually dissimilar, to at least one other item (e.g. hairdryer \u2013 gun), and conceptually similar, but visually dissimilar, to at least one different item (e.g. hairdryer \u2013 comb). Second, in an effort to ensure that visual and conceptual features varied independently across object concepts, stimuli were selected such that the corresponding behavior-based visual and conceptual similarity models were not correlated with one another. \n\n\n### Behavior-based RDMs \n  \n#### Behavior-based visual RDM \n  \nA behavior-based model that captured visual dissimilarities between all pairs of object concepts included in the fMRI experiment (40 object concepts) was derived from the visual similarity judgments obtained from our online rating task. Specifically, similarity ratings for each pair of object concepts were averaged across participants, normalized, and expressed within a 40 \u00d7 40 RDM (1 \u2013 averaged normalized rating). Thus, the value in a given cell of this RDM reflects the visual similarity of the object concepts at that intersection. This behavior-based visual RDM is our visual dissimilarity model. \n\n\n#### Behavior-based conceptual RDM \n  \nA behavior-based model that captured conceptual dissimilarities between all pairs of object concepts included in the fMRI experiment was derived from data obtained in our online feature-generation task. In order to ensure that the semantic relationships captured by our conceptual similarity model were not influenced by verbal descriptions of visual attributes, we systematically removed features that characterized either visual form or color (e.g. \u2018is round\u2019 or \u2018is red\u2019). Using these criteria a total of 58 features (8% of the total number of features provided) were removed. We next quantified conceptual similarity using a concept-feature matrix in which columns\u00a0corresponded to object concepts (i.e. 40 columns) and rows\u00a0to\u00a0the conceptual features associated with those objects (i.e. 282\u00a0rows) ( , center). Specifically, we computed the cosine angle between each row; cosine similarity reflects the conceptual distances between object concepts such that high cosine similarities between items denote short conceptual distance. The conceptual dissimilarities between all pairs of object concepts were expressed as a 40 \u00d7 40 RDM. The value within each cell of the conceptual model RDM was calculated as 1 \u2013 the cosine similarity value between the corresponding object concepts. This behavior-based conceptual RDM is our conceptual dissimilarity model. \n\n\n#### Behavior-based RSA: comparison of behavior-based RDMs \n  \nWe next quantified similarity between our behavior-based visual RDM and behavior-based conceptual RDM using Kendall\u2019s tau-a as the relatedness measure. This ranked correlation coefficient is the most appropriate inferential statistic to use when comparing sparse RDMs that predict many tied ranks (i.e. both models predict complete dissimilarity between many object pairs;  ). Statistical analysis of model similarity was performed using a stimulus-label randomization test (10,000 iterations) that simulated the null hypothesis of unrelated RDMs (i.e. zero correlation) based on the obtained variance. Significance was assessed through comparison of the obtained Kendall\u2019s tau-a coefficient to the equivalent distribution of ranked null values. As noted in the Results section, this analysis revealed that our behavior-based visual and conceptual RDMs were not significantly correlated (Kendall\u2019s tau-a\u00a0=\u00a00.01, p=0.10). Moreover, inclusion of the 58 features that described color and visual form in the behavior-based conceptual RDM did not significantly alter its relationship with the visual behavior-based visual RDM (Kendall\u2019s tau-a\u00a0=\u00a00.01, p=0.09). \n\n\n\n### Experimental procedures: fMRI feature verification task \n  \nDuring scanning, participants completed a feature verification task that required a yes/no judgment indicating whether a given feature was applicable to a specific object concept on a trial-by-trial basis. We systematically varied the feature verification probes in a manner that established a visual feature verification task context and conceptual feature verification task context. Verification probes comprising the visual task context were selected to encourage processing of the visual semantic features that characterize each object concept (i.e. shape, color, and surface detail). To this end, eight specific probes were used: shape [(angular, rounded), (elongated, symmetrical)], color (light, dark), and surface (smooth, rough). Notably, all features are associated with two opposing probes (e.g. angular and rounded; natural and manufactured) to ensure that participants made an equal number of \u2018yes\u2019 and \u2018no\u2019 responses. Verification probes comprising the conceptual feature verification task context were selected to encourage processing of the abstract conceptual features that characterize each object concept (i.e. animacy, origin, function, and affective associations). To this end, eight specific verification probes were used: (living, non-living), (manufactured, natural), (tool, non-tool), (pleasant, unpleasant). \n\n\n### Procedures \n  \nThe primary experimental task was evenly divided over eight runs of functional data acquisition. Each run lasted 7 m 56 s and was evenly divided into two blocks, each of which corresponded to either a visual verification task context or a conceptual feature verification task context. The order of task blocks was counter-balanced across participants. Each block was associated with a different feature verification probe, with the first and second block in each run separated by 12 s of rest. Blocks began with an 8 s presentation of a feature verification probe that was to be referenced for all intra-block trials. With this design, each object concept was repeated 16 times: eight repetitions across the visual feature verification task context and eight repetitions across the conceptual feature verification task context. Behavioral responses were recorded using an MR-compatible keypad. \n\nStimuli were centrally presented for 2 s and each trial was separated by a jittered period of baseline fixation that ranged 2\u20136 s. Trial order and jitter interval were optimized for each run using the OptSeq2 algorithm ( ), with unique sequences and timing across counterbalanced versions of the experiment. Stimulus presentation and timing was controlled by E-Prime 2.0 (Psychology Software Tools, Pittsburgh, PA). \n\n\n### Experimental procedure: fMRI functional localizer task \n  \nFollowing completion of the main experimental task, each participant completed an independent functional localizer scan that was subsequently used to identify LOC. Participants viewed objects, scrambled objects, words, scrambled words, faces, and scenes in separate 24 s blocks (12 functional volumes). Within each block, 32 images were presented for 400 ms each with a 350 ms ISI. There were four groups of six blocks, with each group separated by a 12 s fixation period, and each block corresponding to a different stimulus category. Block order (i.e. stimulus category) was counterbalanced across groups. All stimuli were presented in the context of a 1-back task to ensure that participants remained engaged throughout the entire scan. Presentation of images within blocks was pseudo-random with 1-back repetition occurring 1\u20132 times per block. \n\n\n### ROI definitions \n  \nWe performed RSA in four a priori defined ROIs. The temporal pole, PRC, and parahippocampal cortex were manually defined in both the left and right hemisphere on each participant\u2019s high-resolution anatomical image according to established MR-based protocols ( ), with adjustment of posterior border of parahippocampal cortex using anatomical landmarks described by  ). Lateral occipital cortex was defined as the set of contiguous voxels located along the lateral extent of the occipital lobe that responded more strongly to intact than scrambled objects (p<0.001, uncorrected;  ). \n\n\n### fMRI data acquisition \n  \nScanning was performed using a 3.0 T Siemens MAGNETOM Trio MRI scanner at the Rotman Research Institute at Baycrest Hospital using a 32-channel receiver head coil. Each scanning session began with the acquisition of a whole-brain high-resolution magnetization-prepared rapid gradient-echo T1-weighted structural image (repetition time\u00a0=\u00a02 s, echo time\u00a0=\u00a02.63 ms, flip angle\u00a0=\u00a09\u00b0, field of view\u00a0=\u00a025.6 cm , 160 oblique axial slices, 192\u00a0\u00d7\u00a0256 matrix, slice thickness\u00a0=\u00a01 mm). During each of eight functional scanning runs comprising the main experimental task, a total of 238 T2*-weighted echo-planar images were acquired using a two-shot gradient echo sequence (200\u00a0\u00d7\u00a0200 mm field of view with a 64\u00a0\u00d7\u00a064 matrix size), resulting in an in-plane resolution of 3.1\u00a0\u00d7\u00a03.1 mm for each of 40 2 mm axial slices that were acquired in an interleaved manner along the axis of the hippocampus. The inter-slice gap was 0.5 mm; repetition time\u00a0=\u00a02 s; echo time\u00a0=\u00a030 ms; flip angle\u00a0=\u00a078\u00b0). These parameters yielded coverage of the majority of cortex, excluding only the most superior aspects of the frontal and parietal lobes. During a single functional localizer scan, a total of 360 T2*-weighted echo-planar images were acquired using the same parameters reported for the main experimental task. Lastly, a B0 field map was collected following completion of the functional localizer scan\u00a0 \n\n\n### fMRI data analysis software \n  \nPreprocessing and GLM analyses were performed in FSL5 ( ). Representational similarity analyses were performed using CoSMoMVPA ( ;  ). \n\n\n### Preprocessing and estimation of object-specific multi-voxel activity patterns \n  \nImages were initially skull-stripped using a brain extraction tool (BET,  ) to remove non-brain tissue from the image. Data were then corrected for slice-acquisition time, high-pass temporally filtered (using a 50-s period cut-off for event-related runs, and a 128 s period cut-off for the blocked localizer run), and motion corrected (MCFLIRT,  ). Functional runs were registered to each participant\u2019s high-resolution MPRAGE image using FLIRT boundary-based registration with B0-fieldmap correction. The resulting unsmoothed data were analyzed using first-level FEAT (v6.00; fsl.fmrib.ox.ac.uk/fsl/fslwiki) in each participant\u2019s native anatomical space. Parameter estimates of BOLD response amplitude were computed using FILM, with a general linear model that included temporal autocorrelation correction and six motion parameters as nuisance covariates. Each trial (i.e. object concept) was modeled with a delta function corresponding to the stimulus presentation onset and then convolved with a double-gamma hemodynamic response function. Separate response-amplitude (\u03b2) images were created for each object concept (n\u00a0=\u00a040), in each run (n\u00a0=\u00a08), in each property verification task context (n\u00a0=\u00a02). Obtained \u03b2 images were converted into   t  -statistic maps; previous research has demonstrated a modest advantage for   t  -maps over \u03b2 images in the context of multi-voxel pattern analysis ( ). In a final step, we created mean object-specific   t  -maps by averaging across runs. These data were used for all subsequent similarity analyses. \n\n\n### Representational similarity analysis (RSA) \n  \n#### ROI-based first-level RSA \n  \nWe used linear correlations to quantify the participant-specific dissimilarities (1 \u2013 Pearson\u2019s r) between all object-evoked multi-voxel activity patterns (n\u00a0=\u00a040) within each ROI (n\u00a0=\u00a04). Participant-specific dissimilarity measures were expressed in 40 \u00d7 40 RDMs for each verification task context (n\u00a0=\u00a02), separately. Thus, for each ROI, each participant had one RDM that reflected the dissimilarity structure from the visual feature verification task context (i.e. brain-based visual task RDM), and one RDM that reflected the dissimilarity structure from the conceptual verification task context (i.e., brain-based conceptual task RDM). \n\n\n#### ROI-based second-level RSA \n  \nWe performed second-level RSAs, that\u00a0is, we compared RDMs derived from first-level RSAs, to quantify similarities among behavior-based RDMs and brain-based RDMs. Similarity was quantified in each participant using the ranked correlation coefficient (Kendall\u2019s tau-a) between RDMs. Inferential statistical analyses were performed using a one-sided Wilcoxon signed-rank test across subject-specific RDM correlations to test for significance. This non-parametric test provides valid inference and treats the variation across subjects as a random effect, thus supporting generalization of results beyond the sample. A Bonferroni correction was applied in each analysis to compensate for the number of second-level comparisons. \n\n\n#### Searchlight-based RSA \n  \nWhole-volume RSA was implemented using 100-voxel surface-based searchlights ( ;  ). Each surface-based searchlight referenced the 100 nearest voxels to the searchlight center based on geodesic distance on the cortical surface. Neural estimates of dissimilarity (i.e. RDMs) were calculated in each searchlight using the same approach implemented in our ROI-based RSA. Correlations between behavior-based RDMs were also quantified using the same approach. The correlation coefficients obtained between behavior-based RDMs and brain-based RDMs were then Fisher-  z   transformed and mapped to the voxel at the centre of each searchlight to create a whole-brain similarity map. Participant-specific similarity maps were then normalized to a standard MNI template using FNIRT ( ). To assess the statistical significance of searchlight maps across participants, all maps were corrected for multiple comparisons without choosing an arbitrary uncorrected threshold using threshold-free cluster enhancement (TFCE) with a corrected statistical threshold of p<0.05 on the cluster level ( ). A Monte Carlo simulation permuting condition labels was used to estimate a null TFCE distribution. First, 100 null searchlight maps were generated for each participant by randomly permuting condition labels within each obtained searchlight RDM. Next, 10,000 null TFCE maps were constructed by randomly sampling from these null data sets in order to estimate a null TFCE distribution ( ). The resulting surface-based statistically thresholded   z  -score were projected onto the PALS-B12 surface atlas in CARET version 5.6. ( ;  ;  ). \n\n\n\n \n\n# Table(s)\n## ID: table1\n### Label: Table 1.\nRegion\tCluster extent\tCluster extent.1\tCluster extent.2\tPeak z-value\tX\tY\tZ\nVisual task context\tVisual task context\tVisual task context\tVisual task context\tVisual task context\tVisual task context\tVisual task context\tVisual task context\nBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Visual Task RDM\nMid calcarine\tMid calcarine\t1660\t1660\t5.79\t-2\t\u221274\t12\nR lateral occipital cortex\tR lateral occipital cortex\t455\t455\t3.89\t50\t\u221266\t4\nR perirhinal cortex\tR perirhinal cortex\t112\t112\t3.64\t34\t\u221212\t\u221234\nL superior parietal lobule\tL superior parietal lobule\t110\t110\t3.21\t\u221232\t\u221240\t44\nL perirhinal cortex\tL perirhinal cortex\t76\t76\t2.85\t\u221230\t\u221212\t\u221236\nR superior parietal lobule\tR superior parietal lobule\t48\t48\t2.64\t38\t\u221254\t54\nR fusiform gyrus\tR fusiform gyrus\t45\t45\t2.77\t40\t\u221246\t\u221220\nR precuneus\tR precuneus\t29\t29\t2.66\t12\t\u221276\t48\nR Inferior Temporal Gyrus\tR Inferior Temporal Gyrus\t9\t9\t2.52\t44\t\u221222\t\u221228\nBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Visual Task RDM\nL Perirhinal Cortex\tL Perirhinal Cortex\tL Perirhinal Cortex\t368\t3.96\t\u221224\t2\t\u221238\nR Perirhinal Cortex\tR Perirhinal Cortex\tR Perirhinal Cortex\t232\t3.26\t22\t2\t\u221236\nOverlap\tOverlap\tOverlap\tOverlap\tOverlap\tOverlap\tOverlap\tOverlap\nL Perirhinal Cortex\tL Perirhinal Cortex\tL Perirhinal Cortex\t22\t\t\u221230\t-8\t\u221238\nConceptual task context\tConceptual task context\tConceptual task context\tConceptual task context\tConceptual task context\tConceptual task context\tConceptual task context\tConceptual task context\nBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Conceptual RDM \u2013 Brain-Based Conceptual Task RDM\nL Perirhinal Cortex\tL Perirhinal Cortex\tL Perirhinal Cortex\t79\t2.88\t\u221230\t\u221210\t\u221234\nR Parahippocampal Cortex\tR Parahippocampal Cortex\tR Parahippocampal Cortex\t64\t2.94\t30\t\u221224\t\u221224\nL Temporal Pole\tL Temporal Pole\tL Temporal Pole\t61\t2.89\t\u221234\t4\t\u221226\nR Temporal Pole\tR Temporal Pole\tR Temporal Pole\t25\t2.70\t24\t12\t\u221236\nBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\tBehavior-Based Visual RDM \u2013 Brain-Based Conceptual Task RDM\nL Perirhinal Cortex\tL Perirhinal Cortex\tL Perirhinal Cortex\t98\t4.87\t\u221226\t-4\t\u221210\nR Perirhinal Cortex\tR Perirhinal Cortex\tR Perirhinal Cortex\t26\t3.01\t28\t\u221212\t\u221234\nOverlap\tOverlap\tOverlap\tOverlap\tOverlap\tOverlap\tOverlap\tOverlap\nL Perirhinal Cortex\tL Perirhinal Cortex\tL Perirhinal Cortex\t31\t\t\u221226\t-8\t\u221242\nOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\tOverlap across all Behavior-Based RDMs and Brain-Based RDMs\nL Perirhinal Cortex\tL Perirhinal Cortex\tL Perirhinal Cortex\t16\t\t\u221230\t-8\t\u221236\n### Caption\nClusters in which behavior-based RDMs were significantly correlated with brain-based RDMs as revealed using representational similarity searchlight analyses, with corresponding cluster extent, peak z-values, and MNI co-ordinates1.\n### Footer\n1MNI co-ordinates are reported for the peak voxel in individual clusters and the centre of mass for cluster overlap.\n", "metadata": {"pmcid": 5832413, "text_md5": "3ceb92a8905f1506e2054cbcdc521a1d", "field_positions": {"authors": [0, 100], "journal": [101, 106], "publication_year": [108, 112], "title": [123, 227], "keywords": [241, 337], "abstract": [350, 3554], "body": [3563, 79596], "tables": [79609, 84396]}, "batch": 2, "pmid": 29393853, "doi": "10.7554/eLife.31873", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5832413", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5832413"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5832413\">5832413</a>", "list_title": "PMC5832413  Integrative and distinctive coding of visual and conceptual object features in the ventral visual stream"}
{"text": "Wunderlich, Klaus and Symmonds, Mkael and Bossaerts, Peter and Dolan, Raymond\u00a0J.\nNeuron, 2011\n\n# Title\n\nHedging Your Bets by Learning Reward Correlations in the Human Brain\n\n# Keywords\n\n\n\n# Abstract\n  Summary  \nHuman subjects are proficient at tracking the mean and variance of rewards and updating these via prediction errors. Here, we addressed whether humans can also learn about higher-order relationships between distinct environmental outcomes, a defining ecological feature of contexts where multiple sources of rewards are available. By manipulating the degree to which distinct outcomes are correlated, we show that subjects implemented an explicit model-based strategy to learn the associated outcome correlations and were adept in using that information to dynamically adjust their choices in a task that required a minimization of outcome variance. Importantly, the experimentally generated outcome correlations were explicitly represented neuronally in right midinsula with a learning prediction error signal expressed in rostral anterior cingulate cortex. Thus, our data show that the human brain represents higher-order correlation structures between rewards, a core adaptive ability whose immediate benefit is optimized sampling. \n   Highlights  \n\u25ba Humans learn interdependence of multiple environmental outcomes \u25ba FMRI activity in insula pertains to trial-by-trial estimate of outcome correlation \u25ba Correlation estimate updated by prediction error-based learning mechanism \u25ba Subjects are able to use correlation information to make risk optimal choices \n \n\n# Body\n \n## Introduction \n  \nRisk is ubiquitous in nature with predation, starvation, adverse environmental change, or lack of reproductive opportunity acting as constant background variables that shape an animal's behavior. Animals evolved a variety of strategies to minimize risk such as diversifying mating behavior ( ) or \u201cbet-hedging.\u201d For example, desert bees mitigate against large temporal variability in rainfall by stabilizing their birth rate ( ). These risk-spreading strategies act to minimize between-year variance in reproductive success in a similar way to cost averaging, where financial investors periodically purchase risky assets to reduce the overall risk of an investment portfolio ( ). Our concern here is with risk as defined by outcome variability, measured from the variance of an outcome distribution. This is a first-order approximation of risk commonly used as a critical decision variable in ecological ( ) and financial ( ) decision analysis. \n\nAlthough the aforementioned strategies are naive with respect to higher-order structure in the environment, organisms can reduce risk even more effectively if they deploy knowledge of how different environmental states occur in relation to each other by representing correlations ( ). Thus, a lion learning that buffalo congregate at water holes on hotter days can reduce the chance of starvation by allocating more predation time to this food source by simply registering that the weather on a particular day is hot. In effect, knowledge of a covariance structure between discrete events allows inferences as to the presence, or in many instances quantity, of one outcome merely by observing a complementary event without actually having to sample on the inferred one. \n\nRisk minimization is also a key concept in financial and insurance markets. Hedging, the process of combining multiple positions in different assets to reduce total risk in a portfolio is a common risk minimization strategy in financial investments ( ). Modern portfolio theory (MPT) ( ) formalizes the concept of risk-spreading and relies upon correlations between multiple assets to specify how they can be most efficiently combined to maximize returns and minimize risk. Research in decision neuroscience provides extensive evidence for a neural representation of key decision variables ( ) with a focus heretofore on value signals, putative inputs to the decision process such as action or goal values, and representations of expected outcome after a choice ( ;  ). There is now good evidence that\u00a0fundamental computational mechanisms underlying value-based learning and decision-making are well captured by reinforcement learning algorithms ( ) where option values are updated on a trial by trial basis via prediction errors (PE) ( ). More recently, there is an emergent literature that suggests the brain not only tracks outcome value, but also uncertainty ( ) and higher statistical moments of outcomes such as variance ( ) and skewness ( ). \n\nAn important component of outcomes, namely the statistical relationship between multiple outcomes, and what neural mechanisms might support acquisition of this higher-order structure has remained unexplored. In principle, there are several plausible mechanisms including the deployment of simple reinforcement learning to form individual associative links ( ), or a more sophisticated approach that generates decisions based upon estimates of outcome correlation strengths. If the latter strategy is indeed the one implemented by the brain then this entails a separate encoding of correlations and corresponding prediction errors beyond that of action values and outcomes. \n\nHere, we address the question of how humans learn the relationship between multiple rewards when making choices. We fitted a series of computational models to subjects' behavior and found that a model based on correlation learning best explained subjects' responses. Furthermore, we found evidence for a neural representation of correlation learning evident in the expression of functional magnetic resonance imaging (fMRI) signals in right medial insula that increased linearly with the correlation coefficient between two resources, a normalized measure of the strength of their statistical relationship. A correlation prediction error signal, needed to provide an update on those estimates, was represented in rostral anterior cingulate cortex and superior temporal sulcus. These behavioral and neural data provide evidence that subjects learn the correlative strength between rewards and are able to use this information to make risk-optimal choices. \n\n\n## Results \n  \nTo investigate how humans learn correlations between outcomes we scanned 16 subjects using fMRI while they performed a \u201cresource management\u201d game. This task invoked\u00a0a scenario whereby a power company generates fluctuating amounts of electricity from two renewable energy sources,\u00a0a solar plant and a wind park. We instructed subjects to create an energy portfolio under a specific goal constraint necessitating keeping the total energy output as constant as possible ( A). Subjects accomplished this by adjusting weights that determined how the two resources were linearly combined. A normative best performance is achievable by finding a solution that exploits knowledge of the covariance structure of these resources ( B), a task design that approximates a simple portfolio problem in finance. Importantly, the outcomes of the two resources covaried with each other and this correlation between the two outcomes changed probabilistically over time, requiring subjects to continuously update their estimate of the current correlation structure. This task is well suited for assessing subjects' estimate of the correlation strength because a good performance is only accomplished if subjects learn both the distribution of returns for each resource as well as their correlation. We rewarded participants according to how stable they kept the total output of their mixed energy portfolio relative to the variance resulting from an optimal strategy (specified by MPT-calculated optimal weights). \n\n### Behavioral Model Comparison \n  \nWe speculated that subjects might solve the task by learning the correlative strength between the resources via a correlation prediction error, calculated from the cross-product of the individual resources' outcome prediction errors ( C). This envisages that subjects represent a continuous measure of outcome correlation and update this metric on a trial-by-trial basis. To rule out alternative strategies we examined other computational models that could be used to guide choice in our task, and fitted the free parameters of each model to get model predicted portfolio weights that most closely resembled the actual responses for each subject. \n\nOne such alternative model-based strategy is to exploit trial-by-trial evidence to update a representation of the portfolio weights directly instead of first estimating the correlation coefficient. Similar to correlation learning, this model makes assumptions about the structure of the task and uses individual resource outcomes as a basis for learning. The main difference between the covariance based model and this model is that in the former, subjects update an estimate of the correlation via a prediction error and then translate this correlation strength into task-specific weights on every trial, whereas in the latter the estimates of task-dependent weights (i.e., the position on the response slider) are learned directly. This differentiation is important because the correlation coefficient is a normalized and therefore universal measure of the interdependence between the two outcomes, whereas appropriate mixing weights are task-specific and would need to be relearned if the variances of the individual outcome change or the goal of the task changes from risk minimization to maximization. Both of these strategies are model-based as they require an understanding of how the two individual outcomes interact. There are other potential modes of learning that we also consider. For example, subjects might implement a more simple model-free reinforcement learning based on Q-learning of action values for increasing or decreasing the weights. In contrast to the former approaches requiring subjects to attend to the individual resource outcomes, a subject who updates action values in this model-free way would instead consider the mixed portfolio outcome in every trial and try to minimize its temporal fluctuation using simple outcome based updating. Any change in behavior following a change in correlation between resources would then be due to a relearning of a new optimal mix of actions rather than a more complete knowledge of the structure of the environment. Finally, subjects might use a heuristic of detecting coincidences in the occurrence between outcomes, without a full representation of the strength of correlation. \n\nOut of all tested models, the model based on tracking the correlation coefficient best predicted subjects' behavior ( A and  ). The weights estimated by this model match subjects' behavior very well, as shown by a comparison of model predictions and subjects' actual choices ( B) with the regression of actual observed weights on model predicted weights being highly significant in every individual subject (p\u00a0< 0.0001; average R  [standard coefficient of determination] across subjects\u00a0= 0.77; see   available online). In fact, subjects' responses approximated normatively optimal portfolio weights while subjects attempted to keep the total energy output stable (minimize variance) ( C). Both model predicted and\u00a0subjects' actual responses approach normatively optimal weights with some lag, the latter resulting from a need to have multiple observations to reliably detect any change in correlation strength. In effect, subjects' strategy of determining the correlation approximately compared to a normative calculation of the correlation coefficient over the outcomes of the past ten trials. \n\n\n### Neural Representation of the Correlation Strength \n  \nIf the brain learns the relationship between two rewards by estimating their covariance then this predicts that we should observe a neural representation of the computations that support this process. Consequently, we tested for fMRI signals that track the covariance or correlation strength, and because the outputs vary, there should also be a signal that updates this information. Based on prior evidence, we predicted activity related to covariance would be seen in insular cortex or striatum, areas implicated in encoding the risk or variance of individual outcomes ( ). Consequently, we modeled subjects' trial-by-trial estimates of the correlation coefficient and regressed those model-predicted time series against simultaneously acquired fMRI data. We found BOLD activity in right midinsula varied with the correlation strength between the outputs of the solar and wind power plants (xyz\u00a0= 48, 5, \u22125; Z\u00a0= 4.12; p\u00a0< 0.001 familywise error (FWE) corrected;  A). Right insula was the only region to survive cluster level whole brain correction and we provide a comprehensive list of all activated areas at a lower threshold (p\u00a0< 0.001 uncorrected) in  . \n\nWe next determined whether the correlation strength is represented either as covariance, a raw measure of how much the two variables fluctuate together, or as the correlation coefficient, a scale invariant metric of the covariance normalized by the standard deviation of each resource. We estimated two additional models using Bayesian estimation, with either the covariance or the correlation coefficient as parametric modulator, and compared the ensuing log-evidence maps in a random effects analysis. Activity in right midinsula was better described by the correlation coefficient than by covariance (exceedance probability of p > 0.999). The linear relationship between correlation coefficient and BOLD is visualized in a binned effect size plot ( B). \n\nWe then verified whether this signal was more strongly represented at the time of outcome, when new evidence is available to update estimates, or at choice when subjects actively readjust their allocated weights for the two resources ( C). In addition to plotting the effect time course we tested these neural hypotheses by estimating a design where the correlation coefficient acted as an unorthogonalized parametric modulator of activity at both the time of outcome and time of choice. In this analysis we observed significant effects of correlation strength solely at the outcome time (Z\u00a0= 3.60, p\u00a0= 0.01 FWE corrected) but not at the time of choice (Z\u00a0= 2.40, p\u00a0= 0.02 uncorrected). \n\nIf our behavioral model explains subject's choices and subjects' brain activity represents crucial decision variables in this process then we would expect that brain activity should be particularly well explained in those subjects in whom our model also provides a good choice prediction. This would be expressed in a relationship between the behavioral model fit and the model fit in the general linear model (GLM) against BOLD data. Consistent with our conjecture, we found a significant positive correlation between R  in the behavioral model and R  in the MRI analysis (r\u00a0= 0.50, p\u00a0< 0.03;  D). In effect, this confirms that our model explains a larger proportion of the fluctuation in the neuronal data in those subjects in which the model can also well explain choices. \n\n\n### Neural Correlates of Correlation Prediction Errors \n  \nA neural representation of correlation strength in our task entails that this estimate is updated over time, a process ascribed to a prediction error signal. Analogous to risk prediction errors for individual rewards ( ), the cross-products of the two outcome prediction errors provide a trial-by-trial estimate of the covariance strength. Using this regressor we found that a correlation prediction error was tracked in fMRI activity in left rostral cingulate cortex (xyz\u00a0= \u221215, 44, 7; Z\u00a0= 4.87; p\u00a0< 0.003 FWE corrected;   and  ). \n\n\n### From Correlation to Portfolio Weights \n  \nAfter observing an outcome, participants may have an imperative to change the slider position if their currently set weights deviate from the estimated new best weights, in other words if they are suboptimal. We tested for a signal corresponding to the absolute (i.e., unsigned) deviation between current and new weights on the next trial and found corresponding BOLD activity in a region encompassing anterior cingulate (ACC)/dorsomedial prefrontal cortex (DMPFC) (xyz\u00a0= 6, 26, 34; Z\u00a0= 4.22; p\u00a0< 0.001 FWE corrected) and in right anterior insula (xyz\u00a0= 42, 23, \u22125; Z\u00a0= 4.04; p\u00a0< 0.04 FWE corrected) at the time of the outcome (  and  ). In contrast, no areas corresponded directly to the portfolio weight values or a signed updating of weights, signals one would expect if subjects performed learning over task-specific weights instead of the correlation structure between outcomes. \n\nFinally, an optimal solution to our task requires learning of the individual outcome variances in addition to learning the covariance structure. When we tested for neural activity coupled to local temporal fluctuations in the individual outcome variances we replicated previous findings in highlighting a neural representations of outcome risk in striatum (xyz\u00a0= \u221218, 5, 10; Z\u00a0= 3.81; p\u00a0=\u00a00.04 small volume corrected;  ). \n\n\n### Alternative Model Considerations \n  \nAs an alternative to learning the correlation coefficient subjects might directly learn the weight representation and perform RL over the weights instead of the correlation coefficient. If that were the case then one would also expect to find a neuronal representation of the weights and weight prediction errors, which were conspicuously absent in our data. Another possibility could be that subjects simplified the problem to detecting outcome coincidences (both outcomes either above or below mean versus one outcome above and the other below mean) instead of fully quantifying the trial-by-trial covariance. In that case we would expect to find a neural signal pertaining to mere outcome coincidences. We found no activations coupled to either the weight or the weight prediction errors, or the trial-by-trial coincidences anywhere in the brain at our omnibus cluster level threshold of\u00a0p\u00a0< 0.05. Together with the inferior behavioral fit of the coincidence model this suggests that subjects quantified the trial-by-trial relationship between outcomes. We also implemented a model-free Q-learning algorithm as further alternative strategy, which was clearly outperformed by the correlation model. \n\n\n\n## Discussion \n  \nWe show that human subjects are adept at learning correlations between two dynamic variables, a process also represented neurally. Subjects were highly effective at exploiting this key metric of the statistical relationship between the two individual resources to guide choice in a task requiring minimization of outcome fluctuations. This finding is in contrast to an often-proposed model in behavioral finance, which suggests disregarding environmental structure and using fixed weights according to the 1/N rule ( ). Our subjects performed better than this simple heuristic and learned a more optimal strategy through repeated observations. At\u00a0a neural level, fMRI signals in right midinsula were coupled to the current correlation coefficient, whereas activity in rostral anterior cingulate encoded a correlation prediction error, a signal used to update an estimate of the correlation strength based on new evidence in every trial. \n\nAlthough learning individual outcomes is a central part of decision making, the availabilities of different rewards are rarely independent of each other in a natural environment. Our results provide evidence that subjects also learn the relationship between multiple outcomes by tracking their correlation, and this information can be used to decrease overall sampling risk. Commonly observed risk aversion in animals ( ) and humans ( ) is rational in an evolutionary context, as a small but constant supply of food that always exceeds the critical minimum for survival is far more beneficial to viability than periods of alternating deficiency and extreme excess. In some other instances, risk-seeking behavior may occur, such as in gamblers, and may promote exploration and learning. Note, however, that also in that case a representation of the correlation in the environmental structure is beneficial, as this information can be used both for risk minimization or maximization. \n\nTo generalize our results to more natural situations, we have to\u00a0ascertain that the findings reflect a specific mechanism of correlation learning instead of incidental task variables. Plausible possibilities include shortcuts such as learning the position on the response slider by a model-free gradient descent mechanism or using a model-based strategy, but without representing individual outcome variances and normalized correlation coefficients and instead directly learning a representation of the portfolio weights. Our behavioral and neural data render all these explanations very unlikely. The best-fitting learning rate for outcome variance is similar to the learning rate for correlation and significantly above the one for value for each individual subject. Importantly, we ensured that the signals in our study were not spurious reflections of the individual variances of solar and wind plant outputs by explicitly modeling these signals with\u00a0additional (unorthogonalized) parametric regressors. A fluctuating trial-by-trial estimate of the outcome variance is also represented neurally in striatum ( ), an area previously implicated in variance learning ( ). Although these neural signatures of risk and risk prediction errors were somewhat weaker compared to covariance signals, we suggest this observation is due to an amalgamation of signals tracking the two separate resource variances within the same area, and because the variance of the two outcomes fluctuated only slightly over the course of each experimental block. Importantly, we found no significant correlations with signals pertaining to alternative decision models anywhere in the brain at p\u00a0< 0.05 corrected. Specifically, we examined if there was evidence for a direct representation of desired resource weights, or weight prediction errors, signals one would expect instead of the correlation coefficient if subjects used a more task-specific strategy. We also did not find significant correlations with a more qualitative measure of coincidences instead of fully quantified correlations. Together with a superior behavioral fit of the correlation learning model, this strongly supports the specificity of our neural results and effectively discounts the possibility that the observed activations here relate to incidental task related learning processes instead of learning the correlation between outcomes. \n\nWe found that anterior insula tracked the correlation strength between the outputs in a site slightly posterior to regions previously implicated in tracking variance ( ). Combined, these findings suggest that insular cortex may support a general role in processing statistical information about the environment. At the same time, anterior insula has been implicated in representing bodily states and their translation into feelings and possibly awareness ( ). Note that the calculus-like role proposed here does not contradict the idea that anterior insula represents subjective aspects of experience. Indeed, the somatic marker hypothesis postulates that rational decision theory requires emotional anticipation of outcomes ( ), such that seemingly prudent behavior and emotional decision making are intertwined ( ). The finding of a slightly posterior encoding of correlation relative to risk also tallies with a structural model for how unconscious state representations might be integrated into a sentient self along a posterior to anterior insula ( ). Adequate emotional risk assessment is immediately relevant for fight or flight responses and might therefore require a more direct link to awareness then the meta parameters of how multiple such variables relate to each other ( ). The latter assessment is largely subconscious and may, as implicit function, also be enacted during low-level processing of multidimensional stimuli such as music and rhythm. Interestingly, such tasks have previously been associated with insula activation ( ). Our data show that the brain encodes the correlation coefficient of two outcomes, a normalized value, instead of the covariance itself. In light of previous data ( ), this hints that scale invariance is a ubiquitous concept in encoding decision variables in the brain. \n\nThe representation of a prediction error in anterior cingulate fits neatly with mounting evidence that this area is involved in learning and behavioral control. Several previous studies report a role for anterior cingulate in an error-driven reinforcement learning system ( ), and in prediction errors for actions ( ) or social value ( ). Together with risk prediction errors in anterior insula ( ), this teaching signal for correlation strength might belong to a broader system involved in learning the statistical properties of the environment. \n\nWe also observed an anticipatory signal reflecting an impetus to shift resource allocations on the next trial in order to keep the\u00a0total energy output stable. Interestingly, this signal was expressed in a DMPFC cluster previously linked to updating learning in relation to environmental volatility ( ), implying a more general role for this region in adapting behavior to fluctuations in the statistical characteristics of the environment. Most task-modulated activity, including correlation strength, its prediction error, and a signal reflecting the need to alter responses, occurred at the time of outcome rather than at choice. This suggests that task-relevant computations, including an evaluation of the appropriate action to take after each outcome, occur at the point when individuals can best harvest new evidence. As we focused on the mechanism of learning the correlation strength, rather than on how subjects use this information, this raises the question of how exactly information about a covariance structure is applied in a natural sampling environment. Here, we instantiated this mapping of correlation coefficients into energy resource weights by using the normative function derived from MPT. We assume subjects learned the form\u00a0of this nonlinear transformation during initial training, but it remains a question for future research how this translation is applied. Based on our present results and previous findings that the brain encodes other statistical parameters such as variance and skewness of outcomes ( ), we speculate that in more naturalistic environments subjects form structural representations of the world by encoding summary statistical parameters. Such\u00a0a parameterized representation is both efficient and flexible: the optimal response is dependent upon three parameters\u2014the magnitude, variance and correlation of the available resources\u2014and knowledge of the individual parameters allows fast adaptation in light of changes to any one of them. One way to expand our research to more natural situations could be by changing the cost function to mimic an ecological survival game with perishable outcomes. Such a paradigm would allow one to determine if subjects indeed follow a variance minimizing strategy and incorporate information about reward correlations. \n\nThe recent financial crisis has amply demonstrated that even experts have difficulties regulating correlated risks in the financial domain and investors often deviate from rationality when making financial decisions ( ). In contrast, we show here that individuals are adept at detecting and responding to correlations and appropriately selecting actions to minimize risk in an intricate learning task. Indeed, this exquisite sensitivity taps into an adaptive and evolutionary conserved ability of implicit neurobiological systems to\u00a0learn environmental reward structure through trial-by-trial sampling; intrinsic behavior that might even supersede that of financial experts deciding about explicitly described statistics. \n\n\n## Experimental Procedures \n  \n### Subjects \n  \nSixteen healthy subjects (7 female; 18\u201335 years old) with no history of neurological or psychiatric illness participated in the study. Two additional pilot subjects from the lab were excluded from the final analysis, as they were already familiar with the hypotheses in the experiment. The study was approved by the Institute of Neurology (University College London) Research Ethics Committee. \n\n\n### Task \n  \nTo investigate whether and how subjects learn the reward structure in the environment we designed a portfolio-mixing task in which knowledge of the correlation between two resource outcomes could improve performance. Subjects' task was to keep the combined output of two power stations as stable as possible (i.e., minimize the variance of an energy portfolio) by mixing the fluctuating outcomes of these two individual resources. They accomplished this by adjusting weights that determined how the resources were linearly combined. A normative best performance is achievable in this task by finding a solution that directly depends on knowledge of the covariance structure of these resources, a task design that approximates a simple portfolio problem in finance ( ). \n\nWe presented the task to subjects as a resource management game that invoked a scenario whereby a power company generates fluctuating amounts of electricity from two renewable energy sources, a solar plant and a wind park. The resource outputs r  and r  were drawn as random numbers in every trial from distributions with a common mean M and variances \u03c3  and \u03c3 . Importantly, the two outcomes covaried with each other, and the strength of this correlation changed probabilistically over time. This feature encouraged subjects to form an estimate about the mean and variance of the individual outcomes and continually update their assumption about the correlation strength. \n\nSubjects participated in three consecutive experimental blocks, each corresponding to a 21\u00a0min long session in an fMRI scanner (Siemens Trio 3T). They were instructed that the correlation would probabilistically change over the course of the study but were not given further details about specific parameters used. We also told subjects that the mean and variance of the two resources would remain constant over one block of the experiment, a simplification to an otherwise quite complex task that enabled subjects to perform well within the settings of this experiment. As our goal was to assess covariance learning (in contrast to learning the values and risk) this did not adversely impact on any mechanism we wanted to observe. However, mean and variance values were different for each block. To give subjects the opportunity to learn these basic statistical parameters (mean and variance) before making portfolio choices, we presented them with a 20-trial observation phase at the beginning of each session. In this phase, which immediately preceded the start of fMRI data acquisition, subjects only observed the individual outcomes of the two resources and did not make any choices. There was no change in the ground truth correlation during this phase. Data from pilot studies and model simulations confirmed that 20 observations of a time series were sufficient to form an estimate of its mean and variance. The observation phase was followed by 84 choice trials, consisting of a 5\u00a0s choice period and a 3\u00a0s outcome period, separated by a blank gray screen of 1\u20136\u00a0s duration (uniform distribution). The intertrial-interval was also 1\u20136\u00a0s ( A). \n\nThe portfolio weights (w , w ) indicate how much of a fraction the portfolio contains from both resources r  and r  (portfolio outcome value V \u00a0= w r \u00a0+ w r ). Subjects were allowed to set the portfolio weight w  within a range between \u22121 and 2. Setting negative weights allowed subjects to trade-in a fraction of the trials output from one resource in exchange for multiplying the other output by the same fraction. This concept echoes the possibility of short selling in financial markets and is important for this task as it permits risk minimizing for positively correlated resources (see the section on variance minimizing strategies in the   for further details). The constraint that both weights always add up to 1 automatically determined the weight of the other resource (w \u00a0= 1\u00a0\u2212 w ). A horizontal line on the choice screen represented the slider during the choice period and icons of a solar and wind plant on both ends indicated which resources were mixed in the portfolio. The parts of the slider involving a negative weight were red and the middle part with both positive weights was shown in white with the center position corresponding to a mix with equal weights. A yellow dot on the slider indicated the current position and portfolio weights were additionally shown numerically next to the resource icon. Subjects were able to make responses during the entire 5\u00a0s choice period by pressing two buttons on a button box with their right hand. Each button press moved the current slider position a discrete step of 0.1 units in either direction. Moving the slider a step toward the right always increased the weight for sun and decreased the weight for wind. A new choice period started with the portfolio weights from the last trial and subjects were allowed to freely move the slider as many steps in either direction as they wished during the choice period. Importantly, subjects always had to determine the weights for the current trial prior to seeing the actual outcome. Due to inherent stochastic outcomes, and because serial outcomes were independently drawn, the only rational strategy was to set the weights in a way that would yield the least portfolio variance in the long run and this measure depended on the current correlation. \n\nTo determine subjects' performance we benchmarked their portfolio fluctuation against the fluctuation of a portfolio with optimal weights. The normative solution was calculated by the risk minimizing formula of portfolio theory (see   for details). This ensured that subjects were fairly scored given the stochastic outcomes on a trial-by-trial basis (i.e., even if subjects played optimally the portfolio outcome would fluctuate around the target with the amount of fluctuation dependent on the current covariance). Subjects received reimbursement of 10\u00a3 flat plus a fraction of the maximum bonus of 45\u00a3 in relation to task performance ( ). All participants received basic instructive information about hedging strategies (similar to the   variance minimization strategies and  ) and practiced the task (same number of trials than in the fMRI study but with different parameters for outcome mean and variance) on a separate day prior to scanning. Note, however, that all instructions concerned exclusively how to set portfolio weights (i.e., how to respond) but not how to learn correlations itself. Therefore this latter process cannot be confounded by the explicit information given here. The reason for using a seemingly intricate portfolio task over having subjects merely report the correlation directly is that explicit assessments of decision variables by self-report are often biased ( ). Our procedure is in this respect very similar to other commonly used behavioral measures such as auction bidding ( ) to identify subjects' unbiased value preference. Another advantage of our task is that response behavior does not depend on individually subjective valuation or risk preference. Performance and payout were only related to how close subjects' behavior matched the normative optimal solution (thereby incentivizing an accurate correlation representation) but was independent of the actual amount or variance of the produced energy mix. \n\nImportantly, during the experiment subjects never received direct feedback on their performance at minimizing energy fluctuations (i.e., only saw trial-by-trial outcomes) and the bonus and optimal weights were only revealed after the experiment. We omitted feedback during the task to prevent subjects from using a strategy that is based on optimizing the performance feedback instead of learning the correlation of the individual outcomes. Although the portfolio value is shown on every trial, and the deviance of this value from its mean gives some hints to performance, this is only a crude measure of whether the current weights are good because even with optimal weights the amount of portfolio fluctuation depends on the current correlation. \n\nBecause the optimal mixing weights (portfolio weights) in our task depend on individual variance from solar and wind power plants and their correlation strength, the best strategy is to learn the variances and correlations by observation of individual outcomes and then translate these estimates into an optimal resource allocation (i.e., weightings). Although subjects could learn the statistical properties underlying outcome generation by observation, the outcomes of individual trials were unpredictable. Their task was then to continuously mix the two resources into an energy portfolio and thereby minimize the fluctuation of the portfolio value from trial to trial. \n\n\n### Generation of Outcome Values \n  \nBoth resources fluctuated around a common mean, with outcomes drawn from a rectangular distribution with a specific variance. In our task the standard deviation of one resource was always twice that of the other because this maximized the influence of the correlation on the portfolio weights (see   for details). The sequence of correlated random numbers for the two resources were generated by the Cholesky decomposition method ( ). This was realized by first drawing random numbers x  and x  for resources A, B from a rectangular distribution. The outcome of the second resource x  was then modified as x \u00a0= x  r\u00a0+ x  sqrt(1\u00a0\u2212 r ), whereby r is the generative correlation coefficient. Finally, x  and x  were normalized to their desired standard deviations (in the three blocks: 20/10, 15/30, 10/20) and common means (30, 50, 40). We chose a rectangular distribution to increase the sensitivity of our fMRI experiment in finding neural correlates of covariance and covariance prediction errors as the linear regression against BOLD activity is most sensitive if the values of the parametric modulators are distributed along their entire range. This is not true for normal distributed outcomes, which have proportionally the largest amounts of data close to the mean. \n\nWe varied the generative correlation strength in discrete steps of \u22120.99, \u22120.3, 0.4, 0.7, 0.95, and 0.999. The observable correlation through sampling by the subject will, however, very on a continuous scale also between these steps due to Stochasticity in the outcomes. A change from the current to\u00a0a new correlation was determined probabilistically in every trial with a p\u00a0= 0.3 transition probability, under the constraint that a change would only occur after the new correlation became theoretically detectable by an ideal observer that was tracking the correlation coefficient in a sliding window over the past five trials. In detail, after the normatively estimated correlation based on the last five trials (similar to the sliding window model below) approached the new generative correlation (with a deviation <0.2), the correlation was allowed to change on all further trials. This prevented overly rapid changes in the generative correlation before subjects could have possibly detected the new correlation coefficient from outcome observations. On average (across subjects and sessions) the correlations changed every ten trials. To discourage subjects from persevering on a more favorable spot of the response scale that would give a reasonable result over a wider range of correlations, and instead be forced to track the correlation explicitly, we further implemented an adaptive rule that if subjects' response was both suboptimal (farther from the optimum than 0.2) and they did not change their response within the past five trials then the correlation would jump to the farthest extreme (either \u22120.99 or +0.999). This increased the penalty on subjects payout at their current weights and encouraged them to find a better weight allocation. In practice, this constraint came rarely (never for 10 subjects, one or two occurrences in\u00a0five, and three occurrences in one subject) into use during the fMRI experiment. \n\n\n### Correlation Learning Model \n  \nWe modeled trial-by-trial values of the correlation strength by using principles of reinforcement learning ( ). Reinforcement learning generates in every trial a prediction error as the deviation of the experienced outcome R from the predicted outcome. Those prediction errors, multiplied by the learning rate, are then used to update predictions in future trials: and \n\nThe squared prediction error is also a measure of the outcome fluctuation and thereby a quantifier of risk. A sequence of continuously large prediction errors indicates that the outcomes greatly fluctuate, whereby a sequence of small prediction errors indicate that prediction is precise with little deviation. We used this to model the risk h for both resources: and \n\nWe then extended this model from independent outcomes to the interaction of outcomes, whereby the product of the individual prediction errors measures the covariation of two outcomes: and \n\nThe correlation coefficient \u03c1 was then defined as the covariance normalized by the individual standard deviations of the two involved outcomes: \n\nIn every trial the correlation coefficient was finally translated into a position on the response slider using the normative function (h  \u2013 cov )/(h \u00a0+ h  \u2013 2   cov ), which is derived in the  . This relationship ( ) did not change over the entire course of the experiment (because we always used the same ratio of 1:2 between outcome \u03c3). \n\nWe kept the mean of the resource outcomes constant during each session and therefore the optimal strategy was indeed to not update those variables once a reliable estimate had been formed during the observation phase of each block. In fact, the best-fitting learning rate for resource values was consistently very small across subjects (average 0.08), confirming that, as intended by the design, subjects indeed treated the mean as a stable value after the initial observation period and adjusted their learning rate downward to reflect this steady nature ( ). \n\nWe investigated whether subjects used different learning rates for variance and covariance learning or whether these processes could be described by a single parameter. We did this by comparing a model with separate parameters for variance and covariance learning with a model that used a common parameter for both learning processes. We found that the reduced model could describe learning as well as the full model if model complexity is considered ( ). Note that both overall mean value and variance were constant during the experiment but the best-fitting learning rate for variance was higher than for value. This suggests that, in contrast to mean outcome value, subjects continuously updated their estimate of individual risk in response to local temporal fluctuations in the individual variances. \n\nWe therefore used the reduced model with a common risk/covariance learning parameter to generate fMRI regressors. Parameter estimates were fit for every individual subject using least-squares minimization between model predicted weights and actual weights set by the subject (see below). \n\n\n### Alternative Models \n  \nWe created several alternative models that do not require learning of covariance information. Those models are described in the  . \n\n\n### Model Comparison \n  \nWe compared how well each model predicted subjects' behavior by fitting the free parameters of each model such that the mean squared sum of the deviation between model predicted (w ) and subjects' weights (w ) was minimized. As measure of model fit we then calculated the Bayesian information criterion (BIC) ( ) as and where   L   is the negative log likelihood function, n\u00a0= 252 trials and   k   the number of free model parameters ( ). We also calculated a generalized r -statistics for each model, which is a standardized measure of model fit analogous to accounted variance ( ). It is computed as  . \n\n\n### Stimuli \n  \nStimuli were presented on a gray background using Cogent 2000 ( ) running in MATLAB. Stimuli were presented using an LCD projector running at a refresh rate of 60\u00a0Hz, viewed by subjects via an adjustable mirror. \n\n\n### FMRI Data Acquisition \n  \nData were acquired with a 3T scanner (Trio, Siemens, Erlangen, Germany) using a 12-channel phased array head coil. Functional images were taken with a gradient echo T2 -weighted echo-planar sequence (TR\u00a0= 3.128 s, flip angle\u00a0= 90\u00b0, TE\u00a0= 30\u00a0ms, 64\u00a0\u00d7 64 matrix). Whole brain coverage was achieved by taking 46 slices in ascending order (2\u00a0mm thickness, 1\u00a0mm gap, in-plane resolution 3\u00a0\u00d7 3\u00a0mm), tilted in an oblique orientation at \u221230\u00b0 to minimize signal dropout in ventrolateral and medial frontal cortex ( ). Subjects' head was restrained with foam pads to limit head movement during\u00a0acquisition. Functional imaging data were acquired in three separate 415-volume runs, each lasting about 21\u00a0min. The first five volumes of each run were discarded to allow for T1 equilibration. A B0-fieldmap (double-echo FLASH, TE1\u00a0= 10\u00a0ms, TE2\u00a0= 12.46\u00a0ms, 3\u00a0\u00d7 3\u00a0\u00d7 2\u00a0mm resolution) and a high-resolution T1-weighted anatomical scan of the whole brain (MDEFT sequence, 1\u00a0\u00d7 1\u00a0\u00d7 1\u00a0mm resolution) were also acquired for each subject. \n\n\n### FMRI Data Analysis \n  \nImage analysis was performed using SPM8 (rev. 3911;  ). EPI images were realigned and unwarped using field maps ( ). Each subject's T1 image was segmented into gray matter, white matter, and cerebrospinal fluid, and the segmentation parameters were used to warp the T1 image to the SPM Montreal Neurological Institute (MNI) template. These normalization parameters were then applied to the functional data. Finally, the normalized images were spatially smoothed using an isotropic 8-mm full-width half-maximum Gaussian kernel. \n\nFMRI time series were regressed onto a composite general linear model (GLM) containing regressors representing the time of the choice, the time of the outcome screen, and any button presses during the choice period. The outcome regressor was modulated by a number of model derived decision variables. Modulators for outcome were: prediction errors for the individual resource outcomes and the portfolio outcome (\u03b4 , \u03b4 , \u03b4 ), the absolute deviation of the portfolio outcome from the target (|\u03b4 |), resource risk (h , h ), risk prediction errors (\u03b5 , \u03b5 ), the correlation strength of the resources (\u03c1), and the correlation prediction error (\u03b6). A further modulator captured the anticipated magnitude of actual weight updating in the next trial (|w  \u2212 w |). In contrast to the default procedure in SPM, we entered all regressors and modulators independently (without serial orthogonalization) into the design matrix. Thereby only the additional variance that cannot be explained by any other regressor is assigned to the effect, preventing spurious confounds between regressors ( ). Specifically, this ensured that the observed effects of correlation strength and correlation prediction error are solely accountable by effects not explained by signals relating to the variance of individual outcomes. \n\nThe regressors were convolved with the canonical HRF, and low frequency drifts were excluded with a high-pass filter (128\u00a0s cutoff). Short-term temporal autocorrelations were modeled using an AR(1) process. Motion correction regressors estimated from the realignment procedure were entered as covariates of no interest. Statistical significance was assessed using linear compounds of the regressors in the GLM, generating statistical parametric maps (SPM) of t values across the brain for each subject and contrast of interest. These contrast images were then entered into a second-level random-effects analysis using a one-sample t test against zero. \n\nAnatomical localization was carried out by overlaying the t-maps on a normalized structural image averaged across subjects, and with reference to an anatomical atlas ( ). All coordinates are reported in MNI space ( ). Unless otherwise noted, all statistics are FWE corrected at the cluster level for multiple comparisons at p\u00a0< 0.05 with a height threshold of p\u00a0< 0.001 (using the cluster level statistics implementation within SPM). Small volume correction in the outcome variance contrast for striatum was performed within a 12\u00a0mm sphere around the seed voxel coordinates (xyz\u00a0= \u221210, 3, 3), which were taken from  . \n\n\n### Region of Interest Analysis \n  \nWe extracted data for all region of interest analyses using a cross-validation leave-one-out procedure: we re-estimated our main second-level analysis 16 times, always leaving out one subject. Starting at the peak voxel for the correlation signal in right insula and for the correlation prediction error in rACC we selected the nearest maximum in these cross-validation second-level analyses. Using that new peak voxel, we then extracted the data from the left-out subject and averaged across voxels within an 8\u00a0mm sphere around that peak. \n\n#### Binned Effect Size Plots \n  \nTo create the effect size plots of the parametric decision variables we first divided the values in our parametric modulator into quartiles and estimating the average BOLD response in relation to each bin. We did this by sorting all trials into four bins according to the magnitude of the model predicted signal and defined the 25th, 50th, 75th, and 100th percentile of the range. Then we created and estimated for each subject a new GLM with four new onset regressors containing the trials of each bin. The parameter estimates of these onset regressors represent the average height of the BOLD response for all trials in that bin. The data plots in Figures  B and  B are the average parameter estimates (across all subjects in the cross-validation analyses) converted to percent signal change. This analysis was performed using algorithms in the rfxplot toolbox for SPM ( ). \n\n\n#### Covariance/Correlation Comparison \n  \nFor the test whether bold activity in right insula is better explained by a linear relationship with covariance or correlation we estimated two additional GLMs on BOLD data, each with only one regressor (either model predicted covariance or the correlation coefficient) using Bayesian estimation ( ). This produced a log-evidence map for each model and we calculated average log evidences across all voxels within our region of interest for every subject and performed a random effects model comparison ( ). This analysis suggests that the correlation coefficient can explain BOLD activity\u00a0in midinsula better than covariance (Dirichlet \u03b1\u00a0= 16.9 for correlation versus 1.1 for covariance; posterior probability [correlation] p\u00a0= 0.94, exceedance probability ]probability that the correlation model is more likely] \u22481.0). \n\n\n#### Effect Size Time Course Plots \n  \nTo visualize the nature of the BOLD response to the correlation coefficient as time course plot over the entire trial we upsampled the entire extracted bold signal to 100\u00a0ms (the effective temporal resolution of the averaged time course is higher than the TR because our stimulus presentation was jittered relative to slice acquisition), split the signal into trials and resampled such that the onset of the choice screen is at time 0 and the onset of the outcome screen at 8.5\u00a0s in every trial. We then estimated a GLM across trials for every time point in each subject independently. Lastly, we calculated group average effect sizes at each time point, and their standard errors. The graph in  C shows the time series of effect sizes throughout the trial for the regressor of interest. This method for plotting the effect size time course of a parametrically modulated regressor is also described in detail elsewhere ( ). \n\n\n#### Timing of Correlation Representations \n  \nTo investigate whether subjects carried out task related computations at the time of the outcome or at the time of choice, we estimated a separate GLM that was similar to the main GLM described above except for an additional parametric modulator at the time of choice for the correlation coefficient, i.e., the correlation coefficient modulated both the regressor at the time of the choice screen and the outcome screen. \n\n\n#### Representation of Portfolio Weights \n  \nWe investigated the questions if subjects might learn task-specific portfolio weights instead of the more universal correlation between outcomes by estimating a separate GLM. This was similar to the main GLM except that the parametric modulator \u03c1 was replaced by the portfolio weight w and the correlation prediction error \u03b6 was replaced by the signed weight prediction error (w  \u2013 w ). The nonlinear relationship between \u03c1 and w allows us to differentiate between representations of correlation and weights on the neural level. \n\n\n#### Representation of Outcome Coincidences \n  \nTo test for a neural representation of more qualitative coincidences instead of the correlation coefficient with estimated another GLM, similar to the main GLM except that the parametric modulators \u03c1 and \u03b6 were replaced by a binary parametric modulator with a coincidence value of sign(td ) sign(td ). \n\n\n#### Relationship between Explained Variance in Behavioral Model and BOLD Data \n  \nTo test for a relationship between behavior and neural model fit we compared R  (explained variance) in the behavioral model with the R  in the fMRI GLM. An R  value for the behavioral model was calculated for every subject by regressing trial-by-trial model predicted choice on subject's actual choices. We calculated the R  value for the fMRI regression as the proportion of variance in BOLD that was explained by our interest regressors in relation to the total variance (R \u00a0= RSS /RSS ), where RSS  equals the explained variance (variance of the predicted time course y \u00a0= Xb, X\u00a0= design matrix and b the regression coefficient) and RSS  is the variance of the bold signal after adjusting for block and nuisance effects. \n\nWe also tested the influence of potential confounding variables on this relationship, namely the fitted learning rate and the average absolute amount of weight updating per trial, by calculating partial correlations. This analysis confirmed a significant correlation between behavioral and neural fit (r \u00a0= 0.54, p\u00a0= 0.04) after accounting for potential confounds. Furthermore, there was no relationship between these potential confounds and neural fit (r \u00a0= 0.12, p\u00a0= 0.66; r \u00a0= \u22120.14, p\u00a0= 0.63). \n\n\n#### Psychophysiological Interaction (PPI) Analysis \n  \nWe performed posthoc an exploratory PPI analysis ( ) to investigate changes in functional connectivity with right midinsula at the time of outcome (when almost all task related activity was observed). The PPI term was Y \u00d7 P, with Y being the BOLD time courses in the insula region of interest analysis and P indicating the time during the outcome screen. We then entered the seed region BOLD Y, the psychological variable P, and the PPI interaction term into a new GLM. Findings from this analysis are reported in  . \n\n\n\n \n\n# Table(s)\n## ID: tbl1\n### Label: Table 1\nModel/Parameters\tCorrelation (var/cov)\tCorrelation (val/var/cov)\tQ-Learning\tCoincidence\tSliding Window\t1/N\tRandom Choice\n\u03b1-Val\t0.08\t0.08\t\t\t\t\t\n\u03b1-Risk\t0.25\t0.25\t\t0.16\t\t\t\n\u03b1-Cov\t0.25\t0.26\t\t0.34\t\t\t\nLearning rate\t\t\t0.23\t\t\t\t\nW step width\t\t\t0.1\t\t\t\t\nWindow length\t\t\t\t\t9.93\t\t\nN parameters\t2.0\t3.0\t2.0\t2.0\t1.0\t0.0\t0.0\nNLL\t87.92\t86.2\t197.2\t142.93\t110.96\t283.85\t384.67\nr2\t0.77\t0.78\t0.49\t0.61\t0.71\t0.26\t0.0\nBIC\t186.9\t188.99\t405.45\t296.92\t227.44\t567.69\t769.35\nr2 forecast\t0.77\t0.77\t0.4\t0.56\t0.7\t0.26\t0.0\n### Caption\nModel Comparison and Model Fit\n### Footer\nMedians of best-fitting parameters for the compared learning algorithms. Parameters were fit to individual subjects across the three scanning blocks. The (pseudo) r2 value measures how well the model can capture subjects' behavior (see Experimental Procedures). The r2-forecast measure uses a similar normalization to quantify how well the model could estimate the ground truth correlation. To estimate this value, we refit the parameters of each model to estimate ground truth correlations, pooled over all sessions and subjects. BIC, model evidence corrected for complexity (Bayesian information criterion); Cov, covariance; NLL, model evidence (negative log likelihood, smaller is better); Val, value; Var, variance.\n\n\n## ID: tbl2\n### Label: Table 2\nUnnamed: 0\tx\ty\tz\tZ\tVoxels\tp (FWE)\tRegion\tHemi\nCorrelation coefficient (\u03c1)\t48\t5\t\u22125\t4.12\t59\t0.001???\tMidinsula\tR\nCorrelation coefficient (\u03c1)\t60\t\u22121\t\u22125\t3.87\t\u201c\t\u201c\tMidinsula (extending into superior temporal sulcus)\t\u201c\nCorrelation coefficient (\u03c1)\t48\t\u22127\t\u22122\t3.77\t\u201c\t\u201c\t\u201c\t\u201c\nCorrelation coefficient (\u03c1)\t\u221260\t\u22121\t\u221217\t3.85\t18\t0.61\tSuperior temporal sulcus\tL\nCorrelation coefficient (\u03c1)\t\u221251\t\u221210\t\u221217\t3.2\t\u201c\t\u201c\t\u201c\t\u201c\nCorrelation coefficient (\u03c1)\t\u221218\t\u221216\t1\t3.56\t19\t0.44\tThalamus\tL\nCorrelation coefficient (\u03c1)\t9\t\u221255\t37\t4.5\t8\t0.96\tPrecuneus\tR\nCorrelation coefficient (\u03c1)\t12\t\u221261\t\u22125\t3.33\t5\t0.90\tOccipital cortex\tL\nCorrelation coefficient (\u03c1)\t\u221254\t\u221240\t4\t3.31\t4\t0.96\tSuperior temporal sulcus\tL\nCorrelation prediction error (\u03b6)\t\u221215\t44\t7\t4.87\t36\t0.003???\tRostral ACC\tL\nCorrelation prediction error (\u03b6)\t\u221254\t\u221225\t\u22125\t4.01\t43\t0.14\tSuperior temporal sulcus\tL\nCorrelation prediction error (\u03b6)\t\u221257\t8\t\u221223\t3.95\t4\t0.99\tAnterior superior temporal sulcus\tL\nCorrelation prediction error (\u03b6)\t\u221242\t\u221261\t37\t3.63\t17\t0.80\tInferior parietal lobe\tL\nCorrelation prediction error (\u03b6)\t\u221260\t\u22121\t\u221214\t3.61\t10\t0.93\tSuperior temporal sulcus\tL\nCorrelation prediction error (\u03b6)\t\u221263\t\u22127\t\u22128\t3.48\t\u201c\t\u201c\t\u201c\t\u201c\nCorrelation prediction error (\u03b6)\t12\t\u221213\t52\t3.57\t3\t0.91\tMedial cingulate gyrus\tR\nCorrelation prediction error (\u03b6)\t36\t\u221210\t7\t3.23\t3\t0.99\tPosterior insula\tR\nAbsolute weight update\t6\t26\t34\t4.22\t135\t0.001???\tACC/DMPFC\tR\nAbsolute weight update\t\u22129\t29\t25\t3.5\t\u201c\t\u201c\t\u201c\tL\nAbsolute weight update\t42\t23\t\u22125\t4.04\t55\t0.04???\tAnterior insula\tR\nAbsolute weight update\t15\t\u221264\t34\t3.95\t40\t0.04???\tPrecuneus\tR\nAbsolute weight update\t51\t26\t22\t3.81\t7\t0.73\tDLPFC\tR\nAbsolute weight update\t15\t\u221231\t26\t3.73\t15\t0.38\tCerebellum\tR\nAbsolute weight update\t0\t\u221219\t\u22122\t3.71\t29\t0.20\tVTA vicinity\t\nAbsolute weight update\t\u221233\t17\t\u22125\t3.57\t21\t0.69\tAnterior insula\tL\nAbsolute weight update\t\u221212\t2\t58\t3.37\t7\t0.88\tSMA\tL\nAbsolute weight update\t0\t\u221252\t\u221235\t3.18\t6\t0.97\tCerebellum\t\nRisk (average contrast over individual risk from both outcomes, h1/h2)\t45\t\u22124\t\u221214\t3.69\t7\t0.76\tPosterior insula\tR\nRisk (average contrast over individual risk from both outcomes, h1/h2)\t45\t\u221276\t34\t3.67\t3\t0.98\tPosterior parietal cortex\tR\nRisk (average contrast over individual risk from both outcomes, h1/h2)\t18\t\u221228\t4\t3.6\t3\t0.86\tThalamus\tR\nRisk (average contrast over individual risk from both outcomes, h1/h2)\t\u221221\t2\t7\t3.55\t7\t0.85\tStriatum\tL\nRisk (average contrast over individual risk from both outcomes, h1/h2)\t\u221242\t\u221255\t\u221235\t3.38\t3\t0.99\tCerebellum\tL\nRisk prediction errors (average contrast over individual risk PE from both outcomes, \u03b51/\u03b52)\t\u221224\t23\t\u22128\t3.13\t3\t0.98\tAnterior insula\tL\n### Caption\nSignificant Activations in Statistical Parametric Analysis\n### Footer\nACC, anterior cingulate; DMPFC, dorsomedial prefrontal cortex; FWE, familywise error; Hemi, hemisphere; L, left; MNI, Montreal Neurological Institute; R, right. All peaks are thresholded p\u00a0< 0.001 uncorrected; listed are all clusters with an extent \u22653 voxels.\n", "metadata": {"pmcid": 3183226, "text_md5": "2edefe04cd1488f4359fc6a6d0dca164", "field_positions": {"authors": [0, 80], "journal": [81, 87], "publication_year": [89, 93], "title": [104, 172], "keywords": [186, 186], "abstract": [199, 1572], "body": [1581, 55391], "tables": [55404, 59605]}, "batch": 2, "pmid": 21943609, "doi": "10.1016/j.neuron.2011.07.025", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3183226", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3183226"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3183226\">3183226</a>", "list_title": "PMC3183226  Hedging Your Bets by Learning Reward Correlations in the Human Brain"}
{"text": "Svolgaard, Olivia and Andersen, Kasper Winther and Bauer, Christian and Madsen, Kristoffer Hougaard and Blinkenberg, Morten and Selleberg, Finn and Siebner, Hartwig Roman\nPLoS One, 2018\n\n# Title\n\nCerebellar and premotor activity during a non-fatiguing grip task reflects motor fatigue in relapsing-remitting multiple sclerosis\n\n# Keywords\n\n\n\n# Abstract\n \nFatigue is a common and highly disabling symptom of multiple sclerosis. Patients experience an effort-independent general subjective feeling of fatigue as well as excessive fatigability when engaging in physical or mental activity. Previous research using functional magnetic resonance imaging (fMRI) has revealed heterogeneous findings, but some evidence implicates the motor system. To identify brain correlates of fatigue, 44 mildly impaired patients with relapsing-remitting multiple sclerosis and 25 age- and gender-matched healthy controls underwent functional magnetic resonance imaging at 3 Tesla, while they performed alternating blocks of rest and a non-fatiguing precision grip task. We investigated neural correlates of fatigue using the motor subscore of Fatigue Scale for Motor and Cognitive Functions (FSMC ) using the bilateral motor cerebellum, putamen, and dorsal premotor cortex as regions of interest. Patients and healthy controls performed the grip force task equally well without being fatigued. In patients, task-related activity in lobule VI of right motor cerebellum changed in proportion with individual FSMC  scores. In right dorsal premotor cortex, linear increases in activity across consecutive task blocks scaled with individual FSMC  scores in healthy controls, but not in patients. In premotor and dorsomedial prefrontal areas, patients were impaired at upscaling task-related activity the more they were affected by motor fatigue. The results support the notion that increased sensorimotor processing in the cerebellum contributes to the experience of motor fatigue and fatigability in multiple sclerosis. Additionally, downscaling of motivational input or sensorimotor processing in prefrontal and premotor areas may constitute an additional pathophysiological factor. \n \n\n# Body\n \n## Introduction \n  \nFatigue is one of the most common and disabling symptoms in multiple sclerosis (MS) [ \u2013 ]. Fatigue is a complex phenomenon to study because the patients experience an effort-independent general subjective feeling of fatigue as well excessive fatigability when engaging in physical or mental activity [ ]. Effort-independent fatigue is often referred to as the \u201ctrait\u201d fatigue, whereas fatigability is referred to as a \u201cstate\u201d feature of fatigue. In a clinical setting, the two aspects are usually measured jointly using standardized scales [ \u2013 ]. \n\nThe precise mechanisms that determine the emergence and magnitude of effort-independent \u201cstate\u201d fatigue and effort-evoked \u201ctrait\u201d fatigability in a given patient are still largely unknown and treatment remains a challenge [ ]. Whatever the causal mechanisms may be, the experience of excessive fatigue and fatigability are underpinned by pathophysiological changes in functional brain networks [ ]. Identifying brain activity that scales with the experience of fatigue and fatigability during everyday life may not only reveal important insights into the pathophysiology of fatigue, but may be a step towards establishing neuroimaging-based biomarkers of fatigue that can supplement the subjective clinical scores. \n\nFunctional magnetic resonance imaging (fMRI) has been used in patients with MS to link task-related brain activity patterns to subjectively experienced fatigue during everyday life, yet results have been relatively incongruent across studies [ \u2013 ]. This can be attributed to the fact that MS is a heterogeneous disease and most studies examined relatively few patients. Additionally, there are several methodological differences in the studies, e.g. regarding the experimental tasks, the MS phenotypes, age range, disease-related disability (i.e. as reflected by EDSS scores), disease durations, fatigue questionnaires, etc. Only a couple of the studies share some common ground regarding the fatigue related brain activation changes [ ,  ,  ,  ]. Specogna et al. [ ] acquired fMRI, while patients performed a self-paced, sequential, thumb-to-finger opposition task. Fatigue was assessed using the Fatigue Severity Scale (FSS) [ ]. In fatigued patients with a score above 5, task-induced fatigue was associated with stronger task-related activity in right middle frontal gyrus, dorsal premotor cortex and putamen compared to non-fatigued patients with a score below 4 [ ]. Pardini et al. [ ] studied mildly affected patients, while they performed an acoustically paced, sequential thumb-to-finger opposition task twice per second. None of the patients perceived the task as fatiguing. Using the Modified Fatigue Impact Scale as index of fatigue (MFIS) during everyday life [ ], a positive correlation was found between experienced fatigue and task-related activity in right motor cerebellum (lobule VI) as well as orbitofrontal cortex [ ]. In another fMRI study, mildly disabled patients and healthy controls made repetitive finger flexion\u2013extension movements [ ]. Healthy controls showed a linear increase in task-related activity across task blocks in right and left putamen, and left precentral cortex [ ]. This time-dependent linear increase in activity was reduced in patients who suffered from fatigue [ ]. In a recent fMRI study, 14 MS patients performed an acoustically paced, sequential thumb-to-finger opposition task with their right hand twice per second to test fatigability by evoking effort-induced fatigue [ ]. Among other parts of the basal ganglia, patients recruited the putamen already at the beginning of the task before fatigability arose [ ]. This initial activation differs from the activity pattern found in healthy subjects [ ]. Healthy subjects recruited the putamen first after continuous task performance had induced a state of fatigue, but not at the beginning of task performance [ ]. Furthermore, other fMRI tasks have been used to study neural correlates of fatigue in MS such as stress or reward-processing tasks [ ,  ]. \n\nThis current study took a new step in the search of the pathophysiological changes in functional brain networks related to fatigue in a well-defined group of MS patients. Extending previous fMRI studies, we chose a tonic precision grip task as sensorimotor paradigm, because this task required the continuous integration of visual and somatosensory input with the generated motor output to maintain the required target force level [ ]. We reasoned that the nature of the task would engage sensorimotor control regions that contribute to motor fatigue in MS. We performed whole-brain fMRI to further clarify the relation between sensorimotor brain activity during a non-fatiguing sensorimotor task and the amount of motor fatigue and fatigability experienced during everyday life. Since previous fMRI studies of repetitive finger movements pointed to an alteration of task-related activity in dorsal premotor cortex (PMd), motor cerebellum, and putamen [ ,  ,  ,  ], we defined these areas as region of interest. We expected that patients suffering from motor fatigue and fatigability in their everyday life would display overall differences in task-related recruitment or differences in the time-dependent modulation of task-related activity levels in these areas. We further hypothesized that task-related activity in the ROIs would reflect the amount of motor fatigue and fatigability that patients experience during daily activities. \n\n\n## Material and methods \n  \n### Participants \n  \n50 patients with relapsing-remitting MS and 25 healthy individuals were initially included in the study. Inclusion criteria were age between 18 to 55 years and right-handedness according to Edinburgh Handedness Inventory [ ]. Patients had to have a maximal Expanded Disability Status Scale (EDSS) score of 3.5 and to be attack-free and on same treatment for the last three months. Exclusion criteria were pregnancy, contraindication for MRI, pharmacological treatment of fatigue, medical or psychiatric comorbidity, history of infection, sleeping problems, drug, or alcohol abuse. Approval was given by the Ethics committee of the Capital Region of Denmark (Protocol H-4-2013-182) and written informed consent was obtained before inclusion in the study. \n\n\n### Clinical assessment \n  \nSelf-reported fatigue was assessed with the Danish validated version of the Fatigue Scale for Motor and Cognitive Functions (FSMC) [ ,  ]. The questionnaire has been developed to assess the subjective experience of fatigue in MS patients during normal day-to-day life in general. The questions capture both, effort-independent \u201ctrait\u201d fatigue and effort-dependent \u201cstate\u201d fatigue (i.e., fatigability). The questionnaire has a motor subscale and a cognitive subscale and gives three measures of fatigue: an overall score, a motor score and a cognitive score ranging from 20\u2013100 and 10\u201350, respectively. There is a high correlation between the cognitive and motor sub-scale of the questionnaire [ ]. Since the focus of this study was on the motor component of fatigue and fatigability, only the motor sub-score of the Fatigue Scale for Motor and Cognitive Functions (FSMC ) was considered and used to quantify the magnitude of motor fatigue and fatigability experienced during everyday life. Based on the individual FSMC  score, patients were divided into patients with fatigue (score \u2265 27) and patients without fatigue (FSMC  score \u2265 27) and patients without fatigue (score \u2265 27) and patients without fatigue (FSMC  score < 27) corresponding to the cut-off point for moderate motor fatigue [ ]. Overall disease-related disability was assessed with the EDSS [ ]. Skilled hand function was quantified with the Nine Hole Peg Test (9-HPT) [ ] and Jebsen-Taylor Hand Function Test (JTHFT) [ ]. The severity of depressive symptoms, cognitive impairment, sleep problems were assessed with well-established tests or questionnaires such as the Beck Depression Inventory II (BDI-II) [ ,  ], Symbol Digit Modality Test (SDMT) [ ], Paced Auditory Serial Addition Test (PASAT) [ ], Epworth Sleepiness Scale (ESS) [ ,  ], and Pittsburgh Quality of Sleep Index (PQSI) [ ]. \n\n\n### Magnetic resonance imaging \n  \nWhole-brain MRI was performed with an Achieva 3 Tesla scanner and a 32-channel head coil (Philips, Best, The Netherlands). Blood oxygen level dependent fMRI [ ] was acquired using Echo Planar Imaging (EPI) with a repetition time (TR) of 2500 ms, echo time (TE) of 30 ms and flip-angle of 80\u00b0. Each brain volume consisted of 42 axial slices acquired in interleaved order with a slice-thickness of 3 mm and 3x3x3 mm voxel resolution, covering a field-of-view (FOV) of 192x192x126 mm. Whole-brain fMRI was acquired throughout three phases, a pre-fatigue phase, a fatigue induction phase, and a post-fatigue induction phase. This paper is only using the fMRI data, which were acquired in the pre-fatigue phase, corresponding to the first 201 acquired brain volumes of the fMRI session. The fatigue induction phase was variable across subjects due to the individual differences in fatigability and lasted from 39 seconds to 494 seconds and was used to induce motor fatigue in the subjects. The post-fatigue phase was similar to the pre-fatigue phase, so the total duration of the fMRI scan was between 19.3 minutes and 28.5 minutes (including pauses in between the different phases). Here we will only report the results from the first pre-fatigue phase, results for the two other phases will be presented elsewhere. \n\nStructural MRI scans were additionally acquired to measure lesion load and brain atrophy and included a three-dimensional high-resolution T1-weighted image acquired with a sagittal magnetization prepared rapid acquisition gradient echo (MPRAGE) sequence (TR = 6 ms, TE = 2.70 ms; flip-angle = 8\u00b0, 0.85 mm isotropic voxel size, FOV = 245x245x208 mm). A T2-weighted image was acquired with a turbo spin echo sequence (TR = 2500 ms, TE = 270 ms; flip-angle = 90\u00b0, 0.85 mm isotropic voxel size, FOV = 245x245x190 mm) and a fluid attenuated inversion recovery image (FLAIR) (TR = 4800 ms, TE = 327ms, 1 mm isotropic voxel size, FOV = 256x256x202 mm). We also performed diffusion weighted MRI of the brain, which will be reported separately. \n\n\n### Tonic grip force task during fMRI \n  \nDetailed oral and written task instructions were given and the subjects were familiarized with the task before fMRI. Participants were holding a force sensitive device with their right hand using a pincer grip and produced a steady force level, which was individually adjusted to 20% of their maximal force. The force produced by the participant was continuously visualized as expanding circle on a screen. The circle had to match the size of a ring, which indicated the target force level ( ). To avoid fatigue, alternating 20-s task blocks, during which subjects produced a force level at 20% of individual maximal voluntary contraction (MVC), alternated with 20-s periods of rest. Performance was continuously monitored on a screen in the MRI control room. The acquired grip force data was scaled to reflect force in Newton and the mean and standard deviation of the applied force were extracted using Matlab (The Mathworks Inc., USA,  ). \n   The precision grip task and parametric modulation.  \n (A)   The tonic precision grip task consisted of 12 task blocks (each 20 s) alternated by periods of rest (20 s). During the grip task, visual feedback of the exerted grip force (blue area) and the required target force (grey circle) was continuously provided.   (B)   Participants had to maintain a target force corresponding to 20% of the individual maximal voluntary contraction and the grip force output was continuously recorded.   (C)   Task-related activity was analysed using a General Linear Model in which the constant main effect of task (main effect) as well as linear modulation of task-related activity (linear time effect) were modelled. Task-related activation during the first block (red line) was separately modelled and treated as effect of no interest. \n  \n\n### Pre-processing and analysis of MRI data \n  \nLesions were automatically delineated on the FLAIR images using Jim software (JIM version 6.0 Xinapse System, Leicester, UK,  ). The delineated lesions were checked and if necessary, corrected by an expert using the co-registered T2- and T1-weighted images as support. The individual subject\u2019s T1-weighted image was normalized to Montreal Neurological Institute (MNI) space using Statistical Parametric Mapping software (SPM 12, Welcome Department of Imaging Neuroscience, London, UK,  ) and the normalization warp was then applied to the lesion mask. The normalized lesion masks were then summed across subjects to form a lesion frequency image in MNI space. \n\nStructural reconstruction and volumetric segmentation of structural MRIs were performed with FreeSurfer software (version 5.3.0;  ) using a standard processing pipeline [ ,  ], which includes intensity normalization to MNI space, skull stripping, filtering, segmentation, and surface deformation. To increase the segmentation accuracy for the patients, the semi-automated lesion delineations were entered into FreeSurfer as white matter hypointensity (on T1w) voxels in the segmentation pipeline [ ]. Quality of the skull stripping and accuracy of grey and white matter outer boundaries were reviewed by a trained researcher. The volumetric data of estimated total intracranial volume (TIV), white matter volume (WMV), and grey matter volume (GMV) were extracted using specialized FreeSurfer tools for automated parcellation of grey and white matter [ ]. The extracted volume measures were transformed into z-scores for further analyses. \n\nThe fMRI data were analysed using SPM 12. Images were realigned to the mean EPI image using a six-parameter, rigid-body transformation and spatial normalized to the MNI ICMB European brain template, using the mean realigned image to determine the transformation. The images were resampled to 2x2x2 mm3 voxels in MNI space and smoothed with a 6 mm full-width at half-maximum isotropic Gaussian kernel. For each participant, a general linear model (GLM) was used to model the fMRI time series. The design matrix modelled task-related activation as a boxcar function reflecting the alternation of task and rest periods convolved with the canonical hemodynamic response function. A second regressor modelled the first-order (linear) modulation of task-related BOLD signal changes across the session orthogonalized to the main task regressor [ ]. The design matrix included additional 24 nuisance regressors derived from the realignment parameters [ ] and a regressor-of-no-interest for the first block of the tonic precision grip task during which subjects reached steady-state performance. \n\n\n### Statistical analyses \n  \nGroup analysis of the fMRI data employed random effects analysis to test for voxel-wise significance within and between groups, yielding mean statistical parametric maps for each group and for between-group difference using one-sample and two-sample T-tests, respectively. The group models for within and between group analyses contained the FSMC  score as effect of interest, and the two nuisance regressors \u201cage\u201d and \u201chand function\u201d measured with the JTHFT. Separate group models were set up for the main effect of task and the first-order modulation of task-related activation during the session. \n\nGroup analyses tested for differences in task-related activity between healthy controls and patients with MS as well as differences between patients with excessive fatigue (FMS group) and patients without fatigue (NFMS group). In the latter analysis, individual BDI-II scores were included as a covariate in the model to isolate the effect of fatigue from those associated with the presence of depressive symptoms. \n\nThe correction for multiple non-independent comparisons at the peak voxel level was performed using the family-wise error method implemented in SPM based on Gaussian random fields and the statistical threshold was set to p < 0.05. A single mask consisting of the cerebellum lobule VI, putamen, and PMd of both hemispheres were used to define the region of interest ( ). The PMd ROI was defined based on the Human Motor Area Template (HMAT) number 9 and 10 [ ] converted from Talairach to MNI space with tal2mni ( ). The putamen ROI was defined with the Automated Anatomic Labelling Atlas (AAL) [ ]. The cerebellar lobule VI was defined with the probabilistic MRI cerebellum atlas by Diedrichsen et al. [ ]. For voxels within the ROI, small volume correction was applied considering all voxels within the ROI mask. In addition, we used the lesion frequency map to exclude voxels, which was labelled as a lesion voxel in one or more patients, which was done to restrict the analysis to non-lesion brain tissue. For descriptive purposes, all group statistical parametric maps used an uncorrected, cluster-forming threshold of p < 0.001. \n   The mask used to define the region of interest.  \nA single mask consisting of the cerebellum lobule VI, putamen, and PMd of both hemispheres were used to define the region of interest. \n  \nClinical, behavioural and structural MRI measures are given as mean (\u00b1 standard deviation) and were analysed with SPSS software (version 22, IBM Corp., Armonk, New York, USA), using repeated measures ANOVA, t-tests and Pearson or Spearman correlation when appropriate. Significance threshold was set at p < 0.05. \n\n\n\n## Results \n  \n### Clinical and grip force data \n  \nForty-nine of the 50 patients underwent MRI scanning, but three fMRI data sets could not be used because of motion artefacts or insufficient task compliance. Two additional patients were excluded because of high BDI-II scores. In these two patients, the total BDI-II score indicated the presence of severe symptoms of depression, although these patients had no clinical diagnosis of depression. Thus, 44 MS patients (27 FMS patients and 17 NFMS patients) and 25 healthy controls were included in the group analyses. Clinical characteristics and group data of the structural MRI analyses are summarized in  . Healthy controls and the MS patients had comparable age and sex distributions. Patients had higher total, motor, and cognitive FSMC scores than healthy controls. Patients also had significantly higher average BDI-II, PQSI, and JTHFT scores than healthy controls. \n   Clinical characteristics of MS patients and healthy controls.        \nIn the patient group, individual FSMC  scores showed a positive correlation with BDI-II scores (r = 0.53, p < 0.001) and EDSS scores (r = 0.47, p = 0.001). The individual FSMC  scores did not correlate with disease duration or total white matter lesion volume. Accordingly, the FMS group had higher BDI-II and EDSS scores than the NFMS patients, while other clinical scores did not differ significantly between the two groups ( ). TIV and GMV were higher in the NFMS group than in the FMS group ( ). \n   Clinical characteristics of the MS patients.        \nPatients performed the precision grip task equally well as healthy controls during fMRI. Mean grip force was 16.17 (\u00b14.67) N in healthy controls and 16.20 (\u00b12.40) N in MS patients. The mean variability across subjects of the applied force was 0.54 (\u00b10.80) N in healthy controls and 0.52 (\u00b10.31) N in patients. Repeated-measures ANOVA showed no time or group effect and no interaction between time and group for mean force levels and the variability or grip force during the task. \n\n\n### Task-related activity during tonic grip force task \n  \n#### Task-related activation \n  \nThe tonic grip force task activated a well-known sensorimotor network that has been shown to be engaged in visually guided control of precision grip force [ ]. The network comprised cortical clusters in the prefrontal, premotor, sensorimotor, parietal and occipital cortex, as well as cerebellum and basal ganglia bilaterally. The task-related activity pattern was very similar in both groups with no significant between-group differences in task-related activation between MS and healthy controls ( ) or between the FMS and NFMS groups. \n   Main effect of the precision grip task.  \nT-score maps showing the brain activation during the tonic precision grip task in healthy controls and patients with MS. For visualisation purposes, the maps were thresholded at an uncorrected p-value of < 0.001. \n  \n\n#### Relation between task-related activation and motor fatigue \n  \nPatients with MS showed a linear relationship between task-related activation and individual FSMC  scores in the right upper cerebellar lobule VI ( ). The cerebellar cluster was located in the hand motor representation ipsilateral to the hand performing the task ( ), indicating that cerebellar task-related activity scaled positively with the magnitude of self-reported motor fatigue and fatigability during everyday life. No linear relationship between individual fatigue scores and task-related cerebellar activity was found in healthy controls. \n   MS patients\u2014within group analysis.  \nLinear scaling of the constant task-related activation during a non-fatiguing grip force task, with the amount of experienced fatigue during daily life, as indexed by the FSMC  score. In right motor cerebellum there was a linear increase in task-related activation in the MS group with increasing motor fatigue (p  = 0.046, r  = 0.36). \n     Group results of the fMRI data.        \nWe divided the patient group in patients with fatigue (FMS group) and without fatigue (NFMS group). When comparing these groups, we found regional differences in the scaling between task-related activity and FSMC  scores in two clusters within the left PMd, peaking at MNI-coordinates x, y, z = -30, 4, 46 and x, y, z = -26, -12, 74 ( ). In these PMd regions, NFMS patients who did not experience excessive motor fatigue during everyday life showed a linear increase in task-related activation with the magnitude of experienced motor fatigue ( ). This relationship between task-related activity and FSMC  scores was absent in FMS patients who reported excessive levels of motor fatigue ( ). The same pattern was found in a cluster in the dorsomedial prefrontal cortex (dmPFC) rostral to the pre-supplementary area. Here task-related activity scaled positively with individual FSMC  scores in the NFMS group, but not in the FMS group ( ). \n   The non-fatigued MS patients compared to the fatigued MS patients.  \nLinear scaling of the constant task-related activation during a non-fatiguing grip force task, with the amount of experienced fatigue during daily life, as indexed by the FSMC  scores in the non-fatigued MS patients compared to the fatigued MS patents.  (A  ) The left ventral part of the dorsal premotor cortex (PMd) (p  = 0.017),   (B)   left caudal part of the dorsal premotor cortex (PMd) (p  = 0.049) and   (C)   left dorsomedial prefrontal cortex (dMPFC) showed increased linear correlation between task-related activation and FSMC  scores in the non-fatigued MS patients (blue) compared with the fatigued MS patients (red) (p  = 0.038). \n  \n\n#### Linear changes in activation during repeated task performance \n  \nCompared to patients with MS, healthy controls showed a stronger time-dependent increase in task-related activity in the right posterior cingulate cortex and adjacent lingual gyrus ( ). Conversely, patients showed no brain region where task-related activation increased more strongly with time than in healthy controls. We also found no differences in time-dependent task modulation between the FMS and NFMS groups. \n\nConsidering only the patients with MS, we found a negative linear effect of time on task-related activity in the motor territory of the left cerebellum contralateral to the hand performing the grip force task ( ). In contrast, no brain region showed a significant linear increase or decrease in task-related activity with the duration of task performance in healthy controls. \n\nA correlation analysis between the individual FSMC  scores and the task-related brain activity revealed a difference in the linear time-dependent modulation of task-related activity ( ). In right caudal PMd, the time-dependent increase in task-related activity scaled more strongly with the individual FSMC  scores in healthy controls than in patients with MS ( ). The higher the individual FSMC  scores, the stronger the time-dependent increase of task-related PMd activity in healthy controls, but not in MS patients ( ). The same pattern was found in a rostromedial cluster of the left cerebellum and lingual gyrus. When each group was tested separately, the relationship between time-dependent modulation of PMd activity and FSMC  scores did not reach significance. \n   MS patients compared to healthy controls.  \nMS patients\u2019 task-related activity scaled with individual FSMC  scores relatively to the scaling in healthy controls. Healthy controls showed a stronger time-dependent increase in task-related activity in the right dorsal premotor cortex (PMd) than patients with MS (p  = 0.031). In healthy controls, the linear time modulation of task scaled with the individual FSMC  scores (blue). The more controls experienced fatigue during daily life; the more they displayed a linear increase in task-related activity with time during the non-fatiguing grip force task. This relationship was not present in MS patients (red). \n  \nThere were no clusters in the brain where the time-dependent increase in task-related activity correlated more strongly with FSMC  scores in MS patients than in controls. There was also no influence of the FSMC  scores on time-dependent activity changes, when contrasting FMS and NFMS patients. \n\n\n\n\n## Discussion \n  \nHere we used task-related fMRI to map sensorimotor brain activity evoked by a tonic right-hand grip force task in mildly impaired patients with MS and healthy controls. We identified distinct regions in the cerebellum and premotor cortex where sensorimotor activity in the non-fatigued state scaled with the amount of motor fatigue that patients experienced during everyday life. Task-related activity in right motor cerebellum increased in proportion with self-reported fatigue. Furthermore, patients lacked a \u201cnormal\u201d upscaling of regional task-related activity in premotor and dorsomedial prefrontal areas with the level of subjectively experienced fatigue. As pointed out above, self-reported \u201cmotor fatigue\u201d, as probed with the FSMC  or other standardized clinical scales, reflects both effort-independent \u201ctrait\u201d fatigue as well as effort-induced \u201cstate\u201d fatigue (i.e., fatigability) [ \u2013 ]. \n\n### Cerebellar activity and self-experienced fatigue \n  \nThe right motor cerebellum ipsilateral to the grasping hand was the only brain region, where functional activation during a non-fatiguing tonic grip force task scaled significantly with the amount of experienced motor fatigue in patients with MS ( ). This finding confirms and extends previous fMRI studies on fatigue in MS. In 14 mildly affected patients with relapsing-remitting MS, subjective fatigue during everyday life correlated positively with task-related activation of the right cerebellar lobule VI ipsilateral to the moving hand [ ]. In that study, patients had to generate externally paced finger-to-thumb opposition sequences with their right hand at a rate of 2 Hz during fMRI. A possible correlate at the metabolic level has also been reported in a study using 18F-fluorodeoxyglucose positron emission tomography [ ]. Likewise, an early fMRI study reported a stronger overall activation of the right motor cerebellum in mildly impaired MS patients suffering from fatigue as opposed to those without fatigue, when patients performed flexion\u2013extension finger movements with their right hand at a paced rate of 1 Hz [ ]. In summary, our and previous fMRI studies consistently show across a range of non-fatiguing manual tasks, that task-related activation of the sensorimotor cerebellum reflects how much fatigue patients experience during their everyday live. \n\nFunctional and structural changes in the cerebellum contribute significantly to disease-induced motor disability in MS [ ,  ] as well as to cognitive and emotional disturbances [ ]. The motor cerebellum is involved in the detection of motor errors and their correction during on-going movements and motor learning [ ,  ] and secures temporal and spatial precision and fluency of movements based on internal models [ ,  ]. Accordingly, in addition to individual fatigue scores, the temporal accuracy of repetitive finger movements correlated positively with the activity in right cerebellar lobule VI and temporal accuracy during the task correlated positively with the self-reported fatigue in the study by Pardini et al. [ ]. This \u2018\u2018fatigue-motor performance paradox\u201d prompted Pardini et al. to propose that patients who experience fatigue may be the ones who excessively monitor their errors to optimize performance [ ]. In other words, scaling-up cerebellar sensorimotor control might be a compensatory mechanism to secure good performance but at the same time cause fatigue. Excessive sensorimotor processing in the cerebellum may lead to a faster exhaustion of neural resources, and thereby promote effort-induced experience of fatigue. Given that the cerebellum plays an important role in a range of non-motor functions [ ], a similar consideration may apply for non-motor aspects of fatigue and altered processing in other non-motor territories in the cerebellum. \n\nThe increase in cerebellar motor activity with increasing individual fatigue scores was found during both tonic motor activity in the present study and phasic repetitive activity in the study by Pardini et al. [ ]. The sensorimotor task employed by Pardini et al. [ ] required temporal error processing to optimize the timing of finger movements relative to an auditory pacing cue. In contrast, the sensorimotor task used in the present study engaged the processing of magnitude errors in force output based on the simultaneous visual display of the exerted force and the target force. Although the two tasks implicated different types of error processing, they both required the continuous integration of external target signals with sensory feedback created by the motor output. Both sensorimotor settings revealed a positive relationship between task-related motor activation of ipsilateral cerebellar lobule VI and self-reported magnitude of fatigue, supporting the notion that the motor cerebellum excessively monitors performance during relatively simple motor tasks that has yet not induced fatigability. \n\nIn the left sensorimotor cerebellum contralateral to the grasping hand, patients displayed a time-dependent linear decrease in task-related activity during the fMRI session ( ). In addition, the time-dependent linear increase in task-related activity in the rostromedial part of the left motor cerebellum scaled more strongly with the individual FSMC  scores in healthy controls than in patients with MS. The higher the individual FSMC  scores, the stronger was the time-dependent increase of task-related cerebellum activity during the fMRI session in healthy controls, but not in MS patients. This finding indicates that not only the constant level of ipsilateral cerebellar sensorimotor activation, but also the lack of temporal modulation of contralateral cerebellar activity during continued task performance may be related to motor fatigue experienced during everyday life. \n\n\n### Premotor activity and self-experienced fatigue \n  \nThe premotor cortex forms multiple reciprocal loops with the parietal cortex, through which sensory information is processed and transformed into actions [ \u2013 ]. The PMd is a key region for manual motor control and is involved in response selection and non-routine visuo\u2013motor mapping [ \u2013 ]. PMd participates both in motor planning and execution [ ], displaying a rostro-caudal functional gradient with the more caudal part being associated more closely with motor execution [ ,  ,  ]. \n\nIn accordance with our hypothesis, several clusters in PMd showed an altered activation profile in patients with MS that change in proportion with the amount of motor fatigue experienced during daily life. In the caudal part of right PMd, patients and controls showed differences in the linear time-dependent modulation of task-related activity during the fMRI session, which scaled linearly with the individual FSMC  scores. In the right caudal PMd, healthy controls showed a stronger time-dependent increase of task-related activity with the experienced magnitude of motor fatigue than MS patients ( ). This difference between groups suggests that healthy individuals gradually increase task-related recruitment of the PMd during repeated task blocks, the more they experience fatigue during daily life. Of note, none of the healthy controls reported a level of fatigue that was of clinical relevance. Hence, the relationship found in healthy controls between the time-dependent modulation of PMd activity and the FSMC  scores applies to normal inter-individual variations in the physiological range. One might speculate that the ability to recruit the right PMd during continuous task performance might protect against the occurrence of excessive fatigue or fatigability. \n\nThe positive relationship between the temporal modulation of PMd activity and experienced daily-life fatigue was absent in the patient group, even though patients showed a wider inter-individual spread and overall higher FSMC  scores. Using a non-fatiguing hand flexion-extension task, a recent fMRI study found that MS patients suffering from fatigue showed a reduced activation change over time in left putamen and precentral gyrus compared to healthy controls [ ]. Our results extend the findings showing a deficient time-dependent task-related activation over time in the right caudal PMd the more patients experienced motor fatigue during daily life. In addition, the comparison of the FMS and NFMS groups revealed that overall task-related activity in a ventral cluster and a caudal cluster of left PMd depended on the presence of motor fatigue during daily life ( ). In these left-hemispheric clusters, task-related activity scaled differentially with the magnitude of fatigue in the FMS groups relative to the NFMS group. NFMS patients, who had FSMC  scores close to the normal range, showed a linear increase in task-related activation of left PMd with their individual FSMC  scores. In contrast, FMS patients, who had abnormally high FSMC  scores, showed a linear decrease or no change in task-related activation depending on their individual FSMC  scores. In agreement with our findings, Specogna et al. [ ] found stronger task-related activity in a ventral cluster of the left PMd during a self-paced sequential finger-tapping task in NFMS patients relative to healthy controls. This increase in task-related premotor activation was not present in MS patients with fatigue [ ]. The results suggest a link between the inability of task-related PMd recruitment and the daily experience of motor fatigue in patients with MS. The NFMS group upscaled task-related activation of PMd, the more patients experienced signs of motor fatigue during everyday life. Conversely, the FMS group failed to up-scaled the task-related activation of PMd with the increasing severity of daily-life motor fatigue. Based on these findings, we hypothesize that patients who suffer from motor fatigue may fail to gradually upscale task-related engagement of PMd. The inability to sufficiently recruit PMd during prolonged performance of non-fatiguing motor tasks might reflect deficient sensorimotor integration within the PMd and contribute to abnormal fatigability during daily activities. \n\n\n### No consistent abnormality of task-related activity of the putamen \n  \nThe putamen was the only pre-defined region of interest where we found no significant alteration of the regional activation profile in relation to fatigue. This negative finding may be related to the nature of the task, which did not rely critically on the basal ganglia, but rather on cerebellar integration of the produced motor output and the visual and somatosensory input to produce a constant force output. Other motor tasks, for instance tasks that require repetitive or sequential movements, might reveal altered activity patterns in the basal ganglia that are related to motor fatigue in MS as seen in other studies [ ,  ]. \n\n\n### Motivational drive and dorsomedial prefrontal cortex \n  \nThe left dorsomedial part of the prefrontal cortex showed a difference in task-related activation in the patient group depending on whether patients suffered from excessive fatigue or not. Patients without fatigue showed a positive relationship between task-related dmPFC activity and their individual FSMC  scores, whereas patients with motor fatigue did not show this pattern ( ). In the FMS group, dmPFC activity did not change in proportion with the magnitude of self-reported motor fatigue. In accordance with our finding, a recent task-related fMRI study reported reduced activation of dmPFC in FMS patients compared to NFMS patients and HC during a repetitive extension-flexion task [ ]. \n\nFurthermore, a fMRI study in healthy individuals has identified a motivational action control circuit that secures consistent force production \u201cdespite changes in emotional context\u201d and includes the dmPFC, PMv and PMd [ ]. The study showed that dmPFC and PMv increase task-related activity during a visually cued phasic grip task, when the task context is emotionally salient [ ]. Additional connectivity analysis revealed a stronger functional coupling of dmPFC with ventral and dorsal portions of premotor cortex in an emotionally salient versus a neutral context. In present study, we find that the more severe motor fatigue the patients are experiencing, the more the task-related activity was downscaled in left dmPFC and PMd. Taking into account the work by Coombes et al. (2012) in healthy individuals, we speculate that a downscaling of dmPFC and PMd activity may point to a dysfunction of the motivational action control circuit in MS patients who suffer from motor fatigue, reducing the internal motivational drive. \n\n\n### Methodological considerations and limitations of this study \n  \nThe FSMC questionnaire has been developed to assess fatigue in MS and requests the subject to evaluate how much they experience an extreme form of tiredness (fatigue) i.e. the \u201coverwhelming state of lethargy, exhaustion and lack of energy which comes on abruptly and is unrelated to any obvious external causes\u201d during their day-to-day life [ ]. Hence, the questionnaire probes the subjective experience of fatigue during day-to-day life in general rather than the momentary expression of fatigue at the time of examination. The questionnaire contains items that capture effort-independent \u201ctrait\u201d fatigue as well as effort-related \u201cstate\u201d fatigue (i.e., fatigability). Since we used the FSMC  score as proxy for motor fatigue in this study, it is impossible to disentangle whether the brain activation changes are related to \u201ctrait\u201d fatigue, fatigability and/or an interaction between the two. Furthermore, it remains controversial whether\u201dtrait\u201d fatigue and \u201cstate\u201d fatigability can be dissociated [ ]. While fMRI can help to pinpoint abnormal patterns of regional brain activations related to motor fatigue in MS, fMRI provides no insights into the specific neurobiological mechanisms through which MS gives rise to these functional activation changes [ ]. Furthermore, whether these brain activation changes are a response, cause or mediator of fatigue cannot be inferred from the present study. This question may be tackled with an interventional study design in which the amount of fatigue or the activation patterns are altered by a targeted intervention (e.g. pharmacological therapy or focal brain stimulation). \n\nThe present study deliberately focussed on relatively mildly affected patients with a relapsing-remitting presentation of MS. Therefore the generalizability to other clinical forms of MS such as primary or secondary progressive MS or more severely impaired patient groups is limited. \n\nWe used a visual-spatial grip force control task to study neural correlates of motor fatigue in sensorimotor brain networks. While the focus was on the motor component of fatigue, the motor and cognitive subscales of the FSMC questionnaire were highly correlated in our sample, in agreement with the literature [ ]. Therefore, it remains unclear how much the present findings are really specific to motor aspects of fatigue or generalize to the cognitive domain. \n\nIn addition, the task did not activate motor networks implicated in the control of other motor effectors such as legs (gait) or mouth (speech and swallowing). The relatively simple task also did not capture the physical and mental challenges of skilled manipulative actions during everyday life. This implies that the present findings need to be interpreted in the context of the specific motor task and generalization to other motor tasks should be made with caution. Another inherent limitation is that MS leads to motor impairment, and the effects of motor impairment on task-related activation may confound the activation patterns related to motor fatigue. However, we consider it highly unlikely that the present findings were accounted for by disease-related impairment of hand function. Inter-individual differences in hand function were taken into account in our statistical model. In contrast to task-related fMRI, resting state fMRI has the advantage of not being confounded be type of task type or task performance. \n\nPatients and healthy controls performed the grip force task equally well during the fMRI session, and there were no between-group differences in task-related brain activation. However, the results of this study are limited by the lack of controlling for regional lesion burden. \n\nFinally, it is generally accepted that fatigue and depression constitute two different but closely related conditions [ ]. This results in an inherent problem when studying fatigue, as patients rating high on a fatigue questionnaire will also score high on a depression rating scale, even when excluding patients with a clinical diagnosis of major depression. In this study, to make sure the differences in brain activation was not biased by depression none of the patients had a clinical diagnosis of depression, patients with high BDI scores indicative of severe depressive symptoms were excluded and the comparison between the NFMS and FMS group was corrected for depression. \n\n\n\n## Conclusions \n  \nThe present study advances the current understanding of the neural underpinnings of fatigue in MS. We show that the functional activation of the motor cerebellum during a non-fatiguing tonic grip force task reflects the severity of motor fatigue and fatigability experienced during daily life. In dorsal and ventral premotor as well as dorsomedial prefrontal areas, inter-individual difference in task-related activation scaled with the level of experienced fatigue during everyday life. MS patients showed a reduced upscaling of task-related activity in this prefrontal-premotor network, the more the patients were affected by motor fatigue. In summary, the results are compatible with the notion that motor fatigue in MS is associated with an upscaling of cerebellar sensorimotor integration along with a downscaling of motivational drive and sensorimotor processing in prefrontal and premotor areas. However, whether these brain activation changes are a response, a cause or a mediator of fatigue cannot be concluded. \n\n \n\n# Table(s)\n## ID: pone.0201162.t001\n### Label: Table 1\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tMS n = 44\tUnnamed: 3_level_0\tUnnamed: 4_level_0\tHC n = 25\tUnnamed: 6_level_0\tUnnamed: 7_level_0\nUnnamed: 0_level_1\tMean\tRange\tSD\tMean\tRange\tSD\tp\nAge\t35.9\t(22\u201353)\t8.8\t35.8\t(19\u201355)\t10.6\t0.979\nGender (M:F)\t14:30\t32%:68%\t\t9:16\t36%:64%\t\t0.723\nMedian EDSS\t2.5\t(0\u20133.5)\t1.0\t\t\t\t\nDisease duration\t6.3\t(0\u201328)\t5.2\t\t\t\t\nTreatment\t40 MS\t90.9%\t\t\t\t\t\nClinical scores\t\t\t\t\t\t\t\nFSMC TOTAL???\t59.3\t(20\u201392)\t21.3\t28.0\t(20\u201346)\t8.2\t0.0\nFSMC MOTOR???\t28.8\t(10\u201345)\t10.6\t12.9\t(10\u201323)\t3.2\t0.0\nFSMC COGNITIVE???\t30.5\t(10\u201348)\t11.9\t15.0\t(10\u201328)\t5.6\t0.0\nBDI\u2014II???\t7.2\t(0\u201322)\t6.0\t1.6\t(0\u201311)\t2.8\t0.0\nPSQI???\t5.2\t(1\u201318)\t3.7\t3.4\t(1\u20135)\t1.4\t0.005\nESS\t8.2\t(2\u201317)\t3.9\t6.4\t(0\u201314)\t4.0\t0.08\nPASAT\t50.1\t(33\u201360)\t7.5\t51.1\t(43\u201359)\t5.0\t0.506\nSDMT\t54.2\t(35\u201389)\t10.5\t56.5\t(41\u201370)\t6.7\t0.28\nJTHFT RIGHT HAND???\t37.7\t(30\u201353)\t4.2\t35.4\t(29\u201341)\t3.5\t0.026\n9-HPT RIGHT HAND\t15.9\t(13\u201324)\t2.0\t15.7\t(13\u201319)\t1.8\t0.628\nStructural MRI metrics\tStructural MRI metrics\t\t\t\t\t\t\nMean TIV\t1561.3\t\t141.4\t1594.9\t\t154.7\t0.362\nMean WM\t482.7\t\t59.9\t500.2\t\t56.9\t0.135\nMean GMV\t637.5\t\t47.9\t657.2\t\t47.9\t0.17\nMean WMHV\t5.9\t(0.3\u201330.7)\t6.5\t\t\t\t\n### Caption\nClinical characteristics of MS patients and healthy controls.\n### Footer\n* = p\u2013value < 0.05Abbreviations: Age = Age in years, BDI\u2014II = Beck depression inventory version II, Disease duration = Years since diagnose, EDSS = Expanded disability status score, ESS = Epworth sleepiness scale, FMS = MS patients with fatigue, FSMCCOGNITIVE = FSMC cognitive score, FSMCMOTOR = FSMC motor score, FSMCTOTAL = Fatigue scale for motor and cognitive functions total score, Gender (M : F) = Male: female ratio, HC = Healthy controls, GMV = Grey matter volume in millilitre, JTHFT = Jebsen-Taylor hand function test, MS = Multiple sclerosis, NFMS = MS patients without fatigue, WMHV = White matter hyperintensities volume (i.e. white matter lesions, in millilitre), 9-HPT = Nine hole peg test, p = P\u2013value, PASAT = Paced auditory serial addition test, PSQI = Pittsburgh sleep quality index, SD = Standard deviation, SDMT = Symbol digit modalities test, TIV = Total intracranial (volume in millilitre), Treatment = In treatment with multiple sclerosis disease modifying drugs, WMV = White matter volume in millilitre.\n\n\n## ID: pone.0201162.t002\n### Label: Table 2\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tNFMS n = 17\tUnnamed: 3_level_0\tUnnamed: 4_level_0\tFMSn = 27\tUnnamed: 6_level_0\tUnnamed: 7_level_0\nUnnamed: 0_level_1\tMean\tRange\tSD\tMean\tRange\tSD\tp\nAge\t34.5\t(22\u201350)\t8.3\t36.7\t(25\u201353)\t9.7\t0.411\nGender (M : F)\t8:9\t47%:53%\t\t6:21\t22%:78%\t\t0.085\nMedian EDSS???\t2.0\t(0\u20133.5)\t1.1\t2.5\t(0\u20133.5)\t0.8\t0.023\nDisease duration\t6.4\t(1\u201328)\t6.4\t6.2\t(0\u201316)\t4.5\t0.891\nTreatment\t15 MS\t88.2%\t\t25 MS\t92.6%\t\t0.624\nClinical scores\t\t\t\t\t\t\t\nFSMC TOTAL???\t38.3\t(20\u201357)\t14.3\t72.5\t(45\u201392)\t12.5\t0.0\nFSMC MOTOR???\t17.4\t(10\u201325)\t5.5\t35.9\t(27\u201345)\t5.4\t0.0\nFSMC COGNITIVE???\t20.9\t(10\u201342)\t9.6\t36.6\t(15\u201348)\t8.9\t0.0\nBDI\u2014II???\t3.4\t(0\u201310)\t3.3\t9.7\t(0\u201322)\t6.2\t0.0\nPSQI\t4.4\t(2\u20139)\t1.7\t5.7\t(1\u201318)\t4.5\t0.171\nESS\t6.8\t(2\u201317)\t4.3\t9.0\t(3\u201317)\t3.5\t0.062\nPASAT\t52.2\t(41\u201360)\t5.3\t48.8\t(33\u201360)\t8.4\t0.102\nSDMT\t55.4\t(40\u201389)\t12.3\t53.5\t(35\u201371)\t9.3\t0.557\nJTHFT RIGHT HAND\t37.3\t(13\u201322)\t2.4\t37.9\t(13\u201324)\t5.1\t0.648\n9-HPT RIGHT HAND\t16.0\t(32\u201340)\t2.0\t15.9\t(30\u201353)\t2.1\t0.954\nStructural MRI metrics\tStructural MRI metrics\t\t\t\t\t\t\nMean TIV???\t1620.4\t\t147.4\t1524\t\t126.3\t0.026\nMean WM\t496.7\t\t69.2\t473.8\t\t52.7\t0.262\nMean GMV???\t656.2\t\t42.8\t625.7\t\t47.9\t0.038\nMean WMHV\t6.9\t(0.5\u201330.7)\t7.8\t5.3\t(0.3\u201322.9)\t5.5\t0.42\n### Caption\nClinical characteristics of the MS patients.\n### Footer\n* = p\u2013value < 0.05Abbreviations: Age = Age in years, BDI\u2014II = Beck depression inventory version II, Disease duration = Years since diagnose, EDSS = Expanded disability status score, ESS = Epworth sleepiness scale, FMS = MS patients with fatigue, FSMCCOGNITIVE = FSMC cognitive score, FSMCMOTOR = FSMC motor score, FSMCTOTAL = Fatigue scale for motor and cognitive functions total score, Gender (M : F) = Male: female ratio, HC = Healthy controls, GMV = Grey matter volume in millilitre, JTHFT = Jebsen-Taylor hand function test, MS = Multiple sclerosis, NFMS = MS patients without fatigue, WMHV = White matter hyperintensities volume (i.e. white matter lesions, in millilitre), 9-HPT = Nine hole peg test, p = P\u2013value, PASAT = Paced auditory serial addition test, PSQI = Pittsburgh sleep quality index, SD = Standard deviation, SDMT = Symbol digit modalities test, TIV = Total intracranial (volume in millilitre), Treatment = In treatment with multiple sclerosis disease modifying drugs, WMV = White matter volume in millilitre.\n\n\n## ID: pone.0201162.t003\n### Label: Table 3\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tUnnamed: 2_level_0\tPeak\tMNI-coordinates\tMNI-coordinates\tMNI-coordinates\tP value\tCluster size\nContrast\tRegion\tSide\tT value\tx\ty\tz\tUnnamed: 7_level_1\tUnnamed: 8_level_1\nMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\tMain effect of task\u2014Linear scaling of the main effect of task with FSMCMOTORscores\nMS(positive)\tCerebellum VI\tR\t4.68\t30\t-44\t-24\t0.046 (SVC)\t35\nHC > MS\tSTG\tR\t5.98\t48\t-34\t20\t0.004\t123\nNFMS > FMS\tPMd\tL\t6.27\t-30\t4\t46\t0.017\t87\n\tPMd\tL\t4.75\t-26\t-12\t74\t0.049 (SVC)\t39\n\tdmPFC\tL\t5.96\t-12\t38\t54\t0.038\t70\nFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\tFirst-order time modulation of task-related activity\u2014Linear change in task-related activity\nMS(negative)\tCerebellum VI\tL\t4.75\t-34\t-46\t-32\t0.042 (SVC)\t30\nHC > MS\tPCC\tR/L\t5.62\t2\t-44\t10\t0.018\t685\n\tLingual gyrus\t\t\t\t\t\t\t\nFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\tFirst-order time modulation of activity\u2014Linear scaling the with FSMCMOTORscores\nHC > MS\tPMd\tR\t4.60\t22\t-12\t78\t0.031 (SVC)\t31\n\tCerebellum\tL\t4.57\t-16\t-58\t-12\t0.034 (SVC)\t11\n\tLingual gyrus\tL\t7.17\t-16\t-54\t-10\t0.000\t185\n### Caption\nGroup results of the fMRI data.\n### Footer\nGroup results of the fMRI data. T-values and p-values refer to the voxel showing peak difference in a given cluster. Cluster extent is defined by an uncorrected cluster-forming extent threshold of p < 0.001. The p-values reflect significant activity changes at peak-voxel level (p-value < 0.05) after whole-brain FWE correction for multiple comparisons. SVC = small volume correction: For voxels within the a priori defined ROIs, FWE correction only considered the voxels within the mask comprising all pre-defined ROIs. As for the whole-brain analysis, the FWE method was applied at the peak-voxel level. Only voxels with a FWE corrected p-value < 0.05 were considered to be significant. Cerebellum VI = Cerebellum lobe VI. dmPFC = Dorsomedial prefrontal cortex. FMS = Fatigued MS patients. FSMCMOTOR = Fatigue Scale for Motor and Cognitive Functions, motor subscale. HC = Healthy controls. MS = Multiple sclerosis. NFMS = non-fatigued MS patients. PCC = Posterior cingulate cortex. PMd = Dorsal premotor cortex. STG = Superior temporal gyrus.\n", "metadata": {"pmcid": 6200185, "text_md5": "253020e7e54abef0a0668cf4f0947b11", "field_positions": {"authors": [0, 170], "journal": [171, 179], "publication_year": [181, 185], "title": [196, 326], "keywords": [340, 340], "abstract": [353, 2162], "body": [2171, 46021], "tables": [46034, 54710]}, "batch": 2, "pmid": 30356315, "doi": "10.1371/journal.pone.0201162", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6200185", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6200185"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6200185\">6200185</a>", "list_title": "PMC6200185  Cerebellar and premotor activity during a non-fatiguing grip task reflects motor fatigue in relapsing-remitting multiple sclerosis"}
{"text": "Peraza, Luis R. and Kaiser, Marcus and Firbank, Michael and Graziadio, Sara and Bonanni, Laura and Onofrj, Marco and Colloby, Sean J. and Blamire, Andrew and O'Brien, John and Taylor, John-Paul\nNeuroimage Clin, 2014\n\n# Title\n\nfMRI resting state networks and their association with cognitive fluctuations in dementia with Lewy bodies\n\n# Keywords\n\nCognitive fluctuations\nVisual hallucinations\nResting state network\nLewy bodies\nDementia\n\n\n# Abstract\n \nCognitive fluctuations are a core symptom in dementia with Lewy bodies (DLB) and may relate to pathological alterations in distributed brain networks. To test this we analysed resting state fMRI changes in a cohort of fluctuating DLB patients (  n  \u00a0=\u00a016) compared with age matched controls (  n  \u00a0=\u00a017) with the aim of finding functional connectivity (FC) differences between these two groups and whether these associate with cognitive fluctuations in DLB. Resting state networks (RSNs) were estimated using independent component analysis and FC between the RSN maps and the entirety of the brain was assessed using dual regression. The default mode network (DMN) appeared unaffected in DLB compared to controls but significant cluster differences between DLB and controls were found for the left fronto-parietal, temporal, and sensory\u2013motor networks. Desynchronization of a number of cortical and subcortical areas related to the left fronto-parietal network was associated with the severity and frequency of cognitive fluctuations. Our findings provide empirical evidence for the potential role of attention\u2013executive networks in the aetiology of this core symptom in DLB. \n   Highlights  \n  \nWe report resting state network (RSN) alterations in dementia with Lewy bodies (DLB). \n  \nThe default mode network was intact in DLB compared to healthy controls (HC). \n  \nFronto-parietal, temporal, and\u00a0sensory\u2013motor RSNs showed differences (DLB\u00a0<\u00a0HC). \n  \nThe left fronto-parietal network (FPN) correlated with cognitive fluctuations in DLB. \n  \nThe FPN therefore may be a potential marker for cognitive fluctuations in DLB. \n  \n \n\n# Body\n \n## Introduction \n  \nDementia with Lewy bodies (DLB) accounts for approximately 4\u20138% of dementia cases ( ). It is characterized by complex visual hallucinations (VHs), cognitive fluctuations, and parkinsonism. These three core features help differentiate DLB from other dementias such as Alzheimer's disease (AD) with the presence of at least two out of the three required to make a diagnosis of probable DLB ( ). Out of the three core features, probably the least understood is that of cognitive fluctuations and this lack of knowledge has hampered the development of appropriate treatment for this deleterious symptom in DLB ( ). \n\nAs a core feature, cognitive fluctuations may be more specific to DLB than parkinsonism ( ). Quantitatively and qualitatively, cognitive fluctuations appear to relate to intrinsic brain processes rather than environmental or situational factors ( ;  ), may associate with attentional impairments, and\u00a0often co-occur with visual hallucinations. Their presence can have significant functional impacts upon patients and their carers ( ;  ). \n\nNeurobiologically, cognitive fluctuations are likely to arise from distributed functional network perturbations rather than specific structural abnormalities ( ); on electroencephalography (EEG), increased and fluctuating slow wave activity occurs in posterior regions in DLB patients compared to Alzheimer's disease (AD) patients and these changes have been correlated with the frequency and severity of clinically observed cognitive fluctuations ( ;  ). Similarly, relative decreases in cerebral perfusion in posterior parietal areas covariant with relative increases in perfusion in distributed motor networks have been observed in fluctuating DLB patients ( ). Another approach which may be sensitive to cortical network disturbances associated with cognitive fluctuations is resting state blood oxygen level dependent (BOLD) functional magnetic resonance imaging (fMRI) as this allows the characterization of resting state networks (RSNs) that are task free and thus are not confounded by task dependent differences in cognitive or motor function which may be compromised in patients with dementia and/or parkinsonism. \n\nCurrent research on RSNs and dementia has focussed mainly on AD, where the current consensus points to a disconnection of the default mode network (DMN) as intrinsic to this type of dementia (see for instance\u00a0 ;  , and  ). This network is highly related to consciousness and memory ( ;  ) which are primarily affected in AD. In DLB, recent work by   and   has examined the DMN although findings on how it is altered in DLB have been inconsistent which may, in part, relate to methodological and cohort differences between studies. \n\nGiven the intimated role of the DMN in internal mentation and its role in attentional/ behavioural performance ( ) it has been speculated that alterations in the DMN may relate to cognitive fluctuations in DLB. However resting fMRI data on this is limited. A report by   focussed on the role of the DMN in DLB cognitive fluctuations and they found, contrary to expectation, that the DMN in DLB patients with cognitive fluctuations was as active as in healthy controls, in contrast to AD patients where it was under-active. It was suggested that this either represented a compensatory attempt to maintain DMN function ( ), due to the fact that there is relatively greater pathological load in AD compared to DLB, or that there is a loss of frontal inhibition of the DMN in DLB. \n\nAlternatively, it may be that there is a failure to switch out of the DMN to task positive or attentional networks which is more relevant for attentional lapses ( );   observed that despite being relatively intact in DLB, the DMN failed to deactivate during motion and colour tasks, which may be indicative of impairments in changing from resting state to focussed attention. \n\nTherefore, RSNs other than the DMN may be more apposite to DLB and the manifestation of cognitive fluctuations, in particular the fronto-parietal networks (also known as executive control networks), and which include both the dorsal attention network (DAN) and ventral attention network (VAN) ( ;  ;  ). \n\nOur questions were therefore to, firstly, establish if the DMN was functionally impaired in DLB patients compared to similarly aged controls and, secondly, in an exploratory data-driven manner, determine what other RSNs aside from the DMN are altered in DLB and if these RSN changes were associated with the severity and frequency of cognitive fluctuations. \n\nIn this study we employed a \u201cdual-regression\u201d analysis ( ) approach on DLB patients with cognitive fluctuations compared to age matched controls. Dual regression has been used successfully in other studies investigating dementia (e.g.  ). In dual regression the selected RSN maps are used in a spatial regression per subject to obtain a single time series which then is regressed again (hence the name of dual regression) to obtain subject specific spatial correlation maps. Dual regression may be superior to using the original independent component time series as seeds since it recovers more features for an individual subject's correlation map. \n\n\n## Methods \n  \n### Subjects \n  \nParticipants (  n  \u00a0=\u00a016 DLB and   n  \u00a0=\u00a017 controls) were recruited from the local dwelling population of patients who had been referred to local old age psychiatry and neurology services. Approval for the current study was granted by the Newcastle Ethics Committee. \n\nDiagnosis of DLB was performed by two experienced clinicians using standardized clinical diagnostic criteria. Nine out of the 16 DLB participants had previously undergone dopaminergic imaging and of these all had reduced bilateral uptake of tracer within their striata. Clinical assessments included the Cambridge Cognitive Examination (CAMCOG), Mini-Mental State Examination (MMSE), Neuropsychiatric Inventory (NPI) ( ), and the Unified Parkinson's Disease Rating Scale (UPDRS) ( ). Prior to MRI acquisition, the Clinical Assessment of Fluctuations (CAF) ( ) was administered to patients to assess cognitive fluctuations; this measure provides a quantification of the frequency and duration of fluctuations in patients. For assessment of visual hallucinations, caregivers were asked to complete the hallucinations subscale of the NPI, with specific reference to the occurrence of visual hallucinations in the past month in terms of severity and frequency (NPI ). \n\nSimilarly aged controls were selected from friends and spouses of patients and demonstrated no history of psychiatric or neurological brain disease and an MMSE score\u00a0>\u00a026. From our DLB group, 13 participants were taking cholinesterase inhibitors, 8\u00a0 -DOPA based medications, one of the DLB participants was taking a dopamine agonist, two subjects antidepressants, and two low dose benzodiazepines (clonazepam) for suspected REM-sleep behaviour disorder. \n\n\n### Data acquisition \n  \nImaging was performed using a 3\u00a0T Philips Intera Achieva scanner. Structural images were acquired with a magnetization prepared rapid gradient echo (MPRAGE) sequence, sagittal acquisition, echo time 4.6\u00a0ms, repetition time 8.3\u00a0ms, inversion time 1250\u00a0ms, flip angle\u00a0=\u00a08\u00b0, SENSE factor\u00a0=\u00a02, and in-plane field of view 240\u00a0\u00d7\u00a0240\u00a0mm with slice thickness 1.0\u00a0mm, yielding a voxel size of 1.0\u00a0\u00d7\u00a01.0\u00a0\u00d7\u00a01.0\u00a0mm. Resting state scans were obtained with a gradient echo echo-planar imaging (GE-EPI) sequence with 25 contiguous axial slices, 128 volumes, anterior\u2013posterior acquisition, in-plane resolution\u00a0=\u00a02\u00a0\u00d7\u00a02\u00a0mm, slice thickness\u00a0=\u00a06\u00a0mm, repetition time\u00a0=\u00a03000\u00a0ms, echo time\u00a0=\u00a040\u00a0ms, and field of view\u00a0=\u00a0260 \u00d7\u00a0260\u00a0mm. An axial orientation gradient echo T1 weighted image was also acquired\u00a0to aid in coregistering the resting state to the structural TR 223\u00a0ms, TE 2.3\u00a0ms, flip angle 80\u00b0, slice thickness 4\u00a0mm, and pixel size 1.5\u00a0\u00d7\u00a01.5\u00a0mm. \n\n\n### Analysis of MRI and resting state \n  \nData analysis for RSN inference was performed using time concatenated (controls\u00a0+\u00a0DLB subjects) MELODIC from the FMRIB's Software Library (FSL version 4.1;  ). Pre-processing included FSL tool FLIRT motion correction with spatial smoothing FWHM of 6.0\u00a0mm, and high pass filter cutoff equivalent to 150\u00a0s. Registration to the MNI152 standard brain for both structural and functional MRI was carried out using FSL tool FNIRT (non-linear coregistration with 10\u00a0mm warp resolution). The concatenated volumes were decomposed in 42 spatial component maps. Component maps of interests were selected by visual inspection according to previous literature ( ;  ;  ) and having a concentrated power spectrum below 0.1\u00a0Hz. The maps derived are shown in   and included the central and lateral visual networks, DMNs I and II, left (L) and right (R) fronto-parietal, sensory\u2013motor, and temporal networks. \n\nGroup averages and between subject analyses for group comparisons were performed using dual-regression (available in FSL 4.1). For statistical significance non-parametric permutation was implemented in dual-regression (10,000 permutations), where corrections for age, sex and grey matter (using feat_gm_prepare script available in FSL 4.1) were also included as covariates in the design matrix. Finally, in order to assess positive relations of the dual-regressed time series we implemented contrast masking, i.e. group comparison results were masked by group average maps (voxels that fell within either DLB or control group average maps, thresholded at   p  -value\u00a0<\u00a00.05, familywise error (FWE) correction for multiple comparison using threshold free cluster enhancement (TFCE)). No statistical correction for multiple RSNs was implemented. \n\n\n### Statistical analysis of clinical measures. \n  \nStatistical results in   including the two-sample   t  -tests were obtained using R (version 2.15.3, psych library). The association of RSNs was tested by Spearman's rank correlation against the CAF scale for cognitive fluctuations. As part of a secondary analysis we also considered RSN alterations associated with other DLB symptoms including the degree of parkinsonism (UPDRS) and the severity and frequency of visual hallucinations (NPI ) in DLB patients. Statistical significance for regression of clinical measures with seeded significant clusters given by dual regression (subjects' normalized   z  -score images) was tested using nonparametric permutations (10,000 permutations) for Spearman's correlations (with correlation equating zero as null hypothesis) and implemented in Python (scipy.stats library version 0.9.0). Only clusters >10\u00a0voxels were analysed for correlation with clinical scores.   \nDemographic, clinical and cognitive measures. \n          \n\nFurthermore, as an alternative method we also run a non-parametric permutation analysis to further assess relations between the core clinical scores and the significant clusters using the FSL general linear model (GLM) tool to create a one-group design matrix (DLB) with the clinical scores as covariates of interest. Significance was assessed using the FSL randomize function. The non-parametric analysis is shown in  . \n\n\n\n## Results \n  \n### Demographics and clinical measures \n  \nOur study included 16 patients diagnosed with DLB and 17 control subjects. Demographic and clinical scores including relevant subscales are shown in  . Both groups, DLB patients and controls, are matched for age (  p  -values\u00a0=\u00a00.524). \n\nAs expected, compared to controls, the DLB group was cognitively impaired, had a variable degree of cognitive fluctuations as measured by the CAF, as well as evidence of parkinsonism and recurrent visual hallucinations with variable frequency and severity. \n\n\n### Resting state networks and dual-regression \n  \nA total of 42 component maps were obtained by MELODIC using default FSL parameters for data dimension estimate (17 component maps were identified as noise or artefactual origin, 11 components were identified as resting state networks, and the remaining 14 maps were of unknown origin). From the identified RSNs, the L/R fronto-parietal, sensory\u2013motor, DMN (I and II), temporal, and medial and lateral visual networks were selected for dual regression. The automatic MELODIC threshold which fits a mixture model to the histogram of intensity values (alternative hypothesis test at   p  \u00a0>\u00a00.5) for each map was used for visual inspection. \n\nFor dual regression, significant decreased FC in DLB compared to controls (DLB\u00a0<\u00a0controls;   p  -value\u00a0<\u00a00.05, FWE corrected for multiple comparisons using TFCE) was found for three networks; the L fronto-parietal, temporal, and sensory\u2013motor networks. No statistical differences were found for the DMN (I and II), the R fronto-parietal, and the medial and lateral visual networks. None of the RSNs showed significant increased FC (DLB\u00a0>\u00a0controls;   p  -value\u00a0<\u00a00.05 FWE corrected). \n\nSignificant clusters from these networks for the DLB\u00a0<\u00a0control comparisons are reported in  . Nine clusters were found for the L fronto-parietal network covering several regions such as the L pallidum, L/R putamen, lingual gyrus, intracalcarine cortices, and R frontal operculum ( a). For the temporal network shown in  , fourteen clusters were found covering the L/R lingual gyrus, R putamen, R precentral gyrus, L cingulate gyrus (middle) and L/R intracalcarine cortices. The sensory\u2013motor network showed ten clusters. The largest one widely distributed encompassing both occipital (e.g. L/R lateral occipital cortex, L/R lingual gyrus) and parietal (e.g. L supramarginal gyrus) areas. Two smaller clusters cover the R superior temporal and the L middle cingulate gyri as shown in  .   \nCluster report from dual regression output of significant clusters. All clusters are FWE corrected for multiple comparisons using TFCE. Fronto-parietal network (FPN), sensory\u2013motor network (SMN), temporal network (TN). * indicates the lowest   p  -value region. \n    \nDual regression significant clusters shown in blue colour (  p  -value\u00a0<\u00a00.05, FWE corrected). Resting state networks are shown in green. a) Left fronto-parietal network. b) Temporal network. c) Sensory\u2013motor network. Dual-regression results are corrected for sex, age, and grey matter. Brain images are nonlinear coregistered average brains transformed to MNI152 space and shown in radiological convention. \n  \n\nA potential confound affecting the patterning of RSNs, particularly in a neurodegenerative group may have been volumetric loss specific to the DLB group. To test this, we carried out a voxel-based morphometry (VBM) analysis using the statistical parametric mapping software, SPM8 ( ). However we found no structural differences between the groups that may have affected our functional findings ( ); only two significant clusters were identified and these lay external to our functional results given by dual-regression. \n\n\n### Regression analysis with cognitive fluctuations and other clinical variables \n  \nInferred clusters (DLB\u00a0<\u00a0controls) were seeded and 15 indices (i.e. those clusters\u00a0>10\u00a0voxels) from the normalized   z  -score images were extracted from the DLB group. Regression results and significant uncorrected   p  -values are shown in  , which shows the clusters where significant correlations were found with the CAF score. Significant correlations for the L fronto-parietal network were found between clusters FPN-1, FPN-3, FPN-4 and FPN-6 (which include the L pallidum, L lingual gyrus, and the R putamen, see  ) and the CAF score. Clusters for the temporal and sensory\u2013motor RSNs did not show significant correlations with CAF.   \nCorrelation with DLB core clinical measures; CAF with dual-regression significant clusters. \n  \n\nThe non-parametric permutation analysis to assess relations between the CAF scores and LFPN clusters showed similar results (see  ). \n\n\n\n## Discussion \n  \nIn summary, we found from our exploratory dual-regression analysis that the sensory\u2013motor, temporal and L fronto-parietal networks showed significantly lower FC at several regions in DLB patients compared to controls. For the sensory\u2013motor network decreased FC (DLB\u00a0<\u00a0controls) was observed in three main clusters covering several regions on posterior areas of the brain (occipital and parietal areas mainly;  ); for the temporal network, significantly decreased FC was seen in the L/R lingual gyri and intracalcarine cortices, the L lateral occipital cortex, R insular cortex, the L/R cingulate gyrus, and the temporal occipital fusiform cortex ( ). Finally our dual-regression results showed significant clusters for the L fronto-parietal network in regions that include the L/R putamen, L/R pallidum, R frontal operculum, and R supramarginal gyrus ( ). In contrast, we were not able to find significant differences in the DMN between DLB patients and the control group and these results concord with previous publications reporting a spared or increased DMN in DLB ( ;  ;  ). We discuss the implications of these findings apposite to these networks below. \n\n### Sensory\u2013motor network \n  \nThis network is central to the execution of voluntary movements ( ) and abnormalities in the functional connectivity of the sensory\u2013motor network have been reported in Parkinson's patients. In addition the topography features of this network may be dopamine dependent ( ). Therefore, given the presence of parkinsonism in DLB, it is not unsurprising that we found that FC of this network was affected. Exploratory analysis tentatively supported this as there was a trend association between the severity of parkinsonism as measured by the UPDRS and the functional disconnectivity of this network (Spearman's rank correlation between cluster SMN-1 and UPDRS score:   p  -value\u00a0=\u00a00.073 uncorrected). The lack of strong relationship may be driven by the tendency to less parkinsonism and known variability in nigrostriatal neuronal loss in DLB ( ). \n\nPrior evidence from covariant analyses of perfusion data in DLB have suggested that the expression of both anti-correlated motor (e.g. supplementary motor area and putamen) and non-motor (parietal) networks is intrinsic to cognitive fluctuations and attentional dysfunction in DLB ( ). These areas overlap with the sensory\u2013motor network reported here although in the present cohort we found no evidence of an association between CAF and the FC reduction in the sensory\u2013motor network of DLBs. Possible explanations for this may be differences in the sample, investigative modality (resting state vs. perfusion) or analysis approach between the present study and that of\u00a0 . \n\n\n### Temporal network \n  \nThis network covers the auditory system, in specific the primary and secondary auditory cortices. Alterations in FC in this network did not associate with cognitive fluctuations in DLB although\u00a0it is notable that the temporal occipital fusiform cortex is mainly associated with body and face recognition and the lingual gyri on the other hand have been associated with processing of complex images. Certainly visuo-perceptual deficits ( ) and abnormalities in the ventral visual stream ( ;  ) have been reported in DLB. Similarly a diffusion tensor imaging (DTI) study published by   found lower fractional anisotropy (FA) in visual-related areas in DLB patients and lower FA values in bilateral inferior occipitofrontal fasciculus (IOFF; connecting the orbitofrontal cortex with the occipital lobe) and the L inferior longitudinal fasciculus (ILF; connecting the inferior temporal cortex with the occipital lobe). These findings concord with our results showing a disconnection between occipital regions and the temporal RSN. However on our secondary analyses none of the significant clusters related to the temporal RSN correlated with the severity or frequency of visual hallucinations (  p  -values\u00a0>\u00a00.13) suggesting that FC alterations of the temporal network of DLBs while perhaps being permissive to the manifestation of hallucinations, do not predict, in themselves, hallucination severity or frequency. \n\nFurthermore, we did not see a significant correlation between the thalamic cluster (TN-6) and cognitive fluctuations. This was somewhat surprising given that the thalamus has roles in mediation of arousal and attention ( ). In DLB, specifically, alterations in thalamic perfusion in DLB patients have also been related to this symptom ( ) and more recent work with functional resting state MRI has also found altered connectivity between the thalamus and frontal and limbic (cingulate cortex) regions ( ) although the relationship of this altered connectivity to clinical symptom expression was not described in this paper. \n\nExplanations for the apparent lack of association between thalamic changes in RSN connectivity and cognitive fluctuations in our study may include the lower disease severity of DLB group compared to other studies. However it is notable that thalamic involvement in the manifestation of fluctuations has not been noted in other perfusion studies which take a network perspective ( ). Further studies focussing on the structure\u2013function role of the thalamus in DLB which include active attentional task comparisons with resting state may be helpful. \n\n\n### Left fronto-parietal network and default mode network \n  \nThe fronto-parietal network, also known in the literature as the attentional network, is composed of the VAN and DAN. The VAN is known to respond to task-relevant distractors, and the DAN responds together with the VAN when reorientation of attention is needed ( ). Even though the attentional system is reported as bilateral for attentional tasks, in resting state it is lateralized for the VAN while the DAN remains bilateral ( ). \n\nIn the present study areas with reduced FC with this network in DLBs included the putamen and pallidum, R frontal operculum, and R supramarginal gyrus; these are areas which have been implicated in the attentional control network ( ;  ), and specifically we found that the putamen and pallidum bilaterally showed significant correlation with the CAF score. Given the conflation between attention dysfunction and cognitive fluctuations in DLB ( ) it is not unsurprising that attentional networks have implicated in the aetiology of cognitive fluctuations ( ;  ). Interestingly, we did not see any association with FC in this network and the severity of parkinsonism (as measured by the UPDRS) given the association with a number of putamenal clusters. However the fronto-parietal attentional network is not a motor network and thus this finding is perhaps unsurprising; rather the finding of putamen disconnectivity may point towards the cognitive role of subcortical motor areas ( ) and is in tune with previous data implicating motor networks in attentional and cognitive dysfunction in DLB ( ). \n\nOur findings of an intact DMN in DLB compared to controls, yet abnormal fronto-parietal network which associates with the CAF, point towards this latter network having a specific role in DLB associated cognitive fluctuations. This is consistent with previous findings presented by   suggesting decreased resting state FC between frontal and parietal areas in DLB patients with more marked cognitive fluctuations although this was observed in the right hemisphere rather than the left, unlike the current study. \n\nLateralization in our results towards the L fronto-parietal network is challenging to explain, although our findings are consistent with previous data by   who observed a lateralization of the DLB pathology towards the left brain hemisphere by a disconnection of white matter tracts. \n\nIt is notable that recent work by  found a relation between both the putamina and the left fronto-parietal network with motor chunking and event segmentation; the latter being a method used by the brain to divide our daily living activities in a set of shorter segments that are concatenated and where attention is increased at the end and start of each event ( ) and thus, speculatively, our observation of lower functional connectivity between the left fronto-parietal network with putamenal regions and its correlation with the CAF score might imply that cognitive/attentional fluctuations might relate to aberrant event segmentation although specific task-related paradigms would be needed to test this hypothesis. \n\n\n### Common elements in dysfunctional networks in DLB \n  \nAll three of the RSNs (L fronto-parietal, temporal, and sensory\u2013motor networks) that displayed reduced FC in DLB compared to controls had functional disconnectivity with occipital lobe structures, specifically the lingual gyrus and calcarine cortices. The ubiquity of desynchronization of the lingual and calcarine gyri that we observed across several RSNs in the present study is in keeping with posterior, occipital changes which occur in this condition (for example, perfusion and metabolism deficits;  ;  ;  ) and which have been postulated to link with the increased propensity of visuo-perceptual deficits and visual hallucinations which typify DLB ( ). However despite evidence of desynchronization of these non-visual RSNs with occipital lobe regions, surprisingly, we did not see any gross differences in functional connectivity in visual RSNs in themselves. This may reflect the variable findings reported across different investigative modalities, on the one hand, demonstrating specific deficits in visual areas in DLB patients ( ;  ) and others suggesting, that certainly early/lower visual areas are intact ( ;  ). The present findings may suggest that abnormalities in the visual system in DLB are arising as a consequence of changes in regions reciprocally connected but external to the visual system and/or in the connectivity of these regions with (e.g. top-down attentional networks) visual areas. For example desynchronization of L fronto-parietal, temporal, and sensory\u2013motor networks with visual areas may be explained by structural connectivity changes in the white matter that connects the occipital lobe to higher association areas and this is supported by a number of DTI studies which have demonstrated occipital white matter abnormalities ( ;  ). Alternatively, our failure to see visual RSN abnormalities may be related to the relatively mild cognitive impairment and low visual hallucination symptom score in our cohort (see  ); it may be that with more severely affected DLBs, alterations in visual RSNs may become more manifest. \n\nFunctional disconnection between controls and DLBs was also evident in the clusters which covered several regions including the putamen and pallidum with regard to both the fronto-parietal and temporal networks. Given the presence of parkinsonism in DLB patients it is not surprising that subcortical motor areas may display abnormalities although we failed to see any clear correlation between these clusters and the severity of parkinsonism on our secondary analyses as measured on the UPDRS. However it may be that these areas are more relevant to cognitive fluctuations since these showed disconnection from the LFPN; in support of this covariant perfusion changes between putamen and parietal areas ( ) appear to associate with cognitive fluctuations in DLB ( ), and the present data provide further support for a role in cognitive fluctuations in DLB by subcortical motor networks. \n\n\n### Limitations \n  \nThe data presented, despite our a priori focus on cognitive fluctuations remains exploratory and thus, in particular, correlations between clinical variables and functional connectivity in DLBs need to be treated with caution and need replication. \n\nDiagnosis of patients was on the basis of antemortem clinical examination rather than pathological diagnosis which represents another potential limitation. However this was mitigated against by the use of standardized clinical criteria and robust, well validated clinical scales and the diagnostic approach applied to the current patient cohort has been shown to have high specificity in autopsy validation studies ( ). Another limitation is that 15 out of 16 of the DLB patients were on cholinesterase inhibitors which may have biased our findings; for example   found restored resting state activity compared to healthy controls with improvements in controlled attention in Parkinson's disease patients under rivastigmine treatment. In addition, in our study, the DLB group was relatively mild in terms of cognitive impairment and neuropsychiatric symptoms compared to previous resting state studies in DLB (see for instance  ) and this may contribute to cohort specific differences in resting state findings. However despite our DLB group being cognitively milder and on medications, our patients expressed a wide range of cognitive fluctuations in terms of severity and frequency which strongly coupled with RSN disconnections. Thus we would argue that even in mild DLB, RSN disconnectivity is evident and may be helpful in early diagnosis although our data would need to be contrasted against a control dementia group. \n\n\n\n## Conclusions \n  \nIn conclusion, we found a number of RSNs which were functionally disconnected in DLB compared to controls and specifically that there was an association between disconnectivity of the L fronto-parietal network with cognitive fluctuations. Our results provide support for the concept that cognitive fluctuations in DLB depend upon distributed cortical and subcortical networks and may involve attentional systems. However our present data cannot determine whether disruption to the fronto-parietal RSN is merely correlative with cognitive fluctuations or is actually causally linked. \n\nFurther studies characterizing how longitudinal changes in RSNs, mainly the fronto-parietal network, relate to cognitive fluctuations are necessary as well as fMRI attention-task related studies to explore the dynamic switching between default brain states and task-positive networks in DLB. \n\n \n\n# Table(s)\n## ID: tbl1\n### Label: Table\u00a01\nUnnamed: 0\tDLB(n\u00a0=\u00a016)\tControls(n\u00a0=\u00a017)\tp-Value\nM:F (% female)\t13:3 (19%)\t14:3 (18%)\t\u03c72\u00a0=\u00a00.0067, p\u00a0=\u00a00.934???\nAge\t76.2\u00a0\u00b1\u00a05.7\t77.3\u00a0\u00b1\u00a04.7\tt31\u00a0=\u00a00.415, p\u00a0=\u00a00.524???\nMMSE\t24.2\u00a0\u00b1\u00a03.75\t29.1\u00a0\u00b1\u00a00.83\tt31\u00a0=\u00a027.38, p\u00a0<\u00a00.001???\nUPDRS total\t15.94\u00a0\u00b1\u00a05.93\t1.41\u00a0\u00b1\u00a01.87\tt31\u00a0=\u00a092.46, p\u00a0<\u00a00.001???\nCAMCOG total\t78.8\u00a0\u00b1\u00a011.9\t96.4\u00a0\u00b1\u00a03.43\tt31\u00a0=\u00a033.95, p\u00a0<\u00a00.001???\nCAF total\t3.56\u00a0\u00b1\u00a04.35\tna\tna\nNPI total\t8.60\u00a0\u00b1\u00a05.59???\tna\tna\nNPI hallucinations subscale\t1.75\u00a0\u00b1\u00a01.84\tna\tna\n### Caption\nDemographic, clinical and cognitive measures.\n### Footer\nValues expressed as mean\u00a0\u00b1\u00a01SD.Abbreviations: DLB, dementia with Lewy bodies; MMSE, Mini-Mental State Examination; CAMCOG, Cambridge Cognitive Examination; NPI, Neuropsychiatric Inventory;\u00a0CAF, Clinical Assessment of Fluctuations; UPDRS, Unified Parkinson's Disease Rating Scale; na, not applicable.\n\n\n## ID: tbl2\n### Label: Table\u00a02\nUnnamed: 0\tNumber of voxels\tp-Value\tMNI (X, Y, Z)\tLocation\nCluster code\tFronto-parietal network\t\t[Max\u00a0z-score]\t\nFPN-1\t107\t0.022\t[\u221226, \u221210, 0]\tL pallidum*, L putamen\nFPN-2\t103\t0.03\t[38, 26, 8]\tR frontal operculum*, R inferior frontal gyrus,\nFPN-3\t93\t0.03\t[\u22122, \u221270, 0]\tL lingual gyrus*, L/R intracalcarine cortices, R lingual gyrus\nFPN-4\t67\t0.029\t[34, \u22122, 4]\tR putamen*, R pallidum\nFPN-5\t27\t0.033\t[34, \u221230, 32]\tR white matter*, R supramarginal gyrus\nFPN-6\t26\t0.027\t[14, 10, \u22124]\tR putamen*, R pallidum\n\t3 clusters\u00a0<\u00a010\u00a0voxels\t\t\t\n\t\t\t\t\n\tSensory\u2013motor network\t\t\t\nSMN-1\t2226\t0.001\t[\u221242, \u221274, \u22124]\tL lateral occipital cortex, inferior division*, L/R lingual gyrus, R/L intracalcarine cortex, L/R precentral gyrus, L/R precuneus, L planum temporale\nSMN-2\t30\t0.005\t[50, \u221210, 12]\tR superior temporal gyrus, posterior division*, R planum temporale\nSMN-3\t21\t0.034\t[\u22126, \u22126, 32]\tL middle cingulate gyrus*\n\t7 clusters\u00a0<\u00a010\u00a0voxels\t\t\t\n\t\t\t\t\n\tTemporal network\t\t\t\nTN-1\t834\t0.003\t[\u221210, \u221282, \u221212]\tL lingual gyrus*, R lingual gyrus, L/R intracalcarine cortex, L lateral occipital cortex, inferior division, L temporal occipital fusiform cortex.\nTN-2\t786\t0.01\t[\u221210, \u22126, 32]\tL cingulate gyrus (middle*), R cingulate gyrus.\nTN-3\t206\t0.01\t[38, \u22122, 4]\tR insular cortex*, R putamen, R frontal orbital cortex\nTN-4\t67\t0.011\t[34, 6, 24]\tR precentral gyrus*, R inferior frontal gyrus\nTN-5\t21\t0.034\t[22, \u221238, \u221212]\tR lingual gyrus*, R parahippocampal gyrus, posterior division\nTN-6\t15\t0.036\t[\u221210, \u221218, \u22128]\tL white matter*, L brain stem, L thalamus\n\t8 clusters\u00a0<\u00a010\u00a0voxels\t\t\t\n### Caption\nCluster report from dual regression output of significant clusters. All clusters are FWE corrected for multiple comparisons using TFCE. Fronto-parietal network (FPN), sensory\u2013motor network (SMN), temporal network (TN). * indicates the lowest p-value region.\n### Footer\nNone\n\n\n## ID: tbl3\n### Label: Table\u00a03\nCluster\tSpearman's rank correlation (p-value)\nFPN-1\t0.603 (0.0184)\nFPN-2\t0.482 (0.0630)\nFPN-3\t0.612 (0.0124)\nFPN-4\t0.519 (0.0442)\nFPN-5\t0.066 (0.7926)\nFPN-6\t0.551 (0.0344)\n### Caption\nCorrelation with DLB core clinical measures; CAF with dual-regression significant clusters.\n### Footer\nNone\n", "metadata": {"pmcid": 3984441, "text_md5": "23a0ea78bfbb33da2c09b8101efcfb19", "field_positions": {"authors": [0, 193], "journal": [194, 209], "publication_year": [211, 215], "title": [226, 332], "keywords": [346, 434], "abstract": [447, 2076], "body": [2085, 31964], "tables": [31977, 35007]}, "batch": 2, "pmid": 24818081, "doi": "10.1016/j.nicl.2014.03.013", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3984441", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=3984441"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3984441\">3984441</a>", "list_title": "PMC3984441  fMRI resting state networks and their association with cognitive fluctuations in dementia with Lewy bodies"}
{"text": "Z\u00fcst, Marc Alain and Colella, Patrizio and Reber, Thomas Peter and Vuilleumier, Patrik and Hauf, Martinus and Ruch, Simon and Henke, Katharina\nPLoS One, 2015\n\n# Title\n\nHippocampus Is Place of Interaction between Unconscious and Conscious Memories\n\n# Keywords\n\n\n\n# Abstract\n \nRecent evidence suggests that humans can form and later retrieve new semantic relations unconsciously by way of hippocampus\u2014the key structure also recruited for conscious relational (episodic) memory. If the hippocampus subserves both conscious and unconscious relational encoding/retrieval, one would expect the hippocampus to be place of unconscious-conscious interactions during memory retrieval. We tested this hypothesis in an fMRI experiment probing the interaction between the unconscious and conscious retrieval of face-associated information. For the establishment of unconscious relational memories, we presented subliminal (masked) combinations of unfamiliar faces and written occupations (\u201cactor\u201d or \u201cpolitician\u201d). At test, we presented the former subliminal faces, but now supraliminally, as cues for the reactivation of the unconsciously associated occupations. We hypothesized that unconscious reactivation of the associated occupation\u2014actor or politician\u2014would facilitate or inhibit the subsequent conscious retrieval of a celebrity\u2019s occupation, which was also actor or politician. Depending on whether the reactivated unconscious occupation was congruent or incongruent to the celebrity\u2019s occupation, we expected either quicker or delayed conscious retrieval process. Conscious retrieval was quicker in the congruent relative to a neutral baseline condition but not delayed in the incongruent condition. fMRI data collected during subliminal face-occupation encoding confirmed previous evidence that the hippocampus was interacting with neocortical storage sites of semantic knowledge to support relational encoding. fMRI data collected at test revealed that the facilitated conscious retrieval was paralleled by deactivations in the hippocampus and neocortical storage sites of semantic knowledge. We assume that the unconscious reactivation has pre-activated overlapping relational representations in the hippocampus reducing the neural effort for conscious retrieval. This finding supports the notion of synergistic interactions between conscious and unconscious relational memories in a common, cohesive hippocampal-neocortical memory space. \n \n\n# Body\n \n## Introduction \n  \nEpisodic memory is a class of declarative memory thought to depend on consciousness of encoding and retrieval [ \u2013 ]. The hippocampus is the neuroanatomical hub governing the encoding and retrieval of episodic memories. Damage to the hippocampal-anterior thalamic axis produces severe impairments of episodic memory, but leaves unconscious forms of memory such as skill-learning or priming intact because these forms of memory depend on extrahippocampal structures [ \u2013 ]. \n\nRecent evidence suggests, however, that episodic memory formation and retrieval is possible even without conscious awareness of encoding and retrieval, and that both encoding and retrieval depend on the hippocampal-anterior thalamic axis [ ]. These findings question classic notions of separate memory systems [ \u2013 ] and support the processing-based memory model [ ] that distinguishes memory systems based on processing modes rather than consciousness. The processing-based memory model distinguishes between memory systems with respect to 3 variables: speed of encoding (rapid versus slow), nature of representation (flexible versus rigid), and memory content (single items versus associations). This model hypothesizes the existence of both a conscious and unconscious form of episodic memory with both forms depending on the hippocampal anterior-thalamic axis. Consciousness, therefore, is not prerequisite for relational encoding and retrieval but rather an independent factor that serves the strengthening of hippocampal memory representations [ ]. \n\nIf episodes can be encoded with and without consciousness by way of the hippocampal anterior-thalamic axis and related cortices [ \u2013 ], the organization of consciously and unconsciously acquired information in a single, cohesive hippocampal memory space is economically and evolutionarily sensible. Linked episodic knowledge\u2014conscious and unconscious\u2014informs and guides us better through life than episodic knowledge that is stored separated according to levels of representation from conscious to unconscious. Episodic memories are dynamic and subject to transformation from conscious to unconscious and vice versa. Consider an unconscious memory trace that suddenly \u201cpops\u201d into consciousness, or implicit knowledge of a hidden sequence in a serial reaction time task [ ], or a rule in the number reduction task [ , ] that become consciously accessible following sleep. Conversely, memory traces can also get purged from conscious access dropping to a pre-conscious representation [ ]. Consciously encoded memories can also become inaccessible when one is instructed to forget them [ ]. In all of these cases, a cohesive memory space provides for a stable organizational structure of memory that allows for shifts in the level of representation from unconscious to conscious and vice versa. Such representational shifts appear more difficult if one assumes a strict division between memory systems based on conscious access. \n\nIf conscious and unconscious episodic memories are both accommodated by the hippocampal memory system, they can be expected to interact both synergistically and competitively. For example, the activation of   unconscious   memories may facilitate the subsequent formation and retrieval of content-congruent   conscious   memories through activation of nearby or overlapping neural assemblies. We tested this hypothesis using functional magnetic resonance imaging (fMRI). In particular, the hippocampus was hypothesized to be place of interactions between unconscious and conscious retrieval processes. \n\nParticipants were first presented with subliminal combinations of unfamiliar faces and occupations (face plus the label \u201cactor\u201d or face plus the label \u201cpolitician\u201d) for unconscious relational encoding. Due to the relational nature of unconscious memory formation, we expected the hippocampus to be activated during unconscious encoding. Following the subliminal presentation of face-occupation combinations, an unconscious-conscious retrieval interaction test was given. We studied whether the unconscious reactivation of the earlier formed face-occupation association would facilitate or inhibit the conscious retrieval of a stored association between a celebrity\u2019s face and his occupation, namely actor or politician. We used portraits of famous actors and politicians as cues for the conscious retrieval of occupations. This relational retrieval draws on both the episodic and the semantic (facts) memory system depending on the experience that the young participants in our study had with movies and political shows/news [ ]. Each test trial included the brief but visible presentation of a former subliminal face, stripped off its occupation label, followed by the presentation of the portrait of a celebrity. Participants were instructed to react to the famous face by deciding whether the depicted person was an actor or a politician ( ). \n   Experimental design.  \n A:   Attention task during subliminal encoding. Participants saw a flickering stream of black-and-white pixel masks. Subliminal stimuli were presented between masks. The top left depicts one encoding trial containing twelve repetitions of one subliminal stimulus. Four encoding trials constitute a condition block in this fMRI design. On the top right, a section of an encoding trial is highlighted with indicated presentation durations. To the lower left, the used fixation screens are displayed with their respective frequencies of appearance. Each encoding trial contained one response slide (either a vertical or horizontal line segment). To the lower right, we display the three stimulus categories that belong to the three experimental encoding conditions (from left to right):   Face-Occupation Pairs   for associative encoding,   Faces Alone   for single item encoding (non-associative baseline) and   Contour   for a non-encoding baseline (not discussed in this paper). Portraits belong to the FERET database   [ ]  .   B:   Unconscious-conscious retrieval interaction with indicated presentation durations. A former subliminal face is briefly presented to cue the unconscious reactivation of previously formed face-occupation association. Next, a portrait of a celebrity comes up for the conscious retrieval of the celebrity\u2019s occupation (actor or politician) Participants were required to recognise the famous person and to indicate his occupation by button press. Each condition block contained four trials.   illustrates a trial of the associative retrieval condition   Incongruent   and a trial of the   Old Faces   baseline condition, where no unconscious-conscious interaction was possible. Celebrities\u2019 portraits were taken from Wikimedia Commons ( ). Berlusconi: public domain; DiCaprio: Siebbi ( ). \n  \nWe expected that the former subliminal face\u2019s occupation (actor or politician) would be reactivated unconsciously and would facilitate or inhibit the conscious retrieval of the celebrity\u2019s occupation (actor or politician) depending on whether the two faces share occupations or not. A facilitating interaction may render the conscious retrieval more efficient reducing neural activation and reaction times. Conversely, an inhibitory interaction may increase neural activation and reaction times. These two conditions were contrasted to a baseline condition that provided for unconscious face encoding and retrieval without relational demands and hence was neutral regarding occupational categorization. \n\nThe hypothesized neural basis of unconscious-conscious interactions comprises the neocortical storage sites of occupations, namely the lateral and polar temporal cortex [ , ], as well as the hippocampal-anterior thalamic axis. Evidence in favour of a common memory space for both unconscious and conscious relational memories would speak to a common memory system for conscious and unconscious relational (i.e., episodic) memories. Such evidence would challenge the traditional segmentation of memory systems according to consciousness [ \u2013 ] and would support the processing-based memory model [ ]. \n\n\n## Methods \n  \n### Participants \n  \nForty-two healthy male volunteers (age 19\u201332 years;   M   \u00b1   SD   = 23.86 \u00b1 3.02) participated in the experiment. They denied previous or current neurological or psychiatric disorders and drug abuse. Each participant fulfilled inclusion criteria and no exclusion criteria for MRI. All participants were right handed [ ] and had normal or corrected-to-normal vision. Participants gave semi-informed consent. They were not informed of subliminal presentations until debriefing following the fMRI experiment. This study was approved by the local ethics committee for human studies (Kantonale Ethikkommission Bern). \n\nTwo participants were excluded from data analysis due to their insufficient acquaintance with the famous faces used in the experiment. Seven further participants were excluded because of their above-chance performance on the awareness tests (cf. section 0). Accordingly, thirty-three participants entered data analyses. \n\n\n### Material \n  \n#### Stimuli \n  \nFor subliminal encoding, 216 frontal portraits of unknown male faces were retrieved from the internet using Google ( ) and the FERET database [ ]. The portraits were converted to grayscale, realigned and contrast-reduced. They were then validated concerning their prototypicality for the occupations \u201cactor\u201d and \u201cpolitician\u201d by 32 (separate) students, who agreed to evaluate the faces in an online experiment using a forced-choice task. The 148 least prototypical portraits were used as a stimulus pool for the experiment. Forty-eight portraits were used in the main experiment and the remaining 100 portraits were used in the awareness tests. The assignment of faces to these two lists was randomized for each participant. A contour of a human head was reduced in contrast and blurred to be used in a baseline condition in the subliminal encoding part of the fMRI experiment \n\nFor the test of an unconscious-conscious interaction during retrieval we collected frontal portraits of 32 famous male actors and 32 famous male politicians from the internet. These portraits were also grayscaled and realigned but not contrast-reduced because they were not used for subliminal presentation. \n\n\n#### Setup \n  \nStimuli were presented with a Benq\u00a9 WXGA SP830 DLP video projector using a resolution of 1024 \u00d7 768 pixels and a screen refresh rate of 60 Hz. Stimuli were projected onto a backlit screen with a viewing angle of 16\u00b0 width and 9\u00b0 height. Stimulus presentation was programmed with the software Presentation Version 11.3 (Neurobehavioral Systems,  ). Participants responded by key press on a Lumina Response Pad LU400-Pair by Cedrus ( ) while lying in the MR Scanner. \n\n\n\n### Experimental procedure \n  \nThe experiment was carried out in a dimmed MRI chamber. The study encompassed the following phases in this order: 1) a conscious memory task was given to establish a task-set that prepares participants for unconscious associative encoding, 2) the fMRI experiment encompassing subliminal encoding and a test of unconscious-conscious interaction during retrieval, 3) a test of stimulus awareness, and 4) the explicit identification of famous faces. Phases 1 through 3 were carried out while the participants where situated inside the MR scanner. \n\nThe experiment was designed to suit an fMRI block design with alternating condition blocks. There were two fMRI time-series, one for subliminal encoding and the other for the interaction test. All condition blocks took 24 seconds and contained four trials spanning 6 seconds each. The assignment of stimuli to conditions and of occupations to faces was pseudo-randomized. Condition blocks alternated regularly in a fixed order. The starter block varied between participants to distribute over experimental conditions certain psychological dispositions such as stress or fatigue and the pervasive scanner drift. \n\n#### Subliminal encoding \n  \nWe used our established presentation protocol with subliminal stimuli embedded in an attention task [ ] ( ). Initially, a fixation cross (F) was presented for 233 ms. Four noise masks (M) were then presented for 183 ms each. Between the noise masks, stimuli (S) were presented subliminally for 17 ms. Stimuli were either   Face-Occupation Pairs  ,   Faces Alone   (= non-associative baseline) or   Contour   (not discussed in this study). The noise masks served as forward- and backward masks [ , ]. One trial took six seconds, consisted of 6 sub-trials and ran down in the following order: 6 \u00d7 (F-M-S-M-M-S-M). This resulted in 12 consecutive subliminal presentations of a stimulus. In each trial, one of the six fixation crosses was replaced by either a horizontal or a vertical line segment. These replacements had to be acknowledged by participants with key press responses. This attention task ensured that participants\u2019 attention remained focused on the centre of the screen throughout the task. \n\nSubliminal encoding was implemented as a block design with three alternating conditions, namely   Face-Occupation Pairs  ,   Faces Alone   baseline and   Contour  . Each condition embraced four blocks with four trials each. Hence, we presented 16   Face-Occupation Pairs  , 16   Faces Alone   and 16 times the   Contour  . According to this scheme, 32 of the 48 experimental unfamiliar portraits were presented during the encoding task. The remaining 16 portraits were later used for the unconscious-conscious retrieval interaction test in the   Novel Faces   condition (see next section). \n\n\n#### Test of an unconscious-conscious interaction during retrieval \n  \nIn the test of interaction during retrieval, participants had to categorize celebrities with respect to their occupation\u2014actor or politician ( ). This test encompassed four conditions:   Congruent  ,   Incongruent  ,   Old Face   and   Novel Face  . Each condition embraced four blocks of four trials. Sixty-four portraits of famous actors and politicians were presented as targets. The presentation of a portrait was preceded by the brief but clearly visible presentation of one of 48 non-famous faces. Of the 48 non-famous faces, 32 had previously been shown in the subliminal encoding task. The previously presented 16   Face-Occupation Pairs   were assigned to both the   Congruent   and the   Incongruent   condition. The previously presented   Faces Alone   were assigned to the no-interaction baseline condition of   Old Faces  . The remaining 16 faces had not been presented for encoding; they were presented in the condition of   Novel Faces   (not discussed in this paper). The apparent discrepancy between the number of non-famous faces (48: 16 associative old, 16 single old, 16 not presented for encoding) and the number of famous faces (64) is explained by the fact that each of the 16 former subliminal   Face-Occupation Pairs   was used twice, namely once in the congruent condition and once in the incongruent condition. Accordingly, 16 famous faces were preceded by a congruent associative old face, 16 by an incongruent associative old face, 16 by a non-associative old face, and 16 by a new (not previously presented) face. A trial ( ) started with the presentation of a fixation cross for 1300 ms. This was followed by a 200 ms presentation of a non-famous face. Next, a fixation cross appeared again for 500 ms (= cue-target interval). Finally, a famous face was presented for 4000 ms. Participants were asked to indicate as quickly as possible whether the famous face was an actor or a politician. \n\n\n#### Test of stimulus awareness \n  \nFollowing the fMRI experiment, participants were asked whether they had noticed something during the attention task that they performed in the first part of the fMRI experiment. When they denied, they were further asked whether they might have perceived faces or words between or within the noise masks. A yes answer led to the exclusion of this participant\u2019s data set. Following this inquiry, all participants were informed of the subliminal presentation paradigm. Next, we administered two objective tests of stimulus awareness. In these tests, participants\u2019 potential awareness of subliminal stimuli was assessed based on their choice behaviour. We first applied a test of face awareness that tested for the awareness of subliminally presented individual faces. Next, we applied a test of occupation awareness that tested for the awareness of subliminally presented faces plus written occupations. Each awareness tests comprised 50 trials. A trial consisted of the 12-fold subliminal presentation of a stimulus (procedure adopted from subliminal encoding in the main experiment) followed by the forced-choice test concerning this stimulus. Hence, unlike the experiment, there was no encoding-test interval. The immediate succession of a subliminal stimulus and its test facilitates the behavioural expression of stimulus awareness. In the test of face awareness, we presented 50 subliminal unfamiliar faces, each followed by the supraliminal side-by-side presentation of the target face plus a distractor face (presentation duration: 5 s). Subjects were asked to indicate which of the two faces had just been presented subliminally. In the test of occupation awareness, half of 50 faces were presented subliminally with the written occupation \u201cactor\u201d and the other half with \u201cpolitician\u201d. Each subliminal face-occupation pair was followed by a forced-choice test that required participants to choose between the two occupations. Participants were given 5 s to indicate which of the two occupations was just presented subliminally. In both awareness tests, participants received direct test instructions: they were instructed to base their decisions between faces or occupations on their previous conscious perception of shapes or fragments of subliminal stimuli. Direct test instructions such as this are known to be more sensitive to conscious than unconscious perception and memory [ , ], which allows measuring stimulus awareness. On the other hand, indirect retrieval tests such as the one used in the main experiment (evaluating a famous faces), are more sensitive to unconscious processing. If subjects performed above chance (binomial test;   p   <. 2) in either of these two awareness tests, their experimental data were excluded from analysis. \n\n\n#### Test of knowledge of celebrities \n  \nBecause our participants were young and unexperienced, we needed to ensure that they knew the politicians and actors used in the second part of the fMRI experiment. An interaction between unconscious and conscious retrieval could only occur if participants were able to identify our portraits of celebrities. To this end, participants were instructed at the end of the session to classify the previously used portraits of celebrities according to \u201cpolitician\u201d and \u201cactor\u201d and to retrieve the celebrities\u2019 names. If participants claimed to know a celebrity but failed to retrieve his name, they described the celebrity and/or where they knew them from to prove identification. All participants but two were able to identify the celebrities. The experimental data of those two participants who failed were excluded from analysis. \n\n\n\n### MRI data acquisition \n  \nAnatomical and functional images were acquired with a 3T Siemens Magnetom Trio whole-body scanner. Anatomical T1-weighted image acquisition followed a 3D-gradient echo-sequence with a spatial resolution of 1 \u00d7 1 \u00d7 1 mm  (acquisition matrix = 256 \u00d7 256 voxels, 176 sagittal slices; time of repetition (TR) = 7.92 ms; echo time (TE) = 2.48 ms; flip angle (FA) = 16\u00b0; field of view (FOV) = 256 \u00d7 256 mm ). Structural image acquisition was carried out during the awareness tests. \n\nFunctional T2*-weighted images were acquired using a blood-oxygen-level-dependent (BOLD) sensitive, interleaved 2D-gradient echo planar single-shot pulse (EPI) sequence with a spatial resolution of 1.8 \u00d7 1.8 \u00d7 4 mm  (acquisition matrix = 128 \u00d7 128 voxels, 34 transversal slices; TR = 4000 ms; TE = 32 ms; FA = 90\u00b0; FOV = 230 \u00d7 230 mm ). \n\n\n### Behavioral data analysis \n  \nChoice reaction times (RT) acquired during the interaction task were analysed with IBM SPSS (version 20). Trials with RT deviating more than 2   SD   from the individual mean were excluded. Because RTs were not normally distributed (Kolmogorov-Smirnov tests, all   p   <. 001; skewness > 0), nonparametric statistics were computed (Wilcoxon signed rank exact test). However, parametric testing yielded comparable results. \n\n\n### fMRI data analysis \n  \nPreprocessing of volumes was carried out with the software SPM8 (Wellcome Department of Cognitive Neurology, London, UK). Volumes were slice-time corrected, realigned to the first volume, coregistered to the anatomical volume, normalized to the MNI T1 template and finally smoothed with an 8 mm (FWHM) isotropic Gaussian kernel. \n\nFirst, we computed independent component analyses (ICA) and correlated the extracted components of brain activity with the time-course of the alternations between condition blocks in each of the two fMRI time-series, i.e., the encoding time-series and the interaction time-series. This analysis yields a model-and hypothesis-free estimate of functionally coupled brain areas that were engaged during unconscious associative encoding and retrieval. We computed group-level ICAs using the GIFT toolbox ( ). The optimal number of independent components was estimated according to the minimum description length criteria [ ] in advance of the actual analysis, which was run with the Infomax algorithm [ ]. This procedure resulted in the extraction of 17 independent components for the encoding time-series and 19 independent components for the interaction time-series. We were interested in components reflecting unconscious relational memory processes that covary with the occurrence of associative condition blocks. Independent components were thus sorted with respect to their regression fit with the modelled time course of associative condition blocks. Associative condition blocks contained   Face-Occupation Pairs   at encoding and   Congruent   and   Incongruent Faces   at test. False discovery rate (FDR)-corrected [ ] one-sample t-tests were computed on the \u03b2-weights of sorted components to determine whether a component was significantly associated with a time-series. Significant components were subsequently checked for a-priori regions of interest, namely hippocampus and lateral- and polar temporal neocortices. Significant components containing a-priori regions of interest where then tested for a regression fit with their baseline condition (i.e.,   Faces Alone   at encoding;   Old Faces   at test) to ensure that functional coupling of these components was specific for unconscious associative memory processes. Hence, a non-significant regression fit with baseline conditions was expected. Cluster statistics were calculated in SPM8 with a height threshold of   p   = .05 (family-wise-error corrected). Component images were thresholded at   Z   > 2 for visualisation. Labelling and visual inspection of the activation patterns was carried out with xjView8 ( ). \n\nWhile ICA is able to uncover global-scale networks, it only allows to plot the strength of association of single voxels with these networks, but is limited in providing insight into how local neural groups relate to behaviour directly. Therefore, we regressed retrieval performance (reaction time differences) onto fMRI contrasts to reveal signal changes that relate linearly to the behavioural evidence of unconscious-conscious retrieval interactions. SPM8 was used for first and second level analyses of contrasts between conditions. In the first level analysis, the time-series of each participant were modelled with a box car function convolved with a canonical hemodynamic response function. In the second level analysis, group level statistics were computed on first level contrasts using within-subject one-way ANOVAs. We entered the RT-differences recorded at test as a covariate of interest into the second-level GLM. \n\nFor subliminal encoding, the contrast (  Face-Occupation Pairs   >   Faces Alone   baseline) was correlated with the difference in reaction times in the incongruent versus congruent condition. This RT difference was chosen as a regressor over the RT difference of   Old Faces   baseline\u2014  Congruent   because there is no difference between a prospectively congruent and incongruent face at the time of encoding, and because each   Face-Occupation Pair   was used in both the   Incongruent   and the   Congruent   condition. \n\nFor the interaction test, the contrast (  Congruent   >   Old Faces   baseline) was correlated with the difference in reaction times recorded in the   Congruent   versus the   Old Faces   condition. Both this RT measure and the fMRI contrast reflect facilitating interactions between unconscious and conscious associative retrieval. The fMRI data were not analysed regarding interfering interactions (  Incongruent   condition) because the behavioural data (see below) showed no evidence of interference between unconscious and conscious retrieval. No corrections for multiple comparisons were applied due to the small signals associated with unconscious processing [ , , ]. The height threshold was   p   = .001 for the whole brain and   p   = .005 for the hippocampus, which was the a priori key region of interest. The extent threshold was four voxels. Labelling and visual inspection of the activation patterns was carried out with xjView8. \n\n\n\n## Results \n  \n### Awareness tests \n  \nParticipants were oblivious of both the fact of subliminal stimulation and the subliminal stimuli. For the analysis of data obtained in the two objective awareness tests, we took a conservative approach analysing the data of each individual using binomial testing. Participants with a performance above the upper 20%- cut-off of the chance distribution of correct responses were considered potentially aware of subliminal stimuli. Their data acquired in the fMRI experiment were therefore excluded from analysis. The 20%-cut-off corresponded to a hit rate of 56% (50% = chance level). Seven participants performed better than expected by chance either on the face or on the occupation awareness test. The remaining participants performed at chance level as individuals and as a group on both the face awareness test (49 \u00b1 7.3% (  M   \u00b1   SD  ); one-sample   t  -test against 0.5:   t  (32) = -.583,   p   = .564) and the occupation awareness test (49 \u00b1 7.2%;   t  (32) = -.527,   p   = .603). Hence, these remaining participants were unable to consciously detect subliminal faces or words or fragments thereof. \n\n\n### Main Experiment: Behavioural performance \n  \n#### Subliminal processing and attention task \n  \nParticipants were simultaneously processing two different streams of information at the unconscious and the conscious level. At the conscious level, participants engaged in the attention task. At the unconscious level, they processed subliminal faces and written occupations. We collected behavioural data on the attention task and calculated accuracy scores. Participants performed the attention task with high accuracy (hit rate = 94 \u00b1 23.7%,   M   \u00b1   SD  ) indicating that they focused gaze at the middle of the screen and paid attention to the masked presentations during the whole stimulation sequence. \n\n\n#### Interaction of unconscious with conscious retrieval of occupations \n  \nIn the critical retrieval interaction test, participants responded to the presentation of portraits of famous actors and politicians by manually indicating their occupational category \u201cactor\u201d versus \u201cpolitician\u201d. Two participants performed poorly (46.9% and 65.6% correct) because they were not familiar with the celebrities; these two participants were excluded from data analysis. The remaining participants identified celebrities with 91 \u00b1 10% (  M \u00b1 SD)   (  Congruent  ), 93 \u00b1 9% (  Incongruent  ) and 92 \u00b1 8% (  Old Faces  ) correct responses. Because accuracy of choice did not differ between conditions (  F  (2,64) = 1.315,   p   = .276), reaction times were the dependent variable that could be modulated by the preceding unconscious retrieval processes. \n\nA Wilcoxon exact test revealed a significant difference in reaction times between the congruent and the incongruent condition (  Z   = -2.850,   p   = .002, one-tailed, effect size   r   = .50) with faster responses to congruent versus incongruent famous faces. We further investigated whether this effect was due to congruence gains or incongruence costs by comparing the two conditions to the non-associative baseline condition   Old Faces  . This analysis showed that response latencies were significantly shorter to   Congruent   than   Old Faces   (  Z   = -1.689,   p   = .047, one-tailed,   r   = .29). There was no statistical difference between   Incongruent   and   Old Faces   (  Z   = -.777,   p   = .437) ( ). Hence, the above behavioural effect was due to congruence gains rather than incongruence costs. The   M   \u00b1   SD  s of the RTs in the interaction task were: 1279 \u00b1 313 ms (  Congruent  ), 1351 \u00b1 352 ms (  Incongruent  ) and 1337 \u00b1 373 ms (  Old Faces   baseline). In conclusion, unconscious-conscious interactions were only apparent in the   Congruent   condition, where the unconsciously encoded and retrieved occupations were identical with the consciously retrieved occupations. \n   Reaction times at categorizing famous faces.  \nGroup means and SEM are displayed.   Old Face   trials (no association) are used as baseline. * Mean difference   (  \u0394  M  ) = 57 ms,   p   = .047, effect size   r   = .29; ** \u0394  M   = 71 ms,   p   = .002,   r   = .50; one-tailed Wilcoxon signed rank exact tests. \n  \nAs all former subliminal faces in the congruent condition were also used in the incongruent condition and vice versa, a bias could arise due to their repeated presentation. This was, however, not the case: Wilcoxon exact tests showed that RTs to famous faces did not differ between the first versus second presentation of face cues in the congruent condition (  Z   = -1.099,   p   = .280, two-tailed) nor the incongruent condition (  Z   = -0.116,   p   = .916, two-tailed). \n\n\n\n### Main Experiment: fMRI data \n  \n#### Independent component analyses \n  \nWe performed an independent component analysis (ICA) on the fMRI data acquired during the encoding fMRI time-series to explore the functional connectivity of brain regions during the subliminal processing of   Face-Occupation Pairs  . The subliminal presentation of   Face-Occupation Pairs   was associated with decreased activity in a number of functionally connected brain areas that constituted one of the obtained components (  r   = -.16,   t  (32) = -3.1,   p   = .004 < FDR critical   p   = .006) (  and  ). This component included bilateral areas in the superior temporal sulcus (extending into superior and middle temporal gyrus) and temporal pole, which harbour storage sites of lexical-semantic information such as occupations [ ]; bilateral hippocampus and ventromedial thalamus, required for encoding of new information [ ]; and bilateral amygdala, which is considered to play an important role in face perception and evaluation. As faces convey highly significant social and emotional information, the amygdala is automatically engaged when faces are perceived [ ]. Importantly, this component did not covary with the   Faces Alone   baseline (  r   = .13,   t  (32) = 0.4,   p   = .69), and the regression-fit of this component with   Face-Occupation Pairs   was significantly better than with   Faces Alone   (  t  (32) = -2.1,   p   = .044, effect size   r   = .35) ( ). In conclusion, we can assume that this component was specifically related to the semantic associative binding of subliminal faces with written occupations. \n   Independent component analysis (ICA) on encoding time-series.  \nThe depicted component is significantly associated with the occurrence of subliminal   Face-Occupation Pairs  .   A:   Clusters within the component encompassing bilateral hippocampus, amygdala, superior temporal sulcus, and temporal pole. These brain regions are important for episodic and semantic memory. Coordinates are according to MNI space; left is left on the coronal slice and upwards is left on the transversal slice.   B:   The temporal coupling of this network is specific for unconscious associative encoding. The component is significantly associated with the occurrence of   Faces-Occupation Pairs   (Pearson\u2019s   r   = -.16, **   p   = .004) but not with   Faces Alone   (Pearson\u2019s   r   = .13,   p   = .69). The regression fit of the component is significantly better with   Face-Occupation Pairs   than with   Faces Alone   (*   p   = .044, effect size   r   = .35). The bar plot shows \u03b2-weights of the time course modelled specifically to the associative and the baseline condition. Error bars indicate the SEM. \n     Idependent component analysis of subliminal encoding: Functional network coupled with presentation of subliminal   Face-Occupation Pairs   (  r   = -.16,   p   = .004).        \nThe negatively (rather than positively) deflected fMRI signal during subliminal relational versus single face encoding calls for an explanation. Such negative deflections are in fact a replicable phenomenon observed during subliminal associative encoding relative to a non-associative baseline [ , , ]. The hippocampus is active whenever an event is experienced [ ] and also during rest because it retrieves and stores memories in the stream of spontaneous conscious mentation [ ]. During subliminal encoding, the hippocampus may split its processing capacity between conscious spontaneous mentation and unconscious encoding of subliminal stimuli. Because backward masks interrupt the firing response of activated neurons [ , ], the processing of subliminal face-occupation pairs gets interrupted by backward masks. The more neurons are recruited to encode subliminal stimuli instead of spontaneous conscious thoughts, the more spiking activity is interrupted in the hippocampus, which reduces the fMRI signal. Relative to a relational condition, where many hippocampal neurons are recruited for unconscious encoding, a non-relational baseline condition frees hippocampal neurons from subliminal processing and makes them available for encoding the stream of spontaneous conscious thoughts. Hence, the firing of more hippocampal neurons is interrupted in the experimental than the baseline condition reducing the fMRI signal. \n\nWe also performed an ICA on the fMRI data acquired during the interaction time-series. This ICA yielded no significant component. Because all experimental conditions included the conscious inspection of famous faces and the conscious retrieval of their occupations\u2014i.e., tasks associated with strong signal changes in the brain\u2014, we suspect that the superimposed signal changes associated with unconscious processes were too weak and sparse for a clear modulation of the global signal. \n\n\n#### Correlation of fMRI data with behavioural performance \n  \nThe reaction time difference   Incongruent  \u2014  Congruent   was regressed onto the subliminal encoding contrast (  Face-Occupation Pairs   >   Faces Alone  ) to reveal brain activation underlying successful unconscious associative encoding ( ). Activity reductions during subliminal associative encoding were related to faster responses at test in the congruent versus incongruent condition. Significant correlations were located in a large area that included the left hippocampus and amygdala (  r   = -.564;  ) corroborating the results of the subliminal encoding ICA, and extending them by linking brain activity at encoding with behavioural facilitation at test. Further inverse correlations were located in the right frontal operculum/insula (BA 44/13) and bilateral lentiform nuclei, i.e., putamen and globus pallidus. Activity in or near these two regions has been shown to be associated with word reading [ ], more consistently within the left, rather than the right hemisphere [ ]. It should be noted that unconscious information processing is often strongly supported by the right hemisphere, especially if the encoded information is emotionally relevant [ ]. Hence, unconsciousness of processing might explain why we found a right hemisphere focus of activation in areas usually displaying left hemisphere dominance. \n   Hippocampal activity relates to retrieval performance.  \nLocations of significant correlations are displayed on the left side of the figure. The circled hippocampal clusters correspond to the respective scatterplots displayed on the right side of the figure. Pearson-correlation coefficients are included.   A:   Correlation of the encoding contrast (  Face-Occupation Pairs   >   Faces Alone  ) with the reaction time difference (\u0394RT) between the   Incongruent   and   Congruent   condition.   B:   Correlation of the interaction contrast (  Congruent   >   Old Faces  ) with the \u0394RT between the   Congruent   and the   Old Faces   condition. Coordinates are in MNI space; the left side of the image corresponds to the left side of the brain. Warm colours indicate positive correlations (none present), cold colours negative correlations. **   p   <. 01, ***   p   <. 001. \n     Subliminal encoding-related fMRI signal correlates with behavioural facilitation during the interaction test.        \nWe also regressed reaction time differences at test onto brain activity underlying the interaction of unconscious with conscious associative retrieval. Because the behavioural data indicated that the unconscious-conscious retrieval interaction yielded only congruence gains, and no incongruence costs, we focussed on congruence effects. The reduction in response time in the   Congruent   versus   Old Face   condition was regressed onto the fMRI contrast (  Congruent   >   Old Faces  ). Significant negative correlations ( ) were located in the right posterior hippocampus (  r   = -.475;  ), the left temporal pole (BA 38) (  r   = -.572), and within the posterior end of the right superior temporal sulcus extending into the angular region (BA 22 & 39) (  r   = -.556). The posterior superior temporal sulcus is a face-responsive region often associated with theory of mind [ , , ], and the temporal poles have been shown to specifically account for person-related semantics such as occupations [ ]. That activity in these areas predicts the magnitude of the congruence effect suggests that these areas supported the unconscious recognition of the former subliminal faces and the unconscious reactivation of associated knowledge (occupations), which could then facilitate the conscious retrieval of the famous individual\u2019s occupations. We will discuss below why this correlation was negative and what its theoretical implications are. \n   Retrieval-related fMRI signal correlates with behavioural facilitation during the interaction test.        \n\n\n\n## Discussion \n  \nBased on previous evidence that experienced episodes can be encoded with and without consciousness and recruit the hippocampal anterior-thalamic axis and related cortices in both cases [ \u2013 ], we hypothesized that consciously and unconsciously acquired relational memories are harboured within a single, cohesive hippocampal-neocortical memory space, where they interact with each other. The reactivation of an unconsciously acquired relational memory facilitated the subsequent conscious retrieval of a semantically congruent relational memory. This facilitation was reflected in shortened reaction times and simultaneously recorded reductions in neural activation within hippocampus and neocortical storage sites thought to harbour lexical-semantic and person identity information. In the following, we discuss potential mechanisms that may underlie this facilitative unconscious-conscious retrieval interaction. \n\nOur results point to facilitatory unconscious-conscious retrieval interactions in the congruent condition of our fMRI experiment. The supraliminal presentation of a non-famous person, who was previously presented subliminally with an occupation (e.g., politician), led to reduced response times to celebrities that share this occupation (e.g., also politician). The shortening of response times indicates that the celebrities\u2019 occupations were preactivated by the presentation of the former subliminal faces. Accordingly, subliminal face-occupation combinations must have been encoded and stored in the first place. This finding replicates previous demonstrations of the feasibility of subliminal semantic paired-associative encoding and long-term storage using face-occupation combinations [ , , , ] and word pairs [ , \u2013 ]. \n\nSavings in response times in the congruent condition went along with modulations of neural activation within hippocampus, temporal pole, superior temporal sulcus, angular gyrus, and precuneus. These neural effects were probably due to conscious rather than unconscious retrieval processes because signals associated with conscious versus unconscious mental processes are much stronger [ \u2013 ]. We suggest two possible mechanisms that may have caused response time and neural savings in the congruent condition ( ). \n   Network model of the assumed unconscious-conscious retrieval interaction.  \nWe suggest an intrahippocampal interaction mechanism as cause for the congruence effects: the supraliminal presentation of the former subliminal face elicits unconscious face recognition activating the fusiform gyrus. The fusiform signal triggers the hippocampal reactivation of the face-associated occupation (e.g., politician) (  1  ), which in turn activates occupational knowledge (politician) in the lateral temporal lobe (  2  ). The activated hippocampal relational engram coactivates other overlapping engrams; e.g., memories of other politicians. This intra-hippocampal preactivation facilitates the retrieval of a celebrity\u2019s occupation (  3  ). If a portrait of Obama were presented in the congruent condition, hippocampal and lateral temporal activity would be reduced compared to the baseline condition, where a hippocampal ab-initio activation would build up. Incongruence costs are not to be expected because the preceding hippocampal retrieval of a professional with another occupation (actor) would leave non-overlapping politician-related hippocampal memories unaffected. This scenario would support the view that consciously and unconsciously acquired memories are organized in a single, cohesive hippocampal-neocortical memory space with memories organized relative to their contents. Overlapping memories are linked, which supports pattern completion, abstraction and anticipation. \n  \n1) Facilitation in the congruent condition may have occurred through conceptual priming of occupational knowledge stored in the lateral temporal lobe. Following the presentation of the former subliminal face and identification through face recognition units in the fusiform face area, the face-associated occupation (e.g., politician) was retrieved through hippocampal processes ( .1.) that in turn activated occupation-relevant storage sites in the lateral temporal lobe ( .2.). This preactivation of occupational knowledge sites in the lateral temporal lobe may then have primed the conscious retrieval of the famous person\u2019s occupation (e.g., politician) reducing net activation in the lateral temporal lobe through repetition suppression due to neural sharpening or facilitation [ , ]. The reduced activation in hippocampus can be explained in terms of a sparse hippocampal recruitment for recovering the preactivated occupation of the famous face. The conceptual preactivation curtailed any unnecessary hippocampal search processes, which were necessary in the baseline condition increasing the hippocampal signal. Because the congruent condition was contrasted with the baseline condition, the activation level was relatively reduced. This mechanistic explanation of the unconscious-conscious interaction is, however, flawed by the absence of an inhibitory unconscious-conscious interaction in the incongruent condition. If conceptual priming was the crucial mechanism, we should have observed negative priming [ ] in the incongruent condition (i.e. slower reactions). Because no incongruence costs occurred in the incongruent condition, conceptual priming is probably not the only mechanism underlying the unconscious-conscious interaction. A further reason why conceptual priming is unlikely to be the only mechanism at work is evidence in amnesic patients that the hippocampus is necessary for the relational encoding and retrieval of subliminal item pairs [ ]. Accordingly, it can be assumed that both neocortex and hippocampus were involved in the unconscious and conscious retrieval of face-occupation associations. \n\n2) Another mechanism seems therefore more likely, which assumes an intrahippocampal interaction as an additional cause for the congruence effects. According to this scenario, the supraliminal presentation of the former subliminal face elicited unconscious face recognition activating the fusiform gyrus. The fusiform signal triggered the hippocampal reactivation of the face-associated occupation (e.g., politician) ( .1.), which in turn activated occupational knowledge (politician) in the lateral temporal lobe ( .2.). The activated hippocampal relational engram coactivated other overlapping engrams [ ], e.g., memories of other politicians. This intra-hippocampal preactivation facilitated the retrieval of the presented celebrity\u2019s occupation ( .3.). This second scenario is in line with known characteristics of the hippocampal memory system: the hippocampal memory system forms relational networks of memory traces that share aspects. This organizational structure permits an activated memory trace to trigger the activation of memory traces that share aspects and hence overlap [ ]. E.g., the presentation of Obama\u2019s portrait in the congruent condition would be accompanied by reduced activity in the hippocampus and lateral temporal lobe due to the semantic overlap of unconscious and conscious memory traces. The preactivation of the overlapping neural populations in hippocampus during unconscious retrieval allows for a more sparing activation during conscious retrieval. In the baseline condition, no unconscious relational memories are formed that could be reactivated at test. Thus, in the baseline condition the hippocampal search process builds up fully. Incongruence costs are not to be expected because the preceding hippocampal retrieval of, say, an actor would leave non-overlapping politician-related hippocampal memories unaffected. This scenario is analogous to retrieval-induced forgetting, where a partial retrieval of information can impair the subsequent retrieval of the remaining information, if the remembered and forgotten information comes from the same semantic category [ ]. This second scenario is also likely in view of earlier findings of a hippocampal role in unconscious relational encoding/retrieval [ ]. If this interpretation is correct, the finding suggests that consciously and unconsciously acquired memories are organized in a single, cohesive hippocampal-neocortical memory space. There is evidence that memories are organized topologically within the hippocampus relative to their contents, with more closely related engrams represented increasingly overlapping neural populations [ ]. Linked overlapping memories support pattern completion, abstraction and anticipation [ ] and newly encoded information is readily integrated into pre-existing relational networks [ ]. The degree of representation from consciously accessible to inaccessible memories is presumably orthogonal to the content-based organization of hippocampal memories [ ]. \n\nA synergistic unconscious-conscious interaction may be counterintuitive when considering previous reports of competing interactions between implicit and explicit memories [ , ]. In these earlier studies, however, declarative memory was compared to either procedural memory or priming, managed by hippocampus, basal ganglia and neocortex, respectively. Consequently, competing memory interactions may have occurred because unconscious and conscious learning mechanisms did not share the same memory system. Conversely, the interaction in the current study was harmonious because both unconscious and conscious relational memories were supported by the hippocampus. \n\nThe current study design has its limitations. It does not allow the isolation of neural activity underlying unconscious versus conscious retrieval because the rapid succession (500 ms) of the non-famous face cue for unconscious reactivation and the famous face cue for conscious retrieval results in a blurring of signals. Therefore, we can only speculate about the mechanisms underlying the facilitatory unconscious-conscious interactions. A further limitation is that our portraits of celebrities might tap semantic information [ ] besides episodic memories. Hence, the probed memory system cannot be determined beyond doubt. Yet, during the test of knowledge of celebrities it became clear that our participants were not overly familiar with many of the used famous faces and had to draw on their episodic memory. Furthermore, if semantic person knowledge was sufficient to recall occupations, unconscious-conscious interactions would likely not have modulated hippocampal signals but neocortical signals alone [ ]. \n\nThe classic view of the hippocampal memory system holds that consciousness is required for episodic memory formation [ \u2013 ]. However, the unconscious-conscious retrieval interaction reported here suggests that conceptually overlapping unconscious and conscious memories are stored in close association within hippocampus. An intertwined store of consciously accessible and consciously inaccessible relational hippocampal memories is compatible with the processing based memory model [ ]. Also, a single, cohesive hippocampal memory space for any level of representation\u2014unconscious to conscious\u2014is evolutionarily sensible. As pointed out earlier, episodic memories may shift from a conscious to an unconscious representation and vice versa over time [ \u2013 ]. In both these cases, a cohesive memory space provides for a stable organizational structure of hippocampal memories. Such representational shifts appear difficult if one assumes a strict division between memory systems based on conscious access. It is more economical to assume one hippocampal memory system that serves one computational goal, namely rapidly establishing new flexible associations, irrespective of conscious access [ ]. \n\n \n\n# Table(s)\n## ID: pone.0122459.t001\n### Label: Table 1\nRegion of activation\tL/R\tBrodmann area\tX\tY\tZ\tN of voxels\tT\nInsula, Superior temporal sulcus (extending into Superior and Middle temporal gyrus), Temporal pole\tL\t21, 22, 34, 35, 38, 47\t-40\t10\t-16\t4260.0\t15.98\nBrain Stem (multiple local maxima)\tbilat\t\t6\t-28\t-20\t\t15.79\nHippocampus, Amygdala\tL\t\t-20\t-12\t-16\t\t9.12\nHippocampus, Amygdala\tL\t\t-26\t-10\t-20\t\t8.58\nEntorhinal cortex\tL\t28\t-22\t-20\t-24\t\t8.54\nInsula\tL\t13\t-42\t-2\t-4\t\t7.17\nSuperior temporal sulcus (extending into superior temporal gyrus), Temporal pole\tR\t21, 22, 28, 34, 38, 47\t40\t8\t-14\t850.0\t12.45\nInsula\tR\t13\t42\t0\t-6\t\t8.73\nHippocampus, Amygdala\tR\t\t24\t-12\t-16\t\t8.01\nHippocampus, Amygdala\tR\t\t30\t-6\t-22\t\t7.4\nAmygdala\tR\t\t30\t-6\t-16\t\t7.35\nCerebellum, vermis\tL\t\t-4\t-68\t-18\t29.0\t8.8\nVentromedial thalamus\tbilat\t\t2\t-12\t-8\t31.0\t7.55\n### Caption\nIdependent component analysis of subliminal encoding: Functional network coupled with presentation of subliminal Face-Occupation Pairs (r = -.16, p = .004).\n### Footer\np <. 05 (FWE). L, left; R, right; bilat, bilateral.\n\n\n## ID: pone.0122459.t002\n### Label: Table 2\nRegion of activation\tL/R\tBrodmann area\tX\tY\tZ\tN of voxels\tT\trcluster\nNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\tNegative correlation: Faces Alone > Face-Occupation Pairs \u00d7 \u0394RT(Incongruent\u2014Congruent)\nLentiform nucleus\tL\t\t-22\t2\t2\t27\t4.14\t-.589\nHippocampus ???\tL\t\t-32\t-10\t-14\t147\t3.92\t-.564\nAmygdala\tL\t\t-26\t-2\t-20\t\t\t\nLentiform nucleus\tR\t\t24\t2\t-2\t20\t3.77\t-.582\nInsula, frontal operculum\tR\t13 / 44\t46\t-4\t12\t8\t3.60\t-.545\nPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\tPositive correlation: Face-Occupation Pairs > Faces Alone \u00d7 \u0394RT(Incongruent\u2014Congruent)\nNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\tNo Suprathreshold clusters\n### Caption\nSubliminal encoding-related fMRI signal correlates with behavioural facilitation during the interaction test.\n### Footer\np <. 001 (unc.);*p <. 005 (unc.).L, left; R, right; \u0394RT, reaction time difference\n\n\n## ID: pone.0122459.t003\n### Label: Table 3\nRegion of activation\tL/R\tBrodmann area\tX\tY\tZ\tN of voxels\tT\trcluster\nNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\tNegative correlation: Old Faces > Congruent \u00d7 \u0394RT(Old Faces\u2014Congruent)\nTemporal pole\tL\t38\t-42\t20\t-26\t4\t3.87\t-.572\nSuperior temporal s / angular g\tR\t39 / 22\t44\t-56\t14\t4\t3.76\t-.556\nPrecuneus / Calcarine sulcus\tR\t31 / 18\t2\t-72\t18\t22\t3.71\t-.583\nHippocampus ???\tR\t\t32\t-36\t0\t5\t2.87\t-.475\nPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\tPositive correlation: Congruent > Faces Alone \u00d7 \u0394RT(Old Faces\u2014Congruent)\nNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\tNo suprathreshold clusters\n### Caption\nRetrieval-related fMRI signal correlates with behavioural facilitation during the interaction test.\n### Footer\np <. 001 (unc.);*p <. 005 (unc.);L, left; R, right; \u0394RT, reaction time difference; s, sulcus; g, gyrus.\n", "metadata": {"pmcid": 4380440, "text_md5": "2c83c2efc6486a73151c5c09413c3a13", "field_positions": {"authors": [0, 142], "journal": [143, 151], "publication_year": [153, 157], "title": [168, 246], "keywords": [260, 260], "abstract": [273, 2441], "body": [2450, 53285], "tables": [53298, 58793]}, "batch": 2, "pmid": 25826338, "doi": "10.1371/journal.pone.0122459", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4380440", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4380440"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4380440\">4380440</a>", "list_title": "PMC4380440  Hippocampus Is Place of Interaction between Unconscious and Conscious Memories"}
{"text": "Zuo, Meimei and Xu, Yi and Zhang, Xiaomin and Li, Man and Jia, Xiuqin and Niu, Jinliang and Li, Dongfang and Han, Yanqing and Yang, Yanhui\nFront Neurol, 2018\n\n# Title\n\nAberrant Brain Regional Homogeneity and Functional Connectivity of Entorhinal Cortex in Vascular Mild Cognitive Impairment: A Resting-State Functional MRI Study\n\n# Keywords\n\nvascular mild cognitive impairment\nentorhinal cortex\nresting-state functional MRI\nregional homogeneity\nfunctional connectivity\n\n\n# Abstract\n \nThe aim of this study was to investigate changes in regional homogeneity (ReHo) and the functional connectivity of the entorhinal cortex (EC) in vascular mild cognitive impairment (VaMCI) and to evaluate the relationships between such changes and neuropsychological measures in VaMCI individuals. In all, 31 patients with VaMCI and 32 normal controls (NCs) underwent rs-fMRI. Differences in whole-brain ReHo and seed-based bilateral EC functional connectivity (EC-FC) were determined. Pearson's correlation was used to evaluate the relationships between regions with significant group differences and different neuropsychological measures. Vascular mild cognitive impairment (VaMCI) patients had lower scores in Mini-mental State Examination (MMSE) and Montreal Cognitive Assessment (MoCA) and higher ones in Activity of Daily Living (ADL) (  p   < 0.05). Vascular mild cognitive impairment (VaMCI) individuals had significantly lower ReHo in the left cerebellum and right lentiform nucleus than NCs (  P   < 0.05, TFCE FWE correction). Vascular mild cognitive impairment (VaMCI) subjects showed significant decreases in the FC of the right EC in the right inferior frontal gyrus, right middle frontal gyrus, bilateral pre-central gyrus, and right post-central/superior parietal lobules (  P   < 0.05, TFCE FWE correction). Significant positive correlations were found between ReHo and MoCA scores for the right lentiform nucleus (  r   = 0.37,   P   < 0.05). The right post-central/superior parietal lobules showed a significant positive correlation between right EC-FC and MoCA scores (  r   = 0.37,   P   < 0.05). Patterns in ReHo and EC-FC changes in VaMCI patients and their correlations with neuropsychological measures may be a pathophysiological foundation of cognitive impairment, which may aid the early diagnosis of VaMCI. \n \n\n# Body\n \n## Highlights \n    \nWe investigated spontaneous neural activity and the functional connectivity of the entorhinal cortex (EC) in VaMCI patients. \n  \nThe VaMCI individuals had significantly lower ReHo in the left cerebellum and right lentiform nucleus. \n  \nThe VaMCI subjects showed significant decreases in the FC of the right EC in the right inferior frontal gyrus, right middle frontal gyrus, bilateral pre-central gyrus and right post-central/superior parietal lobules. \n  \nReHo and EC-FC changes and their correlations with neuropsychological measures may aid the early diagnosis of VaMCI. \n  \n\n## Introduction \n  \nDementia is a public health issue ( ,  ). Vascular dementia is now recognized as the second most common form of dementia after Alzheimer's disease, and there is increasing awareness that early intervention may help prevent dementia, even of the Alzheimer type ( ,  ,  ). Therefore, the early identification of vascular cognitive impairment (VCI), particularly vascular mild cognitive impairment (VaMCI), is particularly important. \n\nResting state functional MRI (rs-fMRI), which has been established as a useful non-invasive technique for determining how structurally segregated and functionally specialized cerebral centers are interconnected, has been receiving increased attention in brain science research in recent years and is widely used in the study of diseases of cognitive impairment ( \u2013 ). A valuable method for analyzing the local features of rs-fMRI signals ( ), regional homogeneity (ReHo) measures the temporal synchronization of time series of nearest neighbors and can be used to map local spontaneous neural activity, making it a useful tool for identifying changes in cerebral activity ( \u2013 ). Functional connectivity (FC) can be used to map long-distance connectivity and to detect the undiscovered haemodynamic responses that ReHo cannot reveal ( ). \n\nReHo has also been used in several clinical studies, including attention deficit hyperactivity disorder (ADHD), AD, and MCI ( ,  ). Zhang et al. report that the patients with MCI exhibit altered ReHo in the medial prefrontal cortex, the bilateral posterior cingulate gyrus/precuneus and the left inferior parietal lobule (IPL), and higher of ReHo in the left IPL could indicate the presence of a compensatory mechanism in MCI ( ). For FC analysis, the choice of regions of interest (ROI) is not always the same previous studies mainly focus on the posterior cingulate cortex (PCC) connectivity and its crucial role in cognitive function and memory. Ding et al. report that patients with subcortical VCI (sVCI) exhibit decreases in FC of the left thalamus with the PCC ( ). In addition, Deng et al. found that the patients with VaMCI exhibited altered ReHo in ACC-FC in some regions, and decreases in the left pre-central gyrus ( ). Wang et al. and Li et al. selected the thalamus and Meynert basal nuclei (BNM), respectively, as the seed voxel and demonstrated a markedly abnormal FC mode in mild cognitive impairment (MCI) ( ,  ). Less attention has been devoted to the potential role of brain regions that are significantly related to cognitive function, such as the entorhinal cortex (EC). \n\nEC is the gate for multimodal information from many cortices, which converges onto the hippocampus. The EC\u2013hippocampal neural network is the key center for learning, episodic memory and performing spatial navigation ( ). Hafting et al. found grid cells with strong discharge on specific location of space in EC, and the specific anatomical basis determined the relative specificity of spatial memory ( ). Von Gunten et al. found that alteration starts from the EC and then gradually expanded to the hippocampus and surrounding structures from MCI to AD ( ,  ). According to previous studies, the EC, a vital region for widespread cognitive function, was defined as ROI in the current study. We hypothesized that the ReHo and EC functional connectivity (EC-FC) would be disrupted in VaMCI patients. \n\n\n## Materials and Methods \n  \n### Subjects and Assessments \n  \nAll participants were given a detailed explanation of the study and signed an informed consent form prior to its commencement. During the selection of subjects, all of the subjects were performed T1-weighted image (T1WI), T2-weighted image (T2WI), diffusion weighted imaging (DWI), fluid-attenuated inversion-recovery (FLAIR), and rs-fMRI scanning routinely. \n\nIn all, 31 right-handed VaMCI patients were recruited from among outpatients and inpatients of the neurology department of the Second Affiliated Hospital of Shanxi Medical University from January 2017 to December 2017. The inclusion criteria for the VaMCI group were based on the statement of the Society for Vascular Behavioral and Cognitive Disorders and the diagnostic guidelines for VaMCI in China, which include the following ( ,  ): there exist risk factors for cerebrovascular disease or cerebral vascular diseases such as hypertension, diabetes mellitus, hyperlipemia, or others; imaging examination revealed evidence of cerebrovascular lesions such as white matter lesions in key infarcts and multiple lacunar infarcts. In addition, we took a coronal scanning to exclude the patients with hippocampal atrophy; patients themselves or their families complain of a decline in cognition, with such symptoms of cognitive decline lasting for at least 6 months and having a fluctuating course; damage to cognitive function and risk factors of cerebrovascular disease are directly related to cerebrovascular disease; activity of daily living (ADL) is normal or near normal with a ADL score < 26; cognitive abilities is normal, with a Mini-mental State Examination (MMSE) score \u226524; Montreal Cognitive Assessment (MoCA) score < 26; Hachinski Ischemic Score (HIS) \u22657; Clinical Dementia Rating (CDR) = 0.5; and cognitive impairment has not yet reached the standard of a diagnosis of dementia in the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition (DSM-IV). \n\nFrom the community, 32 right-handed NCs were recruited for comparison. The inclusion criteria for the NCs were as follows: no current or previous diagnosis of any neurological or psychiatric disorders; no neurological deficiencies in physical examinations; absence of abnormal findings on brain MRI; no complaints of cognitive changes; and a CDR = 0. Additional exclusion criteria for both VaMCI and NCs participants included contraindications for MRI such as use of cardiac pacemakers and claustrophobia ( ). \n\nA medical history was taken on all participants, who also received physical examinations and neuropsychological tests. MMSE was used to assess patient status in cognitive abilities in five aspects, including orientation, memory, attention, computation power, and language competence. The level of education for all participants was required to be junior high school and above. MoCA was used to assess cognitive abilities in the following eight aspects: visual space, executive function, naming, attention, language, abstract, delayed recall, and directional force. An MoCA score < 26 points means that the patient's cognitive function is damaged. ADL was used to assess the patients' activities of daily living. CDR was used to assess the degree of cognitive impairment of patients. HIS was used to differentiate the nature of the cognitive impairment. An HIS score \u22657 points means that the patient's cognitive impairment is caused by vascular factors. The Hamilton Anxiety Rating scale (HAMA) and Hamilton Depression Rating scale (HAMD) were used to assess the patients' activity. \n\n\n### MRI Acquisition \n  \nMRI data were acquired with a 3-Tesla Trio scanner (General Electric Discovery silent, MR750W, America). All participants were asked to lie still, with their eyes closed. Foam padding was employed to limit head motion, and headphones were used to reduce scanner noise. Functional images were acquired using an echo-planar imaging (EPI) sequence with a repetition time (TR)/echo time (TE)/flip angle (FA) = 2,000 ms/30 ms/90, field of view (FOV) = 220 \u00d7 220 mm, slice thickness/gap = 3.6/0.4 mm and a data matrix = 64 \u00d7 64. \n\n\n### Image Data Pre-processing and Analysis \n  \nRs-fMRI data were pre-processed and analyzed using statistical parametric mapping software (SPM12,  ) and the data processing assistant for rs-fMRI (DPARSF V 4.3,  ), created using Matlab R2014a. The original data from the Digital Imaging and Communications in Medicine (DICOM) format were converted into a Neuroimaging Informatics Technology Initiative (NIFTI) format using SPM12 software ( ). The first 10 functional images were discarded to reduce the fluctuation of MRI signals during the initial stages of scanning. To correct all layers to the same point, different time points among layers in the course of scanning needed to be corrected. It took several minutes to scan the functional images, so the subjects would inevitably move their heads, caused by breathing, blood flow, or other physiological factors. The geometric displacement caused by the head motion was corrected: data from subjects whose head translation was more than 2 mm in any direction (x, y, or z) or whose angle of head rotation was >2\u00b0 were deleted in the process of scanning. To compare the images of different subjects using the same method, each participant's image was converted into a standard size and orientation. All subjects' functional images were registered onto an EPI cerebral template ( ). Then these image data were resampled based on a 3 \u00d7 3 \u00d7 3 mm  volume unit, and all functional data were standardized in Montreal Neurological Institute (MNI) space through parameter conversion. To reduce baseline drift caused by noise, the linear trend was removed after functional images were spatially normalized. To reduce physiological interference, all functional images were processed using low-frequency filtering, from 0.01 to 0.08 Hz. A linear regression model was used to further remove the interference of other possible influencing factors, such as head and white-matter cerebrospinal fluid. The ReHo calculation was performed using pre-processed images, and the resulting images were smoothed with an isotropic Gaussian kernel of 4 mm full-width half-maximum ( ). FC methods based on low-frequency (0.01\u20130.08 Hz) spontaneous blood oxygenation level-dependent (BOLD) fluctuations in rs-fMRI provide a powerful tool for characterizing intrinsically functional associations among brain regions. In this study, the bilateral EC ROI were generated using the free Anatomy Toolbox software V2.2b ( ). For each seed region, the BOLD time series of the voxels within the seed region was averaged to generate a reference time series. To further enhance the normality of the data analysis, the correlation r value was transformed into a   z  -value using the Fisher   r  -to-  z   transformation. \n\n\n\n## Statistical Analysis \n  \nThe statistical software package SPSS 19.0 was used to compare demographic and Neuropsychological measures. A two-sample   t  -test was adopted to compare the age, education and neuropsychological measures between the VaMCI and NC groups. The chi-square test was used to compare sex differences between groups. The difference was statistically significant when   P   < 0.05. \n\nA one-sample   t  -test was used to acquire the mode patterns of ReHo and EC-FC using the statistical analysis tool REST ( ,  ). A result was considered statistically significant at   P   < 0.05 (threshold free cluster enhancement family wise error, TFCE FWE corrected) and voxels >10. A two-sample   t  -test was used to compare differences in ReHo and EC-FC between VaMCI and NC. A   P   < 0.05 and cluster size threshold >10 voxels was considered statistically significant (FDR corrected). The XjView software package ( ) was used to confirm the specific anatomical positions corresponding to the MNI coordinates, which were statistically significant for the brain region. \n\nROI analysis was performed on the regions showing significant ReHo or EC-FC changes in patients with VaMCI compared to NCs. Partial correlations were conducted to evaluate the relationship between abnormal functional changes demonstrated by ReHo or EC-FC values in these ROIs and neuropsychological assessments in patients with VaMCI. Statistical significance was set at   p   < 0.05. \n\n\n## Results \n  \n### Demography and Neuropsychological Tests \n  \nDemographic characteristics and neuropsychological scores are shown in Table  . There were no significant differences between the two groups in sex, age, years of education, the degree of anxiety, or depression. Compared to the NC group, the VaMCI patients had lower scores in MMSE (  p   < 10 ) and MoCA (  p   < 10 ) and greater ADL (  P   = 0.001) scores. \n  \nClinical characteristics of VaMCI patients and NC groups. \n  \n MoCA, Montreal Cognitive Assessment; MMSE, Mini-Mental State Examination; ADL, Activity of Daily Living scale; HAMA, Hamilton Anxiety Rating scale; HAMD, Hamilton Depression scale; values are means \u00b1 SD  . \n  \n\n### ReHo Values Differ Between VaMCI Patients and NCs \n  \nThe differences in ReHo values between the NC and VaMCI group are shown in Figure   and Table  . Compared to the NCs, the VaMCI patients showed a significant ReHo decrease in the right lentiform nucleus, left cerebelum_crus2 (  P   < 0.05 TFCE FWE corrected). \n  \nBetween-group ReHo results were thresholded at a voxel-wise   P   < 0.05 (FWE corrected) and cluster size >10 voxels; color bar indicates t-score. \n    \nReHo results for the NC and VaMCI groups. \n    \n\n### EC-FC Changes Between VaMCI Patients and NCs \n  \nThe EC-FC changes between the NCs and VaMCI groups are shown in Figure   and Table  . The VaMCI patients showed a significantly lower FC relative to the right EC and the right inferior/middle frontal gyrus, bitemporal pre-central gyrus, and right post-central/superior parietal lobule than the NC group (  P   < 0.05, TFCE FWE corrected). \n  \nSignificant EC-FC for the NC and VaMCI groups.   P   < 0.05 (FWE corrected) and cluster size >10 voxels; color bar indicates   t  -score. \n    \nEC-FC changes for the NC and VaMCI groups. \n  \n Frontal_Inf_R, right inferior frontal gyrus; Frontal_Mid_R, right inferior/middle frontal gyrus; Pre-central_L, left pre-central gyrus; Pre-central_R, right pre-central gyrus; Postcentral/Parietal_Sup_R, right postcentral/superior parietal lobule  . \n  \n\n### Correlation Analysis \n  \nThe results of partial correlation analyses indicated that the ReHo of the right lentiform nucleus positively correlated with MoCA scores in VaMCI patients (  r   = 0.37,   P   < 0.05) (Figure  ). There was no significant correlation between ReHo values and MoCA scores in the right lentiform nucleus in NCs (  r   = \u22120.24,   P   = 0.193) (Figure  ). In addition, the FC of the right post-central/superior parietal lobules showed a significant positive correlation between right EC-FC and MoCA scores (  r   = 0.37,   P   < 0.05) (Figure  ). \n  \nThe linear correlation of ReHo values and MoCA scores in the right lentiform nucleus in VaMCI patients (  r   = 0.37,   P   < 0.05); red, VaMCI group; blue, NC group. \n    \nThe linear correlation of FC between ECR and Rt.Postcentral G/SPL in VaMCI patients (  r   = 0.37,   P   < 0.05); ECR, right EC; Rt.Postcentral G/SPL, right postcentral/superior parietal lobule. \n  \n\n\n## Discussion \n  \nPrevious studies have shown that normal brain development experiences local to holistic tissue patterns, which are important for revealing the neural mechanisms of cognition ( ). Moreover, certain diseases, such as schizophrenia, relapsing-remitting multiple sclerosis, and type 2 diabetes mellitus, exhibit synchronicity changes in local functions that can also spread to distant brain regions ( \u2013 ). Our study shows that compared to NCs, patients with VaMCI had significantly lower ReHo in the left cerebellum and right lentiform nucleus and significant decreases in the FC of the right EC in the right inferior frontal gyrus, right middle frontal gyrus, bilateral pre-central gyrus, and right post-central/superior parietal lobule. The right lentiform nucleus showed a significant positive correlation between ReHo and MoCA scores and a significant positive correlation between the FC of the right EC and MoCA scores. \n\nThe cerebellum plays an important role in maintaining the balance of the body and coordinating its movements. An increasing number of studies have shown that the cerebellum also functions in cognitive regulation ( ,  ). In their SPECT studies, Baillieux et al. found that the main cognitive function of the left cerebellum is attention and the function of visual space, confirming the cross-connection pattern of a loop passing from the cerebellum to the brain to the cerebellum again ( ). Zheng et al. using BOLD-fMRI, found that both the cerebellum and cerebral cortex participated in the cognitive process of spatial memory ( ). Similar to that study, we found that patients with VaMCI had significantly lower ReHo in the left cerebellum. Moreover, we also found that patients with VaMCI had significantly lower ReHo in the right lentiform nucleus. The lentiform nucleus which received the cholinergic projection of the Meynert basal forebrain and had extensive fibrous connections with the rest of the brain, playing a variety of functions such as motor coordination and cognitive activity. A wide range of diseases are related to the injury of the lenticular nucleus (bipolar disorder, schizophrenia, and so forth) ( ,  ). As part of the basal ganglia, the lentiform nucleus is not only the core structure of the related motor system but also plays an important role in cognitive activities, such as working memory, executive function, learning, emotive behaviors, and reward. Cao et al. found a significant reduction in rCBF in the lentiform nucleus ( ). In our study, the changes we observed in the ReHo of VaMCI patients imply that the left cerebellum and right lentiform nucleus were impaired; this is a pathophysiological foundation for the cognitive impairment evident in early stages of the disease. \n\nOur study adds new evidence to the disconnection hypothesis because we investigated EC connectivity with all other brain regions. We found that several regions such as the right post-central/superior parietal lobule have disrupted connectivity to the right EC. In addition, Colby et al. using EEG, proved that the parietal lobe plays an important role in spatial memory ( ). We found that VaMCI patients had significant decreases in the FC of the right EC in the right post-central/superior parietal lobule. This is related to the impairment of multiple cognitive domains such as orientation. In the frontal lobe region, we found that the lateral frontal regions (right inferior/middle frontal gyrus) showed disrupted connectivity to the right EC, which is related to attention processing ( ). In addition, we also noticed that the bilateral pre-central gyrus showed decreased connectivity to the right EC. This may imply that the change in connectivity extended into the primary motor cortex in VaMCI patients. The relationship between EC and the above regions in VaMCI patients must be further investigated. \n\nBased on correlation analyses, the decreased right lentiform nucleus showed a significant positive correlation between the ReHo and MoCA scores; there was a significant positive correlation between the decreased FC of the right EC connectivity with the right post-central/superior parietal lobule and MoCA scores. That is, the lower the FC, the lower the MoCA score. As noted above, the lenticular nucleus and the right post-central/superior parietal lobule play an important role in a variety of cognitive functions; these brain areas are also known to be the site of the pathophysiological foundations of cognitive impairment caused by the early stages of the disease. \n\nAs far as we know, our study is the first in which both ReHo and EC-FC analysis have been applied to rs-fMRI in VaMCI. We hypothesize that the ReHo and EC-FC would be disrupted in VaMCI patients. In theory, increased functional activity could provide a compensatory mechanism, through plasticity, helps limit the consequences of cognitive impairment. However, this putative compensatory function is at odds with what we have found in this study. These include the fact that no areas showed increased ReHo and EC-FC were detected in VaMCI patients than in the NCs. Hence, we consider that might be contribute to the light degree of cognitive impairment in the patients screened and the relatively small sample size, which requires more investigation ( ). \n\nThere were some limitations to the current study. First, our sample size was small. Second, we could not exclude the interference of potential confounding factors such as artifacts of the respiratory and cardiac cycles, and so on. Third, we did not add the MCI case groups which the early stage of AD for further analysis. Fourth, we used neuropsychological measures that reflected overall cognitive function in correlation analyses; more detailed measures, particularly for specific cognitive domains, must be further investigated. The last, we were unable to observe dynamic changes in ReHo and EC-FC following the onset of VaMCI. A longitudinal study is needed. \n\n\n## Conclusion \n  \nThe patterns of changes in ReHo and EC-FC in VaMCI patients and the correlation with neuropsychological measures may be a pathophysiological foundation of cognitive impairment, which will aid the early diagnosis of VaMCI. \n\n\n## Ethics Statement \n  \nThe study was conducted under a research protocol approved by the Ethics Committee of the Second Affiliated Hospital of Shanxi Medical University. A written informed consent was obtained from all participants prior to the study. \n\n\n## Author Contributions \n  \nMZ designed of the study and carried out data collection and wrote the manuscript. ML and DL screened the clinical data of the study. YX and JN completed the acquisition of functional imaging data. XZ sorted the data. XJ carried out data analysis. YH and YY contributed to conceptualization of the study and revision of the manuscript. \n\n### Conflict of Interest Statement \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nUnnamed: 0\tNC group (n = 32)\tVaMCI group (n = 31)\t\u03c72/t\tP-value\nSex (male/female)\t18/14\t18/13\t0.21\t1.000\nAge (years)\t62.72 \u00b1 8.22\t63.84 \u00b1 14.1\t\u22120.39\t0.701\nEducation (years)\t10.25 \u00b1 2.33\t9.32 \u00b1 2.12\t1.65\t0.104\nMoCA score\t27.75 \u00b1 1.72\t23.32 \u00b1 1.33\t11.40\t< 10\u22124\nMMSE score\t28.75 \u00b1 1.39\t26.32 \u00b1 2.06\t5.47\t< 10\u22124\nADL score\t20.00\t20.87 \u00b1 1.43\t\u22123.39\t0.001\nHAMA score\t1.69 \u00b1 3.08\t3.16 \u00b1 3.66\t\u22121.73\t0.089\nHAMD score\t1.37 \u00b1 3.18\t2.61 \u00b1 3.59\t\u22121.45\t0.152\n### Caption\nClinical characteristics of VaMCI patients and NC groups.\n### Footer\nMoCA, Montreal Cognitive Assessment; MMSE, Mini-Mental State Examination; ADL, Activity of Daily Living scale; HAMA, Hamilton Anxiety Rating scale; HAMD, Hamilton Depression scale; values are means \u00b1 SD.\n\n\n## ID: T2\n### Label: Table 2\nRegion\tCluster size\tMNI???\tMNI???\tMNI???\tT-score\nUnnamed: 0_level_1\t(voxels)\tx\ty\tz\tUnnamed: 5_level_1\n0.01\u20130.08\t\t\t\t\t\nCerebelum_Crus2_L\t201.0\t\u221221\t\u221278\t\u221233\t4.84\nLentiform_R\t73.0\t21\t3\t6\t4.99\n### Caption\nReHo results for the NC and VaMCI groups.\n### Footer\n*Numbers indicate the Z coordinate according to the Montreal Neurological Institute (MNI); between-group results were thresholded at a voxel-wise P < 0.05 (FWE corrected) and cluster size >10 voxels; L, Left; R, Right.\n\n\n## ID: T3\n### Label: Table 3\nRegion\tCluster size\tMNI\tMNI\tMNI\tT-score\nUnnamed: 0_level_1\t(voxels)\tx\ty\tz\tUnnamed: 5_level_1\nNC-VaMCI\t\t\t\t\t\nFrontal_Inf_R\t13.0\t42\t15\t30.0\t4.01\nFrontal_Mid_R\t32.0\t33\t39\t30.0\t4.04\nPrecentral_L\t10.0\t\u221233\t\u22126\t42.0\t4.08\nPre-central_R\t74.0\t48\t6\t48.0\t4.63\nPostcentral/Parietal_Sup_R\t136.0\t18\t48\t72.0\t3.93\n### Caption\nEC-FC changes for the NC and VaMCI groups.\n### Footer\nFrontal_Inf_R, right inferior frontal gyrus; Frontal_Mid_R, right inferior/middle frontal gyrus; Pre-central_L, left pre-central gyrus; Pre-central_R, right pre-central gyrus; Postcentral/Parietal_Sup_R, right postcentral/superior parietal lobule.\n", "metadata": {"pmcid": 6350268, "text_md5": "db11f088444edbe5be3072a0354ab088", "field_positions": {"authors": [0, 138], "journal": [139, 151], "publication_year": [153, 157], "title": [168, 328], "keywords": [342, 469], "abstract": [482, 2320], "body": [2329, 24734], "tables": [24747, 26644]}, "batch": 2, "pmid": 30723453, "doi": "10.3389/fneur.2018.01177", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6350268", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6350268"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6350268\">6350268</a>", "list_title": "PMC6350268  Aberrant Brain Regional Homogeneity and Functional Connectivity of Entorhinal Cortex in Vascular Mild Cognitive Impairment: A Resting-State Functional MRI Study"}
{"text": "Kjelvik, Grete and Evensmoen, Hallvard R. and Hummel, Thomas and Engedal, Knut and Selb\u00e6k, Geir and Saltvedt, Ingvild and H\u00e5berg, Asta K.\nFront Neurol, 2020\n\n# Title\n\nThe Human Brain Representation of Odor Identification in Amnestic Mild Cognitive Impairment and Alzheimer's Dementia of Mild Degree\n\n# Keywords\n\nsmell\nolfaction\nneurodegenaration\ncentral nervous system (CNS)\ncognition\n\n\n# Abstract\n \n Background:   Odor identification (OI) ability is a suggested early biomarker of Alzheimer's disease. In this study, we investigated brain activity within the brain's olfactory network associated with OI in patients with amnestic mild cognitive impairment (aMCI) and mild Alzheimer's dementia (mAD) to uncover the neuronal basis of this impairment. \n\n Materials and Methods:   Patients with aMCI (  n   = 11) or mAD (  n   = 6) and 28 healthy older adults underwent OI functional MRI (fMRI) at 3T, OI, odor discrimination, and cognitive tests and apolipoprotein-e4 (APOE4) genotyping. Eleven patients had cerebrospinal fluid (CSF) analyzed. Those with aMCI were followed for 2 years to examine conversion to dementia. \n\n Results:   The aMCI/mAD group performed significantly worse on all OI tests and the odor discrimination test compared to controls. The aMCI/mAD group had reduced activation in the right anterior piriform cortex compared to the controls during OI fMRI [Gaussian random field (GRF) corrected cluster threshold,   p   < 0.05]. This group difference remained after correcting for age, sex education, and brain parenchymal fraction. This difference in piriform activity was driven primarily by differences in odor discrimination ability and to a lesser extent by OI ability. There was no group by odor discrimination/identification score interaction on brain activity. Across both groups, only odor discrimination score was significantly associated with brain activity located to the right piriform cortex. Brain activity during OI was not associated with Mini Mental Status Examination scores. At the group level, the aMCI/mAD group activated only the anterior insula, while the control group had significant activation within all regions of the olfactory network during OI fMRI. There was no association between brain activity during OI fMRI and total beta-amyloid levels in the CSF in the aMCI/mAD group. \n\n Conclusion:   The OI impairment in aMCI/mAD patients is associated with significantly reduced activity in the piriform cortex compared to controls. Activation of downstream regions within the olfactory network is also significantly affected in the aMCI/mAD group, except the anterior insula, which is impinged late in the course of Alzheimer's disease. OI tests thus reflect Alzheimer's disease pathology in olfactory brain structures. \n \n\n# Body\n \n## Introduction \n  \nOdor identification (OI) is considered an early biomarker of Alzheimer's disease ( ). Patients with amnestic mild cognitive impartment (aMCI) who are at risk of developing AD and patients with Alzheimer's dementia (AD) have a specific impairment in OI but also display reduced odor detection and odor discrimination abilities ( \u2013 ). As healthy older adults also experience a decline in odor detection and discrimination, but not a similar reduction in OI, OI is considered to separate people with aMCI or AD from older people with intact cognition ( ,  ). Importantly, OI ability is shown to predict both a later diagnosis of MCI in healthy older adults and conversion from MCI to dementia ( ,  ). Hence, OI testing can be used as an inexpensive and non-invasive supplement in the clinical evaluation of suspected AD ( ,  ). OI's utility as a clinical tool and biomarker of dementia risk depends on a better understanding of the neuronal correlates underlying OI impairment in the early symptomatic phase of Alzheimer's disease. \n\nIn the brain, olfactory stimuli are processed in the olfactory network (ON), which includes the primary (piriform cortex, entorhinal cortex, amygdala) and secondary (hippocampus, thalamus, orbitofrontal cortex, and insula) olfactory regions ( ,  ). These regions are affected in a sequential manner by tau and beta-amyloid pathologies during the course of Alzheimer's disease. In the early symptomatic period of Alzheimer's disease when aMCI presents, tau pathology is found in the entorhinal and piriform cortices, the amygdala, and to a limited degree in the hippocampus, while \u03b2-amyloid is present in the orbitofrontal cortex. As the disease develops and dementia is diagnosed, tau pathology has spread to the anterior insula while \u03b2-amyloid plaques can be detected in the amygdala and allocortical structures (e.g., entorhinal and piriform cortex, hippocampus) ( \u2013 ). \n\nPrevious functional MRI (fMRI) studies of olfaction in patients with MCI and AD have focused on aspects of odor perception. They report greatly reduced whole-brain activity to smelling ( ,  ) as well as fewer activated voxels or lower fMRI signal in regions of interest in the piriform cortex/primary olfactory cortex and/or hippocampus during smelling, applying uncorrected statistical approaches ( ,  ). Moreover, impaired cross-adaptation ( ) and habituation ( ,  ) of the fMRI signal have been demonstrated in regions of interest in the piriform cortex using uncorrected statistics in patients with AD and MCI. Taken together, the knowledge is sparse with regard to the neural substrates of OI impairment in patients with aMCI and dementia due to Alzheimer's disease (AD). \n\nWe investigated OI using fMRI at 3T in patients with aMCI and Alzheimer's dementia of mild degree (mAD) compared to healthy older adults. To this end, we used an OI paradigm that provides robust activation within all regions of the ON ( ). We hypothesized reduced OI fMRI activity in patients with aMCI/mAD in the ON regions affected early in the course of Alzheimer's disease, i.e., the entorhinal and piriform cortices, and amygdala, while the insula would be less affected due to the later occurrence of Alzheimer's disease pathology in this region. \n\n\n## Materials and Methods \n  \n### Participants \n  \nNineteen patients (between 65 and 81 years) from the Memory Clinic, Geriatric Department, St. Olav's Hospital, Trondheim, Norway, agreed to participate and were MRI compatible. Inclusion criteria were a diagnosis of aMCI probably caused by Alzheimer's disease or mAD according to a comprehensive clinical assessment at the time of inclusion, age >55 years, and MRI compatibility. Patients were examined and diagnosed by an experienced geriatrician according to the research criteria of the International Classification of Diseases (ICD-10) and the National Institute of Neurological and Communicative Disorders and Stroke and the Alzheimer's Disease and Related Disorders Association (NINCDS-ADRDA) ( ,  ). Patients fulfilling the accepted US National Institute on Aging\u2013Alzheimer's Association (NIA-AA) diagnostic criteria for aMCI were also included ( ,  ). The examination encompassed a diagnostic workup with medical history obtained from both patient and their caregivers and clinical examination including neurological examination, cardiovascular status, and cerebral MRI. Cognitive function was assessed with the Mini Mental Status Examination (MMSE), Trail Making Tests A and B (TMT-A and TMT-B, respectively), and the Ten-Word Test (TWT) from the Consortium to Establish a Registry for Alzheimer's disease (CERAD) ( ). Handedness was determined with the Edinburgh Handedness Inventory ( ). Ethylenediaminetetraacetic acid (EDTA) blood samples were obtained to determine apolipoprotein-e4 (APOE4) allele status. In 11 patients, the cerebrospinal fluid (CSF) biomarker \u03b2-amyloid was analyzed. \n\nTwo patients were excluded; one because of an olfactory meningioma uncovered in this study, and the second patient developed late-onset bipolar depression, which was considered the cause of the initial aMCI diagnosis. Thus, 17 patients, 11 (four men and seven women) with aMCI and six (four men and two women) with mAD, were included. At 6 months' follow-up, 13 of the aMCI patients had progressed to dementia due to AD, while four were still diagnosed as aMCI. After 2 years, two of those with aMCI had converted to dementia, while two remained aMCI. These two participants with aMCI after 2 years of follow-up had typical symptoms of Alzheimer's disease. All included aMCI/mAD patients were right-handed as determined with the Edinburgh Handedness Inventory, with a mean score of 93.0 \u00b1 9.7. \n\nA control group of 35 healthy adults was recruited from senior citizen centers, advertisements, and personal networks. MRI compatibility was an inclusion criterion. In total, 28 controls (14 men and 14 women) between 55 and 81 years were included. The participants in the control group performed the same cognitive test battery (MMSE, TMT-A, TMT-B, and TWT) plus the Edinburgh Handedness Inventory, and blood was obtained for APOE4 allele testing. Seven controls were excluded due to technical problems during MRI scanning. Of the control participants included, 93% were right-handed and 7% were left-handed with a mean Edinburgh Handedness Inventory score of 82.4 \u00b1 29. \n\nThe sample size for this fMRI study was determined based on analyses of pilot data and data from previous fMRI studies we have conducted. In addition, we performed an   a priori   power analysis using G Power ( ). With an assumed medium effect size of 0.55, 80% power, and alpha = 0.05, the sample size of   n   = 21 per group was estimated. \n\nAt the time of the MRI, all participants completed a self-evaluation form of previous and present smoking habits. Anterior rhinoscopy was performed in all participants, and they were systematically checked for a history of olfactory, nasal, and/or respiratory problems (trauma, septum deviation, nasal/sinus surgery, hypertrophic rhinitis, drug-induced rhinitis, cold, upper respiratory tract infection, acute or chronic sinusitis, nasal tumors, Sj\u00f8gren's syndrome, or nasal polyposis). Five participants had seasonal pollen/grass allergy, but none had active allergy when the experiment was conducted. \n\nThe study was approved by the Regional Committee of Medical Research Ethics (REC-mid Norway) and the Norwegian data inspectorate. All participants had the capacity to consent to participation, and they gave written informed consent after the procedure had been carefully explained and after they had the opportunity to ask questions about the research. \n\n\n### MRI \n  \nMRI examinations were performed on one Siemens Trio 3T system (Siemens, Erlangen, Germany) equipped with a 12-channel head coil. Foam pads were used to minimize head motion. The scan protocol included a high-resolution T1-weighted three-dimensional (3D) MPRAGE sequence (196 slices; TE 30 ms; TR 2,300 ms; isotropic voxels of 1 mm ), followed by a T2-weighted image series of the sinuses and nasal cavity (40 slices; TE 77 ms; TR 4,290 ms; slice thickness 2 mm). The latter sequence was used to exclude individuals with pathology in the nasal cavity, sinuses, and/or olfactory bulbs and tract. If the participant did not have a structural pathology, the nasal mask (Respironics, ScanMed AS, Norway) was put on before fMRI. The subject was repositioned in the scanner, and a new scout image for positioning of the fMRI scans was obtained. \n\nTwo OI fMRI runs were performed using a T2 -weighted blood oxygen level-dependent (BOLD) sensitive, single echo-planar imaging (EPI) pulse sequence [47 slices; TE 30 ms; TR 2,600 ms; field of view (FoV) 230 mm, giving a resolution of 3 \u00d7 3 \u00d7 3 mm; acquisition matrix 80 \u00d7 80]. Each fMRI run consisted of 265 volumes plus three dummy scans for magnetization stabilization, giving a total acquisition time of 12 min for each run. The slices were angled as perpendicular to the long axis of the hippocampus as possible and the slice package anterior border was the frontal pole to optimize imaging of the ON, which is prone to susceptibility artifacts ( ). \n\n\n### The Olfactometer \n  \nOdor stimuli were presented with a custom-built MRI-compatible, automated olfactometer built by an engineer at the Norwegian University of Science and Technology (NTNU) based on modifications of earlier MRI-compatible olfactometers ( \u2013 ). The olfactometer has 14 glass chambers for deposition of liquid odors and allows the odor stimuli in the chambers to be delivered into the nasal mask in a preprogrammed and timed order, i.e., each odor is presented at a certain time for a certain duration ( ). The olfactometer was positioned 2.25 m from the magnet's isocenter during fMRI. Medical air flowing at a rate of 12 L/min went into the odor-filled chambers, allowing the odors to be released. From each chamber, the odor was conveyed   via   a separate tubing into the main Teflon tubing entering the nasal mask ( ). Since odors were released in the air into the mask and not delivered directly into the nostrils, body temperature heated the incoming scented air ( ). An additional hole at the superior end of the mask was connected to the hospital's gas evacuation system   via   tubings to ensure continuous airflow and removal of scented air. All tubings were made of very low adsorbent material (Teflon fluorinated ethylene propylene) to minimize absorption of odor molecules into the tubes ( ). The olfactometer was started by the experimenter using a remote control from the scanner operating room exactly at the time of initiation of fMRI scanning. \n  \nThe top row   (A)   displays photos of the automated olfactometer to the left, followed by a person wearing the olfactory mask in the middle, and the setup in the scanner room on the right.   (B)   The lower row shows the design of the fMRI experiment. The experiment consisted of two fMRI runs with odor identification (OI) followed by psychophysical olfactory tests completed after MRI scanning. The fMRI paradigm was a mixed block (OI state)\u2013event (successful OI) design (bottom row). Each run consisted of 11 olfactory blocks, and each olfactory block consisted of three odors in a random order, followed by a 7.8-s null event period (to ensure removal of scented air) and a non-odor baseline condition (water). The persons in the photos have provided consent for publication. \n  \n\n### Olfactory fMRI Paradigm \n  \nThe participants performed an OI task during fMRI based on Kjelvik et al. ( ). They were told not to sniff, just breath regularly throughout the experiment, and let the air with the odor pass over and into the nose. The participants were asked to identify the odors, and in case they were confident of correct OI, to press a response button (NordicNeuroLab AS, Bergen, Norway). This design was deemed feasible for older adults based on OI fMRI pilot studies that showed that collecting responses using, for instance, forced choice between odor names presented on a screen during fMRI was too complicated for this group. \n\nThe participants were familiarized with the odor task, breathing, the mask, and the response button before scanning. Scanning started when participants performed the task correctly. The participants were informed that they would be asked to identify the same odors after scanning. \n\nThe OI fMRI paradigm was a mixed block (OI state)\u2013event (self-reported successful OI) design. Ten odor chambers were filled with liquid odorants, and one chamber was filled with water. Two milliliters of odor-liquids were used for each of the 10 odors; lemon, chocolate toffee, musk, anise, banana, and rose (Stockholm's Essence Fabric, Wallinggatan 14, 111 24 Stockholm, Sweden;  ), vanillin and apple (Sigma Aldrich, Germany), and fresh coffee and cinnamon from local suppliers were in water solutions. Each odorant was presented for 10.4 s to ensure that at least one breathing cycle was completed within the stimulus' duration ( ) ( ). Each olfactory block consisted of three odors in a random order; e.g., lemon\u2013coffee\u2013cinnamon. The total duration of an odor block was 31.2 s. A total of 22 olfactory blocks (i.e., 66 odor exposures) were presented to each participant across two runs. Each of the 10 odors was presented between six and 10 times in a pseudo-random manner. Water was used as the baseline non-odor condition and presented in blocks of 26 s between the olfactory blocks. A 7.8-s period following each odor block was used as a null event to ensure removal of scented air ( ). The participants were asked to identify the odors during OI fMRI, and in case they were confident they were correct, to press the response button. \n\nBetween participants, the olfactometer was carefully cleaned, and the nasal mask was disinfected with PeraSafe (Puls AS, Oslo, Norway). The short tubings from each chamber were removed, and new tubings were added after each day of scanning, and new odor-liquids were used at the day of scanning. After each experiment, medical air from the hospital's gas provision system was used for 10 min to clean the long tubings and the olfactometer. \n\n\n### Post-scan Assessment \n  \nAfter fMRI acquisition, the participants were presented with an OI task with the same 10 odors as during fMRI. The odors were presented in a random order, each in 1-ml liquid solutions in glass bottles. Participants were asked to identify the odors first spontaneously, and then with forced multiple choice with four alternatives. Subsequently, two standard clinical OI tests were used to evaluate the participants' OI abilities: the Brief Smell Identification Test (B-SIT; Sensonics Inc., Haddon Heights, NJ, USA) and the Sniffin' Sticks Identification Test (SSIT, Burghart Messtechnik, Wedel, Germany). B-SIT is a scratch and sniff test with 12 microcapsulated odorants and a forced multiple choice between four items per odorant. The SSIT consists of 16 penlike odor-dispensing devices, with common odors, and uses forced multiple choice between four items per test odorant. The participants were allowed to sniff at the Sniffin' Sticks pens once or twice for 3\u20134 s. In both tests, the alternatives were given orally twice from the experimenter; in addition, the participants read the alternatives themselves on a card presented with the odor. The participants were told to give an answer for all odors, even if they did not smell anything, to make the tests valid. No feedback was given during the administration of the tests. The Sniffin' Sticks Discrimination Test (SSDT, Burghart Messtechnik, Wedel, Germany) was performed to evaluate odor discrimination abilities. The SSDT was completed in 13 of the patients (nine aMCI and four mAD) due to fatigue in the others. The SSDT consists of 16 triplets, where two pens have the same smell, while one of the three pens contains a different odor. Participants were asked to identify the pen that had the different odor and were blindfolded because the pens were color-coded. Participants were asked to choose one of the three pens of the triplet even if they did not perceive or recognize a difference between the odors. In each olfactory test, correctly identified odors received one point, giving a possible score range of 0\u201312 points for B-SIT, 0\u201316 for SSIT, and 0\u201316 for SSDT. \n\n\n### Statistical Analysis of Demographic and Behavioral Data \n  \nStatistics were performed using SPSS version 26 (SPSS, IBM). Characteristics of the control group and the aMCI/mAD group, as well as performance on cognitive tests, were compared using Student's   t  -tests. Differences with regard to cognitive test scores between the aMCI and mAD groups were also assessed with Student's   t  -tests. Group differences on psychophysical tests (free recall, multiple choice test, B-SIT, SSIT, and SSDT) were analyzed with Student's   t  -tests and Cohen's d and handedness with the chi-square test. The Pearson correlation-test was used to assess correlations between SSIT and SSDT and age and smoking in each group. Results are presented as a percentage or mean \u00b1 SD. Statistical significance threshold was set at   p   < 0.05. \n\n\n### Analysis of fMRI Data \n  \n#### Olfactory Network Region of Interest Analysis \n  \nAn ON region of interest mask was used in the fMRI analyses. The ON mask consisted of the piriform cortex, entorhinal cortex, anterior parahippocampal gyrus, hippocampus, amygdala, orbitofrontal cortex, insula, and thalamus and was created by combining the probabilistic maps of the Harvard\u2013Oxford Structural Atlases and the Juelich Histological Atlas (part of FSL;  ) as well as anatomical landmarks for the piriform cortex ( ). \n\n\n#### fMRI Analysis \n  \nImaging data were analyzed using FSL 6.0.3 (Analysis Group, FMRIB, Oxford, UK). First, non-brain tissue was removed from the T1-weighted 3D images using BET 2 with robust center estimation (Brain Extraction Tool, FMRIB, Oxford, UK). The resulting images were transformed to the Montreal Neurological Institute (MNI) 1 \u00d7 1 \u00d7 1 mm  template (Montreal Neurological Institute, Montreal, QC, Canada) non-linearly with FNIRT (FMRIB, Oxford, UK). The fMRI data were motion corrected using MCFLIRT with the median volume of each run as reference. Importantly, none of the subjects showed a mean relative root mean square displacement above 0.5 mm, the threshold in FSL for movement considered too severe to be corrected by MCFLIRT. Subsequently, each functional run was co-registered to the anatomical T1-weighted image before it was transformed into MNI space by using the transformation matrix obtained with the T1-weighted image. The functional data were smoothed with a 9-mm full-width at half-maximum Gaussian filter and temporally high-pass filtered with a cutoff time of 130 s. \n\nWithin the ON mask, voxelwise statistical analysis was performed using FEAT (FMRIB, Oxford, UK). For each subject, the two runs were analyzed separately (first level) and then combined within individuals using a fixed-effects GLM analysis (second level). Finally, effects across individuals were estimated by using separate GLM models and FLAME 1 (FMRIB's Local Analysis of Mixed Effects) (third level). At the first level, the explanatory variables were odor presentation (OI state blocks), scent removal (a 7.8 s period following odor presentation to ensure removal of scented air), and water baseline. At the third level, five GLM models investigated differences in activation within the ON using the contrast OI state > water baseline between the patients with aMCI/mAD and the control groups. The first model included one categorical variable for the aMCI/mAD and one categorical variable for the control group to evaluate group differences during the OI state. In the second model, age, sex, education, and brain parenchymal fraction ( ,  ) were added as separate regressors. The parenchyma brain fraction was obtained from the T1weighted MPRAGE volume and estimated using FreeSurfer 6.0.0 ( ). One patient and one control were excluded from this analysis because their education level was missing, and two more patients were excluded because they did not pass the FreeSurfer quality assessment ( ). In the third model, the average SSIT score was added as a separate regressor to the first model to investigate the effect of odor identification ability on activity within the ON. In the fourth model, the average SSDT score was added as a separate regressor to the first model to assess the impact of SSDT ability on activational differences between the aMCI/mAD and control group. The fifth model included the average MMSE score as a separate regressor to the first model to evaluate any association between MMSE score and brain activity during the OI state. Presence of an interaction between group and SSDT, SSIT, or MMSE performance on brain activity was investigated by splitting the score regressor into one regressor for aMCI/mAD and one for the control group. If no significant interaction was observed, the model without the interaction term was used. We choose to use the SSIT scores as covariate because of the larger score span for that test (16 possible correct points) compared to B-SIT and because it is the counterpart to the odor discrimination test (SSDT). An earlier study has shown a positive correlation between SSIT and B-SIT scores among aMCI/mAD patients ( ). Unexpectedly, the planned event analysis (self-reported successful odor identification during fMRI) could not be performed due to too few events in both the patient and control groups. For model one, contrast OI state > water baseline was also investigated for each group separately. An independent two-sample   t  -test was used to investigate differences between the aMCI/mAD and control group, while one-sample   t  -tests were used to investigate the average effect for the patient or control group separately. Each voxel was thresholded using   Z   = 3.5 (  p   = 0.0005) to define contiguous clusters. The significance level of each cluster was then estimated from GRF theory using a corrected cluster threshold of   p   = 0.05. \n\n\n\n\n## Results \n  \n### Demographics and Clinical Variables \n  \nAll included participants had normal anterior rhinoscopy and normal sinuses and posterior nasal structures on MRI. The aMCI/mAD group was slightly older than the control group, but no significant differences were found in education level or smoking habits between the groups ( ). Sniffin' Sticks Test scores were significantly correlated with age (  r   = 0.436,   p   = 0.003) and smoking (  r   = 0.510,   p   < 0.0001) in both the aMCI/mAD group and control group. \n  \nCharacteristics of the control group and the aMCI/mAD group. \n  \n Significant differences using Student's t-test for control group compared to aMCI/mAD group  , \n\n aMCI, amnestic mild cognitive impairment; APOE4, apolipoprotein E4; CSF, cerebrospinal fluid; mAD, Alzheimer's dementia of mild degree  . \n  \nSignificantly more patients than controls were APOE4 carriers ( ). The CSF total amyloid beta from the 11 patients (seven aMCI and four mAD) undergoing lumbar puncture were in the range considered as indicating Alzheimer's disease ( ) ( ). \n\nMini Mental Status Examination scores and performance of the cognitive tests were significantly lower in the aMCI/mAD group compared to those in the control group ( ). The aMCI group performed significantly slower on both TMT-A and TMT-B tests than the mAD group ( ). \n  \nPerformance of cognitive tests (mean \u00b1 SD) for the control group, combined aMCI/mAD group, and the aMCI and mAD groups separately. \n  \n Significant differences using Student's t-test  , \n\n aMCI, amnestic mild cognitive impairment; mAD, Alzheimer's dementia of mild degree; MMSE, Mini Mental Status Examination; s, seconds  . \n  \nThere was no significant difference in handedness between the patient and control groups (Pearson chi square   p   = 0.55, df 13) ( ). \n\n\n### Post-scan Assessment of Olfaction Abilities \n  \nCompared to the control group, the aMCI/mAD group had significantly lower OI ability as determined with post-scan uncued OI and multiple-choice OI tests using the odors presented during scanning, B-SIT, and SSIT, as well as lower odor discrimination ability, as determined with SSDT ( ). \n  \nOlfactory tests scores (mean \u00b1 SD) for the control group compared to aMCI/mAD group. \n  \n Significant differences using Student's t-test and Cohen's d for control group compared to aMCI/mild AD group. The number of patients and controls for each test is presented as n = patients/controls in the table  . \n\n aMCI, amnestic mild cognitive impairment; B-SIT, Brief Smell Identification Test; mAD, Alzheimer's dementia of mild degree; OI, odor identification; SSIT, Sniffin' Sticks Identification Test; SSDT, Sniffin' Sticks Discrimination Test. Bold font indicates statistically significant group differences  . \n  \n\n### Olfactory fMRI \n  \nDuring OI fMRI, the aMCI/mAD group had reduced activation of the right piriform cortex with the peak located to the anterior subdivision compared to the control group (  and  ) (Z-max = 4.1, cluster size = 297). Importantly, the reduced activation in the right piriform cortex for the aMCI/mAD group persisted after controlling for age, sex, education, and brain parenchymal fraction. Two smaller clusters of increased activation in orbitofrontal cortex also appeared after correction. The difference in activation in the piriform cortex between the aMCI/mAD and the control group was reduced when controlling for SSIT performance (Piriform: Z-max = 3.8, cluster size = 57) and disappeared when controlling for SSDT score. Controlling for MMSE score affected the group difference in piriform cortex activity only to a minor extent (Piriform: Z-max = 3.9, cluster size = 169). There was no interaction effect between group and SSIT, SSDT, or MMSE score on brain activity. In the combined group, only SSDT score was associated with fMRI activity located in the right piriform cortex, while no associations were present between SSIT or MMSE scores and fMRI activity ( ). \n  \nBrain activation during odor identification for amnestic mild cognitive impairment (aMCI)/Alzheimer's dementia of mild degree (mAD) patients and controls. Voxels in the olfactory cortices that showed increased activation during passive smelling for   (A)   aMCI/mAD patients > Controls,   (B)   Controls > aMCI/mAD patients, aMCI/mAD patients in upper row and with the nuisance variables age, sex, education, and brain parenchymal fraction in the lower row.   (C)   aMCI/mAD group and   (D)   Control group. The analysis was carried out using an olfactory network region of interest mask and a corrected cluster threshold of p = 0.05 (see section Materials and Methods). The \u201cx=\u201d in the lower left corner of each brain image indicates the position in the Montreal Neurological Institute (MNI) space. For more details on activation locations, see  ; for associations with olfactory test scores and cognition, see  . \n    \nLocation of peak brain activations in MNI space during odor identification in the control group and aMCI/mAD groups. \n  \n The analysis was carried out using an olfactory network mask (see section Materials and Methods for structures included) and a corrected cluster threshold of p = 0.05. X, Y, and Z are coordinates of peak activation in MNI coordinates using the 1-mm template. Only clusters that were larger than or equal to one functional voxel were reported, and up to five local maxima were reported for each cluster. The nuisance variables included age, sex, education, and brain parenchymal fraction. R, right; L, left. See   for brain maps  . \n\n aMCI, amnestic mild cognitive impairment; mAD, Alzheimer's dementia of mild degree; MNI, Montreal Neurological Institute  . \n    \nLocation of brain activations during OI fMRI associated with olfactory test scores and Mini Mental Status Examination score. \n  \n The GLM analyses were carried out within the olfactory network mask (see section Materials and Methods for structures included) and a corrected cluster threshold of p = 0.05. X, Y, and Z are coordinates of peak activation in MNI coordinates using the 1-mm template. Since there were no group *test performance interactions, the associations are assessed across both groups. Only clusters that were larger than or equal to one functional voxel were reported, and up to five local maxima were reported for each cluster. R, right; L, left; MMSE, Mini Mental Status Examination; MNI, Montreal Neurological Institute; OI, odor identification; SSDT, Sniffin' Sticks Discrimination Test; SSIT, Sniffin' Sticks identification test  . \n  \nIn the separate group analysis, the aMCI/mAD group displayed activation above the statistical threshold only in the bilateral anterior insula ( ). No activity within the ON correlated with CSF total-amyloid beta in the aMCI/mAD group. In the control group, increased activation was present within all ON regions during OI fMRI (  and  ). \n\n\n\n## Discussion \n  \nIn this OI fMRI study combined with psychophysical tests of olfactory functions, the aMCI/mAD group recruited neuronal resources in the piriform cortex significantly less and performed markedly poorer on all OI tests and the odor discrimination test than the control group. However, we did not find the expected lower brain activity in the entorhinal cortex or amygdala in the aMCI/mAD compared to the control group. Within the aMCI/mAD group, only insula activity was detected within the ON, in line with this region being affected later in the course of AD than the temporal and frontal brain regions. In the control group, on the other hand, all regions of the ON were strongly activated by the OI fMRI task, verifying the validity of the paradigm in activating the ON. \n\nThe piriform cortex activity was associated with OI impairment, as the difference between the aMCI/mAD and control groups became more restricted when controlling for SSIT. Nevertheless, the piriform cortex activity was mainly driven by odor discrimination ability, since the group difference disappeared completely when controlling for SSDT. The peak of the activation difference was located in the anterior piriform cortex, which is the main recipient of afferents from the olfactory bulb. The anterior piriform cortex also has extensive internal as well as external (e.g., with the orbitofrontal cortex) reciprocal connections ( ,  ). The primary role of the anterior piriform cortex is odor discrimination and identification ( \u2013 ) as clearly reflected by the current results. Reduced piriform cortex activity has been reported in previous neuroimaging studies in patients with MCI and AD using different olfactory perception tasks ( ,  ,  ,  ). These studies focused on metrics extracted from regions of interest analyses in the piriform or primary olfactory cortex, making direct comparison with these studies difficult. The present study extends these findings by performing OI fMRI in carefully selected patients using a variety of odors, which were dispensed with an automated olfactometer, combined with preprocessing and statistical analysis of the fMRI activity using a strict cluster-defining threshold as recommended. Taken together, the previous studies together with the current results demonstrate lower activity in the piriform cortex to olfactory stimuli from the first symptomatic stage of AD to late AD dementia. This is consistent with tau pathology being present in the piriform cortex from the very early symptomatic stage of AD ( ,  ). \n\nThe reduced piriform activity in the aMCI/mAD group compared to the control group could originate from altered input to the piriform cortex as well as from local pathology. AD-related tau pathology is present in the olfactory bulb before it is found in the piriform cortex and could impair upstream activation of the piriform cortex ( ,  ). Still, it appears unlikely that the lower activity in the piriform cortex in the aMCI/mAD group was caused mainly by reduced input from the olfactory bulb, as the activity difference was associated with odor identification (SSIT) and odor discrimination (SSDT) abilities, functions localized to the piriform cortex and not the olfactory bulb. Furthermore, \u03b2-amyloid plaques in the orbitofrontal cortex at the time of the first AD-related symptoms/MCI ( ,  ) could also influence activity in the piriform cortex. The reciprocal piriform\u2013orbitofrontal network is involved in both odor discrimination and identification ( ) and might be disrupted both by local AD pathology in piriform and orbitofrontal cortices and/or through impaired downstream activation of the orbitofrontal cortex due to, for instance, a primary deficit in processing of olfactory stimuli in the piriform cortex in the aMCI/mAD group. The presence of significantly higher activity in the control group in two small clusters in the orbitofrontal cortex after correction for age, sex, education, and brain parenchymal fraction provides additional evidence for aberrant reciprocal piriform\u2013orbitofrontal activity in the aMCI/mAD group. Taken together, the OI impairment in patients with MCI and AD likely arises from local pathology that affects stimulus processing, amplified by the disruption of network activity. Both aberrant downstream signaling from the piriform cortex and altered downstream processing of olfactory information could explain the lack of the expected differences in fMRI activity in the entorhinal cortex and amygdala. These regions are affected by tau pathology even earlier than the piriform cortex and before onset of aMCI/mAD symptoms. \n\nIndeed, the lack of other group differences in activity during OI fMRI suggested highly variable brain activity in these regions in the aMCI/mAD group. A network affected by regional pathology within a network of regions would give rise to such variability. The presence of such variability could explain the need for uncorrected statistical thresholding in previous fMRI studies on olfaction in MCI/AD. The two previous olfactory fMRI studies in participants with MCI/AD reporting uncorrected voxel-based whole-brain activation show low overall brain activity and fewer and varying brain regions activated in MCI/AD ( ). \n\nThe lack of an interaction between group and SSIT, SSDT, and MMSE scores on piriform activity demonstrated similar functional roles of the piriform cortex in the aMCI/mAD and control groups. Within the aMCI/mAD group, the only consistent activity during OI fMRI was located in the anterior insula, which is known to be affected later by AD-related pathology, at a time when dementia is well-established, compared to the other areas within the ON ( ,  ,  ). CSF total \u03b2-amyloid levels were not associated with the anterior insula activity in the aMC/mAD group, neither were SSIT, SSDT, or MMSE scores. The lack of a group difference in insula activity and the similar location of the peak activation suggest that the anterior insula is involved in a similar manner during OI fMRI in the aMCI/AD and control groups. The insula activity in the aMCI/mAD and control groups was located in the same coordinates as in healthy young adults during OI fMRI ( ). Extensive functional connections have been reported between piriform cortex and anterior insula in healthy adults, supporting the importance of insula in olfaction ( ). Given the aberrant activity in the piriform cortex, it is possible that the activity observed in anterior insula is not related to olfaction   per se  . The lack of associations between insula activity and SSIT and SSDT scores supports this interpretation. Insula has important functions in cognitive effort, and the same insula region activated in the MCI/mAD and control groups during OI fMRI has previously been shown to have a higher fMRI signal during high compared to low cognitive effort conditions ( \u2013 ). Spontaneous OI is cognitively challenging, and the anterior insula activity may represent cognitive control efforts. Mini Mental Status Examination scores were not associated with the insula activity, but since these scores do not reflect effort, this observation does not rule out the possibility of insula activity representing cognitive effort during OI fMRI. The anterior insula is highly connected to several brain regions including all other ON regions ( ), has no or limited AD pathology in the MCI and early AD phases ( ,  ), and as such may receive sufficient input from various sources within the ON and other brain regions connected to, for instance, cognitive control to generate a consistent fMRI signal similar to that in the control group. \n\nThe aMCI/mAD group in this study had a higher mean MMSE score than in a previous fMRI study on olfaction in MC/AD ( ). They still scored significantly lower than the control group on all psychophysical tests, with the largest effect sizes found for the OI tests, in agreement with the literature ( ,  ). On average, the aMCI/mAD group scored about 30% lower on the OI tests while about 20% lower on the odor discrimination test, reflecting OI tests' superior ability to differentiate between aMCI/mAD and healthy elderly ( ). The performance of the aMC/mAD group on SSIT was similar to that reported in Swedish and German patients with aMCI/mAD ( ), lending credence to the generalizability of the current results across aMCI/mAD populations. As expected, the percentage of carriers of one or two APOE4 alleles was significantly higher in the aMCI/mAD group than among controls. Harboring APOE4 alleles affects olfaction even in healthy older adults ( ), and the group difference in brain activity could be enhanced by this imbalance. Nevertheless, an APOE4 imbalance will be present in studies of aMCI/AD compared to health elderly due to the importance of APOE4 for AD risk ( ). \n\nThere are several limitations of this study. Firstly, we designed a very simple OI fMRI paradigm based on experience with difficulties getting older adults to perform more advanced olfactory fMRI paradigms. Despite the simple task design and pre-scan training, the participants in both the aMCI/mAD and control groups did not press the button to signal successful odor identification during scanning as younger adults do ( ) and the older adult pilot data indicated. The number of successful spontaneous OI during fMRI was so low that it was impossible to perform the planned event analysis. Since participants in both groups were able to spontaneously identify odors presented outside the scanner, it could be that the fMRI setting made them more cautious and/or insecure with regard to their own OI success or that they forgot to press the response buttons when they were not prompted by an examiner. We therefore analyzed activation associated with the OI state, i.e., the bloc where participants attempted to identify odors. Secondly, the control group was slightly younger than the aMCI/AD group. Given that the fMRI analysis correcting for age, sex, education, and brain parenchymal fraction was quite similar to the analysis without these covariates, the age difference between the two groups should not have affected the fMRI results ( ). There was no significant difference in the frequency of smokers between the two groups, and as such, the effect of being a smoker on OI performance should be limited. Thirdly, the sample size was modest, and we were not able to include enough patients to reach the estimated group size due to MRI compatibility issues and clinical characteristics uncovered during scanning or in the follow-up period. We were still able to uncover significant group differences even with fewer participants in the patient group though. Nevertheless, by including a larger group of patients, we might have uncovered more details especially with regard to differences in brain activity in the regions with high fMRI signal variability in the patient group, such as the medial temporal lobe. Calculating sample size is difficult in fMRI studies, but based on previous fMRI studies in MCI/dementia and other clinical populations, between 12 and 23 participants is most common in clinical fMRI ( ). With small samples, both type I and type II errors can be present, but the statistical approach implemented here has been shown to limit the inflated error rate for a two-sample   t  -test, even with only 10 subjects in each group ( ). Importantly, after correcting for age, sex, education, and brain parenchymal fraction, the main group difference in activity in the piriform cortex remained significant (even though the patient group size was reduced with three cases due to missing data), demonstrating a robust group difference. A fourth limitation of this study was the use of the ON region of interest mask, which does not allow for uncovering group differences in fMRI activity in brain regions outside the ON. \n\nA strength of the study is that all aMCI patients included were followed prospectively and clinically diagnosed as converted to AD or not. Moreover, the fMRI image analysis approaches and statistical thresholding were rigorously adhering to best practices, including a strict corrected threshold that correctly controls the family-wise error rate ( ). \n\n\n## Conclusion \n  \nOur findings show that during OI fMRI, patients with aMCI/mAD recruited the piriform cortex significantly less than the controls, and this activity was strongly associated with odor discrimination ability and to a lesser extent OI. The lack of consistent activity in the other ON structures in the aMCI/mAD group suggested large variability in activity due to differences in local AD-related pathology accompanied by aberrant downstream and reciprocal signaling within the regions of the ON. The reduced activity in the piriform cortex and normal activity in the anterior insula in the aMCI/mAD group likely reflect the presence of AD-related pathology in the piriform cortex but not in the insula, in accordance with the AD stages of the included patients. OI tests thus reflect AD pathology in olfactory structures. \n\n\n## Data Availability Statement \n  \nThe raw data supporting the conclusions of this article will be made available by the authors, without undue reservation. \n\n\n## Ethics Statement \n  \nThe studies involving human participants were reviewed and approved by REC Central\u2014Secretariat. The patients/participants provided their written informed consent to participate in this study. \n\n\n## Author Contributions \n  \nAll authors listed have made a substantial, direct and intellectual contribution to the work, and approved it for publication. \n\n\n## Conflict of Interest \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nCharacteristics\tControls (n = 28)\taMCI/mAD (n = 17)\nGender (female/male %)\t47/53\t53/47\nAge (years), mean (SD)\t67.4 (7.6)???\t74.4 (6.5)\nEducation (years), mean (SD)\t17.1 (3.5)\t15.3 (2.6)\nDaily smokers (%)\t3.4%\t6.3%\nAPOE4 genotype (% carriers 1\u20132 alleles) (n = 15/24)\t20.0%\t73.3%\nCSF total amyloid beta, mean (SD) (n = 0/11)\t-\t575.8 (227.6)\n### Caption\nCharacteristics of the control group and the aMCI/mAD group.\n### Footer\nSignificant differences using Student's t-test for control group compared to aMCI/mAD group,*p < 0.005.aMCI, amnestic mild cognitive impairment; APOE4, apolipoprotein E4; CSF, cerebrospinal fluid; mAD, Alzheimer's dementia of mild degree.\n\n\n## ID: T2\n### Label: Table 2\nUnnamed: 0\tControls (n = 28)\taMCI/mAD group (n = 17)\taMCI group at MRI (n = 11)\tmAD group at MRI (n = 6)\nMMSE (max 30)\t28.7 \u00b1 1.2\t25.5 \u00b1 2.5???\t26.0 \u00b1 1.6\t24.7 \u00b1 3.7\nTen-Word Test, total recall (max 30)\t22.7 \u00b1 3.6\t12.5 \u00b1 3.8???\t12.6 \u00b1 4.2\t12.4 \u00b1 2.9\nTen-Word Test, delayed recall (max 10)\t8.1 \u00b1 1.9\t2.2 \u00b1 1.7???\t2.27 \u00b1 1.8\t2.0 \u00b11.6\nTrail Making Test-A (s)\t52.6 \u00b1 21.1\t64.7 \u00b1 21.8???\t72.5 \u00b1 17.9\t50.5 \u00b1 24.5???\nTrail Making Test-B (s)\t104.1 \u00b1 37.5\t140.3 \u00b1 51.8???\t150.3 \u00b1 58.3\t122.8 \u00b1 26.0???\n### Caption\nPerformance of cognitive tests (mean \u00b1 SD) for the control group, combined aMCI/mAD group, and the aMCI and mAD groups separately.\n### Footer\nSignificant differences using Student's t-test,*p < 0.05,**p < 0.0005.aMCI, amnestic mild cognitive impairment; mAD, Alzheimer's dementia of mild degree; MMSE, Mini Mental Status Examination; s, seconds.\n\n\n## ID: T3\n### Label: Table 3\nUnnamed: 0\tControls\taMCI/mAD\tp-value\tCohen's d\n1. Clinical psychophysical tests\t1. Clinical psychophysical tests\t1. Clinical psychophysical tests\t1. Clinical psychophysical tests\t1. Clinical psychophysical tests\nB-SIT (max 12) (n = 17/28)\t9.5 \u00b1 2.0\t6.7 \u00b1 2.6\t<0.0005\t1.25\nSSIT (max 16) (n = 16/28)\t12.8 \u00b1 2.4\t9.4 \u00b1 3.0\t0.001\t1.25\nSSDT (max 16) (n = 12/27)\t9.7 \u00b1 2.8\t7.5 \u00b1 3.0\t0.099\t0.76\n2. Post-scan OI-tests\t2. Post-scan OI-tests\t2. Post-scan OI-tests\t2. Post-scan OI-tests\t2. Post-scan OI-tests\nPost-scan test free recall (max 10) (n = 16/27)\t3.9 \u00b1 2.1\t2.0 \u00b1 1.4\t0.004\t1.12\nPost-scan test multiple choice (max 10) (n = 16/27)\t8.0 \u00b1 2.0\t6.1 \u00b1 2.0\t0.003\t0.97\n### Caption\nOlfactory tests scores (mean \u00b1 SD) for the control group compared to aMCI/mAD group.\n### Footer\nSignificant differences using Student's t-test and Cohen's d for control group compared to aMCI/mild AD group. The number of patients and controls for each test is presented as n = patients/controls in the table.aMCI, amnestic mild cognitive impairment; B-SIT, Brief Smell Identification Test; mAD, Alzheimer's dementia of mild degree; OI, odor identification; SSIT, Sniffin' Sticks Identification Test; SSDT, Sniffin' Sticks Discrimination Test. Bold font indicates statistically significant group differences.\n\n\n## ID: T4\n### Label: Table 4\nBrain region\tHemisphere\tCluster nr.\tCluster size\tZ-value (max)\tX\tY\tZ\naMCI/mAD>Controls\taMCI/mAD>Controls\taMCI/mAD>Controls\taMCI/mAD>Controls\taMCI/mAD>Controls\taMCI/mAD>Controls\taMCI/mAD>Controls\taMCI/mAD>Controls\nna\t\t\t\t\t\t\t\naMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\taMCI/mAD>Controls, with nuisance variables\nna\t\t\t\t\t\t\t\nControls>aMCI/mAD\tControls>aMCI/mAD\tControls>aMCI/mAD\tControls>aMCI/mAD\tControls>aMCI/mAD\tControls>aMCI/mAD\tControls>aMCI/mAD\tControls>aMCI/mAD\nPiriform cortex\tR\t1\t297\t4.13\t24\t6\t\u221222\nControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\tControls>aMCI/mAD, with nuisance variables\nPiriform cortex\tR\t1\t86\t3.73\t24\t5\t\u221220\nOrbitofrontal cortex\tL\t2\t37\t3.69\t\u221231\t36\t\u221218\nOrbitofrontal cortex\tR\t3\t23\t3.61\t34\t25\t\u221218\naMCI/mAD group\taMCI/mAD group\taMCI/mAD group\taMCI/mAD group\taMCI/mAD group\taMCI/mAD group\taMCI/mAD group\taMCI/mAD group\nInsula, anterior\tR\t1\t126\t3.79\t35\t19\t\u22121\nInsula, anterior\tL\t2\t42\t3.71\t\u221235\t19\t\u22125\nControl group\tControl group\tControl group\tControl group\tControl group\tControl group\tControl group\tControl group\nPiriform cortex\tR\t1\t11,209\t5.86\t23\t3\t\u221222\nInsula, anterior\tR\t1\t11,209\t4.91\t38\t19\t\u22127\nEntorhinal cortex\tR\t1\t11,209\t4.72\t16\t\u22127\t\u221217\nOrbitofrontal cortex\tR\t1\t11,209\t4.69\t48\t20\t\u22129\nInsula, anterior\tL\t2\t5,926\t6.24\t\u221234\t18\t\u22129\nOrbitofrontal cortex\tL\t2\t5,926\t4.91\t\u221239\t26\t\u22121\nOrbitofrontal cortex\tL\t2\t5,926\t4.44\t\u221232\t33\t\u221222\nPiriform cortex\tL\t3\t2,403\t5.67\t\u221219\t0\t\u221222\nHippocampus, anterior\tL\t3\t2,403\t4.4\t\u221210\t\u22129\t\u221220\nThalamus, prefrontal\tL\t4\t1,756\t4.99\t\u22129\t\u22123\t1\nThalamus, temporal\tL\t4\t1,756\t4.94\t\u22127\t\u22123\t\u22123\nThalamus, temporal\tR\t4\t1,756\t4.46\t0\t\u221217\t3\nThalamus, prefrontal\tR\t4\t1,756\t4.19\t4\t\u221218\t9\nInsula, posterior\tL\t5\t210\t3.81\t\u221239\t\u22125\t8\nThalamus, parietal\tL\t6\t192\t3.9\t\u221212\t\u221230\t\u22124\nThalamus, sensory\tL\t6\t192\t3.83\t\u221213\t\u221223\t\u22125\nThalamus, motor\tL\t6\t192\t3.8\t\u221211\t\u221224\t\u22124\nPerirhinal cortex\tL\t8\t27\t3.6\t\u221227\t\u221212\t\u221242\nSubcallosal cortex\tL\t9\t17\t3.77\t\u22127\t12\t\u221222\n### Caption\nLocation of peak brain activations in MNI space during odor identification in the control group and aMCI/mAD groups.\n### Footer\nThe analysis was carried out using an olfactory network mask (see section Materials and Methods for structures included) and a corrected cluster threshold of p = 0.05. X, Y, and Z are coordinates of peak activation in MNI coordinates using the 1-mm template. Only clusters that were larger than or equal to one functional voxel were reported, and up to five local maxima were reported for each cluster. The nuisance variables included age, sex, education, and brain parenchymal fraction. R, right; L, left. See Figure 2 for brain maps.aMCI, amnestic mild cognitive impairment; mAD, Alzheimer's dementia of mild degree; MNI, Montreal Neurological Institute.\n\n\n## ID: T5\n### Label: Table 5\nBrain region\tHemisphere\tCluster nr.\tCluster size\tZ-value (max)\tX\tY\tZ\nSSDT\tSSDT\tSSDT\tSSDT\tSSDT\tSSDT\tSSDT\tSSDT\nPiriform cortex\tR\t1\t10\t3.66\t12\t\u22127\t\u221221\nSSIT\tSSIT\tSSIT\tSSIT\tSSIT\tSSIT\tSSIT\tSSIT\nna\t\t\t\t\t\t\t\nMMSE\tMMSE\tMMSE\tMMSE\tMMSE\tMMSE\tMMSE\tMMSE\nna\t\t\t\t\t\t\t\n### Caption\nLocation of brain activations during OI fMRI associated with olfactory test scores and Mini Mental Status Examination score.\n### Footer\nThe GLM analyses were carried out within the olfactory network mask (see section Materials and Methods for structures included) and a corrected cluster threshold of p = 0.05. X, Y, and Z are coordinates of peak activation in MNI coordinates using the 1-mm template. Since there were no group *test performance interactions, the associations are assessed across both groups. Only clusters that were larger than or equal to one functional voxel were reported, and up to five local maxima were reported for each cluster. R, right; L, left; MMSE, Mini Mental Status Examination; MNI, Montreal Neurological Institute; OI, odor identification; SSDT, Sniffin' Sticks Discrimination Test; SSIT, Sniffin' Sticks identification test.\n", "metadata": {"pmcid": 7838677, "text_md5": "4515e2b25919e9099b1732827e66f805", "field_positions": {"authors": [0, 137], "journal": [138, 150], "publication_year": [152, 156], "title": [167, 298], "keywords": [312, 385], "abstract": [398, 2766], "body": [2775, 45596], "tables": [45609, 52819]}, "batch": 2, "pmid": 33519686, "doi": "10.3389/fneur.2020.607566", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7838677", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7838677"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7838677\">7838677</a>", "list_title": "PMC7838677  The Human Brain Representation of Odor Identification in Amnestic Mild Cognitive Impairment and Alzheimer's Dementia of Mild Degree"}
{"text": "Hernandez, Leanna M. and Green, Shulamite A. and Lawrence, Katherine E. and Inada, Marisa and Liu, Janelle and Bookheimer, Susan Y. and Dapretto, Mirella\nFront Psychiatry, 2020\n\n# Title\n\nSocial Attention in Autism: Neural Sensitivity to Speech Over Background Noise Predicts Encoding of Social Information\n\n# Keywords\n\nspeech\nautism\nvoice-selective\nattention\nconversation\nnoise\naversive\nsensory\n\n\n# Abstract\n \nAutism spectrum disorder (ASD) is a neurodevelopmental disorder characterized by lack of attention to social cues in the environment, including speech. Hypersensitivity to sensory stimuli, such as loud noises, is also extremely common in youth with ASD. While a link between sensory hypersensitivity and impaired social functioning has been hypothesized, very little is known about the neural mechanisms whereby exposure to distracting sensory stimuli may interfere with the ability to direct attention to socially-relevant information. Here, we used functional magnetic resonance imaging (fMRI) in youth with and without ASD (N=54, age range 8\u201318 years) to ( ) examine brain responses during presentation of brief social interactions (i.e., two-people conversations) shrouded in ecologically-valid environmental noises, and ( ) assess how brain activity during encoding might relate to later accuracy in identifying what was heard. During exposure to conversation-in-noise (  vs  . conversation or noise alone), both neurotypical youth and youth with ASD showed robust activation of canonical language networks. However, the extent to which youth with ASD activated temporal language regions, including voice-selective cortex (i.e., posterior superior temporal sulcus), predicted later discriminative accuracy in identifying what was heard. Further, relative to neurotypical youth, ASD youth showed significantly greater activity in left-hemisphere speech-processing cortex (i.e., angular gyrus) while listening to conversation-in-noise (  vs  . conversation or noise alone). Notably, in youth with ASD, increased activity in this region was associated with higher social motivation and better social cognition measures. This heightened activity in voice-selective/speech-processing regions may serve as a compensatory mechanism allowing youth with ASD to hone in on the conversations they heard in the context of non-social distracting stimuli. These findings further suggest that focusing on social and non-social stimuli simultaneously may be more challenging for youth with ASD requiring the recruitment of additional neural resources to encode socially-relevant information. \n \n\n# Body\n \n## Introduction \n  \nAutism spectrum disorder (ASD) is a common neurodevelopmental disorder characterized by difficulties in social interaction and communication, the presence of repetitive behaviors and restricted interests, as well as sensory processing atypicalities ( ). Research in infants who later go on to get an ASD diagnosis has consistently shown that allocation of attention to social stimuli is disrupted early in development [for a review, see ( )]. For instance, young children with ASD fail to show a preference for listening to their mothers' voice ( ), as well as to child-directed speech ( ); disrupted attention to language early in life may set the stage for subsequent atypical language acquisition, as well as altered development of the neural systems responsible for language processing. Importantly, the ability to selectively attend to and learn from social interactions in one's environment often requires the simultaneous filtering out competing non-social stimuli. As heightened sensory sensitivity to mildly aversive auditory stimuli (e.g., loud noises) is observed in a significant number of children with ASD ( ), we hypothesize that this may be one potential mechanism through which attention may be drawn away from social input in favor of other non-social stimuli present in the environment. Despite growing interest in the relationship between sensory processing and social impairments in ASD ( \u2013 ), little research to date has investigated how individual variability in neural responses to   simultaneous   social and non-social sensory stimuli may relate to the ability to \u201chone in\u201d on socially-relevant input. \n\nConverging neuroimaging data indicate altered brain responses to language in individuals with ASD. While ASD is characterized by a great deal of heterogeneity ( ), young children with ASD who go on to have poorer language skills show hypoactivity in temporal cortex during language listening ( ), as well as reduced functional connectivity between nodes of the language network ( ). In children and adolescents with ASD, functional MRI (fMRI) studies have found reduced functional lateralization and increased rightward asymmetry during a variety of language processing tasks, as compared to the leftward asymmetry observed in neurotypical individuals ( \u2013 ), as well as reduced connectivity between voice-selective cortex and reward-related brain regions ( ). \n\nImportantly, however, in most real-life situations language is not heard in isolation but against the background of other competing sensory distractors (e.g., a buzzing fan, a barking dog). In neurotypical adults, the bilateral posterior superior temporal sulcus (pSTS) responds selectively to vocal stimuli, and activity in this region is reduced when voice stimuli are degraded or masked by background noise ( ,  ). In contrast, individuals with ASD fail to activate voice-selective regions in the pSTS during exposure to vocal stimuli ( ) and show increased recruitment of right hemisphere language homologues ( ). Furthermore, the ability to detect speech-in-noise appears reduced in individuals with ASD, who are poorer at identifying speech heard in the context of background noise ( ,  ). Interestingly, a recent study showed that sensory processing atypicalities modulate brain activity during language processing in youth with ASD during simultaneous processing of sarcastic remarks and distracting tactile stimulation ( ). However, it has yet to be examined how sensory distractors in the   same sensory modality   as speech may affect the allocation of attention to language processing during social interactions. This type of study has implications for understanding how auditory filtering deficits may affect encoding of social information in everyday life where conversations commonly occur in the context of background noises. \n\nIn adults with ASD, heightened sensory over-responsivity (SOR)\u2014characterized by extreme behavioral response to everyday sensory stimuli\u2014is related to higher autism traits ( ). Importantly, roughly 65% of children with ASD show atypical sensory responsivity to non-social auditory stimuli ( ,  ), including a lower tolerance for loud noises ( ,  ) and hypersensitivity to certain environmental noises, such as the sound of a dog barking or a vacuum cleaner ( ). A growing body of neuroimaging research also suggests that children with ASD who have high levels of SOR display neural hyper-responsivity to aversive visual, tactile, and auditory stimuli in primary sensory brain regions and areas important for salience detection ( ,  ), suggesting that there may be an over-allocation of attentional resources to sensory stimuli in youth with ASD. Together, these data suggest that language processing within social contexts in which there are other competing sensory stimuli\u2014such as those that occur in the natural environment\u2014may be particularly challenging for some individuals with ASD. \n\nHere, we examined brain responses to auditory social and non-social stimuli in a paradigm where participants heard brief conversations between two people which were shrouded in competing environmental noises. Ecologically valid stimuli were developed to examine the effects of ASD diagnosis on neural processing of commonly encountered environmental noise, conversation, and conversation-in-noise (i.e., noise and conversation presented simultaneously). In addition, participants completed a post-scan computerized test that probed recognition of the noises and topics of conversation presented during the fMRI paradigm, thus providing a measure of attention to, and encoding of social and non-social information. We hypothesized that, relative to neurotypical youth, youth with ASD would show reduced activity in left hemisphere language cortices when listening to conversation alone, as well as increased activity in sensory cortices when exposed to aversive noise. Further, we expected that the presence of distracting noises during speech processing would result in greater activation of subcortical and cortical brain regions involved in sensory processing in youth with ASD relative to neurotypical youth. Finally, we expected that the ability to recognize details from the conversations heard in presence of background noises would be associated with increased activity in canonical left hemisphere language regions and voice-selective cortex in the pSTS in both groups, reflecting the recruitment of additional neural resources to \u201chone in\u201d on social stimuli in the context of non-social distractors; to the extent that some youth with ASD may show hypersensitivity to auditory stimuli, we expect this effect would be more pronounced in this group. \n\n\n## Materials and Methods \n  \n### Participants \n  \nParticipants were 26 youth with ASD and 28 age-matched typically-developing (TD) youth who were recruited through referrals from the University of California, Los Angeles (UCLA) Child and Adult Neurodevelopmental (CAN) Clinic, as well as from posted advertisements throughout the greater Los Angeles area. Exclusionary criteria included any diagnosed neurological or genetic disorders, as well as structural brain abnormalities, or metal implants. ASD participants had a prior clinical diagnosis, which was confirmed using the Autism Diagnostic Observation Schedule\u20142nd Edition (ADOS-2) ( ) and Autism Diagnostic Interview-Revised (ADI-R) ( ) by licensed clinicians at the UCLA CAN Clinic. All participants had full-scale IQ above 70 as assessed by the Wechsler Abbreviated Scale of Intelligence ( ) ( ). Data were originally acquired for 30 ASD and 30 TD youth, 4 ASD participants, and 2 TD participants were excluded from the final sample due to excessive head motion during fMRI data acquisition (i.e., greater than 3.5 mm of maximum relative motion; see   for mean motion parameters in the final sample). Study procedures were approved by the UCLA Institutional Review Board and informed consent and assent to participate in this research were obtained in writing from legal guardians and study participants. \n  \nDescriptive statistics. \n    \n\n### Behavioral Measures \n  \nSocial functioning was assessed in both ASD and TD youth using the Social Responsiveness Scale\u20142  Edition (SRS-2) ( ). The SRS-2 is intended for use in both neurotypical populations and individuals with ASD and provides a measure of the severity of social impairment associated with autism. In the current study, we examined the relationship between t-scores for the socially-relevant subscales of the SRS-2 (i.e., social awareness, social cognition, social communication, and social motivation) and neural activity during conversation-in-noise listening. \n\n\n### Experimental Design \n  \nDuring the fMRI scan, auditory stimuli were presented according to a canonical block design ( ) using E-Prime 2.0 Software on a Dell Latitude E6430 laptop computer. Each block consisted of 15 s of auditory stimulus presentation alternating with 7.5 s of rest. A crosshair was presented at the center of a white screen throughout the duration of the scan. Blocks consisted of three types: conversation (C), noise (N), and conversation-in-noise (CIN; i.e., conversation and noise presented simultaneously). Stimuli were ecologically valid and mimicked those encountered in everyday life, whereby one overhears two people engaged in a conversation that is shrouded by competing auditory stimuli, thus forcing the listener to \u201chone in\u201d on the socially relevant speech. Inspiration for conversation topics were taken from scripted television series focusing on childhood/adolescence ( ). Speech passages were recorded by two actors (one male, one female) using GarageBand 6.0.5 and an Apogee MiC digital microphone connected to a Macintosh computer. Noise stimuli were downloaded from Freesound.org. Selection of noise stimuli ensured that they were ecologically valid (i.e., commonly encountered in everyday life). The aversive nature of the selected noises was rated in an independent sample (N=30) using a 7-point Likert scale (1=not aversive, 7=extremely aversive); the final 12 noise stimuli used in the fMRI paradigm were rated as moderately aversive (rating M=4.7, range 3.6\u20135.5) and included such sounds as a jackhammer, a police siren, and a blender. Root-mean-square amplitude was normalized across all stimuli to control for loudness. Stimuli were counterbalanced such that half of the participants heard a given conversation without noise, whereas the other half of participants heard the same conversation masked by noise (i.e., in the CIN condition). Likewise, for any given noise, half of participants heard the noise alone, while the other half heard the noise in the CIN condition. Each block type (C, N, CIN) was presented six times; order was counterbalanced across subjects. The total run time was 7 min and 7.5 s. Prior to the fMRI scan, participants were told that they would hear some people talking and some noises; they were instructed to just listen and look at the crosshair on the screen. Participants were not specifically instructed to pay attention to what was said, as we wanted the paradigm to have high ecological validity by mimicking situations encountered in everyday life when we may overhear others talking and are not explicitly asked to pay attention or remember what was said. \n  \nExperimental design.   (A)   Block design functional MRI (fMRI) task.   (B)   Example of a conversation heard during fMRI data acquisition.   (C)   Sample of post-scan questions. CIN, conversation-in-noise; C, conversation; N, noise. \n  \nTo assess the participants' ability to recognize stimuli presented in the three experimental conditions, and thus gain a proximal measure of in-scanner attention, a brief post-MRI scanning questionnaire was administered using E-Prime 2.0 Software on a Dell Latitude E6430 laptop computer. During this post-scanning test, participants heard and read questions about the conversations and noises they were exposed to during the fMRI data acquisition, interspersed with foils (i.e., with questions about conversations and noises they did not hear). For each conversation and noise stimulus presented during the fMRI scan, participants were first asked to answer a question about whether they heard such a particular conversation topic or noise. For the conversations, the post-scan test was tiered such that if a participant's yes/no response to this initial question was correct ( , top), a more nuanced question about that conversation was then presented ( , bottom). Incorrect responses to the initial yes/no questions resulted in being presented the next set of questions about a different conversation topic. Participant responses were recorded in E-Prime. A sensitivity index (d') was calculated to assess the ability of youth to discriminate between topics of conversation heard during MRI scanning and foils. d' was calculated as the standardized (i.e., z-transformed) proportion of hits minus the standardized proportion of false alarms. \n\n\n### MRI Data Acquisition \n  \nMRI data were collected on a 3.0 Tesla Siemens Prisma MRI Scanner using a 64-channel head coil. For each subject, a multi-slice echo-planar (EPI) sequence was used to acquire functional data: 595 volumes; repetition time (TR) = 720 ms; multiband acceleration factor = 8; matrix size = 104 x 104; field of view (FOV) = 208 \u00d7 208 mm; in-plane resolution = 2 \u00d7 2 mm; slice thickness = 2 mm, no gap; 72 slices; bandwidth = 2,290 Hz per pixel; echo time (TE) = 37 ms. Visual and auditory stimuli were presented   via   magnetic resonance compatible goggles and headphones (Optoacoustics LTD, Or Yehuda, Israel). Subjects wore earplugs and headphones to lessen scanner noise. \n\n\n### Functional MRI Data Analysis \n  \nData were processed using FSL (FMRIB's Software Library,  ) ( ) and AFNI (Analysis of Functional NeuroImages) ( ). Functional data were motion corrected to the average functional volume with FSL's Motion Correction Linear Registration Tool (MCFLIRT) ( ) using sinc interpolation and skull stripped using FSL's Brain Extraction Tool (BET) ( ). Time series statistical analyses were run in FSL's FMRI Expert Analysis Tool (FEAT) version 6.0. Functional images were spatially smoothed [full width at half maximum (FWHM) 5 mm] and a temporal high pass filter of 67.5 s was applied. Functional data were linearly registered to the Montreal Neurological Institute (MNI) 2 mm standard brain with 12\u00b0 of freedom. Motion outliers were identified using FSL's motion outliers tool (comparing the root mean square intensity difference from the center volume to identify outliers) and were included as a confound explanatory variable in the single subject analyses; there was no difference in the mean number of volumes censored between ASD and TD participants (p=0.31). Condition effects were estimated by convolving a box-function for each condition with a double-gamma hemodynamic response function, along with the temporal derivative. Each condition was modeled with respect to resting baseline (C, N, CIN); single-subject models were combined into a group-level mixed effects model (FLAME1+2). Verbal IQ was entered as a covariate in all group-level analyses. Within-group and between-group maps were pre-threshold masked by grey matter and thresholded at z > 3.1 (p < 0.001), cluster-corrected for multiple comparisons at p < 0.05. Between-group comparisons (i.e., ASD   vs  . TD) were masked by the sum of within-group activity for each condition of interest. \n\n\n### Statistical Analysis \n  \nTwo-tailed t-tests were performed to assess between-group differences in age, IQ, and motion parameters. To test whether participant's discriminative accuracy (d') for identifying the topics of conversation varied as a function of diagnostic group, condition, or question, a repeated measures ANOVA was conducted with group (i.e., ASD   vs  . TD) as the between-subjects factor and condition (i.e., N, C, CIN) as within-subjects factors. To further examine differences in behavioral performance, we also ran separate repeated measures ANOVAs comparing percent of correct responses for easy (yes/no) and hard (multiple-choice) questions separately with group (i.e., ASD   vs  . TD) as the between-subjects factor and condition (i.e., C   vs  . CIN) as the within-subjects factor. \n\n\n\n## Results \n  \n### Demographics \n  \nThere were no statistically significant differences between ASD and TD youth in sex, age, and non-verbal IQ, or across any of the four motion parameters tested ( ). Two-sample t-tests revealed significant differences in full-scale and verbal IQ between ASD and TD youth, whereby TD youth had higher IQ relative to their ASD counterparts. As expected, ASD and TD youth also had significantly different t-scores on the social awareness, social cognition, social communication, and social motivation subscales of the Social Responsiveness Scale (SRS), as well as differences in SRS Total t-scores, indicative of poorer parent-reported social functioning in youth with ASD. \n\n\n### Post-Scan Recognition Test \n  \nTo assess participants' ability to discriminate between what was actually heard   vs  . foils (i.e., correctly identifying a conversation, or noise, that was heard\u2014\u201chits\u201d\u2014  vs  . incorrectly endorsing a conversation or noise that was not heard\u2014\u201cfalse alarms\u201d), we calculated a sensitivity index (d') for each participant. In ASD youth, mean d' was 0.64, 0.59, 1.73, 1.28, for noises heard in the alone condition, noises heard in the conversation-in-noise condition, conversations head in the alone condition, and conversations heard in the conversation-in-noise condition, respectively. Likewise, mean d' in TD youth was 0.65, 0.67, 1.92, and 1.59 for noises heard in the alone condition, noises heard in the conversation-in-noise condition, conversations head in the alone condition, and conversations heard in the conversation-in-noise condition, respectively. A repeated-measures ANOVA was performed to test the interaction between group x condition. This analysis revealed no significant group x condition interaction [F(3,156)=0.56, p=0.64)] or main effect of Group [F(1,52)=0.83, p=0.37)]. However, the main effect of condition was significant [F(3,156)=46.46, p < 0.001)]; pairwise comparisons showed that both ASD and TD participants had higher accuracy (d') for conversations heard in the alone condition as compared to noises heard in the alone condition, as well as higher accuracy for conversations than noises when these were heard in the conversation-in-noise condition. \n\nIn order to further examine differences in behavioral performance, we also compared subjects' percent accuracy using separate repeated measures ANOVAs for easy (yes/no) and hard (multiple-choice) questions. For the easy questions, the main effect of condition was significant [F(1,52)=19.77, p < 0.001], whereby both groups were more accurate at identifying topics of conversation heard in the conversation alone condition than in the conversation-in-noise condition. However, there was no significant group x condition interaction [F(1,52)=0.38, p=0.54] or main effect of group [F(1,52)=1.02, p=0.32)]. For the hard (multiple-choice) questions, there was also a main effect of condition [F(1,52)=10.00, p < 0.01)], whereby both groups were more accurate at identifying topics of conversation heard in the conversation alone condition. However, while there was no main effect of group [F(1,52)=0.51, p=0.48)], there was a significant group x condition interaction [F(1,52)=5.53, p=0.02)].   Post hoc   tests showed that while the ASD and TD groups did not differ in percent accuracy for the conversation alone or conversation-in-noise conditions, the ASD group was significantly more accurate for the conversation alone condition than for the conversation-in-noise (p < 0.01); this was not the case for TD youth (p > 0.05). \n\n\n### Functional MRI Results \n  \n#### Within-Condition Analyses \n  \nAcross each of the three conditions, both youth with ASD and TD youth showed the expected activity in bilateral Heschl's gyrus, superior temporal gyrus, planum temporal, and planum polare ( ,  ). During exposure to conversation-in-noise (CIN) and conversation alone (C), both groups showed robust activation in auditory and language cortices, including bilateral superior temporal gyrus (STG), middle temporal gyrus, temporal pole, left angular gyrus, and superior frontal gyrus. Activity in ventromedial prefrontal cortex, a region involved in theory of mind and mentalizing, was observed in TD youth in the CIN condition, and in ASD youth in the C condition. In contrast to the extended network of regions activated during conditions in which speech was presented (i.e., CIN and C), brain activity during the noise condition (N) was restricted to primary and secondary auditory cortices; ASD youth showed additional activation in right inferior frontal gyrus and pars triangularis. No between-group differences were observed for any of the three experimental conditions at this statistical threshold (z > 3.1, p < 0.05). \n  \nWhole-brain activation in typically developing (TD) youth and youth with autism spectrum disorder (ASD) during exposure to conversation-in-noise (CIN), conversation (C), and noise (N). Maps are thresholded at z > 3.1, corrected for multiple comparisons at the cluster level (p < 0.05). \n    \nMontreal Neurological Institute (MNI) coordinates for each condition (conversation-in-noise, CIN; conversation, C; noise, N) compared to baseline. \n  \nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%. \n  \n\n#### Between-Condition Analyses \n  \nHere we compared brain activity between experimental conditions. First, we examined differences in brain activity when listening to conversation-in-noise relative to listening to noise alone (CIN > N). For this contrast, both TD and ASD youth showed increased activity in bilateral temporal pole, superior temporal gyrus, Heschl's gyrus, superior frontal gyrus, and medial prefrontal cortex ( ,  ), consistent with increased attention to language stimuli in the CIN condition. TD youth also showed activation in the right angular gyrus and bilateral hippocampus, whereas ASD youth showed significant activation in the precuneus. No regions showed significant between-group differences when comparing CIN and N conditions. \n  \nWithin-group results for comparisons between experimental conditions. Maps are thresholded at z > 3.1, corrected for multiple comparisons at the cluster level (p < 0.05). CIN, conversation-in-noise; N, noise; C, conversation. \n    \nMontreal Neurological Institute (MNI) coordinates for between-condition contrasts. \n  \nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%. \n  \nNext, we assessed differences in brain activity when listening to conversation-in-noise   versus   conversation alone (CIN > C). For this contrast, TD youth showed increased activity in lateral occipital cortex, whereas ASD youth had increased activity in right frontal pole, precuneus, and occipital pole ( ,  ). Between-group comparisons revealed that the ASD group had greater activity in primary visual cortex and precuneus relative to TD youth for the contrast of CIN > C; there were no brain regions where TD youth showed greater activity relative to ASD youth ( ). No brain regions showed greater activity when listening to conversation alone   vs  . conversation-in-noise (i.e., C > CIN). \n  \nMontreal Neurological Institute (MNI) coordinates for between-condition between-group contrasts. \n    \nLastly, to tap into the neural correlates of social attention (i.e., selective attention to speech in the context of background noise), we examined brain activity specifically associated with listening to conversation-in-noise, above and beyond activity observed for the conversation and noise alone conditions (CIN > C+N). For this contrast, both TD and ASD youth displayed activity in brain regions involved in auditory and language processing as well as theory of mind (i.e., angular gyri, superior frontal gyrus, and superior temporal regions); ASD youth displayed additional activity in the precuneus whereas TD youth showed activity in ventral medial frontal cortex ( ,  ). No significant between-group differences were observed for this contrast. \n\n\n#### Brain Activity Predicting Post-Scan Performance \n  \nIn an attempt to identify the neural substrates of social attention, we assessed how brain activity during the fMRI scan might predict accuracy in the post-scan test by entering d' as a regressor of interest in bottom-up regression analyses. We focused these analyses on our primary contrast of interest\u2014CIN > C+N\u2014in order to examine how d' related to brain activity specifically associated with processing conversation-in-noise   above and beyond   brain activity associated with processing conversation and noise alone. Whereas TD youth with higher d' showed selective activation of left posterior superior temporal sulcus (pSTS; i.e., voice-selective cortex), ASD youth with higher d' showed widespread increased activity primarily in language areas ( ,  ). Direct between-group comparisons showed that, relative to TD youth, ASD youth with higher d' showed significantly greater activity in speech-processing cortex in the left angular gyrus; there were no significant results for the reverse contract. To interpret the ASD > TD effect, we examined how activity in this speech-processing region while listening to conversation-in-noise might be related to social functioning in ASD youth. Parameter estimates of activity during the CIN condition were extracted from this region and correlated with scores from the SRS subscales. Higher activity in this left speech-processing region in ASD youth was associated with lower scores on the social motivation (  r  =\u22120.51, p=0.009) and social cognition (  r  =\u22120.41, p=0.04) SRS subscales, indicating more typical patterns of behavior. \n  \nMontreal Neurological Institute (MNI) coordinates for brain activity associated with discriminative accuracy (d') for topics of conversation heard in the conversation-in-noise (CIN) condition. \n  \nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%. \n    \nTop: associations between brain activity (CIN > C+N) and discriminative accuracy (i.e., d') for topics of conversation heard in the CIN condition. Maps are thresholded at z > 3.1, corrected for multiple comparisons at the cluster level (p < 0.05). Bottom: correlations between blood oxygen level dependent (BOLD) signal response for the CIN condition and scores on two subscales of the SRS in autism spectrum disorder (ASD) youth. CIN, conversation-in-noise; N, noise; C, conversation; SRS, Social Responsiveness Scale. \n  \n\n\n\n## Discussion \n  \nHere, we examined neural activity in response to   ecologically valid   social and non-social stimuli in youth with and without ASD to elucidate the neural mechanisms through which attention may be drawn away from socially-relevant information in the presence of distracting sensory stimulation in individuals with ASD. To do so, we employed a novel paradigm whereby participants heard naturalistic conversations in the context of common environmental noises that are often in the background of everyday social interactions. Overall, both youth with ASD and typically-developing youth showed a similar pattern of brain activity in auditory and language networks when listening to conversations presented alone and conversations presented with background noise; further, minimal differences were observed between diagnostic groups when comparing brain activity during listening to conversations alone   versus   conversations shrouded in noise. When we honed in on neural mechanisms underlying the ability to later recognize the topics of conversations that were heard in the presence of background noise, we found that higher recognition accuracy was associated with greater activity in left hemisphere voice-selective cortex in typically-developing youth. In contrast, in youth with ASD, better recognition accuracy was associated with increased activity in a larger network of regions subserving language processing, with significantly greater activity observed in left speech-processing cortex relative to typically-developing youth. Furthermore, we found that increased activity in this left-hemisphere speech-processing region when listening to conversations masked in noise was related to better social motivation and social cognition in ASD youth. \n\nAt the behavioral level, youth with and without ASD were equally accurate at discriminating noises   vs  . foils (d'), regardless of whether these were presented alone or simultaneously with conversations. As expected, accuracy in discriminating what was heard during the conversations (  vs  . foils) was overall higher in typically-developing youth, compared to youth with ASD, both when the conversations were presented alone or in the context of background noise; however, these differences were not statistically significant. Notably, we deliberately did not alert participants to pay attention to what was heard in the MRI scanner, as we wanted our paradigm to have high ecological validity by mimicking situations encountered in everyday life, when we may overhear a conversation and are not asked to explicitly pay attention or remember what was said. By explicitly asking participants to carefully listen and try to remember the conversations, any differences in overall discriminative accuracy between diagnostic groups would have likely been further reduced. Indeed, previous studies where direct attentional cues were provided to ASD youth have shown increased brain activity and improved behavioral performance as compared to conditions where such instructions were not given ( ,  ). Importantly, both neurotypical youth and youth with ASD had higher discriminative accuracy for conversations than noises when these were each presented alone, as well as higher discriminative accuracy when identifying conversations than noises when conversations and noises were presented simultaneously. In addition, both neurotypical and ASD youth showed the expected pattern whereby accuracy in identifying topics of conversation was poorer for conversations presented over background noise than for conversations presented alone. Although this latter difference was not statistically significant when using d' collapsed across the easy (yes/no) and hard (multiple-choice) questions, when looking at percent accuracy for the harder multiple-choice questions, ASD youth performed significantly worse in the conversation-in-noise condition than in the conversation alone condition, a pattern not observed in TD youth. Overall, these findings are in agreement with previous work in adults and adolescents with ASD showing that recall is poorer for sentences presented simultaneously with background sounds ( ,  ). However, our findings of similar discriminative accuracy (d') between typically-developing and ASD youth when identifying conversations heard in the context of background noises are in contrast to previous work suggesting that individuals with ASD are poorer at discriminating speech-in-noise relative to their neurotypical counterparts ( ,  ). This difference may in part be explained by our choice of noise stimuli, which were deliberately chosen to be only mildly aversive and, unlike those used in prior studies, also easily recognizable. Indeed, this methodological choice may also explain why we did not observe between-group differences in brain regions previously implicated in processing aversive auditory stimuli (e.g., amygdala, thalamus, auditory cortex), which have previously been documented in ASD participants ( ,  ,  ,  ). Importantly, the lack of significant between-group differences in brain responses to mildly aversive noises in this study may also in part reflect the more stringent statistical threshold employed in the current study, in keeping with evolving standards in the neuroimaging field ( ). Indeed, at more liberal thresholds we too observed greater activity in the amygdala and primary auditory cortex during exposure to mildly aversive noise in ASD youth as compared to TD youth. \n\nAt the neural level, typically-developing and ASD youth showed overall similar patterns of brain activity when listening to conversations alone, noises alone, and conversations shrouded in noise. The only significant between-group difference was detected when comparing brain activity observed when youth were presented with conversations and environmental noises simultaneously   versus   conversations alone. Here, the addition of background noise to conversations elicited greater activity in the precuneus and primary visual cortex in ASD relative to TD youth. The precuneus is a canonical hub of the default mode network, a network of brain regions implicated in thinking about the self and others ( ) and narrative comprehension in neurotypical adults ( ,  ). Our finding of increased activity in visual cortex during auditory stimulation in ASD youth, relative to typically-developing youth, is consistent with previous findings in individuals with ASD showing increased brain activity in the visual system during semantic decision making ( ) as well as auditory pitch discrimination ( ), suggesting atypical integration of auditory and visual sensory systems in ASD ( ,  ). Our findings thus suggest that similar behavioral profiles may in part reflect processing differences at the neural level whereby the challenging task of listening to social interactions over background noise requires activation of additional brain regions in youth with ASD, relative to neurotypical controls. \n\nThe ability to deploy attention to socially meaningful information rests on being able to divert attention away from less relevant distracting stimuli; accordingly, in an attempt to hone in on the neural substrates of social attention, we next sought to identify brain activity that was related to the successful encoding of the topics of conversation. More specifically, we examined how brain responses while participants listened to conversations in the context of background noise (above and beyond brain responses associated with attending to conversations and noises alone) predicted later recognition of what was heard. In both neurotypical youth and youth with ASD, greater accuracy in identifying the topics of conversations heard in the context of background noise was predicted by greater activity in left hemisphere voice-selective cortex. Previous work in neurotypical adults has shown that this voice-selective region preferentially responds to vocal stimuli, and that activity in this region decreases when voice stimuli are masked by background noise ( ,  ). Thus, heightened activity in this region when listening to conversations shrouded in common environmental noises may serve as a compensatory mechanism, allowing both youth with and without ASD to focus their attention on the socially-relevant information in the presence of distracting auditory stimuli. Importantly, better recognition accuracy in youth with ASD was also associated with greater activity in a wider network of brain regions implicated in language processing. Indeed, relative to typically-developing youth, ASD youth showed significantly greater activity in left-hemisphere angular gyrus. This region plays an important role in language comprehension ( \u2013 ) and prior work shows that disrupting activity in this area reduces the ability to comprehend speech under difficult listening conditions ( ). The angular gyrus is also an important region for theory of mind (TOM)\u2014the ability to understand the actions and thoughts of others ( ,  ). TOM is a critical skill in reasoning about others' state of mind and plays a role in high-level language processing including the use and understanding of language within a social environment ( ). Thus, similar to the heightened response in the voice-selective-region observed in both neurotypical and ASD youth, this increased activity in speech processing cortex in youth with ASD could reflect compensatory processes resulting in improved sensitivity to speech stimuli, thereby boosting youths' ability to encode and later accurately discriminate between conversation topics heard over background noise. If this interpretation is correct, individual differences in responsivity observed in this region in the context of our paradigm should be associated with the more general ability to hone in on socially-relevant information, and ultimately result in less severe social impairments. Consistent with this hypothesis, neural activity in this speech-processing region while participants listened to conversations shrouded in noise was associated with better social motivation and social cognition in youth with ASD. \n\nThis study has several limitations. First, due to the correlational nature inherent to all neuroimaging studies, while we hypothesized that the increased activity in language-related and TOM regions allowed ASD youth to hone in on socially relevant information, we cannot rule out the alternative account that greater activity in these brain regions merely resulted from more successful processing of language through noise. Second, atypical heightened sensitivity to sensory stimuli (known as sensory over-responsivity; SOR) affects over half of children with ASD ( ,  ) and is an important contributor to altered processing of both social and non-social stimuli in youth with ASD ( ,  ,  ,  ); however, given our small sample size, we were unable to directly compare groups of ASD youth with and without SOR. More work is needed to understand how SOR may mediate neural responses to ecologically valid social and non-social stimuli in the environment. Importantly, recent work also suggests that there may be sex-differences in the development of multisensory speech processing in TD and ASD youth ( ); thus, examining the interaction between sex, sensory processing, and social cognition is an important direction for future research. In addition, participants in our study were all high-functioning individuals who developed language and had verbal IQ in the normal range, making it more likely that our participants would have the ability to hone in on social stimuli compared to more affected individuals. In future studies it will be crucial replicate these findings and to extend this work to individuals with more severe ASD phenotypes, as well as to younger children on the autism spectrum. To this end, prospective studies of infants at high risk for developing ASD will be essential to track the longitudinal co-development of sensory responsivity, language acquisition, and ASD symptomatology. \n\nTo conclude, using a novel and ecologically valid paradigm, here we sought to better understand the neural correlates of social attention. Our findings indicate youth with ASD who successfully encoded socially-relevant information in the presence of distracting stimuli did so by up-regulating activity in neural systems supporting speech and language processing, thus suggesting that focusing on both social and non-social stimuli simultaneously may be more of a challenge for ASD youth relative to their neurotypical counterparts. This work buttresses the importance of further examining the relationship between social attention and sensory processing atypicalities, particularly early in development, to shed new light on the onset of autism symptomatology, as well as to inform the design of novel interventions. \n\n\n## Data Availability Statement \n  \nThe datasets generated for this study are available on request to the corresponding author. \n\n\n## Ethics Statement \n  \nThe studies involving human participants were reviewed and approved by University of California, Los Angeles Institutional Review Board. Written informed consent to participate in this study was provided by the participants' legal guardian/next of kin. \n\n\n## Author Contributions \n  \nThis study was conceived of and designed by LH, SG, KL, JL, SB, and MD. Data acquisition was performed by LH, KL, and JL. Data analysis was completed by LH and MI. All authors contributed to data interpretation and drafting of the manuscript, and provided critical feedback on the manuscript and its intellectual content. \n\n\n## Funding \n  \nThis work was supported by the National Institute of Mental Health (grants R01MH100028 and K08 MH112871) and the Simons Foundation Autism Research Initiative (grant 345389). Some of the authors were supported by training grants/fellowships from the National Institute of Neurological Disorders and Stroke (F99 NS105206 to LH, T32 NS048004 to LH and KL), the National Institute of Mental Health (F32 MH105167 to SG, F31 MH110140 to KL), the National Institute of Child Health and Human Development (F31 HD088102 to JL), and the Roche/ARCS Foundation Scholar Award Program in the Life Sciences (KL and JL). The project was also in part supported by grants RR12169, RR13642, and RR00865 from the NIH National Center for Research Resources. We are also grateful for generous support from the Brain Mapping Medical Research Organization, Brain Mapping Support Foundation, Pierson-Lovelace Foundation, The Ahmanson Foundation, the William M. and Linda R. Dietel Philanthropic Fund at the Northern Piedmont Community Foundation, the Tamkin Foundation, the Jennifer Jones-Simon Foundation, the Capital Group Companies Charitable Foundation, the Robson Family, and the Northstar Fund. The contents of this paper are solely the responsibility of the authors and do not necessarily represent the official views of the National Institutes of Health. \n\n\n## Conflict of Interest \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nUnnamed: 0\tASD mean (SD)\tTD mean (SD)\tt or x2\tUnnamed: 4\nDemographics\t\t\t\t\nSex (N male)\t19\t17\t0.93\t\nAge\t13.75 (2.98)\t13.78 (2.66)\t\u22120.04\t\nFull IQ\t102.42 (14.92)\t113.11 (13.05)\t\u22122.79\t**\nNonverbal IQ\t107.96 (17.61)\t112.61 (12.69)\t\u22121.11\t\nVerbal IQ\t97.42 (14.30)\t110.64 (13.42)\t\u22123.50\t***\nSRS Total T-Score\t68.77 (12.06)\t44.46 (5.90)\t9.30\t***\nSRS Social Awareness T-Score\t67.50 (11.19)\t45.18 (6.98)\t8.72\t***\nSRS Social Cognition T-Score\t67.27 (12.54)\t44.54 (7.30)\t8.06\t***\nSRS Social Communication T-Score\t67.58 (12.75)\t44.57 (5.76)\t8.44\t***\nSRS Social Motivation T-Score\t61.77 (11.80)\t47.01 (7.41)\t5.44\t***\nMotion\t\t\t\t\nMean absolute motion (mm)\t0.44 (0.28)\t0.42 (0.28)\t0.36\t\nMax absolute motion (mm)\t1.76 (1.65)\t1.39 (1.23)\t0.92\t\nMean relative motion (mm)\t0.14 (0.07)\t0.14 (0.06)\t\u22120.02\t\nMax relative motion (mm)\t1.21 (1.08)\t0.92 (0.78)\t1.11\t\nPost-scan test: percent correct\t\t\t\t\nConversations, alone condition\t\t\t\t\nEasy questions\t75.76% (20.77)\t81.95% (17.35)\t\u22121.18\t\nHard questions\t79.58% (16.92)\t76.02% (22.82)\t0.65\t\nConversations, conversation-in-noise condition\t\t\t\t\nEasy questions\t66.43% (16.36)\t69.59% (16.36)\t\u22120.60\t\nHard questions\t61.73% (25.46)\t73.16% (25.46)\t\u22121.60\t\n\t\t\t\t\nPost-Scan Test: discriminative accuracy (d')\t\t\t\t\nConversations, alone condition\t1.73 (0.97)\t1.92 (1.01)\t\u22120.71\t\nConversations, conversation-in-noise condition\t1.28 (0.86)\t1.59 (0.99)\t\u22121.21\t\n### Caption\nDescriptive statistics.\n### Footer\n**p < 0.01, ***p < 0.001ASD, autism spectrum disorder; TD, typically developing; IQ, intelligence quotient.\n\n\n## ID: T2\n### Label: Table 2\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tConversation-in-noise (CIN)\tUnnamed: 11_level_0\tConversation (C)\tConversation (C)\tConversation (C)\tConversation (C)\tConversation (C)\tConversation (C)\tConversation (C)\tConversation (C)\tConversation (C)\tUnnamed: 21_level_0\tNoise (N)\tNoise (N)\tNoise (N)\tNoise (N)\tNoise (N)\tNoise (N)\tNoise (N)\tNoise (N)\tNoise (N)\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tASD\tASD\tASD\tASD\tUnnamed: 6_level_1\tTD\tTD\tTD\tTD\tUnnamed: 11_level_1\tASD\tASD\tASD\tASD\tUnnamed: 16_level_1\tTD\tTD\tTD\tTD\tUnnamed: 21_level_1\tASD\tASD\tASD\tASD\tUnnamed: 26_level_1\tTD\tTD\tTD\tTD\nUnnamed: 0_level_2\tUnnamed: 1_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 6_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 11_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 16_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 21_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 26_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\nUnnamed: 0_level_3\tUnnamed: 1_level_3\tUnnamed: 2_level_3\tX\tY\tZ\tUnnamed: 6_level_3\tUnnamed: 7_level_3\tX\tY\tZ\tUnnamed: 11_level_3\tUnnamed: 12_level_3\tX\tY\tZ\tUnnamed: 16_level_3\tUnnamed: 17_level_3\tX\tY\tZ\tUnnamed: 21_level_3\tUnnamed: 22_level_3\tX\tY\tZ\tUnnamed: 26_level_3\tUnnamed: 27_level_3\tX\tY\tZ\nAngular gyrus\tL\t3.57\t\u221260\t\u221258\t22\t\t5.27\t\u221258\t\u221256\t20\t\t3.66\t\u221260\t\u221258\t22\t\t3.83\t\u221258\t\u221258\t16\t\t\t\t\t\t\t\t\t\t\nCentral opercular cortex\tL\t4.39\t\u221252\t\u221212\t10\t\t4.12\t\u221258\t\u221210\t8\t\t4.79\t\u221260\t\u221220\t14\t\t4.21\t\u221258\t\u221210\t8\t\t3.85\t\u221260\t\u221216\t12\t\t3.59\t\u221250\t\u221220\t14\nCentral opercular cortex\tR\t4.63\t50\t\u221212\t10\t\t4.24\t56\t\u22126\t6\t\t4.81\t48\t\u221212\t10\t\t4.0\t54\t\u221210\t8\t\t3.58\t50\t\u221210\t8\t\t3.55\t56\t\u22126\t6\nFrontal operculum cortex\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.51\t40\t24\t2\nFrontal orbital cortex\tR\t\t\t\t\t\t4.48\t40\t30\t\u221218\t\t\t\t\t\t\t3.26\t40\t26\t\u221220\t\t\t\t\t\t\t\t\t\t\nFrontal pole\tL\t3.54\t\u22122\t60\t20\t\t5.06\t\u221212\t50\t34\t\t3.88\t\u221210\t58\t28\t\t4.83\t\u221212\t52\t32\t\t\t\t\t\t\t\t\t\t\nFrontal pole\tR\t3.77\t4\t60\t20\t\t\t\t\t\t\t\t\t\t\t\t4.01\t12\t50\t36\t\t\t\t\t\t\t\t\t\t\nFrontal medial cortex\tL\t\t\t\t\t\t3.48\t\u22122\t36\t\u221224\t\t4.07\t\u22124\t38\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nFrontal medial cortex\tR\t\t\t\t\t\t4.41\t2\t44\t\u221216\t\t4.1\t4\t38\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nHeschl's gyrus\tL\t5.78\t\u221250\t\u221222\t8\t\t6.79\t\u221240\t\u221224\t10\t\t6.73\t\u221238\t\u221226\t12\t\t7.15\t\u221240\t\u221224\t10\t\t6.13\t\u221244\t\u221218\t4\t\t6.03\t\u221244\t\u221218\t4\nHeschl's gyrus\tR\t6.43\t44\t\u221216\t6\t\t5.75\t50\t\u221220\t8\t\t6.71\t48\t\u221214\t6\t\t5.62\t42\t\u221222\t10\t\t6.21\t46\t\u221214\t6\t\t5.49\t44\t\u221218\t8\nInsular cortex\tL\t\t\t\t\t\t3.74\t\u221240\t\u221216\t6\t\t3.68\t\u221242\t\u221212\t4\t\t3.69\t\u221240\t\u221216\t6\t\t3.88\t\u221240\t\u22124\t\u221212\t\t3.82\t\u221242\t\u22126\t\u22126\nInsular cortex\tR\t\t\t\t\t\t\t\t\t\t\t3.2\t42\t\u221212\t6\t\t\t\t\t\t\t3.17\t40\t\u22126\t\u221210\t\t\t\t\t\nLateral occipital cortex\tL\t3.11\t\u221258\t\u221264\t24\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nMiddle temporal gyrus\tL\t5.01\t\u221258\t\u22122\t\u221216\t\t5.58\t\u221252\t\u221228\t\u22126\t\t5.55\t\u221256\t\u22122\t\u221218\t\t5.59\t\u221266\t\u221216\t\u221216\t\t\t\t\t\t\t\t\t\t\nMiddle temporal gyrus\tR\t5.32\t50\t\u221224\t\u22126\t\t5.26\t58\t\u221232\t\u22122\t\t4.98\t50\t\u221224\t\u22126\t\t5.16\t64\t\u221212\t\u221210\t\t\t\t\t\t\t\t\t\t\nParacingulate gyrus\tL\t\t\t\t\t\t3.79\t\u22124\t48\t26\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nParacingulate gyrus\tR\t3.78\t4\t52\t20\t\t\t\t\t\t\t\t\t\t\t\t3.3\t4\t50\t22\t\t\t\t\t\t\t\t\t\t\nParietal operculum cortex\tL\t5.22\t\u221248\t\u221228\t14\t\t3.54\t\u221246\t\u221230\t14\t\t5.59\t\u221248\t\u221228\t14\t\t3.7\t\u221258\t\u221230\t16\t\t5.59\t\u221246\t\u221230\t14\t\t3.93\t\u221248\t\u221228\t14\nParietal operculum cortex\tR\t4.31\t44\t\u221224\t16\t\t3.77\t46\t\u221226\t16\t\t3.87\t44\t\u221224\t16\t\t3.84\t48\t\u221226\t16\t\t\t\t\t\t\t4.12\t54\t\u221224\t16\nPlanum polare\tL\t4.82\t\u221244\t\u221218\t\u22124\t\t4.08\t\u221248\t0\t\u221212\t\t4.65\t\u221242\t2\t\u221220\t\t4.06\t\u221248\t0\t\u221212\t\t4.47\t\u221246\t0\t\u221212\t\t5.4\t\u221246\t\u22128\t\u22126\nPlanum polare\tR\t4.25\t46\t\u221212\t\u22124\t\t3.97\t48\t2\t\u221214\t\t4.1\t58\t2\t0\t\t4.26\t46\t4\t\u221216\t\t4.19\t44\t4\t\u221216\t\t4.47\t46\t\u22124\t\u221210\nPlanum temporale\tL\t6.55\t\u221256\t\u221228\t8\t\t6.25\t\u221252\t\u221226\t6\t\t7.23\t\u221256\t\u221228\t8\t\t6.01\t\u221262\t\u221220\t8\t\t6.27\t\u221244\t\u221232\t10\t\t5.74\t\u221252\t\u221226\t8\nPlanum temporale\tR\t6.18\t58\t\u221224\t10\t\t6.02\t62\t\u221220\t8\t\t6.0\t44\t\u221230\t12\t\t6.0\t62\t\u221220\t8\t\t4.65\t60\t\u221222\t10\t\t6.64\t58\t\u221226\t12\nPostcentral gyrus\tL\t3.25\t\u221264\t\u221216\t16\t\t\t\t\t\t\t3.63\t\u221264\t\u221216\t16\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nPostcentral gyrus\tR\t3.1\t66\t\u221214\t16\t\t\t\t\t\t\t3.13\t66\t\u221214\t16\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nSubcallosal cortex\tL\t\t\t\t\t\t4.39\t\u22122\t20\t\u221224\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nSubcallosal cortex\tR\t\t\t\t\t\t4.71\t2\t20\t\u221224\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nSuperior frontal gyrus\tL\t3.43\t\u22122\t52\t34\t\t4.59\t\u22124\t52\t28\t\t5.54\t\u22124\t50\t32\t\t4.7\t\u22126\t52\t30\t\t\t\t\t\t\t\t\t\t\nSuperior frontal gyrus\tR\t5.77\t4\t52\t30\t\t\t\t\t\t\t3.35\t2\t48\t36\t\t3.66\t6\t50\t36\t\t\t\t\t\t\t\t\t\t\nSuperior temporal gyrus\tL\t6.65\t\u221266\t\u221228\t10\t\t6.23\t\u221266\t\u221224\t0\t\t6.39\t\u221266\t\u221228\t10\t\t6.13\t\u221266\t\u221218\t4\t\t4.1\t\u221266\t\u221226\t10\t\t4.89\t\u221266\t\u221226\t10\nSuperior temporal gyrus\tR\t6.25\t68\t\u221218\t4\t\t6.72\t66\t\u221220\t2\t\t6.71\t68\t\u221218\t4\t\t6.96\t66\t\u221220\t2\t\t5.18\t68\t\u221220\t2\t\t7.17\t70\t\u221224\t2\nSupramarginal gyrus\tL\t4.38\t\u221258\t\u221246\t22\t\t3.99\t\u221264\t\u221246\t16\t\t3.93\t\u221264\t\u221246\t16\t\t3.17\t\u221264\t\u221248\t16\t\t\t\t\t\t\t\t\t\t\nSupramarginal gyrus\tR\t3.63\t66\t\u221240\t10\t\t3.65\t66\t\u221240\t10\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nTemporal pole\tL\t5.69\t\u221244\t16\t\u221220\t\t6.1\t\u221246\t10\t\u221220\t\t5.9\t\u221258\t6\t\u221216\t\t5.88\t\u221250\t10\t\u221220\t\t4.5\t\u221252\t6\t\u22128\t\t3.81\t\u221252\t6\t\u22126\nTemporal pole\tR\t7.08\t42\t14\t\u221222\t\t5.51\t56\t10\t\u221220\t\t5.38\t52\t12\t\u221226\t\t6.63\t52\t14\t\u221218\t\t3.6\t58\t8\t\u22128\t\t3.52\t56\t8\t\u22126\nThalamus\tL\t3.63\t\u221210\t\u221232\t0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nThalamus\tR\t3.7\t10\t\u221232\t0\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n### Caption\nMontreal Neurological Institute (MNI) coordinates for each condition (conversation-in-noise, CIN; conversation, C; noise, N) compared to baseline.\n### Footer\nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%.\n\n\n## ID: T3\n### Label: Table 3\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tCIN > N\tCIN > N\tCIN > N\tCIN > N\tCIN > N\tCIN > N\tCIN > N\tCIN > N\tCIN > N\tUnnamed: 11_level_0\tCIN > C\tCIN > C\tCIN > C\tCIN > C\tCIN > C\tCIN > C\tCIN > C\tCIN > C\tCIN > C\tUnnamed: 21_level_0\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tASD\tASD\tASD\tASD\tUnnamed: 6_level_1\tTD\tTD\tTD\tTD\tUnnamed: 11_level_1\tASD\tASD\tASD\tASD\tUnnamed: 16_level_1\tTD\tTD\tTD\tTD\tUnnamed: 21_level_1\tASD\tASD\tASD\tASD\tUnnamed: 26_level_1\tTD\tTD\tTD\tTD\nUnnamed: 0_level_2\tUnnamed: 1_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 6_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 11_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 16_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 21_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 26_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\nUnnamed: 0_level_3\tUnnamed: 1_level_3\tMax z\tX\tY\tZ\tUnnamed: 6_level_3\tMax z\tX\tY\tZ\tUnnamed: 11_level_3\tMax z\tX\tY\tZ\tUnnamed: 16_level_3\tMax z\tX\tY\tZ\tUnnamed: 21_level_3\tMax z\tX\tY\tZ\tUnnamed: 26_level_3\tMax z\tX\tY\tZ\nAmygdala\tL\t\t\t\t\t\t4.78\t\u221228\t\u22126\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nAmygdala\tR\t\t\t\t\t\t4.74\t24\t\u22126\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nAngular gyrus\tL\t3.89\t\u221262\t0\t20\t\t4.64\t\u221258\t\u221256\t20\t\t\t\t\t\t\t\t\t\t\t\t3.32\t\u221262\t\u221254\t20\t\t5.92\t\u221256\t\u221254\t20\nAngular gyrus\tR\t\t\t\t\t\t5.39\t52\t\u221254\t20\t\t\t\t\t\t\t\t\t\t\t\t4.35\t62\t\u221248\t22\t\t4.15\t54\t\u221250\t18\nCentral opercular cortex\tL\t3.95\t\u221252\t\u221212\t10\t\t4.52\t\u221258\t\u221210\t8\t\t\t\t\t\t\t\t\t\t\t\t3.64\t\u221250\t\u22128\t6\t\t3.96\t\u221252\t\u221210\t8\nCentral opercular cortex\tR\t4.33\t48\t\u221216\t12\t\t3.19\t62\t\u22128\t8\t\t\t\t\t\t\t\t\t\t\t\t3.57\t48\t\u221216\t12\t\t4.25\t62\t\u22128\t8\nCingulate gyrus posterior\tL\t3.83\t\u22122\t\u221250\t22\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.26\t\u22122\t\u221250\t18\t\t\t\t\t\nCingulate gyrus posterior\tR\t3.68\t2\t\u221250\t20\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.24\t2\t\u221248\t18\t\t\t\t\t\nCuneal cortex\tL\t\t\t\t\t\t\t\t\t\t\t3.77\t\u22122\t\u221282\t34\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nFrontal medial cortex\tL\t4.46\t\u22124\t42\t\u221216\t\t4.45\t\u22122\t38\t\u221222\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.6\t\u22122\t36\t\u221222\nFrontal medial cortex\tR\t4.93\t2\t44\t\u221216\t\t6.46\t2\t42\t\u221222\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t5.05\t4\t40\t\u221222\nFrontal orbital cortex\tL\t3.65\t\u221238\t20\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nFrontal orbital cortex\tR\t\t\t\t\t\t3.14\t40\t26\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.19\t44\t28\t\u221218\nFrontal pole\tL\t3.57\t\u22124\t64\t24\t\t3.7\t\u221210\t58\t28\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nFrontal pole\tR\t4.11\t12\t42\t48\t\t\t\t\t\t\t4.84\t38\t44\t6\t\t\t\t\t\t\t4.03\t12\t48\t46\t\t\t\t\t\nFusiform cortex\tL\t\t\t\t\t\t3.69\t\u221240\t\u221218\t\u221224\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nHeschl's gyrus\tL\t5.11\t\u221248\t\u221218\t8\t\t5.09\t\u221240\t\u221222\t8\t\t\t\t\t\t\t\t\t\t\t\t4.45\t\u221250\t\u221222\t8\t\t6.35\t\u221246\t\u221224\t10\nHeschl's gyrus\tR\t5.25\t48\t\u221220\t10\t\t5.67\t50\t\u221220\t8\t\t\t\t\t\t\t\t\t\t\t\t4.04\t48\t\u221220\t10\t\t4.66\t50\t\u221220\t8\nHippocampus\tL\t\t\t\t\t\t4.85\t\u221226\t\u22128\t\u221222\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nHippocampus\tR\t\t\t\t\t\t4.66\t26\t\u22128\t\u221220\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nInferior temporal gyrus\tL\t\t\t\t\t\t3.61\t\u221256\t\u221218\t\u221228\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.58\t\u221256\t\u221220\t\u221226\nLateral occipital cortex\tL\t3.86\t\u221256\t\u221264\t24\t\t4.2\t\u221250\t\u221262\t26\t\t3.7\t\u221212\t\u221282\t46\t\t4.41\t\u221248\t\u221274\t26.0\t\t3.57\t\u221256\t\u221262\t26\t\t\t\t\t\nLateral occipital cortex\tR\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.79\t54\t\u221264\t18\t\t\t\t\t\nMiddle temporal gyrus\tR\t5.26\t50\t\u221224\t\u22126\t\t6.31\t\u221254\t\u221226\t\u22128\t\t\t\t\t\t\t\t\t\t\t\t4.02\t\u221256\t\u221232\t\u22124\t\t5.84\t\u221254\t\u221228\t\u22126\nMiddle temporal gyrus\tL\t5.55\t\u221256\t0\t\u221228\t\t4.99\t64\t\u221212\t\u221210\t\t\t\t\t\t\t\t\t\t\t\t5.16\t52\t\u221220\t\u22128\t\t4.9\t62\t\u221230\t\u22124\nOccipital pole\tL\t\t\t\t\t\t\t\t\t\t\t4.74\t\u221212\t\u221296\t\u22122\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nOccipital pole\tR\t\t\t\t\t\t\t\t\t\t\t3.51\t2\t\u221296\t6\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nParacingulate gyrus\tL\t3.26\t\u22126\t50\t20\t\t3.32\t\u22122\t48\t26\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.31\t\u22122\t48\t26\nParacingulate gyrus\tR\t3.18\t4\t52\t20\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.27\t4\t42\t34\t\t\t\t\t\nParahippocampal gyrus\tL\t\t\t\t\t\t4.16\t\u221220\t\u221226\t\u221218\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nParietal operculum Cortex\tL\t4.11\t\u221242\t\u221234\t16\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.18\t\u221242\t\u221234\t16\t\t\t\t\t\nParietal operculum Cortex\tR\t3.45\t48\t\u221222\t16\t\t3.75\t44\t\u221224\t16\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nPlanum polare\tL\t3.43\t\u221254\t\u22122\t0\t\t3.99\t\u221244\t\u22122\t\u221218\t\t\t\t\t\t\t\t\t\t\t\t3.18\t\u221248\t\u22124\t\u22128\t\t4.04\t\u221244\t0\t\u221218\nPlanum polare\tR\t3.56\t58\t2\t0\t\t4.07\t46\t4\t\u221216\t\t\t\t\t\t\t\t\t\t\t\t3.62\t46\t0\t\u221216\t\t4.54\t48\t2\t\u221214\nPlanum temporale\tL\t5.61\t\u221254\t\u221228\t8\t\t5.92\t\u221262\t\u221220\t8\t\t\t\t\t\t\t\t\t\t\t\t5.24\t\u221254\t\u221228\t8\t\t6.15\t\u221262\t\u221220\t8\nPlanum temporale\tR\t4.39\t62\t\u221220\t8\t\t4.39\t62\t\u221218\t8\t\t\t\t\t\t\t\t\t\t\t\t3.86\t62\t\u221220\t8\t\t4.19\t62\t\u221218\t8\nPrecuneus cortex\tL\t3.59\t\u22122\t\u221260\t22\t\t\t\t\t\t\t4.05\t\u221212\t\u221264\t22\t\t\t\t\t\t\t3.75\t\u22122\t\u221258\t18\t\t\t\t\t\nPrecuneus cortex\tR\t4.07\t4\t\u221256\t22\t\t\t\t\t\t\t4.06\t8\t\u221254\t50\t\t\t\t\t\t\t4.07\t2\t\u221258\t18\t\t\t\t\t\nSubcallosal cortex\tL\t\t\t\t\t\t5.07\t\u22122\t20\t\u221224\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.84\t\u22122\t20\t\u221224\nSubcallosal cortex\tR\t\t\t\t\t\t5.61\t2\t24\t\u221226\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.66\t2\t20\t\u221224\nSuperior frontal gyrus\tL\t3.12\t\u22124\t54\t24\t\t5.57\t\u22124\t54\t24\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.69\t\u22124\t42\t38\nSuperior frontal gyrus\tR\t4.79\t2\t50\t36\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t4.03\t2\t42\t40\t\t3.29\t4\t50\t32\nSuperior temporal gyrus\tL\t5.7\t\u221262\t\u221226\t0\t\t6.59\t\u221264\t\u221218\t\u22124\t\t\t\t\t\t\t\t\t\t\t\t5.47\t\u221264\t\u221226\t2\t\t6.01\t\u221264\t\u221218\t\u22124\nSuperior temporal gyrus\tR\t5.31\t54\t\u221218\t\u22126\t\t6.34\t58\t\u221218\t\u22124\t\t\t\t\t\t\t\t\t\t\t\t5.26\t52\t\u221212\t\u221210\t\t6.06\t58\t\u221220\t\u22122\nSupramarginal gyrus\tL\t4.33\t\u221264\t\u221246\t16\t\t3.22\t\u221264\t\u221248\t16\t\t\t\t\t\t\t\t\t\t\t\t4.08\t\u221258\t\u221246\t22\t\t4.25\t\u221264\t\u221246\t16\nSupramarginal gyrus\tR\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t3.46\t66\t\u221238\t18\t\t3.37\t66\t\u221240\t10\nTemporal pole\tL\t5.19\t\u221232\t14\t\u221228\t\t6.47\t\u221250\t12\t\u221236\t\t\t\t\t\t\t\t\t\t\t\t5.74\t\u221246\t16\t\u221220\t\t6.52\t\u221250\t8\t\u221222\nTemporal pole\tR\t5.84\t48\t18\t\u221230\t\t5.63\t50\t14\t\u221222\t\t\t\t\t\t\t\t\t\t\t\t7.31\t50\t18\t\u221230\t\t6.04\t58\t8\t\u221218\n### Caption\nMontreal Neurological Institute (MNI) coordinates for between-condition contrasts.\n### Footer\nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%.\n\n\n## ID: T4\n### Label: Table 4\nUnnamed: 0_level_0\tUnnamed: 1_level_0\tCIN > C\tCIN > C\tCIN > C\tCIN > C\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tASD > TD\tASD > TD\tASD > TD\tASD > TD\nUnnamed: 0_level_2\tUnnamed: 1_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\nUnnamed: 0_level_3\tUnnamed: 1_level_3\tMax z\tX\tY\tZ\nCuneal cortex\tL\t3.47\t\u22122\t\u221286\t34\nOccipital pole\tL\t3.6\t\u221210\t\u221294\t0\nPrecuneus cortex\tL\t3.51\t\u22126\t\u221264\t30\n### Caption\nMontreal Neurological Institute (MNI) coordinates for between-condition between-group contrasts.\n### Footer\nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%.\n\n\n## ID: T5\n### Label: Table 5\nCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\tCIN > C+N\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tASD + TD\tASD + TD\tASD + TD\tASD + TD\tASD\tASD\tASD\tASD\tTD\tTD\tTD\tTD\tASD > TD\tASD > TD\tASD > TD\tASD > TD\tUnnamed: 18_level_1\nUnnamed: 0_level_2\tUnnamed: 1_level_2\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tMax z\tMNI peak (mm)\tMNI peak (mm)\tMNI peak (mm)\tUnnamed: 18_level_2\nUnnamed: 0_level_3\tUnnamed: 1_level_3\tMax z\tX\tY\tZ\tMax z\tX\tY\tZ\tMax z\tX\tY\tZ\tMax z\tX\tY\tZ\tUnnamed: 18_level_3\nAngular gyrus\tL\t4.98\t\u221252\t\u221260\t20\t5.37\t\u221256\t\u221258\t26\t\t\t\t\t4.07\t\u221250\t\u221260\t24\t\nAngular gyrus\tR\t\t\t\t\t3.82\t46\t\u221250\t28\t\t\t\t\t\t\t\t\t\nFrontal orbital cortex\tR\t4.44\t44\t24\t\u221214\t4.26\t44\t24\t\u221214\t\t\t\t\t\t\t\t\t\nFusiform cortex\tL\t\t\t\t\t\t\t\t\t\t\t\t\t3.86\t\u221234\t\u221258\t\u221216\t\nLateral occipital cortex\tL\t3.16\t\u221254\t\u221264\t26\t5.48\t\u221254\t\u221264\t20\t\t\t\t\t4.74\t\u221248\t\u221264\t26\t\nLateral occipital cortex\tR\t\t\t\t\t4.09\t42\t\u221284\t\u22122\t\t\t\t\t\t\t\t\t\nMiddle temporal gyrus\tL\t4.95\t\u221262\t\u221210\t\u22128\t5.15\t\u221254\t\u22124\t\u221228\t3.74\t\u221252\t\u221234\t\u22124\t\t\t\t\t\nMiddle temporal gyrus\tR\t4.79\t56\t2\t\u221220\t5.02\t56\t2\t\u221230\t\t\t\t\t\t\t\t\t\nOccipital pole\tL\t\t\t\t\t4.07\t\u221232\t\u221294\t\u221210\t\t\t\t\t\t\t\t\t\nOccipital pole\tR\t\t\t\t\t4.47\t36\t\u221292\t\u22122\t\t\t\t\t\t\t\t\t\nParietal operculum cortex\tR\t\t\t\t\t4.19\t44\t\u221232\t20\t\t\t\t\t\t\t\t\t\nPlanum temporale\tL\t4.0\t\u221260\t\u221226\t6\t4.37\t\u221262\t\u221224\t10\t\t\t\t\t\t\t\t\t\nPlanum temporale\tR\t4.34\t52\t\u221230\t16\t4.82\t60\t\u221230\t16\t\t\t\t\t\t\t\t\t\nPrecentral gyrus\tR\t\t\t\t\t4.17\t54\t\u22122\t42\t\t\t\t\t\t\t\t\t\nSuperior temporal gyrus\tL\t5.47\t\u221262\t\u221226\t2\t3.62\t\u221258\t\u221238\t6\t3.13\t\u221260\t\u221244\t8\t\t\t\t\t\nSuperior temporal gyrus\tR\t4.52\t46\t\u221232\t4\t3.55\t52\t\u221232\t4\t\t\t\t\t\t\t\t\t\nSupramarginal gyrus\tL\t5.31\t\u221256\t\u221246\t10\t3.89\t\u221260\t\u221246\t22\t\t\t\t\t\t\t\t\t\nTemporal pole\tL\t4.71\t\u221244\t4\t\u221220\t4.43\t\u221244\t14\t\u221238\t\t\t\t\t\t\t\t\t\nTemporal pole\tR\t5.17\t58\t8\t\u221220\t4.7\t56\t10\t\u221230\t\t\t\t\t\t\t\t\t\n### Caption\nMontreal Neurological Institute (MNI) coordinates for brain activity associated with discriminative accuracy (d') for topics of conversation heard in the conversation-in-noise (CIN) condition.\n### Footer\nRegion labels refer to Harvard Oxford Atlas, thresholded at 50%.\n", "metadata": {"pmcid": 7194032, "text_md5": "02fdfcd52bf827411e141a4109bd246a", "field_positions": {"authors": [0, 153], "journal": [154, 170], "publication_year": [172, 176], "title": [187, 305], "keywords": [319, 395], "abstract": [408, 2593], "body": [2602, 44553], "tables": [44566, 59177]}, "batch": 2, "pmid": 32390890, "doi": "10.3389/fpsyt.2020.00343", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7194032", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=7194032"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7194032\">7194032</a>", "list_title": "PMC7194032  Social Attention in Autism: Neural Sensitivity to Speech Over Background Noise Predicts Encoding of Social Information"}
{"text": "Mooshagian, Eric and Kaplan, Jonas and Zaidel, Eran and Iacoboni, Marco\nPLoS One, 2008\n\n# Title\n\nFast Visuomotor Processing of Redundant Targets: The Role of the Right Temporo-Parietal Junction\n\n# Keywords\n\n\n\n# Abstract\n \nParallel processing of multiple sensory stimuli is critical for efficient, successful interaction with the environment. An experimental approach to studying parallel processing in sensorimotor integration is to examine reaction times to multiple copies of the same stimulus. Reaction times to bilateral copies of light flashes are faster than to single, unilateral light flashes. These faster responses may be due to \u2018statistical facilitation\u2019 between independent processing streams engaged by the two copies of the light flash. On some trials, however, reaction times are faster than predicted by statistical facilitation. This indicates that a neural \u2018coactivation\u2019 of the two processing streams must have occurred. Here we use fMRI to investigate the neural locus of this coactivation. Subjects responded manually to the detection of unilateral light flashes presented to the left or right visual hemifield, and to the detection of bilateral light flashes. We compared the bilateral trials where subjects' reaction times exceeded the limit predicted by statistical facilitation to bilateral trials that did not exceed the limit. Activity in the right temporo-parietal junction was higher in those bilateral trials that showed coactivation than in those that did not. These results suggest the neural coactivation observed in visuomotor integration occurs at a cognitive rather than sensory or motor stage of processing. \n \n\n# Body\n \n## Introduction \n  \nParallel processing of multiple sensory stimuli is critical for efficient, successful interaction with the environment. It allows for the simultaneous identification of multiple stimuli and thus swift action. An experimental approach to studying parallel processing in sensorimotor integration is to examine responses to multiple copies of the same stimulus. Reaction time tends to be faster to bilateral, redundant copies than to a single copy of a stimulus. Responding faster to redundant stimuli is known as the \u2018redundant targets effect\u2019  . The redundant target effect has been obtained with unimodal redundant visual   and auditory   stimuli as well as with bimodal audio-visual stimuli  , and it has been observed in both choice  , and simple detection tasks  . \n\nTwo alternative mechanisms have been proposed to account for the redundant target effect. \u201cStatistical facilitation\u201d posits that the observed facilitation in reaction time to redundant targets occurs because redundant targets activate multiple, independent, parallel processing channels. Each channel processes one of the redundant targets, and its speed varies from trial to trial as a stochastic process. Consequently, reaction time in a given trial reflects the processing time of whichever channel happened to be faster on that trial, causing the average reaction time to multiple redundant targets to be shorter than the average reaction time for any of the two channels alone. By analogy, statistical facilitation is sometimes described as a \u2018horse race\u2019, where the winner initiates the response  . This mechanism assumes that there is no interaction among the channels. \u201cCoactivation models\u201d, on the other hand, posit that engaging parallel channels results in a multiplicative activation, or interaction of channels, prior to response initiation  ,  . This pooled activation, thus, yields a faster initiation of the motor response. The original coactivation model was abstract and did not take into consideration the underlying neural architecture. Recently, however, coactivation has been typically interpreted as indicating neural summation  \u2013 . \n\nMiller   proposed a mathematical test (see  ) to differentiate between statistical facilitation and coactivation accounts of the redundant target effect. His equation establishes the maximum difference between reaction times to single versus redundant presentations for which statistical facilitation can adequately explain the redundant target effect. In practice, this limit is exceeded on some trials, evidence that some other mechanism must be responsible for response facilitation, at least in those trials. [See, for example, 2,3,15,16]. It is important to note that when this limit is exceeded, statistical facilitation is ruled out as an explanation of the redundant target effect. However, when the limit is not exceeded, coactivation cannot be ruled out. \n\nTheoretically, the functional locus of the redundant target effect may occur at a sensory, central (cognitive), or motor stage of processing. The empirical data are mixed. Many studies have ruled out that it occurs at either very early perceptual or late motor stages of processing. The redundant target effect is typically greater with bimodal stimuli (for example, visual-tactile) than with unimodal stimuli (for example, visual-visual)  . These instances provide evidence that the effect occurs after early sensory processing, when information from different modalities is integrated (Miller, 1982). On the other hand, two event-related potential studies reported an early locus of the redundant target effect  ,  . In both studies, earlier peak P1 latencies were observed for redundant visual stimuli compared to single visual stimulus trials. Another event-related potential study used redundant audio-visual stimuli and reported early audio-visual interactions consistent with sensory processing  . Likewise, Cavina-Pratesi et al.   addressed whether the redundant target effect occurs as late as a motor stage of processing, using a task where subjects had to withhold responses on trials with stop-signals. Redundant stop-signals were more effective than single stop-signals in inhibiting motor responses. Similarly, responses to redundant stimuli were more difficult to inhibit compared to single stimuli. The effects of redundant signals on motor responses in these two stop-signal experiments suggest that the redundant target effect occurs at a late, pre-motor, stage, prior to late ballistic motor output  . \n\nAs for the anatomical locus of the effect, reports have suggested that it occurs in either extrastriate or premotor regions, in line with information processing accounts of the effect. The event-related potential data suggest that the redundant target effect is detectable in the extrastriate cortex, but the poor spatial resolution of the event-related potential technique makes it difficult to precisely identify sources of influence  . A single-trial fMRI study, on the other hand, found increased blood oxygen-level dependent (BOLD) signal in the left and right dorsal premotor cortex and right intraparietal sulcus for redundant compared to single stimulus targets  . The premotor activations reported in that study support a later, motor, stage of processing. \n\nGiven the conflicting reports in the literature, the critical brain regions associated with parallel processing of stimuli remain a matter of investigation. Importantly, previous studies have only considered redundant versus single target conditions without distinguishing between performance explained by statistical facilitation and coactivation. Therefore an investigation of the neural locus of coactivation must look at these special trials separately. \n\nThe bilateral display used in this paradigm introduces an interhemispheric component to the task. Somewhat paradoxically, split brain and acallosal subjects often exhibit redundant target effects much larger than those in normal subjects which often exceed the boundary predicted by statistical facilitation  ,  ,  . These results suggest, counterintuitively, a greater degree of interhemispheric interaction in the absence of the corpus callosum and that, in the normal brain, the corpus callosum may serve to inhibit interhemispheric interaction  . Analysis of the functional connectivity of brain regions associated with the redundant target effect could prove useful in determining the role of interhemispheric connections in mediating it. Functional connectivity analyses allow us to examine the temporal cross-correlation of brain regions associated with activity in a seed region and are presumed to reflect structural connectivity between functionally related regions  . This analysis is complementary to task activation maps because it describes regions that follow the temporal sequence of information processing rather than the regions that engage simultaneously. \n\nIn the present study, we used event-related fMRI to investigate the BOLD signal associated specifically with those trials that exceed the limit for the statistical facilitation account of the redundant target effect. Thus, rather than considering the anatomical localization of fast responses to redundant targets in general, we examined the anatomical localization of the neural coactivation. We also used functional connectivity analyses to investigate interaction within and between the hemispheres during instances of coactivation. \n\n\n## Results \n  \n### Behavior \n  \nThere was a main effect of visual field F(2, 28)\u200a=\u200a22.012, p\u200a=\u200a.0001. As predicted, mean reaction time to bilateral trials was significantly faster (295.51\u00b17.42 msec) than mean RT to unilateral left stimuli (311.57\u00b16.79 msec), t(14)\u200a=\u200a5.34, p\u200a=\u200a.0001, or unilateral right stimuli (313.80\u00b17.61 msec), t(14)\u200a=\u200a6.08, p\u200a=\u200a.0001 ( ). The difference in reaction time for bilateral trials and the average of the unilateral trials was 17.18 msec. The Response Hand \u00d7 Visual Field interaction approached significance, F(2, 28)\u200a=\u200a2.678, p\u200a=\u200a.0862. \n   Mean reaction times to each stimulus type.  \nMean reaction time for unilateral left visual field (LVF), right visual field (RVF) and redundant bilateral visual field (BVF) trials. \n  \nThe fastest trials exceed the limit for statistical facilitation.   plots the cumulative distribution function for bilateral trials compared to the sum of unilateral left and unilateral right trials (statistical facilitation boundary). Only reaction time data from those runs in which more than 10% of the bilateral trials exceeded Miller's limit were included so as to match the image analysis (see Brain Imaging Results and Data Processing). \n   Performance exceeding the limit for statistical facilitation.  \nThe top panel shows the cumulative distribution function (CDF) of redundant trials in comparison with the limit for statistical facilitation. Miller's limit is exceeded wherever the redundant trial curve is to the left of the boundary. Redundant trials exceed the statistical facilitation boundary for the fastest reaction times. The bottom panel shows the differences between the CDF for bilateral trials and CDF for the race model inequality. \n  \n\n### Functional MRI \n  \nThe task produced widespread activations throughout the brain, including activations throughout the sensorimotor network. Significant signal changes were found in left and right premotor, supplementary, and primary motor areas as well as the superior parietal lobule, insula, cerebellum and visual cortex. \n\nContrasts of left visual field trials minus right visual field trials, and right visual field trials minus left visual field trials revealed activations in the contralateral visual cortices in line with the lateralized presentation of the stimuli. A contrast of bilateral trials to unilateral trials showed significantly greater signal changes in the visual cortex bilaterally ( ). Activations for each contrast are reported in  . \n   Signal changes for specific contrasts.  \nA Voxels showing significant signal changes in the task compared to rest. B Voxels showing significant signal changes in bilateral minus unilateral VF presentation. \n  \nThe comparison of bilateral trials that exceeded the limit to bilateral trials that did not exceed the limit revealed a single region in intersection of the posterior superior temporal gyrus and angular gyrus (right temporo-parietal junction) that showed a significantly higher BOLD signal for the coactivation trials compared to the non-coactivation trials ( ,  ). Average percent signal change for each trial type (coactivation, non-coactivation, left visual field, right visual field) in this region revealed a selective increase in BOLD signal for coactivation trials compared to all other trial types. Non-coactivation redundant trials actually revealed a small decrease in percent signal change in the right temporo-parietal junction region ( ). \n   Selective activation of the right temporo-parietal junction during coactivation.  \nA Average percent signal change in the region activated during coactivation compared to non-coactivation trials for each trial type. B Voxels showing significant signal changes during coactivation minus non-coactivation redundant trials. \n     MNI coordinates and peak activation statistics for four contrasts.           MNI coordinates and peak activation for coactivation minus non-coactivation contrast.        \nFunctional connectivity analysis using the activated right temporo-parietal junction region as a seed revealed a functionally related network that includes the left temporo-parietal junction, right inferior frontal gyrus, and right middle temporal gyrus ( ,  ). \n   Activity correlated with time-series of the right temporo-parietal region.  \nVoxels showing correlated activity with time-series of the right temporo-parietal region activated in coactivation minus non-coactivation trials as a seed region. \n     MNI coordinates and peak activations for functional connectivity analysis using timeseries of the right superior temporal gyrus as a seed region.        \n\n\n## Discussion \n  \nOur main objective in the present study was to shed light on the functional and neuroanatomical loci associated with coactivation of multiple channels of sensory processing. To the best of our knowledge, this is the first fMRI study to report BOLD activity specifically for bilateral, redundant targets on which performance exceeds the limit predicted by statistical facilitation. Performance that exceeds this limit can only be explained by coactivation. We reasoned that it could be profitable to focus on these trials as they provide clear instances of coactivation occurring. Thus, our imaging analyses focused on the BOLD activity of trials in which performance exceeded the limit predicted by statistical facilitation. \n\nUsing this novel approach, we observed selective increase in BOLD signal centered in the right angular gyrus (temporo-parietal junction) for coactivation compared to non-coactivation redundant target trials. Recall that these trials are visually identical yet on some trials, the speeds of responses are so fast that they exceed the upper limit of statistical facilitation. Our results fit well with the larger body of work on the redundant target effect which concluded that the functional locus of the redundant target effect is post-perceptual, but prior to ballistic motor output  ,  ,  . \n\nThe right temporo-parietal junction is an established sensorimotor region important for spatial attention. From an information processing point of view, the right temporo-parietal junction is situated in a central \u2018cognitive\u2019 stage of processing. Damage in the region is associated with visuospatial neglect  ,   and transcranial magnetic stimulation induces hemiextinction when applied over the right temporo-parietal junction  . In terms of functional anatomy, the right temporo-parietal junction has been implicated as part of a larger right-lateralized ventral fronto-parietal system that also includes the middle and inferior frontal gyri and is activated during detection of behaviorally relevant, salient, unattended stimuli  . Indeed, our functional connectivity analyses revealed activity in the homologous, albeit a more restricted temporo-parietal junction region in the left hemisphere as well as the right middle temporal gyrus, right middle frontal gyrus and right inferior frontal, largely consistent with the proposed network. \n\nThe question occurs whether there exist trials where coactivation occurs, but which do not exceed the limit for statistical facilitation.   suggests that the answer is \u201cno\u201d, at least in the right temporo-parietal junction. Non-coactivation trials do not activate this region at all (relative to rest). This indicates that the right temporo-parietal junction is active only during coactivation trials that exceed the limit for statistical facilitation. However, our data cannot exclude that coactivation may occur in other brain regions for trials not exceeding the limit of statistical facilitation. \n\nHow do identical stimuli result in such differences in reaction time? A schematic model of how this might occur is presented ( ). Under single target conditions, the reaction time is determined by the processing speed of a single activated channel ( ). However, in redundant bilateral targets conditions, one of two possible scenarios occurs. In the typical redundant targets case, a statistical facilitation occurs where the faster of two independent processing streams determines the speed of response, resulting in faster average reaction times compared to the single target conditions ( ). On some redundant trials, however, a reaction time advantage beyond that predicted by statistical facilitation occurs (coactivation). On these trials, the two parallel processing streams operate at just the right delay for coactivation ( ), as suggested by previous data on callosal patients  . This would be due to intrinsic properties of oscillatory systems, as cortical neural systems tend to be (see ref. 14 for a full explanation of the model.) The probability of such a delay is much greater in the split-brain than in the normal brain. \n   A schematic model of how reaction time differences under single target, non-coactivation, and coactivation instances, occur.  \nIn the single target condition A, the reaction time is determined by the speed of processing of the single stimulus. In the redundant target condition B, the reaction time is determined by a race between two independent and equal processing channels. The faster of the two channels determines the speed of the response. However, the delay between the two channels falls inside a window (indicated by the square brackets) for which no coactivation occurs. A longer arrow represents a faster channel. In the special redundant target case when Miller's limit is exceeded C, the two processing channels operate at just the right delay (see text for full explanation) resulting in a difference that exceeds the critical window and thus a coactivation at the right temporo-parietal junction (rTPJ). The coactivation of this region by the two processing channels results in threshold for firing being reached faster and consequently faster processing downstream of the right TPJ, ultimately resulting in reaction times that are faster than in either the single stimulus or redundant target conditions. The threshold for response execution is represented by the vertical dashed line. \n  \nSplit-brain patients often exhibit a redundant target effect that exceeds statistical facilitation  ,  ,  ,  . Reuter-Lorenz et al. (1995) proposed an \u2018and-or\u2019 model to explain the paradoxically enhanced redundant target effect in simple reaction time that exceeds statistical facilitation observed in split-brain patients. They posited that coactivation occurs at a response selection stage and acts as an \u2018and\u2019 gate that requires input from both hemispheres. Under this scheme, a redundant target effect is due to the release of a chronic inhibition on motor pathways under bilateral redundant stimuli conditions. This model was ruled out on empirical grounds  . Corballis et al.   offered an alternative account where the corpus callosum normally serves to inhibit interhemispheric signals, while in the split brain, interhemispheric inhibition is released. Thus, in the healthy brain, performance that exceeds the limit is rare and intermittent, presumably due to removal of inhibition during rare and limited fluctuations in interhemispheric inhibition. By contrast, in the split brain, this left hemisphere inhibition is constantly released because the corpus callosum is sectioned, resulting in the paradoxical \u2018hyper\u2019 redundant target effect. \n\nOur own data showing the right lateralized activation for reaction times that exceed the statistical facilitation limit and the right lateralized functional network observed here for bilateral trials indeed suggest a role for the corpus callosum in mediating the redundant target effect. The dynamic modulation of interhemispheric inhibition may account for why healthy subjects' performance is typically explained by statistical facilitation, while there are also infrequent, yet clear, instances of coactivation in the healthy brain. \n\nA few studies have investigated the redundant target effect in visuomotor integration of redundant stimuli using fMRI. However, even though these studies used the same general paradigm, they investigated different aspects of the visuomotor transformations required by the task. For instance, Iacoboni et al.   studied individual differences in the redundant target effect in patients with callosal agenesis. They interpreted their findings as suggesting different forms of cortico-subcortical interactions in callosal agenesis patients with and without performance that exceeds statistical facilitation. Iacoboni & Zaidel   used single-trial fMRI to look at the neural correlates of the redundant target effect in the healthy brain. Their results revealed increased BOLD signal for responses to bilaterally redundant stimuli compared to unilateral single stimuli in the precentral gyri bilaterally, left postcentral gyrus, and right intraparietal sulcus. Here, we investigated yet another aspect of the performance at this task, namely those instances of coactivation in the healthy brain. Different brain regions seem associated with these different aspects of the performance at the task, suggesting a fair amount of regional specialization for the visuomotor transformations that occur. \n\nTaken together, our data suggest that a right hemisphere ventrolateral network encompassing the temporo-parietal junction and the inferior frontal cortex is responsible for the transient, very rapid parallel processing of visuomotor information. It is unclear whether the transient nature of this rapid visuomotor processing is due to waxing and waning of activation in the right ventrolateral network or to fluctuating inhibition from the left hemisphere. \n\n\n## Materials and Methods \n  \n### Subjects \n  \nFifteen right-handed subjects (8 male, 7 female) were recruited and compensated for their participation. Subjects gave written informed consent according to the guidelines of the UCLA Institutional Review Board. The UCLA Institutional Review Board approved all aspects of the study. All participants were screened to rule out medication use, head trauma, and history of neurological or psychiatric disorders, substance abuse, or other serious medical conditions. \n\n\n### Behavioral Task \n  \nThe software program Presentation\u00ae ( ) was used to present stimuli and record latency data. Visual stimuli were presented through magnet-compatible goggles (Resonance Technology, Inc.). A central fixation cross was displayed during the entire experiment. On each trial, subjects saw a briefly presented white box against a black background. The stimuli subtended 1.0 degree of visual angle and were 5 centimeters from the fixation cross to the center of the stimulus. The stimulus was presented for 50 msec following a random interval between 250\u20131000 msec. A random interval was used to prevent anticipatory responses in the detection task. Stimuli were presented in either the left or the right visual field (\u2018unilateral\u2019 condition), or in both visual fields simultaneously (\u2018redundant\u2019 condition). For all trials, the subject's task was to respond as quickly and accurately as possible after detecting the light stimulus regardless of stimulus location by pressing a response button. \n\nSubjects completed 4 functional runs of 114 trials each, comprising equal numbers of left visual field, right visual field, and bilateral visual field stimulus presentations. The three trial types were intermixed in an order optimized to produce maximal signal discriminability and to ensure temporal jitter among the three categories using Optseq2 ( ). Subjects responded via a response box situated on their torso while in a supine position in the scanner. Responses were made with the left or right index finger, and response hand was counterbalanced across run. \n\n\n### Functional MRI Acquisition \n  \nBrain images were acquired using a Siemens Allegra 3.0 T MRI scanner. Two sets of high-resolution anatomical brain images were acquired for registration purposes. We acquired an MP-RAGE structural volume (TR\u200a=\u200a2300, TE\u200a=\u200a2.93, flip angle\u200a=\u200a8\u00b0) with 160 sagittal slices, each 1 mm thick with .5 mm gap and 1.33 mm\u00d71.33 mm in-plane resolution. We also acquired a T2-weighted co-planar volume (TR\u200a=\u200a5000, TE\u200a=\u200a33, flip angle\u200a=\u200a90\u00b0) with 36 transverse slices covering the whole brain, each 3 mm thick with 1 mm gap, a 128\u00d7128 matrix and an in-plane resolution of 1.5 mm\u00d71.5 mm. \n\nEach functional run involved the acquisition of 156 EPI volumes (gradient-echo, TR\u200a=\u200a2000, TE\u200a=\u200a25, flip angle\u200a=\u200a90\u00b0), each with 36 transverse slices, 3 mm thick, 1 mm gap, and a 64\u00d764 matrix yielding an in-plane resolution of 3 mm\u00d73 mm. A functional run lasted 5 minutes and 12 seconds, and each subject completed 4 functional runs. \n\n\n### Data Processing and Statistical Analysis \n  \n#### RT Analysis \n  \nResponse time data were submitted to repeated-measures ANOVA with Response Hand (left, right) and Visual Field (bilateral, left, right) as within-subject variables. The redundancy gain was computed by subtracting the median RT for bilateral trials from the median RT for unilateral trials. \n\nTo distinguish between statistical facilitation and coactivation we used the approach described by Miller  . The \u201c[horse] race model inequality\u201d (Equation 1) establishes the upper limit which statistical facilitation can reach: In equation 1, the limit for statistical facilitation can be determined by summing the rank ordered RTs (cumulative distribution functions, CDFs) for the two single stimulus conditions (left and right visual field). The left side of the equation indicates that the fastest responses to redundant stimuli are faster than the fastest single stimulus trials. When this occurs, statistical facilitation cannot adequately explain the redundant target effect and performance reflects the occurrence of coactivation. \n\nTo evaluate the inequality, we proceeded as follows. We rank-ordered RTs from fastest to slowest for each stimulus type by subject. We used the resulting cumulative distribution functions (CDFs) from each subject to compute the average CDF for each stimulus type. All the RTs from each subject were averaged at each point in the rank order for each stimulus type. We summed the CDFs for the unilateral left and right trials. The summed CDF for the unilateral trials was then compared to the CDF of the bilaterally presented trials. Probability models require that the CDF of for bilateral trials be everywhere to the right of the summed CDFs of the unilateral trials ( ). When the CDF for bilateral trials is to the left of the CDF for the unilateral trials, coactivation occurs. \n\n\n#### Functional MRI Analysis \n  \nAnalysis was carried out using FEAT (FMRI Expert Analysis Tool), part of FSL (FMRIB's Software Library,  ). After motion correction, images were temporally high-pass filtered with a cutoff period of 50 seconds and smoothed using an 8 mm Gaussian FHWM algorithm in 3 dimensions. \n\nWe modeled the BOLD response using a separate explanatory variable (EV) for each of the three stimulus types (left visual field, right visual field, and bilateral). For each stimulus type, the design was convolved with a gamma function to produce an expected BOLD response. The temporal derivative of this timecourse was also included in the model for each EV. Functional data were then fitted to the model using FSL's implementation of the general linear model. \n\nEach subject's statistical data were then warped into a standard space based on the MNI-152 atlas. We used FLIRT to register the functional data to the atlas space in three stages. First, functional images were aligned with the high-resolution co-planar T2-weighted image using a 6 degrees of freedom rigid-body warping procedure. Next, the co-planar volume was registered to the T1-weighted MP-RAGE using a 6 degrees of freedom rigid-body warp. Finally, the MP-RAGE was registered to the standard MNI atlas with a 12 degrees of freedom affine transformation. \n\nAfter analyzing the functional data for each subject, data were passed into a higher-level mixed effects analysis. Higher-level analysis was carried out using FLAME (FMRIB's Local Analysis of Mixed Effects)  . Z (Gaussianised T/F) statistic images were thresholded using clusters determined by Z>2.3, uncorrected. \n\nIn order to examine brain activity involved in coactivation, we ran another analysis that reclassified each bilateral trial as either a coactivation trial or as a non-coactivation trial. For each run, we compared the CDF for redundant (bilateral) trials to the CDF for unilateral trials. Any trials falling within the range of the CDF that exceeded the limit established for statistical facilitation were considered coactivation trials. In this analysis, there were four EVs at the subject level: right visual field trials, left visual field trials, coactivation, and non-coactivation trials. The analysis of coactivation trials included only those runs in which >10% of responses to bilateral trials exceeded the race model inequality. 25 of 60 total runs were excluded for not meeting these criteria. \n\nCoactivation trials are faster than non-coactivation trials by definition. To exclude the possibility that the physiological differences between coactivation and non-coactivation bilateral trials were due simply to random fluctuations in speed, we compared BOLD response on the fastest and slowest 20% of unilateral trials. The analysis of fast versus slow unilateral trials did not show any significant differences in BOLD activation, arguing against a simple speed account. \n\nFor the functional connectivity analysis, we created a \u201cseed\u201d ROI based on the right temporo-parietal region activated during coactivation trials from our group-level analysis. The seed mask was warped into each subject's native space and used to extract a timeseries by averaging across all voxels within the mask. We then carried out multiple regression analysis using the seed timeseries as a regressor to identify voxels that were correlated with the activity within the ROI. This produced subject-level maps of all active and deactivated voxels associated with the timeseries regressor. Group-level analyses were carried out using a mixed-effects model implemented in FSL and produced thresholded z-score maps of functional connectivity. \n\n\n\n \n\n# Table(s)\n## ID: pone-0002348-t001\n### Label: Table 1\nContrast\tAnatomical Region\tCoordinates\tCoordinates\tCoordinates\tMax Z Score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tX\tY\tZ\tUnnamed: 5_level_1\nTask - Rest\t\t\t\t\t\n\tRight postcentral gyrus\t48\t\u221218\t52\t4.77\n\tLeft postcentral gyrus\t\u221258\t\u221224\t40\t4.93\n\t\t\t\t\t5.0\n\tLeft precentral gyrus\t\u221252\t\u22126\t40\t4.67\n\tRight postcentral gyrus\t46\t\u221222\t64\t4.63\n\tLeft insula\t\u221242\t\u22128\t12\t5.02\n\tSMA\t0\t\u22128\t50\t4.8\n\tLeft mOcG\t\u221252\t\u221272\t0\t4.76\n\tRight mOcG\t52\t\u221272\t\u22126\t4.8\n\tRight Cerebellum\t24\t\u221260\t\u221224\t5.18\n\tLeft Cerebellum\t\u221220\t\u221254\t\u221222\t4.91\nLVF - RVF\t\t\t\t\t\n\tRight Lingual gyrus\t18\t\u221282\t\u221212\t3.97\nRVF \u2013 LVF\t\t\t\t\t\n\tLeft Fusiform gyrus\t\u221226\t\u221276\t\u221218\t5.21\nBi - Uni\t\t\t\t\t\n\tLeft mOcG\t\u221250\t\u221278\t\u22122\t4.2\n\tRight mOcG\t46\t\u221278\t0\t3.98\n\tRight Cuneus\t4\t\u221288\t4\t3.81\n\tLeft Fusiform\t\u221238\t\u221262\t16\t4.0\n\tRight Fusiform\t30\t\u221262\t\u221218\t3.65\n### Caption\nMNI coordinates and peak activation statistics for four contrasts.\n### Footer\nMFG\u200a=\u200amiddle frontal gyrus; IOcG\u200a=\u200ainferior occipital gyrus; OcG\u200a=\u200aoccipital gyrus; STG\u200a=\u200asuperior temporal gyrus.\n\n\n## ID: pone-0002348-t002\n### Label: Table 2\nContrast\tAnatomical Region\tCoordinates\tCoordinates\tCoordinates\tMax Z Score\tNo. Voxels\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tX\tY\tZ\tUnnamed: 5_level_1\tUnnamed: 6_level_1\nCoactivation \u2013 Non-coactivation\t\t\t\t\t\t\n\tRight AnG\t62.0\t\u221252\t18.0\t4.03\t75.0\n### Caption\nMNI coordinates and peak activation for coactivation minus non-coactivation contrast.\n### Footer\nAnG\u200a=\u200aangular gyrus\n\n\n## ID: pone-0002348-t003\n### Label: Table 3\nContrast\tAnatomical Region\tCoordinates\tCoordinates\tCoordinates\tMax Z Score\nUnnamed: 0_level_1\tUnnamed: 1_level_1\tX\tY\tZ\tUnnamed: 5_level_1\n\tRight AnG\t62\t\u221252\t18\t13.503\n\tMidline Parietal/Occipital junction\t\u22122\t\u221274\t34\t9.66\n\tLeft AnG\t\u221262\t\u221258\t20\t9.1\n\tRight MTG\t56\t\u221226\t\u221212\t9.33\n\tRight MFG\t48\t30\t28\t8.84\n\tRight IFG\t54\t12\t8\t8.79\n\tRight CG\t6\t34\t26\t8.7\n\tRight CG\t4\t\u221222\t40\t8.55\n\tRight cuneus\t14\t\u221272\t34\t8.48\n\tRight frontal pole\t26\t56\t18\t8.45\n\tRight temporal pole\t50\t18\t\u221212\t8.43\n\tRight SFG\t8\t54\t22\t8.29\n\tRight MFG\t40\t14\t54\t8.27\n\tRight precuneus\t6\t\u221254\t32\t8.25\n\tRight temporal pole\t44\t16\t\u221230\t8.1\n\tRight thalamus\t10\t\u221218\t\u22122\t8.1\n\tRight SFG\t4\t30\t46\t8.1\n\tRight ITG\t48\t\u221246\t\u221222\t8.01\n### Caption\nMNI coordinates and peak activations for functional connectivity analysis using timeseries of the right superior temporal gyrus as a seed region.\n### Footer\nAnG\u200a=\u200aangular gyrus; CG\u200a=\u200acingulate gyrus; IFG\u200a=\u200ainferior frontal gyrus; IFG\u200a=\u200ainferior frontal gyrus; ITG\u200a=\u200ainferior temporal gyrus; MFG\u200a=\u200amiddle frontal gyrus; MTG\u200a=\u200amiddle temporal gyrus; SFG\u200a=\u200asuperior frontal gyrus; OcG\u200a=\u200aOcciptial gyrus\n", "metadata": {"pmcid": 2390848, "text_md5": "04bdbecfd4d92e8b2d4a44c84676d080", "field_positions": {"authors": [0, 71], "journal": [72, 80], "publication_year": [82, 86], "title": [97, 193], "keywords": [207, 207], "abstract": [220, 1647], "body": [1656, 31350], "tables": [31363, 33891]}, "batch": 2, "pmid": 18523591, "doi": "10.1371/journal.pone.0002348", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2390848", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=2390848"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2390848\">2390848</a>", "list_title": "PMC2390848  Fast Visuomotor Processing of Redundant Targets: The Role of the Right Temporo-Parietal Junction"}
{"text": "Rothmayr, Christoph and Baumann, Oliver and Endestad, Tor and Rutschmann, Roland M and Magnussen, Svein and Greenlee, Mark W\nBehav Brain Funct, 2007\n\n# Title\n\nDissociation of neural correlates of verbal and non-verbal visual working memory with different delays\n\n# Keywords\n\n\n\n# Abstract\n \n## Background \n  \nDorsolateral prefrontal cortex (DLPFC), posterior parietal cortex, and regions in the occipital cortex have been identified as neural sites for visual working memory (  WM  ). The exact involvement of the DLPFC in verbal and non-verbal working memory processes, and how these processes depend on the time-span for retention, remains disputed. \n\n\n## Methods \n  \nWe used functional MRI to explore the neural correlates of the delayed discrimination of Gabor stimuli differing in orientation. Twelve subjects were instructed to code the relative orientation either verbally or non-verbally with memory delays of short (2 s) or long (8 s) duration. \n\n\n## Results \n  \nBlood-oxygen level dependent (BOLD) 3-Tesla fMRI revealed significantly more activity for the short verbal condition compared to the short non-verbal condition in bilateral superior temporal gyrus, insula and supramarginal gyrus. Activity in the long verbal condition was greater than in the long non-verbal condition in left language-associated areas (STG) and bilateral posterior parietal areas, including precuneus. Interestingly, right DLPFC and bilateral superior frontal gyrus was more active in the non-verbal long delay condition than in the long verbal condition. \n\n\n## Conclusion \n  \nThe results point to a dissociation between the cortical sites involved in verbal and non-verbal   WM   for long and short delays. Right DLPFC seems to be engaged in non-verbal   WM   tasks especially for long delays. Furthermore, the results indicate that even slightly different memory maintenance intervals engage largely differing networks and that this novel finding may explain differing results in previous verbal/non-verbal   WM   studies. \n\n \n\n# Body\n \n## Background \n  \n Working Memory   (  WM  ) is the ability to keep a limited amount of information online for immediate use during short intervals [ ]. In typical   WM   experiments 1 to 10 items are maintained in memory for periods up to and including 60 s [ ]. The classical model of   WM   consists of the   central executive   and three subsidiary systems, namely the   visuo-spatial sketchpad  , the   phonological loop  , and the recently proposed   episodic buffer   [ ]. \n\nA memory system related to the   visuo-spatial sketchpad   component of   WM   is   perceptual memory  , which has been described as a low-level memory process that is comprised of a series of independent parallel mechanisms for various basic stimulus dimensions. These attributes, such as spatial frequency, contrast, or orientation, are thought to be the building blocks of visual images [ ]. According to this theory, each attribute is stored with high precision in separate perceptual stores [ ]. These models of sensory-based WM emphasize the delay-related signals in sensory cortex and the reciprocal projections of these areas to parietal and prefrontal cortex [ ]. \n\nObjects in visual   WM   may be encoded with the help of verbal or non-verbal strategies. Numerous studies have investigated verbal and non-verbal WM [ - ]. The stimuli to test verbal and non-verbal WM differ significantly, ranging from single letters, numbers, dots, squares to complex objects and scenes [ - ]. The extent to which these stimuli can be coded verbally represents a major confound in these studies [ ], since the labels given by the observer to the material, and not their visual representations   per se  , will be stored. \n\nSeveral brain areas have been identified as the neural correlates of visual   WM   by means of lesion studies [ - ], PET [ , ], ERPs [ ], and fMRI [ , ]. Among these is posterior parietal cortex, which may reflect the neural capacity limit of visual   WM   [ ]. Recently, Xu and Chun [ ] have proposed that the inferior intraparietal sulcus (IPS), the superior IPS, and lateral occipital cortex (LOC) work in parallel to support visual   WM   encoding and maintenance. They suggest that representations in inferior IPS may be limited to a fixed number of objects, whereas capacity in LOC and superior IPS is limited by object complexity. LOC and superior IPS may thus participate in storing detailed representations of stimuli in visual   WM  . In addition, various striate and extra-striate areas of the occipital cortex have been identified as visual   WM   correlates [ ]. Interestingly, relatively early visual areas beyond V1, which have previously only been associated with visual perception, are also active during visual   WM   delays [ ]. Virtually all studies that investigated visual   WM   found activity in prefrontal cortex (PFC). The dorsolateral prefrontal cortex (DLPFC; BA 46/9) seems to play a crucial role in   WM  -related processes [ - ]. DLPFC activity has foremost been found in studies that required the manipulation of relevant items in memory [ , ]. Most of these studies have used   n  -back tasks in which the subject has to remember an item presented   n  -trials ago and match it to the present item. Delayed-discrimination tasks, on the other hand, show less DLPFC activity [ ]. During delayed-discrimination tasks an item has to be discriminated from the previously presented item. Thus, the mere maintenance of an item and not its manipulation is required. Several review articles point to a role for DLPFC in the active manipulation of material in visual WM [ - ]. However, other evidence suggests that DLPFC is involved in the storage of visual information for several objects [ ]. \n\nFurther studies have attempted to identify brain regions related to either verbal or non-verbal   WM  . Based on the identified neural networks a verbal/non-verbal dissociation has been suggested in either a ventral/dorsal or a left/right fashion [ , ]. Using a 2-back task, Ikeda and Osaka [ ] investigated memory for colours that could be coded either verbally or visually. Analysis of the results from the condition where colours could be coded verbally revealed activity in areas associated with the   phonological loop  , such as inferior frontal gyrus and inferior parietal lobule. The non-verbal coding of colours resulted in right inferior frontal gyrus activity, an area that has been associated with the   visuo-spatial sketchpad   of   WM  . These results stand in contrast to the results of the review article by Cabeza and Nyberg [ ] of more than 60 visual   WM   studies. These authors concluded that there is little evidence for a dissociation of verbal and non-verbal   WM   in the human cortex. This could be explained by the observation that most paradigms allow for the verbal encoding of visual material. Although Ikeda and Osaka [ ] revealed a possible dissociation between verbal and non-verbal   WM  -associated brain areas, their non-verbal stimuli may also have been coded verbally by the subjects. The words \"lighter\" or \"darker\" may have been used by the subjects for the intended non-verbal stimuli that all stemmed from one color category. Although their study revealed differing brain activity between verbal and non-verbal conditions this does not imply that this was due to their subjects' coding approaches. Mere differences in the visual appearance of the stimuli could also, at least in part, account for their results. \n\nThe effect of memory delay length on cortical activation has received less attention. In the visual   WM   studies reviewed above, inter-stimulus intervals (ISIs) in delayed discrimination paradigms varied from 350 ms [ ] to 24 s [ ]. Barch et al. [ ] reported on the impact of delay length on brain activation in visual   WM   tasks. In their verbal   WM   task the retention interval was either 1 or 8 s. The task used was a variant of the Continuous Performance Test [ ]. Subjects had to press a button whenever the letter X followed the letter A. The fMRI data revealed increased activation for the longer delay in inferior frontal gyrus, left posterior parietal lobe, and the left DLPFC. The previously mentioned conflicting results with respect to a dissociation of verbal/non-verbal   WM   may be, in part, due to the varying retention intervals used [ ]. Differences in task demands ranging from simple delayed-discrimination to demanding n-back tasks may also underlie the differences in brain activation. \n\nThe present study attempts to account for some of the inconsistencies in visual   WM   studies by systematically varying both delay length and coding strategies in the discrimination of simple grating stimuli. We used Gabor stimuli of differing orientation and instructed subjects to explicitly encode the relative orientations using a verbal code. The results from this condition were compared to those arising from a condition, where verbal coding could not be readily employed. We believe that we were able to create a paradigm in which non-verbal stimuli were virtually identical to the verbal stimuli but which could not be coded verbally as may have taken place in previous   WM   studies. Our findings suggest that the coding strategy used by the subjects has a profound effect on the pattern of brain activation exhibited during the delayed discrimination of similar stimuli. These differences are most pronounced for the long delay, where verbal stimuli seem to engage predominantly left-hemispheric temporo-parietal areas, whereas non-verbal memory is associated with medial and right-hemispheric frontal brain activity. \n\n\n## Materials and methods \n  \n### Subjects \n  \nTwelve right-handed adults (6 male, 6 female), aged between 20 and 40 years (mean= 25.4 yrs), participated in the study. All participants gave their written informed consent. All had normal or corrected-to-normal vision and reported no prior psychiatric or neurological impairments. \n\n\n### Task \n  \nIn the experiment the participants had to decide whether two Gabor stimuli, which were presented sequentially and separated by a delay period, had the same or a different orientation. The inter-stimulus interval (ISI) between the reference and the test stimulus was either 2 or 8 seconds. Gabor pairs were constructed so that they could be coded either verbally or non-verbally. Thus, the experiment consisted of four conditions (verbal/non-verbal x ISI 2 s/ISI 8 s). \n\nIn the verbal conditions stimuli were either oriented to the left (79\u00b0C) or to the right (101\u00b0C) of vertical, resulting in a difference in angle of 22\u00b0C. This was done so that subjects could verbally code these orientations with the words \"left\" and \"right\", as it had been suggested to them in the instruction. An example stimulus pair from the verbal conditions is depicted in Figure   for a \"different\" trial. In the two non-verbal conditions three reference Gabors were used that were oriented at either 34\u00b0C, 40\u00b0C, or 46\u00b0C, with respect to horizontal (0\u00b0C). Corresponding test stimuli had an orientation that was 22\u00b0C greater or lesser than that of the reference stimulus, or it had the same orientation. Gabors were constructed in this manner so that they could not be easily coded in a verbal manner (i.e., reference to the principal axes did not ease the task) but demanded perceptual coding. An exemplary non-verbal stimulus pair is shown in Figure   for a trial in which the reference and the test grating differed. \n  \nA. An example of a reference Gabor stimulus with its corresponding test stimulus for the verbal condition, in which the participants were instructed to memorize the orientation with a sub-vocal verbal rehearsal strategy (e.g. \"left\", \"right\" of vertical). The example depicts stimuli on a trial in which the test and the reference grating differed. B. An example of a stimulus pair for the nonverbal conditions, in which the instructions emphasized the use of visual encoding. Here the stimuli are taken from a trial in which the test and the reference stimulus differed. \n  \nIn 50% of all trials both the reference and the test stimulus had the same orientation, on the other trials the reference and test stimuli differed in orientation. Trials were presented in random order and subjects were instructed to maintain central fixation throughout the experiment. \n\nAt the beginning of each trial, a red or green bar appeared for 1000 ms in the centre of fixation. A red bar signified that a non-verbal stimulus pair was coming up, while a green bar stood for a verbally codable stimulus pair. The bar was either short or long. A short bar indicated an upcoming short ISI (2 s) and a long bar indicated a long ISI (8 s). Subjects were cued in this way on each trial to optimize their respective coding strategies. This cue was followed for 1200 ms by a black fixation point in the centre of the screen. Then the reference grating appeared for 200 ms in either the lower left or the upper right quadrant of the screen, with the fixation point still remaining in the centre of the screen. Gabors were presented in the periphery (see below). During the following ISI (either 2000 or 8000 ms), only the fixation point appeared on the screen. After this the test grating appeared in the same quadrant as the reference Gabor for 200 ms. Subjects then had to press a button with the index finger of their right hand if they thought that the test and the reference grating had the same orientation. Another button was pressed with the middle finger of the right hand if they thought that the two orientations differed. Participants had been instructed to respond as quickly and as accurately as possible. After the offset of the test Gabor, a fixation point appeared for either 8200 ms (for the 2s ISI) or for 2200 ms (for the 8s ISI). A schematic depiction of a trial for the short retention interval (ISI 2s, verbal), in which the reference and the test stimulus were the same, is depicted in Figure  . \n  \nSchematic depiction of a trial from the verbal ISI 2s condition in which the test and the reference stimulus differed. Trials started with a bar that informed subjects about delay length (short bar: 2 s, long bar: 8 s) and type of stimulus pair (green bar: verbal, red bar: non-verbal). After this a fixation point appeared that remained in the centre of the screen for the rest of the trial. This was followed by the reference Gabor that was shown in either the upper right or lower left quadrant of the screen (here a trial with stimuli in the lower left quadrant are presented). The delay interval was presented afterwards (2 or 8 s), followed by the test Gabor that appeared in the same quadrant as the previous reference Gabor. During the following interval, the subject had to judge if the test and the reference stimulus had the same or a different orientation and press the corresponding button. \n  \nPrior to the fMRI experiment subjects participated in a training session outside the scanner (n = 40 trials). In the fMRI experiment, each subject participated in one session that consisted of a total of 144 trials. At the end of the session, subjects were asked if and how often they had used verbal coding strategies in both the verbal and the non-verbal conditions. \n\n\n### Display and stimulus parameters \n  \nStimuli were created with Matlab 6.5.1 software (Math Works Inc., Natick, MA) and presented with Presentation 9.13 software (Neurobehavioral Systems Inc., Albany, CA). Stimuli were back-projected on a screen inside the scanner with a D-ILA LCD-projector (JVC Corp., Japan) with a frame refresh rate of 60 Hz. The screen size subtended 16.4\u00b0C \u00d7 21.7\u00b0C of visual angle. Gabor stimuli had a diameter of approximately 6.5\u00b0C of visual angle and were presented in the lower left quadrant or the upper right quadrant of the screen at a visual angle of 8.6\u00b0C from central fixation, measured from the centre of the Gabors. Gabor patches had a maximum contrast close to 100% and a spatial frequency of 3.4 c/deg. The contrast of the Gabors was tapered with a Gaussian kernel (Gauss constant: 1.3 deg). \n\nSubjects responded by pressing the buttons of a Lumitouch (Photon Control, Burnaby, Canada) optical response device with their index finger and the middle finger of their right hand. Reaction time (RT) and accuracy data were recorded and stored for offline analysis. \n\n\n### fMRI methods \n  \nBlood-oxygen-level-dependant imaging data were acquired with a 3-Tesla Siemens Allegra head scanner (Siemens Inc., Erlangen, Germany) at the University of Regensburg. The scanner acquired echo-planar-imaging (EPI) sequences using fast gradients. A standard one-channel head coil was used. During T2* image acquisition 34 slices (whole brain) were scanned in interleaved order. Time-to-repeat (TR) was 2000 ms. Time-to-echo (TE) was set at 30 ms, with a flip angle of 90\u00b0C. Voxel-size was set to 3 \u00d7 3 \u00d7 3 mm. The field of view measured 192 \u00d7 192 mm. Trials in the experimental paradigm were synchronized with scanner pulses. In every experimental session, 1088 scans were acquired. In order to obtain a better estimate of the actual hemodynamic response function (hrf) a jitter was implemented during the acquisition of functional images. Therefore on half of the trials in the experimental paradigm the trial onset was shifted by a fixed amount of time. A 1000 ms fixation period was added at the beginning and at the end of each respective trial, thus shifting events in the jittered trials by 1000 ms. Anatomical T1-weighted images were obtained using a MPRAGE pulse sequence (Magnetization Prepared RApid Gradient Echo) with time-to-repeat (TR) of 2300 ms, a time-to-echo (TE) of 3.93 ms, and a flip angle of 12\u00b0C. A total of 176 slices were scanned, with isotropic voxels sized 1 \u00d7 1 \u00d7 1 mm. The field of view had a size of 256 \u00d7 256 mm. \n\n\n### Data analysis \n  \nReaction time and accuracy data were analyzed statistically with SPSS for Windows 12.0 software (SPSS Inc., Chicago, IL). A repeated-measures ANOVA was conducted at a significance level of p \u2264 0.05. \n\nImages were pre-processed and statistically analyzed with SPM2 [ ] which runs in MatLab (Math Works Inc., Natick, MA). Prior to pre-processing all obtained imaging data in DICOM format were transformed to ANALYZE file format. Functional data were slice timed and realigned. A T2*-weighted mean image of the unsmoothed images was co-registered with the corresponding anatomical T1-weighted image of the same individual. The individual T1-image was used to derive the transformation parameters for the stereotaxic space using the SPM2 template (Montreal Neurological Institute (MNI) Template), which was then applied to the individual single co-registered EPI images. The voxel sizes of the written normalised images were 1 mm . Images were then smoothed with a 8-mm full-width half maximum (FWHM) isotropic Gaussian kernel. \n\nStatistical evaluation consisted of modeling the onset times of the test Gabor-stimuli as events on individual first level. These onsets were modeled separately for each of the 4 conditions if the correct response was given. Another two regressors for incorrect responses after an ISI of 2 or 8 seconds, respectively, were also included amounting to a total of 7 regressors (including constant) for each individual analysis. Interesting effects were contrasted using T-statistics, generating the relevant contrast images for second level evaluation. \n\nFor the random-effects group level statistics, T-value maps were calculated with appropriate contrast images. Activation vs. baseline maps were thresholded at p < .05 corrected on cluster level (cluster-defining threshold t = 4.0). Thresholds were adjusted for differential contrasts as we expected only small differences of effect sizes. Clusters surpassing an individual threshold of p < .05 corrected on cluster level (cluster-defining threshold t = 2.0) are reported as significant differential activations. To visualize the results, the activations were overlaid on a normalized rendered image from one of the subjects. \n\n\n\n## Results \n  \n### Behavioural results \n  \nThe computation of each individual's performance revealed that all participants were able to discriminate the relevant stimuli reasonably well. Mean accuracy (proportion of correct responses) for the four conditions was as follows: verbal, 2s ISI: 0.958 (standard error of the mean, SE = 0.013); verbal, 8s ISI: 0.949 (SE = 0.017); non-verbal, 2s ISI: 0.775 (SE = 0.024) and non-verbal, 8s ISI: 0.778 (SE = 0.022). A repeated-measures ANOVA with the factors type of stimulus (verbal/non-verbal) and ISI (2 s/8 s) revealed a significant effect of type of stimulus [F(1,11) = 55.27, p \u2264 0.01]. Accuracy was correspondingly higher for the verbal conditions. \n\nReaction times (RTs) were computed for correct trials only and were as follows: verbal, 2s ISI: 1012 ms (SE = 30 ms); verbal, 8s ISI: 1109 ms (SE = 31 ms); non-verbal, 2 s ISI: 1096 ms (SE = 35 ms); non-verbal, 8s ISI: 1168 ms (SE = 30 ms). An ANOVA revealed a significant main effect for the factor type of stimulus [F(1,11) = 8.27, p \u2264 0.05] and a highly significant main effect for the factor ISI [F(1,11) = 29.19, p \u2264 0.01]. Thus, RTs in the verbal conditions were significantly lower than in the non-verbal conditions. Also, RTs in the long retention (8 s) conditions were significantly longer when compared to the short retention (2 s) conditions, in agreement with earlier psychophysical results [ ]. The portion of correct responses and RTs for all four conditions (averaged over all participants) are depicted in Figure  . \n  \n A  . Mean reaction times are presented for the non-verbal and the verbal conditions. Reaction times in the non-verbal trials were significantly higher than in the verbal conditions [F(1,11) = 8.27, p \u2264 0.05]. There was a significant increase in the reaction time for the 8s ISI when compared to the 2s ISI [F(1,11) = 29.19, p \u2264 0.01].   B  . Performance (portion correct responses) in the verbal and the non-verbal 2 and 8s ISI conditions. Accuracy in the verbal conditions was higher than in the non-verbal conditions [F(1,11) = 55.27, p \u2264 0.01]. \n  \nThe examination of the responses given by the subjects after having been asked about their coding strategies revealed that the overwhelming majority of them used verbal coding for all verbal trials (92% of subjects) and refrained from doing so in the non-verbal trials (75% claimed to have used verbal coding at no time or only seldom). The few subjects who had attempted to use verbal coding for non-verbal trials reported to have used the words \"tilted\"/\"more tilted\". These subjects also claimed to have aborted the strategy soon after the onset of the experiment because they had felt that it was not successful. The different results for verbal versus non-verbal trials may therefore be regarded as a consequence of the participants' coding strategies. All participants claimed to have used the words \"left\" and \"right\" of vertical for the verbal coding trials in covert speech. \n\n\n### Functional imaging results \n  \nResults from the contrasts against baseline are displayed in Table  . The hemisphere, anatomical region, corresponding Brodmann area number, the MNI location, as well as the magnitude and size of the activated cluster are given for each of the four conditions. The patterns of activation indicate that the brain activity resulting from the verbal and non-verbal conditions are widely spread across prefrontal, cingulate, parietal, temporal and occipital regions in both hemispheres. \n  \nBrain areas showing significant activation. Contrasts: verbal 2s ISI > baseline, verbal 8s ISI > baseline, non-verbal 2s ISI > baseline, and non-verbal 8s ISI > baseline. The Montreal Neurological Institute (MNI) coordinates of the most active voxel is given for each cluster, along with the z-value of the magnitude of activation and the number of voxels contained within the cluster (in parentheses). Abbreviations for each brain structure assigned using the SPM2 extension MSU: MFG = middle frontal gyrus; IFG = inferior frontal gyrus; IPL = inferior parietal lobule; STG = superior temporal gyrus; SFG = superior frontal gyrus; MTG = middle temporal gyrus \n  \nFor our purposes, we focus on the comparison of activation across the different experimental conditions. The results for these differential contrasts (condition A > condition B) are displayed in Table  . No significant activity was found for the contrast in which the activity arising in the non-verbal ISI 2s > verbal ISI 2s condition was compared. This lack of difference could be related to the temporal overlap of the BOLD response to the perceptual encoding and retrieval events in the non-verbal condition. \n  \nBrain areas showing significant activation. Contrasts: verbal 2s ISI > non-verbal 2s ISI, verbal 8s ISI > non-verbal 8s ISI, and non-verbal 8s ISI > verbal 8s ISI, otherwise as in Table 1. No activity was detected in the contrast non-verbal 2s ISI > verbal 2s ISI. For abbreviations see Table 1 \n  \nActivity in the contrast verbal 2s ISI > non-verbal 2s ISI was detected in bilateral insula, superior temporal gyrus, and the right inferior parietal lobule. Significantly more BOLD-dependent activity was found in left SMG, posterior cingulate, right cingulate gyrus, and the right precentral lobule for this contrast. The contrast verbal 8s ISI > non-verbal 8s ISI revealed activity in the cuneus, posterior cingulate, middle temporal gyrus, superior temporal gyrus, and the inferior parietal lobule of the left hemisphere, as well as in the bilateral precuneus. The contrast non-verbal 8s ISI > verbal 8s ISI resulted in activity in bilateral superior frontal gyrus, left medial frontal gyrus, right inferior frontal gyrus, and right middle frontal gyrus. This differential activity, representing the mean differential contrasts for all participants, is depicted on a structural brain image of one of the subjects in Figure  . \n  \nResults from the random-effects group-analysis.   A. B  rain areas showing significant activation in the contrast verbal 2s ISI > non-verbal 2s (blue shading). No significant activity was found for the contrast non-verbal ISI 2s > verbal ISI 2s.   B  . Significant activation in the conditions verbal 8s ISI > non-verbal (blue shading), and non-verbal 8s ISI > verbal 8s ISI (red shading). \n  \n\n\n## Discussion \n  \nThis study investigated differences in cortical BOLD activity for a verbal and non-verbal delayed-discrimination   WM   paradigm for short and long retention intervals. The paradigm used here, a delayed orientation discrimination task, focused on the maintenance of visual memory representations without any manipulation process. In the verbal encoding condition, Gabor patches were oriented slightly to the left or to the right of vertical so that subjects could covertly use the terms \"left\" and \"right\" as verbal cues. The \"non-verbal stimuli\" were oriented to the left only and could not be readily related to the vertical or horizontal axes. Gabors were constructed in this manner so that they could not be easily coded in a verbal manner (i.e., reference to the principal axes did not ease the task) but demanded perceptual coding. Differences in orientation angle between the reference and test gratings, however, were the same for both encoding conditions. We believe that subjects coded verbal and non-verbal stimulus pairs with a verbal coding strategy in one case and refrained from doing so in the latter instance. Firstly, subjects were explicitly told in the instruction to code verbal stimuli with the words \"left\" and \"right\". \n\nSecondly, non-verbal stimuli were constructed in a fashion that would not lend themselves to verbal coding. Gratings in these conditions differed by 22\u00b0C (for \"different\" trials) and were all oriented to the left. \n\nOrientations were selected that were not near prominent positions of an analogue clock face and stimuli were presented for 200 ms only. Verbal stimuli were oriented to the left or to the right of the vertical plane, thus inevitably yielding the verbal codes \"left\" and \"right\". Although usually considered an unreliable measure of experimental control, subject debriefings conducted in our experiment confirmed that subjects had used verbal coding in the verbal condition, and refrained from doing so in the nonverbal condition, as intended. \n\nWe believe that the stimuli used in this study represent a novel approach in the investigation of verbal and non-verbal   WM  . Due to the virtually identical visual appearance of the verbal and the non-verbal stimuli, differences in brain activity in this experiment can be attributed entirely to the coding strategies applied by the subjects. Indeed, the trial-by-trial cues instructed the subjects to apply the appropriate strategies to the individual trial types. This manipulation may not have been properly achieved in previous studies. \n\nThe systematic variation of delay length, as conducted here, presents a novelty in verbal/non-verbal   WM   research and may explain differing results as well. \n\nThe behavioural data revealed slower reaction times and lower accuracies for the non-verbal conditions as opposed to the verbal conditions, suggesting the use of different neural mechanisms. \n\nNon-verbal   WM   is typically associated with the engagement of the visuospatial sketchpad component of   WM  , whereas verbal   WM   additionally engages the phonological loop component. It has frequently been reported in previous studies that verbal coding, as opposed to non-verbal   WM  , enhances   WM   performance, a finding that is reflected in this study's behavioural results. \n\nAccuracies and reaction times differed between the verbal and non-verbal conditions (Fig.  ). It could be argued that we should have adapted the stimulus differences in angle between stimulus pairs or presentation time to yield equivalent performance for the two trial types. By doing this, however, differences in brain activity could not have been attributed to underlying coding strategies used by the subjects but would have to be explained in terms of differing visual stimulus properties. Such a procedure (i.e., different stimuli for verbal and nonverbal trial types), which was knowingly avoided in this study, may have constituted a major confound in previous studies. We believe that, although accuracies differed between verbal and non-verbal trials, the results may be interpreted as a result subjects' coding strategies and not to differing stimulus properties, a major problem in previous   WM   studies. \n\nThe functional imaging results presented here reflect maintenance processes dependent on both delay period and coding strategy applied. Since a simple delayed-discrimination   WM   paradigm was used here, it does not reflect manipulation processes that are usually captured in n-back tasks and that are thus hard to disentangle from maintenance processes [ - ]. \n\nThe random-effects group analysis (Table  ), in which all four conditions were contrasted with baseline activation levels, revealed activity in prefrontal, posterior parietal cortex and further areas that have previously been associated with   WM  . The main focus of this study, however, was on the dissociation between verbal and non-verbal   WM   at different delay lengths. Therefore we will not discuss these results in detail, but rather focus on the direct comparisons of verbal and non-verbal conditions. The differential analysis between the verbal and non-verbal conditions revealed differing activity for the comparisons between the conditions with the same delay duration. In the short retention interval, significantly more activity was detected in bilateral areas close to well-known language areas, such as the supramarginal gyrus, superior temporal gyrus, and inferior frontal gyrus, with preponderance in the left hemisphere. No additional activity was found when contrasting the short non-verbal to the short verbal condition. In the long interval, however, the non-verbal condition showed more activity in right DLPFC and medial frontal areas than the verbal condition. In the verbal long-retention condition more activity could be measured in left language associated areas (such as supramarginal gyrus, superior temporal gyrus, as well as in medial parietal areas) when compared to that found in the long non-verbal condition. \n\nThese results suggest an interaction in visual   WM   between the effects of memory delay length and modality of encoding. The right DLPFC is significantly more active in the non-verbal condition with the long retention interval when compared to the verbal condition of same retention interval (Fig.  ). In contrast, in the long delay conditions, parietal, temporal, and frontal areas in the immediate proximity of language areas of the left hemisphere, as well as medial parietal areas, especially precuneus, were more active in the verbal than in the non-verbal condition. The neural basis for the   phonological loop   component of   WM   has been localized in left supramarginal gyrus, Broca's area, inferior frontal gyrus, and the superior parietal lobule [ , ]. Our study revealed relatively more activity in these same areas for the verbal coding condition and may thus indicate the engagement of the   phonological loop   for these conditions. On the other hand, the precuneus is a structure that has frequently been reported in connection with different forms of higher-order cognition including episodic memory retrieval [ ]. The exact role of the precuneus in the contrast between the verbal versus the nonverbal conditions with long retention interval requires further investigation. \n\nThe short verbal condition showed more brain activity bilaterally around the Sylvian fissure, such as the supramarginal gyrus, which have previously been associated with the   phonological loop   component of   WM   [ , ]. Activity in the supramarginal gyrus has also been related to articulatory rehearsal [ ]. For short retention intervals, we were not able to detect any areas that were more active in the non-verbal when compared to the verbal condition (Fig.  ). \n\nThis finding suggests that non-verbal   WM   for shorter delay periods depends on different maintenance mechanisms than non-verbal   WM   for longer delay periods. Our study suggests that especially right DLPFC seems to play a crucial role in the maintenance of stimuli in non-verbal   WM  . Since our experiment required the mere maintenance of items without any manipulation process, the results also suggest that DLPFC plays not only a role in manipulation processes [ - ], but also in   WM   maintenance [ ]. The differential activity between the verbal and nonverbal conditions (Fig.  ) supports the idea of a dissociation between the left and right hemispheres for verbal and non-verbal   WM  , respectively. Our results are in line with the findings that point to a dominance of the right hemisphere for non-verbal material [ ], and these hemispheric differences appear even more pronounced for long retention intervals. One possible reason for the controversy regarding a possible hemispheric specialization for verbal and nonverbal WM might be related to the different retention intervals used in different studies. In a study of Barch et al. [ ], the left DLPFC was active for verbal WM only for long delay periods (8 s) as opposed to a short (1 s) retention interval. \n\n\n## Conclusion \n  \nIn conclusion, the present study explored the neural correlates of verbal and non-verbal visual   WM   at different delay lengths. Our findings point to a dissociation between verbal and nonverbal WM processing, with a prominent activation of the left hemisphere in verbal coding and a right prefrontal activation associated with non-verbal coding. A recent study by Ikeda and Osaka [ ] explored hemispheric differences in inferior frontal and posterior parietal cortex in the verbal and nonverbal encoding of colour stimuli. Together with our findings, these results point to a dissociation of left and right hemispheric processing for verbal and nonverbal working memory for visual stimuli. Furthermore, our findings give rise to the assumption that even slight differences in memory delay length have a significant effect on associated neural networks. \n\n\n## Competing interests \n  \nThe author(s) declare that they have no competing interests. \n\n\n## Authors' contributions \n  \nCR, OB and MWG designed the experiment. CR programmed the paradigm. CR and OB collected experimental data. CR, OB and RMM analyzed behavioural and fMRI data. CR, OB and RMM designed and prepared illustrations. CR, OB, TE, SM and MWG wrote the article. \n\n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nUnnamed: 0\tUnnamed: 1\tUnnamed: 2\tMNI coordinates\tMNI coordinates.1\tMNI coordinates.2\tUnnamed: 6\nHemisphere & Region\tBrodmann Area\tHemisphere\tx\ty\tz\tZ-values of maxima (cluster size in number of voxels)\n\t\t\t\t\t\t\nVerbal 2s ISI > baseline\tVerbal 2s ISI > baseline\tVerbal 2s ISI > baseline\tVerbal 2s ISI > baseline\tVerbal 2s ISI > baseline\tVerbal 2s ISI > baseline\tVerbal 2s ISI > baseline\n\t\t\t\t\t\t\ncingulate gyrus, IPL, MFG, postcentral gyrus, precentral gyrus\t4/6/24/44\tL\t-2\t8\t52\t5.92 (13387)\ncerebellum\t\tL/R\t8\t-54\t-10\t5.61 (2642)\ncuneus, posterior cingulate, precuneus\t30/31\tL/R\t24\t-44\t0\t5.18 (1464)\nIPL, postcentral gyrus, precuneus\t2/7/40\tR\t20\t-64\t46\t5.15 (1883)\nInsula, MFG\t6/13/44\tR\t30\t50\t30\t4.82 (1626)\n\t\t\t\t\t\t\nVerbal 8s ISI > baseline\tVerbal 8s ISI > baseline\tVerbal 8s ISI > baseline\tVerbal 8s ISI > baseline\tVerbal 8s ISI > baseline\tVerbal 8s ISI > baseline\tVerbal 8s ISI > baseline\n\t\t\t\t\t\t\ncingulate gyrus, insula, precentral gyrus\t4/6/24/44\tL/R\t6\t-26\t0\t5.88 (22831)\nMFG\t6\tR\t30\t-8\t60\t4.79 (184)\npostcentral gyrus, precentral gyrus\t9/10\tR\t32\t58\t22\t4.59 (248)\nMFG, SFG\t9/10\tL\t-42\t26\t30\t4.57 (371)\nMTG, STG\t39\tR\t50\t-58\t6\t4.15 (113)\nMFG\t6\tR\t36\t-2\t38\t4.13 (275)\nMFG, SFG\t9/10\tR\t32\t58\t22\t3.92 (272)\n\t\t\t\t\t\t\nNon-verbal 2s ISI > baseline\tNon-verbal 2s ISI > baseline\tNon-verbal 2s ISI > baseline\tNon-verbal 2s ISI > baseline\tNon-verbal 2s ISI > baseline\tNon-verbal 2s ISI > baseline\tNon-verbal 2s ISI > baseline\n\t\t\t\t\t\t\ncerebellum\t\tL/R\t8\t-60\t-10\t5.56 (2308)\nIPL, postcentral gyrus\t2/3/4/40\tL\t-38\t-40\t52\t4.75 (1777)\nIPL\t2/40\tR\t38\t-56\t52\t4.58 (1353)\nIFG, insula\t13/44\tL\t-48\t8\t16\t4.58 (839)\ncingulate gyrus, MFG\t8/24/32\tL/R\t4\t16\t52\t4.41 (795)\nIFG, insula\t13/47\tR\t40\t16\t2\t4.35 (181)\ncingulate gyrus\t23\tL/R\t8\t-32\t32\t4.32 (149)\n\t\t\t\t\t\t\nNon-verbal 8s ISI > baseline\tNon-verbal 8s ISI > baseline\tNon-verbal 8s ISI > baseline\tNon-verbal 8s ISI > baseline\tNon-verbal 8s ISI > baseline\tNon-verbal 8s ISI > baseline\tNon-verbal 8s ISI > baseline\n\t\t\t\t\t\t\nIFG, insula, thalamus\t9/13/41/44\tL\t-6\t-18\t4\t5.85 (5935)\nIFG, insula, IPL, MFG, precentral gyrus\t13/23/30/40\tR\t40\t16\t0\t5.84 (11186)\ncingulate gyrus medial, frontal gyrus\t23/24/33\tL/R\t4\t18\t48\t5.82 (8829)\ncuneus, precuneus\t19\tL\t-30\t-80\t34\t4.60 (339)\n### Caption\nBrain areas showing significant activation. Contrasts: verbal 2s ISI > baseline, verbal 8s ISI > baseline, non-verbal 2s ISI > baseline, and non-verbal 8s ISI > baseline. The Montreal Neurological Institute (MNI) coordinates of the most active voxel is given for each cluster, along with the z-value of the magnitude of activation and the number of voxels contained within the cluster (in parentheses). Abbreviations for each brain structure assigned using the SPM2 extension MSU: MFG = middle frontal gyrus; IFG = inferior frontal gyrus; IPL = inferior parietal lobule; STG = superior temporal gyrus; SFG = superior frontal gyrus; MTG = middle temporal gyrus\n### Footer\nNone\n\n\n## ID: T2\n### Label: Table 2\nUnnamed: 0\tUnnamed: 1\tUnnamed: 2\tMNI coordinates\tMNI coordinates.1\tMNI coordinates.2\tUnnamed: 6\nHemisphere & Region\tBrodmann Area\tHemisphere\tx\ty\tz\tZ-values of maxima (cluster size in number of voxels)\n\t\t\t\t\t\t\nVerbal 2s ISI > non-verbal 2s ISI\tVerbal 2s ISI > non-verbal 2s ISI\tVerbal 2s ISI > non-verbal 2s ISI\tVerbal 2s ISI > non-verbal 2s ISI\tVerbal 2s ISI > non-verbal 2s ISI\tVerbal 2s ISI > non-verbal 2s ISI\tVerbal 2s ISI > non-verbal 2s ISI\n\t\t\t\t\t\t\ninsula, IPL, STG\t13/41/42/43/44\tR\t52\t-32\t14\t4.90 (2641)\ninsula, STG, supramarginal gyrus\t13/40/41/42\tL\t-12\t-12\t20\t3.91 (7176)\ncingulate gyrus, posterior cingulate, precentral lobule\t5/24/30/31\tL/R\t20\t-48\t-4\t3.88 (6931)\n\t\t\t\t\t\t\nVerbal 8s ISI > non-verbal 8s ISI\tVerbal 8s ISI > non-verbal 8s ISI\tVerbal 8s ISI > non-verbal 8s ISI\tVerbal 8s ISI > non-verbal 8s ISI\tVerbal 8s ISI > non-verbal 8s ISI\tVerbal 8s ISI > non-verbal 8s ISI\tVerbal 8s ISI > non-verbal 8s ISI\n\t\t\t\t\t\t\ncuneus, posterior cingulate, precuneus\t7/23/30/31\tL/R\t8\t-60\t52\t4.38 (3948)\nIPL, MTG, STG, supramarginal gyrus\t39/40/41/44\tL\t-62\t-40\t28\t4.29 (2327)\n\t\t\t\t\t\t\nNon-verbal 8s ISI > verbal 8s ISI\tNon-verbal 8s ISI > verbal 8s ISI\tNon-verbal 8s ISI > verbal 8s ISI\tNon-verbal 8s ISI > verbal 8s ISI\tNon-verbal 8s ISI > verbal 8s ISI\tNon-verbal 8s ISI > verbal 8s ISI\tNon-verbal 8s ISI > verbal 8s ISI\n\t\t\t\t\t\t\nmedial frontal gyrus, SFG\t32/9/8\tL/R\t8\t22\t50\t4.70 (2934)\nIFG, MFG\t8/9/46\tR\t54\t8\t24\t3.24 (1004)\n### Caption\nBrain areas showing significant activation. Contrasts: verbal 2s ISI > non-verbal 2s ISI, verbal 8s ISI > non-verbal 8s ISI, and non-verbal 8s ISI > verbal 8s ISI, otherwise as in Table 1. No activity was detected in the contrast non-verbal 2s ISI > verbal 2s ISI. For abbreviations see Table 1\n### Footer\nNone\n", "metadata": {"pmcid": 2151069, "text_md5": "87bc62d7ebbfb69390afd3648df69d20", "field_positions": {"authors": [0, 124], "journal": [125, 142], "publication_year": [144, 148], "title": [159, 261], "keywords": [275, 275], "abstract": [288, 2016], "body": [2025, 36737], "tables": [36750, 41415]}, "batch": 2, "pmid": 17958919, "doi": "10.1186/1744-9081-3-56", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2151069", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=2151069"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2151069\">2151069</a>", "list_title": "PMC2151069  Dissociation of neural correlates of verbal and non-verbal visual working memory with different delays"}
{"text": "Zhou, Zhiheng and Whitney, Carol and Strother, Lars\nPLoS One, 2019\n\n# Title\n\nEmbedded word priming elicits enhanced fMRI responses in the visual word form area\n\n# Keywords\n\n\n\n# Abstract\n \nLexical embedding is common in all languages and elicits mutual orthographic interference between an embedded word and its carrier. The neural basis of such interference remains unknown. We employed a novel fMRI prime-target embedded word paradigm to test for involvement of a visual word form area (VWFA) in left ventral occipitotemporal cortex in co-activation of embedded words and their carriers. Based on the results of related fMRI studies we predicted either enhancement or suppression of fMRI responses to embedded words initially viewed as primes, and repeated in the context of target carrier words. Our results clearly showed enhancement of fMRI responses in the VWFA to embedded-carrier word pairs as compared to unrelated prime-target pairs. In contrast to non-visual language-related areas (e.g., left inferior frontal gyrus), enhanced fMRI responses did not occur in the VWFA when embedded-carrier word pairs were restricted to the left visual hemifield. Our finding of fMRI enhancement in the VWFA is novel evidence of its involvement in representational rivalry between orthographically similar words, and the co-activation of embedded words and their carriers. \n \n\n# Body\n \n## Introduction \n  \nHuman ventral occipital temporal cortex (vOT) is frequently implicated in visual object recognition and reading. A \u201cvisual word form area\u201d (VWFA; [ ,  ]) in left vOT exhibits differentiable fMRI responses to words as compared to pseudowords and non-linguistic control stimuli [ \u2013 ]. The VWFA is highly sensitive to orthographic structure [ ,  \u2013 ]. This sensitivity is presumably the result of extensive experience [ ,  ,  ], and it is consistent with the possibility that the VWFA serves as an interface between orthography-sensitive visual representations and those in non-visual language centers of the human brain. \n\nThe purpose of the current study was to measure the sensitivity of the VWFA and other regions of the brain to lexical embedding using fMRI. Lexical embedding is common in English [ ]. Unlike other words, embedded words elicit a unique type of representational rivalry in which an embedded word and its carrier compete for both orthographic and semantic representation within the word recognition circuit (e.g., \u2018CAR\u2019 in \u2018CART\u2019). Embedded-carrier rivalry is the result of mutual interference at different levels of form-to-meaning representation during cascaded orthographic and semantic processing, which begins at the level of orthography [ ,  ]. By virtue of their inherent orthographic similarity, embedded words and their carriers co-activate and therefore compete for representation via mutual inhibition [ ]. Traditionally, orthographic neighbors refer to similar words with one letter substitution. However, previous studies have shown that the embedded word and its carrier are also orthographic neighbors by letter deletion and addition, respectively, and exhibit orthographic similarity interference effects [ \u2013 ]. The neural basis of representational rivalry during embedded word viewing is currently unknown. Given its sensitivity to orthography, we predicted the VWFA as a highly plausible candidate, in addition to other brain regions involved in cascaded orthographic-semantic mapping. We tested our prediction using a novel embedded prime-target word pair paradigm, in two fMRI experiments. In the scanner, observers viewed three-letter primes (the embedded word) followed by four-letter targets (the carrier word) which either contained the prime (\u2018CAR\u2019 \u2192 \u2018CART\u2019 or \u2018CAR\u2019 \u2192 \u2018SCAR\u2019), or shared no letters (\u2018CAR\u2019 \u2192 \u2018STEM\u2019). \n\nWe hypothesized three possible outcomes of our fMRI experiments: repetition   enhancement   [ \u2013 ], repetition   suppression   [ ,  \u2013 ], or both. Findings of mutual interference between the embedded words and their carriers in behavioral priming studies indicate a co-activation of the embedded words and their carriers [ ,  ]. Such co-activation supports the possibility of repetition enhancement of fMRI responses, which are typically consistent with interference effects underlying negative priming [ \u2013 ]. The observation of fMRI repetition enhancement in the VWFA would be the first of its kind. A potentially related finding was recently reported in left vOT (in a location consistent with the VWFA) for syllabic negative priming [ ]. On the other hand, fMRI repetition suppression has been proposed to reflect a facilitation effect due to repetition priming. Specifically, the VWFA showed repetition suppression for repeated whole words (\u2018CART\u2019 \u2192 \u2018CART\u2019) but not for repeated sublexical orthographic structure (\u2018CART\u2019 \u2192 \u2018CAST\u2019), in an fMRI priming study [ ]. Because embedded words followed by their carriers (e.g., \u2018CAR\u2019 \u2192 \u2018CART\u2019) share letters that form the embedded word, this could result in repetition suppression in the VWFA for these kinds of word pairs. This possibility is consistent the results of the Glezer et al. study [ ], in which equivalent release from suppression occurred for one letter substitution (\u2018CART\u2019 \u2192 \u2018CAST\u2019) and whole word change (\u2018CART\u2019 \u2192 \u2018STEM\u2019), neither of which involve lexical repetition, despite sub-lexical repetition in the first case (i.e., three of the four letters are repeated between the word pairs). Additionally, the suppression prediction is also supported by the results of Devlin et al. [ ], which demonstrated repetition suppression in left vOT (in a location consistent with the VWFA) underlying orthographic priming during the viewing of orthographically similar words with lexical embedding under conditions of letter subtraction (e.g., \u2018passive\u2019 \u2192 \u2018PASS\u2019). Taken together with the results of the study by Glezer et al., it is reasonable to predict suppressed fMRI responses to embedded word repetition in our study, despite differences in letter addition as opposed to substitution (Glezer et al.,) and subtraction (Devlin et al.). \n\nIt should be noted that fMRI repetition enhancement and suppression are not mutually exclusive, and could plausibly co-occur and cancel out. For instance, it is possible that for embedded word pairs, both enhancement and suppression co-occur in the same orthography-sensitive brain region (e.g., the VWFA), either simultaneously or at different latencies. In either case, canceling out could occur, because although the latency of repetition suppression voxels is typically faster than the latency of repetition enhancement voxels (~3 s); due to poor temporal resolution of fMRI and the limitation of the current study, it would be impossible to detect such a difference [ ]. Additionally, or alternatively, concurrent enhancement and suppression for the embedded words could co-occur in different brain regions based on sensitivity to visual versus language-related characteristics of stimuli (e.g., [ ]). \n\nWhile left vOT was of primary interest, the VWFA in particular, we also anticipated the involvement of left inferior frontal gyrus (IFG) given its involvement in both orthographic and semantic processing underlying word recognition. For example, using an fMRI repetition suppression paradigm similar to that adopted here, Glezer et al. [ ] showed that the left IFG was associated with release of fMRI repetition suppression (i.e. an absence of suppression due to change) for homophones and different words as compared to repeated words, indicating a sensitivity to orthography in the left IFG. Another fMRI study by Purcell, Jiang, & Eden [ ] also found that the left IFG is sensitive to orthography and works together with left vOT during reading and spelling. The authors suggested that there are three possible roles of the left IFG, which might map orthographic and phonological representations, involve orthographic long-term memory, or handle competition for multiple lexical units. Consistent with this view, a study by Pas et al. [ ] found repetition enhancement for syllabically similar prime-target pairs as compared to unrelated pairs. The authors interpreted their results as evidence that the left IFG is involved in resolving lexical competition between similar words by mediating co-activated lexical neighbors, which compete via mutual inhibition for representation. Taken together, these findings support the possibility of observing that the left IFG will show responses to embedded words. \n\nFinally, in addition to our primary manipulations of prime and target, we tested for a prospective effect of hemifield by presenting prime-target word pairs in either the right hemifield (RVF \u2192 RVF), left hemifield (LVF \u2192 LVF), or by varying the location of the prime and target between hemifields (LVF \u2192 RVF or RVF \u2192 LVF). Early fMRI studies showed location-invariant word representation in the VWFA [ ,  ,  ], but this finding has since been challenged by findings of position sensitivity in the VWFA and other portions of left vOT [ \u2013 ]. There are two general predictions related to the hemifield effect in the VWFA. If the VWFA is location-invariant, we predict that repetition enhancement (or conversely, suppression) will be the same for all conditions; if the VWFA is position sensitive, we predict that the neural responses will be maximal in the RVF-RVF condition, which is consistent with the contralateral bias of orthography-sensitive mechanisms in left vOT, but that it will nevertheless occur in the remaining conditions. \n\n\n## Methods \n  \n### Participants \n  \nEleven right-handed observers (3 females and 8 males; mean age 33.1 years, range 25\u201347 years) participated in both Experiments 1 and 2. All observers were right-handed literate native English speakers with normal or corrected-to-normal vision, and none of them had neurological or psychiatric disorders. All participants were recruited from the University of Nevada, Reno, and the study with all consent forms and experimental procedures was approved by the Institutional Review Board of University of Nevada, Reno. \n\n\n### Stimulus apparatus \n  \nAll experiments were conducted using a 2.53 GHz MacBook Pro with an NVIDIA GeForece 330 M graphics processor (512 MB of DDR3 VRAM). Stimuli were created and presented using PsychotoolBox-3 [ ,  ] for MATLAB (The MathWorks Inc., Natick, MA). Observers viewed stimuli through a mirror attached to the head coil which projected a 32 in. SensaVue (1920 \u00d7 1080 resolution; 31.5\u00b0 \u00d7 18.9\u00b0 visual angle; 85 Hz refresh rate) visual display system (Invivo, Inc., Gainesville, FL) ~125 cm anyway outside of the scanner bore. \n\n\n### Main experiments \n  \nWe used a rapid event-related fMRI prime-target design in which primes were three-letter words followed by four-letter word targets, in two separate experiments. Each experiment employed a 2 \u00d7 2 factorial design ( ) with independent variables of embeddedness and prime-target hemifield location(s). In the   embedded   condition, primes were embedded within the target carrier word (e.g. CAR-CART or CAR-SCAR), and in the   unrelated   condition, the target shared no letter with the prime (e.g. CAR-STEM). In Experiment 1, the prime and target were always presented in the same visual hemifield (i.e. both prime and target in LVF or RVF). In Experiment 2, the prime and target were always presented in opposite hemifields (i.e. prime in LVF and target in RVF, or prime in RVF and target in LVF). \n   Stimuli and conditions in Experiment 1 and 2.  \nIn the   embedded   condition, the target repeats the primed embedded word and adds a letter to the prime; in the   unrelated   condition, the target shares no letter with the prime. (A) In Experiment 1, the prime either appears in the LVF or in the RVF, and the target always appears in the same hemifield as the prime. (B) In Experiment 2, the prime either appears in the LVF or in the RVF, and the target always appears in the opposite hemifield as the prime. \n  \nThe procedures for both experiments were identical. Each experiment started with a central fixation cross followed by a variable inter-trial-interval (ITI), which ranged between 3 and 11 s (in 2 s increments), and the appearance of a three-letter prime in either the LVF or RVF, always for 0.3 s. Four-letter target words appeared 0.4 s after the prime had disappeared, either in same visual hemifield as the prime (Experiment 1), or in the opposite visual hemifield (Experiment 2), always for 0.3 s. Targets and their embedded primes were never morphologically related. The morphological relation between the prime and target was defined according to the study of Devlin et al. [ ], in which \u201cmorphologically related\u201d means that the prime and target contain the same orthographic structure as well as the same semantic meaning. Accordingly, PASSIVE \u2192 PASS are orthographically but not semantically related, and thus are not morphologically related. However, HUNTER \u2192 HUNT are both orthographically and semantically related and thus morphologically related. All words were displayed in black against a gray background. The fixation cross subtended a visual angle of 0.2\u00b0 \u00d7 0.2\u00b0, and four-letter words subtended an angle of 3.4\u00b0 \u00d7 0.8\u00b0. The inner edge of each word fell just next to the fixation cross. To maintain the same visual overlap between the prime and target across hemifields, the additional letter in the target was in the first position in the LVF and in the fourth position in the LVF ( ). \n\nEach experiment consisted of 4 runs and all 8 runs were collected in the same scan session with each experiment run alternating after the other. Observers viewed a total of 224 different English prime-target pairs in each experiment (All words are listed in  ). First-letter addition and last-letter addition trials each contained 112 prime-target pairs. Due to the limited availability of stimulus pairs, the psycholinguistic variables for word pairs were not fully controlled. To avoid possible confounding variables due to this limitation, the word stimuli in   LVF-LVF   (Experiment 1) and   RVF-LVF   (Experiment 2) conditions, and the   RVF-RVF   (Experiment 1) and   LVF-RVF   (Experiment 2) conditions were the same and randomized across runs for the   embedded   and   unrelated   conditions. Each run started and ended with a 10-s fixation, and there were 14 trials per each condition with a total of 56 trials which lasted for 360 s. Trial sequences and ITIs were generated using the Optseq ( ) to optimize the rapid event-related fMRI design. Observers maintained central fixation throughout the entire experiment. A change-detection fixation task was used to encourage and monitor central fixation (observers pressed a button when the fixation cross changed from black to gray). Changes in the fixation cross occurred randomly for 50% of the ITIs. \n\n\n### Localizer scans \n  \nWe identified the VWFA for each individual observer using a standard block design localizer experiment. This experiment was performed separately from the main experiments. Stimulus were 2-D grayscale (~5\u00b0 \u00d7 5\u00b0 for non-word stimulus; ~5\u00b0 \u00d7 1\u00b0 for words) images presented centrally against a white background consisting of words, faces, common daily objects, or scrambled images. Each block was presented for 16 seconds, and within each block, 16 images of the same category were presented for 0.5 s followed by 0.5 s blank screen. There were 16 blocks in each run and 4 blocks per each stimulus category, and the block order was counterbalanced across runs. 9 out of 11 observers completed 2 runs, and the other 2 observers completed 1 run due to scheduling conflicts. The region of interest (ROI) of VWFA was defined for each observer as a cluster of voxels (  p   < 0.05 ~ 0.01, uncorrected) in which the BOLD responses were greater for words compared with scrambled images. The VWFA was constrained to clusters that showed responses in anatomical landmark regions consisting of the fusiform gyrus and inferior occipitotemporal sulcus. The same contrast was also used to define the ROI of left IFG for 10 out of 11 observers, and the Word > Fixation contrast was used to identify the left IFG for the last observer who did not show any activation in the left IFG using the Word > Scrambled image contrast. The left IFG was constrained to correspond the location of the left IFG which was known for orthographic processing [ ,  ]. \n\n\n### fMRI data acquisition \n  \nThe main experiments and the localizer scans were conducted at the Renown Health hospital (Reno, NV) using a 3T Philips Ingenia MRI system equipped with a 32-channel digital SENSE head coil. Continuous whole-brain BOLD signals were collected using T2*-weighted interleaved, echo-planar functional images (TE = 40 ms, TR = 2 s, flip angle = 71\u00b0, 32 axial slices, 3 mm , 2 mm thickness, 1 mm gap, matrix size = 128 \u00d7 128, field of view = 240 \u00d7 240). Dummy scans were collected for a minimum of 10 s at the beginning of every run to allow for stabilization of the magnetic field. High-resolution anatomical images obtained using a 3-D T1-weighted pulse sequence (TE = 4.60 ms, TR = 3.0 s, flip angle = 8\u00b0, resolution = 1 \u00d7 1 \u00d7 1 mm, matrix size = 256 \u00d7 256) and were used for anatomical reconstruction of the cortical hemisphere surfaces. \n\n\n### fMRI data preprocessing \n  \nData were preprocessed and analyzed using AFNI [ ], SUMA [ ], FreeSurfer [ ,  ], and MATLAB. We performed corrections for slice scan time and head motion (always < 2 mm), and each functional voxel was temporally normalized using AFNI\u2019s 3dDetrend command. Functional data were spatially smoothed using a Gaussian kernel of 6 mm. The group level analyses of the data were based on (1) a whole-brain analysis using the 3dANOVA3 function for standardized Talairach space [ ] data and (2) a ROI analysis using an independent localizer (described earlier) in which the anatomical volume was transformed to surface for defining the surface-based topographic ROIs. \n\n\n### fMRI data analysis \n  \nStatistical analyses based on the general linear model (GLM) were performed on each voxel to obtain beta weights (coefficients) by convolving with a model hemodynamic response function using a BLOCK model in AFNI\u2019s 3dDeconvolve function. Nine additional nuisance regressors were also included: three run-wise baseline parameters corresponding to constant signal, linear drift, and second-degree polynomials, and six rigid motion registration parameters. \n\nFor the group-level whole-brain GLM, each individual\u2019s data was first transformed into standard Talairach space. Statistical maps were calculated based on the 2 \u00d7 2 factorial model using AFNI\u2019s 3dANONVA3 function which accounted for both within- and between-participant variance. The statistical threshold was set at voxel-wise   p   < 0.01 with cluster size larger than 28 voxels at   p   < 0.05 cluster-level corrected, determined by the AFNI AlphaSim function with Monte Carlo simulations. To increase the statistical power for the effect on embeddedness, we performed additional analysis by collapsing the prime-target hemifield and combining two experiments (8 runs total), and the statistical maps were calculated based on a one factorial model for the embeddedness. The statistical threshold was set at voxel-wise   p   < 0.005 with cluster size larger than 23 voxels at   p   < 0.01 cluster-level corrected, determined by the AFNI AlphaSim function with Monte Carlo simulations. \n\nFor the group-level ROI analyses, a separate general linear model was applied using the combined data of all 4 four runs for each experiment in which the finite impulse responses were derived for each condition staring from 4 s prior to and extending 20 s following the start of each events (TENT model in AFNI\u2019s 3dDeconvolve function). BOLD time-courses were derived for all four conditions based on average BOLD signals in all voxels within each ROI. A 2 \u00d7 2 repeated-measures ANOVA was conducted on the peak BOLD responses, corresponding to the 6 and 8 s, for embeddedness (  Embedded   and   Unrelated  ) and prime-target hemifield location(s) (Experiment 1:   LVF-LVF   and   RVF-RVF  ; Experiment 2:   LVF-RVF   and   RVF-LVF  ). \n\n\n\n## Results \n  \n### Whole-brain analyses \n  \nWe performed whole-brain group-level analyses combining the two experiments (see more details in   session).   and   show the results from this whole-brain analyses. First, we sought to identify clusters showing greater responses for embedded words by the contrast   embedded   >   unrelated  . We observed that embedded words was associated with brain responses in the left fusiform gyrus (FG), left precuneus (PCun), left IFG and left middle frontal gyrus (MFG). The center of mass of left FG was located in the Talairach coordinate, x = -47, y = -49, z = -11, which corresponded to the known VWFA location [ ,  ,  ]. Second, we aimed to find any brain regions that might show repetition suppression related to the embedded words processing by the contrast   unrelated   >   embedded  . However, no cluster showed repetition suppression even at a relatively liberal threshold (  p   < 0.01, uncorrected). These results indicated the effect of whole-word embedding was associated with fMRI repetition enhancement, but there was no fMRI repetition suppression associated with embedded words. \n   Results of whole brain analyses from combining Experiment 1 and 2.  \nThe effect of embeddedness is revealed by the   Embedded   >   Unrelated   contrast, which yields enhanced fMRI responses in the VWFA and left IFG. \n     Results of the significant activations revealed by the whole-brain analysis.        \nWe then performed separate whole-brain group-level analyses based the 2 \u00d7 2 factorial design for each experiment.   shows the whole-brain analyses results for Experiment 1 and 2. In Experiment 1, we observed similar results of embeddedness as in the combined analysis, in which the   Embedded   >   Unrelated   contrast revealed activation in the left FG, left PCun, and left IFG (Note: it did not survive after cluster-level correction). Again, there was no significant voxel revealed by the   Unrelated   >   Embedded   contrast. At a liberal threshold (  p   < 0.05, uncorrected), we observed repetition enhancement in the left FG and left IFG in the   RVF-RVF   condition, however, only the left IFG was associated with repetition enhancement in the   LVF-LVF   condition. In Experiment 2, we again observed repetition enhancement in the same brain regions, including the left FG, left IFG, and left PCun (Note: it did not survive after cluster-level correction), revealed by the   Embedded   >   Unrelated   contrast. Similarly, no brain region showed suppression as defined by the   Unrelated   >   Embedded   contrast. At a liberal threshold (  p   < 0.05, uncorrected), unlike Experiment 1, both the   LVF-RVF   and   RVF-LVF   condition yielded significant repetition enhancement in the left FG and left IFG. In short, analyses for both experiments showed consistent results that an enhancement was associated with processing the embedded words in the VWFA and other non-visual language-related brain areas. \n\n\n### ROI analyses \n  \nIn each observer, we then identified the VWFA defined as Word > Scrambled image contrast. We successfully identified the VWFA for all observers located in anatomical regions constrained to the FG and inferior occipitotemporal sulcus ( ). The average Talairach coordinates of the VWFA was located at x = -41.8 \u00b1 2.7, y = -54.9 \u00b1 8.0, z = -12.3 \u00b1 3.3, which was close to the left FG in the whole-brain analyses and also in the vicinity of previously reported VWFA location [ ,  ,  ].   shows the BOLD percent signal change in the VWFA from Experiment 1. We performed a two-way repeated measures ANOVA on the BOLD responses for embeddedness (  Embedded   and   Unrelated  ) and prime-target hemifield (  LVF-LVF   and   RVF-RVF  ). The result suggested a main effect of embeddedness,   F  (1, 10) = 7.29,   p   = 0.022, and an interaction between these two factors,   F  (1, 10) = 10.21,   p   = 0.0096. The main effect of the prime-target hemifield was marginally significant,   F  (1, 10) = 4.85,   p   = 0.052. Post-hoc paired t-test suggested that the fMRI responses for   Embedded   was larger than these for   Unrelated   in the   RVF-RVF   condition,   t  (10) = 4.46,   p   = 0.0012; however, this was not the case in the   LVF-LVF   condition,   t  (10) = -0.12,   p   = 0.91. In short, the VWFA ROI results were consistent with the whole-brain results which suggested that fMRI repetition enhancement for the embedded words, and additionally, such enhancement was observed only for the   RVF-RVF   condition in Experiment 1. \n   Results of ROI analyses from Experiment 1 and 2.  \n(A) In Experiment 1, the VWFA shows fMRI repetition enhancement for   embedded   words as compared to the   unrelated   words, in Experiment 1. Importantly, the VWFA shows an interaction between the embeddedness and prime-target hemifield, and an absence of fMRI repetition enhancement is observed for the   LVF-LVF   condition (marked by \u201cNS\u201d, non-significant). (B) The fMRI repetition enhancement is observed in the left IFG in Experiment 1. In Experiment 2, the fMRI repetition enhancement is observed in the VWFA (C) and the left IFG (D). \n     Center Talairach coordinates and cluster sizes of individual ROIs for all participants.      \nThe left IFG was identified using the same contrast which yielded an average Talairach coordinates located at x = -40.3 \u00b1 5.4, y = 3.9 \u00b1 5.7, z = 28.5 \u00b1 3.3 ( ). This result was consistent with the location of the left IFG from the whole-brain analyses ( ) and also close to the location reported in previous studies [ ,  ].   shows the BOLD percent signal change in the left IFG from Experiment 1. Similar to the VWFA, a two-way repeated measures ANVOA was performed, and the results revealed a main effect of embeddedness,   F  (1, 10) = 6.11,   p   = 0.033. However, there was no main effect of prime-target hemifield,   F  (1, 10) = 2.59,   p   = 0.14, nor interaction between these two,   F  (1, 10) = 0.13,   p   = 0.72. This means that unlike the VWFA, the repetition enhancement effect in the left IFG was not affected by the prime-target hemifield location(s). \n\n shows the BOLD percent signal change for the VWFA from Experiment 2. As before, a two-way repeated measures ANOVA on BOLD percent signal change in the VWFA was conducted. The result showed a main effect of embeddedness,   F  (1, 10) = 9.55,   p   = 0.011. We did not find any main effect of prime-target hemifield (  F  (1, 10) = 0.43,   p   = 0.53) or interaction between these two (  F  (1, 10) = 0.68,   p   = 0.43). This result means that the fMRI repetition enhancement in the VWFA for the embedded words was not affected by primes and targets being viewed sequentially in opposite hemifields.   shows the BOLD percent signal change in the left IFG from Experiment 2. We observed similar fMRI responses in the left IFG as shown in Experiment 1. A two-way repeated measures ANVOA revealed a main effect of embeddedness,   F  (1, 10) = 11.86,   p   = 0.006, but neither the main effect of prime-target hemifield (  F  (1, 10) = 2.72,   p   = 0.13) nor the interaction between these two (  F  (1, 10) = 0.067,   p   = 0.80) was statistically significant. In short, both the VWFA and left IFG showed consistent fMRI repetition enhancement in both experiments, but unlike left IFG, the VWFA did not show repetition enhancement for prime-target word pairs presented in the   LVF-LVF   condition in Experiment 1. \n\n\n\n## Discussion \n  \nThe current study used a novel fMRI embedded word priming paradigm. Our main finding was a repetition enhancement effect, which occurred for prime-target word pairs comprised of embedded words followed by containing words. The enhancement effect was not widespread\u2014it was mostly limited to the VWFA in left vOT and other non-visual language-relate brain areas in the left hemisphere (IFG, MFG and PCun). The effect was consistently strong in the VWFA except for a single prime-target hemifield condition (  LVF-LVF  ), in which the VWFA failed to show enhancement. We interpret our findings with respect to behavioral studies of embedded word recognition and functional properties of the VWFA reported in other fMRI studies. \n\n### fMRI repetition enhancement and lexical competition \n  \nOur finding of fMRI repetition enhancement in the VWFA is the first of its kind. In contrast to fMRI suppression, which is associated with facilitative priming effects [ ,  ,  ,  ], fMRI enhancement is associated with inhibitory priming effects [ ,  \u2013 ]. Several behavioral studies of word recognition have shown that embedded words are co-activated, automatically and in parallel, with their carrier words [ ,  ,  ], which could plausibly result in fMRI enhancement in the context of fMRI priming [ ,  ,  ]. Such co-activation is strong enough to connect with meaning and induce semantic interference that arises from sub-word orthographic activation [ ]. Consistent with this, interference due to co-activation of embedded words and their carriers is not limited to semantic level competition, and occurs during silent reading during a lexical decision task [ ], and other natural reading situations [ ]. This is important because although our study employed passive word viewing in conjunction with a fixation task, it is plausible embedded words and their carriers nevertheless co-activated. Consistent with this, models of word recognition posit that representations of a word and its orthographically similar neighbors are co-activated and compete for representation via mutual inhibition during word recognition, a result supported by the results of lexical interference tasks [ ]. \n\nAdditional support for co-activation of embedded words and their carriers in our study relates to our use of the prime-target paradigm. That is, by using embedded words as primes, this may have increased re-activation of the embedded word in the target. Studies of embedded word recognition using a prime-target paradigm similar to that used here have shown orthographic interference in a lexical decision task [ ,  ]. Such findings are consistent with the possibility that, in our study, embedded word primes were re-activated when viewing the target carrier word\u2014that is, co-activation of the embedded and carrier word. This co-activation would likely result in orthographic interference arising from inhibitory connections between embedded words and their carriers related to their status as orthographic neighbors [ ,  ]. It should also be noted that embedded words interfere with their carriers irrespective of their position within the carrier (i.e., \u2018CAR\u2019 \u2192 \u2018SCAR\u2019 and \u2018CAR\u2019 \u2192 \u2018CART\u2019 exhibits equivalent orthographic interference, [ ]), and that lateral inhibition underlying orthographic interference more generally is observed in both masked and non-masked priming paradigms [ ,  ]. Taken together, other studies of embedded word viewing have shown that co-activation and interference of embedded words and their carriers occurs in a variety of different contexts. \n\nConsistent with our findings, fMRI enhancement resulting from lexical competition was recently reported in a related study of sub-word orthographic representation. A study by Pas et al. [ ] reported an fMRI enhancement effect using a syllabic masked priming paradigm. In their study, repetition enhancement was interpreted to reflect lexical competition between syllabically overlapping words rather than embedded words. The authors concluded that lexical interference resulted from automatic memory retrieval of the prime [ ,  ], which caused the interference effect and corresponding fMRI enhancement. Based on their interpretation of fMRI enhancement, the results of behavioral studies of embedded word recognition, and orthographic sensitivity in the VWFA [ ,  \u2013 ], we interpret the observed fMRI enhancement as the result of reactivation of primed embedded words, which interfere with their carrier words during viewing of the target. \n\nA possible criticism of our experiment is that the observed enhancement effect was due to our use of a fixation task in conjunction with our conditions of interest. For example, one might argue that attention is drawn to words in the   embedded   condition more than those in the   unrelated   condition because the former involves only very subtle physical (single letter) changes between word pairs, and draws more attention away from the fixation task, resulting in a corresponding increase in fMRI response. Unfortunately, it is not possible to fully rule out the potential contribution of attention-related factors to our results. It should be noted, however, that a previous fMRI repetition suppression study observed equivalent suppression for fixation-based and stimulus-relevant tasks [ ]. Additionally, other fMRI studies showed that the degree of repetition suppression corresponds to the magnitude of stimulus change, with small changes producing suppression similar to no change. For example, Fang et al. [ ] reported similar degrees of repetition suppression in early visual cortex for both repetition and small stimulus change conditions compared to a large stimulus change condition when participants performed a fixation task. A similar effect has been shown for faces in extrastriate cortex [ ,  ]. These findings are difficult to reconcile with an attention-related account of our results in which small stimulus changes lead to repetition enhancement rather than suppression. We therefore conclude that our novel finding of repetition enhancement for embedded words is not necessarily attention-related. \n\nAlso, if our enhancement effect was due solely to differences in the degree of attention employed in our different conditions, then we would expect evidence of the effect in both a bilateral ventral visual cortical word recognition circuit [ ], in addition to brain regions commonly associated with capture of attention, such as parietal cortex and the temporal parietal junction [ ,  ]. However, our results showed no enhancement in these attention related regions, nor in right vOT. Instead, our results indicate that enhancement in word-selective left hemisphere brain regions only, and an interaction of hemifield and condition, which further complicates an attention-based account of our results. We nevertheless concede that attention could play a role in our results, as in other studies of fMRI repetition enhancement [ ,  ]. \n\nLastly, even though we predicted repetition suppression could occur, possibly in regions associated with visual processing, no evidence of repetition suppression was found in whole-brain group and additional ROI analyses of the early visual cortex ( ). Early visual cortex showed brain activation to words presented in the contralateral visual hemifield, but showed no effect of enhancement or suppression. The study by Pas et al. [ ], mentioned earlier, also failed to find repetition suppression accompanying enhancement for syllabic repetition. In their study, they observed repetition suppression only for exact stimulus repetitions, as in Glezer et al. [ ], also discussed earlier. \n\n\n### Hemifield-dependent enhancement in the VWFA \n  \nA noteworthy exception to fMRI enhancement in the VWFA in our study was the absence of the effect in the   LVF-LVF   condition (Experiment 1), which did not occur in other brain regions that showed fMRI enhancement. This lack of fMRI enhancement was not due to overall decreased fMRI responses in the   LVF-LVF   condition. Our ROI analyses showed that fMRI responses in the   unrelated   prime-target condition did not differ from those in the   RVF-RVF   condition in Experiment 1, and no significant prime-target cross hemifields effect (  LVF-RVF and RVF-LVF  ) in Experiment 2, consistent with hemifield-invariant fMRI responses in this condition. This also means that the lack of fMRI enhancement reflects a lack of increased fMRI response in the   embedded   prime-target condition rather than an increased fMRI response in the   unrelated   prime-target condition. In short, fMRI responses to   unrelated   prime-target pairs showed no effect of hemifield, but the re-activation underlying fMRI enhancement did, but only for one particular condition (  LVF-LVF  ). \n\nThe absence of fMRI enhancement in the   LVF-LVF   hemifield condition was unexpected, and it is difficult to explain. One plausible interpretation is that it reflects a lack of re-activation of the prime, and a consequent absence of competition between the embedded word and its carrier when viewing the target word. The lack of fMRI enhancement in the   LVF-LVF   condition means that, for orthographic interference to occur, an embedded word needs to appear in the RVF, either as a prime, target or both. This could be due to greater sensitivity to orthographic information in the left hemisphere than in the right, and its relation to the location of a word in the visual field [ \u2013 ], possibly in conjunction with differences between the VWFA and other non-visual language centers in the left hemisphere (which we discuss in the next section). Alternatively, it is reasonable to hypothesize that the enhancement observed in the VWFA, and its interaction with word location (RVF/LVF) reflects the distinct underlying mechanisms for processing words in the RVF as compared to the LVF. This possibility is consistent with findings of RVF superiority for holistic word processing and feature-based processing of LVF words [ ]. According to this view, the highly similar words are more discriminable in the RVF than the LVF, which is associated with stronger representations for these highly similar words in the RVF. Again, this consistent with our interpretation of our results as indicative of unique word-selective processing for words viewed in the RVF, in contrast to other findings of RVF-LVF invariance in the VWFA [ ]. \n\nFinally, in the negative syllabic priming fMRI study by Pas et al. [ ], the authors reasoned that negative priming would be stronger for RVF stimuli as compared to LVF stimuli given stronger lateral inhibition of lexical competitors in the left hemisphere than in the right. Thus, with respect to embedded words, LVF prime-target viewing could result in decreased lateral inhibition between embedded words and their carriers in addition to either weaker activation of the embedded word prime, its re-activation in the target, or both. Additionally, it is possible that because only the left hemisphere VWFA represents whole words [ ], then the right hemisphere fails to activate embedded target words; an analogous argument has been proposed for lack of fMRI repetition effect for LVF viewed face stimuli [ ]. The failure of embedded word re-activation could also be due to callosal transfer of LVF words for left hemisphere processing, which results in a time delay and reduction of quality of stimulus representation [ ]. Alternatively, it is also possible that the repetition enhancement may be offset by repetition suppression in   LVF-LVF   condition. For instance, it has been shown that orthographic processing was associated with facilitation for words presented in the LVF, at the sublexical level of orthographic coding [ ], but inhibition for words presented in the RVF [ ]. Thus, presenting the embedded words twice in the LVF may lead to a combined facilitative effect of sublexical repetition between primes and targets, and lexical competition between whole-word representations of the primes and the targets. \n\n\n### Beyond the VWFA \n  \nAlthough our primary brain region of interest was the VWFA, our results revealed a dissociation between the VWFA and other non-visual brain areas implicated elsewhere in orthographic processing, including left IFG. Early studies have shown the involvement of the left IFG in sematic and phonological processing (for a review see [ ]), but recent studies have shifted attention to the role of the left IFG in orthographic processing [ ,  ]. Our results thus offer further evidence of orthographic representation in left IFG. Consistent with this, left IFG has been shown involving higher-level abstract orthographic processing [ ] and orthographic long-term memory [ ]. In the fMRI study by Pas et al. [ ], discussed earlier, the authors argued that the observed repetition enhancement in the left vOT (likely the VWFA) was driven by the feedback responses from the left IFG, which acts as a fast visual word processing system [ ,  ], faster than and distinct from the VWFA. This distinction may explain the lack of hemifield effect on fMRI enhancement observed in the left IFG in our study. It should be noted that the aim of the current study was not to separate effects related to orthographic or semantic levels processed in different brain regions. It is however possible that, unlike the VWFA which only showed orthographic sensitivity [ ], the left IFG could be associated with semantic processing, consistent with the view that this region is involved in the neural representation of competing semantic information [ ]. This conclusion is tentative because of our fixation task instead of a semantic categorization task, which would allow for a behavioral measure of semantic interference (e.g., [ ]). \n\nIn addition to left IFG, our whole-brain analyses also show fMRI enhancement in left PCun and left MFG. Unlike left IFG, these areas were not identified in our independent localizer and we were therefore unable to perform ROI analyses as we did for left IFG. Both areas are commonly activated in fMRI studies of word recognition and reading. Left PCun has been implicated in orthographic representation [ ] and monitoring the orthographic and phonological consistency related to attention [ ], however, it is also has been suggested to associate with semantic representation [ ]. A large amount of studies have suggested that left MFG is also associated with semantic representation (for a review see [ ]), in addition to allocation spatial attention during word recognition [ ], but it is not strongly associated with orthographic representation. It is possible that our finding of repetition enhancement in left PCun and left MFG is related to the co-activation of semantic representations of the embedded words, consistent with the view that sub-word orthographic interference is strong enough to connect with meaning and induce semantic interference [ ,  ]. However, this interpretation could not be tested in the current study, because we did not control for the semantic relationship between words in the   embedded   and   unrelated   conditions. \n\nIn conclusion, the present study provides the first neural evidence of lexical interference during embedded word viewing. Observation of the fMRI repetition enhancement in the VWFA and its failure under the   LVF-LVF   prime-target hemifield condition revealed a clear dissociation between the VWFA and non-visual language-related areas in the brain. Our findings are consistent with the view that the VWFA underlies lexical-level orthographic representation. Our findings also support the view that the VWFA is distinct from other brain areas involved in orthographic neural representation, and which possibly exert feedback effects on the VWFA. \n\n\n\n## Supporting information \n  \n \n\n# Table(s)\n## ID: pone.0208318.t001\n### Label: Table 1\nContrast\tBrain Region\tHemisphere\tCluster Center Coordinates\tCluster Center Coordinates\tCluster Center Coordinates\tNumber of Voxels\tThreshold(Cluster Corrected)\nContrast\tBrain Region\tHemisphere\tx\ty\tz\tNumber of Voxels\tThreshold(Cluster Corrected)\nExperiment 1 and 2 combined\t\t\t\t\t\t\t\nEmbedded > Unrelated\tFusiform gyrus\tLeft\t-47.0\t-49.0\t-11.0\t76\tp < 0.005\n\tPrecuneus\tLeft\t-24.0\t-69.0\t34.0\t57\tp < 0.005\n\tInferior frontal gyrus\tLeft\t-46.0\t4.0\t21.0\t52\tp < 0.005\n\tMiddle frontal gyrus\tLeft\t-42.0\t30.0\t23.0\t27\tp < 0.005\nExperiment 1\t\t\t\t\t\t\t\nEmbedded > Unrelated\tMiddle frontal gyrus\tLeft\t-41.0\t30.0\t23.0\t42\tp < 0.01\n\tPrecuneus\tLeft\t-24.0\t-69.0\t33.0\t37\tp < 0.01\n\tCerebellum\tLeft\t-14.0\t-42.0\t-16.0\t32\tp < 0.01\n\tFusiform gyrus\tLeft\t-47.0\t-47.0\t-16.0\t30\tp < 0.01\n\tInferior frontal gyrus\tLeft\t-43.0\t4.0\t20.0\t21???\tp < 0.01\n\tThalamus\tRight\t11.0\t-13.0\t0.0\t37\tp < 0.01\nExperiment 2\t\t\t\t\t\t\t\nEmbedded > Unrelated\tFusiform gyrus\tLeft\t-47.0\t-49.0\t-11.0\t92\tp < 0.01\n\tInferior frontal gyrus\tLeft\t-43.0\t1.0\t24.0\t44\tp < 0.01\n\tPrecuneus\tLeft\t-27.0\t-67.0\t26.0\t15???\tp < 0.01\n### Caption\nResults of the significant activations revealed by the whole-brain analysis.\n### Footer\nNote* Cluster-level uncorrected\n\n\n## ID: pone.0208318.t002\n### Label: Table 2\nParticipant\tThreshold(uncorrected)\tVWFA (left)\tVWFA (left)\tVWFA (left)\tNumber of Voxels\tleft IFG\tleft IFG\tleft IFG\tNumber of Voxels\nParticipant\tThreshold(uncorrected)\tx\ty\tz\tNumber of Voxels\tx\ty\tz\tNumber of Voxels.1\nP1\tp < 0.01\t-47.0\t-65.0\t-13.0\t106.0\t-44.0\t-5.0\t36.0\t134.0\nP2\tp < 0.05\t-46.0\t-45.0\t-15.0\t90.0\t-39.0\t7.0\t23.0\t36.0\nP3\tp < 0.01\t-43.0\t-52.0\t-14.0\t79.0\t-43.0\t10.0\t30.0\t92.0\nP4\tp < 0.01\t-39.0\t-47.0\t-17.0\t85.0\t-52.0\t-2.0\t27.0\t105.0\nP5\tp < 0.01\t-38.0\t-51.0\t-11.0\t59.0\t-40.0\t7.0\t25.0\t49.0\nP6\tp < 0.05\t-42.0\t-55.0\t-6.0\t30.0\t-41.0\t7.0\t29.0\t107.0\nP7\tp < 0.05\t-41.0\t-56.0\t-9.0\t54.0\t-37.0\t2.0\t29.0\t58.0\nP8\tp < 0.05\t-42.0\t-44.0\t-16.0\t84.0\t-39.0\t1.0\t27.0\t57.0\nP9\tp < 0.05\t-41.0\t-64.0\t-10.0\t52.0\t-42.0\t-3.0\t29.0\t49.0\nP10\tp < 0.05\t-40.0\t-58.0\t-14.0\t47.0\t-31.0\t6.0\t30.0\t20.0\nP11\tp < 0.05\t-41.0\t-67.0\t-10.0\t30.0\t-35.0\t13.0\t28.0\t46.0\nMean\t\t-41.8\t-54.9\t-12.3\t65.1\t-40.3\t3.9\t28.5\t68.5\nSD\t\t2.7\t8.0\t3.3\t25.2\t5.4\t5.7\t3.3\t35.5\n### Caption\nCenter Talairach coordinates and cluster sizes of individual ROIs for all participants.\n### Footer\nNone\n", "metadata": {"pmcid": 6328158, "text_md5": "71ee0db9afdaa257bbfe774c79f1f7b0", "field_positions": {"authors": [0, 51], "journal": [52, 60], "publication_year": [62, 66], "title": [77, 159], "keywords": [173, 173], "abstract": [186, 1369], "body": [1378, 43379], "tables": [43392, 45691]}, "batch": 2, "pmid": 30629612, "doi": "10.1371/journal.pone.0208318", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6328158", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=6328158"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6328158\">6328158</a>", "list_title": "PMC6328158  Embedded word priming elicits enhanced fMRI responses in the visual word form area"}
{"text": "Ziv, Michal and Goldin, Philippe R and Jazaieri, Hooria and Hahn, Kevin S and Gross, James J\nBiol Mood Anxiety Disord, 2013\n\n# Title\n\nEmotion regulation in social anxiety disorder: behavioral and neural responses to three socio-emotional tasks\n\n# Keywords\n\nSocial anxiety\nEmotion regulation\nReappraisal\nfMRI\nDMPFC\nTemporal dynamics\n\n\n# Abstract\n \n## Background \n  \nSocial anxiety disorder (SAD) is thought to involve deficits in emotion regulation, and more specifically, deficits in cognitive reappraisal. However, evidence for such deficits is mixed. \n\n\n## Methods \n  \nUsing functional magnetic resonance imaging (fMRI) of blood oxygen-level dependent (BOLD) signal, we examined reappraisal-related behavioral and neural responses in 27 participants with generalized SAD and 27 healthy controls (HC) during three socio-emotional tasks: (1) looming harsh faces (Faces); (2) videotaped actors delivering social criticism (Criticism); and (3) written autobiographical negative self-beliefs (Beliefs). \n\n\n## Results \n  \nBehaviorally, compared to HC, participants with SAD had lesser reappraisal-related reduction in negative emotion in the Beliefs task. Neurally, compared to HC, participants with SAD had lesser BOLD responses in reappraisal-related brain regions when reappraising faces, in visual and attention related regions when reappraising criticism, and in the left superior temporal gyrus when reappraising beliefs. Examination of the temporal dynamics of BOLD responses revealed late reappraisal-related increased responses in HC, compared to SAD. In addition, the dorsomedial prefrontal cortex (DMPFC), which showed reappraisal-related increased activity in both groups, had similar temporal dynamics in SAD and HC during the Faces and Criticism tasks, but greater late response increases in HC, compared to SAD, during the Beliefs task. Reappraisal-related greater late DMPFC responses were associated with greater percent reduction in negative emotion ratings in SAD patients. \n\n\n## Conclusions \n  \nThese results suggest a dysfunction of cognitive reappraisal in SAD patients, with overall reduced late brain responses in prefrontal regions, particularly when reappraising faces. Decreased late activity in the DMPFC might be associated with deficient reappraisal and greater negative reactivity. \n\n\n## Trial registration \n  \nClinicalTrials.gov identifier:  \n\n \n\n# Body\n \n## Background \n  \nSocial anxiety disorder (SAD) is characterized by heightened anxiety in a wide array of social situations [ ]. It has been suggested that these elevated levels of anxiety may be due to ineffective emotion regulation [ ]. Specifically, it has been suggested that patients with SAD use adaptive emotion regulation strategies, such as cognitive reappraisal, less frequently than non-anxious healthy adults [ ]. In healthy individuals, cognitive reappraisal, which involves changing the meaning of a stimulus that gives rise to an emotion, can modify emotional reactions to anxiety-provoking situations, leading to greater psychological flexibility and emotional well being [ ]. In SAD, deficits in cognitive reappraisal are thought to be related to difficulty in modifying the negative thoughts that arise before, during, and after social evaluative situations [ ]. \n\n### Neuroimaging findings \n  \nOne source of evidence regarding reappraisal in SAD comes from neuroimaging studies. To date, three studies have investigated the neural correlates of cognitive reappraisal in SAD. In the first study, Goldin and colleagues examined cognitive reappraisal of social (harsh facial expressions) and physical (violent scenes) threat in SAD patients and healthy controls. Regulation during social threat, but not physical threat, was associated with diminished recruitment of brain systems implicated in cognitive reappraisal (dorsomedial and dorsolateral prefrontal cortex (PFC)), and attention modulation (medial cuneus, posterior cingulate cortex, and parietal cortex) in SAD, compared to healthy controls [ ]. \n\nIn a second study by this group, using negative self-beliefs, the temporal dynamics of the BOLD response, in addition to its signal magnitude, were analyzed [ ]. Findings revealed greater early activity in healthy controls during reappraisal of negative self-beliefs in brain networks implicated in reappraisal (dorsomedial, dorsolateral, and ventrolateral PFC), language (left inferior frontal gyrus), and visual (precuneus, inferior parietal) processing, while SAD patients had greater late responses in dorsomedial and ventrolateral PFC, insula, and visual processing regions. Taken together, these two studies suggest a failure to recruit reappraisal-related prefrontal regions in SAD. This differential activity of prefrontal regulatory regions in SAD has been observed in other neuroimaging studies [ - ]. \n\nThe third study that explicitly addressed the neural correlates of emotion regulation in SAD, by Bruhl and colleagues [ ], reported results that are discrepant with the two studies reported above. In this study, patients were instructed either to perform \u2018reality checking\u2019 or to simply anticipate and then look at negative, positive, and neutral pictures. Thus, in contrast to the first two studies, which compared patients to healthy controls, this study compared patients applying cognitive control with patients not using cognitive control. The authors found regulation-related reduced activity in emotion reactivity regions (amygdala, insula, thalamus), and in the dorsolateral PFC and cingulated cortex, with no regions with increased activity due to cognitive control. \n\n\n### Explaining mixed findings \n  \nOne possible explanation for the mixed findings may be the different contexts that were examined. Each of these studies focused on only one emotional probe: faces, beliefs, or non-socially specific affective pictures. However, in the SAD literature, it has been shown that the choice of emotional probes and experimental paradigms has a much larger effect on the results of fMRI investigations than is typically thought [ ]. \n\nIn addition to using different stimuli, another source of variability in the imaging literature is the different data analytic approaches used in each study. The majority of studies in SAD so far have used BOLD signal magnitude analyses that usually collapse across time. Only a handful of studies examined the temporal dynamics of the BOLD responses [ , - ]. Of these studies, only one [ ] has specifically focused on emotion regulation processes. Analysis of BOLD signal temporal dynamics can reveal information that might be hidden when averaging across time. It can also reveal between-group differences in brain regions that have the same averaged response among two groups, such as a pattern of early brain responses in one group, or delayed responses in the other group. Indeed, the one study examining temporal dynamics of emotion regulation processes in SAD found delayed BOLD signal onset in the dorsomedial and ventrolateral PFC regions in patients, relatively to healthy controls [ ]. \n\n\n### The present study \n  \nThe goal of the present study was to examine behavioral and fMRI BOLD responses in patients with SAD compared to healthy controls (HC) when reappraising socio-emotional stimuli. To test whether emotion dysregulation in SAD is related to a specific socio-emotional stimulus, or whether this is a more general core deficit, three contexts were compared: (1) looming harsh faces (Faces); (2) dynamic video clips of actors delivering social criticism (Criticism); and (3) written autobiographical social anxiety-related negative self-beliefs (Beliefs). To our knowledge, no study has directly tested reappraisal-related BOLD responses in patients with SAD across several distinct socio-emotional tasks that vary in both content and form. \n\nBehaviorally, we hypothesized that, compared to HC, patients with SAD would be less successful in down regulating negative emotional reactivity when implementing cognitive reappraisal in each of the three tasks. Neurally, we hypothesized that, compared to HC, patients with SAD would have: (1) lesser BOLD responses in reappraisal-related PFC regions; and (2) delayed (that is, late) BOLD responses in reappraisal-related PFC regions. In addition to analyzing the differential and common BOLD responses separately for each task, we examined BOLD signal temporal dynamics in regions showing similar reappraisal-related increased activity in SAD and HC across all three tasks. The purpose of this analysis was to see whether there are cognitive reappraisal-related brain responses that are stimulus-independent, and whether more refined timing differences in patients and HC could be revealed using analyses of the BOLD signal temporal dynamics. \n\n\n\n## Methods \n  \n### Participants \n  \nThis study was part of a randomized controlled trial (RCT) of cognitive-behavioral therapy (CBT) for SAD, and data from participants in this RCT have been published in other baseline brain papers [ , ]. Participants included 27 (12 women) unmedicated (minimum of three months since stopping pharmacotherapy) adults who met   DSM-IV-TR  [ ] criteria for primary generalized SAD and 27 (13 women) HC with no lifetime history of psychiatric disorders (Table\u00a0 ). As reported in Ziv et al. [ ], patients were recruited through clinician referrals and advertisements on community and online bulletin boards. Two PhD-level clinical psychologists assessed each potential participant using the Anxiety Disorders Interview Schedule for   DSM-IV-TR Lifetime version (ADIS-IV-L  ) [ ]  .   Only patients who met clinical diagnostic criteria for a principal diagnosis of current generalized SAD (defined as greater than moderate anxiety/fear for five or more distinct social situations) or HC with no current or past history of DSM-IV disorders were eligible for participation. \n  \nDemographic and clinical variables \n  \n P   <0.0001. \n\nLSAS-SR\u2009=\u2009Liebowitz Social Anxiety Scale - Self-Report. \n  \nPatients and HC did not differ significantly in age or years of education (see Table\u00a0 ). All participants were right-handed as assessed by the Edinburgh Handedness Inventory [ ]. Potential patients were excluded if they reported current pharmacotherapy or psychotherapy, history of neurological disorders, and current psychiatric disorders (other than SAD, generalized anxiety disorder, agoraphobia without a history of panic attacks, dysthymia, or specific phobia). HC were not permitted to meet criteria for any current or past psychiatric disorders. \n\nAmong patients, current Axis-I co-morbidity included two with panic attacks, two with generalized anxiety disorder, two with dysthymia, and two with specific phobia. Past Axis-I co-morbidity included six with major depression, one with post-traumatic stress disorder, four with substance abuse, and one with eating disorder. Thirteen patients reported past (that is, ended >1\u00a0year ago) non-cognitive-behavioral psychotherapy, and seven reported past pharmacotherapy. The study was approved by the Stanford Medical Research Institutional Review Board (Protocol ID #79403). All participants provided informed consent in accordance with Stanford University Human Subjects Committee rules. \n\n\n### Clinical assessment \n  \nTo assess social anxiety symptom severity, participants completed the Liebowitz Social Anxiety Scale-Self-Report (LSAS-SR) [ ]. This questionnaire assesses both fear and behavioral avoidance of social situations, and is widely used in the research of SAD [ ]. \n\nTo provide greater sensitivity, from 67 patients who were eligible for the study, we selected a subgroup of 27 SAD patients with the highest social anxiety symptom severity (range of LSAS-SR scores for the whole group: 66\u2013102; and for the subgroup: 85\u2013102). We compared this SAD subgroup to a group of 27 healthy controls. \n\n\n### Experimental tasks \n  \nThe three fMRI tasks have been described previously by Ziv et al. [ ]. The tasks were composed of \u2018React\u2019 and \u2018Reappraise\u2019 conditions. Prior to scanning, participants were trained in how to react and to reappraise with stimuli not used in the MR scanner tasks. The instructions for the \u2018React\u2019 condition were to react normally without any attempt to control, modify, or regulate any reactions. During the \u2018Reappraise\u2019 condition, participants were instructed to try and down regulate negative emotion reactions by actively reinterpreting the meaning of the emotion inducing stimulus. We used reappraisal methods developed by Ochsner et al. [ ]. \n\nAfter each trial, participants provided a negative emotion rating using a button response pad positioned in the participant\u2019s right hand inside the magnet by responding to \u2018How negative do you feel?\u2019 (1\u2009=\u2009not at all to 5\u2009=\u2009very much). All tasks were programmed in Eprime (Psychology Software Tools, Inc.). \n\n#### Faces task \n  \nThis task consisted of 24 trials during which the participants viewed color photos of faces displaying Ekman facial action coded anger and contempt facial expressions [ ]. Each trial consisted of a cue (Look or Reframe) lasting 1.5\u00a0s, a single harsh facial stimulus presented in color and appearing to move closer to the participant to simulate looming (every 3\u00a0s over a total of 9\u00a0s), and a negative emotion rating after the face stimulus terminated (3\u00a0s) (Figure\u00a0 a). The length of the entire task was 516 TRs, which is 12\u00a0min and 54\u00a0s (774\u00a0s). Participants were trained prior to the baseline scan to either react to the faces by engaging in the picture (\u2018Just let yourself feel\u2019) and thinking: \u2018This person is upset with me; angry with me\u2019, or to reappraise their emotion, for example by thinking: \u2018Maybe this person just had a bad day\u2019. \n  \n The three socio-emotional tasks. (a)   Looming harsh faces (Faces);   (b)   Social criticism (Criticism);   (c)   Negative self-beliefs (Beliefs). Each task was composed of \u2018React\u2019 and \u2018Reappraise\u2019 trials, which consisted of: (1) a 1.5-s \u2018Cue\u2019; (2) a socio-emotional stimulus (a looming harsh face/ a video-clip of an actor delivering social criticism/ an autobiographical sentence\u2009+\u2009negative self-beliefs); and (3) a negative emotion rating scale. Participants were instructed to either react normally to the stimuli without any attempt to control, modify, or regulate their reactions (\u2018React\u2019), or to try and down regulate negative emotion reactions by actively reinterpreting the meaning of the emotion inducing stimulus (\u2018Reappraise\u2019). \n  \n\n#### Criticism task \n  \nThe task consisted of videotaped actors delivering social criticism and social praise and harsh or happy evaluation-congruent facial expressions (Figure\u00a0 b). The stimuli were delivered by five male and five female actors (seven Anglo-Americans and three Asian-Americans), with an age range of 23 to 50\u00a0years. In each trial the participants were asked to either \u2018Just Watch\u2019 or \u2018Reframe\u2019 their reaction (1.5\u00a0s) during the social evaluation video clip (12\u00a0s). Each video clip had a 4.5-s waiting period during which the actor silently maintained a neutral facial expression followed by a 7.5-s evaluation period in which the actor delivered a social criticism or praise statement while displaying a harsh or positive facial expression. For the current study, only the 7.5-s evaluation period of the social criticism trials were included in the analysis. After each video clip, participants were cued to rate their current negative emotion (3\u00a0s). Each condition consisted of 16 trials delivered across two runs of 342 TRs, 8\u00a0min 35\u00a0s each (513\u00a0s). Participants were trained on the instructions prior to scanning. Participants were told to react to the social criticism by reflecting on how the statement represents something true about themselves, or to reappraise their emotion, for example by thinking: \u2018this is not always true\u2019, or \u2018this is only a thought, not a fact\u2019. \n\n\n#### Beliefs task \n  \nThis task consisted of five situations. The first was an experimenter-composed neutral situation that was used to obtain baseline emotion ratings for reading neutral statements. The neutral situation was followed by four participant-generated autobiographical social anxiety situations that were characterized by social anxiety, humiliation, and/or embarrassment. Prior to scanning session, participants composed a single paragraph describing the events, thoughts, and feelings for each situation, and provided situation-specific negative self-beliefs (NSBs). At the scanner, the participants were asked to either React to the negative self-beliefs, or to Reframe their reaction. \n\nThree situations were presented in a first run lasting 374 TRs, 9\u00a0min 21\u00a0s (561\u00a0s), followed by two situations in a second run of 256 TRs, 6\u00a0min 24\u00a0s (534\u00a0s). Each situation consisted of an instruction to react/reframe (1.5\u00a0s), 16 sentences (3\u00a0s each,) in white font against a black background describing the situation, 10 NSBs (9\u00a0s each) embedded in the unfolding story in uppercase letters that flashed nine times (850\u00a0ms on\u2009+\u2009150\u00a0ms off), and a negative emotion rating after each NSB (3\u00a0s) (Figure\u00a0 c). Participants were trained prior to scanning to react to the NSBs by reflecting on how the NSB represents something that is true about themselves, or to reappraise their reaction by thinking of a positive coping statement that directly challenges the thoughts (\u2018try to re-interpret the statement so it is less negative and toxic for you\u2019). \n\n\n\n### Image acquisition \n  \nInformation about the fMRI image acquisition and data preprocessing have been described previously by Ziv et al. [ ]. We used a General Electric 3-T Signa magnet with a T2*-weighted gradient echo spiral-in/out pulse sequence [ ] and a custom-built quadrature \u2018dome\u2019 elliptical bird cage head-coil (GE Healthcare, Milwaukee, WI, USA). Head movements were minimized using a bite-bar and foam padding. Functional volumes (516 for faces, 684 for criticism, 630 for belief tasks) were obtained from 22 sequential axial slices (repetition time\u2009=\u20091500\u00a0ms, echo time\u2009=\u200930\u00a0ms, flip angle\u2009=\u200960\u00b0, field of view\u2009=\u200922\u00a0cm, matrix\u2009=\u200964\u2009\u00d7\u200964, single-shot, resolution\u2009=\u20093.438\u00a0mm \u2009\u00d7\u20094.5\u00a0mm). Three-dimensional high-resolution anatomical scans were acquired using a fast spin-echo spoiled gradient recall (resolution\u2009=\u20090.8594\u00a0mm \u2009\u00d7\u20091.5\u00a0mm; field of view\u2009=\u200922\u00a0cm, frequency encoding\u2009=\u2009256). \n\n\n### FMRI data preprocessing \n  \nWe used Analysis of Functional Neuroimages (AFNI) software [ ] for preprocessing and statistical analysis. Preprocessing included an analysis of potential outliers, volume registration to a base image, motion correction, 4\u00a0mm  isotropic Gaussian spatial smoothing, high-pass filtering (0.011\u00a0Hz), linear detrending, and conversion into BOLD signal percentage change in each voxel. In addition, the first four images of each functional run were excluded, to allow for T2* equilibration effects. For the Criticism and Belief tasks, the two functional runs were concatenated prior to statistical analysis. No volumes demonstrated motion in the x, y, or z directions in excess of \u00b11\u00a0mm. There was no evidence of stimulus-correlated motion, as assessed by correlations between condition-specific reference functions and x, y, z motion correction parameters. \n\n\n### fMRI statistical analysis \n  \nMultiple-regression implemented with AFNI 3dDeconvolve included baseline parameters to remove mean, linear, and quadratic trends, and motion-related variance in the BOLD signal. Regressors for the React and Reappraise conditions were convolved with the Cohen\u2019s gamma variate model of the hemodynamic response function [ ]. Functional MRI BOLD signal intensity was computed as percentage of signal change, an effect size measure [(MR signal per voxel per time point/mean MR signal in that voxel for the entire functional run)\u2009\u00d7\u2009100]. \n\nIndividual brain maps were converted to Talairach atlas space [ ] and second-level group statistical parametric maps were produced according to a random-effects model. To correct for multiple comparisons, AlphaSim, a Monte Carlo simulation bootstrapping program in the AFNI library, was used to protect against false positives [ ]. This method uses a voxel-wise and cluster volume joint-probability threshold to establish a cluster-wise false-positive cluster detection level. The cluster statistical threshold for the between-group analyses consisted of a voxel-wise   P   <0.005 and cluster volume >244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ) to protect against false-positive cluster detection at   P   <0.01. \n\nTo examine differential responses in BOLD signal magnitude, we conducted a whole-brain 2 Group (SAD, HC) between-group t-test of Reappraise   versus   React in SAD   versus   HC. To identify common responses, we ran a one-sample t-test of Reappraise   versus   React in SAD, and separately in HC. \n\nTo further examine the between-group differences in the BOLD responses during reappraisal, we ran between-group t-tests for early (first three time points, 0 to 4.5\u00a0s) and late (last two/three time points, 4.5 to 7.5\u00a0s or 4.5 to 9\u00a0s) BOLD responses for the contrast of Reappraise   versus   React. This analysis was conducted in each of the brain regions showing a between-group difference, and had several sub-steps: (1) creating masks from each of the clusters surviving the threshold of the between-group t-test, separately for each task; (2) extracting the percent signal change from each of these regions, at the individual subject level, for the Reappraise condition and for the React condition; (3) calculating the percent signal change for Reappraise minus React; (4) averaging (for each subject) the percent signal change for the first three time points, and for the last three time points; and (5) running between-group t-tests (SAD   versus   HC) separately for the early and late averaged responses, for each task. \n\nIn a secondary analysis, we examined brain regions showing BOLD responses common to SAD and HC across the three tasks, and ran between-group t-tests on the contrast of Reappraise   versus   React, for early and late responses, separately, for each task. \n\n\n\n## Results \n  \n### Faces task \n  \n#### Behavioral responses: negative emotion ratings \n  \nA between-group t-test revealed no significant differences (  P   >0.23) in percent reduction in negative emotion between HC (30\u00a0%) and SAD (23\u00a0%) when reappraising faces (Additional file  : Figure S1a). \n\n\n#### Brain responses: BOLD signal magnitude \n  \n##### Differential responses \n  \nCompared to HC, patients had lesser reappraisal-related BOLD responses in the left inferior frontal gyrus (IFG), dorsal anterior cingulate cortex (dACC), and left lateral orbitofrontal cortex (LOFC) (Figure\u00a0 a). \n  \n Faces task: brain responses during Reappraise     versus     React in SAD and HC. (a)   Differential BOLD responses in patients with SAD   versus   healthy controls (HC\u2009>\u2009SAD). 1\u2009=\u2009left inferior frontal gyrus, 2\u2009=\u2009dorsal ACC, 3\u2009=\u2009left lateral orbitofrontal cortex.   (b)   Common BOLD responses in patients with SAD and healthy controls. 1\u2009=\u2009left cuneus, 2\u2009=\u2009left lingual gyrus, 3\u2009=\u2009left parahippocampus, 4\u2009=\u2009left middle temporal gyrus, 5\u2009=\u2009left precentral gyrus, 6\u2009=\u2009dorsomedial PFC. Statistical threshold for BOLD responses: t-value threshold \u22652.93, voxel   P   <0.005, minimum cluster volume threshold \u2265244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ), cluster-wise   P   <0.01. \n  \n\n##### Common responses \n  \nSeparate one-sample t-tests of Reappraise   versus   React demonstrated increased BOLD responses in both groups in bilateral cuneus, precuneus, lingual gyrus, and hippocampus, and in left middle temporal gyrus, left precentral gyrus, and dorsomedial PFC (Figure\u00a0 b). See Table\u00a0  for both differential and common responses. \n  \n Faces task: differential and common BOLD responses for Reappraise     versus     React  \n  \nRegions showing increased BOLD response during Reappraise   versus   React in both SAD and HC (common responses) are marked in italics. \n\nNote.   t  -value threshold \u22652.932, voxel   P   <0.005, minimum cluster volume threshold \u2265244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ), cluster   P   <0.01. \n\nBA\u2009=\u2009Brodmann area, xyz\u2009=\u2009Talairach and Tournoux coordinates of maximum BOLD signal intensity voxel. \n  \n\n\n#### Brain responses: BOLD signal temporal dynamics \n  \nTo examine between-group differences in the BOLD responses during reappraisal, we conducted between-group t-tests for early (first three time points; 0\u20134.5\u00a0s) and late (last three time points; 4.5-9\u00a0s) BOLD responses for the Reappraise   versus   React contrast in the left IFG, dACC, and left LOFC. Between-group t-tests revealed a significantly greater late responses in HC, compared to SAD, in the left IFG (mean HC\u2009=\u20090.09   vs.   mean SAD\u2009=\u2009-0.03, t \u2009=\u2009-3.70,   P   <0.0005) and the dACC (mean HC\u2009=\u20090.07   vs  . mean SAD\u2009=\u2009-0.11, t \u2009=\u2009-3.26,   P   <0.002), with no between-group differences in early responses (Figures\u00a0 a, b). For the left LOFC, a between-group t-test showed that, compared to SAD, HC had greater early (mean HC\u2009=\u20090.09   vs  . mean SAD\u2009=\u2009-0.05, t \u2009=\u2009-2.34,   P   <0.02) and late (mean HC\u2009=\u20090.13   vs  . mean SAD\u2009=\u2009-0.09, t \u2009=\u2009-5.10,   P   <0.0001) responses for the Reappraisal   versus   React contrasts (Figure\u00a0 c). \n  \n Faces task: temporal dynamics of the BOLD response during Reappraise     versus     React in SAD and HC.   Asterisks represent a significant between-group difference in the average of the first three time points (early) or last three time points (late) BOLD responses.   (a)   Left inferior frontal gyrus;   (b)   Dorsal ACC;   (c)   Left lateral orbitofrontal cortex. \n  \n\n\n### Criticism task \n  \n#### Behavioral responses: negative emotion ratings \n  \nA between-group t-test revealed a trend towards greater percent reduction in negative emotion ratings for HC (23\u00a0%, SD\u2009=\u200918) than SAD (14\u00a0%, SD\u2009=\u200917; t \u2009=\u2009-1.93,   P   <0.059) when reappraising criticism (Additional file  : Figure S1b). \n\n\n#### Brain responses: BOLD signal magnitude \n  \n##### Differential responses \n  \nCompared to HC, patients had lesser reappraisal-related BOLD responses in bilateral fusiform gyrus, left lingual gyrus, left putamen, and right cerebellum (Figure\u00a0 a). \n  \n Criticism task: brain responses during Reappraise     versus     React in SAD and HC. (a)   Differential BOLD responses in patients with SAD   versus   healthy controls (HC\u2009>\u2009SAD). 1\u2009=\u2009left fusiform gyrus, 2\u2009=\u2009right fusiform gyrus, 3\u2009=\u2009left putamen, 4\u2009=\u2009left lingual gyrus, 5\u2009=\u2009right cerebellum.   (b)   Common BOLD responses in patients with SAD and healthy controls. 1\u2009=\u2009right precuneus, 2\u2009=\u2009dorsomedial PFC, 3\u2009=\u2009left dorsolateral PFC. Statistical threshold for BOLD responses: t-value threshold \u22652.93, voxel   P   <0.005, minimum cluster volume threshold \u2265244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ), cluster-wise   P   <0.01. \n  \n\n##### Common responses \n  \nSeparate one-sample t-tests of Reappraise   versus   React demonstrated increased BOLD responses in both groups in the right precuneus, dorsomedial PFC, and left dorsolateral PFC (Figure\u00a0 b). See Table\u00a0  for both differential and common responses. \n  \n Criticism task: differential and common BOLD responses for Reappraise     versus     React  \n  \nRegions showing increased BOLD response during Reappraise   versus   React in both SAD and HC (common responses) are marked in italics. \n\nNote.   t  -value threshold \u22652.93, voxel   P   <0.005, minimum cluster volume threshold \u2265244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ), cluster   P   <0.01. \n\nBA\u2009=\u2009Brodmann area, xyz\u2009=\u2009Talairach and Tournoux coordinates of maximum BOLD signal intensity voxel. \n  \n\n\n#### Brain responses: temporal dynamics \n  \nTo examine the between-group differences in the BOLD signal timing during reappraisal, we conducted between-group t-tests for early (first three time points; 0\u20134.5\u00a0s) and late (last two time points; 4.5-7.5\u00a0s) BOLD responses for the Reappraise   versus   React conditions in left and right fusiform gyrus, left lingual gyrus, left putamen, and right cerebellum. \n\nBetween-group t-tests revealed a significant greater early response in HC, compared to SAD, in the left (mean HC\u2009=\u20090.03   vs  . mean SAD\u2009=\u2009-0.09; t \u2009=\u2009-2.20,   P   <0.03) and right (mean HC\u2009=\u20090.05   vs  . mean SAD\u2009=\u2009-0.19, t \u2009=\u2009-2.78,   P   <0.008) fusiform gyrus. For the left lingual gyrus, there were no early or late significant between-group differences (All   Ps  \u2009>\u20090.26). Significant increased late response in HC, compared to SAD, was found in the left putamen (mean HC\u2009=\u20090.05, mean SAD\u2009=\u2009-0.05, t \u2009=\u2009-2.88,   P   <0.006). Time course analyses for the right cerebellum showed both early (mean HC\u2009=\u20090.05   vs  . mean SAD\u2009=\u2009-0.15, t \u2009=\u2009-2.32,   P   <0.03) and late (mean HC\u2009=\u20090.05   vs  . mean SAD\u2009=\u2009-0.15, t \u2009=\u2009-2.22,   P   <0.03) increased responses in HC, compared to SAD, during reappraisal (Figure\u00a0 a-e) . \n  \n Criticism task: temporal dynamics of the BOLD response during Reappraise     versus     React in SAD and HC.   Asterisks represent a significant between-group difference in the average of the first three time points (early) or last two time points (late) BOLD responses.   (a)   Left fusiform gyrus;   (b)   Right fusiform gyrus;   (c)   Left lingual gyrus;   (d)   Left putamen;   (e)   Right cerebellum. \n  \n\n\n### Beliefs task \n  \n#### Behavioral responses: negative emotion ratings \n  \nA between-group t-test revealed greater percent reduction in negative emotion ratings for HC (31%, SD\u2009=\u200916.2) than SAD (19%, SD\u2009=\u200919; t49\u2009=\u2009-2.52,   P   <0.02) when reappraising beliefs (Additional file  : Figure S1c). \n\n\n#### Brain responses: BOLD signal magnitude \n  \n##### Differential responses \n  \nCompared to HC, patients had lesser BOLD responses in the left superior temporal gyrus (STG) (Figure\u00a0 a). \n  \n Beliefs task: brain responses during Reappraise     versus     React in SAD and HC. (a)   Differential responses in patients with SAD   versus   healthy controls (HC\u2009>\u2009SAD). 1\u2009=\u2009left superior temporal gyrus.   (b)   Common BOLD responses in patients with SAD and healthy controls. 1\u2009=\u2009dorsomedial PFC. Statistical threshold for BOLD responses: t-value threshold \u22652.93, voxel   P   <0.005, minimum cluster volume threshold \u2265244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ), cluster-wise   P   <0.01. \n  \n\n##### Common responses \n  \nSeparate one-sample t-tests of Reappraise   versus   React demonstrated increased response in both groups in the dorsomedial PFC (Figure\u00a0 b). See Table\u00a0  for both differential and common responses. \n  \n Beliefs task: differential and common BOLD responses for Reappraise     versus     React  \n  \nRegions showing increased BOLD response during Reappraise versus React in both SAD and HC (common responses) are marked in italics. \n\nNote.   t  -value threshold \u22652.93, voxel   P   <0.005, minimum cluster volume threshold \u2265244\u00a0mm  (6 voxels\u2009\u00d7\u20093.438\u00a0mm ), cluster   P   <0.01. \n\nBA\u2009=\u2009Brodmann area, xyz\u2009=\u2009Talairach and Tournoux coordinates of maximum BOLD signal intensity voxel. \n  \n\n\n#### Brain responses: temporal dynamics \n  \nTo examine between-group differences in the BOLD responses during reappraisal of beliefs, we conducted between-group t-tests for early (first three time points; 0\u20134.5\u00a0s) and late (last three time points; 4.5-9\u00a0s) BOLD responses for the Reappraise   versus   React conditions in the left STG. This analysis revealed a significant increased late response in HC, compared to SAD (mean HC\u2009=\u20090.02   vs  . mean SAD\u2009=\u2009-0.09, t \u2009=\u2009-3.52,   P   <0.0009) (Figure\u00a0 ). \n  \n Beliefs task: temporal dynamics of the left STG BOLD responses during Reappraise     versus     React in SAD and HC.   Asterisks represent a significant between-group difference in the average of the last three time points (late) BOLD responses. \n  \n\n\n### Secondary analyses \n  \nExamination of the reappraisal-related brain responses common for SAD and HC revealed only one region, the dorsomedial PFC (DMPFC), which showed reappraisal-related increased activity in both groups, in all three tasks (Figure\u00a0 ). To examine the temporal dynamics of the BOLD response, and its potential association with between-group differences, we conducted two between-group t-tests: one for early and one for late BOLD responses during the Reappraise   versus   React conditions in this region, separately for each task. \n  \n Dorsomedial PFC BOLD responses during the three socio-emotional tasks.   The dorsomedial PFC (DMPFC) showed increased activity in both patients with SAD and HC, during reappraisal of faces, criticism, and beliefs. \n  \nThere were no significant between-group differences in early or late responses for the contrast of Reappraise   versus   React Faces (  P  s >0.08) and Criticism (  P  s >0.26) (Figure\u00a0 a,b). However, for Beliefs, compared to HC, patients had lesser late BOLD responses (mean HC\u2009=\u20090.17, mean SAD\u2009=\u20090.07, t \u2009=\u2009-2.12,   P   <0.04) (Figure\u00a0 c). \n  \n Temporal dynamics of the dorsomedial PFC BOLD responses during Reappraise     versus     React Faces (a), Criticism (b), and Beliefs (c) in SAD and HC.   No significant between-group differences were found in early or late DMPFC activity when reappraising faces and criticism. A significant between-group difference was found in late DMPFC activity when reappraising beliefs (P <0.04). \n  \nGreater late DMPFC responses were associated with greater reduction in negative emotion ratings in SAD patients (r\u2009=\u20090.42,   P   <0.04), but not HC (r\u2009=\u2009-0.32,   P  \u2009=\u20090.13; Zdiff\u2009=\u20092.52,   P   <0.05) (Figure\u00a0 ). \n  \n Beliefs task: association between dorsomedial PFC BOLD responses during Reappraise     versus     React and percent reduction in negative emotion ratings.   When reappraising beliefs, DMPFC BOLD responses were positively correlated with % reduction in negative emotion ratings in SAD patients (r\u2009=\u20090.42,   P   <0.04). \n  \n\n\n## Discussion \n  \nWe tested the hypothesis that dysfunctional emotion regulation processes in SAD patients are associated with altered reappraisal-related activity in prefrontal brain regions. We focused on both BOLD signal magnitude and temporal dynamics during reappraisal of three different socio-emotional stimuli in patients with SAD   versus   healthy controls. Results suggest distinct behavioral and neural effects related to each of the socio-emotional tasks. \n\n### Behavioral correlates of reappraisal in SAD \n  \nBehaviorally, the results of this study indicated a smaller percent reduction of negative emotion in patients with SAD compared to HC, but only during the reappraisal of idiographic social anxiety-related negative self-beliefs. Though it has long been thought that patients with SAD have problems with down regulating negative emotions [ , , , ], the behavioral findings in our study suggest a more nuanced picture of deficits in reappraisal. Specifically, the emotion regulation deficits were most pronounced when facing the negative self-beliefs. These idiographic stimuli, each linked to autobiographical social anxiety-related situations, are highly potent - in our previous report [ ], using the same stimuli and the same sample, negative self-beliefs were associated with the greatest increase in negative emotion, compared to faces and criticism, in both SAD and HC. This suggests greater emotional effect for these stimuli, which might be related with the difficulty in down regulating its associated negative emotions. \n\nOur finding is partially in line with the results of the one other study examining cognitive regulation of negative self-beliefs in SAD [ ]. In that study, although no difference was found between patients and controls in the amount of reappraisal-related reduction of negative emotion, greater social anxiety symptom severity was associated with lesser down regulation of negative emotion in patients, suggesting that severity of social anxiety contributes to deficits in cognitive reappraisal of negative beliefs. \n\n\n### Neural correlates of reappraisal in SAD \n  \nNeurally, based on the prior findings in patients with SAD [ , ] and non-clinical populations [ ], we hypothesized that, relative to HC, patients would have reduced recruitment of PFC regions during reappraisal. The between-group analyses partially confirmed our hypothesis. While there was PFC activation during reappraisal in both patients and controls during all three tasks, between-group differential PFC activation was found only during the reappraisal of faces, with no differential PFC responses when reappraising beliefs and criticism. \n\n#### Reappraisal of looming harsh faces \n  \nWhen reappraising faces, compared to HC, patients had reduced activity in a PFC network that included left IFG, dACC, and lateral OFC. In these regions, time course analyses revealed greater BOLD response during the second half of the trial in HC compared to patients. This increased late responses in HC when reappraising looming harsh faces might be related to integrated cognitive processes that rely on linguistic (left IFG), cognitive control/attention (dACC), and evaluation/response selection (lateral OFC) processes [ ]. In patients, the reduced late recruitment of prefrontal regulatory brain regions suggests deficits in reappraisal processes, especially of faces displaying contempt, anger, or disapproval. The use of harsh faces as an emotional probe in patients with SAD has ecological validity given that SAD is characterized by fear of interpersonal situations and a tendency to avoid eye contact [ ]. Cognitive behavioral models of social anxiety suggest that patients with SAD manifest increased attentional focus on others\u2019 facial expressions and negative evaluation during social situations [ ]. Supporting the models, behavioral studies have reported that patients with SAD tend to remember critical faces better than accepting ones [ ], and scan faces with a different pattern of eye movements than is used by healthy controls [ ]. The results of the current study accord with these models of social anxiety and extend the current theory by suggesting a delayed regulatory deficit in SAD. \n\n\n#### Reappraisal of social criticism \n  \nDuring reappraisal of criticism, the left putamen exhibited increased reappraisal-related activity in HC, compared to SAD, during the second half of the trials. Previous studies implicated the putamen as involved in implicit learning, and specifically in prediction of future reward [ ]. Recently, the left putamen was shown to be active when participants had to explicitly mirror observed emotional facial expressions [ ]. The authors of this study suggested that the putamen is involved in the establishment of a successful social connection with another person. In the current study, it might be that HC, but not patients, were able to form a relatively more positive (or less negative) interpretation of the social feedback delivered by the actor following the reappraisal instruction. For patients with SAD, difficulties implementing cognitive reappraisal might make it harder for them to relate to the person in the video clip in a positive way, and prevent them from seeing the social situation as a potential rewarding event. \n\nInterestingly, time course analyses of the fusiform gyrus, lingual gyrus, and cerebellum responses revealed that the between-group differences derived less from increased reappraisal-related responses in HC, and more from increased reactivity-related responses in patients with SAD. These results are in line with electrophysiological studies demonstrating early hyper-vigilance followed by attentional avoidance in adults with SAD when facing social threat stimuli [ ]. Overall, this result confirms previous findings of increased activity in visual attention-related regions in SAD when reacting to social relevant stimuli [ ]. \n\n\n#### Reappraisal of autobiographical negative self-beliefs \n  \nDuring reappraisal of beliefs, the between-group results indicated increased reappraisal-related activity in the left STG in healthy controls. The STG also manifested a late activity peak for HC, compared to SAD. The STG is related to social cognition, namely, the ability to attribute mental states to the self and others. During cognitive reappraisal, attending to one\u2019s own emotional state or to those of others is crucial to be able to monitor the process of changing the affective state [ ]. Thus, greater activity in this region in HC, compared to patients, might be associated with the patients\u2019 reduced ability to regulate their cognitions when facing their self-created negative self-beliefs. \n\n\n\n### Temporal dynamics of reappraisal \n  \nAcross the three tasks, the results of the temporal dynamics analyses converged, showing greater reappraisal-related neural responses in HC, compared to SAD, during the late reappraisal period. In the one previous paper that examined the temporal dynamics of neural responses during reappraisal, findings indicated greater reappraisal-related neural responses in HC, compared to HC, during the early reappraisal period [ ]. That study utilized one of the three tasks reported in the current paper (negative self-beliefs) and tested reappraisal processes using similar reappraisal training methods. However, while the current study focused on between-group effects of the contrast of reappraise   versus   react, separately in the early and late responses, the goal of the previous study was to examine linear decreases in emotional reactivity and increases in regulatory responses during the whole 9-s trial. Thus, the previous study used linear regression to examine linear changes in BOLD responses over time, and compared early   versus   late BOLD responses on each trial, separately for reappraise and for react, in SAD compared to HC. In the present study, we ran between-group t-tests for early and late responses separately, but contrasted the reappraise and react conditions. In addition to these differences in data analytic approaches, the previous study examined one task, while three different contexts were tested in the current paper. Despite these dissimilarities, the results of both studies clearly suggest different timing of the brain responses in SAD and HC during reappraisal. The idea that differences in the temporal dynamics of the brain response are a key factor in regulation processes is consistent with recent findings by Goldin and colleagues, who showed changes in the timing of the BOLD responses in patients with SAD following an 8-week mindfulness-based stress reduction program, and following 16 sessions of individual CBT for SAD [ ]. \n\n\n### Task independent reappraisal responses \n  \nFor each task separately, examination of reappraisal-related BOLD responses common to patients and HC revealed a task-specific network of regions. These regions are implicated in visual attention (cuneus, precuneus, lingual gyrus), working memory (dorsolateral PFC), cognitive regulation (dorsomedial PFC), memory (hippocampus), and language (left MTG, left precentral gyrus) processes, which all take part during reappraisal. Of these regions, the dorsomedial PFC was the only region showing increased activity for both HC and patients during all three tasks. \n\nThe DMPFC has been implicated in multiple cognitive functions, including strategic evaluation, introspection, and decision-making [ - ]. In the present study, though no group differences in DMPFC BOLD signal magnitude were found, time course analyses revealed increased late DMPFC activity in healthy controls, compared to SAD patients, when reappraising negative self-beliefs. This finding accords well with the study by Bruhl and colleagues [ ], which found comparable MPFC activity in SAD patients who applied reality-checking to negative stimuli and in SAD patients who just perceived the stimuli with no regulation attempts. The researchers suggested that the lack of increased recruitment of MPFC activity due to cognitive control might point to deficits in emotion regulation processes in SAD. \n\nThis idea that the lack of additional recruitment of MPFC could be an important neural correlate of emotion regulation deficits in SAD is supported by the results of the current study, and more specifically by the convergence between the neural and behavioral findings: compared to SAD, HC manifested both greater late DMPFC activity, and greater percent reduction in negative emotion ratings, when reappraising negative self-beliefs. In addition, in patients with SAD, greater late DMPFC responses were associated with greater reduction in negative emotion ratings. Thus, decreased DMPFC activity in SAD might be associated with reduced emotion regulation capability, and consequently to reduced ability to down regulate negative reactivity. \n\n\n\n## Conclusions \n  \nThe present study found reduced late BOLD responses in PFC regions in SAD, compared to healthy controls, when reappraising harsh faces. In addition, reduced late responses in the DMPFC in patients with SAD, compared to controls, were related to less reduction in negative emotion ratings when reappraising negative self-beliefs. Together, these results suggest deficient cognitive reappraisal processes in SAD. Importantly, these results indicate that probes with different stimulus dimensions (visual/linguistic, static/dynamic, general/idiographic) are associated with different reappraisal-related behavioral and brain responses. While reappraisal of faces was associated with increased prefrontal activity in HC when compared to patients with SAD, but with no between-group behavioral effects, reappraisal of beliefs was associated with less ability to down regulate negative emotions in patients, compared to HC, with much less robust between-group neural differences. It is important for future research to specifically examine which of these stimulus dimensions could be the most informative in studying reappraisal processes in SAD. \n\nThe results of this study suggest that when cued, patients with SAD do try to implement cognitive reappraisal, but their efforts are less efficient, leading to less than optimal emotional relief. Though reappraisal training is a crucial part of CBT for SAD, our results emphasize the importance of teaching patients how to improve the effectiveness of their reappraisal efforts. Mastering more adaptive regulation processes will help patients with SAD reduce the negative emotions they experience. \n\nAn interesting question arising from this study is whether, when no external cue exists, patients use cognitive reappraisal less frequently than healthy controls. To answer this question, future studies may examine the extent to which patients with SAD activate un-cued implicit emotion regulation, compared to healthy controls, in addition to examining the associated brain regions that are activated during implicit,   versus   explicit, emotion regulation processes. \n\nOne possible limitation of the current study is the specificity of the stimuli that were chosen to evoke negative emotional response. Because of the social nature of these stimuli, these stimuli were probably more emotionally evocative for patients than for HC. Future studies could examine whether regulatory deficits in SAD, behaviorally and in the brain, are specific to socially-related stimuli, or whether this is a more general deficit. \n\nFinally, the current findings stress the importance of performing analyses that elucidate neural temporal change. Here we focused on temporal dynamics of cognitive reappraisal. However, when a patient with SAD enters a social situation, many other regulatory processes such as rumination, attention deployment, and expression suppression are activated. Although the theory suggests that distinct forms of emotion regulation have their own neural circuitry and temporal features [ ], in SAD, the temporal dynamics of the BOLD response in regulatory brain regions are still not well understood. Future studies could examine brain activity related to different regulatory processes, taking place at different points in the emotion-generative process. \n\n\n## Endnote \n  \nThe increased reappraisal-related activity during criticism was found in two clusters identified as the left fusiform gyrus (1. x,y,z\u2009=\u2009-24, -68, -12, voxel size\u2009=\u200916; 2. x,y,z\u2009=\u2009-45, -65, -16, voxel size\u2009=\u20096) and in three clusters identified as the right cerebellum (1. x,y,z\u2009=\u20093, -68, -9, voxel size\u2009=\u200912; 2. x,y,z\u2009=\u200924, -51, -16, voxel size\u2009=\u20097; 3. x,y,z\u2009=\u200917, -58, -12, voxel size\u2009=\u20097). All demonstrated similar pattern of temporal dynamics. For simplicity, we report here only the effects of the biggest cluster in each region (16 voxels for the left fusiform, 12 voxels for the right cerebellum). \n\n\n## Competing interests \n  \nThe authors declare that they have no competing interests. \n\n\n## Authors\u2019 contributions \n  \nMZ participated in the study\u2019s design and coordination, contributed to data acquisition, conducted the fMRI sessions, conducted the data analyses, and took the lead on writing the manuscript. PRG helped conceive of the design of the study, participated in the study\u2019s design and coordination, contributed to data acquisition, conducted the fMRI sessions, consulted on data analyses, and contributed to writing the manuscript. HJ participated in the study\u2019s design and coordination, contributed to data acquisition, conducted the fMRI sessions, consulted on data analyses, and contributed to writing the manuscript. KSH consulted on data analyses, and contributed to writing the manuscript. JJG helped conceive of the design of the study, consulted on data analyses, and contributed to writing the manuscript. All authors have read and approved the final manuscript. \n\n\n## Supplementary Material \n  \n \n\n# Table(s)\n## ID: T1\n### Label: Table 1\nUnnamed: 0_level_0\tSAD\tHC\tt-value\tPartial eta2\nUnnamed: 0_level_1\tn\u2009=\u200927\tn\u2009=\u200927\tUnnamed: 3_level_1\tUnnamed: 4_level_1\nWomen (n)\t12\t13\t\t\nAge (mean years\u2009\u00b1\u2009SD)\t31.1\u2009\u00b1\u20097.6\t32.6\u2009\u00b1\u20099.5\t0.6\t\nEducation (mean years\u2009\u00b1\u2009SD)\t16.3\u2009\u00b1\u20092.3\t17.5\u2009\u00b1\u20091.5\t2.0\t\nEthnicity\tEthnicity\tEthnicity\tEthnicity\tEthnicity\n- Caucasian\t12\t17\t\t\n- Asian\t5\t8\t\t\n- Latino\t6\t2\t\t\n- Native American\t1\t0\t\t\n- Native Hawaiian\t1\t0\t\t\n- Filipino\t1\t0\t\t\n- African American\t1\t0\t\t\nLSAS-SR (Mean\u2009\u00b1\u2009SD)\t99.3\u2009\u00b1\u200911.8\t15.3\u2009\u00b1\u20099.1\t29.21\t0.94\n### Caption\nDemographic and clinical variables\n### Footer\n1P <0.0001.LSAS-SR\u2009=\u2009Liebowitz Social Anxiety Scale - Self-Report.\n\n\n## ID: T2\n### Label: Table 2\nUnnamed: 0_level_0\tx y z\tVol (mm3)\tt-value\nBetween-group differential responses\tBetween-group differential responses\tBetween-group differential responses\tBetween-group differential responses\nSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React-none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React-none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React-none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React-none\nHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\nLeft inferior frontal gyrus\t-34, 25, 15\t426\t3.56\nDorsal anterior cingulate gyrus\t0, 18, 33\t372\t3.46\nLeft lateral orbitofrontal cortex\t-31, 52, -6\t372\t3.63\nWithin-group responses1\tWithin-group responses1\tWithin-group responses1\tWithin-group responses1\nSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\nRight cuneus\t3, -82, 39\t57,444\t3.39\n(Left cuneus, bilateral precuneus, bilateral lingual gyrus, bilateral parahippocampal gyrus)\t3, -82, 39\t57,444\t3.39\nLeft superior temporal gyrus BA38\t-48, 28, -19\t3,191\t3.30\nLeft Superior Temporal Gyrus BA21\t-65, -20, -2\t1,330\t3.76\nLeft dorsomedial PFC\t-3, 11, 63\t1,330\t3.38\nLeft precentral gyrus BA6\t-52, -3, 29\t1,170\t3.61\nRight middle temporal gyrus BA21\t55, -3, -9\t1,117\t3.64\nLeft putamen\t-21, 4, 5\t1,117\t4.26\nRight superior temporal gyrus BA38\t45, 21, -16\t1,011\t3.56\nLeft inferior frontal gyrus BA45\t-55, 31, 8\t532\t3.09\nLeft superior temporal gyrus\t-65, -13, -2\t479\t3.72\nLeft thalamus\t-14, -13, -8\t426\t4.05\nRight thalamus\t14, -13, 12\t426\t4.15\nRight superior temporal gyrus\t38, 7, -12\t372\t3.12\nLeft middle temporal gyrus\t-55, -10, -9\t372\t3.75\nHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\nLeft lingual gyrus\t-3, -58, 5\t67,125\t7.08\n(Right lingual gyrus, bilateral cuneus, bilateral precuneus, bilateral parahippocampus)\t-3, -58, 5\t67,125\t7.08\nLeft dorsomedial PFC\t-3, 4, 63\t3,191\t3.73\nLeft precentral gyrus BA4/6\t-55, -3, 50\t1,808\t3.21\nLeft supramarginal gyrus BA40\t-65, -48, 19\t1,011\t3.83\nLeft superior temporal gyrus\t-55, -17, -2\t798\t5.05\nLeft inferior frontal gyrus\t-52, 25, -6\t745\t3.62\nLeft superior temporal gyrus BA22\t-62, -34, 12\t745\t3.10\nRight superior temporal gyrus BA38\t41, -24, 1\t691\t3.53\nLeft superior temporal gyrus BA38\t-52, 14, -9\t585\t3.40\nRight precentral gyrus BA6\t62, 4, 19\t426\t3.69\nLeft middle temporal gyrus\t-55, -6, -6\t426\t4.69\n### Caption\nFaces task: differential and common BOLD responses for Reappraise versus React\n### Footer\n1Regions showing increased BOLD response during Reappraise versus React in both SAD and HC (common responses) are marked in italics.Note. t-value threshold \u22652.932, voxel P <0.005, minimum cluster volume threshold \u2265244\u00a0mm3 (6 voxels\u2009\u00d7\u20093.438\u00a0mm3), cluster P <0.01.BA\u2009=\u2009Brodmann area, xyz\u2009=\u2009Talairach and Tournoux coordinates of maximum BOLD signal intensity voxel.\n\n\n## ID: T3\n### Label: Table 3\nUnnamed: 0_level_0\tx y z\tVol (mm3)\tt-value\nBetween-group differential responses\tBetween-group differential responses\tBetween-group differential responses\tBetween-group differential responses\nSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\nHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\nLeft fusiform gyrus\t-24, -68, -12\t904\t3.16\nRight cerebellum\t3, -68, -9\t745\t3.01\nRight fusiform gyrus\t24, -75, -12\t585\t4.13\nLeft putamen\t-28, -13, -6\t479\t2.96\nLeft lingual gyrus\t-7, -75, -12\t426\t3.28\nRight cerebellum\t24, -51, -16\t372\t2.94\nRight cerebellum\t17, -58, -12\t372\t3.04\nWithin-group responses1\tWithin-group responses1\tWithin-group responses1\tWithin-group responses1\nSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\nLeft dorsomedial PFC\t-3, 11, 60\t2,500\t4.27\nLeft dorsolateral PFC\t-48, 7, 50\t1,170\t3.59\nRight precuneus\t17, -55, 63\t745\t3.36\nRight parahippocampal gyrus\t24, -44, -6\t372\t3.25\nHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\nLeft lingual gyrus\t-3, -58, 5\t13,936\t3.21\n(Right lingual gyrus, bilateral fusiform gyrus, bilateral cerebellum)\t-3, -58, 5\t13,936\t3.21\nRight precentral gyrus BA6/BA4\t28, -17, 63\t9,308\t3.14\nLeft dorsomedial PFC\t-3, 11, 67\t6,915\t3.34\nLeft dorsolateral PFC\t-52, 4, 50\t3,776\t3.83\nLeft supramarginal gyrus\t-62, -58, 15\t3,351\t4.09\nLeft middle frontal gyrus\t-45, 21, 29\t2,234\t3.42\nRight superior parietal cortex/precuneus\t24, -55, 60\t2,128\t3.31\nLeft superior parietal cortex/precuneus\t-24, -75, 53\t1,808\t4.18\nLeft inferior frontal gyrus BA45\t-55, 25, -2\t1,755\t3.25\nLeft medial frontal gyrus\t-3, 7, 43\t1,170\t3.15\nRight precuneus\t28, -72, 22\t1,064\t3.45\nLeft superior temporal gyrus\t-65, -174, -2\t1,064\t3.79\nLeft middle frontal gyrus\t-31, 49, 12\t851\t3.14\nLeft precuneus\t-31, -89, 19\t745\t3.34\nLeft anterior insula\t-48, 11, 5\t745\t3.53\nLeft precentral gyrus BA4\t-24, -24, 56\t691\t3.56\nLeft thalamus\t-3, -3, 12\t638\t3.34\nLeft angular gyrus\t-48, -61, 36\t585\t3.12\nLeft superior temporal gyrus\t-38, -55, 29\t319\t3.38\nLeft putamen\t-31, -10, -2\t319\t3.28\nLeft middle temporal gyrus\t-52, -34, 5\t319\t3.33\n### Caption\nCriticism task: differential and common BOLD responses for Reappraise versus React\n### Footer\n1Regions showing increased BOLD response during Reappraise versus React in both SAD and HC (common responses) are marked in italics.Note. t-value threshold \u22652.93, voxel P <0.005, minimum cluster volume threshold \u2265244\u00a0mm3 (6 voxels\u2009\u00d7\u20093.438\u00a0mm3), cluster P <0.01.BA\u2009=\u2009Brodmann area, xyz\u2009=\u2009Talairach and Tournoux coordinates of maximum BOLD signal intensity voxel.\n\n\n## ID: T4\n### Label: Table 4\nUnnamed: 0_level_0\tx y z\tVol (mm3)\tt-value\nBetween-group differential responses\tBetween-group differential responses\tBetween-group differential responses\tBetween-group differential responses\nSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\tSAD\u2009>\u2009HC: Reappraise\u2009>\u2009React - none\nHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\tHC\u2009>\u2009SAD: Reappraise\u2009>\u2009React\nLeft superior temporal gyrus BA41\t-58, -13, 12\t585\t2.96\nWithin-group responses1\tWithin-group responses1\tWithin-group responses1\tWithin-group responses1\nSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\tSAD only: Reappraise\u2009>\u2009React\nLeft dorsomedial PFC\t-3, 7, 60\t1,596\t3.16\nLeft inferior frontal gyrus BA45\t-55, 25, 8\t638\t3.81\nLeft dorsolateral PFC\t-41, 7, 50\t638\t3.57\nHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\tHC only: Reappraise\u2009>\u2009React\nLeft dorsomedial PFC\t-3, 11, 63\t1,170\t3.09\n### Caption\nBeliefs task: differential and common BOLD responses for Reappraise versus React\n### Footer\n1Regions showing increased BOLD response during Reappraise versus React in both SAD and HC (common responses) are marked in italics.Note. t-value threshold \u22652.93, voxel P <0.005, minimum cluster volume threshold \u2265244\u00a0mm3 (6 voxels\u2009\u00d7\u20093.438\u00a0mm3), cluster P <0.01.BA\u2009=\u2009Brodmann area, xyz\u2009=\u2009Talairach and Tournoux coordinates of maximum BOLD signal intensity voxel.\n", "metadata": {"pmcid": 4029608, "text_md5": "0ebc62fe75c773bd82df17aa9e1c4173", "field_positions": {"authors": [0, 92], "journal": [93, 117], "publication_year": [119, 123], "title": [134, 243], "keywords": [257, 332], "abstract": [345, 2373], "body": [2382, 49464], "tables": [49477, 57285]}, "batch": 2, "pmid": 24517388, "doi": "10.1186/2045-5380-3-20", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029608", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4029608"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029608\">4029608</a>", "list_title": "PMC4029608  Emotion regulation in social anxiety disorder: behavioral and neural responses to three socio-emotional tasks"}
{"text": "Kaplan, Raphael and Horner, Aidan J and Bandettini, Peter A and Doeller, Christian F and Burgess, Neil\nHippocampus, 2014\n\n# Title\n\nHuman hippocampal processing of environmental novelty during spatial navigation\n\n# Keywords\n\namygdala\nfMRI\nMTL\ncontent\ncontext\n\n\n# Abstract\n \nThe detection and processing of novel information encountered as we explore our environment is crucial for learning and adaptive behavior. The human hippocampus has been strongly implicated in laboratory tests of novelty detection and episodic memory, but has been less well studied during more ethological tasks such as spatial navigation, typically used in animals. We examined fMRI BOLD activity as a function of environmental and object novelty as humans performed an object-location virtual navigation task. We found greater BOLD response to novel relative to familiar environments in the hippocampus and adjacent parahippocampal gyrus. Object novelty was associated with increased activity in the posterior parahippocampal/fusiform gyrus and anterior hippocampus extending into the amygdala and superior temporal sulcus. Importantly, whilst mid-posterior hippocampus was more sensitive to environmental novelty than object novelty, the anterior hippocampus responded similarly to both forms of novelty. Amygdala activity showed an increase for novel objects that decreased linearly over the learning phase. By investigating how participants learn and use different forms of information during spatial navigation, we found that medial temporal lobe (MTL) activity reflects both the novelty of the environment and of the objects located within it. This novelty processing is likely supported by distinct, but partially overlapping, sets of regions within the MTL. \n \n\n# Body\n \n## INTRODUCTION \n  \nWhen exploring our environment, we must react to changes in our overall surroundings, but also simultaneously detect the novel content located within our environment. How the brain processes these different forms of novelty is not fully understood. A prime candidate for a role in novelty detection is the hippocampus ( ;  ;  , ; Kumaran and  ; for reviews see  ;  ;  ), an area normally associated with human mnemonic function (e.g., Scoville and  ; see Eichenbaum and  ;   for review). However, it is unclear from human and rodent models of the hippocampal system whether the hippocampus preferentially encodes novel content or contexts. Some studies in humans have found that the hippocampus responds to individual novel stimuli (e.g.,  ;  ,b;  ), while others have reported novel pictures/contexts/object pairings eliciting hippocampal activation ( ;  ;  ). \n\nHuman intracranial EEG and fMRI data and studies in animal models have also implicated other medial temporal lobe (MTL) regions with mixed results. The perirhinal cortex was found to respond to novel objects and also stimuli pairings in humans ( ,  ) and novel object identification in nonhuman primates and rodents ( ; for review see Brown and  ). Previous studies have found pre-rhinal/parahippocampal cortex responses to novel contexts across species ( ;  ;  ), but one study did find parahippocampal cortex responses to object novelty ( ) that could be related to its hypothesized role in retrieving individual representations of a context (see   for review). Although the amygdala is most commonly activated in fMRI paradigms using affective and reward-related stimuli ( ;  ;  ), studies have also implicated the amygdala in detection of novel objects both in humans ( ;  ;  ) and rodents ( ;  ;  ). Consequently, it is unclear how different MTL structures might process novel objects and environments during a naturalistic spatial learning task. \n\nWe examined the effects of environmental and object novelty on fMRI activity during a virtual spatial memory paradigm, similar to tasks used with rodents (see also  ,  ;  ), see  . Participants used a button box to navigate a first person perspective within virtual environments. Within each session, they learned the locations of six objects encountered within the environment, over four trials per object. In the replacement phase of the experiment, they were then cued by a picture of an object, replaced in the environment and had to navigate to the object's location, for one trial per object. Each session in a novel environment was followed by a session in the same (now familiar) environment. Three of the objects encountered in a session were new to that session and three had been encountered before in a different environment (see  ). \n  \nExperimental Structure. A: Experimental environments shown from the participants' (first-person) perspective. Four different environments are presented in eight experimental sessions. The first two sessions (always the desert environments) provided practice outside of the scanner. Sessions 3\u20138 contained three novel-familiar environment repetitions with environment order, counterbalanced across participants. B: Learning phase trial structure. During learning trials, participants use a button box to navigate and \u201ccollect\u201d three novel and three familiar (previously presented) objects (vase shown as example) four times each (a total of 24 trials per session). C: The object replacement phase, trial structure. After being cued for 3 s with a picture of an object that had been collected in the learning phase of the current session, participants were placed back in the environment and had to navigate to where they thought the object (object replacement) had been located during that learning period. [Color figure can be viewed in the online issue, which is available at  .] \n  \n\n## MATERIALS AND METHODS \n  \n### Participants \n  \nTwenty male participants (mean age years = 23.9; SD = 3.7 years; range = 18\u201333) gave written consent and were compensated for performing the experimental task, as approved by the local Research Ethics Committee at University College London. All participants were right-handed with normal or corrected-to-normal vision and reported to be in good health with no prior history of neurological disease. Two participants were excluded from the fMRI analyses because of scanner malfunction. \n\n\n### Stimuli, Task, and Trial Structure \n  \nAs in  , the experiment was composed of eight sessions. The first two sessions were practice sessions in the same virtual desert environment, conducted on a laptop outside the MRI scanner. The participants familiarized themselves with the environment by navigating around and then collecting objects in the environment by running into them and then being tested on their previous location. These practice sessions lasted for \u223c2\u20133 min. \n\nDuring the fMRI sessions, an individual trial consisted of a participant being randomly placed in an environment and having to navigate towards an object to collect it and to remember its location (mean duration 9.04 s per trial; SD = 3.12s). Participants had four trials to learn the location for each of the six objects interleaved in a set of 24 trials. Next participants were presented with a gray screen with a crosshair for 4 s between trials. After the learning phase was completed, there was a 30 s inter-phase rest period, when instructions on the next phase (object replacement phase) were presented. The object replacement phase for the location of each of the six collected objects started with a 3 s period in which an object was presented on a gray background (cue phase). Participants were then placed at a random location in the environment and told to navigate to the spot where they believed the pictured object had been located (mean duration = 12.41 s; SD = 4.14 s). They then pressed a button to indicate its previous location. Once the button was pressed, the ITI period would begin again for 4 s. \n\n\n### Procedure and Design \n  \nParticipants were instructed that they were going to navigate through a virtual environment over multiple sessions using a button box, and that they would have to pick up several different objects (six) in the environment, four times each (three objects, three times each for the two practice sessions). The order of trials was randomized (but unknown to participants) separated into three miniblocks. Object location never changed within a session. After they completed this learning phase, they were tested in an object replacement period, described above. \n\nDuring the fMRI portion of the experiment, a new environment was presented and then represented at the next session as a familiar environment. This occurred on four occasions (three in the fMRI component), so that half of the eight environments were novel (refer to  A). Each environment arena had the same area, but had its own unique shape (square, circle, triangle, and rectangle) and texture (desert, grass, snow, and rocky textures; refer to  ) to differentiate the environments. \n\nParticipants were presented with counterbalanced familiar or novel objects within each environment. Following the practice sessions, the objects presented in an environment were comprised of objects that the participants had either collected (\u201cfamiliar\u201d) or not collected (\u201cnovel\u201d) in a previous session. Familiar objects were always from different environments in the fMRI experiment and the first familiar objects were introduced during the practice session outside of the scanner. \n\n\n### fMRI Acquisition \n  \nFunctional images were acquired on a 3T Siemens Trio scanner. Blood oxygenation level dependent (BOLD) T2*-weighted functional images were acquired using a gradient-echo EPI pulse sequence acquired obliquely at 45\u00b0 with the following parameters: repetition time, 3,360 ms; echo time, 30 ms; slice thickness, 2 mm; interslice gap, 1 mm; in-plane resolution, 3 \u00d7 3 mm; field of view, 64 \u00d7 72 mm ; 48 slices per volume. A field-map using a double echo FLASH sequence was recorded for distortion correction of the acquired EPI ( ). After the functional scans, a T1-weighted 3-D MDEFT structural image (1 mm ) was acquired to co-register and display the functional data. \n\n\n### fMRI Data Analysis \n  \nFunctional images were processed and analyzed using SPM8 ( ). The first five volumes were discarded to allow for T1 equilibration. Standard preprocessing included correction for differences in slice acquisition timing, realignment/unwarping to correct for interscan movement, and normalization of the images to an EPI template (specific to our sequence and scanner) that was aligned to the T1 MNI template. Finally, the normalized functional images were spatially smoothed with an isotropic 8 mm full-width half maximum Gaussian kernel. For all models, all regressors, with the exception of the movement parameters, were convolved with the SPM hemodynamic response function. Data were also high-pass filtered (cut-off period = 128 s). \n\nStatistical analyses were performed using a general linear model within SPM8 with a block design for navigation periods during the learning phase, where we compared those navigation trial blocks to the blocks of adjacent intertrial intervals (ITI) to remove effects of slow variations in BOLD signal. Each fMRI session was modeled with seven regressors of interest, (1) navigation to novel objects during learning, (2) navigation to familiar objects during learning, (3) navigation with novel object cues during object replacement, (4) navigation with familiar object cues during object replacement, (5) novel object cue periods, and (6) familiar object cue periods, and (7) the ITI. Each trial was modeled as a boxcar function lasting the length of the navigation period (i.e., the length of time the participant took to \u201cpick up\u201d or \u201cdrop\u201d the object for that specific trial). Although we explicitly modelled the cue periods, they were not used in our subsequent analyses, because of the low number and brief duration of trials. Each session included a further six \u201cmovement\u201d' regressors estimated during realignment. \n\nSix sessions were modeled, three relating to novel environments and three to familiar environments. This resulted in eight main conditions of interest (at both learning and object replacement; although objects were cued beforehand and not visible within an environment during object replacement): novel objects in a novel environment during the learning phase, familiar (previously seen) objects in a novel environment during the learning phase, novel objects in a familiar environment during the learning phase, familiar objects in a familiar environment during the learning phase, novel objects in a novel environment during the replacement phase, familiar objects in a novel environment during the replacement phase, novel objects in a familiar environment during the replacement phase, familiar objects in a familiar environment during the replacement phase. Each condition was contrasted with the session specific ITI prior to second-level analyses. From these conditions of interest, we ran an omnibus test to look at novelty effects during learning and replacement phases, which equated to a 2 \u00d7 2 \u00d7 2 (Experimental Phase \u00d7 Environmental Novelty \u00d7 Object Novelty) factorial design. \n\nA further analysis split the learning phase into four quartiles (for each of the four object presentations, i.e., first\u2013fourth presentations during the learning phase), to assess changes in novelty across encoding trials, resulting in 16 regressors (plus movement parameters). The six objects were repeatedly presented across four mini-blocks (first\u2013fourth presentations), so that object presentation quartiles also coincided with the first quartile-fourth quartile of trials in a novel or familiar environment. Using a one-way ANOVA for first\u2013fourth quartiles for each condition of interest, we investigated significant linear decreases over time for both novel versus familiar environments and objects. \n\nData were high-pass filtered (cut-off period = 128 s). Based on strong a priori hypotheses related to MTL involvement in novelty processing and use of a similar fMRI paradigm ( , ;  ), we report activations surviving an uncorrected statistical threshold of   P =   0.001 and cluster threshold   k   = 5 for the whole brain. Since we are using an uncorrected statistical threshold, we also report whether the peak voxel of MTL activations survive small-volume correction (SVC) for multiple comparisons (FWE p<.05) using a bilateral MTL mask encompassing the amygdala, hippocampus, and parahippocampal gyrus constructed in the automated anatomical labeling (AAL) toolbox for SPM ( ). Coordinates of brain regions are reported in MNI space. Post-hoc statistical analyses were conducted using 10 mm radius spheres in MarsBar ( ) toolbox within SPM8 around the respective peak voxel specified in the corresponding results section to compare activity in one region across different conditions (e.g., to determine whether an object novelty effect was present in a region defined by the main effect of environmental novelty, or vice versa). \n\n\n\n## RESULTS \n  \n### Behavioral Results \n  \nTo assess behavioral performance, we looked at the distance error between where participants had indicated an object was during the object replacement phase and where it was actually located in the environment. Behavior was generally in line with past studies using this paradigm ( ). The average length of navigation trials was 9.04 s (SD = 3.12 s) during the learning phase and 12.41 s (SD = 4.14 s) during the test phase. There were converse effects of environmental and object novelty on navigation time during the learning phase with more time spent navigating in novel versus familiar environments (  P   = 0.024; F(1,19) = 5.993) and less time spent navigating toward novel versus familiar objects (  P   = 0.01;F(1,19) = 8.272). However, there was no significant interaction between effects of object and environmental novelty on navigation times (  P   = 0.598; F(1,19) = 0.288). During the object replacement phase there were no significant differences in navigation trial times between novel versus familiar environments (  P   = 0.670; F(1,19) = 0.187), novel versus familiar objects (  P   = 0.395; F(1,19) = 0.758), or any interaction between effects of object and environmental novelty (  P   = 0.552; F(1,19) = 0.367). See Table  for group means. \n  \nBehavioral Data by Condition \n  \nThere were no significant performance differences between memory (i.e., 1/distance error) for novel versus familiar object locations (  P   = 0.268; F(1,19) = 1.31), or object locations in novel versus familiar environments (  P   = 0.281; F(1,19) = 1.23; see Table  for group means). In line with our effect showing significant longer exploration durations for familiar versus novel objects, there was significantly enhanced performance for learning the location of novel versus familiar objects in novel environments (  P   = 0.049,   t  (19) = 2.11; see Table  for group means). These findings are similar to previous behavioral findings showing proactive interference, where participants have impaired performance and need to spend more time learning object locations of \u201cfamiliar\u201d objects that were associated with a location in a previous environment ( ). Over the course of the experiment, participants displayed a significant linear trend towards spending less time navigating during learning (  P   = 0.024; F(1,19) = 6.00) and test (  P   = 0.017; F(1,19) = 6.86) trials in later experimental sessions (see Table  for group means). Participants also performed better in later sessions, exhibiting a marginal linear trend toward improved performance (increased 1/distance error) over sessions (  P   = 0.089; F(1,19) = 3.191; see Table  for group means). \n  \nBehavioral Data by Session \n  \n\n### fMRI Results \n  \n#### Environmental novelty \n  \nWe used a 2 \u00d7 2 \u00d7 2 ANOVA (Object \u00d7 Environment \u00d7 Phase) to test whether there were significant differences for object and environmental novelty processing during learning and object replacement phases. When contrasting navigation in novel versus familiar environments (collapsed across learning and replacement phases), the strongest increase across the whole brain was in the medial temporal lobe, with a peak in the left posterior hippocampus/parahippocampal gyrus (  x   = \u221230;   y   = \u221228;   z   = \u221214;   Z  -score = 4.65; SVC FWE   P   = 0.001; see  A and Table ) and another subpeak that was part of the same cluster in the anterior hippocampus (  x   = \u221227;   y   = \u221219;   z   = \u221217;   Z  -score = 3.56). \n  \nEnvironmental and object novelty during the navigation task. A: Left hippocampal activity corresponding to environmental novelty during navigation (above; peak voxel:   x   = \u221230;   y   = \u221228;   z   = \u221214;   Z  -score = 4.65; including both learning and object replacement phases). Percent signal change in a 10 mm sphere around the left hippocampal peak for all four conditions (navigating toward or replacing novel or familiar objects within novel or familiar environments, below, showing mean \u00b1 SEM over the 18 participants). B: Left anterior hippocampal activity, extending into the amygdala and superior temporal sulcus, corresponding to object novelty during navigation (above, peak voxel:   x   = 39;   y   = \u221240;   z   = \u221214;   Z  -score = 3.81). Percent signal change in a 10 mm sphere around the left anterior hippocampal peak for all four conditions (below, mean \u00b1 SEM). C: Left parahippocampal/fusiform activity corresponding to object novelty during navigation (above, peak voxel:   x   = 39;   y   = \u221240;   z   = \u221214;   Z  -score = 4.10). Percent signal change in a 10 mm sphere around the left parahippocampal/fusiform peak for all four conditions (mean \u00b1 SEM). D: Right ventral pallidum activity corresponding to the interaction between environmental novelty and experimental phase (left; peak voxel:   x   = 15;   y   = \u221210;   z   = \u22128;   Z  -score = 4.34; left ventral pallidum and midbrain/VTA effects visible in axial slice). Percent signal change in a 10 mm sphere around the right ventral pallidal peak during navigation in novel versus familiar environments during the learning and replacement phases (mean \u00b1 SEM). All activations are shown at the uncorrected threshold of   P   < 0.001 for display purposes and overlaid on the Montreal Neurological Institute 152 T1 image. [Color figure can be viewed in the online issue, which is available at  .] \n    \nMain Effect of Environmental Novelty \n  \nIn a post-hoc statistical analysis based on 10 mm spheres around the peak hippocampal voxel for environmental novelty, the left posterior hippocampus cluster also responded to object novelty (  F   = 7.584;   P   = 0.014), but no interaction between environmental and object novelty was observed (  F   = 0.019;   P   = 0.892). Despite our posterior hippocampal peak also responding to object novelty, we found that the posterior hippocampus showed a significantly stronger response to environmental novelty than to object novelty [t(17) = 3.350;   P   = 0.004]. We also found increases related to environmental novelty in the left cerebellum, left dorsolateral prefrontal cortex, left angular gyrus, right precuneus, right superior parietal lobule, and right caudate (see Table ). Additionally, subthreshold right hippocampal activations for environmental novelty were observed at   P   < 0.005 uncorrected. A post-hoc paired t-test conducted on data extracted from 10 mm spheres around left and right hippocampus peak voxels did not reveal a significant difference between the left and right hippocampus in their response to environmental novelty [t(17) = 1.515;   P   = 0.148]. There were no significant increases in the brain for environmental familiarity. \n\n\n#### Object novelty \n  \nWe found a main effect for novel versus familiar objects, regardless of environment, in the bilateral parahippocampal/fusiform gyrus that was strongest in the right hemisphere (right peak:   x   = 39;  y   = \u221240;   z   = \u221214;   Z  -score = 4.10; whole-brain cluster-level FWE   P   = 0.002; see  C and Table ). There was also a significant MTL cluster in the left anterior hippocampus (  x   = \u221224;   y   = \u221219;   z   = \u221217;   Z  -score = 3.81; SVC FWE   P   = 0.032; see  B and Table ), which extended into the amygdala and left superior temporal sulcus. Post-hoc statistical analyses measured from a 10 mm sphere around the posterior parahippocampal/fusiform gyrus peak found that it was not sensitive to environmental novelty (  F   = 1.991,   P   = 0.176) and showed no interaction between object and environmental novelty effects (  F   = 1.505;   P   = 0.237). Notably, the anterior hippocampal peak overlapped with the subpeak from the environmental novelty contrast, which was reflected in post-hoc statistical analyses that showed that the anterior hippocampus was also sensitive to environmental novelty (  F   = 6.486;   P   = 0.021), but displayed no interaction between the two novelty effects. Further analyses showed that the anterior hippocampus was not differentially responsive to object novelty or environmental novelty [  t  (17) = 0.766;   P   = 0.454]. We also found significant increases related to object novelty in the cingulate gyrus and right angular gyrus (see Table ). There were no significant increases anywhere in the brain for object familiarity. \n  \nMain Effect of Object Novelty \n  \n\n\n### Novelty \u00d7 Experimental Phase Interactions \n  \nWe did not find any significant interactions in the medial temporal lobe between object novelty and experimental phase, or between environmental novelty and experimental phase. In other words, the MTL object and environmental novelty effects did not differ as a function of learning versus replacement phase. However, an environmental novelty by experimental phase interaction was seen in bilateral ventral pallidum, strongest on the right side (left:   x   = \u221215;   y   = \u22121;   z   = \u221211;   Z  -score = 3.56; right:   x   = 15;   y   = \u221210;   z   = \u22128;   Z  -score = 4.34; see  D). We also found a significant interaction between environmental novelty and experimental phase in the midbrain/ventral tegmental area (VTA;   x   = 3;   y   = \u221219;   z   = \u22125;   Z  -score = 3.57) and right caudate. Notably, environmental novelty related activity was higher in the replacement versus the learning phase in the ventral pallidum and midbrain/VTA, while the caudate showed the opposite effect of being higher in the learning phase than the replacement phase. Additionally, we observed a significant interaction between object novelty and experimental phase in the cerebellum and cingulate gyrus, where object novelty related increases during navigation were higher in the object replacement versus learning phase. \n\n\n### Short-Term Effects of Novelty During Learning \n  \nWe investigated how the above environmental and object novelty effects changed across time during the learning phase. We split learning phases into four quartiles (matching the four repetitions of object-location encoding during the learning phase) and assessed both environmental and object novelty across these quartiles. Searching for a linear decrease of environmental novelty from quartiles 1\u20134 failed to reveal any significant regions in the MTL or neocortex. However, a significant linear decrease in the object novelty effect (i.e., novel \u2013 familiar) from the first to fourth quartile was seen in the left amygdala (peak:   x   = \u221227;   y   = \u22121;   z   = \u221214;   Z  -score = 3.65; uncorrected   P   = 0.000131; FWE SVC   P   =.074), left lateral occipital cortex (peak:   x   = \u221230;   y   = \u221285;   z   = \u221220;   Z  -score = 4.50), left fusiform gyrus (peak:   x   = \u221248;   y   = \u221255;   z   = \u221217;   Z  -score = 3.74), and left posterior parahippocampal cortex (peak:   x   = \u221236;   y   = \u221237;   z   = \u221217;   Z  -score = 3.87). See  . Other areas showing a significant decrease in the object novelty effect from the first to fourth quartile were the bilateral ventrolateral prefrontal cortex, ventromedial prefrontal cortex, left middle temporal gyrus, and right angular gyrus. These analyses add to our original object novelty effects (comparing whole sessions) by revealing several novelty signals that attenuate within each session. By contrast, environmental novelty signals appear to attenuate only over the slower timescale of sessions, perhaps indicating that learning environmental layout is a slower process than some of the short-term effects of object novelty. \n  \nTemporal attenuation of amygdala object novelty effect. Above: Left amygdala activity (peak:   x   = \u221227;   y   = \u22121;   z   = \u221214;   Z  -score = 3.65) corresponding object novelty (novel versus familiar objects) showed a linear decrease over the course of the learning phase as relative novelty decreased. Below: Percent signal change extracted from a 10 mm sphere around the peak left amygdala voxel averaged across 18 participants for novel versus familiar objects for the first to fourth quartile of the learning phase. Activations are shown at the uncorrected threshold of   P   < 0.001 and overlaid on the Montreal Neurological Institute 152 T1 image for display purposes. [Color figure can be viewed in the online issue, which is available at  .] \n  \n\n\n## DISCUSSION \n  \nWe investigated environmental and object novelty during a spatial navigation task. We found environmental and object novelty effects throughout the MTL, including the hippocampus ( ). Environmental novelty effects were seen in the mid-posterior hippocampus, anterior hippocampus, and parahippocampal gyrus. Object novelty effects were seen in the anterior hippocampus, fusiform/parahippocampal gyrus, and amygdala. Notably, the more posterior hippocampal region showed a greater response to environmental than object novelty, while the anterior hippocampus peak responded to both environmental and object novelty. Thus, we provide evidence for distinct, though partially overlapping, MTL networks for processing environmental and object novelty. \n\nOur finding that the anterior hippocampus responds to both object novelty and environmental novelty is consistent with previous fMRI studies showing anterior hippocampal responses to the novelty of a variety of stimuli ( ;  ;  ;  ,b; Kumaran and  ). To our knowledge, our findings are the first to show responses to both environmental and object novelty during goal-directed virtual navigation. However, our results also suggest a partial dissociation within the hippocampus, with more posterior hippocampal regions showing a greater response to environmental novelty than to object novelty. Mid-posterior hippocampal activation related to environmental novelty is consistent with a role in learning environmental layout, including the spatial relations between the various topographical features of the environment (the environmental boundary and the distant mountains). This fits with the known role of the hippocampus in encoding spatial layout (e.g.,  ;  ) and when navigating more accurately ( ;  ). The findings are also consistent with a more general hippocampal role in representing relational information (Eichenbaum and  ) and with rodent studies showing hippocampal involvement in detecting environmental novelty ( ,  ;  ,  ;  ;  ). An important potential research direction will be determining whether the anterior hippocampus might function as a convergence zone ( ) for processing both object/item and environmental/contextual novelty ( ;  ;  ; Ranganath and  ) and how these hippocampal processing distinctions relate to ideas about \u201cnonspatial\u201d and \u201cspatial\u201d processing streams within the MTL ( ). Notably, we did not find any novelty processing differences between learning and object replacement phases in the hippocampus, or the rest of MTL. Future studies can explore how hippocampal sub-regions might process novelty differently depending on whether a subregion needs to either encode or retrieve an item/context. \n\nOutside of the hippocampus, we found that the parahippocampal/fusiform gyrus responded to object novelty and that more anterior parts of the parahippocampal gyrus responded to environmental novelty. Our finding of parahippocampal responses to environmental novelty is in line with previous fMRI findings showing that the parahippocampal cortex responds to novel scenes (Epstein and  ;  ). However, our activation was slightly anterior to the \u201cplace area\u201d regions typically associated with the perceptual processing of environmental scenes, and so may relate more specifically to the learning of environmental layout for the purposes of navigation, and the nearby activation of the hippocampus. In fact, our object novelty activation was located in these more posterior parahippocampal/fusiform regions. We assume that this activation reflects the introduction of a novel navigationally relevant object into posterior parahippocampal representations of the environment (Janzen and van  ;  ). That is, the effect of object novelty in this region reflects the fact that the objects themselves are navigationally relevant components of the wider spatial environment. Nonetheless, fusiform regions are also thought to be involved in representing individual objects ( ;  ; Horner and  ), so the fusiform object-novelty activation may also reflect the learning of novel object representations. \n\nWe also found effects of object novelty in the amygdala. These results parallel previous fMRI findings showing amygdala and anterior hippocampal responses to novelty ( ;  ;  ;  ). They also accord with rodent studies showing that amygdala lesions impair object novelty detection ( ,  ), and with human intracranial recordings showing amygdala (and sometimes anterior hippocampal) responses to novel or surprising events ( ;  ;  ). The amygdala activity during learning was characterized by a linear reduction in response to novel objects across repetitions, with the maximal effect for the first presentation of the object. This rapidly decaying amygdala activation might reflect a temporary novelty-related increase in salience as opposed to our novelty responses over the longer timescale of trials, which we tentatively related to learning. Rapidly attenuating amygdala activations have also been seen in response to emotional/arousing stimuli ( ;  ;  ;  ). \n\nOne caveat for the interpretation of our findings is that we only studied males, to avoid compromising our result with the additional uncontrolled variable of the sexual dimorphism in neural bases of spatial navigation ( ; see   and   for reviews). Gender differences could especially be important for the amygdala and anterior hippocampus results, since hormonal release potentially modulates behavior in these areas during mnemonic function (Strange and  ). Further study will be needed to see if our findings generalize to females, or whether they differ between the sexes. And further replication will be required to corroborate the rapidly attenuating amygdala object novelty effect during the learning phase, which did not pass correction for multiple comparisons. \n\nAlthough our MTL novelty effects did not differ across the learning and replacement phases, we did observe that ventral pallidum and midbrain/VTA BOLD activity was higher during navigation in novel versus familiar environments during the replacement phase, while environmental novelty related activity in the caudate was higher during the learning phase. The ventral pallidum and midbrain/VTA effects are consistent with findings highlighting strong responses in ventral basal ganglia and midbrain/VTA regions for images of novel versus familiar scenes ( ). Our ventral pallidum findings match rodent studies showing this region as a key interchange between limbic and movement-planning circuitry that helps guide goal-directed exploratory movement (Yang and  ; for review see Mogenson and  ), while our caudate findings might relate to the formation of more route-like representations from one object location to another as their locations are learned, consistent with the parallel hippocampal and striatal involvement in the learning of \u201cplaces\u201d and \u201cresponses\u201d (e.g., Packard and  ;  ; White and  ;  ;  ). Although further replication is needed, our results might reflect a potential role for interactions between the MTL and basal ganglia in guiding the memory of novel contexts (see reviews by  ; van der  ) and in disambiguating overlapping routes ( ; Brown and  ). \n\n\n## CONCLUSION \n  \nWe employed a naturalistic virtual reality navigation paradigm to assess how the human brain processes novel environments and their contents (i.e., object-location associations). We found that the anterior hippocampus responded to both environmental and object novelty during navigation, whereas mid to posterior hippocampus preferentially responded to environmental novelty, consistent with a role in representing the layout of a new environment. Our results suggest that the MTL is crucial in processing both object and environmental novelty during spatial navigation and that novelty processing is likely to be supported by a distinct, but partially overlapping, set of regions in the MTL. \n\n \n\n# Table(s)\n## ID: tbl1\n### Label: Table 1\nUnnamed: 0\tNovel object in a novel environment\tFamiliar object in a novel environment\tNovel object in a familiar environment\tFamiliar object in a familiar environment\nMean learning phase navigation time (s)\t9.49 (SD = 3.55)\t10.3 (SD = 4.52)\t7.96 (SD = 2.09)\t8.47 (SD = 2.59)\nMean replacement phase navigation time (s)\t12.19 (SD = 4.03)\t12.86 (SD = 4.87)\t12.26 (SD = 4.22)\t12.36 (SD = 4.36)\nMean performance 1/distance error (virtual meters)\t0.051 (SD = 0.020)\t0.059 (0.025)\t0.060 (SD = 0.025)\t0.058 (SD = 0.024)\n### Caption\nBehavioral Data by Condition\n### Footer\nNone\n\n\n## ID: tbl2\n### Label: Table 2\nUnnamed: 0\tfMRI session 1\tfMRI session 2\tfMRI session 3\tfMRI session 4\tfMRI session 5\tfMRI session 6\nMean learning phase navigation time (s)\t11.6 (SD = 7.96)\t9.26 (SD = 3.57)\t9.31 (SD = 4.11)\t7.73 (SD = 2.23)\t8.67 (SD = 3.10)\t7.66 (SD = 2.90)\nMean replacement phase navigation time (s)\t13.4 (SD = 5.02)\t13.6 (SD = 6.13)\t12.5 (SD = 3.88)\t12.0 (SD = 4.52)\t11.7 (SD = 4.64)\t11.3 (SD = 4.78)\nMean performance 1/distance error (virtual meters)\t0.049 (SD = 0.0262)\t0.056 (SD = 0.0261)\t0.056 (SD = 0.0270)\t0.054 (SD = 0.0268)\t0.060 (SD = 0.0326)\t0.067 (SD = 0.0299)\n### Caption\nBehavioral Data by Session\n### Footer\nNone\n\n\n## ID: tbl3\n### Label: Table 3\nRegion\tx\ty\tz\tZ-score\nL Hippocampus/Parahippocampal Gyrus\t\u221230\t\u221228\t\u221214\t4.65\nL Cerebellum\t\u221215\t\u221252\t\u221238\t3.58\nL Dorsolateral Prefrontal Cortex\t\u221254\t41\t4\t3.56\nL Angular Gyrus\t\u221266\t\u221249\t1\t3.52\nR Precuneus\t27\t\u221279\t16\t3.41\nR Superior Parietal Lobule\t48\t\u221273\t13\t3.4\nR Caudate\t18\t17\t19\t3.26\n### Caption\nMain Effect of Environmental Novelty\n### Footer\nNone\n\n\n## ID: tbl4\n### Label: Table 4\nRegion\tx\ty\tz\tZ-score\nR Parahippocampal/Fusiform Gyrus\t39\t\u221240\t\u221214\t4.1\nL Anterior Hippocampus/Amygdala/Superior Temporal Sulcus\t\u221224\t\u221219\t\u221217\t3.81\nL Parahippocampal/Fusiform Gyrus\t\u221230\t\u221249\t\u22128\t3.77\nCingulate Gyrus\t12\t\u22124\t40\t3.59\nR Angular Gyrus\t39\t\u221264\t19\t3.47\n### Caption\nMain Effect of Object Novelty\n### Footer\nNone\n", "metadata": {"pmcid": 4255751, "text_md5": "b1e66c75b801f950edf744a6580e3dc4", "field_positions": {"authors": [0, 102], "journal": [103, 114], "publication_year": [116, 120], "title": [131, 210], "keywords": [224, 258], "abstract": [271, 1743], "body": [1752, 35058], "tables": [35071, 37033]}, "batch": 2, "pmid": 24550152, "doi": "10.1002/hipo.22264", "pmc_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4255751", "efetch_url": "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4255751"}, "display_title": "pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4255751\">4255751</a>", "list_title": "PMC4255751  Human hippocampal processing of environmental novelty during spatial navigation"}
