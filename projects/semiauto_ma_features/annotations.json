[
{"annotations":[{"end_byte":813,"end_char":801,"label_name":"TaskName","start_byte":788,"start_char":776},{"end_byte":6275,"end_char":6196,"label_name":"TaskDescription","start_byte":5891,"start_char":5818}],"display_title":"pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324609\">5324609</a>","list_title":"PMC5324609  The role of the hippocampus in generalizing configural relationships","metadata":{"batch":1,"doi":"10.1002/hipo.22688","efetch_url":"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5324609","field_positions":{"abstract":[197,1771],"authors":[0,33],"body":[1780,24282],"journal":[34,45],"keywords":[144,184],"publication_year":[47,51],"title":[62,130]},"pmc_url":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324609","pmcid":5324609,"pmid":27933668,"text_md5":"16ef9d7ab42b76b944ac37702a03bbb3"},"text":"Berens, Sam C. and Bird, Chris M.\nHippocampus, 2017\n\n# Title\n\nThe role of the hippocampus in generalizing configural relationships\n\n# Keywords\n\nlearning\nmemory\npattern completion\nfMRI\n\n\n# Abstract\n  ABSTRACT  \nThe hippocampus has been implicated in integrating information across separate events in support of mnemonic generalizations. These generalizations may be underpinned by processes at both encoding (linking similar information across events) and retrieval (“on‐the‐fly” generalization). However, the relative contribution of the hippocampus to encoding‐ and retrieval‐based generalizations is poorly understood. Using fMRI in humans, we investigated the hippocampal role in gradually learning a set of spatial discriminations and subsequently generalizing them in an acquired equivalence task. We found a highly significant correlation between individuals’ performance on a generalization test and hippocampal activity during the test, providing evidence that hippocampal processes support on‐the‐fly generalizations at retrieval. Within the same hippocampal region there was also a correlation between activity during the final stage of learning (when all associations had been learnt but no generalization was required) and subsequent generalization performance. We suggest that the hippocampus spontaneously retrieves prior events that share overlapping features with the current event. This process may also support the creation of generalized representations during encoding. These findings are supportive of the view that the hippocampus contributes to both encoding‐ and retrieval‐based generalization via the same basic mechanism; retrieval of similar events sharing common features. © 2016 The Authors Hippocampus Published by Wiley Periodicals, Inc. \n \n\n# Body\n \nLearning relationships between features within the environment is central to complex behaviors such as navigation (Cohen and Eichenbaum,  ). However, it is often not sufficient to rely on information that was learnt within a single episode. Frequently, memories acquired across multiple episodes must be integrated to allow the expression of novel behaviors (Bunsey and Eichenbaum,  ). Such “memory generalizations” are also fundamental to the formation of the context‐free memory structures that characterize semantic knowledge (Eichenbaum,  ). \n\nThe hippocampus has long been implicated in supporting memory generalization (Bunsey and Eichenbaum,  ). Broadly speaking, there are two classes of model that attempt to describe the role of the hippocampus in generalization. Encoding‐based models propose that when related events are encoded, their representations overlap with each other and therefore contain information that is common to all of the events (Shohamy and Wagner,  ). This results in unitary (or generalized) memory traces where the retrieval of any one detail automatically cues the retrieval of related features. In contrast, retrieval‐based models pose that study events are strictly “pattern separated” at encoding. Nonetheless, these models suggest that the hippocampus can engage “on‐the‐fly” generalization where representational overlaps are inferred during retrieval (e.g., Kumaran and McClelland,  ). \n\nPrevious investigations have provided evidence for both encoding‐ and retrieval‐based accounts of hippocampal generalization (e.g., Shohamy and Wagner,  ; Preston et al.,  ). Indeed, it has been suggested that these models are not mutually exclusive. In particular, the hippocampus may initially form pattern separated representations which gradually become integrated over a period of memory consolidation (Zeithamova et al.,  ). Consolidation is associated with memory traces becoming more dependent on neocortical regions that underlie semantic memory (McClelland et al.,  ). This raises the possibility that generalization may sometimes depend on functions of the neocortex rather than the hippocampus. \n\nTo date, two studies have examined how the hippocampus and neocortex contribute to generalization over the course of both an initial learning phase and a generalization test (Zeithamova and Preston,  ; Zeithamova, et al.,  ). Both have provided good evidence for a mixed encoding/retrieval account. These studies used “relational inference” paradigms where hierarchical or pairwise relationships between stimuli must be inferred from training on a set of “premise pairs.” This contrasts with simpler forms of generalization where novel discriminations are made on the basis that stimuli belong to particular “equivalence classes.” For example, if particular configurations of stimuli are always rewarded, then they belong to the same superordinate class of rewarded items. It remains unclear whether or not generalizations reliant on equivalence class membership depend on hippocampal and/or neocortical involvement at either study or test. We used fMRI to examine the brain mechanisms involved in gradually learning and subsequently generalizing a set of visual discriminations. In particular, we explored whether hippocampal and/or neocortical activity at encoding, retrieval, or both, was associated with generalizations between equivalence classes. \n\nTwenty‐three right‐handed students were recruited by way of online advertisement. All gave written informed consent to take part and were compensated for their time. Subjects had either normal or corrected‐to‐normal vision and reported no history of neurological or psychiatric illness. Of those who participated, eight did not exhibit sufficient levels of learning on the task to be included in the analyses (see below). As such, analyses reported here used data from 15 subjects (7 male) with a mean age of 23.8 years (SD = 4.14). The study was approved by the Brighton and Sussex Medical school's Research Governance and Ethics Committee. \n\nDuring scanning participants learned a set of visual discriminations via trial‐and‐error (learning phase), and were subsequently tested on their ability to generalize what they had learned (generalization phase). Both learning and generalization occurred within a single scanning session and took place in the context of a first‐person virtual reality environment (see Fig.  ). On each trial, a scene was presented depicting two buildings positioned equidistantly from a start location. One building concealed a pile of gold (the “reward”). The location of this gold was determined by the configuration of wall textures rendered onto the towers of each building. Participants were required to select the rewarded building (within 3 s). Following a response, video feedback was presented (7 s) before an inter‐trial interval (1 s). The stimuli for the task were generated in Unreal Development Kit (Epic Games, 2012) and presented via the Cogent 2000 toolbox in MATLAB (Mathworks). \n  \nUpper: Details of the trained and generalized discriminations. Each capitalised letter refers to a unique wall texture as indicated by the three wall texture samples (left). The two tables list how wall textures were combined and which arrangements were rewarded. Each row within a table corresponds to a unique discrimination and vertical bars (i.e. |) indicate spatial arrangements within each building (‘X|Y' indicates ‘X' to the left of ‘Y'). The ‘+' column denotes wall texture combinations that were rewarded while the ‘−' column denotes wall texture combinations that were unrewarded. Note: The reward was equally likely to be in the left or right building. Lower: Example of a trained discrimination within the virtual‐reality reality environment. [Color figure can be viewed at  ] \n  \nThree discriminations were learnt (see Fig.  ). In each discrimination there were two buildings and each building comprised two textures (in other words, each building was a “compound” stimulus). Participants were required to learn not only which combination of textures was rewarded but also which spatial arrangement of textures was rewarded. For example, when texture A appeared with texture B, the building with A to the left of B was rewarded (A|B). However, when texture A appeared with texture C, the building with C to the left of A was rewarded (C|A). This form of “structural” configural learning, which includes a spatial or temporal component, is thought to depend on hippocampal learning mechanisms (Sanderson et al.,  ; Aggleton et al.,  ). There were 48 trials per discrimination which were presented in a pseudorandom order. \n\nThe initial learning phase also included a set of non‐memory discriminations (location of gold visible at trial onset) and a further set of three discriminations that constituted a transverse patterning contingency (see Moses et al.,  ). However, these trials were not subject to a generalization test after leaning and are therefore not discussed in the current study. \n\nThe generalization phase involved 12 test trials. Here each rewarded wall texture configuration was presented alongside an unrewarded configuration that had only ever been trained in the context of a different discrimination (e.g., A|B+ vs. A|C−, see Fig.  ). As such, these trials involved making novel discriminations between stimuli on the basis of an equivalence class membership (rewarded vs. unrewarded). Encoding‐based models of generalization predict that during the initial training phase, participants not only learn specific relationships between texture combinations (A|B+ vs. B|A−), but also the superordinate equivalence classes (A|B+, B|C+, and C|A+ all belong to a rewarded class whereas B|A−, C|B−, and A|C− all belonging to an unrewarded class). Given this, we would expect brain activity during the initial training phase to be correlated with subsequent generalization performance. In contrast, retrieval‐based models predict that generalization depends on recalling trained associations when stimuli are presented in a novel combination. Under this view, we would expect brain activity during the generalization test itself to correlate with generalization performance. Relatively few generalization trials were run to ensure that participants did not develop a well‐practiced response to each trial type. \n\nBehavioral outputs from the task were binary sequences indicating correct versus incorrect responses on each trial. Trials were also coded as incorrect when no response was made within 3 s. For each discrimination of the initial learning phase, these binary sequences were then converted into learning curves using a state‐space smoothing model developed by Smith et al. ( ). This model indicates a “learning trial” defined as the first trial at which there is a significant level of certainty (  P   < 0.05) that a subject is performing above chance and the discrimination has been learnt. All participants included in the sample reached the learning trial for each discrimination at least five trials before the end of training (mean learning trial = 22.56, S.D. = 8.37). \n\nWe wished to group each trial of the experiment into one of four stages based on how many of the three discriminations had been learnt; from “stage 0” (prior to the learning trial of any discrimination), to “stage 3” (after all three discriminations had been learnt). Across participants, the mean (and S.D.) number of trials within each stage were as follows; Stage 0 = 43.33 (23.39), Stage 1 = 23.13 (22.75), Stage 2 = 21.53 (20.50), Stage 3 = 56 (33.79). Importantly, response times did not significantly differ between learning stage;   F  (3,42) = 1.125,   P   = .350. As such, it is unlikely that any BOLD effects coincident with learning stage are a result of differential reaction times. Performance on the 12 generalization trials was taken as the proportion of correct responses. Although each subject included in the analysis showed a high degree of learning on each of the directly trained discriminations, generalization performance was highly variable across subjects; mean proportion correct: 0.73, range 0.33–0.92. \n\nEncoding‐based models of generalization propose that new representations overlap with existing ones, such that the commonalities across different discrimination pairs are also represented. We therefore looked for brain regions where encoding‐related BOLD activity increased linearly with the number of discriminations that had been learnt. This pattern of results would be consistent with the notion that the representation of one discrimination automatically triggers the retrieval of overlapping discriminations that have been learnt by that stage. As an additional and stronger test of encoding‐based models, we carried out a between‐subjects’ analysis to test whether BOLD activity during the final stage of learning (stage 3) correlated with subsequent generalization performance. \n\nThe imaging analyses were performed in SPM8 ( , see Supporting Information for details about the imaging protocols and pre‐processing). Following image pre‐processing, first‐level models of the fMRI data were produced that specified five regressors of interest; four of these modeled the trial onsets within each learning stage (i.e., stages 0–3) and an additional regressor modeled the trial onset of each generalization test trial. Nuisance regressors included motion parameters and a vector coding for drift in the MR signal. HRF amplitude estimates relating to each event of interest were then subject to group‐level analyses. \n\nAt the group level, we specified a mixed‐effects regression model that tested for linear increases in activity across the four learning stages (random intercepts for each subject were also modeled). This revealed four clusters showing the predicted linear increases, each significant after controlling for the family‐wise error rate at the cluster‐level (whole‐brain, map‐wide height threshold was   P   < 0.001); see Table   (upper) and Figure  . An unthresholded statistical image for this contrast can be viewed and downloaded at  . The analysis did not reveal any significant linear increases or decreases in hippocampal BOLD activity when either performing a small volume correction within an bilateral hippocampal ROI (Tzourio‐Mazoyer et al.,  ) or, averaging across all hippocampal voxels,   t  (14) = −1.285,   P   = 0.220. \n  \nLeft panel: Cluster in the left inferior temporal gyrus (ITG) exhibiting linear increases in activity as a function of the number of learnt discriminations. Right panel: Bar chart illustrating the ITG effect. Because the plot shows data selected by a whole‐brain analysis, the bars are a biased representation of the true effect size in this region. Error bars indicate 95% confidence intervals. [Color figure can be viewed at  ] \n    \nClusters Showing Linear Changes in BOLD Activity Across the Four Learning Stages \n  \nFor the clusters exhibiting activation increases as a function of learning stage, we, we next examined whether BOLD activity during stage 3 (i.e., the final stage of learning) was correlated with subsequent generalization performance (across participants). A significant positive association was detected in the inferior temporal gyrus but not in any other cluster,   r  (13) = 0.666,   P   = 0.028 (Bonferroni adjusted for four comparisons). This suggests that the region may be involved in representing overlapping associative information in a manner that supports mnemonic generalizations as specified by encoding‐based models. \n\nRetrieval‐based models of generalization propose that generalizations are carried out “on‐the‐fly” (i.e., during novel tests) when problems cannot be solved by reproducing exactly what has been learnt. We therefore carried out a between‐subjects’ analysis to identify the brain regions that were activated most by individuals who performed best on the generalization test. To examine this, the HRF amplitude estimates relating to generalization test trials were correlated with generalization performance at the second‐level. This revealed one cluster in the right posterior hippocampus showing a positive association (see Fig.  ). This effect was significant after controlling for the family‐wise error rate at the peak level within a bilateral hippocampal ROI (Tzourio‐Mazoyer et al.,  );   r  (13) = 0.861,   P   = 0.011, peak MNI coordinate = [24,−30, −06]). The unthresholded statistical image for this contrast can be viewed and downloaded at  . A Kolmogorov–Smirnov test verified that the assumption of normally distributed errors had been met,   D  (15) = 0.143,   P   > 0.200. However, it is noteworthy that the performance of one subject was numerically below chance (i.e., <0.5) and that this subject yielded a relatively large regression‐residual. As such, we examined whether the hippocampal effect was robust to the removal of this data point. Even after excluding the outlier, the correlation remained significant;   r  (13) = 0.761,   P   < 0.001. No other significant effects were detected. \n  \nCorrelation between generalization performance and right hippocampal activity during the generalization test. [Color figure can be viewed at  ] \n  \nWe next explored whether the hippocampal region identified above showed a BOLD correlation with generalization performance during the final stage of learning (stage 3). A significant positive association was indeed found (  r   = 0.599,   P   = 0.018) suggesting that the region may also play a role in encoding‐based generalization. We further examined whether the hippocampal cluster exhibited linear changes in activity coincident with initial learning. Across the three learning stages, there was a marginally significant decrease in BOLD activity;   t  (44) = −1.98,   P   = 0.054. This latter result neither corroborates or rules out a role for the hippocampus in learning conjunctions between related discriminations, especially given that decreases in hippocampal BOLD may actually reflect successful associative binding (Olsen et al.,  ). \n\nGiven the above, an important possibility is whether the hippocampal generalization effects actually reflect the retrieval of specific reward contingencies rather than a generalization process per se. Indeed, our study was not ideally suited to examine associative generalization since participants could have solved the generalization task by retrieving the value of individual compound stimuli (e.g., A|B is rewarded). This would entail a form of “stimulus” generalization, that is, the extension of a prelearnt response across similar contexts. As such, while we did not detect any significant modulations of hippocampal BOLD over the course learning, it is possible that the hippocampal effects simply reflect better stimulus generalization in participants with the strongest representations of the original contingencies. However, we consider this to be unlikely. Participants’ ability to generalize was uncorrelated with learning rate (as measured by the time to reach stage 3);   r  (13) = 0.19,   P   = 0.498. Furthermore, the hippocampal correlations with generalization at both stage 3 and the generalization test held after controlling for learning rate;   r  (12) = 0.649,   P   = 0.013, and   r  (12) = 0.843,   P   < 0.001 (respectively). Given these findings, we suggest that the hippocampus contributed to generalization performance over and above simply representing the directly trained associations. \n\nThe main focus of this study is on the role of the hippocampus in learning a set of related discriminations and generalizing them on the basis of equivalence class membership. We found no strong evidence for learning‐related BOLD changes within the hippocampus that would be consistent with encoding‐based models of generalization. However, it remains a possibility that the small number of subjects included in our final sample may have limited our ability to detect such effects. Nonetheless, during the generalization test, one hippocampal region showed a robust correlation between BOLD activity and individuals’ ability to generalize. Importantly, the association between generalization performance and hippocampal BOLD was also present in the learning phase after all discriminations had been learnt. This suggests that representations necessary for accurate generalization may have been present in the hippocampus before there was any requirement to make generalizations. Although post‐hoc, this latter finding is partially supportive of an encoding‐based mechanism. \n\nTaken together, the results of our study support a role for the hippocampus in both “on‐the‐fly” generalizations that are computed in novel situations and in generalizations during initial learning where the hippocampus activates information from previous events which share features relevant to the current event. Our results are therefore consistent with proposals that the hippocampus contributes to generalization at both encoding and test via the same fundamental mechanism (Zeithamova and Preston,  ; Zeithamova et al.,  ). \n\nThe region of the hippocampus associated with generalization in our study was midway along its length. Several neuroimaging studies have implicated the anterior hippocampus in generalization (Heckers et al.,  ; Shohamy and Wagner,  ; Schlichting et al.,  ). However, it may be that the site of hippocampal involvement in generalization depends on the nature of the information that must be generalized. It has been argued that the longitudinal axis of the hippocampus is characterized by a functional gradient whereby mnemonic representations that are more local to each other in space or time are coded by more posterior hippocampal regions (see, Strange et al.,  ). Moreover, associations between events that are closely related within a narrative structure may be represented by posterior parts of the hippocampus while associations between more distally related events are represented by anterior regions (Collin et al.,  ). It is therefore possible that the precise locus of hippocampal involvement in generalization depends on the nature of the associations that are being generalized. \n\nOutside of the hippocampus, learning‐related effects were observed in several regions, including two which are strongly implicated in semantic processing (the left angular gyrus [AG] and left inferior temporal gyrus [ITG]). Unlike the hippocampus, the ITG showed activation increases suggestive of gradually learning generalized memory traces. Interestingly, activity in this region also correlated with generalization performance during the initial learning phase. Damage to the ITG results in a loss of semantic knowledge (e.g., Mummery et al.,  ; Schwartz et al.,  ). Given this, we suggest that the left ITG may be responsible for storing integrated memory traces relevant to subsequent generalization. In contrast, the left AG is believed to play a role in matching the conjunctions of perceptual features to specific memory representations (especially in the light of competition from similar, overlapping representations; see Ansari,  ). \n\nWe also observed learning‐related effects in the ventromedial prefrontal cortex (vmPFC). Previous learning and generalization studies have shown that vmPFC activity and its connectivity with the hippocampus correlates with subsequent generalization performance, both during encoding and retrieval (Zeithamova and Preston,  ; Zeithamova et al.,  ). Furthermore, lesions to this region impair the ability to make transitive inferences (Koscik and Tranel,  ). One model suggests that the vmPFC acts to reactivate well‐established memories (i.e., schemas) when they are consistent with incoming information and to integrate new information into memory schemas (Van Kesteren et al.,  ). Thus the vmPFC, working in close association with the hippocampus, is able to create integrated knowledge representations that have been abstracted away from individual events that share common elements (see also, Schlichting and Preston,  ). \n\nTo conclude, our findings support the hypothesis that the hippocampus enables generalization, primarily though retrieving stimuli that share overlapping details. This occurs both in novel situations, when there is an explicit requirement to generalize, but is also present during learning, when similar stimuli might be assigned spontaneously to a superordinate equivalence class. \n\n## Supporting information \n  \n \n","utf8_text_md5_checksum":"16ef9d7ab42b76b944ac37702a03bbb3"},
{"annotations":[{"end_byte":12626,"end_char":12588,"label_name":"TaskName","start_byte":12607,"start_char":12569},{"end_byte":12646,"end_char":12608,"label_name":"TaskName","start_byte":12631,"start_char":12593}],"display_title":"pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8318202\">8318202</a>","list_title":"PMC8318202  Age-Related Differences in Auditory Cortex Activity During Spoken Word Recognition","metadata":{"batch":1,"doi":"10.1162/nol_a_00021","efetch_url":"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=8318202","field_positions":{"abstract":[350,2048],"authors":[0,150],"body":[2057,36320],"journal":[151,172],"keywords":[285,337],"publication_year":[174,178],"title":[189,271]},"pmc_url":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8318202","pmcid":8318202,"pmid":34327333,"text_md5":"8143bd723654bdf1385cf807c530bc44"},"text":"Rogers, Chad S. and Jones, Michael S. and McConkey, Sarah and Spehar, Brent and Van Engen, Kristin J. and Sommers, Mitchell S. and Peelle, Jonathan E.\nNeurobiol Lang (Camb), 2020\n\n# Title\n\nAge-Related Differences in Auditory Cortex Activity During Spoken Word Recognition\n\n# Keywords\n\nspeech perception\ncognitive aging\nspeech production\n\n\n# Abstract\n \nUnderstanding spoken words requires the rapid matching of a complex acoustic stimulus with stored lexical representations. The degree to which brain networks supporting spoken word recognition are affected by adult aging remains poorly understood. In the current study we used fMRI to measure the brain responses to spoken words in two conditions: an attentive listening condition, in which no response was required, and a repetition task. Listeners were 29 young adults (aged 19–30 years) and 32 older adults (aged 65–81 years) without self-reported hearing difficulty. We found largely similar patterns of activity during word perception for both young and older adults, centered on the bilateral superior temporal gyrus. As expected, the repetition condition resulted in significantly more activity in areas related to motor planning and execution (including the premotor cortex and supplemental motor area) compared to the attentive listening condition. Importantly, however, older adults showed significantly less activity in probabilistically defined auditory cortex than young adults when listening to individual words in both the attentive listening and repetition tasks. Age differences in auditory cortex activity were seen selectively for words (no age differences were present for 1-channel vocoded speech, used as a control condition), and could not be easily explained by accuracy on the task, movement in the scanner, or hearing sensitivity (available on a subset of participants). These findings indicate largely similar patterns of brain activity for young and older adults when listening to words in quiet, but suggest less recruitment of auditory cortex by the older adults. \n \n\n# Body\n \n## INTRODUCTION \n  \nUnderstanding spoken words requires mapping complex acoustic signals to a listener’s stored lexical representations. Evidence from neuropsychology and cognitive neuroscience provides increasingly converging evidence about the roles of the bilateral temporal cortex (particularly the superior temporal gyrus and the middle temporal gyrus) in processing speech acoustics and recognizing single words ( ;  ;  ). However, the degree to which the networks supporting spoken word recognition change over our lifetime remains unclear. The goals of the current study were to test whether young and older adults relied on different brain networks during successful spoken word recognition, and whether any age differences were related to the specific task. \n\nImportant themes when considering older adults’ language processing include the degree to which linguistic processing is preserved, and whether older adults may adopt different strategies when understanding language compared to young adults ( ;  ). Particularly important for spoken word recognition is that adult aging frequently brings changes to both hearing sensitivity ( ) and cognitive ability ( ). Thus, it is not surprising that older adults’ spoken word perception differs from that of young adults, particularly in the presence of background noise ( ). Older adults tend to take longer to recognize words ( ;  ), make more recognition errors than young adults, and show increased sensitivity to factors such as the number of phonological neighbors (competitors) associated with a given target word ( ). An open question centers on the brain networks on which older adults rely during spoken word recognition. Of particular interest is whether additional regions may be recruited to support successful recognition, compared to those engaged by young adults. \n\nA number of studies have investigated neural activity during older adults’ speech processing in noise or other acoustic degradation, using an assortment of tasks and testing participants with different levels of hearing ( ;  ;  ;  ;  ).  , for example, examined spoken word recognition in young and older adults. They varied the intelligibility of the target items using low-pass filtering of the acoustic signal. During scanning, participants were asked to repeat back the word they heard. The authors found increased activity in regions associated with word processing, including the auditory cortex and the premotor cortex, when words were more intelligible; these intelligibility-related changes did not statistically differ between young and older adults. Older adults did show more activation in the anterior cingulate cortex and the supplemental motor area than the young adults did, suggesting a possible increase in top-down executive control. \n\nAge differences in speech understanding have also been studied in the context of sentence comprehension. One common finding is that during successful sentence processing, older adults show additional activity compared to young adults (e.g., in contralateral homologs to regions seen in young adults, or in regions beyond the network activated by young adults;  ;  ). These findings have been interpreted in a compensation framework in which older adults are less efficient using a core speech network and need to recruit additional regions to support successful comprehension ( ). However, at least some of this additional activity has been shown to be related to the tasks performed by participants in the scanner, which frequently contain metalinguistic decisions not required during everyday conversation ( ). Thus, it may be that core language computations are well-preserved in aging ( ;  ). \n\nThe role of executive attention in older adults’ spoken word recognition has also been of significant interest. Listening to speech that is acoustically degraded can result in perception errors, after which listeners must re-engage attention systems to support successful listening. The cingulo-opercular network, an executive attention network ( ;  ), shows increased activity following perception errors (similar to error-related activity in other domains). Crucially, when listening to spoken words in background noise, increased cingulo-opercular activity following one trial is associated with recognition success on the following trial ( ;  ), consistent with a role in maintaining task-related attention ( ). \n\nAn important challenge when considering the performance of listeners with hearing loss is that words may not be equally intelligible to all listeners. A common measure of accuracy in spoken word recognition is to ask listeners to repeat each word after hearing it; however, this type of task requires motor responses, which may obscure activations related to speech perception and increase participant motion in the scanner ( ). In addition, differences in the brain regions coordinating speech   production   in older adults ( ;  ) may interfere with clear measurements of activity during perception and recognition. The degree to which motor effects resulting from word repetition may obscure activity related to speech perception is unclear. In sentence processing tasks, task effects can be significant ( ), and if not accounted for may obscure what are actually consistent patterns of language-related activity across the lifespan ( ). \n\nIn the current study we investigated spoken word processing in young and older adult listeners in the absence of background noise. We compared paradigms requiring words to be repeated with “attentive listening” (no motor response required). Our interest is, first, whether age differences exist in the brain networks supporting spoken word recognition, and second, whether these differences are affected by the choice of task. Thus, our primary analyses will focus on activity seen for words (greater than noise) in the experimental conditions. \n\nThe influence of psycholinguistic factors on spoken word recognition has long been appreciated. In a secondary set of analyses, we will investigate whether word frequency or phonological neighborhood density modulate activity during spoken word recognition. Although behavioral and electrophysiological studies suggest that high frequency words are processed more quickly than low frequency words, the degree to which this might be captured in fMRI is unclear. Similarly, although neighborhood density effects are widely reported in behavioral studies (with words from dense neighborhoods typically being more difficult to process), the degree to which lexical competition effects may differ with age is unclear. \n\n\n## MATERIALS AND METHODS \n  \nStimuli, data, and analysis scripts are available from  . \n\n### Participants \n  \nWe recruited two groups of participants (young and older adults) for this study. The young adults were 29 self-reported healthy, right-handed adults, aged 19–30 years (  M   = 23.8,   SD   = 2.9, 19 female), and were recruited via the Washington University in St. Louis Department of Psychological and Brain Sciences Subject Pool. Older adult participants were 32 self-reported healthy, right-handed adults, aged 65–81 years (  M   = 71.0,   SD   = 5.0, 17 female). All participants self-reported themselves to be native speakers of American English with no history of neurological difficulty, and with normal hearing (and no history of a diagnosed hearing problem). Participants were compensated for their participation, and all provided informed consent commensurate with practices approved by the Washington University in St. Louis Institutional Review Board. \n\nAudiograms were collected on a subset of eight young and nine older participants using pure-tone audiometry ( ). We summarized hearing ability using a better-ear pure tone average (PTA) at 1, 2, and 4 kHz. PTAs in participants’ better hearing ears ranged from −3.33 to 8.33 dB HL in young adults (  M   = 2.92,   SD   = 4.15), and 8.33 to 23.3 dB HL in older adults (  M   = 23.3,   SD   = 9.17). \n  \nExperiment overview. (a) Audiograms for the subset of participants on whom hearing was available for left and right ears. Individual participants are shown in thin lines, group means in thick lines. (b) Frequency of occurrence and phonological neighborhood density for the 240 experimental items. (c) Task design for attentive listening and word repetition tasks. (d) Behavioral accuracy for the repetition condition for young and older adults. HAL = Hyperspace Analogue to Language, EPI = echo planar imaging. \n  \n\n### Materials \n  \nStimuli for this study were 375 monosyllabic consonant-vowel-consonant words. The auditory stimuli were recorded at 48 kHz using a 16-bit digital-to-analog converter with an Audio Technica 2035 microphone in a quiet room. Words were spoken by a female speaker with a standard American dialect. Root-mean-square amplitude of the stimuli was equated. \n\nOut of the full set of words, 75 words were vocoded using a single channel with white noise as a carrier signal ( ) using   jp_vocode.m   from  . These stimuli were used for an unintelligible baseline “noise” condition. The remaining 300 words were divided into five lists of 60 words, using MATCH software ( ), and were balanced for word frequency (as measured by the log of the Hyperspace Analogue to Language dataset), orthographic length, concreteness ( ), and familiarity ( ). The distribution of word frequency and phonological neighborhood density are shown in  . \n\nOne of these lists was combined with 15 of the noise vocoded words and used for word repetition task practice outside of the scanner. The remaining four lists of 60 words served as the critical items inside the scanner, with half of the lists used for attentive listening (120 total words) and the other half for word repetition (120 total words). Word lists were counterbalanced such that each word was presented in both “listen” and “repeat” conditions across participants. \n\n\n### Procedure \n  \nPrior to scanning, participants were taken to a quiet room. (The room was not sound isolated and low frequency noise from the building heating, ventilation, and air conditioning system was typically present.) During that time participants provided informed consent, completed demographic questionnaires, and a subset had their hearing tested using a calibrated Maico MA40 portable audiometer (Maico Diagnostics, Inc., Eden Prairie MN) by an audiologist-trained researcher. \n\nParticipants were then instructed for the two tasks they would perform in the scanner: attentive listening and word repetition. During attentive listening, participants were asked to stay alert, still, and keep their eyes focused on a fixation cross while listening to a sequence of auditory sounds, including words, silence, and noise (single-channel noise vocoded words). During word repetition, participants were asked to do the same as in attentive listening, with the addition of repeating the word they just heard aloud. Participants were instructed to repeat the words following the volume acquisition after each word ( ). Participants were told to give their best guess if they could not understand a word. Participants practiced a simulation of the word repetition task until the experimenter was confident that the participant understood the pacing and the nature of the task. Sound levels were adjusted to achieve audible presentations at the beginning of the study and thereafter not adjusted. \n\nFunctional MRI scanning took place over the course of four scanning blocks, where participants alternated between blocks of attentive listening and word repetition ( ). The order of blocks was counterbalanced such that participants were equally likely to begin with a word repetition or an attentive listening block. During word repetition, participants’ spoken responses were recorded using an in-bore Fibersound optical microphone. These responses were scored for accuracy offline by a research assistant ( ). \n\n\n### MRI Data Acquisition and Processing \n  \nThe MRI data collected in this study are available from   ( ). MRI data were acquired using a Siemens Prisma scanner (Siemens Medical Systems) at 3 T equipped with a 32-channel head coil. Scan sequences began with a T1-weighted structural volume using an MPRAGE sequence (repetition time [TR] = 2.4 s, echo time [TE] = 2.2 ms, flip angle = 8°, 300 × 320 matrix, voxel size = 0.8 mm isotropic). Blood oxygenation level-dependent fMRI images were acquired using a multiband echo planar imaging sequence ( ; TR = 3.07 s, TA = 0.770 s, TE = 37 ms, flip angle = 37°, voxel size = 2 mm isotropic, multiband factor = 8). (The flip angle was suboptimal due to an error setting up the sequences; although discovered partway through the study, we left it unchanged to maintain consistent data quality. With a TR of ~3 s we would expect a better signal-to-noise ratio with a flip angle of 90°.) We used a sparse imaging design in which there was a 2.3 s delay between scanning acquisitions and the TR was longer than the acquisition time to allow for minimal scanning noise during stimulus presentation and audio recording of participant responses ( ;  ). \n\nAnalysis of the MRI data was performed using Automatic Analysis version 5.4.0 ( ; RRID:SCR_003560), which scripted a combination of SPM12 (Wellcome Trust Centre for Neuroimaging) version 7487 (RRID:SCR_007037) and FMRIB Software Library (FSL; FMRIB Analysis Group;  ) version 6.0.1 (RRID:SCR_002823). \n\nData were realigned using rigid-body image registration, and functional data were coregistered with the bias-corrected T1-weighted structural image. Spatial and functional images were normalized to MNI space using a unified segmentation approach ( ), and resampled to 2 mm. Finally, the functional data were smoothed using an 8 mm full width at half maximum Gaussian kernel. \n\nFor the attentive listening condition, we did not have measures of accuracy, so we analyzed all trials. For the repetition condition, we analyzed only trials associated with correct responses. For both tasks, we modeled the noise condition in addition to words. Finally, we included three parametric modulators for word events: word frequency, phonological neighborhood density, and their interaction. To avoid order effects ( ), these were not orthogonalized. \n\nMotion effects were of particular importance given that participants were speaking during the repetition condition. To mitigate the effects of motion, we used a thresholding approach in which high motion frames were individually modeled for each subject using a delta function in the general linear model (see, e.g.,  ). Motion was quantified using framewise displacement (FD), calculated from the six motion parameters estimated during realignment, assuming the head is a sphere having a radius of 50 mm ( ). We then chose an FD threshold (0.561) that we used for all participants. Our rationale was that some participants move more, and thus produce worse data; we therefore wanted to use a single threshold for all participants, resulting in more data exclusion from high-motion participants. This threshold resulted in 2.2–19.4% (  M   = 6.21,   SD   = 4.45) data exclusion for the young adults and 2.8–58.4% (  M   = 22.6,   SD   = 15.3) data exclusion for the older adults. For each frame exceeding this threshold, we added a column to that participant’s design matrix consisting of a delta function at the time point in question, which effectively excludes the variance of that frame from the model. \n\nContrast images from single subject analyses were analyzed at the second level using permutation testing (FSL   randomise  ; 5,000 permutations;  ), with a cluster-forming threshold of   p   < 0.001 (uncorrected) and results corrected for multiple comparisons based on cluster extent (  p   < 0.05). Images (contrast images and unthresholded   t   maps) are available from   ( ). Anatomical localization was performed using converging evidence from author experience ( ) viewing statistical maps overlaid in MRIcroGL ( ), supplemented by atlas labels ( ). \n\nFor region of interest (ROI) analysis of primary auditory cortex, we used probabilistic maps based on postmortem human histological staining ( ), available in the SPM Anatomy toolbox ( ; RRID:SCR_013273). We created a binary mask for regions Te1.0 and Te1.1 and then extracted parameter estimates for noise and word contrasts for the attentive listening and repetition conditions from each participant’s first-level analyses by averaging over all voxels in each ROI (left auditory, right auditory). \n\nOutputs from analysis stages used for quality control are available from   in the aa_report folder. \n\n\n\n## RESULTS \n  \n### Behavioral Data \n  \nWe analyzed the accuracy data using a linear mixed effects analysis, implemented using the   lme4   and   lmerTest   packages in R version 3.6.2 ( ;  ; RRID:SCR_001905). Because trial-level accuracy data was binary, we used logistic regression. We first tested for age differences using a model that included age group as a fixed factor and subject as a random factor:  \nm0 <- glmer(accuracy ~ age_group + (1 | subject), \n\n   data = df, family = \"binomial\") \n \n\nThe estimate of age_group was −1.4929 (  SE   = 0.1902),   p   = 4.24e−15, consistent with a main effect of age (older adults performing more poorly). Because of the ceiling effects and the lack of variability in the young adult data, we ran an additional analysis only in the older adults, using a model that included neighborhood density and word frequency as fixed factors, and item and subject as random factors:  \nm1 <- glmer(accuracy ~ neighborhood_density * log_freq + \n\n   (1 | word) + (1 | subject), \n\n   data = df, family = \"binomial\") \n \n\nThe model failed to converge when including a more complex random effect structure. The results of this model are shown in  . There were no significant effects of neighborhood density or word frequency in the accuracy data. \n  \nFixed effects results for accuracy data model \n    \nThere are many reasons a participant might make an incorrect response, and our primary interest is in the processes supporting successful comprehension. Thus, for the fMRI analyses, we restricted our analyses to correct trials only. \n\n\n### Imaging Data \n  \nWe began by looking at activity in the auditory cortex, followed by whole-brain analyses. Activity in left and right auditory cortex for noise and word conditions for young and older adults is shown in  . We analyzed these data using a linear mixed effects analysis, implemented using the   lme4   and   lmerTest   packages in R version 3.6.2 (RRID:SCR_001905). The full model included task (listen, repeat), stimulus (word, noise), hemisphere (left, right), age group (young, older), and accuracy on the repetition task as fixed factors, with subject, stimulus type, and task as random factors:  \nm1 <- lmer(activity ~ task * stimulus * hemisphere * agegroup + accuracy + \n\n   (1 + stimulus * task | subject), \n\n   data = dfleftright) \n When including hemisphere as an additional random factor, the model failed to converge, and as our main interests lay elsewhere we settled on the above model. \n  \nActivity in auditory cortex regions of interest. (a) Activity (parameter estimates, arbitrary units) for left and right auditory cortex as a function of age group and task. Participants are indicated by individual dots; mean ± standard error indicated by error bars. (b) Activity for left and right auditory cortex during the word repetition task in older adults as a function of accuracy and hearing (hearing only available in a subset of participants). \n  \nFull model results are shown in  . The   p   values were obtained from the   lmerTest   package using the Satterthwaite method for degrees of freedom and   t   statistics. We found significant interactions between task and stimulus, consistent with a greater degree of activation for words relative to noise in the repetition task compared to the attentive listening task. Importantly, there was a significant interaction between stimulus and age group, consistent with greater age differences for words relative to noise. We verified this with follow-up   t   tests, collapsing over hemisphere, which showed a significant difference in activity between young and older adults for words, attentive listening:   t  (57.973) = 3.1428,   p   = 0.002636; repetition:   t  (56.619) = 2.5583,   p   = 0.01322, but not for noise, attentive listening:   t  (58.559) = 0.66361,   p   = 0.5095; repetition:   t  (57.241) = 0.19028,   p   = 0.8498. None of the other main effects or interactions were significant. \n  \nFixed effects results for auditory cortex model \n    \nTo explore the possible contribution of other factors to older adults’ reduced activity in the auditory cortex, we conducted a series of exploratory correlation analyses with accuracy, hearing, and movement parameters from fMRI (median FD). None of these analyses showed significant correlations with auditory cortex activity. Correlations for accuracy and hearing in the word repetition task are shown in  . Overall, we interpret these results as being consistent with less auditory activity for the older adults during spoken word perception (but not during our nonspeech control condition). \n\nTo complement the ROI analyses, we next performed whole-brain analyses for all conditions of interest. Activity for word perception in the attentive listening condition (greater than the noise baseline) is shown in   (with maxima listed in  – ). As expected, both young and older adults showed significant activity in the bilateral superior temporal cortex. Young adults showed significantly stronger activity in the superior temporal cortex near the auditory cortex. There were no regions in which older adults showed greater activity than young adults. \n  \nWhole-brain activity for the attentive listening condition. Top: Unthresholded parameter estimates. Middle: Unthresholded   t   maps. Bottom: Thresholded   t   maps (  p   < 0.05, cluster corrected). White ovals highlight left and right auditory cortex. \n    \nPeak activations for attentive listening condition greater than noise, young adults \n    \nPeak activations for attentive listening condition greater than noise, older adults \n    \nPeak activations for attentive listening condition greater than noise, young > older adults \n  \nIn addition to the overall pattern associated with word perception, we examined psycholinguistic effects of word frequency and phonological neighborhood density using a parametric modulation analysis. There were no significant effects of either word frequency or neighborhood density in the attentive listening condition. \n\nActivity for word perception in the repetition condition (relative to a noise baseline) is shown in   (with maxima in  – ). Again, both young and older adults showed significant activity in the bilateral temporal cortex, as well as frontal regions related to articulatory planning, including the premotor cortex and the supplemental motor area. As with the attentive listening condition, young adults showed significantly more activity in superior temporal regions near the auditory cortex. There were no regions where older adults showed more activity than the young adults. \n  \nWhole-brain activity for the repetition condition (correct responses only). Top: Unthresholded parameter estimates. Middle: Unthresholded   t   maps. Bottom: Thresholded   t   maps (  p   < 0.05, cluster corrected). White ovals highlight left and right auditory cortex. \n    \nPeak activations for repetition condition greater than noise, young adults \n    \nPeak activations for repetition condition greater than noise, older adults \n    \nPeak activations for repetition condition greater than noise, young > older adults \n  \nIn addition to the overall pattern associated with word perception, we examined psycholinguistic effects of word frequency and phonological neighborhood density using a parametric modulation analysis. There were no significant effects of either word frequency or neighborhood density in the repetition condition. \n\nFinally, we directly compared the attentive listening and repetition conditions, shown in   (with maxima in   and  ). Compared to the attentive listening condition, during the repetition condition both young and older listeners showed increased activity in motor and premotor cortex. There were no significant differences between young and older adults. \n  \nWhole-brain activity for the repetition condition > attentive listening. Top: Unthresholded parameter estimates. Middle: Unthresholded   t   maps. Bottom: Thresholded   t   maps (  p   < 0.05, cluster corrected). White ovals highlight left and right auditory cortex. There were no significant differences between young and older adults in the repetition > listening contrast. \n    \nPeak activations for word recognition in the repetition condition greater than listening condition, young adults \n    \nPeak activations for word recognition in the repetition condition greater than listening condition, older adults \n  \n\n\n## DISCUSSION \n  \nWe used fMRI to examine neural activity during spoken word recognition in quiet for young and older adult listeners. In both ROI and whole-brain analyses, we found converging evidence for reduced activity in the auditory cortex for the older adults. The age differences in auditory cortex activation were present in both the attentive listening task and the word repetition task: Although the repetition task resulted in more widespread activation overall, patterns of age-related differences in the auditory cortex were comparable. \n\nThere are a number of possible explanations for older adults’ reduced activity during spoken word recognition. One possibility is that age differences in intelligibility might play a role. Intelligible speech is associated with increased activity in a broad network of frontal and temporal regions ( ;  ), and in prior studies of older adults, intelligibility has correlated with auditory cortex activity ( ). We restricted our analyses to correct responses in the repetition condition, and found no statistical support for a relationship between intelligibility and auditory cortex activation (although numerically, participants with better accuracy showed more activity than participants with worse accuracy). \n\nThe fact that young and older adults showed comparable activity in the auditory cortex during noise trials, with age differences emerging for word recognition trials, is significant. Group differences in activation could be driven not only by neural processing, but also by such factors as neurovascular coupling, goodness-of-fit of a canonical hemodynamic response, or movement within the scanner—in other words, artifacts that might differentially impact model parameter estimates in young and older adults but are not of theoretical interest in this context. Although impossible to completely rule out, the selective age differences for speech (but not noise) are consistent with a condition-specific—and thus we argue, neural—interpretation. \n\nRecent evidence suggests age-related changes in temporal sensitivity in auditory regions can be detected with fMRI ( ). Although our current stimuli do not allow us to explore specific acoustic features, one possibility is that the age-related differences in auditory activity we observed reflect well-known changes in auditory cortical processing that occur in normal aging ( ). Given the increased acoustic complexity of the words relative to noise, acoustic processing differences might drive overall response differences. Such changes may also reflect decreased stimulation as a result of hearing loss; we had insufficient data to rule out this possibility. It is important to note that we cannot completely rule out audibility effects. Even though we limited our responses to correct identification trials, specific acoustic features may still have been less audible for the older adults. It remains an open question whether varying the presentation level of the stimuli would change the age effects we observed. \n\nAge differences in auditory processing are not the only explanation for our results. The auditory cortex is positioned in a hierarchy of speech processing regions that include both ascending and descending projections ( ;  ). The auditory cortex not only is sensitive to changes in acoustic information, but also reflects top-down effects of expectation and prediction ( ;  ;  ). Thus, the observed age differences in the auditory cortex may reflect differential top-down modulation of auditory activity in young and older adult listeners. \n\nIndeed, prior to conducting this study, we expected to observe increased activity (e.g., in the prefrontal cortex) for older adults relative to young adults, reflecting top-down compensation for reduced auditory sensitivity. Such activity would be consistent with increased cognitive demand during speech perception in listeners with hearing loss or other acoustic challenges ( ;  ). Although we were somewhat surprised not to see this, in retrospect, perhaps it would be expected. The stimuli in the current study were presented in quiet, and thus may not have challenged perception sufficiently to robustly engage frontal brain networks. We conclude that during perception of acoustically clear words, older adults do not seem to require additional resources from the frontal cortex; whether this changes with increasing speech demands (either acoustic or linguistic) remains an open question. \n\nWe did not observe significant effects of either word frequency or phonological neighborhood density on activity during spoken word recognition. These results stand in contrast to prior studies showing frequency effects in visual word perception in fMRI ( ;  ), and word frequency effects in electrophysiological responses ( ). Prior fMRI studies of lexical competition (including phonological neighborhood density) have been mixed, with some studies finding effects ( ) and others not ( ). It could be that a wider range of frequency or density or a greater number of stimuli would be needed to identify such effects. \n\nFinally, we found largely comparable age differences in the attentive listening and repetition conditions in the auditory cortex. The similarity of the results suggests that using a repetition task may be a reasonable choice in studies of spoken word recognition: Although repetition tasks necessarily engage regions related to articulation and hearing one’s own voice, in our data these were not differentially affected by age. An advantage of using a repetition task, of course, is that trial-by-trial accuracy measures can be obtained, which are frequently useful. It is worth noting that our finding of comparable activity in young and older adults for attentive listening and repetition tasks may not generalize to other stimuli or tasks ( ;  ). \n\nA significant limitation of our current study is that we only collected hearing sensitivity data on a minority of our participants. Thus, although we saw a trend toward poorer hearing being associated with reduced auditory cortex activation, it is challenging to draw any firm conclusions regarding the relationship between hearing sensitivity and brain activity. Prior studies using sentence-level materials have found relationships between hearing sensitivity and brain activity in both young ( ) and older ( ) adults. Future investigations with a larger sample of participants with hearing data will be needed to further explore the effects of hearing in spoken word recognition. \n\nFrom a broader perspective, the link between spoken word recognition and everyday communication is not always straightforward. Much of our everyday communication occurs in the context of semantically meaningful, coherent sentences, frequently with the added availability of visual speech and gesture cues. Given potential age differences in reliance on many of these cues—including older adults’ seemingly greater reliance on semantic context ( ;  ;  )—it seems likely that our findings using isolated spoken words cannot be extrapolated to richer naturalistic settings. \n\nIn summary, we observed largely overlapping brain regions supporting spoken word recognition in young and older adults in the absence of background noise. Older adults showed less activity than young adults in the auditory cortex when listening to words, but not noise. These patterns of age difference were present regardless of the task (attentive listening vs. repetition). \n\n\n## ACKNOWLEDGMENTS \n  \nResearch reported here was funded by grant R01 DC014281 from the US National Institutes of Health. The multiband echo planar imaging sequence was provided by the University of Minnesota Center for Magnetic Resonance Research. We are grateful to Linda Hood for assistance with data collection, and to Henry Greenstein, Ben Muller, Olivia Murray, Connor Perkins, and Tracy Zhang for help with data scoring. \n\n\n## FUNDING INFORMATION \n  \nJonathan E. Peelle, National Institute on Deafness and Other Communication Disorders ( ), Award ID: R01 DC014281. \n\n\n## AUTHOR CONTRIBUTIONS \n  \nChad S. Rogers: Conceptualization: Equal; Data curation: Equal; Investigation: Equal; Project administration: Equal; Supervision: Supporting; Validation: Equal; Writing–Review & Editing: Equal. Michael S. Jones: Formal analysis: Lead; Methodology: Equal; Software: Lead; Validation: Lead; Writing–Review & Editing: Equal. Sarah McConkey: Investigation: Equal; Project administration: Equal; Writing–Review & Editing: Equal. Brent Spehar: Conceptualization: Equal; Investigation: Supporting; Resources: Supporting; Writing–Review & Editing: Equal. Kristin J. Van Engen: Conceptualization: Equal; Funding acquisition: Supporting; Project administration: Equal; Writing–Review & Editing: Equal. Mitchell S. Sommers: Conceptualization: Equal; Funding acquisition: Supporting; Project administration: Supporting; Writing–Review & Editing: Equal. Jonathan E. Peelle: Conceptualization: Equal; Data curation: Equal; Formal analysis: Equal; Funding acquisition: Lead; Project administration: Equal; Supervision: Lead; Visualization: Lead; Writing–Original Draft: Lead; Writing–Review & Editing: Equal. \n\n \n","utf8_text_md5_checksum":"8143bd723654bdf1385cf807c530bc44"},
{"annotations":[{"end_byte":500,"end_char":500,"label_name":"RestingState","start_byte":487,"start_char":487}],"display_title":"pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5090046\">5090046</a>","list_title":"PMC5090046  An individual differences analysis of the neurocognitive architecture of the semantic system at rest","metadata":{"batch":1,"doi":"10.1016/j.bandc.2016.07.003","efetch_url":"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=5090046","field_positions":{"abstract":[417,2373],"authors":[0,145],"body":[2382,41327],"journal":[146,156],"keywords":[287,404],"publication_year":[158,162],"title":[173,273]},"pmc_url":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5090046","pmcid":5090046,"pmid":27662589,"text_md5":"1b22fc2ff8ac96a8576b9db1fb96c39d"},"text":"Mollo, Giovanna and Karapanagiotidis, Theodoros and Bernhardt, Boris C. and Murphy, Charlotte E. and Smallwood, Jonathan and Jefferies, Elizabeth\nBrain Cogn, 2016\n\n# Title\n\nAn individual differences analysis of the neurocognitive architecture of the semantic system at rest\n\n# Keywords\n\nFunctional connectivity\nAnterior temporal lobe\nInferior frontal gyrus\nVisual word form area\nSemantics\nVerbal fluency\n\n\n# Abstract\n  Highlights  \n  \nVariations in semantic performance are reflected in resting-state networks. \n  \nInferior frontal connectivity predicts verbal fluency performance. \n  \nConnectivity between visual and anterior temporal areas predicts synonym judgement. \n  \n  \nEfficient semantic cognition depends on accessing and selecting conceptual knowledge relevant to the current task or context. This study explored the neurocognitive architecture that supports this function by examining how individual variation in functional brain organisation predicts comprehension and semantic generation. Participants underwent resting state functional magnetic resonance imaging (fMRI) and, on separate days, performed written synonym judgement, and letter and category fluency tasks. We found that better synonym judgement for high frequency items was linked to greater functional coupling between posterior fusiform and anterior superior temporal cortex (aSTG), which might index orthographic-to-semantic access. However, stronger coupling between aSTG and ventromedial prefrontal cortex was associated with poor performance on the same trials, potentially reflecting greater difficulty in focussing retrieval on relevant features for high frequency items that appear in a greater range of contexts. Fluency performance was instead linked to variations in the functional coupling of the inferior frontal gyrus (IFG); anterior IFG was more coupled to regions of primary visual cortex for individuals who were good at category fluency, while poor letter fluency was predicted by stronger coupling between posterior IFG and retrosplenial cortex. These results show that individual differences in functional connectivity at rest predict semantic performance and are consistent with a component process account of semantic cognition in which representational information is shaped by control processes to fit the current requirements, in both comprehension and fluency tasks. \n \n\n# Body\n \n## Introduction \n  \nSemantic cognition has a central role in behaviour since it allows us to understand the meanings of words and objects around us and to use this conceptual knowledge to perform complex goal-orientated acts. Theories of semantic cognition emphasise that this capacity depends on multiple interacting components, supported by different neural processes ( ,  ,  ). Although the extent to which visual, auditory and motor regions support semantic knowledge is still a matter of debate ( ,  ), a wealth of studies provide evidence that these brain regions contribute to our knowledge of what things look and sound like, and how we hold and use objects ( ,  ,  ,  ). Anterior regions of the temporal lobe are thought to bring these different aspects of knowledge together to form amodal conceptual representations, allowing us to understand that items such as ‘kiwi’ and ‘pineapple’ are members of the same category even though they are different colours, sizes, shapes, have different textures, and are associated with different actions ( ,  ,  ,  ). Finally, left ventral and lateral prefrontal regions, as well as posterior middle and inferior temporal cortex, are important when conceptual information must be retrieved in the absence of strong contextual support, when there is strong competition from competing meanings, or when non-dominant aspects of meaning must be brought to the fore: for example, understanding that “kiwi” can refer to a bird as well as fruit ( ,  ,  ,  ,  ,  ). \n\nSemantic cognition, therefore, reflects our ability to use conceptual information in a flexible way to serve different purposes. We retrieve semantic information to make sense of the environment around us, and also to generate thoughts and actions. Consequently, we need to be able to differentially engage different components of semantic cognition that support the current task demands ( ,  ). First, in order to understand the significance of words and objects that we encounter in the external world, we need to be able to access relevant semantic representations from our sensory systems: for example, the comprehension of written words is thought to utilise mappings between visual responses in posterior fusiform cortex (encompassing the so-called ‘visual word form area’) and conceptual representations in anterior temporal cortex ( ,  ,  ). The nature of the stimulus can affect the efficiency of this visual-to-semantic transformation. For instance, highly imageable words, that rapidly arouse mental images associated with their meaning, enjoy a processing advantage compared to words that are less imageable. This advantage occurs because highly imageable words benefit from richer semantic associations ( ,  ). Similarly, high frequency words that are often encountered benefit from a stronger mapping between orthography and meaning that is reflected in faster reading times ( ,  ). However, this type of semantic “access” may not be sufficient for good performance on tasks such as synonym judgement. This is because for any given concept, we have a multitude of knowledge and only a subset of this information is relevant for any given context. In order to correctly match words on the basis of their shared features (e.g., kiwi with tomato), semantic retrieval must be channelled to focus on relevant elements and away from strong functional associations (tomato goes with cheese sandwich). High frequency words are thought to require this type of control to a greater extent since they occur in multiple contexts and thus have a higher ‘contextual diversity’ ( ,  ,  ). \n\nThere may be some differences in the neurocognitive components that are engaged when semantic information must be generated internally, as opposed to accessed from an external input (although both situations are thought to recruit conceptual representations in the anterior temporal lobes) ( ,  ). In fluency tasks, conceptual information must be generated from a cue such as a letter or category name; here, the capacity to search for and select relevant knowledge is paramount. It is hypothesised that this process depends on the co-operation of the representational and control systems and draws heavily on left inferior frontal gyrus ( ,  ). Moreover, the type of cue influences the extent to which control is required. Letter fluency, in which participants attempt to generate words starting with a particular letter, is particularly demanding of generation and selection mechanisms, while generating items from a category name such as “animals” requires less control, since a process of spreading activation between concepts will elicit high frequency and/or prototypical animals ( ,  ). Recent work has shown that category fluency is more impaired in patients with degradation of conceptual representations following anterior temporal atrophy, while letter fluency is more vulnerable to poor semantic control ( ). Moreover, category fluency appears to activate a broader range of sites implicated in internally-focussed memory retrieval, particularly retrosplenial cortex, while letter fluency has a clear prefrontal focus ( ,  ,  ,  ). \n\nSince comprehension and generation tasks require the components of semantic cognition to be brought together differently, we might anticipate that individual differences in these capacities should depend on different patterns of neural coupling that emerge at rest. This individual difference approach has been used successfully to understand the neural basis of various features of higher order cognition including meta-cognition, binocular rivalry, intelligence, reading comprehension and spontaneous thought ( ,  ,  ,  ,  ,  ). Few studies have attempted to link individual differences in semantic performance to the strength of resting state connectivity patterns. The most relevant study is by  , who found that stronger connectivity between posterior middle temporal gyrus and other parts of the semantic network, such as anterior temporal lobes and inferior frontal gyrus, predicted good performance on picture and sound naming and association judgements in a sample of 34 participants. \n\nIn the current study, we recorded resting state fMRI in a cohort of 48 participants who performed a series of tasks tapping different aspects of semantic performance on a subsequent day. This second experimental phase included a synonym judgement task to index the capacity to understand the meaning of an external stimulus ( ) and semantic and letter fluency tasks that required participants to internally generate representations. We explored how variation in participants’ performance on these tasks was related to resting state connectivity between regions previously implicated in written comprehension and fluency. This allows us to test the diagnostic value of resting state fMRI in the domain of individual differences in semantic cognition. \n\n### Regions of interest \n  \nReflecting the component process account of semantic cognition above, we selected regions for our analysis that are implicated in (i) semantic representation (in the anterior temporal lobes), (ii) access to semantics from orthographic input (in left posterior fusiform), and (iii) lexical selection and semantic control (in inferior frontal gyrus). Previous fMRI studies of verbal semantic tasks have observed two distinct peaks in left anterior temporal lobe (ATL), in anterior superior temporal gyrus (aSTG) and in ventral ATL respectively ( ,  ,  ,  ,  ). Ventral ATL might provide a multimodal semantic hub anticipated by  , since it responds across tasks and modalities (e.g., to pictures, environmental sounds, spoken and written words;  ,  ;  ;  ;  ). Ventral ATL is functionally connected with semantic and default mode regions ( ,  ,  ,  ,  ). However, magnetic susceptibility artefacts produce signal loss and distortion in this region in standard EPI sequences, which mean it is consequently under-represented in the fMRI literature (compared with studies employing PET;  ). In contrast, aSTG is less affected by magnetic susceptibility artefacts and often shows strong peaks in verbal comprehension tasks ( ,  ,  ), including studies employing the synonym judgements task used here ( ,  ). This region is functionally connected with auditory, somatosensory and other language-related regions ( ,  ,  ,  ). \n\nIn addition to these sites in ATL, we selected a region of left posterior fusiform cortex, often activated by orthographic stimuli and sometimes referred to as the “visual word form area” ( ,  ). This region has been consistently shown to be functionally and anatomically connected with language areas ( ) and regions in the dorsal attention network ( ). We expected the connectivity profile of this region to explain differences in performance specifically in the synonyms task that relies on mapping the orthographic form of a stimulus onto the word meaning. \n\nFinally, we selected sites in left inferior frontal gyrus (IFG), implicated in the selection and production of words. Studies have revealed functional specialisation within left IFG, with posterior regions engaged by lexical selection and phonological tasks, while anterior regions contribute to the controlled retrieval of semantic information ( ,  ,  ,  ,  ,  ). Consequently, we expected that the connectivity profile of seeds in posterior and anterior IFG might explain individual differences in letter and category fluency tasks respectively. Moreover, since synonym judgement requires semantic information to be retrieved in a controlled fashion, we expected that aIFG might also explain aspects of this task related to control demands. \n\n\n### Specific aims \n  \nIn summary, our study was set out to examine the diagnostic value of measuring functional connectivity at rest in understanding individual differences in semantic cognition. We selected regions whose behaviour was expected to be important for making sense of written input in the synonyms task (posterior fusiform) and selecting and producing words in the fluency task (posterior IFG). We also selected two regions in the anterior temporal lobe thought to be critical for supporting semantic representations (in ventral ATL and aSTG), plus a region implicated in semantic control (anterior IFG), whose functional coupling could be important in different types of semantic tasks. \n\n\n\n## Materials and methods \n  \n### Participants \n  \nThis study was approved by the Ethics committee of the York Neuroimaging Centre and participants provided written informed consent prior to their participation. They took part to the study in exchange for course credit or monetary compensation. Participants were English native speakers, right handed, with normal or corrected-to-normal vision and no history of neurological or psychiatric disease. \n\nThe main study involved 48 participants (Group A; 14 men, age range 18–25 years). Five participants were excluded from the analysis due to technical problems affecting the behavioural tasks (N = 2), performance identified as outlier in the behavioural tasks (N = 1) or insufficient brain coverage (N = 2). The final sample of Group A included 43 participants (11 men, mean 20.3 ± 1.2 years). \n\nResting-state fMRI data from 20 participants in another experiment (Group B; 9 men, mean 23.8 ± 4.6 years) provided an independent repository with which to explore the networks underpinning the results observed for the group level regressions from Group A. \n\n\n### Experimental design and procedures \n  \nMembers of Group A participated in three experimental sessions taking part in three separate days. They underwent a resting state functional and structural MRI scan during Session 1 and performed a series of computer-based tasks outside the scanner in Sessions 2 and 3, including synonym judgement and verbal fluency. Fluency and synonyms were both assessed in Session 2, with the fluency task performed first. Group B took part in a single session, starting with a resting state fMRI scan, followed by a task-based fMRI scan. The present study only used the resting state data from this sample. \n\n\n### Task stimulus materials and procedures \n  \nDuring   Verbal Fluency   (from Cambridge Semantic Battery; ( ,  ), participants had 1 min to generate as many unique words as possible belonging to a semantic category (category fluency) or starting with a specific letter (letter fluency). Semantic fluency was assessed for eight categories split in two blocks (Block A: animals, fruits, birds, type of dogs; Block B: vehicles, tools, household objects, boats). Letter fluency was assessed for three letter cues (Block C: A, F, S). Block order was counterbalanced across participants and the order of cues within each block was randomized. Participants’ verbal responses were collected and the audio recordings were transcribed and scored off-line. \n\nThe   Synonyms Task   comprised 96 trials split into six conditions according to lexical frequency (high and low) and imageability (high, medium and low), details about this task can be found in  . All of the words in each trial fell into the same frequency and imageability condition. Each trial started with a fixation cross for 1 s, followed by a trial which remained on screen until the participant responded. A probe word was presented at the top of the screen (e.g.,   STONE  ) with the target and two unrelated distracters on the bottom row (e.g.,   ROCK  ,   WINTER  ,   BOTTLE  ). The words were written in black Arial font, size 18, on a white background. Participants were asked to select among the three choices the word closest in meaning to the probe. Responses were collected using the numeric keyboard. \n\nFor the purposes of the resting state functional connectivity analysis, participants’ performance in each task was evaluated by subtracting z-scored reaction times (RT) from z-scored accuracy. This   efficiency score   controls for speed accuracy trade-offs in a single measure. Positive efficiency scores indicate better performance, as these values follow the subtraction of negative z-scores for RT (indicating faster responses than average), from positive z-scores for accuracy (indicating more accurate responses than average). \n\n\n### MRI data acquisition \n  \nBrain imaging data were acquired at the York Neuroimaging Centre using a GE 3T HDX Excite MRI scanner and an eight-channel phased array head coil tuned to 127.4 MHz. The parameters for the functional and structural recordings were the same for Group A and B. The imaging session started with a 9 min eyes-open resting state functional scan using a gradient single-shot echo planar imaging (EPI) sequence with repetition time (TR) 3000 ms, echo time (TE) minimum full, 180 volumes, flip angle 90°, voxel size 3 × 3 × 3 mm , matrix size 64 × 64, field of view (FOV) 192 × 192 mm , slice thickness 3 mm and 60 slices with an interleaved (bottom up) acquisition order. The structural data were recorded using a sagittal isotropic 3D fast spoiled gradient-recalled echo (3D FSPGR) structural T1 weighted scan with the following parameters: TR 7.8 ms, TE minimum full, flip angle 20°, matrix size 256 × 256, 176 slices, voxel size 1.13 × 1.13 × 1 mm , FOV 290 × 290 mm . For each participant, a high-resolution T1-weighted in-plane anatomical picture was also acquired using a fluid attenuated inversion recovery (FLAIR) in order to facilitate the co-registration of the functional data onto the structural images. \n\n\n\n## Analysis \n  \n### Resting state functional connectivity analysis \n  \n#### Pre-processing \n  \nFunctional and structural data were pre-processed and analysed using FMRIB’s Software Library (FSL version 4.1,  ). Individual FLAIR and T1 weighted structural brain images were extracted using BET (Brain Extraction Tool) ( ). Structural images were linearly registered to the MNI-152 template using FMRIB’s Linear Image Registration Tool (FLIRT) ( ). The resting state functional data were pre-processed and analysed using the FMRI Expert Analysis Tool (FEAT). The individual subject analysis involved: motion correction using MCFLIRT ( ); slice-timing correction using Fourier space time-series phase-shifting; spatial smoothing using a Gaussian kernel of FWHM 6 mm; grand-mean intensity normalisation of the entire 4D dataset by a single multiplicative factor; highpass temporal filtering (Gaussian-weighted least-squares straight line fitting, with sigma = 100 s); Gaussian lowpass temporal filtering, with sigma = 2.8 s. \n\n\n#### Seed based functional connectivity analysis \n  \nFunctional connectivity was measured by looking at the temporal correlation between our regions of interest and the rest of the brain. There are different methods for correcting for physiological noise during resting state regression. Following from our prior studies (e.g.  ,  ,  ), we did not use global signal regression but instead implemented component correction recommended by   which involves the extraction of the principle components in the white matter and the ventricles and controlling for these for the analysis of individual resting state scans. \n\nThe time series from 3 mm radius spheres were extracted and used as explanatory variables in connectivity analyses at the single subject level. In each analysis, we entered 11 nuisance regressors; the top five principal components extracted from white matter (WM) and cerebrospinal fluid (CSF) masks based on the CompCor method ( ) and six head motion parameters. WM and CSF masks were generated from each individual’s high resolution structural image ( ). \n\nSeed based functional connectivity analysis for Group A was conducted for seeds in the frontal and temporal lobes in the left hemisphere. First, we selected two coordinates within left anterior and posterior Inferior Frontal Gyrus (IFG), implicated in verbal fluency and semantic control. These regions are differentially implicated in semantic and letter fluency ( ,  ,  ), and in the controlled retrieval and selection of semantic representations ( ,  ). The seed locations we used were taken from a meta-analysis of semantic control ( ): the posterior IFG site responded to control demands across both semantic and phonological tasks (pIFG; MNI x/y/z: −47/21/18), while the anterior IFG site responded to semantic control more than phonological control (aIFG; MNI x/y/z: −43/38/−10, both converted from Talairach using Bioimage suite ( ). Secondly, we examined two spheres in the left anterior temporal lobe (ATL), taken from a previous fMRI study that examined functional activation for the same synonym judgement task used in our investigation ( ). This study revealed strong engagement of anterior Superior Temporal Gyrus (aSTG; MNI x/y/z: −57/6/−18), commonly activated by verbal semantic tasks in the wider literature ( ,  ,  ), and some activation in ventral ATL, where activation is less commonly observed across studies ( ).   used a novel fMRI sequence designed to overcome magnetic susceptibility artefacts in ventral anterior temporal regions. We did not observe task effects relating to the ventral ATL seed, perhaps because we did not use methods designed to minimise signal loss and distortion at this site: thus ventral ATL is not discussed further below. Finally, we examined a region in the posterior fusiform cortex known as the Visual Word Form Area (VWFA; MNI x/y/z: −43/−57/−23; ( ). This region has been consistently shown to be involved in the identification of written words ( ). \n\nFor Group A, the statistical group-level analyses were carried out using FMRIB’s Local Analysis of Mixed Effects (FLAME1). The group-level analyses included a series of multiple regressions using the connectivity maps for each seed region as the dependent variable and the participants’ performance as the independent variable. Separate regression models were run for each task and for each seed. \n\nFor the Synonyms Task, we employed separate models examining differences in performance relative to frequency (conditions: high and low frequency items) and imageability items (conditions: high and low imageability items - the medium imageability items were disregarded). For Fluency, we included Category and Letter Fluency conditions in the same model. The contrasts explored the correlation between the functional connectivity maps of each seed and (a) good or bad performance at each condition, (b) good or bad performance at the task, plus (c) differential effects of the conditions (HF vs. LF and HI vs. LI words in the synonym task; letter vs. category fluency). \n\nThe nature and interpretation of correlation in resting state analysis is a matter of a debate that is focused on a lack of clarity regarding what constitutes a correlation of zero (see  ). Our results describe the beta weights that are produced through the process of multiple regression and reflect a significant positive or negative difference relative to the z-scored distribution of correlations in the whole brain. In other words our analysis allows the identification of regions that show relatively greater or relatively weaker correlations with the seed region. We therefore use the terms ‘relative strong’ and ‘relative weak’ correlated to describe regions whose correlation with the seed region is higher or lower than the average. \n\nAll analyses were corrected for multiple comparisons at a cluster-wise family-wise p < 0.05, using a z-statistic threshold of 2.3 to define contiguous clusters. In the multiple regressions analysis, we also controlled for the number of seed regions, as well as the two-tailed nature of our hypotheses, adopting a highly conservative alpha value of 0.00625.  As this is likely to generate Type II errors, we also report statistically significant effects at the standard threshold of 0.05, as those results can help the interpretation of the effects observed at the more conservative threshold. Furthermore the unthresholded maps are made publicly available through Neurovault here:  . \n\nTo examine the functional architecture associated with the spatial maps that predicted behavioural performance, a second seed-based functional connectivity analysis was performed using data from Group B. Here, we seeded the spatial maps that correlated with behavioural performance from the original four seeds to recover their broader resting-state networks. \n\nThese statistical models include multiple predictors as explanatory variables and so any statistical results that emerge from these models are independent of the other explanatory variables. We formalised contrasts that captured these statistically independent results, as well as explicit contrasts that differentiate between the explanatory variables. \n\n\n\n\n## Results \n  \n### Behavioural data \n  \nIn the Synonyms Task, responses in high frequency trials were more accurate (t(42) = 12.73, p < 0.001) and faster (t(42) = −16.33, p < 0.001) than low frequency trials. Similarly, trials composed of high imageability words were more accurate (t(42) = 7.70, p < 0.001) and faster (t(42) = −7.45, p < 0.001) than low imageability trials. \n\nIn the Fluency Tasks, the number of correct words generated per minute was equivalent for Category and Letter Fluency (t(42) = 0.43, p = 0.67). There were more errors in Category than Letter fluency (t(42) = −5.23, p < 0.001). Descriptive statistics are shown in   while the correlations between the behavioural measures are shown in  . \n\n\n### Neuroimaging results \n  \nIn the resting state fMRI analysis, we calculated spatial maps corresponding to relatively strong correlation of the time series, and relatively weak correlation, for each seed region, presented in  . Both aIFG and pIFG exhibited extensive bilateral connections to dorsal medial and lateral prefrontal cortex, as well as lateral regions of the posterior temporal cortex extending on the left hemisphere into the angular gyrus and lateral occipital cortex. This pattern of connectivity partially overlaps with the ‘fronto-parietal control network’ ( ,  ). Differences in the functional specialisation between these two regions are confirmed by the relatively strong connectivity of aIFG with bilateral insula and left anterior temporal lobe – a core region in the semantic system - and the stronger connectivity of the posterior seed with the left superior temporal sulcus involved in phonological processing ( ). In addition, both regions showed low correlation with the cingulate cortex and precuneus, this pattern was observed bilaterally for the anterior seed and predominantly on the right hemisphere for the posterior seed. The VWFA seed was strongly correlated with occipital regions and posterior and ventral temporal cortex, bilaterally. This region exhibited a pattern of connectivity usually identified as visual network and dorsal-attention network ( ). It also showed relatively weak correlation with medial temporal lobe, angular gyrus and cingulate cortex extending into ventral medial prefrontal cortex, bilaterally. The aSTG seed was strongly coupled to the temporal lobes and to regions of motor cortex, including supplementary motor cortex. This pattern is consistent with the connectivity profile of the anterior portion of the superior temporal cortex reported in previous studies ( ,  ,  ). This seed also showed relatively weak correlation with the ventral striatum, middle frontal gyrus, regions in the dorsal precuneus and angular gyrus, bilaterally.   provides a complete description of the regions passing cluster correction for all seed regions. \n\n\n### Relationship to behaviour \n  \nThe next step in our analysis examined the relationship between the functional connectivity measures for each participant and their performance on synonym judgement and fluency. We implemented a series of multiple regressions using FLAME with the spatial maps generated from each seed as the dependent variable and the efficiency with which the participant performed each task as the independent variable. In order to determine the functional architecture associated with the cluster maps identified with the previous analysis, we subsequently seeded these cluster maps in an independent dataset (Group B). \n\n#### Synonyms task \n  \nWe found a significant relationship between synonym performance and the connectivity of the two temporal lobe regions: VWFA and aSTG. These are presented in  .   presents the magnitude and size of the clusters that were significant in these analyses. For the VWFA, we observed a region of right aSTG and anterior insula that was more coupled to the seed region for people who performed the high frequency trials with greater efficiency. This result could reflect more efficient semantic access from orthographic/visual processes to semantic representations in ATL. Seeding this region in an independent data set (Group B) revealed that it was functionally coupled to anterior and mid-cingulate cortex as well as bilaterally to the temporal lobe. In addition, poor performance on the high frequency trials of the synonym task was associated with stronger coupling between the aSTG seed and a region of ventral prefrontal cortex (vPFC, see   and  ). This same cluster also showed stronger coupling with aSTG for participants who showed relatively poor performance for high frequency vs. low frequency trials indicating that the pattern was a differential effect associated with performance specifically on high frequency items ( ). Subsequent seeding of this region in the data from Group B demonstrated that it was functionally coupled to the medial prefrontal cortex, ventral regions of the lateral prefrontal cortex and limbic regions including the ventral anterior temporal lobe which may promote a pattern of off-task semantic retrieval which could be especially disruptive for HF trials with higher contextual diversity and control demands. \n\nFinally, stronger coupling between aSTG and precuneus was associated with poor synonym performance, on average, for the trials in the imageability analysis. The connectivity maps associated with this cluster, seeded in the data from Group B, included ventromedial and ventrolateral prefrontal regions and bilateral angular gyrus, a pattern that reflects the so-called default mode network (DMN) ( ,  ). This is presented in  . This pattern of coupling suggests that connectivity between the aSTG and the posterior core of the DMN was associated with inefficient performance on the synonyms task in general. \n\n\n#### Fluency task \n  \nFluency performance was associated with greater connectivity from the prefrontal cortex seeds (see  ,  ). Superior performance on Category Fluency was associated with greater connectivity between the aIFG seed region and the medial occipital cortex. Seeding these regions in the data from Group B illustrated that this region was functionally coupled to primary visual areas in both hemispheres. Finally, greater efficiency on Category Fluency was also associated with stronger connectivity between aSTG and a cluster in the cerebellum, extending into ventral inferior temporal cortex bilaterally. These latter results are difficult to interpret because the cluster map crosses anatomical boundaries that are not directly linked (e.g. there are no direct links between primary visual cortex and the cerebellum, see also   for a similar issue). For this reason, we won’t include them in the discussion but we made the unthresholded maps of these results publicly available on Neurovault ( ). \n\nPoor performance on Letter Fluency was associated with greater connectivity between pIFG and the retrosplenial cortex (RSC). This cluster overlapped with a region that showed an effect of category > letter fluency that passed correction for multiple comparisons at family-wise error level of p < 0.05. Although this did not pass the alpha value that controls for the number of seed regions, this pattern allows us to reject the hypothesis that this increased connectivity was associated with problems in fluency per se – instead, the effect was a differential effect that was specific to poor Letter Fluency. Thus, stronger connectivity between IFG and RSC was associated with difficulty in efficiently generating words that started with a specific letter as opposed to items that were conceptually linked. Seeding of this cluster in the data from Group B demonstrated strong coupling between RSC and ventromedial cingulate/prefrontal cortex, as well as with anterior temporal lobes. \n\n\n\n\n## Discussion \n  \nThe current study set out to investigate how variations in performance in tasks that emphasise different aspects of semantic cognition are reflected in the functional connectivity of the brain at rest. We found that connectivity of the left IFG was predictive of performance in fluency tasks, consistent with observations from functional neuroimaging and lesion studies showing that this region is activated in the generation of semantic information. We also found that synonym judgement performance was related to the connectivity of both the putative VWFA and aSTG, regions that are activated when participants perform similar tasks. Together these data indicate that individual differences in semantic performance can be related to the behaviour at rest of specific cortical regions implicated in semantic processing. \n\nMore generally, our results are consistent with the hypothesis that semantic cognition emerges through the flexible interaction of distributed and functionally independent components, including areas implicated in conceptual representation, access to semantics from vision and the capacity to generate and select information ( ,  ,  ,  ). Effective synonym judgement for high frequency words was linked to strong connectivity between the putative VWFA and regions of the ATL: this pattern might reflect greater coupling between temporo-occipital regions supporting visual/orthographic processing and anterior temporal regions representing the meanings of words. This effect was not apparent for fluency tasks that rely on the generation of information from memory rather than the translation of orthographic input. Instead, the ability to generate exemplars of a category was associated with stronger coupling between aIFG and the occipital cortex, a finding that is broadly consistent with accounts of semantic cognition that emphasise the contribution of visual and other sensory/motor regions to conceptual processing ( ,  ,  ). Specifically, in category fluency tasks, participants are asked to generate objects within a category that tend to have some overlap of their visual features – for example, animals all have legs, eyes, ears etc. Visual imagery or retrieval drawing on these primed features could therefore allow category exemplars to be generated more effectively. \n\nWe also found that effective generation in response to a letter cue, but not a category cue, was linked to reduced connectivity between pIFG and RSC. Recent functional evidence has shown that the RSC shows an increased response when participants generate information from categorical cues ( ), perhaps because generating items in a spatial context facilitates the retrieval of more category members that are also found in the same context (e.g., thinking of a snake in the zoo helps the retrieval of more zoo animals). This interpretation draws on findings showing a response in RSC in situations in which context supports memory retrieval ( ,  ) and more generally through the role of this system in scene construction ( ). Letter fluency would not benefit from the application of context in the same way since items that start with the same initial letter are not typically found in the same context – indeed the generation of strong contextual or schematic information in this task could hinder performance. For example, thinking of snake in the zoo when generating items starting with   S   is likely to elicit competition from concepts related to snake that do not start with the appropriate letter. \n\nOur results build on prior studies that have examined resting state networks linked to semantic processing ( ,  ,  ) by demonstrating differences in the functional coupling between components of the semantic network at rest can be related to differences in performance on a range of semantic tasks. This is consistent with the proposal that aspects of semantic cognition emerge through the flexible coupling of nodes within large-scale distributed networks (e.g.  ). We found that poor performance across tasks (e.g., less efficient synonym judgement and poor letter fluency) was commonly linked to stronger engagement of default mode and limbic regions. Psychologically, letter fluency and synonym performance for high frequency words share a reliance on executive processes ( ,  ,  ,  ,  ,  ), so it is possible that this commonality may reflect the role that control processes play in semantic cognition. For example, some participants may have had more difficulty deploying task-appropriate strategies in the face of strong but irrelevant semantic links: for letter fluency, they may have engaged a search based on global associations, while for synonym judgement, they may have retrieved associations rather than concepts with shared features. Alternatively, some participants may have had difficulty constraining their attention to the task in hand, a state that is known to impact negatively on task performance (for a review see  ). This latter hypothesis is supported by the observation that the DMN ( ,  ) has an antagonistic relationship to executive regions ( ) and can derail task performance when activity occurs under inappropriate conditions ( ,  ). There was a link between poor performance and stronger connectivity between language/semantic and default mode regions in several independent models (e.g., for letter fluency from pIFG, and high frequency words from aSTG): when the regions associated with poorer performance in these analyses were seeded in an independent data set, they showed common areas of functional connectivity in default mode and limbic cortex, most clearly in ventromedial PFC. Nevertheless, these findings do not contradict the view that, under some circumstances, greater engagement of regions within the DMN (e.g., regions in ATL that fall within this network) may show a positive relationship with semantic performance. It may be the specific nature of network-network coupling combined with the specific task demands that determine the consequence for behaviour (see also  ). \n\nIn conclusion, these data demonstrate that performance on semantic tasks can be understood by investigating the functional architecture of the brain at rest. We found that certain features of semantic task performance are linked to patterns of stronger functional coupling, such as the increased temporal correlation between posterior fusiform (VWFA) and ATL which predicted better performance on synonym judgement trials employing high frequency words. Other aspects of semantic performance were linked to decreased coupling between regions, such as the reduced connectivity between the posterior inferior frontal gyrus and the retrosplenial cortex that was linked to worse letter fluency. These data support a component process account of semantic cognition in which semantic retrieval emerges through the flexible interaction of different nodes within a distributed semantic network. One important aim for future studies will be identifying the extent to which there are patterns of resting state activity that are common to particular semantic tasks and others that discriminate between them. It would also be useful to examine how these putative semantic networks at rest are related to the spatial extent of the same networks as localised by online semantic task performance, allowing similarities and differences in the behaviour of semantic cognition networks to be characterised at rest and during tasks (for an example of this see  ,  ). Our method may also aid the assessment of semantic cognition in populations such as children or patients, when measuring task performance can be problematic. \n\nWe conclude with the observation that since prior studies have identified a relationship between functional organisation at rest and the type of cognition that is experienced during the resting state ( ,  ,  ), some of the relationships that our study identified may reflect the expression of spontaneous thought when participants are not actively engaged with an externally-presented task. It seems plausible that particular types of spontaneous thought may recruit aspects of semantic cognition for their expression and elements of the neural coupling that we have identified at rest indicate these relationships. A future comparison of how connectivity patterns at rest relate to ongoing stimulus independent thoughts, and semantic task performance, could reveal the role that the semantic system plays in naturally occurring forms of thinking. \n\n \n","utf8_text_md5_checksum":"1b22fc2ff8ac96a8576b9db1fb96c39d"},
{"annotations":[{"end_byte":91,"end_char":91,"label_name":"Meta-analysis","start_byte":78,"start_char":78}],"display_title":"pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10634720\">10634720</a>","list_title":"PMC10634720  Meta-Analysis Reveals That Explore-Exploit Decisions are Dissociable by Activation in the Dorsal Lateral Prefrontal Cortex, Anterior Insula, and the Anterior Cingulate Cortex","metadata":{"batch":1,"doi":"10.1101/2023.10.21.563317","efetch_url":"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=10634720","field_positions":{"abstract":[333,1673],"authors":[0,53],"body":[1682,45048],"journal":[54,61],"keywords":[266,320],"publication_year":[63,67],"title":[78,252]},"pmc_url":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10634720","pmcid":10634720,"pmid":37961286,"text_md5":"5a0ed4903fa6c70a81b2b43828a24898"},"text":"Sazhin, Daniel and Dachs, Abraham and Smith, David V.\nbioRxiv, 2024\n\n# Title\n\nMeta-Analysis Reveals That Explore-Exploit Decisions are Dissociable by Activation in the Dorsal Lateral Prefrontal Cortex, Anterior Insula, and the Anterior Cingulate Cortex\n\n# Keywords\n\nExploration\nExploitation\nDynamic Decision Making\nfMRI\n\n\n# Abstract\n \nExplore-exploit research faces challenges in generalizability due to a limited theoretical basis for exploration and exploitation. Neuroimaging can help identify whether explore-exploit decisions involve an opponent processing system to address this issue. Thus, we conducted a coordinate-based meta-analysis (N=23 studies) finding activation in the dorsal lateral prefrontal cortex, anterior insula, and anterior cingulate cortex during exploration versus exploitation, which provides some evidence for opponent processing. However, the conjunction of explore-exploit decisions was associated with activation in the dorsal anterior cingulate cortex and dorsal medial prefrontal cortex, suggesting that these brain regions do not engage in opponent processing. Furthermore, exploratory analyses revealed heterogeneity in brain responses between task types during exploration and exploitation respectively. Coupled with results suggesting that activation during exploration and exploitation decisions is generally more similar than it is different suggests, there remain significant challenges in characterizing explore-exploit decision making. Nonetheless, dlPFC, AI, and ACC activation differentiate explore and exploit decisions and identifying these responses can aid in targeted interventions aimed at manipulating these decisions. \n \n\n# Body\n \n## Introduction \n  \nExplore-exploit problems are ubiquitous in many real-world situations such as staying in one line of employment or moving to another, keeping versus selling a stock, or trying out a new ice cream flavor versus sticking with what you know. In situations where a person does not have full knowledge of their opportunities and outcomes, there is a fundamental dilemma of whether to explore the space of possibilities available to them or to exploit what they already know. Due to their prevalence in naturalistic settings, explore-exploit dilemmas have been extensively investigated, with an emphasis on whether certain people are consistently likely to overexploit or underexploit. Over and under exploitation is especially interesting in psychological research as markers of psychopathology, such as among people with anxiety, compulsivity and smoking habits ( ;  ;  ). \n\nDespite the interest in explore-exploit tasks, generating generalizable insights from decisions made in the lab presents several major challenges. The first challenge is that explore-exploit situations generally involve many independent variables that are difficult to control, such as the hidden payoffs of existing options, the number of options available to the participant, the strategies guiding exploration (random or directed), and the time horizons of the tasks ( ). Even simply understanding the payoffs of these choices include a multitude of decision variables such as risk, uncertainty, and ambiguity. Overall, the independent variables investigated, such as uncertainty ( ), task difficulty ( ), information search ( ) suggest explore-exploit decisions are a subset of within a value-based decision-making process. Controlling these independent variables is necessary to assess if exploration and exploitation can be construed as a consistent and useful psychological construct. \n\nSecond, is a lack of behavioral convergence across foraging and n-armed bandit tasks ( ), which suggests that exploration and exploitation may not be guided by consistent attitudes. Third, there remains a lack of a unified theory of exploration and exploitation, behaviorally and neurally, as to whether exploration and exploitation are opponent processes, or the result of the interaction of multiple underlying systems. These major questions suggest that reviewing the common features of exploration and exploitation could yield clarity both theoretically and empirically regarding how the field should understand these decisions. Specifically, by assessing common and distinct patterns of activation between exploration and exploitation across n-armed bandit and foraging tasks, it may be possible to identify evidence for whether explore-exploit decisions are dissociable psychological constructs. To do so, we first review extant literature, followed by conducting a coordinate-based (CBMA) meta-analysis to understand which brain regions are involved in exploration and exploitation. \n\n### Understanding Explore-Exploit Decisions Behaviorally \n  \nMany tasks have been conceived to isolate explore-exploit decisions, though they mostly fall within two categories: foraging tasks ( ) and n-armed bandit tasks ( ;  ;  ). These tasks are highly prevalent in explore-exploit research because they have computationally optimal closed-form solutions. In foraging tasks, a participant selects whether to forage from a patch of resources such as an apple tree, or to travel to another patch at some distance from the current patch ( ;  ;  ). The optimal strategy is determined by a marginal value theorem (pMVT) which is based on the payoffs within a current patch and the distance to the next patch ( ). Foraging tasks can be modeled through Markov decision processes ( ). In n-armed bandit tasks, the participant decides which slot machine they would like to sample from ( ). Explore-exploit decisions are classified through a variety of computational algorithms, such as Boltzmann exploration (softmax), reinforcement learning ( ), and can be approximated through Partially Observable Markov Decision Processes (POMDP) ( ). Ultimately, when the participant chooses bandits higher expected value, the decisions are classified as exploitative and when they choose bandits with lower or unknown expected value, they are classified as explorative (Daw et al., 2006). \n\nWhile there are canonical foraging and n-armed bandit tasks, there are many other variants of these tasks. One variation of the n-armed bandit task is the Horizon Task which runs for 15, 30, or 45 minutes and was developed to discern if task length affects behavior ( ). Another variation of the n-armed bandit is the Leapfrog task where two bandits’ values are fixed until the lower value bandit ‘leapfrogs’ over the higher value bandit at random intervals ( ). Variations of foraging also include the Clock Task ( ). Optimal stopping problems such as the Secretary Task ( ) are also sometimes grouped as explore-exploit dilemmas. With such a variety of tasks, a critical question is whether the independent variables manipulated within these tasks guide exploration and exploitation, or if general tastes in exploration and exploitation tend to guide behavior. If choices are inconsistent between tasks, then exploration and exploitation should not be conceived as independent constructs, but rather as the interaction of the underlying independent variables. Recent evidence suggests that foraging tasks and n-armed bandits lack behavioral convergence ( ) which suggests that how people explore and exploit in n-armed bandits does not predict how people will explore or exploit in a foraging task. The lack of behavioral convergence between tasks is a major challenge as this suggests that there is a lack of a unifying psychological mechanism underlying exploration and exploitation decisions. \n\nAnother approach may be to assess if economic or psychological differences can reliably differences in exploration or exploitation. Investigators have found that the explore-exploit tradeoff was associated information gain and the level of recent rewards ( ), and that this effect was modulated based on the cognitive load experienced by the participant ( ). In the context of temporal discounting problems there have been mixed findings, with one investigation finding associations between temporal discounting and directed exploration and no relationship between temporal discounting and random exploration ( ) and another study suggesting inconsistent preferences for temporal discounting and exploration and exploitation across multiple studies ( ). In assessing effects of impulsive behaviors, or risk attitudes, there were no significant associations with foraging decisions though gamblers exhibited more exploratory behavior ( ). \n\nOther kinds of individual difference measures have yielded somewhat more robust associations with exploratory or exploitative behaviors. Experiences of lifetime scarcity were related to decreased resource-maximizing decision-making ( ) and individuals with adverse childhood experiences explored less in a foraging task ( ). Contextual effects in foraging tasks affect the explore-exploit tradeoff, with greater acute stress yielding overexploitation ( ), increased arousal associated with increased levels of exploration, and increases in valence substantially increased exploitation ( ). Further, there are associations between psychopathologies and explore-exploit decisions. Some examples include that smokers make less initial exploratory choices ( ), people with greater anxiety and depression use lower levels of directed exploration ( ), subjects with alcohol use disorders or binge eating disorders showed decreased exploration when confronted with losses ( ), and people with schizophrenia overuse random exploration strategies ( ). Taken together, explore-exploit tasks have been applied in a variety of psychological domains, yielding little consistency in terms of economic decisions, though people with maladaptive psychological or psychiatric attributes have an attenuated ability to optimize these decisions. \n\n\n### Neurobiological Mechanisms of Exploration and Exploitation \n  \nExplore-exploit tasks lack behavioral convergence, contain a multitude of possible independent variables, and lack a coherent theory as to whether exploration and exploitation are products of disparate versus unified mechanisms. Given the lack of clarity regarding the constructs and behaviors guiding explore-exploit decisions, another approach could examine the neurobiological factors that are consistent across explore-exploit choices. One notable challenge that could be observed neurobiologically is if explore-exploit tasks elicit a consistent or disparate set of responses during exploration versus exploitation ( ) (see  ). If exploration and exploitation elicit reliably different patterns of activation across various tasks, it could provide a window into the mechanisms may modulate explore-exploit decisions through an opponent processing system. Over the past two decades, the accumulation of neuroimaging studies conducted in explore-exploit tasks suggests that reviewing these common patterns may provide insight into explore-exploit decision making as a whole. \n\nExplore-exploit decisions in neuroscience have identified several key cortical and subcortical brain regions that contribute to these choices ( ). In animal literature, the Anterior Cingulate Cortex (ACC) has been identified as a major modulator of explore-exploit decisions. Versions of the n-armed bandit task have been adapted for rats and mice using n-armed radial mazes ( ). ACC activation has been linked to foraging in rats through an adapted patch foraging task ( ) and a two-armed bandit monkey lesion study (Kennerley et al. 2006). Similarly, the dACC is tied to both exploration and exploitation in a monkey foraging task ( ;  ). Nonetheless, other findings suggest that the ventral striatum (VS) and amygdala represent immediate and future value of exploratory choices respectively in rhesus monkeys ( ). In human neuroimaging studies, there are some commonly cited areas of activation in brain regions associated with cognitive control (dlPFC), reward (VS), and attention (ACC), which are often used in region of interest (ROI) analyses ( ;  ;  ). \n\n\n### Evidence for Models of Exploration and Exploitation \n  \nWhile it is known that an array of brain regions is involved in explore-exploit decisions, it remains a key challenge to understand how these brain regions respond to dynamic environments. Two major accounts explain explore–exploit behaviors, which are the interaction of several neural regions depending on contextual features of the explore-exploit decision (e.g., dACC, dorsal striatum, lateral PFC, and VS;  ), or a dual-system driven by opponent processes of exploration and exploitation in frontoparietal regions (e.g., dlPFC, ACC, IPS vmPFC and VS;  ;  ) (  see  )  . If exploration and exploitation are generally more context-dependent rather than dissociable constructs, there may be less consistency in activation across these decision phases and across tasks. Instead, clusters of brain regions may work together depending on the task or context resulting in exploration or exploitation behavior ( ,  ,  ). With this interpretation, exploration and exploitation behaviors may be more context specific, and could potentially better described by underlying variables such as the risk, uncertainty, information, time horizons or other variables involved in the decision-making process. Thus, an interplayed model may be the combination of underlying psychological constructs in a given situation. Nonetheless, one challenge of an interplayed model is that there could also be a more complex set of responses to exploration or exploitation, potentially represented through connectivity patterns in the brain. It is also plausible that exploration and exploitation can be construed as opponent processes with concrete neural markers that reliably switch between exploration and exploitation ( ). If this model has greater support, exploration and exploitation would be dissociable across tasks with consistent neural markers of activation. Furthermore, if there is evidence of opponent processing in exploration and exploitation this could allow for targeted interventions aimed at modulating these behaviors. \n\nIn trying to reconcile these accounts, studies tease apart how certain elements of explore-exploit dilemmas contribute to those decisions. For instance, understanding how environmental uncertainty and trends in information mediate this process may inform some of the underlying mechanisms in explore-exploit choices, with environmental uncertainty of new options ( ;  ;  ) seemingly largely processed in the PFC. Uncertainty in an environment has been represented in the brain in several ways, with relative uncertainty in the right rostrolateral PFC ( ) and striatal dopamine function ( ) driving directed exploration. The vmPFC was implicated in representing environmental uncertainty ( ), evidence accumulation in switching decisions ( ), and determining the value of well-defined foraging options ( ). Taken together, these findings reinforce the importance of both frontopolar and subcortical regions in explore-exploit decisions, though it remains unclear to what degree an opponent process model driven by the frontoparietal cortex is supported by the weight of the evidence. \n\nIn sum, the current state of knowledge is limited in identifying consistent elements supporting neural circuitry associated with explore-exploit decisions, whether there are systematic biases in the literature, and if certain brain regions remain underemphasized in the reporting and interpretation of the data. One means of addressing these limitations is through quantitatively assessing patterns of activation across neuroimaging studies using coordinate-based meta-analyses (CBMA). We hypothesized that there would be convergence across explore-exploit studies in the activation of the vmPFC, dlPFC, VS, ACC, and IPS during explore-exploit decisions. These decisions are differentiated from the feedback phase where participants receive rewards based on their decision. While the feedback phase can provide important information for encoding the value of current and alternative outcomes while receiving feedback ( ;  ) the feedback phase does not completely capture the decision to shift choices on the following turn. Next, we expected that the exploitation versus exploration decision would be associated with greater vmPFC, VS, ACC activity in the exploration phase and that the exploration phase would be associated with greater activation in the IPS and dlPFC than in the exploitation phase. \n\nSince we began this investigation, two groups of researchers have conducted meta-analyses of explore decisions ( ), finding that exploration results in consistent activation of the dorsal medial prefrontal cortex and anterior insula, dorsolateral prefrontal cortex inferior frontal gyrus, and motor processing regions. ( ). We extend these results by comparing exploration versus exploitation with a larger sample of studies and investigating task-based differences between exploration and exploitation using Seed-based D Mapping (SDM) software. Including the contrast between exploration and exploitation serves as a crucial means to subtract the effects of value-based decision making in order to understand activation that is unique to exploration and exploitation. Another group argued that prefrontal and parietal circuits integrate and switch between exploration and exploitation. Our approach differs from ( ) in that we conducted a quantitative rather than qualitative meta-analysis, with regions identified subsequent to conservative thresholding and permutation testing. Overall, our results aims to identify activation patterns that are unique to exploration and exploitation, thereby helping identify to what degree we can theoretically understand these choices within an opponent processing model. We also explore activation differences between n-armed bandits and other types of explore-exploit tasks while making exploration or exploitation decisions. In summary, we investigate the common patterns of activation across explore-exploit tasks, whether there are systematic biases in the literature, and if there are other regions that are underemphasized in the interpretation of the data. \n\n\n\n## Materials and Methods \n  \n### Inclusion Criteria and Study Selection \n  \nThe current coordinate-based meta-analysis primarily followed PRISMA guidelines for meta-analyses regarding inclusion criteria, filtering, and analyses ( ). We incorporated a pre-registration ( ), which detailed the hypotheses and analyses we intended to use. We conducted a systematic literature search to identify explore-exploit studies that used neuroimaging techniques. First, we identified search terms by examining task names from several existing explore-exploit literature reviews ( ;  ;  ). Potentially eligible studies published through 1/01/2023 were identified by searching the PUBMED using the grouped terms: (n-armed OR exploration-exploitation OR explore-exploit OR multi-armed OR forage OR foraging OR “reward rate” OR (explore AND exploit) OR “reward trend” OR “clock task” OR clock-task OR “temporal-difference” OR “patch leaving” OR patch-leaving OR leave-stay OR “time horizon” OR “horizon task” OR bandit OR MVT OR “marginal value theorem” OR leapfrog OR “leap frog” OR leap-frog OR prey model OR “diet breadth model” OR “web surfing task” OR “web-surfing task” OR trend-guided OR “uncertainty driven”) AND (fMRI OR “functional magnetic resonance imaging” OR neuroimaging OR brain OR neural OR MNI OR “Montreal Neurological Institute” OR Tal OR coordinates). To enhance search sensitivity, the reference lists of the retrieved articles and review papers were further checked to identify potentially relevant articles. Additionally, we included studies that reported whole-brain analyses, as region of interest based analyses can bias coordinate-based meta-analyses ( ) and were thus excluded. Finally, we incorporated studies that reported coordinates in a standard stereotactic space [i.e., Talairach or Montreal Neurological Institute (MNI) space]. The search process was conducted by Avi Dachs, with the first author identifying the studies accepted for final inclusion in the meta-analysis. For eligible studies that did not report whole-brain data, we contacted authors if the required information was unavailable in the published reports. \n\nThe initial PUBMED search yielded 6,214 papers. Of these, 5,256 papers were then excluded based on title, leaving 958 papers to be excluded by abstract and full text contents. Of the 958 remaining papers, 762 papers were excluded for not covering explore and exploit tasks, 72 relevant papers were excluded for not collecting fMRI data, 45 animal studies were excluded, and 14 non-empirical papers were excluded, leaving only 65 papers for data extraction and coding (see  ). In the coding phase, 47 more papers were excluded due to data that were incompatible with our analysis (i.e., not fMRI or whole-brain), leaving a total yield of 19 papers. Finally, our list of papers was cross-referenced with the papers included in a similar meta-analysis ( ) revealing 4 papers that had been wrongly excluded from our search. After these papers were added, our final corpus included 23 papers with a cumulative N of 602 participants (see   and  ). In total, we included 13 n-armed bandit studies, which varied in the number of bandits presented to the participant. We identified foraging tasks and 3 other tasks, including a problem-solving task, clock hand task, web surf task, and an observe-bet task. We grouped non-n-armed bandit tasks into an “other” category with a total of 10 studies to serve as a comparison group. Unlike n-armed bandits, the “other” tasks do not employ feedback about exploration or exploitation on each turn. Foraging, web-surf, and observe-or-bet tasks have clear shifts between exploration and exploitation based on observable changes in strategy. The clock hand task employs a fixed reward structure which is learned over time and exploration and exploitation is classified based on response times ( ). Thus, we classify tasks that do not have a continuous sequence of changing rewards as “other” types of exploration and exploitation tasks. Further, n-armed bandits involve   inferred   shifts to exploitation, whereas foraging tasks have distinct shifts from exploiting to traveling to other patches ( ). While both n-armed bandit and foraging tasks are grouped as explore-exploit tasks, they are sufficiently different to serve as potential comparison groups. \n\n\n### Statistical Analysis \n  \nWe conducted a CBMA meta-analysis using Seed-based d mapping software (SDM-PSI version 6.22). SDM was implemented using several steps to conduct analyses described in the SDM tutorial and manual. First, we imported the screened data by preparing folders with MNI text files that reported the clusters and t values for each coordinate. Exploration and exploitation decisions were grouped based on the constructs reported in each study. 11 studies reported explore>exploit and exploit>explore contrasts and were coded as exploration and exploitation respectively (see  ). Other studies reported parametric effects for exploration and exploitation decisions (see  ) through assessing several components underlying value-based decisions in uncertain environments. Studies modulated uncertainty ( ;  ), relative value ( ), task difficulty ( ), search evidence, and search cost across decision stages (i.e.., exploration in Stage 1 and exploitation in Stage 2) ( ). We classified reinforcement learning associated with recent experience as exploration ( ). Another variation of reinforcement learning included assessing exploitation as the last average reward rate, whereas exploration reflecting the expected values associated with learning past reward rates ( ). Another study coded foraging value-decision value contrast for exploration and search value-decision value contrast for exploration ( ). \n\nAnother study varied the parametric value of staying with a foraging patch whereas exploration was classified as the difference in decision versus consumption ( ). Switch-in events were classified as exploration and activation associated with actor absolute reliability as exploitation due to the behavioral design ( ). Other studies varied the presence or absence of newly available information ( ), and the advantageousness of the environment ( ). In another study, the modeled choice kernel reflected exploratory decisions ( ). These classifications of exploration and exploitation reflect the coordinates selected for analysis and are accessible on OSF. Overall, the parametric effects generally reflected sensitivity to value, information, or uncertainty while exploring or exploiting an uncertain environment. \n\nNext, we created an SDM table with all the respective peak coordinates. We noted t-stats in the SDM table with respect to effect sizes and converted reported p and z stats using the SDM “convert peaks” function (see  ). Then, we completed preprocessing using Functional MRI as its modality, with a gray matter correlation matter template following validated methods ( ;  ). We used a 1.0 anistropy setting, a 20 mm FWHM isotropic kernel, a gray matter mask, and a standard 2mm voxel size. This was followed by a mean analyses with 50 imputations ( ). To compare exploration and exploitation decisions, and n-armed bandit versus other tasks, we generated linear models respectively where we compared these groups by assigning a linear model analysis ( ). We used the SDM meta-regression tool with prediction dummy variable {exploit=1, explore=0} and {n-armed=1, other=0} for the positive side of the significance test. Additionally, we included several nuisance regressors to control potentially confounding variables. Specifically, we included analysis type (parametrically modulated = 1, unmodulated = 0) and the smoothing kernel size ( ). We included these nuisance regressors to ensure that analysis type was not a confounding variable and since the size of the smoothing kernel can move the observed activation anterior or posterior of the brain. \n\nSubsequently, we performed family wise error corrections and using n=1000 permutations ( ). This correction controls for multiple comparisons by randomly swapping the effect-sizes between the voxels for each study, recalculating the means of the studies for each voxel and saving the maximum of the means ( ). The results were then thresholded using threshold-free cluster enhancement (TFCE) with a corrected probability threshold of   p   < 0.05 ( ). TFCE has also been shown to have a sensitivity comparable to a Family Wise Error correction and yield valid results with only about five percent of significant clusters based on spurious convergence across 200,000 simulated meta-analyses ( ). TFCE statistics are generally neither too liberal or conservative and have been used across many meta-analyses ( ;  ;  ). Masks were created and their values were extracted for reporting. For the conjunction of explore and exploit conditions, we conducted a CBMA of explore and exploit conditions respectively, and then used the multimodal function provided by SDM to produce the conjunction map. \n\nTo assess potential heterogeneity and potential bias in the CBMA results, we extracted funnel plots. We report the strength of evidence through multiple robustness considerations, study heterogeneity (I2 statistic), effect of small studies on the results (metabias) with resulting funnel plot asymmetry, and excess significance. The funnel plots are constructed through assessing the residual, or the weight each study has in the meta-analysis, with the size of its treatment effect, identified as precision on the y axis, though these tests must be interpreted with caution as publication bias can arise from multiple sources ( ). All analyses were completed in Montreal Neurological Institute (MNI) space. To report consistent results across human brains ( ), we show probabilistic anatomical labels for clusters of activation using the Harvard–Oxford cortical and subcortical atlases ( ). \n\n\n\n## Results \n  \nWe completed meta-analyses that assessed activation across explore-exploit tasks, followed by activation specific to exploration and exploitation. All meta-analyses controlled the size of the smoothing kernel, as well as whether the analyses reported were parametrically modulated or unmodulated. The first meta-analysis investigated activation pooling across both exploration and exploitation conditions and is reported in  . Next, we assessed the contrast between exploration and exploitation. Subsequently, we report activation that is consistent across both exploration and exploitation. Lastly, we show exploratory results revealing activation that is greater among n-armed bandit tasks versus other tasks during exploitation and exploration. \n\n### Neural Responses Between Exploration versus Exploitation Phases \n  \nWe conducted a CBMA contrasting the exploration and exploitation conditions across all the explore-exploit tasks. We hypothesized that the exploitation phase would be associated with greater vmPFC, VS, ACC activity than the exploration phase. We did not find any significant clusters for exploitation versus exploration that exceed a threshold of   p   < .05. Next, we hypothesized that the exploration phase would be associated with greater activation in the IPS and dlPFC than in the exploitation phase. Our results indicated five significant clusters of activation in the dorsolateral prefrontal cortex, right dorsal anterior cingulate cortex, anterior insula, and superior temporal gyrus (see  ,  ). Using the Harvard-Oxford Atlas, our results were consistent with our hypotheses in finding stronger activation in the dlPFC during exploration versus exploitation. We followed up with analyses of metabias and excess significance, finding no significant metabias or excess significance for this CBMA. \n\n\n### Neural Responses to the Conjunction Between Exploration and Exploitation Phases \n  \nWe conducted a conjunction analysis across exploration and exploitation in the sample of studies we collected. We hypothesized that the conjunction of explore and exploit phases would be associated with activation in the IPS, dACC, and dlPFC. Supporting our hypothesis, we found common activation in the dACC in the conjunction between exploration and exploitation decisions (see  ). Activation in exploration and exploitation elicits common activation across multiple regions with a correlation of   r   = .62 across the unthresholded explore and exploit images. These results suggest that areas of common activation should in the future be closely examined using multivariate and connectivity methods to understand how they are involved in exploration and exploitation. In contrast to our hypothesis, we did not find convergence in the IPS or dlPFC. We also found conjunctive patterns of activation in the dmPFC and anterior insula. \n\n\n### Differential Activation Between N-Armed versus Other tasks During Exploration and Exploitation \n  \nWe followed up our pre-registered hypotheses by assessing if there are differences between activation in n-armed bandit tasks compared to other tasks during exploration and exploitation. If there are activation differences between tasks, this may suggest that these tasks are not eliciting consistent patterns of activation in exploration and exploitation as may be expected. During exploration, we did not find any activation differences between n-armed bandits and other tasks. During the exploitation phase, we found that other tasks versus n-armed bandits resulted in two significant clusters (see  ,  ). There was no reported excess significance, or metabias in the results (  p   > .001). \n\n\n\n## Discussion \n  \nThis investigation conducted a coordinate-based meta-analysis of explore-exploit tasks. We included both n-armed bandit and other types of explore-exploit tasks and analyzed them to assess patterns of activation that are consistent across explore-exploit decisions, as well as unique to exploration and exploitation decisions respectively, and differences in activation between tasks. First, we found consistent activation unique to exploration and exploitation decisions, with activation in the dlPFC, vmPFC, ACC, IPS, dmPFC, and VS, suggesting that exploration and exploitation generally evoke activation associated with value-based decision-making ( ). Second, we found greater activation in the dlPFC, dACC, and the AI during exploration versus exploitation. \n\nThird, we conducted an exploratory analysis to assess differences between n-armed bandits and foraging tasks during exploration and exploitation respectively. We found differences in activation in the AI and dmPFC between other tasks and n-armed bandit tasks during exploitation. Overall, our meta-analytic results support previous findings that have identified critical regions involved in exploration and exploitation. Specifically, we found convergence in brain regions reported in the seminal study by Daw et al., 2006 with activation in the dlPFC, vmPFC, IPS, ACC, and VS being involved in both exploration and exploitation. This finding suggests that exploration and exploitation evoke activation consistent with value-based decision-making ( ), although it does not control for activation unique to these individual decision phases. \n\n### Opponent Processing versus Interplaying Models of Exploration and Exploitation \n  \nWhen we investigated the contrast between exploration and exploitation, we found stronger activation in the dlPFC, AI, and dACC during exploration compared to exploitation, suggesting that these regions are part of opponent processes in explore-exploit decisions. These results are consistent with past findings ( ), suggesting that the dlPFC may contribute to tracking the value of alternative choices ( ;  ), attending to risk ( ), tracking uncertainty ( ;  ), and guiding directed exploration ( ). Additionally, as the dlPFC is implicated in cognitive control ( ), dlPFC activation may affect working memory as it relates to information gain and integrating recent rewards ( ;  ). \n\nThe AI subserves several notable computational mechanisms that are relevant for exploration and exploitation. Overall, the AI has been found to respond more strongly exploration versus exploitation ( ;  ;  ;  ). Two recent accounts suggest that the AI could be processing risk ( ), or could serve as part of a broader salience network during exploration ( ). While the AI serves an important role within valuation processing ( ), other studies have indicated that the AI is stronger activated with the sudden introduction of reward structures rather than stable reward systems ( ). Thus, while the AI is involved in risk processes ( ;  ), its role may involve orienting the dACC and dlPFC toward changes in valuations related to risk and uncertainty. \n\nThe ACC may contribute to exploration versus exploitation by tracking trends in foraging tasks ( ;  ), preparing movement away from disadvantageous foraging patches ( ), with more self-focused individuals showing lower activity in dACC compared to individuals who were foraging for others ( ), and evaluating salient feedback for learning optimal strategies ( ). Nonetheless, the interpretations emphasizing the role of the ACC in foraging may be confounded as one investigation found that dACC engagement was explained solely by choice difficulty, and not the value of foraging ( ). Our results are consistent with the prefrontal and parietal circuits integrating and switching between exploration and exploitation ( ;  ). Integrating the roles of the dlPFC, AI and dACC in regulating exploration versus exploitation is also consistent with recent findings suggesting that these regions could be part of a circuit that modulates strategic decisions ( ) and contribute to the opponent processing of exploration or exploitation. \n\nIn contrast to recent meta-analyses ( ;  ), our results suggest that many brain regions involved in value-based decision making are coactivated across both exploration and exploitation rather than evoking distinct patterns of activation. For example, our results suggested that the dorsal medial prefrontal cortex and premotor cortex ( ) were involved in both exploration and exploitation. While these brain regions may be involved in exploration, by subtracting activation related to exploitation we show that these other brain regions may be simply involved in the overall value-based decision process ( ) rather than being unique to exploration. Additionally, while the qualitative approach taken by Wyatt and colleagues indicated that the IPS and Precuneus have greater activation during exploration and exploitation, our quantitative analyses indicate that many of these regions fail to survive thresholding and are generally sensitive to both exploration and exploitation. Thus, while we agree with a recent empirical work that control and attention networks are involved in exploration ( ), our results suggest that more precisely that the dACC, AI, and dlPFC are potentially the more relevant brain regions arbitrating between exploration and exploitation decisions. \n\nHowever, there remain two large issues in interpreting exploration and exploitation through the lens of the opponent process model. The first is that there are more similarities than differences in activation across our results. Even when controlling for the effects of exploration and exploitation decisions specifically, our conjunction analyses reveal that exploration and exploitation generally elicit similar patterns of activation, particularly in the ACC and dmPFC. These results suggest that areas of common activation should closely examined on the future using multivariate and connectivity methods to understand how they are involved in exploration and exploitation. Extending a previous meta-analysis suggests that these regions are not unique to exploration ( ), but are also involved in exploitation. As a result, when differences are reported in these regions, they may be due to the interplaying of more complex underlying variables modulating these brain processes rather than a product of a general opponent processing system for exploration versus exploitation decisions. \n\nSecondly, our exploratory analyses suggest that there remains substantial heterogeneity between tasks. This issue may speak to the lack of behavioral convergent validity between these tasks ( ), which is to say that a participant exploiting in a foraging task does not predict how they will exploit in an n-armed bandit task. During exploitation, we found differences in activation in the insula and dmPFC between other tasks and n-armed bandits. In theory, we would not expect to see differences in activation if exploitation across tasks reliably elicit similar responses, we would not expect to see differences between these tasks. Nonetheless, the differences in AI and dmPFC could reflect differences in how people perceive risk and uncertainty (ie:  ) or salient features (ie: ( ) while exploiting in n-armed bandits versus foraging tasks. Thus, while our results suggest that while the dACC, AI and dlPFC differentiate exploration and exploitation, these constructs remain fragile to the context of the decision based on task, and that most of the activation associated with these decision processes is indistinguishable and is modulated based on context. As such, the interplaying model of exploration and exploitation is generally a better descriptor of these constructs, though the dlPFC, AI, and dACC can act as opponent processes between these types of decisions. \n\n\n### Limitations \n  \nAlthough our work has found that exploration and exploitation can be dissociated by dlPFC, AI, and dACC activation, we acknowledge our study has several notable limitations. First, while we included N=23 studies, this quantity is fairly low for a CBMA type meta-analysis, with a common benchmark suggesting a minimum of 17–20 Experiments (Yeung et al. 2019). However, the exploratory CBMA of n-armed bandits versus other tasks during exploration and exploitation contrasted 13 versus 10 studies. Since this sample size is below the benchmark, it should be considered exploratory. Nonetheless, there is a lack of clear guidance as to what constitutes acceptable sample sizes for SDM, as this highly depends on the effects measured, the number of participants, and whether thresholded images are included or not. Second, while we found substantial areas of coactivation between explore-exploit conditions, we cannot conclude that these areas are consistently involved with both types of decisions. For example, prior studies have shown that a region may appear to be involved in different processes despite having patterns of activation and connectivity profiles ( ;  ). Further analyses could disentangle the involvement of these brain regions and show distinct connectivity with other brain regions to better understand their involvement in explore-exploit decisions. \n\nOther limitations extend beyond meta-analytic methods when assessing exploration and exploitation more generally. Explore-exploit tasks limit the manner in which information is presented, and a latent variable that may bias switching decisions includes the trend in information. Some studies have started to explore the effects of trends in information ( ;  ;  ), though it remains underexplored how these trends bias people to act too soon or too late. Further, brain connectivity ( ;  ) may reveal patterns of explore-exploit decision making, yet few connectivity studies ( ;  ) have been completed in this domain. Since the default mode network (DMN) is implicated in executive function and cognitive control ( ), and the executive control network (ECN) serves to rapidly instantiate new task states ( ), both the DMN and ECN could interact to drive exploiting versus exploring decisions. Future studies may reconcile the gap that remains in understanding how explore-exploit decisions are associated with brain connectivity patterns. \n\nWhile acknowledging limitations for generalizing both behavioral and neural results resulting from exploration and exploitation, the finding that the dlPFC, AI, and dACC reliably distinguish exploration and exploitation could inspire important future directions. First, a fruitful future direction includes modulating dlPFC responses, which are quite common in transcranial stimulation studies. Since there are many links between the dlPFC and psychopathology such as schizophrenia ( ), anxiety ( ), and substance use ( ), regulating dlPFC activation may reliably modulate explore-exploit decisions. Specific to substance use, while there has been extensive research into the neural mechanisms of addiction, it remains underexplored how individual differences in decision making serve as risk factors for increasing consumption of substances. Past investigations revealed that smokers explore less and learn faster ( ) and require greater cognitive control when exploring ( ). People with greater alcohol use tend to avoid uncertainty ( ) and explore less. Brain responses may be modulated by substance use and mediated by social context ( ). Sharing rewards with friends decreases connectivity between VS and dorsomedial prefrontal cortex ( ), suggesting that social contexts are an important feature of understanding substance use decisions. Future investigations could also study the role of trends in decision making and assess whether substance users forecast future trends worse than non-substance users. Using explore-exploit dilemmas, researchers can assess how people make predictions, and whether substance users have an impaired cognitive ability to predict future outcomes. \n\n\n### Conclusion \n  \nIn summary, we conducted a coordinate-based meta-analysis of neuroimaging studies using explore-exploit tasks. We found that areas associated with executive control (dlPFC), attention (IPS, dACC), and reward (VS) are reflected in exploration and exploitation decisions. Exploration versus exploitation can be distinguished by greater activation in the dlPFC, AI, and dACC. Nonetheless, there remains substantial heterogeneity in brain responses due to task types, modulated by activation in the AI and the dmPFC while exploiting. Further, exploration and exploitation are associated with more similar than dissimilar patterns of activation in the AI, dmPFC, ACC, and VS. These results suggest that exploration and exploitation are not reliable opponent processes but are more of a product of the interplaying of underlying physiological and psychological features guiding these decisions. Nonetheless, the finding that the dlPFC, AI, and dACC distinguish exploration and exploitation could serve as an important area of future research in cognitive neuroscience and psychopathology, as modulating these brain regions could shift how people explore and exploit. \n\n\n\n## Supplementary Material \n  \n \n","utf8_text_md5_checksum":"5a0ed4903fa6c70a81b2b43828a24898"},
{"annotations":[{"end_byte":13468,"end_char":13430,"label_name":"RestingState","start_byte":13455,"start_char":13417}],"display_title":"pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9202476\">9202476</a>","list_title":"PMC9202476  Visual Attention and Poor Sleep Quality","metadata":{"batch":1,"doi":"10.3389/fnins.2022.850372","efetch_url":"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=9202476","field_positions":{"abstract":[278,2161],"authors":[0,46],"body":[2170,36886],"journal":[47,61],"keywords":[131,265],"publication_year":[63,67],"title":[78,117]},"pmc_url":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9202476","pmcid":9202476,"pmid":35720693,"text_md5":"0e5118e34b06053e8259e7a050f4da4f"},"text":"Abdolalizadeh, Amirhussein and Nabavi, Samaneh\nFront Neurosci, 2022\n\n# Title\n\nVisual Attention and Poor Sleep Quality\n\n# Keywords\n\nsleep quality\nsleep deprivation\nattention network\nvisual search\nMRI\nsuperior longitudinal fasciculus\narcuate fasciculus\nbrain mapping\n\n\n# Abstract\n \n## Background \n  \nSleep deprivation disrupts visual attention; however, the effects of chronic poor sleep quality on it are not understood. The dorsal attention network (DAN) and the ventral attention network (VAN) are involved in visual attention and search (VSA), with the DAN being important for the serial attention network and the VAN for parallel “pop-out” visual search. \n\n\n## Objective \n  \nThe aim of the study was to evaluate correlation of sleep quality with visual attention and search, functional, and tracts’ properties of the DAN and VAN. \n\n\n## Materials and Methods \n  \nWe recruited 79 young male subjects and assessed their sleep quality using the Pittsburgh Sleep Quality Index (PSQI), dividing subjects into poor sleepers (PSs) and good sleepers (GSs) based on a cutoff of 5. Daytime sleepiness, sleep hygiene, depression, and anxiety levels were also evaluated. We assessed VSA using a computerized match-to-sample (MTS) task. We extracted functional networks and tracts of the VAN and DAN and statistically assessed group differences in task performance and imaging covarying age, depression, and anxiety. An interaction model with MTS × group was also done on imaging. \n\n\n## Results \n  \nIn total, 43.67% of subjects were PSs. Sleep quality significantly correlated with daytime sleepiness, sleep hygiene, depression, and anxiety (all   p   < 0.001). No between-group differences were seen in task performance and functional or tract properties of the attention networks. Interaction analysis showed that the task performance was highly reliant on the DAN in PSs and on the VAN in GSs. \n\n\n## Conclusion \n  \nOur findings show no association between sleep quality and VSA in task performance and imaging correlates of the attention network. However, unlike the GS group, poor sleep quality is associated with VSA being more reliant on the DAN than on the VAN. \n\n \n\n# Body\n \n## Introduction \n  \nProper sleep is required to maintain optimal cognitive function. Lack of nighttime sleep, even for one night, has detrimental effects on several cognitive functions, especially sustained attention and vigilance, but other cognitive aspects are also involved, including executive function and sensory perception (e.g., visuospatial perception) ( ). Evaluating different aspects of sleep (subjective quality, duration, daytime sleepiness, etc.) over a period of time, rather than simply assessing the duration of one-night sleep, can provide a more robust and general assessment of sleep function and quality. The Pittsburgh Sleep Quality Index (PSQI) ( ) is based on the aforementioned factors to assess sleep over a period of 1 month to better determine the presence of any chronic poor sleep quality. Using the PSQI and depending on the community studied, chronic poor sleep has been found in around one-third to half of the population ( ;  ;  ). Of great importance, poor sleep quality is usually associated with concurrent medical or psychiatric conditions (e.g., depression and anxiety) ( ;  ). Despite the high prevalence of chronic poor sleep quality and its associations with psychiatric comorbidities, its effects on cognition have not been extensively studied. Previous studies have shown that poor sleep quality based on the PSQI is associated with problems in sustained attention ( ;  ), executive function ( ), and working memory ( ) in healthy community samples. However, complex cognitive functions, such as visuospatial attention and search, which require the proper function of multiple cognitive aspects (including but not limited to attention and visual pattern recognition), have not been studied. \n\n proposed a dual network model for attention: the dorsal attention network (DAN) connecting visual and parietal areas (especially intraparietal sulcus [IPS]) to frontal areas (especially frontal eye fields [FEFs]), and the right-side dominant ventral attention network (VAN) connecting middle and superior temporal gyri and temporoparietal junction (TPJ) to the middle and inferior frontal areas. According to their model, the DAN is involved in orienting attention overtly or covertly in space. The VAN seems to work as a “circuit breaker” for the DAN, in which it directs the DAN to unattended task-related or unrelated salient stimuli ( ;  ;  ;  ;  ). Of course, these two networks are highly connected having reciprocal connections, and the DAN also updates the VAN regarding the expected stimuli ( ). Importantly, the VAN is different from the salience network, in which the latter involves the cingulum, the pre-motor supplementary, and the insula–frontal operculum ( ). Tractography studies using diffusion-weighted imaging (DWI) have identified major tracts associated with each network. The superior longitudinal fasciculus (SLF) has three branches: SLF-1 located dorsally connecting the IPS to superior frontal areas and FEFs (i.e., nodes of the DAN), SLF-3 located ventrally connecting nodes of the VAN, and SLF-2 seems to connect lower parietal areas and the TPJ to superior frontal areas, probably being the pathway between the DAN and VAN ( ;  ,  ). Also, the arcuate fasciculus (AF) on the right side is involved in connecting the VAN nodes to each other ( ). However, how do these networks relate to visual search? \n\nVisual search is a complex behavior requiring working memory, scenery-related information processing (e.g., pattern recognition, color, and shape), and attention. Two models are proposed for visual search. In the “serial” search (inefficient), the subject screens each object independently, matching it with the sample presented or asked. However, it seems that, in real-life situations, we usually implement the “parallel” strategy (efficient, “pop-out”); despite being overtly attended to one location in space, the attention is covertly scanning the periphery and nearby, searching for the target stimuli, and changing the overt attention toward the target upon finding it ( ). In a previous study by Leonards et al., fMRI activation maps of both parallel and serial search strategies overlapped significantly on the IPS, FEFs, and occipital areas (e.g., lateral occipital cortex). Contrasting search strategies against each other revealed more activation in superior frontal areas in serial search than in parallel search ( ). In another study, the same patterns of serial vs. parallel activation differences were seen in frontal, superior parietal, and superior occipital regions ( ). Although these two studies have not mapped the found areas on the networks, it seems the serial vs. parallel contrast mostly overlaps over the DAN. In a recent study by   using a designed task to force the subjects to use the overt serial visual search task resulted in higher activation of the DAN. In another study using an exploratory visual search task similar to real-life situations, DAN activation was associated with orienting toward the salient stimuli. By contrast, the right supramarginal gyrus, a major node in the VAN, was activated by processing the targets, probably indicating the template-matching function in this region ( ). Direct intracranial recordings also support the notion that parallel search strategies are reliant on the VAN ( ). Moreover, inactivating DAN nodes (FEFs and IPS) using repetitive transcranial magnetic stimulation disrupted the non-pop-out search strategy, while it had no effect on the pop-out visual search, proving a causal role of the DAN in the serial visual search ( ). \n\nIn this study, we first aimed to examine the effects of chronic poor sleep quality on a complex attention task, visual search and attention, controlling for major confounds such as depression and anxiety. Next, we examined the effects of chronic poor sleep quality on neuroimaging correlates of visual attention using fMRI to identify the DAN and the VAN and using DWI to delineate fibers connecting these two networks (i.e., SLF 1-2-3 and right AF). Finally, using an interaction model, we attempted to identify the association between sleep quality × brain findings and task outcomes. \n\n\n## Materials and Methods \n  \n### Subjects \n  \nIn total, 79 subjects were recruited via local flyers and online advertisements using Twitter and Telegram channels in the city of Tehran, Iran [mean age (SD) = 24.10 (4.16)]. The inclusion criteria for this study were being men, being 20–40 years of age, having no current or previously untreated psychiatric or neurologic disorders, with no prior history of head trauma leading to loss of consciousness, with no history of claustrophobia, and with no current signs or symptoms of or admission history due to COVID-19. This study was approved by the Ethics Review Board of Iran University of Medical Sciences, Tehran, Iran, with the ID IR.IUMS.REC.1400.026. \n\n\n### Sleep Questionnaires \n  \nSubject demographics including age, handedness, education, marital status, smoking behavior, and any drugs taken or discontinued were acquired. To assess sleep, we used the Persian-translated and validated versions of the Pittsburgh Sleep Quality Index (PSQI) ( ;  ), Epworth Sleepiness Scale (ESS) ( ;  ), and Sleep Hygiene Index (SHI) ( ;  ). The PSQI includes 10 questions, some with several parts, and assesses sleep quality using seven components: subjective sleep quality, sleep latency, sleep duration, habitual sleep efficiency, sleep disturbances, use of sleep medications, and daytime dysfunction. The total PSQI score is the sum of the seven components, and values > 5 are considered to indicate poor overall sleep quality during the last month ( ,  ). The subjects were categorized based on their PSQI total score: poor sleeper (PS; PSQI total > 5) vs. good sleeper (GS; PSQI total ≤ 5). The ESS evaluates daytime sleepiness by the probability of falling asleep during daytime. A higher ESS total score shows higher sleepiness. The SHI is a 13-item questionnaire targeted at activities reducing the quality or probability of initiating night-time sleep (e.g., use of caffeinated beverages before sleep and sleeping in an uncomfortable bedroom). A higher SHI score indicates poor sleep hygiene. \n\n\n### Psychiatric Questionnaires \n  \nDepression and anxiety are major contributors and are also affected by sleep quality. We used Beck Depression Inventory II (BDI-II) ( ,  ;  ) to evaluate depression; a higher sum of all question scores in this 21-item self-report questionnaire indicates higher depressive scores. We also used the State and Trait Anxiety Inventory (STAI) ( ) to assess current (state; STAI-S) and trait (STAI-T) anxiety of the subjects. Higher scores indicate higher anxiety. A meta-analysis also supported that the STAI is the best anxiety questionnaire to examine anxiety in sleep problems ( ). \n\n\n### Visual Search and Attention \n  \nWe used the match-to-sample (MTS) task of the Cambridge Neuropsychological Test Automated Battery (CANTAB) for visual search and attention ( ). In this computerized task, subjects were presented with a complex figure in the middle of the screen. Then, a few patterns were shown in the periphery, from which one was matched with the presented pattern. In the first trials, two patterns were presented in the periphery, and it was increased to eight patterns in the final trials. A total of 48 trials were conducted for each subject. Total correct, mean reaction time (RT), and mean RT change from 2 to 8 pattern trials were calculated for each participant. Prior to the task, the subjects were instructed by an expert cognitive scientist in CANTAB and were allowed to take mock trials to ensure they have completely learned the task. \n\nWe chose this task for several reasons: First, it can be easily performed irrespective of subjects’ education or prior experience. Second, it can assess two complex functions, namely, visual search and visual attention, at the same time. Third, in many tasks, the subjects’ hand movement time cannot be separated from the reaction time; however, in the MTS of CANTAB, the subjects had to hold the mouse button until they have found a match, release it, and touch the target on a touch screen. Thus, the interval between stimulus presentation and mouse click release is considered the reaction time. Of note, it is different from the delayed match-to-sample task, in which working memory load becomes increasingly important. Since previous studies have shown the association between working memory dysfunction and poor sleep quality ( ), we chose the current task version to minimize the effects of working memory on task performance. Finally, the samples and stimuli were matched or non-matched based on their complex figures and different colors, resulting in a higher load on visual processing. \n\n\n### Imaging Acquisition \n  \nAll imaging acquisitions were carried out in a single session using a 3T Siemens Prisma MRI scanner located at the National Brain Mapping Laboratory (NBML), Tehran University, Tehran, Iran. The imaging protocols were as follows: T1 MPRAGE (TR/TE/TI: 2000/3.62/845 ms, FoV: 256 mm, voxel size: 0.8 mm  × 0.8 mm  × 0.8 mm ), T2 SPACE (TR/TE: 3200/409 ms, FoV: 256 mm, voxel size: 0.8 mm  × 0.8 mm  × 0.8 mm ), resting-state fMRI (TR/TE: 2000/30 ms, FoV: 240 mm, 180 measurements, voxel size: 3 mm  × 3 mm  × 3 mm ), diffusion MRI (TR/TE: 8000/92 ms, FoV: 220 mm, voxel size: 2 mm  × 2 mm  × 2 mm , b-value: 1,000 s/mm  in 64 directions, 3 b0s, phase-encoding direction: AP), and 3 b0s with opposite phase-encoding direction from the main DWI sequence (phase-encoding direction: PA). To minimize the possibility of subjects falling asleep under the scanner, which can affect our functional data, we acquired the resting-state fMRI sequence with subjects with open eyes and the third protocol (after localizer and T1 MPRAGE) with a duration of 6:08 mins. \n\n\n### Diffusion-Weighted Imaging Analysis and Tractography \n  \nWe used MRtrix for DWI preprocessing ( ). First, the DWI scan was denoised ( ), and Gibbs ringing artifact was removed ( ) and then preprocessed with   dwifslpreproc   command using reverse-phase encoding b0 scans to perform inhomogeneity distortion correction ( ;  ;  ). Then, B1 field inhomogeneity correction was performed using the ANTs algorithm ( ). Finally, the resulting preprocessed DWI scans were fed to the TRActs Constrained by Underlying Anatomy (TRACULA) tractography pipeline by FreeSurfer v 7.2.0 ( ;  ;  ). \n\nPrior to tractography, the high-resolution structural scans (T1 and T2) were fed into the   recon-all   pipeline to extract white matter and pial surfaces. Cortical parcelation and subcortical volumetry were required for TRACULA. We also performed thalamic nuclei segmentation, which was suggested by Yendiki et al. ( ), to improve tractography for fibers passing the nearby thalamus ( ). The default configuration settings text file of TRACULA was used with changing all preprocessing steps to zero (not perform). TRACULA transforms each subject’s DWI to an anatomical scan (affine transformation), extracts the fractional anisotropy (FA) map, non-linearly transforms it to a high-resolution FA map (named MGH35_HCP_FA_template.nii.gz), fits the probabilistic diffusion model using BedpostX ( ,  ;  ), and then performs tractography. We selected the fibers connecting the DAN and VAN, both intra- and inter-network fibers, including bilateral SLFs (I-II-III) and right AF ( ). The power of TRACULA lies in achieving connectome scanner-level accuracy and tractography quality with DWI data acquired with lower b-values and the number of diffusion directions ( ). We extracted the FA map and mean, axial, and radial diffusivity (MD, AD, and RD, respectively) for each tract afterward. \n  \nTractography   (A)   and resting fMRI components of dorsal and ventral attention systems (DAN and VAN, respectively;   B–E  ).   (A)   Tractography showing four tracts of interest on the right side including the three branches of superior longitudinal fasciculus (SLF) and arcuate fasciculus (AF). Figures b to e show the spatial components of the independent component analysis result identified as DAN and VAN. Coronal views showing   (B)   a region in the inferior frontal gyrus,   (C)   the bilateral intraparietal sulci and the supramarginal gyrus,   (D)   the lateral view showing spatial components in the superior frontal and intraparietal sulcus, as well as a small component in the occipital region, and   (E)   a superior view highlighting bilateral intraparietal sulci and superior frontal gyri. Superior frontal and intraparietal sulci are DAN nodes, and right-side dominant VAN can be visualized as spatial components in the right inferior frontal gyrus and the superior marginal gyrus. \n  \n\n### fMRI Analysis \n  \nWe used the default fMRI pipeline analysis of CONN toolbox v20.b  ( ) ( ) using resting-state fMRI analysis. Functional data were first resampled to 2 mm  × 2 mm  × 2 mm  voxel size, motion-corrected, centered, and slice timing-corrected. Outlier detection using ART was used with a global signal Z-value threshold of 5, and the subject displacement threshold was set to 0.9 mm. Then, the functional and structural data were segmented and normalized to the MNI space. We spatially smoothed the fMRI data using a 6 mm isotropic full-width at half maximum (FWHM) Gaussian kernel. The results of preprocessing were inspected individually to have structural and functional data aligned and normalized. We applied fMRI denoising using the CompCor method ( ) and regressed out physiological noise sources with white matter, cerebrospinal fluid, and scrubbing and motion parameters. Linear detrending and a band-pass filter of 0.008–0.09 Hz were also applied. \n\nTo identify the DAN and VAN, we applied the group independent component analysis (ICA) tool in CONN. We estimated the median number of components of all subjects’ rest fMRI data to be 16 using GIFT toolbox v 3.0c  ( ). Group-level dimensionality reduction was set to 64, the number of factors set to 16, and G1 fast ICA using the group ICA 3 (GICA3) back-propagation method was implemented. Then, we computed spatial match to the template with CONN’s summary tools to identify networks. Using the spatial overlap of suprathreshold areas (Dice coefficient) resulted in a match with the DAN in one of the independent components, with   r   = 0.56 and bilateral IPS and FEFs involved. The VAN is not defined in the template of CONN; however, the same component identified as the DAN also included regions of the right inferior frontal and superior temporal/lower parietal areas (i.e., TPJ), especially on the right side. So, we considered the spatial regions of this component to include both attention networks, DAN and VAN (i.e., IPS, FEFs, right inferior frontal, supramarginal and superior temporal regions, and lateral occipital cortices) ( ). \n\nTo evaluate between-group differences, we used a general linear model (GLM) with age, depression, and anxiety scores (both state and trait) as covariates in the identified spatial component of the VAN and DAN. Moreover, group × MTS score interaction analysis was also performed with the same covariates in the same networks to find group-related differences in behavior and baseline function correlates. Results with a voxel   p  -value threshold < 0.001 and a cluster-wise FDR-corrected   p   < 0.05 were considered significant. \n\n\n### Statistical Analysis \n  \nWe used R version 4.0.4 embedded within RStudio ( ). Between-group differences (PS vs. GS) in age, BDI, and STAI scores were statistically assessed using the t-test or Mann–Whitney   U   test based on the distribution of data. We assessed the correlation between the PSQI total score and components with ESS, SHI, BDI, STAI-T, and STAI-S using Pearson’s or Spearman’s formula based on data distribution. We also used the GLM to assess any association between PSQI components and MTS scores, irrespective of the group, and adjusting for age and scores of depression and anxiety. \n\nDifferences in fiber properties of SLFs and AF between PSs and GSs were evaluated using the same GLM, with age, BDI, and STAI scores as covariates. We also applied an interaction model with MTS measures as the outcome and group × fiber properties as the predicting variable covarying age, BDI, and STAI scores. \n\n\n\n## Results \n  \n### Subject Characteristics \n  \nThe mean (SD) of the education years of the subjects was 12.20 (0.34). Of the 79 subjects, total PSQI scores could be calculated for 71 subjects; 31 subjects had a PSQI total score > 5, indicating a poor sleep quality prevalence of 43.67% in our sample. Although there is no consensus regarding the BDI-II cutoff for depression, using the suggested cutoff of 13 (BDI total ≥ 14) ( ) indicates a prevalence of probable depression in our subjects of 34.67% (26 of 75 completed BDI scores). PS vs. GS differences showed significantly higher ESS, SHI, BDI, and anxiety scores (STAI-T and STAI-S) in PSs than in GSs ( ). Correlation analysis also showed that higher PSQI scores are significantly correlated with higher ESS, SHI, BDI, and anxiety scores ( ). \n  \nMean (SD) of age, Epworth Sleepiness Scale, Sleep Hygiene Index, Beck Depression Inventory, and State and Trait Anxiety Inventory for each sleep quality group based on a Pittsburgh Sleep Quality Index (PSQI) total score of 5. \n      \nCorrelation plot showing bivariate correlations between sleep assessments, depression, and anxiety scores. Correlation coefficients are written inside the cells. All   p  -values are <0.001. PSQI, Pittsburgh Sleep Quality Index; ESS, Epworth Sleepiness Scale; SHI, Sleep Hygiene Index; STAI, State and Trait Anxiety Inventory (STAI-T: Trait, STAI-S: State); BDI, Beck Depression Inventory. \n  \nOf the 79 subjects, 20 right-handed PS and 19 right-handed GS (  n   = 39) were randomly matched by MatchIt ( ) based on age for imaging and MTS task performance at the National Brain Mapping Laboratory, Tehran University, Tehran, Iran. Since there was a 3-month delay between questionnaire filling and MRI/MTS task sessions due to the COVID-19 Alpha/Delta variant surge in Iran, PSQI, BDI, and anxiety questionnaires were filled out again by the participants on the day of MRI acquisition. The new PSQI scores resulted in one of the GS subjects being transferred into our PS group (21 PSs and 18 GSs). \n\n\n### Task Performance \n  \nOverall, 34 subjects successfully completed the MTS task (16 PSs and 18 GSs). While using a GLM with age, BDI, and STAI parameters as covariates, there were no significant associations between MTS task parameters (total correct, mean RT, mean RT change) and PSQI scores (total and each component) ( ). Group differences are shown in  . \n  \nMean (SD) of match-to-sample (MTS) visual search and attention task scores of CANTAB, and demographics for the selected subjects for imaging and cognitive evaluation session. \n    \n\n### Between-Group Differences in Dorsal Attention Networks and Ventral Attention Networks Imaging \n  \nWithout any prior history of claustrophobia or any fears of the dark or closed spaces, 4 subjects, all in the PS group, developed claustrophobia either at the beginning or even prior to the start of the T1 acquisition (during the localizer sequence). Overall, 35 subjects completed the MRI session. \n\nAfter adjusting for age, depression, and anxiety scores, no differences were found between PS and GS in fiber properties of bilateral SLFs and right AF ( ). Moreover, there were no differences in the VAN and DAN between our groups (T-map available at  ). \n  \nMean (SD) for fiber properties of superior longitudinal fasciculus (SLF) branches and right arcuate fasciculus (AF). \n    \n\n### 3.4 Interaction Analysis \n  \nOverall, 30 subjects (13 PSs and 17 GSs) could successfully complete both MRI and MTS tasks. We found significant group × MTS measure interactions for MTS total correct and right SLF3 AD, MTS mean correct RT with left SLF1 AD, right SLF2 FA, right AF FA, MTS mean RT change with right AF FA, and right SLF2 FA (  and  ). Moreover, three significant clusters were also found for the interaction model (  and  ). The results of the fMRI interaction analysis are uploaded on NeuroVault (T-maps on  ). \n  \nInteraction analysis results with match-to-sample scores as the outcome, and fiber properties × Group as the predictor variable. Age, depression, and anxiety scores are covaried. RT, reaction time; SLF, superior longitudinal fasciculus; AF, arcuate fasciculus; FA, fractional anisotropy; AD, axial diffusivity. \n    \nResults of fMRI group–ICA spatial component interaction models corrected at voxel level with uncorrected   p  -value < 0.001 and cluster size   p  -FDR < 0.05. \n    \nInteraction analysis results with match-to-sample scores as the outcome, and group × rest fMRI signal of the spatial components of dorsal and ventral attention systems identified through independent component analysis.   (A)   Cluster identified for mean correct RT × group (PS > GS) in the right lateral occipital cortex, in proximity to intraparietal sulcus,   (B)   cluster identified for total correct × group (GS > PS) in the left middle temporal gyrus (posterior division) and the superior temporal sulcus,   (C)   cluster identified for total correct × group (GS > PS) in the right superior marginal gyrus (posterior division). RT, reaction time; GS: good sleep; PS, poor sleep. \n  \n\n\n## Discussion \n  \nIn this study, we investigated the associations between sleep quality and visual search and attention, using a computerized task (CANTAB match-to-sample), as well as structural and functional correlates of visual attention in two attention networks (dorsal and ventral). In our sample, 43.67% of subjects reported poor sleep quality during the last month based on the PSQI. Poor sleep quality was also correlated with poor sleep hygiene and more daytime sleepiness. It was also highly associated with depression and anxiety. Despite our expectations, we found no associations between sleep quality (based on the PSQI) and visual search and attention, neither in the task nor in the imaging correlates of visual attention covarying for age, depression, and anxiety scores. However, by implementing an interaction model, we found that visual search and attention are highly associated with the DAN (both structural and functional) in the PS group and with the VAN in the GS group. \n\nOne-night lack of sleep is not uncommon among adolescents and early adulthood, and many studies have investigated its effects on cognition so far ( ). However, most studies instructed participants to forcefully not sleep for the purpose of their study. It was not until recently that the effects of poor sleep quality during a longer period (e.g., 1 month) are studied ( ). Poor sleep quality is a common finding in shift workers, such as medical and military staff ( ;  ), but it is also prevalent in the whole population as well, which is estimated to affect one-third to half of the studied population ( ). This raises a major question: What are the neurobiological foundations of poor sleep quality in the general population? It is not unexpected to find lower sleep quality in shift workers due to lack of nighttime sleep, its disruption (e.g., a call from ward), or the stressful nature of their jobs, usually being medical or military ( ;  ). However, what about the general population? Sleep is a complex behavior relating to psychiatric factors such as mood and anxiety levels ( ;  ). This association is as much regarding sleep-related complaints as at least one of the DSM-V criteria for both depression and anxiety disorders ( ;  ). Importantly, one must not confuse correlation with causality; the direction of causality between sleep disruption and psychiatric problems is not clear, but it seems that it is a bidirectional arrow: poor sleep quality can result in psychiatric problems and   vice versa   ( ;  ;  ;  ). We also found a high correlation between poor sleep quality and both depression and anxiety. Considering this correlation and the cognitive association of these disorders ( ;  ;  ;  ;  ;  ), adjusting for depression and anxiety in sleep-related studies is inevitable. \n\nDecreased sustained attention is the most reported finding of cognitive effects of short-period sleep deprivation ( ;  ;  ). Its implications reach far from the area of cognitive sciences, and it is believed that disrupted visual attention may underlie higher rates of accidents after sleep deprivation ( ;  ). However, compared to short-period wakefulness, a few studies have investigated the cognitive effects of low sleep quality over a longer period, yet visual attention itself.   showed that, based on Conner’s continuous performance test (CPT), poor sleep quality was associated with decreased sustained attention in an elderly population (mean age = 60.4).   also reached the same results using a Go/No-Go paradigm to evaluate sustained attention. Of note, both studies evaluate sustained attention based on a task designed with either a letter or number as their stimulus and were not visual attention tasks. Being the first to assess visual attention in poor sleep quality, we did not find any associations between PSQI measures and match-to-sample reaction times, as a measure of visual attention in our sample of 34 subjects. This can be either a genuine finding or due to sample size. There are methods to further analyze negative findings; the simplest and usually used method is the two one-sided test (TOST) ( ;  ). It is a simple approach to test whether the results fall within a specified range of effect size (e.g., Cohen’s d) to conclude the absence of an effect. There is an R package called TOSTER to do it ( ); however, it requires the smallest effect size of interest (SESOI) to be determined and compares the results to it.   proposed a few methods. The first approach involves using a pre-determined fixed effect size (e.g., 0.3 or 0.5), but it is not suggested because the effect rejections may not be applicable to all studies ( ;  ). The second approach is proposed by   based on the effect sizes of a prior study. Since our study is the first in this regard, we did not have any effect size estimation based on prior findings. Also, no differences in the visual attention task performance were replicated in the underlying imaging findings as well; there were no differences in the VAN and DAN between GSs and PSs, both in their fMRI signal and tract properties connecting their nodes. Thus, we believe that our finding is a genuine finding indicating no effects of sleep quality on visual attention, yet future studies are obviously required. \n\nFew studies have investigated neural correlates of poor sleep quality in a healthy population. In a study by  , they implemented a whole-brain functional and diffusion MRI approach toward neural association with poor sleep quality in an elderly population. As in our study on the younger population, they had no significant findings in the white matter properties (i.e., FA, MD, AD, and RD); however, they found lower functional connectivity in a network comprising lower parietal, frontal, temporal, supramarginal, insular, and Rolandic operculum regions associated with higher PSQI scores. Interestingly, they also found no regional volumetric correlates of sleep quality. The presence of no significant imaging correlates of sleep quality does not involve attention networks. Another study using an emotion task fMRI also found no association between sleep quality and neural circuits involved in emotion regulation ( ). Other studies on imaging correlates of sleep quality based on the PSQI were carried out in a population with other major underlying conditions that can affect their sleep, such as Parkinson’s disease ( ), HIV+ ( ), or primary insomnia ( ). \n\nThe results of our interaction analysis are interesting findings. Our findings using both fMRI and tractography showed that task performance is highly reliant on resting activity and properties of fibers connecting the DAN (SLF1 and lateral occipital cortex) in the poor sleeper and the VAN (SLF2 and SLF3 and TPJ) in the good sleeper group. It is a multi-modal finding, found using both fMRI and DWI analysis. Despite not explicitly and overtly implementing a serial visual search task, we believe that this finding probably reflects a higher load on the DAN in PSs and not using the VAN by this group for visual search. Also, since it seems that the serial and parallel search strategies are more reliant on the DAN and VAN, respectively ( ;  ;  ), this finding indicates employing the serial visual search strategy in PSs. Importantly, the exact localization of the TPJ as an important node of the VAN is controversial; however, the supramarginal gyrus is considered a major node of TPJ ( ;  ). \n\nAlthough our study investigates the association between sleep quality and visual search and attention in a task, as well as functional and structural connections of the attention network, it is faced with limitations. The major limitation is the sample size of 39 subjects. Nonetheless, we limited our sample to only include right-handed male subjects to decrease the between-subject variability in the brain and behavior. However, future studies must use a larger sample size including both major genders. For example, we are aware that the ENIGMA-Sleep study is a multi-center study currently conducted to overcome the limitations of small-sample studies ( ). Moreover, based on our interaction analysis findings, using tasks designed to separately investigate serial and parallel search strategies may better elucidate our findings. However, the MTS task does not clearly separate whether subjects have used a serial or parallel search strategy. It has a great potential in separating movement time from reaction time, being computerized and easy to do, and also estimating the increase in cognitive load by increasing the presented stimuli from 2 to 8 objects ( ), but adding an eye-tracking device or even developing it to be observed under an fMRI scanner can clearly improve its power. The readers must also bear in mind the limitations of diffusion-weighted imaging. There are high numbers of cross-fiber in the white matter, estimated to be nearly 90% of the total fibers ( ;  ). Thus, applying multi-shell DWI sequences to higher order models is usually suggested, which can better solve the cross-fiber issue. However, using a b-value of 1,000 s/mm  and a total diffusion direction of 64, as well as the recent TRACULA method, for our analysis can somehow address the cross-fiber issue. \n\nIn conclusion, to our knowledge, this study is the first to investigate visual attention and search in chronic poor sleep. Significant associations of sleep quality were found neither in a visual search and attention task nor in dorsal and ventral attention networks and fibers connecting them. However, we found that task performance is highly reliant on the DAN in the PS group and on the VAN in the GS group, probably reflecting higher cognitive demand in the DAN or implementing different search strategies (serial rather than parallel) in subjects with poor sleep. Future studies with larger sample sizes using separate serial and parallel visual search task designs are suggested. \n\n\n## Data Availability Statement \n  \nThe raw data supporting the conclusions of this article will be made available by the authors, without undue reservation. \n\n\n## Ethics Statement \n  \nThe studies involving human participants were reviewed and approved by the Ethics Review Board of the Iran University of Medical Sciences, Tehran, Iran. The patients/participants provided their written informed consent to participate in this study. \n\n\n## Author Contributions \n  \nAA contributed to the design of the study, data collection, imaging analysis, statistical analysis, and wrote the manuscript. SN contributed to idea formation, designing the study, data collection, and wrote the manuscript. Both authors contributed to the article and approved the submitted version. \n\n\n## Conflict of Interest \n  \nThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n\n\n## Publisher’s Note \n  \nAll claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher. \n\n \n","utf8_text_md5_checksum":"0e5118e34b06053e8259e7a050f4da4f"},
{"annotations":[{"end_byte":35435,"end_char":35287,"label_name":"TaskName_Unsure","start_byte":35422,"start_char":35274},{"end_byte":35435,"end_char":35287,"label_name":"TaskName","start_byte":35422,"start_char":35274},{"end_byte":35684,"end_char":35536,"label_name":"TaskDescription","start_byte":35472,"start_char":35324},{"end_byte":36350,"end_char":36179,"label_name":"TaskName_Unsure","start_byte":36327,"start_char":36156}],"display_title":"pmcid: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4440210\">4440210</a>","list_title":"PMC4440210  fMRI measurements of amygdala activation are confounded by stimulus correlated signal fluctuation in nearby veins draining distant brain regions","metadata":{"batch":1,"doi":"10.1038/srep10499","efetch_url":"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=4440210","field_positions":{"abstract":[352,1370],"authors":[0,156],"body":[1379,41455],"journal":[157,164],"keywords":[339,339],"publication_year":[166,170],"title":[181,325]},"pmc_url":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4440210","pmcid":4440210,"pmid":25994551,"text_md5":"58ce37ccfdfd4ab72cf4bbbf593eb135"},"text":"Boubela, Roland N. and Kalcher, Klaudius and Huf, Wolfgang and Seidel, Eva-Maria and Derntl, Birgit and Pezawas, Lukas and Našel, Christian and Moser, Ewald\nSci Rep, 2015\n\n# Title\n\nfMRI measurements of amygdala activation are confounded by stimulus correlated signal fluctuation in nearby veins draining distant brain regions\n\n# Keywords\n\n\n\n# Abstract\n \nImaging the amygdala with functional MRI is confounded by multiple averse factors, notably signal dropouts due to magnetic inhomogeneity and low signal-to-noise ratio, making it difficult to obtain consistent activation patterns in this region. However, even when consistent signal changes are identified, they are likely to be due to nearby vessels, most notably the basal vein of rosenthal (BVR). Using an accelerated fMRI sequence with a high temporal resolution (TR = 333 ms) combined with susceptibility-weighted imaging, we show how signal changes in the amygdala region can be related to a venous origin. This finding is confirmed here in both a conventional fMRI dataset (TR = 2000 ms) as well as in information of meta-analyses, implying that “amygdala activations” reported in typical fMRI studies are likely confounded by signals originating in the BVR rather than in the amygdala itself, thus raising concerns about many conclusions on the functioning of the amygdala that rely on fMRI evidence alone. \n \n\n# Body\n \nThe human amygdala is the target of a large number of imaging studies due to its central role in emotion processing , emotional learning  and its potential involvement in various psychiatric disorders . Functional magnetic resonance imaging (fMRI) in particular is one of the tools most commonly employed to study the role of this brain region , and indeed has proven a valuable resource (at the time of writing, a pubmed search using the search terms ‘(“fmri” or “functional magnetic resonance imaging”) and amygdala’ yields 2500 results). Still, there is notable heterogeneity and disagreement between fMRI studies of the amygdala, both in terms of activations in tasks  and functional connectivity during rest . \n\nTypical forms of disagreement between studies are the failure of newer studies to replicate results from earlier papers or to find any significant results in the amygdala at all . More subtle effects can be differences in lateralization between studies  or unintuitive laterlization effects within a study. For example, Manuck   et al  .  suggest that their “observed right laterality bias reflects the visuospatial processing demands of [their] paradigm, which preferentially engages right hemisphere circuits”, but without explaning the exact mechanisms that would cause this effect on their measured amygdala activations. \n\nHints for the difficulties in replicating previous amygdala fMRI results might be found in the outcome of reproducibility studies of activation patterns in the amygdala . These studies found that among the paradigms and regions of interest studied, the amygdala activation is the least reproducible both at group and at single-subject level , and that reproducibility of amygdala results even decreased after physiological noise correction, suggesting that the most reproducible findings in the amygdala region might be due to physiological effects . In addition, repeatability was much lower at single-subject level than at group level, leading to a critical view on potential diagnostic uses of such data as opposed to group-level comparisons only . \n\nAnother contribution to the heterogeneity of fMRI results might be found in the type of stimuli used. Emotional faces are a typical cue to evoke amygdala activations, but difficulties arise when choosing an appropriate control condition: neutral faces are considered unreliable in this respect , so non-face control stimuli are more widely used as control condition, but bear the risk of mixing activations due to emotion with activations related to face recognition. More generally, in an early fMRI meta-analysis, Phan   et al  .  found that visual stimulation is more robust in inducing amygdala activation than auditory stimulation (note that none of the studies using auditory cues lead to activations in the amygdala), and that fear is the most robust emotion to evoke activation, with a much higher proportion of studies using fearful emotional cues yielding significant results in the amygdala than happiness, sadness, anger or disgust. This difference in amygdala activation strength depending on the emotion expressed by the faces shown is corroborated by a later meta-analysis by Fusar-Poli   et al  . . More recent studies though found amygdala activations also with non-visual stimuli, including increased amygdala activation in reaction to auditory stimuli in blind subjects compared to healthy controls . Amygdala activations in response to emotion can be evoked in a wide variety of different ways, as shown by various studies employing different paradigms, including auditory, haptic and even intrinsic (e.g., memory recollection) stimuli. Meta-analyses investigating the results of these studies have identified significant variability across different stimulation types, highlighting potential heterogeneity in amygdala activation patterns introduced by the paradigm design. There exists evidence that visual stimuli are among the most robust in producing amygdala activations , with a meta-analysis on subliminal stimuli pointing into the direction that in this particular case, reproducible activations in the amygdala region could be found only in visual stimulation using faces, not with any of the other (somatic, auditory, lexical) paradigm types . Still, even among visual stimuli, the most commonly employed type of paradigm, there is considerable variability in terms of the exact setup of the paradigm as well as in the results induced in terms of amygdala activation. The origin of heterogeneity across different types of paradigms is not yet understood, and it is unclear whether it is due to different responsivity of the amygdala to different types of stimuli or to confounding factors introduced by different types of stimulation that are not directly related to amygdala responsivity. \n\nAnother issue that has been investigated as a potential source of inconsistencies is low signal-to-noise-ratio (SNR), which can be problematic in the amygdala region due to local magnetic field inhomogeneity . Indeed, time series SNR is low in many voxels in and around the amygdala and can vary greatly between left and right amygdala , an observation which suggests that researchers should be wary of null findings in these areas, as they might rather reflect signal loss than absence of neuronal activity, in particular in medial and ventral parts of the amygdalae where signal dropout is greatest. Moreover, lateralization effects are only rarely tested for statistical significance and thus often represent only small, statistically insignificant differences unlikely to be replicated in later studies. For the same reason, even when a study reports amygdala activations to be significant only in one hemisphere, the   difference   between the left and right amygdala activations might in itself not necessarily be statistically significant, and such a result should therefore not be misinterpreted as evidence in terms of lateralization effects. While this is true both in this particular case as well as in general when interpreting null results of statistical tests, it does not preclude the investigation of other leads concerning the reasons of the unreliability of results. Of note, Johnstone   et al  .  achieved fairly good SNR values across the whole amygdala, but nonetheless the activation patterns shown spanned primarily the dorsal and medial parts of the amygdalae, which in their case is less likely to be due to SNR issues in the more ventral parts. Additionally, they found higher reproducibility in the left amygdala than in the right one, despite the SNR values for the left amygdala being lower—hinting at the idea that SNR might not be the only issue at work here. \n\nNew MR sequences might help to shed light on the constitution of signal variability in the amygdala region. Multiband Echo-Planar Imaging (EPI) sequences  allow for the acquisition of fMRI time series with very high temporal resolution that significantly increase functional SNR  and are able to critically sample physiological high-frequency fluctuations, thus offering the possibility to distinguish between these signals and low-frequency fluctuations in areas where both types are abundant, such as the amygdala region . Indeed, overcoming the reduction in SNR due to aliased high-frequency oscillations as well as a higher sampling of the signal variation in its own right leads to a better understanding of the oscillations in and around the amygdalae. Thus, in the present study, we investigated activations in the amygdala region to the presentation of emotional faces using these new techniques alongside more conventional Blood-Oxygenation-Level-Dependent (BOLD) EPI sequences to investigate the origins of signal fluctuations and their heterogeneity in this region and the effects this may have on fMRI research using standard scanning techniques. \n\n## Results \n  \nWe used three main approaches to address the question stated above. The main body of evidence is a low-TR multiband EPI dataset of 16 subjects, comprising both a typical amygdala activation task and a resting state scan, supported by susceptibility-weighted imaging (SWI) for the identification of cerebral veins (in addition to standard T1-weighted reference images). To show that results also apply to standard fMRI studies and rule out the possibility that findings in the first dataset are merely artifacts of this new acquisition method and/or its scan parameters, a comparison dataset of 134 conventional high-TR BOLD EPI scans is used where the same amygdala activation task is employed. Finally, results are complemented by a comparison of the maps identified here with activation cluster coordinates from the literature to underline that distorted results due to the effect described here are indeed widespread. \n\nThe analysis of the low-TR datasets, after standard preprocessing except for the omission of spatial blurring, yielded group-level activation maps for the contrasts ‘Faces − Forms’ with bilateral activation peaks in the occipital lobe, fusiform gyrus, middle frontal gyrus as well as in the amygdala region and around the brain stem (see  ). Activations for the contrast ‘IAPS − Forms’ were essentially in the same regions, with very similar spatial activation patterns. The activation in the amygdala region is particularly noteworthy insofar as it does not represent a focal activation cluster centered on the amygdala, but rather follows a linear course from the amygdala around the brainstem until it joins the posterior activation cluster in the occipital lobe. This corresponds to a typical course of the basal vein of Rosenthal (BVR) , which can be identified in the single-subject SWI data. Indeed, for the 13 subjects for which SWI data were available, this course of the BVR with a posterior drainage could be observed in 16 hemispheres (6 hemispheres showed a clearly different path of the BVR, 4 could not be clearly identified). These single-subject SWI datasets can be compared to the single-subject activation maps from the matching task to identify a correspondence between the venous path in the SWI datasets and the activation clusters in the amygdala region (see  ). Since the vein is in some cases difficult to track on the limited number of slices displayed in a figure on paper, we have also compiled a video scrolling through all the relevant slices for all subjects (see  ). Despite anatomical variability across subjects, the typical course of the BVR can even be distinguished on a mean SWI image averaged across all subjects (see  ). \n\nTo assess whether the activated voxels were more likely to reflect signal changes within the amygdala or in the vasculature around it, resting-state functional connectivity was computed from those same voxels, using the voxels with highest activations from the matching dataset in the amygdala region as seed regions for each subject. Rather than using a thresholded activation map directly, which leads to seed regions of different sizes across subjects and therefore might introduce some bias, we opted to use each subject’s 100 voxels with the highest t-values in the amygdala region as the seed for the functional connectivity analysis. Mean functional connectivity z-scores for 16 subjects are shown in  , revealing a high correlation of the signal from the voxels in the amygdala region that were activated in the task with further voxels on the path of the BVR, as well as other regions characterized by the proximity of large vessels, in particular the lateral sulcus. This pattern of connectivity is markedly different than the functional connectivity associated with the amygdala in previous studies, as well as the functional connectivity of voxels more clearly within the amygdala in our dataset, as identified from various different voxels in the amygdala, but further away from the BVR at its border using AFNI InstaCorr (see  ). This means that the peak activation voxels in the task GLM are, considering their functional connectivity structure, more likely to be located in the BVR than in the amygdala itself. Note also that functional connectivity patterns can vary greatly between even neighbouring voxels in the amygdala region, and that voxels contaminated by vessel signal can be easily distinguished from other voxels by their functional connectivity to other voxels containing vessels. In some cases, voxels with some contamination can be seen between uncontaminated voxels and unambiguous BVR voxels, but at some places, BVR voxels and voxels without any visible contamination by venous signals are direct neighbours. In both cases, the distance between unambiguous amygdala voxels and unambiguous BVR voxels is less than 2 mm. \n\nIn the high-TR dataset, using the same preprocessing pipeline as in the low-TR dataset (i.e. standard preprocessing, but without spatial smoothing), similar activation peaks as with the low-TR dataset can be seen. Most important for our purposes is the clear identification of a bilateral linear formation of activated voxels starting around the amygdalae, passing around the brain stem on both sides before converging in the occipital brain and becoming indistinguishable from the large swathes of activation in the visual cortex (see  ). In the high-TR dataset, the sensitivity in subcortical regions does not allow for an unambiguous identification of the vein at single-subject level, but subgroup analyses reveal that activation in the BVR not only occurs in large sample sizes. Rather, even at the more typical fMRI study sample size of 30 subjects, the activation pattern along the BVR can be clearly discerned (see  ). \n\nTo assess the potential influence of the effects observed in our data on previously published results, coordinates of activation foci for the emotional face > neutral face contrast in the left and right amygdalae, parahippocampal gyri, fusiform gyri and posterior fusiform gyri as provided in the meta-analysis by Sabatinelli   et al  .  (see   for the coordinates used) were used and compared with our group results (see   and  ). Note the close proximity of the four activation foci identified by the meta-analysis in the ventral brain, designated there as left and right amygdala as well as left and right parahippocampal gyrus, to the course of the BVR as identified in our dataset. The meta-analysis by Fusar-Poli   et al  .  also provides coordinates of peak activation, but in Talairach space. We did not depict them separately in our figures and rather use the coordinates from Sabatinelli   et al  .  to avoid potential errors in the transformation of the coordinates, but it should be noted that after our transformations in MNI space, all but one of the amygdala coordinates provided by Fusar-Poli   et al  .  were within one voxel–2 mm—of the coordinates provided by Sabatinelli   et al  . , indicating that the choice of which meta-analytic coordinates to use did not bias our results. Most, but not all, of the other activation foci identified in the meta-analysis correspond to activation clusters seen in our dataset as well. In particular, the activation foci designated as fusiform gyrus and posterior fusiform gyrus, regions potentially drained by the BVR, correspond to large clusters of activation in our dataset. \n\nCorrelations between the signal time courses after accounting for the task blocks show that there are significant connections between the fusiform activation cluster and the ipsilateral BVR cluster, but also between other regions, e.g. between the visual cortex and the fusiform clusters, which might be interpreted as functional connectivity. It is noteworthy though, that the fusiform activation cluster explain more variance in the BVR than the visual cluster (see  ). While this is not in itself a proof for a direct connection, it is consistent with the fact that the BVR may drain the fusiform gyrus, but not the occipital lobe. \n\n\n## Discussion \n  \nThe increased functional sensitivity of low-TR multiband BOLD EPI made it possible to show that major signal changes measured in the amygdala region in a typical emotional task is not, in fact, located in the amygdala itself. Rather, these signal changes occur in the adjacent Basal Vein of Rosenthal (BVR) that drains large regions of the medial temporal lobe and has confluences from other large veins in the amygdala region, and are therefore largely unrelated to neuronal activity in the amygdala itself. While the suggestion that fMRI being only an indirect measure of neuronal activity is not in the least a novel concept , the possibility of signal changes in veins in the ventral brain at such a large distance from the neuronal origin (in this case, probably the fusiform gyrus) have not been demonstrated before. Although the clarity of the association of this activation locus with the BVR at single-subject level is only achieved using novel low-TR multiband sequences, the impact of its effect on fMRI results cannot be missed even in datasets acquired with more commonly employed EPI sequences and parameters. This can be seen in our comparison dataset as well as in the literature on the mapping of emotion processing as a whole, as exemplified in the comparison of our results with the locations of activation foci from meta-analyses . \n\nAs mentioned above, the BVR drains large parts of the medial temporal lobe, but it also usally connects to the deep middle cerebral vein draining the insular and the striatal veins, thereby forming the striatal BVR segment. At the uncus, close to the amygdala, the striatal segment unites with the peduncular BVR segment, where additional peduncular veins join the BVR. The latter often build an anastomosis receiving blood from the contralateral temporal region via the interpeduncular veins. Concerning the peduncular BVR segment the amygdalar vein is an important, but by far not the only, draining vessel of the temporal pole region that variably joins the BVR. Additionally, the venous blood from the anterior region of the medial temporal lobe may not be drained by the BVR only, but also to the superior petrosal or the cavernous sinus . One should thus be careful when making generalizations on the venous structures around the amygdala, as there exist large inter-subject heterogeneity. For example, the anterior segment of the BVR does not or not predominantly drain into the posterior segment and, ultimately, into the vein of Galen, but rather has its own, anterior, drainage, in about a third of the hemispheres—in these cases, the observed activation patterns might differ from those presented in the group average maps in   and   in that it would lack the anterior-posterior connection around the brain stem to the vein of Galen. What can be observed rather consistently is the confluence of the aforementioned deep middle cerebral vein, anterior cerebral vein, and the striatal segments in the proximity of the amygdala. Thus, while the course around the brain stem might be one of the most distinctive features of the BVR activation in   and  , BVR contamination in the amygdala region is likely to occur even in cases where this particular course is not observable. For an excellent schematic of different variants of the BVR, see Fig. 9 by Fernndez-Miranda   et al  . . \n\nDespite this anatomical variability, the confounding effect of the BVR on the signal measured in the amygdala region is very consistent, as it appears in multiple independent datasets under different circumstances. The low-TR multiband dataset using the matching paradigm task had the maximum sensitivity at single subject level due to its high temporal and spatial resolution, the large number of time points acquired and the ability of critically sampling cardiac frequencies at which physiological signal contaminations occur, which could thus be eliminated from the dataset by temporal filtering. Indeed, in this dataset, the systematic stimulus-correlated signal variations are clearly discernable even at the single-subject level (see  ) and can be localized to the veins around the amygdala. The resting-state dataset, acquired during the same scan session with the same protocol, confirms that the signal in the voxels that showed highest activation in the amygdala region were characterized by strong correlation to the signal from voxels follwing the course of the BVR further around the brain stem towards the vein of Galen, the most common variant of the draining of the BVR , and from other voxels in regions with major vessels, like the lateral fissure. This pattern contrasts sharply with the pattern of connectivity found in voxels located more clearly within the amygdala itself, which show no significant correlation of their signal with these regions (see  ). In some cases, voxels partially contaminated by venous signals can be seen between voxels that can be unambiguously attributed to the BVR and the amygdala, and it is noteworthy that there is often less than 2 mm between such unambiguous voxels. This means that when preprocessing pipelines using spatial smoothing with 6 or 8 mm FWHM kernels are applied, as is often the case in standard fMRI preprocessing, the BVR signal contamination is drawn into amygdala voxels that would otherwise have been unaffected. With a smoothing kernel of 8 mm FWHM, for example, this would mean that in a typical amygdala (typically less than 10 mm across), all voxels in the amygdala would be affected by this contamination to some degree. Without spatial smoothing, the spread of the contamination is much reduced, basically to that induced by the point spread function of the MR measurement and partial volume effects, and thus typically reduced to up to the voxel size (typically 2-3 mm). \n\nStill, results based on the low-TR datasets alone might be subjected to criticism concerning the relevance of these results for studies using standard fMRI protocols, and it might be objected that the confounding effect described here is only an artifact of the new measurement protocol used, and the observations made based on this might thus not be broadly applicable to other fMRI studies. This can, however, be ruled out by the comparison with the large dataset using a conventional fMRI protocol, which, when analyzed without spatial smoothing, revealed the same pattern of activation even though it does not share the peculiarities of our multiband acquisition (high sampling rate, large slice gap, etc.). This appearance of the BVR activation in the results in two datasets using very different measurement protocols strongly suggests that its origin is related to the brain rather than the measurement protocol. Both datasets did, however, use the same stimulus, the emotional matching paradigm, and the signal changes in the BVR being correlated to the stimulus blocks imply that they are are related to the brain’s response to the performance of this paradigm in some way. \n\nThis discovery has rather wide-ranging implications. Most immediately, it casts doubt on previous findings on amygdala function that rely solely on fMRI as evidence, in particular where reproducibility has been limited and efforts to confirm them have repeatedly proven difficult . Of course, this should not be interpreted as fMRI being principally unable to detect amygdala activations, and neither do we want to dispute the role of the amygdala in the processing of emotions per se, as this is established well enough even when completely disregarding all fMRI evidence. What can be said, though, is that one should be more wary of fMRI signal changes in this region instead of attributing them to neuronal activity in the amygdala without careful analyses of potential confounding contributions. Due to the confluence of the amygdalar vein into the BVR, it is impossible to say whether—or, to what extent—signal changes measured in BVR voxels may be due to neuronal activity in the amygdala, in more distant brain regions, or both. Furthermore, it is important to acknowledge that, while being a very convenient tool for measuring brain activity  , fMRI also has severe limitations that need to be explored in detail, but are currently often ignored or downplayed . \n\nWe chose a broad approach in demonstrating the effects of the BVR in emotional fMRI paradigms to address possible objections that our finding is dependent on the particular measurement technique involved. Indeed, both the cortical activation patterns and the BVR “activations” are remarkably similar between the two different acquisition protocols employed, suggesting that the effect is not merely a peculiarity of one specific acquisition technique. The impact on the wider literature, on the other hand, is more difficult to assess by any means short of a re-analysis of the original data. Still, the robustness and close correspondence of the location of the venous signal between our two datasets together with the fact that the coordinates of activation foci identified in the meta-analysis by Sabatinelli   et al  .  exactly match this location are highly suggestive. Whether a particular finding in the literature reflects amygdala or BVR signal often remains unclear, especially since the figures shown in a paper typically show slices passing through the amygdala, but give no further indication on the extent of activations in other nearby slices that might give more hints at whether the activation pattern continues to follow the BVR. In addition, the ubiquitous preprocessing step of spatial smoothing helps to diffuse BVR signal changes along most of its course except in the immediate vicinity of the amygdala, i.e. in the region of the confluence of the BVR’s striatal into the anterior peduncular segment. There, three-dimensional gaussian kernels centered in different voxels of the BVR overlap in amygdala voxels, thus strengthening the impression that the activation peak arises from the amygdala itself. \n\nThe resting-state findings illustrate that the signals seen in the voxels we found activated in the emotional task in the amygdala region are most strongly correlated with signals in areas characterized by large vessels, such as around the brain stem and in the lateral fissure. This highlights that signal changes in these areas are not likely to reflect neuronal activity at the location of the measured signal change, but rather (task-related) vascular effects (possibly related to neuronal activity in more distant brain regions). Nevertheless, since the task activations are correlations of the signal time series with a block design, they should not be thought of as representing physiological pulsations—the effect clearly emerges from the presentation of the stimulus. This also means that regression-based methods as otherwise employed to eliminate physiological effects cannot be used in this context, as the elimination of a stimulus-correlated signal as a nuisance regressor would negate all stimulus effects from later analyses \n\nA further question to ask here is what the mechanisms are that lead to the stimulus-correlated signal changes in these voxels. The most likely candidate seems that it originates from blood drained from other brain regions which are directly activated by the task. Among the regions identified in our datasets, the fusiform gyrus appears to be the region with the largest (both by magnitude and extent) activation observed among the regions which most likely drain to the BVR. The ANOVA results, indicating that the residual time series in the fusiform activation clusters best explain the signal variation in the BVR, are consistent with that hypothesis. It also corroborates the observation by Manuck   et al  .  quoted above that lateralization differences in activations in the amygdala region might be related to differences in visuo-spatial processing demands of the paradigms used, and provides a possible explanation of the mechanisms causing it. Furthermore, a large fMRI study by Mende-Siedlecki   et al  .  including 215 subjects recently identified a network active in facial recognition regardless of emotional content—this network also consisted of the amygdalae and the fusiform gyri, suggesting a connection between the two in their activation to the presentation of pictures of faces. \n\nIf this hypothesis on the origin of the signal change is true, it would also suggest that an emotional task widely used to produce activations in the amydala region actually does not seem to involve the amygdala in a way robustly measureable by fMRI. This does not mean that the amygdala is not involved in the processing of this task—as this has been confirmed by multiple studies using different modalities not confounded by venous signal changes . However, it might be necessary to design paradigms specifically for fMRI that do not lead to the systematic BVR signal changes that overshadow any neuronal activation in the amygdala region. If the origin of the BVR signal fluctuations lies in the fusiform gyrus, this might not be easy given the ubiquitous involvement of the fusiform in face and object recognition —tasks without visual cues might perhaps be worth experimenting with. Alternatively, fMRI studies aiming to test activations of the amygdala could be combined with a careful work-up of the regional venous drainage, e.g. based on phase contrast angiography. \n\nBeyond the implications for research on the amygdala itself, if the effect indeed originates in the fusiform gyrus, then our results demonstrate that BOLD signal changes induced by neuronal activity can occur in voxels much farther from the actual source of activation than previously believed. It is thus plausible that such effects might also occur in other areas of the brain characterized by the presence of large vessels and where fMRI currently often leads to ambiguous results—the coordinates for the parahippocampal gyrus noted in Sabatinelli   et al  .  also fall on BVR voxels in our analysis, and the insula might also be a worthwile target for similar analyses. \n\nAnother intriguing possibility is that the signal changes in the BVR might have no localizable origin at all: in an analysis of task response in the brain under low-noise circumstances and thus high statistical power, Gonzalez-Castillo   et al  .  showed that signal time courses in 95% of brain voxels were correlated to the task, albeit only with a small magnitude of task-related signal change and therefore below the detectability threshold of typical fMRI studies with lower power. Nevertheless, the confluence of blood with task-related oxygenation-level changes from wide areas might lead to a larger net sum effect in the veins draining these regions, and thus to a detectable signal change in the veins despite the signal changes in the individual regions contributing to it being too small to be detected in the experiment. Further research is needed to pinpoint the exact origin and mechanisms of the BVR signal fluctuations and clarify whether a local (e.g., the fusiform gyrus) or a more global origin is more plausible. \n\nWhile at first glance, the implication that past investigations of emotional processing pathways in the brain have been heavily confounded by a physiological artifact seems largely negative, but the flip side of this coin is that, with current methods, the identification of this artifact can be rather easy. In addition, the robustness of the localization of the vein after normalization in standard space (MNI in our case as well as the meta-analysis by Sabatinelli   et al  . ) means that researchers can easily identify the location of their unsmoothed activation peaks in MNI space and find out whether they match the coordinates of the BVR provided here. A more direct and rather conservative approach might be to use voxelwise resting-state connectivity from potentially contaminated voxels and discard voxels based on their connectivity pattern (see  ) at single-subject level, which might prove a promising method provided that a resting-state scan using the same measurement protocol and slice positioning is available. For group level analyses, in view of anatomical differences between subjects leading to a large number of voxels affected in at least some subjects, this type of method might need some additional refinement, though. We hope that by eliminating this artifact from the data—either by simply discarding affected voxels or perhaps in the future by more sophisticated techniques—a more unambiguous investigation of amygdala functioning using fMRI might lead to more convergent findings in the near future. \n\n\n## Materials and Methods \n  \n### Subjects \n  \nSixteen healthy subjects (9 females/7 males, mean age  , SD  ) were recruited at Medical University of Vienna. Exclusion criteria were prior psychiatric or neurologic illnesses, as well as the usual exclusion criteria for MR studies. All subjects gave written informed consent prior to the scan and the study was approved by the Ethics Committee of the Medical University of Vienna. All methods were carried out in accordance to the approved guidelines. \n\n\n### Data Acquisition Protocols \n  \nAll MRI scans were performed on a 3 Tesla TIM Trio using the standard 32-channel head coil and whole-body gradients (Siemens Medical Solutions, Erlangen, Germany). First, a high-resolution anatomical image was acquired using MPRAGE with 1 × 1 × 1.1 mm  resolution, and 160 sagittal slices (TE/TR = 4.21/2300 ms, flip angle 90°, inversion time 900 ms). Second, BOLD fluctuations at rest were measured with an advanced, low-TR multi-band EPI-sequence  using 1.7 × 1.7 × 2 mm  resolution, 2 mm slice gap (matrix size 128 × 128, 32 axial slices aligned with the AC-PC line, TE/TR = 31/333 ms, flip angle 30°, multiband factor 8, bandwith = 1776 Hz/Pixel) collecting 1200 volumes. Subsequently, the same EPI sequence was used during a commonly employed matching task  designed to activate the amygdala. Subjects were shown triplets of geometric shapes (as neutral stimuli) and of threatening scenes as well as fearful faces (as emotional conditions) presented in alternating blocks of neutral and emotional stimuli. In this task-fMRI experiment, 1420 volumes were acquired. Finally, susceptibility weighted images (SWI) were acquired at 0.6 × 0.6 × 2.0 mm resolution (matrix size 384 384, 52 slices per slab, 1 slab, TE/TR = 29/42 ms, flip angle 15°) to visualize medium to large venous vessels . \n\n\n### High-TR Reference Dataset \n  \nFurthermore, a second dataset consisting of 134 different healthy subjects (70 f/64 m) was used for comparison purposes. This dataset was also acquired at Medical University of Vienna, and comprised anatomical images using the same MPRAGE sequence as above, as well as functional scans using the same emotional matching task as above, but acquired with a 12 channel head coil and a standard (i.e., non-multiband) single-shot EPI sequence with a TR of 2 s, totalling 280 volumes (TE/TR = 42/2000 ms, 96 × 96 matrix, 210 mm square FOV, 20 axial slices aligned with the AC-PC line, slice thickness = 4 mm, slice gap = 1 mm, interleaved slice acquisition). Earlier results from the same study have been published in Scharinger   et al  . , where a more detailed account of the clinical assessments and inclusion criteria as well as the functional task can be found. \n\n\n### Preprocessing of Anatomical Data \n  \nT1 weighted anatomical images were skull-stripped and normalized to MNI152 space using AFNI, and the transformation matrix of this normalization saved for later use. SWI images were coregistered to the T1 weighted images and subsequently normalized using the transformation matrix from the T1 image normalization. \n\n\n### Preprocessing of Functional Task Data \n  \nAlignment and coregistration of the functional images to the T1 weighted images in MNI space were performed using the AFNI script align_epi_anat.py, using the first volume of each EPI run as the reference volume for the alignment. Functional images were despiked using AFNI 3dDespike, and masked with the binarized skullstripped (using AFNI 3dSkullStrip) T1 weighted image. Voxel time series were converted to percent signal change and bandpassed to frequencies between 0.01 and 0.1 Hz using AFNI 3dBandpass. Voxelwise general linear models were then computed with AFNI 3dDeconvolve, using the motion parameters from the alignment step as covariates and the stimulus blocks convolved with a standard hemodynamic response function as regressors. Finally, for group analyses, the single-subject coefficients for the contrasts ‘Faces – Forms’ and ‘IAPS Pictures – Forms’ were averaged across subjects. The preprocessing steps were applied in the same way to both the high- and low-TR datasets and were chosen to reflect common preprocessing strategies. The only exception to note, however, is the absence of spatial smoothing from the preprocessing pipelines, to avoid the blurring of spatially fine-grained effects. \n\n\n### Correlation analyses \n  \nTo assess the signal correlations between the task-activated regions, the residuals from the high-TR general linear models of each subjects were used. Regions of interest defined as the overlap of the group task activation map at a beta value of 0.5 (to avoid having voxels within the mask that have no relationship to the activation observed) with spheres with a radius of 8 mm centered on the ROI coordinates for the left and right amygdalae, parahippocampal gyrus, fusiform gyrus, posterior fusiform gyrus and visual cortex taken from the meta-analysis by Sabatinelli   et al  . , see  . Pairwise correlations between these regions were computed, along with linear models incorporating fusiform gyrus, posterior fusiform gyrus and visual cortex as regressors to explain the amygdala signal. Using the latter, analyses of variance were performed to assess the predictive value of these variables on amygdala signals. All of these analyses were performed for the left and right hemispheres separately. \n\n\n### Preprocessing and Analysis of Resting-State Data \n  \nFor the resting-state data, preprocessing steps as for the task data were followed, but the bandpassing was extended to a larger band of frequencies, from 0.01 to 0.4 Hz, to harness a larger proportion of the spectrum of the signal time series for the connectivity analyses . For the assessment of BVR functional connectivity, seed time series were extracted as the mean time series from within a mask defined for each subject as the 100 voxels with the highest t-values in its single-subject GLM results for the contrast ‘Faces–Forms’ within in a group mask defined by the intersection of (a) the activation map from the group functional task GLM of the low-TR dataset thresholded at   and (b) two spheres with a radius of 14 mm centered on the left and right amygdala. Using this seed, each subject’s whole-brain functional connectivity map of the voxels activated during the task in that particular subject’s GLM was calculated, the correlation coefficients for these maps were converted to z-scores using the Fischer transformation, and the resulting z-maps were averaged across subjects to generate a group connectivity map. In addition, single-subject functional connectivity for individual voxels was assessed using AFNI InstaCorr to evaluate differences in correlation structure seen between individual voxels. \n\n\n\n## Author Contributions \n  \nR.N.B., E.M.S., B.D., L.P., C.N. and E.M. designed the study. R.N.B., K.K., E.M.S., C.N. were involved in the data acquisition process and R.B., K.K., W.H. and E.M.S. performed the data anaysis. R.N.B., K.K., W.H., C.N. and E.M. wrote the main manuscript text and R.N.B., K.K. and W.H. prepared the figures. All authors reviewed the manuscript. \n\n\n## Additional Information \n  \n How to cite this article  : Boubela, R. N.   et al  . fMRI measurements of amygdala activation are confounded by stimulus correlated signal fluctuations in nearby veins draining distant brain regions.   Sci. Rep.   5  , 10499; doi: 10.1038/srep10499 (2015). \n\n\n## Supplementary Material \n  \n \n","utf8_text_md5_checksum":"58ce37ccfdfd4ab72cf4bbbf593eb135"}
]
